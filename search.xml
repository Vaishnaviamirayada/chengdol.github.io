<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Ansible Galaxy Modules</title>
    <url>/2020/12/16/ansible-galaxy/</url>
    <content><![CDATA[<p>最近在做项目的时候，发现用到了Ansible Galaxy上的模块，这里记录一下。</p>
<p><a href="https://galaxy.ansible.com/" target="_blank" rel="noopener">Web page</a></p>
<ul>
<li><a href="https://galaxy.ansible.com/lean_delivery/java" target="_blank" rel="noopener">ansible java role</a>，对于安装不同的Java 版本非常方便。</li>
</ul>
]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Module Reference</title>
    <url>/2019/03/22/ansible-module-refer/</url>
    <content><![CDATA[<p>There are some commonly used Ansible modules that I will refer frequently. More specific detail please see Ansible document.</p>
<p>How to organize the ansible files structure, see best <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html" target="_blank" rel="noopener">practice</a>.</p>
<h2 id="k8s"><a href="#k8s" class="headerlink" title="k8s"></a>k8s</h2><p>挺有意思，看看这篇文章，和Helm做了一下比较:<br><a href="https://blog.51cto.com/99cloud/2336420?source=dra" target="_blank" rel="noopener">https://blog.51cto.com/99cloud/2336420?source=dra</a></p>
<p>Manage kubernetes objects<br><a href="https://docs.ansible.com/ansible/latest/modules/k8s_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/k8s_module.html</a></p>
<p>除了这个，还有其他一些k8s相关的moduels.</p>
<h2 id="pause"><a href="#pause" class="headerlink" title="pause"></a>pause</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/pause_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/pause_module.html</a><br>Pauses playbook execution for a set amount of time, or until a prompt is acknowledged. All parameters are optional. The default behavior is to pause with a prompt.</p>
<p>The pause module integrates into async/parallelized playbooks without any special considerations (see Rolling Updates). When using pauses with the serial playbook parameter (as in rolling updates) you are only prompted once for the current group of hosts.</p>
<p>Useful when debug certain task to see the execution result:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># just pause </span></span><br><span class="line"><span class="attr">- pause:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># a helpful reminder of what to look out for post-update.</span></span><br><span class="line"><span class="attr">- pause:</span></span><br><span class="line"><span class="attr">    prompt:</span> <span class="string">"Make sure org.foo.FooOverload exception is not present"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># pause to get some sensitive input.</span></span><br><span class="line"><span class="attr">- pause:</span></span><br><span class="line"><span class="attr">    prompt:</span> <span class="string">"Enter a secret"</span></span><br><span class="line"><span class="attr">    echo:</span> <span class="literal">no</span></span><br></pre></td></tr></table></figure></p>
<h2 id="skip"><a href="#skip" class="headerlink" title="skip"></a>skip</h2><p>Sometimes I need to skip some tasks promptly, how to do this?<br>It seems there is no <code>skip</code> module in ansible, but we have workaroud:<br><a href="https://unix.stackexchange.com/questions/424151/skip-some-task-with-prompt-in-ansible" target="_blank" rel="noopener">https://unix.stackexchange.com/questions/424151/skip-some-task-with-prompt-in-ansible</a></p>
<p>You can also apply <code>tag</code> or conditionals<br><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html</a><br><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html#conditionals" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html#conditionals</a></p>
<h2 id="debug"><a href="#debug" class="headerlink" title="debug"></a>debug</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/debug_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/debug_module.html</a><br>This module prints statements during execution and can be useful for debugging variables or expressions without necessarily halting the playbook.</p>
<p>Useful for debugging together with the ‘when:’ directive.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Example that prints return information from the previous task</span></span><br><span class="line"><span class="attr">- shell:</span> <span class="string">/usr/bin/uptime</span></span><br><span class="line"><span class="attr">  register:</span> <span class="string">result</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## var option already runs in Jinja2 context and has an implicit &#123;&#123; &#125;&#125; wrapping</span></span><br><span class="line"><span class="attr">- debug:</span></span><br><span class="line"><span class="attr">    var:</span> <span class="string">result</span></span><br><span class="line">    <span class="comment">## this verbosity is associated with `-vv` parameter</span></span><br><span class="line"><span class="attr">    verbosity:</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## prints the loopback address and gateway for each host</span></span><br><span class="line"><span class="attr">- debug:</span></span><br><span class="line"><span class="attr">    msg:</span> <span class="string">System</span> <span class="string">&#123;&#123;</span> <span class="string">inventory_hostname</span> <span class="string">&#125;&#125;</span> <span class="string">has</span> <span class="string">gateway</span> <span class="string">&#123;&#123;</span> <span class="string">ansible_default_ipv4.gateway</span> <span class="string">&#125;&#125;</span></span><br><span class="line"><span class="attr">  when:</span> <span class="string">ansible_default_ipv4.gateway</span> <span class="string">is</span> <span class="string">defined</span></span><br></pre></td></tr></table></figure></p>
<h2 id="fail"><a href="#fail" class="headerlink" title="fail"></a>fail</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/fail_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/fail_module.html</a><br>This module fails the progress with a custom message.<br>It can be useful for bailing out when a certain condition is met using when.</p>
<p>More error handling see:<br><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_error_handling.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/user_guide/playbooks_error_handling.html</a></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">check</span> <span class="string">async</span> <span class="string">task</span> <span class="string">status</span></span><br><span class="line"><span class="attr">  ignore_errors:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment">## check async task status</span></span><br><span class="line"><span class="attr">  async_status:</span></span><br><span class="line"><span class="attr">    jid:</span> <span class="string">"<span class="template-variable">&#123;&#123; sleepTask.ansible_job_id &#125;&#125;</span>"</span></span><br><span class="line"><span class="attr">  register:</span> <span class="string">job_result</span></span><br><span class="line"><span class="attr">  until:</span> <span class="string">job_result.finished</span></span><br><span class="line"><span class="attr">  when:</span> <span class="string">"inventory_hostname == groups.master[0]"</span></span><br><span class="line"><span class="attr">  retries:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">  delay:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## other things to do</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## fail the process if the retry failed</span></span><br><span class="line"><span class="attr">- fail:</span></span><br><span class="line"><span class="attr">    msg:</span> <span class="string">The</span> <span class="string">time</span> <span class="string">limit</span> <span class="string">hit,</span> <span class="string">the</span> <span class="string">cluster</span> <span class="string">may</span> <span class="string">not</span> <span class="string">be</span> <span class="string">in</span> <span class="string">ready</span> <span class="string">status!</span></span><br><span class="line">  <span class="comment">## it depends what output is in the register variable</span></span><br><span class="line"><span class="attr">  when:</span> <span class="string">job_result.failed</span> <span class="string">==</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h2 id="copy"><a href="#copy" class="headerlink" title="copy"></a>copy</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/copy_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/copy_module.html</a><br>The copy module copies a file from the local or remote machine to a location on the remote machine (depends on the condition). 和template类似, 如果task下面有files文件夹, 在不指定src路径的时候, eg: <code>src: xxx.txt</code>, 会从files文件夹里copy.</p>
<p>Use the <code>fetch</code> module to copy files from remote locations to the local box.</p>
<p>If you need variable interpolation in copied files, use the <code>template</code> module. Using a variable in the content field will result in unpredictable output.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## &#123;&#123; baseDir &#125;&#125;/registry-certs/tls.crt is in control machine</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Copy</span> <span class="string">secure</span> <span class="string">docker</span> <span class="string">registry</span> <span class="string">ssl/tls</span> <span class="string">certs</span> <span class="string">to</span> <span class="string">all</span> <span class="string">worker</span> <span class="string">nodes</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  copy:</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">"<span class="template-variable">&#123;&#123; baseDir &#125;&#125;</span>/registry-certs/tls.crt"</span></span><br><span class="line"><span class="attr">    dest:</span> <span class="string">"/etc/docker/certs.d/<span class="template-variable">&#123;&#123; service name &#125;&#125;</span>:5000/tls.crt"</span></span><br><span class="line"><span class="attr">    owner:</span> <span class="string">root</span></span><br><span class="line"><span class="attr">    group:</span> <span class="string">root</span></span><br><span class="line"><span class="attr">    mode:</span> <span class="string">'0644'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## remote_src: yes means copy is happening on remote machine</span></span><br><span class="line"><span class="comment">## remote_src supports recursive copying as of version 2.8</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Copy</span> <span class="string">a</span> <span class="string">"sudoers"</span> <span class="string">file</span> <span class="string">on</span> <span class="string">the</span> <span class="string">remote</span> <span class="string">machine</span> <span class="string">for</span> <span class="string">editing</span></span><br><span class="line"><span class="attr">  copy:</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">/etc/sudoers</span></span><br><span class="line"><span class="attr">    dest:</span> <span class="string">/etc/sudoers.edit</span></span><br><span class="line"><span class="attr">    remote_src:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure></p>
<p>注意mode 必须是4 digits!! 比如0644 不能是644，否则没对齐会造成sticky bit.<br><a href="https://askubuntu.com/questions/976168/difference-between-three-and-four-digit-file-permissions" target="_blank" rel="noopener">ansible copy make sticky bit</a></p>
<h2 id="fetch"><a href="#fetch" class="headerlink" title="fetch"></a>fetch</h2><p>This module works like copy, but in reverse.</p>
<p>It is used for fetching files from remote machines and storing them locally in a file tree, organized by hostname.</p>
<p>Files that already exist at dest will be overwritten if they are different than the src.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## fetched file is marked by the remote hostname </span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Store</span> <span class="string">file</span> <span class="string">into</span> <span class="string">/tmp/fetched/host.example.com/tmp/somefile</span></span><br><span class="line"><span class="attr">  fetch:</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">/tmp/somefile</span></span><br><span class="line"><span class="attr">    dest:</span> <span class="string">/tmp/fetched</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## If dest ends with '/', it will use the basename of the source file, similar to the copy module.</span></span><br><span class="line"><span class="comment">## This can be useful if working with a single host, or if retrieving files that are uniquely named per host.</span></span><br><span class="line"><span class="comment">## If using multiple hosts with the same filename, the file will be overwritten for each host.</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Specifying</span> <span class="string">a</span> <span class="string">destination</span> <span class="string">path</span></span><br><span class="line"><span class="attr">  fetch:</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">/tmp/uniquefile</span></span><br><span class="line"><span class="attr">    dest:</span> <span class="string">/tmp/special/</span></span><br><span class="line"><span class="attr">    flat:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure></p>
<h2 id="template"><a href="#template" class="headerlink" title="template"></a>template</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/template_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/template_module.html</a><br>这个module在统一设置配置文件时很常用, 或者可以用来初始化script template中的参数, 然后传递到各个host去运行.<br>Templates are processed by the <code>Jinja2</code> templating language.<br>Documentation on the template formatting can be found in the <a href="https://jinja.palletsprojects.com/en/2.10.x/templates/" target="_blank" rel="noopener">Template Designer Documentation</a>.</p>
<p>Usually we have the ansible role structure:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">roles/</span><br><span class="line">  install.components/</span><br><span class="line">      defaults/</span><br><span class="line">        main.yml</span><br><span class="line">      tasks/</span><br><span class="line">        main.yml</span><br><span class="line">      templates/</span><br><span class="line">        example.conf.j2</span><br><span class="line">        example.sh.j2</span><br><span class="line">      files/</span><br><span class="line">        bar.txt</span><br><span class="line">        foo.sh</span><br></pre></td></tr></table></figure></p>
<p>When template works it picks source file from role’s <code>templates/</code> folder.<br>If the template file contains jinja2 placeholder, it will be interpolated.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## from control machine to other nodes</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Template</span> <span class="string">a</span> <span class="string">file</span> <span class="string">to</span> <span class="string">/etc/files.conf</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">/mytemplates/foo.j2</span></span><br><span class="line"><span class="attr">    dest:</span> <span class="string">/etc/file.conf</span></span><br><span class="line"><span class="attr">    owner:</span> <span class="string">bin</span></span><br><span class="line"><span class="attr">    group:</span> <span class="string">wheel</span></span><br><span class="line"><span class="attr">    mode:</span> <span class="string">'0644'</span></span><br></pre></td></tr></table></figure>
<h2 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/shell_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/shell_module.html</a><br>这个太常用了, 可以做几乎所有其他module的工作.</p>
<p>It is almost exactly like the <code>command</code> module but runs the command through a shell (<code>/bin/sh</code>) on the remote node.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Copy</span> <span class="string">IIS</span> <span class="string">docker</span> <span class="string">images</span> <span class="string">to</span> <span class="string">specified</span> <span class="string">worker</span> <span class="string">nodes</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  shell:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    /tmp/copyIISDockers.sh <span class="template-variable">&#123;&#123; iisDockers &#125;&#125;</span> <span class="template-variable">&#123;&#123; imageTag &#125;&#125;</span></span></span><br><span class="line"><span class="string">    if [[ $? -eq 0 ]]; then</span></span><br><span class="line"><span class="string">      touch /tmp/copyIISImageToWorker.done</span></span><br><span class="line"><span class="string">    fi</span></span><br><span class="line"><span class="string"></span><span class="attr">  when:</span> <span class="string">"inventory_hostname == groups.master[0]"</span></span><br><span class="line"><span class="attr">  args:</span></span><br><span class="line">    <span class="comment">## A filename, when it already exists, this step will not be run.</span></span><br><span class="line"><span class="attr">    creates:</span> <span class="string">/tmp/copyIISImageToWorker.done</span></span><br><span class="line">    <span class="comment">## A filename, when it does not exist, this step will not be run.</span></span><br><span class="line"><span class="attr">    removes:</span> <span class="string">/tmp/preTaskOk.done</span></span><br><span class="line">    <span class="comment">## disable task warning</span></span><br><span class="line"><span class="attr">    warn:</span> <span class="literal">no</span></span><br><span class="line">    <span class="comment">## change the shell</span></span><br><span class="line"><span class="attr">    executable:</span> <span class="string">/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Change</span> <span class="string">the</span> <span class="string">working</span> <span class="string">directory</span> <span class="string">to</span> <span class="string">somedir/</span> <span class="string">before</span> <span class="string">executing</span> <span class="string">the</span> <span class="string">command.</span></span><br><span class="line"><span class="attr">  shell:</span> <span class="string">somescript.sh</span> <span class="string">&gt;&gt;</span> <span class="string">somelog.txt</span></span><br><span class="line"><span class="attr">  args:</span></span><br><span class="line"><span class="attr">    chdir:</span> <span class="string">somedir/</span></span><br></pre></td></tr></table></figure>
<h2 id="command"><a href="#command" class="headerlink" title="command"></a>command</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/command_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/command_module.html</a><br>The <code>command</code> module takes the command name followed by a list of space-delimited arguments.<br>The given command will be executed on all selected nodes.<br>The command(s) will <strong>not</strong> be processed through the <code>shell</code>, so variables like $HOME and operations like “&lt;”, “&gt;”, “|”, “;” and “&amp;” will not work. Use the shell module if you need these features.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">return</span> <span class="string">motd</span> <span class="string">to</span> <span class="string">registered</span> <span class="string">var</span></span><br><span class="line"><span class="attr">  command:</span> <span class="string">cat</span> <span class="string">/etc/motd</span></span><br><span class="line"><span class="attr">  register:</span> <span class="string">mymotd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 'args' is a task keyword, passed at the same level as the module</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Run</span> <span class="string">command</span> <span class="string">if</span> <span class="string">/path/to/database</span> <span class="string">does</span> <span class="string">not</span> <span class="string">exist</span> <span class="string">(with</span> <span class="string">'args'</span> <span class="string">keyword).</span></span><br><span class="line"><span class="attr">  command:</span> <span class="string">/usr/bin/make_database.sh</span> <span class="string">db_user</span> <span class="string">db_name</span></span><br><span class="line"><span class="attr">  args:</span></span><br><span class="line"><span class="attr">    creates:</span> <span class="string">/path/to/database</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 'cmd' is module parameter</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Run</span> <span class="string">command</span> <span class="string">if</span> <span class="string">/path/to/database</span> <span class="string">does</span> <span class="string">not</span> <span class="string">exist</span> <span class="string">(with</span> <span class="string">'cmd'</span> <span class="string">parameter).</span></span><br><span class="line"><span class="attr">  command:</span></span><br><span class="line"><span class="attr">    cmd:</span> <span class="string">/usr/bin/make_database.sh</span> <span class="string">db_user</span> <span class="string">db_name</span></span><br><span class="line"><span class="attr">    creates:</span> <span class="string">/path/to/database</span></span><br></pre></td></tr></table></figure>
<h2 id="service"><a href="#service" class="headerlink" title="service"></a>service</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/service_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/service_module.html</a><br>Controls services on remote hosts. Supported init systems include BSD init, OpenRC, SysV, Solaris SMF, systemd, upstart.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Start</span> <span class="string">service</span> <span class="string">httpd,</span> <span class="string">if</span> <span class="string">not</span> <span class="string">started</span></span><br><span class="line"><span class="attr">  service:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">httpd</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">started</span></span><br></pre></td></tr></table></figure>
<h2 id="systemd"><a href="#systemd" class="headerlink" title="systemd"></a>systemd</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/systemd_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/systemd_module.html</a><br>more dedicated then service module, controls systemd services on remote hosts.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Enable</span> <span class="string">and</span> <span class="string">start</span> <span class="string">docker</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  systemd:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">docker</span></span><br><span class="line"><span class="attr">    enabled:</span> <span class="literal">yes</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">started</span></span><br></pre></td></tr></table></figure>
<h2 id="file"><a href="#file" class="headerlink" title="file"></a>file</h2><p>Set attributes of files, symlinks or directories.<br>Alternatively, remove files, symlinks or directories.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Create</span> <span class="string">a</span> <span class="string">directory</span> <span class="string">if</span> <span class="string">it</span> <span class="string">does</span> <span class="string">not</span> <span class="string">exist</span></span><br><span class="line"><span class="attr">  file:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/some_directory</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">directory</span></span><br><span class="line"><span class="attr">    mode:</span> <span class="string">'0755'</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Touch</span> <span class="string">a</span> <span class="string">file,</span> <span class="string">using</span> <span class="string">symbolic</span> <span class="string">modes</span> <span class="string">to</span> <span class="string">set</span> <span class="string">the</span> <span class="string">permissions</span> <span class="string">(equivalent</span> <span class="string">to</span> <span class="number">0644</span><span class="string">)</span></span><br><span class="line"><span class="attr">  file:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/foo.conf</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">touch</span></span><br><span class="line"><span class="attr">    mode:</span> <span class="string">u=rw,g=r,o=r</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Remove</span> <span class="string">file</span> <span class="string">(delete</span> <span class="string">file)</span></span><br><span class="line"><span class="attr">  file:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/foo.txt</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">absent</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Recursively</span> <span class="string">remove</span> <span class="string">directory</span></span><br><span class="line"><span class="attr">  file:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/foo</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">absent</span></span><br></pre></td></tr></table></figure>
<h2 id="lineinfile"><a href="#lineinfile" class="headerlink" title="lineinfile"></a>lineinfile</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/lineinfile_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/lineinfile_module.html</a><br>If you use <code>sed</code> in command module, you will get warning, you can disable the warning by add <code>warn: false</code> or use lineinfile module.</p>
<p>This module ensures a particular line is in a file, or replace an existing line using a back-referenced regular expression.</p>
<p>This is primarily useful when you want to change a single line in a file only.</p>
<p>See the <code>replace</code> module if you want to change multiple, similar lines or check <code>blockinfile</code> if you want to insert/update/remove a block of lines in a file. For other cases, see the copy or template modules.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Make</span> <span class="string">sure</span> <span class="string">group</span> <span class="string">wheel</span> <span class="string">is</span> <span class="string">not</span> <span class="string">in</span> <span class="string">the</span> <span class="string">sudoers</span> <span class="string">configuration</span></span><br><span class="line"><span class="attr">  lineinfile:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/sudoers</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">absent</span></span><br><span class="line"><span class="attr">    regexp:</span> <span class="string">'^%wheel'</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Ensure</span> <span class="string">we</span> <span class="string">have</span> <span class="string">our</span> <span class="string">own</span> <span class="string">comment</span> <span class="string">added</span> <span class="string">to</span> <span class="string">/etc/services</span></span><br><span class="line"><span class="attr">  lineinfile:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/services</span></span><br><span class="line"><span class="attr">    regexp:</span> <span class="string">'^# port for http'</span></span><br><span class="line"><span class="attr">    insertbefore:</span> <span class="string">'^www.*80/tcp'</span></span><br><span class="line"><span class="attr">    line:</span> <span class="string">'# port for http by default'</span></span><br></pre></td></tr></table></figure>
<h2 id="mount"><a href="#mount" class="headerlink" title="mount"></a>mount</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/mount_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/mount_module.html</a><br>This module controls active and configured mount points in <code>/etc/fstab</code></p>
<p>For <code>/etc/exports</code>, no dedicated module for it.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Edit</span> <span class="string">/etc/fstab</span> <span class="string">file</span> <span class="string">to</span> <span class="string">mount</span> <span class="string">share</span> <span class="string">directory</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  mount:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">"/mnt"</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">"<span class="template-variable">&#123;&#123; dfsFileServer &#125;&#125;</span>:<span class="template-variable">&#123;&#123; dfsDataDir &#125;&#125;</span>"</span></span><br><span class="line"><span class="attr">    fstype:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">    opts:</span> <span class="string">"defaults,timeo=10,retrans=3,rsize=1048576,wsize=1048576"</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">mounted</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Edit</span> <span class="string">/etc/fstab</span> <span class="string">file</span> <span class="string">to</span> <span class="string">unmout</span> <span class="string">share</span> <span class="string">directory</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  mount:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">"/mnt"</span></span><br><span class="line"><span class="attr">    fstype:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">    opts:</span> <span class="string">"defaults,timeo=10,retrans=3,rsize=1048576,wsize=1048576"</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">absent</span></span><br></pre></td></tr></table></figure>
<h2 id="asynchronous"><a href="#asynchronous" class="headerlink" title="asynchronous"></a>asynchronous</h2><p><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html</a><br>By default task in playbook blocks, this may not always be desirable, or you may be running operations that take longer than the SSH timeout.</p>
<p>This module can be use to create progress bar for long time task.</p>
<blockquote>
<p>Notice that async task can only be accessed in the same playbook.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">async</span> <span class="string">task</span> <span class="string">in</span> <span class="string">background</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  shell:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    echo "start first task"</span></span><br><span class="line"><span class="string">    sleep 20</span></span><br><span class="line"><span class="string">    touch /tmp/sleep.done</span></span><br><span class="line"><span class="string">  ## when poll &gt; 0, task still blocks</span></span><br><span class="line"><span class="string">  ## when poll = 0, task run in background</span></span><br><span class="line"><span class="string"></span><span class="attr">  poll:</span> <span class="number">0</span></span><br><span class="line">  <span class="comment">## explicitly sets the timeout 1000 seconds</span></span><br><span class="line"><span class="attr">  async:</span> <span class="number">1000</span> </span><br><span class="line">  <span class="comment">## register for later check</span></span><br><span class="line"><span class="attr">  register:</span> <span class="string">sleepTask</span></span><br><span class="line"><span class="attr">  when:</span> <span class="string">"inventory_hostname == groups.master[0]"</span></span><br><span class="line"><span class="attr">  args:</span></span><br><span class="line"><span class="attr">    creates:</span> <span class="string">/tmp/sleep.done</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">check</span> <span class="string">async</span> <span class="string">task</span> <span class="string">status</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment">## check async task status</span></span><br><span class="line"><span class="attr">  async_status:</span></span><br><span class="line"><span class="attr">    jid:</span> <span class="string">"<span class="template-variable">&#123;&#123; sleepTask.ansible_job_id &#125;&#125;</span>"</span></span><br><span class="line"><span class="attr">  register:</span> <span class="string">job_result</span></span><br><span class="line"><span class="attr">  until:</span> <span class="string">job_result.finished</span></span><br><span class="line"><span class="attr">  when:</span> <span class="string">"inventory_hostname == groups.master[0]"</span></span><br><span class="line"><span class="attr">  retries:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">  delay:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="synchronize"><a href="#synchronize" class="headerlink" title="synchronize"></a>synchronize</h2><p>rsync wrapper</p>
<h2 id="loop"><a href="#loop" class="headerlink" title="loop"></a>loop</h2><p><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/user_guide/playbooks_loops.html</a><br>items</p>
<h2 id="variables"><a href="#variables" class="headerlink" title="variables"></a>variables</h2><p>inventory_hostname<br>groups<br>jinjia2 template <figure class="highlight plain"><figcaption><span>&#125;&#125;```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">operator: in</span><br><span class="line"></span><br><span class="line">## conditional</span><br><span class="line">when clause</span><br><span class="line"></span><br><span class="line">```yaml</span><br><span class="line">## 不是每个module都支持creates的</span><br><span class="line">args:</span><br><span class="line">  creates: xxx</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Advanced</title>
    <url>/2019/06/22/book-docker-concept/</url>
    <content><![CDATA[<p>最近看了一本书，书名是<code>&lt;&lt;Docker进阶与实战&gt;&gt;</code>， 这里并不是讲一些基础入门，而是在已经掌握和应用的基础上，告诉你背后的原理和技术细节。平时留意到的很多现象都在这里得到了解释，还是很值得记一下要点的。</p>
<h2 id="Chapter-3-镜像"><a href="#Chapter-3-镜像" class="headerlink" title="Chapter 3 镜像"></a>Chapter 3 镜像</h2><p>主要介绍 Docker Image，其实就是启动容器的只读模板，是容器启动所需的rootfs。</p>
<p>Image 表示方法：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dockerhub-web-address/namespace/repository:tag</span><br></pre></td></tr></table></figure></p>
<ul>
<li>namespace: 用于划分用户或组织，有时并没有用到</li>
<li>repository: 类似于Git仓库，一个仓库有很多镜像</li>
<li>tag: 区分同一镜像不同版本</li>
</ul>
<p>Layer这个东西类似于git commit。Image ID是最上层layer的ID。</p>
<p>Docker开源了镜像存储部分的代码，也就是docker registry, 在接触Docker的开始阶段我一直没明白<code>registry</code>与<code>repository</code>的区别，这2个词长得有点像哦，新手稍不注意就用混了，中文意思也有点类似，一个是档案室，一个是仓库，都可以放东西。</p>
<p>一般来说，docker registry需要与nginx去添加基本鉴权功能，才是一个合格的secure私有镜像库，但有时我并没有这么做。</p>
<p>已经下载到本地的镜像默认是存储在<code>/var/lib/docker</code>路径下的。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /var/lib/docker/image/devicemapper</span><br><span class="line">ls -ltr</span><br><span class="line"></span><br><span class="line">total 4</span><br><span class="line">drwx------ 4 root root   37 May  8 15:21 imagedb</span><br><span class="line">drwx------ 5 root root   45 May  8 15:22 layerdb</span><br><span class="line">drwx------ 4 root root   58 May  8 15:29 distribution</span><br><span class="line">-rw------- 1 root root 1269 Jun 17 09:21 repositories.json</span><br></pre></td></tr></table></figure></p>
<h3 id="使用Docker镜像"><a href="#使用Docker镜像" class="headerlink" title="使用Docker镜像"></a>使用Docker镜像</h3><p><code>dangling</code> image doesn’t have name and tag (present as <code>&lt;none&gt;</code>), <code>docker commit</code> sometimes can generate dangling image, you can use filter to show dangling:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images --filter &quot;dangling=true&quot;</span><br></pre></td></tr></table></figure></p>
<p>只显示image ID:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images -q</span><br></pre></td></tr></table></figure></p>
<p>Remove all dangling images:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images --filter &quot;dangling=true&quot; -q | xargs docker rmi</span><br></pre></td></tr></table></figure></p>
<p>There is a tool <a href="https://github.com/justone/dockviz" target="_blank" rel="noopener"><code>dockviz</code></a> can do image analysis job. 可以图形化的展示image的层次。</p>
<p><code>docker load</code>用于被<code>docker save</code>导出的镜像，还有一个<code>docker import</code>用于导入包含根文件系统的归档，并将之变为镜像, <code>docker import</code>常用来制作Docker baseimage。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker save -o busybox.tar busybox</span><br><span class="line">docker load -i busybox.tar</span><br></pre></td></tr></table></figure></p>
<p><code>docker commit</code>用于增量生成镜像，效率较低，一般用于前期测试（比如当时non-root开发），最终确定步骤后，可以用<code>docker build</code>。</p>
<h3 id="镜像的组织结构"><a href="#镜像的组织结构" class="headerlink" title="镜像的组织结构"></a>镜像的组织结构</h3><p>可以用这2个命令去窥探一下镜像结构和元数据<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker history</span><br><span class="line">docker inspect</span><br></pre></td></tr></table></figure></p>
<h3 id="镜像扩展知识"><a href="#镜像扩展知识" class="headerlink" title="镜像扩展知识"></a>镜像扩展知识</h3><p>Docker引入了联合挂载<code>Union mount</code>技术，使镜像分层成为可能：<br>发展路径:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">unionfs -&gt; aufs -&gt; overlayfs</span><br></pre></td></tr></table></figure></p>
<p><code>写时复制 (copy-on-write)</code> 是Docker image强大的一个重要原因，操作系统中也广泛用到了，比如<code>fork</code>.当父进程fork子进程时，并没有真正分配内存给子进程，而是共享，当2者之一修改共享内存时，触发缺页异常才导致真正的内存分配。这样加速了子进程的创建，也减少了内存消耗。</p>
<p>联合文件系统是实现写时复制的基础，Ubuntu自带<code>aufs</code>, Red Hat和Suse采用<code>deivcemapper</code>方案（在<code>/var/lib/docker/image</code>下就是这个东西），作为Docker的存储驱动，它们的存储结构和性能都有显著差异，要根据实际情况选用。</p>
<h2 id="Chapter-4-仓库进阶"><a href="#Chapter-4-仓库进阶" class="headerlink" title="Chapter 4 仓库进阶"></a>Chapter 4 仓库进阶</h2><p>对Docker registry的API访问，传输对象主要包括镜像layer的块数据(<code>blob</code>)和表单(<code>manifest</code>)。layer数据以二进制方式存放于registry中。主要讲了一下用API进行pull, push的过程，步骤。其实都划分了很多步。</p>
<p>List and Dlete Image 可以参考我这篇博客<a href="https://chengdol.github.io/2019/06/10/docker-registry-api/" target="_blank" rel="noopener"><code>&lt;&lt;Docker Registry API&gt;&gt;</code></a>。</p>
<p>鉴权机制，这里使用的是Docker Engine, Registry和Auth Server协作完成。Auth Server由Registry开发者部署搭建，Registry完全信任Auth Server.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+---------------+               +------------------------+</span><br><span class="line">|               +-------+       |                        |</span><br><span class="line">|  Registry     |       |       | Authorization Service  |</span><br><span class="line">|               +&lt;--+   |       |                        |</span><br><span class="line">+-+--+----------+   |   |       +---------------+--+-----+</span><br><span class="line">  ^  |              |   |                       ^  |</span><br><span class="line">  |  |            5 |   | 6                     |  |</span><br><span class="line">  |  |              |   |                       |  |</span><br><span class="line">1 |  | 2            |   |                     3 |  | 4</span><br><span class="line">  |  |          +---+---v---------+             |  |</span><br><span class="line">  |  +---------&gt;+                 +-------------+  |</span><br><span class="line">  |             |  Docker Daemon  |                |</span><br><span class="line">  +-------------+                 +&lt;---------------+</span><br><span class="line">                +--------+--------+</span><br><span class="line">                         ^</span><br><span class="line">                         |</span><br><span class="line">           +-------------+----------------+</span><br><span class="line">           |      Docker Client           |</span><br><span class="line">           |    $docker pull busybox      |</span><br><span class="line">           |                              |</span><br><span class="line">           +------------------------------+</span><br></pre></td></tr></table></figure>
<ol>
<li>Docker Engine试图赋予HTTP请求一个鉴权的token，如果没有，Daemon会试图fetch/refresh一个新的token。</li>
<li>如果请求没有做过认证且不含token则Registry会返回401 Unauthorized状态</li>
<li>用户带着Registry返回的信息以及证书去访问Auth Server申请token （<strong>这里具体怎么操作？证书在哪里？</strong>）</li>
<li>Auth Server后端账户记录着用户名和密码，获取用户请求后，会将鉴权信息的token返回给用户</li>
<li><p>用户带着token再次访问Regisrty, HEADER中包含:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Authorization: Bearer &lt;token content&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Registry检验token，如通过则开始工作</p>
</li>
</ol>
<h3 id="构建私有仓库"><a href="#构建私有仓库" class="headerlink" title="构建私有仓库"></a>构建私有仓库</h3><p>In general, we can simply run a private docker registry:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --hostname localhost \</span><br><span class="line">  --name registry-v2 \</span><br><span class="line">  -v /opt/data:/var/lib/registry \</span><br><span class="line">  -p 5000:5000 \</span><br><span class="line">  registry:2.0</span><br></pre></td></tr></table></figure></p>
<p>这里将本地目录<code>/opt/data</code>挂载到容器镜像存储目录<code>/var/lib/registry</code>，方便查看和管理镜像数据，在DataStage Installer中也是如此。这时的registry是不安全的，能访问本机5000端口的人都可以上传和下载镜像。</p>
<p>需要为其加上HTTPS反向代理，这里以Nginx来实现。然后代理服务器会接受HTTPS请求，然后将请求转发给内部网络上的registry服务器，并将registry访问结果返回给用户。</p>
<p>可以参考我的这篇blog关于如何搭建<a href=""><code>Secure Docker Registry</code></a>.</p>
<h2 id="Chapter-5-Docker网络"><a href="#Chapter-5-Docker网络" class="headerlink" title="Chapter 5 Docker网络"></a>Chapter 5 Docker网络</h2>]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Quick Test</title>
    <url>/2020/01/24/ansible-quick-test/</url>
    <content><![CDATA[<p>//TODO:<br>Use <code>Vagrant</code> to provision virtual machine cluster.<br>Vagrant的设置主要参考Chapter 3 and Chapter 13</p>
<p>This is a Ansible quick setup to help testing and understanding module functionality.<br>Download from my github project <a href="https://github.com/chengdol/InfraTree/tree/master/vagrant-ansible" target="_blank" rel="noopener">ansible-test</a>.</p>
<p>You can set up a local test cluster on your laptop, more detail please see the <code>README</code> in the git repo.</p>
]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Design Data-Intensive Applications</title>
    <url>/2020/05/21/book-design-dataintensive-app/</url>
    <content><![CDATA[<p>2018年7月18号收货到手的，但一直没有花时间去读😳，评价挺高的一本书。</p>
<p>这次WFH抽时间看了看，其实是一本很好的关于系统设计的书(重点关注的是Data-Intensive System，需要一些数据库的使用知识和经验，然鹅我并没有😂)，如果你曾经准备过系统设计相关的面试，或者有几年系统开发经验，会发现读起来还是挺有收获的。</p>
<p>目前是第一遍阅读，这种书得读个几遍并且结合工作经验才能全面消化，特别对我这种writing不好的人🙁，作者的用词遣句，叙述逻辑也很值得学习!</p>
<h2 id="Part-I"><a href="#Part-I" class="headerlink" title="Part I"></a>Part I</h2><p>主要介绍了Data System Foundation.</p>
<p><code>Reliable, Scalable and Maintainable</code><br>各自的定义，分类和要点，从这3个方面考虑去构建适合需求的系统。比如Relability，有hardware, software and human faults; Scalability，用什么去describe workload and performance, 如何处理越来越多的workload; Mainyainability，要多多考虑operations team (run smoothly), new engineer (easy to pick up)的感受，以及对未来可能的需求改动留有余地。</p>
<p><code>Data Models and Query Language</code><br>主要讲了传统的relational DB 和 NoSQL中的document DB (suitable for one to many relation), 如何随着需求的改变不断进化，还提到了Graph-like Data Model (many to many relation). 讲到了Declarative language 对比 Imperative的好处，比如SQL，系统可以在内部优化而不影响Query语句本身。</p>
<p><code>Storage and Retrieval</code><br>数据库的底层实现，从Hash Indexes，到SSTables (String Sorted Table)，再到LSM-Trees (Log Structure Merge Tree), 最后到B-Trees (一种在disk上保持sorted structure的结构).<br>Advantages and downsides of LSM-Trees. 特别是read/write的performance, LSM-Tree的write operation一般来说比B-Trees效率高，但这里没有一个普世法则，需要通过实际测试才能知道哪种模式适合你。</p>
<p>In-memory database也提到了，相比于non in-memory，它快于不需要encode data in the strucutre to store in disk, 并且可以实现disk上难以实现的index 结构.</p>
<p>最后提到了data warehouse, 这和传统的处理transaction的数据库独立开来了，优化于适合analytics. column-oriented storage经常在data warehouse中使用，但不全是。要注意的是Cassandra有column families的概念，但它并不是属于column-oriented storage.</p>
<p><code>Encoding and Evolution</code><br>Everything changes and nothing stands still.</p>
<p>A changes to app’s feature also requires a change to data that it stores, 这就遇到2个主要的问题: backward compatibility and forward compatibility. backward is commonly to see, forward means old code can read data that was written by new code.</p>
<p>Here encoding has nothing to do with encryption.<br>The translation from in-memory presentation to a byte sequence is called encoding (also known as serialization or marshalling), the reverse is called decoding (parsing, deserialization, unmarshalling).</p>
<p>介绍了一些Language-specific formats，比如Java, Python自带的encoding module or package, but they have deep problems，比如和语言耦合太强，perofrmance太低很verbose.</p>
<p>JSON,XML,CSV很常用，有一些问题但remain popular and good for many purposes.</p>
<p>Binary encoding可以节约一些空间，但它没有schema，所以需要将object field name encode into data.</p>
<p>Schema binary encoding, save a lot compare to JSON/XML/CSV: Thrift (from facebook) and Protocol Buffers (from google), both were made open source. They are more or less similar: define schema (field can be required or optional), then code with field tags, good for schema evolution.</p>
<p>Apache Avro, a subproject from Hadoop, 对于处理Hadoop的大数据很有效, no field tag. 有writer’s schema and reader’s schema来解决encode, decode的问题，对于schema evolution, 只要保证双方schema compitable就可以。</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>system design</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes 进阶实战</title>
    <url>/2019/09/15/book-k8s-adv-practical/</url>
    <content><![CDATA[<blockquote>
<p>06/12/2020， 打算下半年把K8s CKA/CKAD 证书考了，要review一下这本书。</p>
</blockquote>
<p>这是最近几周看的书（中文），年初从国内带过来的。</p>
<p>最近的项目涉及到很多微服务架构设计的问题，和组里大佬讨论的时候发现自己有的地方理解得不太正确甚至一张白纸，给不出一个完善的设计方案和想法，赶紧更新和归纳一下自己之前学到的知识点。</p>
<p>其实接触Kubernetes也快一年了，但一直是对之前项目的维护和更新操作，这次难得机会要集成一个新组件到已有的集群里，从头开始设计这些功能组件的各种配置，结构，生命周期，存储卷，依赖等。这本书算是一个由点到面的总结，提供了不少的帮助。</p>
<p>最近逐渐体会到一个好的，完善的，充分考虑的顶层设计是多么重要，否则每次设计改动对应到底层可能耗时耗力，甚至积重难返，不得不相互妥协。</p>
<p>这本书不打算做细致的笔记，但会记录一些以前没意识到或没见过的概念和工具。之后打算更细致的看一看<code>&lt;&lt;Kubernetes in Action&gt;&gt;</code>。我看最近<code>O&#39;REILLY</code>出版了或即将出版很多关于Kubernetes的新书，其中比较吸引我的是<code>pattern</code>，<code>best practices</code>, <code>Operator</code>以及一些<code>cloud native devops</code>相关的知识点，当然还包括一些重要系统组件和插件，比如<code>SSL/TLS</code>, <code>CoreDNS</code>和<code>etcd</code>等。看来2019剩下的日子是真的会很忙了。</p>
<h1 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h1><p>按照计划在2019年10月之前把这本书看完了第一遍，在书中做了不少标记和勾画，接下来快速记录一下其中的我比较注意的地方：</p>
<hr>
<p>Kubernetes通过其附加组件之一的CoreDNS为系统内置了服务注册和服务发现功能，为每个Service配置了DNS名称，允许客户端通过此名称发出访问，并且Service通过kube-proxy creates iptabls or ipvs内建了负载均衡机制。Service本质上讲是一个四层代理服务，也可将外部流量引入集群内部。</p>
<p>网络存储系统，诸如：NFS, GlusterFS, Ceph, Cinder…目前项目里面其实用的是本地存储，只不过额外设置了NFS将本地存储连接了起来，并没有直接只用K8s中的NFS配置。</p>
<p>API Server是整个集群的网关。</p>
<p>etcd是由CoreOS基于raft协议开发的分布式键值存储，可用于服务发现，共享配置以及一致性保障，它是独立的服务组件，并不隶属于K8s。etcd中键值发生变化时会通知API Server，并通过watch API向客户端输出，实现高效协同。</p>
<p>K8s supports container runtime: Docker, cri-o, RKT, Fraki<br>cri-o use gRPC(Remote procedure call)</p>
<p>K8s Dashborad<br>Prometheus and it’s add-ons<br>Ingress controller: 应用层负载均衡机制: Nginx, HAProxy…</p>
<p>Pod网络由网络插件实现(for example: fannel, calico, weave…), Service网络由K8s指定。</p>
<hr>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes 网络权威指南</title>
    <url>/2020/02/03/book-k8s-networking-guide/</url>
    <content><![CDATA[<p>网络在云计算中又起着至关重要的作用。大概浏览了一下目录和内容总结，很符合我的需求。类似的英文版书籍我一直在寻找，但还真没见到过。很赞同作者在前言中的一句话：工程师不能只当使用者，还要理解底层的实现。其实很多新技术都是原有技术的再封装和创新应用，真正理解了本质的东西对快速学习非常有帮助。</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Command Line and Shell Scripting Bible</title>
    <url>/2019/07/08/book-linux-cmd-shell-bible/</url>
    <content><![CDATA[<p>This is a thick, comprehensive book about Linux command line and shell scripting.</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Operators</title>
    <url>/2020/06/03/book-k8s-operator/</url>
    <content><![CDATA[<p>这段时间开始研究Operator了，刚好有这本书，计划快速过一遍，recap quick start. 看完了一遍，最深得感受就是，如果K8s是云的操作系统，那么Operator就是一个云应用程序自己的管理工具，也就是书中说的application SRE。</p>
<p>Book accompanying git repo:<br><a href="https://github.com/chengdol/chapters/" target="_blank" rel="noopener">https://github.com/chengdol/chapters/</a> (this is forked from origin)<br>还推荐几本书, from O’reilly:</p>
<ul>
<li>Programming Kubernetes (dive deeper into API)</li>
<li>Extending Kubernetes</li>
</ul>
<p>My K8s operator-sdk demo git repo, step by step guide you setup a go-based operator and deploy in K8s cluster:<br><a href="https://github.com/chengdol/k8s-operator-sdk-demo" target="_blank" rel="noopener">https://github.com/chengdol/k8s-operator-sdk-demo</a></p>
<p>其他一些资料收集在了这篇blog中:<br><a href="https://chengdol.github.io/2020/01/23/k8s-operator/" target="_blank" rel="noopener">Kubernetes Operator Learning</a></p>
<h1 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1 Introduction"></a>Chapter 1 Introduction</h1><p>Operators grew out of work at CoreOS during 2015 and 2016. User experience with the Operators built there and continuing at Red Hat.</p>
<p>An Operator continues to monitor its application as it runs, and can back up data, recover from failures, and upgrade the application over time, automatically.</p>
<p>An Operator is a custom Kubernetes controller watching a CR type and taking application-specific actions to make reality match the spec in that resource.</p>
<p>Making an Operator means creating a CRD and providing a program that runs in a loop watching CRs of that kind. </p>
<p>The Operator pattern arose in response to infrastructure engineers and developers wanting to extend Kubernetes to provide features <strong>specific</strong> to their sites and software.</p>
<p>看到这里产生了一个疑问: Helm and Operator.</p>
<ul>
<li><a href="https://medium.com/@cloudark/kubernetes-operators-and-helm-it-takes-two-to-tango-3ff6dcf65619" target="_blank" rel="noopener">Kubernetes Operators and Helm — It takes Two to Tango</a></li>
<li><a href="https://www.openshift.com/blog/make-a-kubernetes-operator-in-15-minutes-with-helm" target="_blank" rel="noopener">Make a Kubernetes Operator in 15 minutes with Helm</a></li>
</ul>
<h1 id="Chapter-2-Running-Operators"><a href="#Chapter-2-Running-Operators" class="headerlink" title="Chapter 2 Running Operators"></a>Chapter 2 Running Operators</h1><p>这是最基本的operator 演示，一个etcd cluster，有很大的启发价值，注意下面例子中各自的创建顺序:<br><a href="https://github.com/kubernetes-operators-book/chapters/tree/master/ch03" target="_blank" rel="noopener">https://github.com/kubernetes-operators-book/chapters/tree/master/ch03</a></p>
<p>First need cluster-wise privilege:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## need cluster wide privilege</span></span><br><span class="line">kubectl describe clusterrole cluster-admin</span><br><span class="line"></span><br><span class="line"><span class="comment">## good</span></span><br><span class="line">Name:         cluster-admin</span><br><span class="line">Labels:       kubernetes.io/bootstrapping=rbac-defaults</span><br><span class="line">Annotations:  rbac.authorization.kubernetes.io/autoupdate: <span class="literal">true</span></span><br><span class="line">PolicyRule:</span><br><span class="line">  Resources  Non-Resource URLs  Resource Names  Verbs</span><br><span class="line">  ---------  -----------------  --------------  -----</span><br><span class="line">  *.*        []                 []              [*]</span><br><span class="line">             [*]                []              [*]</span><br></pre></td></tr></table></figure></p>
<p>Start with <code>etcd</code> as ‘hello world’ example. Deviation:</p>
<ul>
<li>Raft protocol: <a href="https://raft.github.io/" target="_blank" rel="noopener">https://raft.github.io/</a></li>
</ul>
<p>you’ll deploy the etcd Operator, then have it create an etcd cluster according to your specifications. You will have the Operator recover from failures and perform a version upgrade while the etcd API continues to service read and write requests, showing how an Operator automates the lifecycle of a piece of foundation software.</p>
<p>A <code>CRD</code> is akin to a schema for a <code>CR</code>, defining the <code>CR</code>’s fields and the types of values those fields contain:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcdclusters.etcd.database.coreos.com</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  group:</span> <span class="string">etcd.database.coreos.com</span></span><br><span class="line"><span class="attr">  names:</span></span><br><span class="line"><span class="attr">    kind:</span> <span class="string">EtcdCluster</span></span><br><span class="line"><span class="attr">    listKind:</span> <span class="string">EtcdClusterList</span></span><br><span class="line"><span class="attr">    plural:</span> <span class="string">etcdclusters</span></span><br><span class="line"><span class="attr">    shortNames:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">etcdclus</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">etcd</span></span><br><span class="line"><span class="attr">    singular:</span> <span class="string">etcdcluster</span></span><br><span class="line"><span class="attr">  scope:</span> <span class="string">Namespaced</span></span><br><span class="line"><span class="attr">  version:</span> <span class="string">v1beta2</span></span><br><span class="line"><span class="attr">  versions:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">v1beta2</span></span><br><span class="line"><span class="attr">    served:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p>
<p>The <code>CR</code>’s group, version, and kind together form the fully qualified name of a Kubernetes resource type. That canonical name must be unique across a cluster.</p>
<p>Defining an Operator Service Account:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator-sa</span></span><br></pre></td></tr></table></figure></p>
<p>Defining role:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator-role</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">etcd.database.coreos.com</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">etcdclusters</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">etcdbackups</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">etcdrestores</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">'*'</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">pods</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">services</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">endpoints</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">persistentvolumeclaims</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">events</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">'*'</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">apps</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">deployments</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">'*'</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">secrets</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">get</span></span><br></pre></td></tr></table></figure></p>
<p>Defining rolebinding, assigns the role to the service account for the etcd Operator:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator-rolebinding</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator-role</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator-sa</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">default</span></span><br></pre></td></tr></table></figure></p>
<p>The Operator is a custom controller running in a pod, and it watches the EtcdCluster CR you defined earlier.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">etcd-operator</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">etcd-operator</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">etcd-operator</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">quay.io/coreos/etcd-operator:v0.9.4</span></span><br><span class="line"><span class="attr">        command:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">etcd-operator</span></span><br><span class="line"><span class="bullet">        -</span> <span class="bullet">--create-crd=false</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_POD_NAMESPACE</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_POD_NAME</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line"><span class="attr">        imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">etcd-operator-sa</span></span><br></pre></td></tr></table></figure></p>
<p>Declaring an etcd cluster:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">etcd.database.coreos.com/v1beta2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">EtcdCluster</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">example-etcd-cluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  size:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  version:</span> <span class="number">3.1</span><span class="number">.10</span></span><br></pre></td></tr></table></figure></p>
<p>After create <code>CR</code> resource, operator will generate 3 replicas pod (the pod definition is written by operator logic).</p>
<p>This example etcd cluster is a first-class citizen, an <code>EtcdCluster</code> in your cluster’s API. Since it’s an API resource, you can get the etcd cluster spec and status directly from Kubernetes.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## etcdcluster is a resource just like pod/deploy/sts</span></span><br><span class="line">kubectl describe etcdcluster example-etcd-cluster</span><br></pre></td></tr></table></figure></p>
<p>The etcd Operator creates a Kubernetes service in the etcd cluster’s namespace:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get services --selector etcd_cluster=example-etcd-cluster</span><br></pre></td></tr></table></figure></p>
<p>Run the etcd client on the cluster and use it to connect to the client service and interact with the etcd API.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl run --rm -i --tty etcdctl --image quay.io/coreos/etcd --restart=Never -- /bin/sh</span><br></pre></td></tr></table></figure></p>
<p>From the etcd container’s shell, create and read a key-value pair in etcd with etcdctl’s put and get verbs:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> ETCDCTL_API=3</span><br><span class="line"><span class="built_in">export</span> ETCDCSVC=http://example-etcd-cluster-client:2379</span><br><span class="line">etcdctl --endpoints <span class="variable">$ETCDCSVC</span> put foo bar</span><br><span class="line">etcdctl --endpoints <span class="variable">$ETCDCSVC</span> get foo</span><br><span class="line"></span><br><span class="line"><span class="comment">## check etcd cluster general health</span></span><br><span class="line">etcdctl --endpoints http://example-etcd-cluster-client:2379 cluster-health</span><br></pre></td></tr></table></figure></p>
<p>You can try to delete etcd pod or upgrade the version (edit cr file then apply) and watching the operator recover the health.</p>
<p>kubectl tricks for upgrade:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl patch etcdcluster example-etcd-cluster --<span class="built_in">type</span>=<span class="string">'json'</span> \</span><br><span class="line">  -p <span class="string">'[&#123;"op": "replace", "path": "/spec/version", "value":3.3.12&#125;]'</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Chapter-3-Operators-at-the-Kubernetes-Interface"><a href="#Chapter-3-Operators-at-the-Kubernetes-Interface" class="headerlink" title="Chapter 3 Operators at the Kubernetes Interface"></a>Chapter 3 Operators at the Kubernetes Interface</h1><p>Operators extend two key Kubernetes concepts: <code>resources</code> and <code>controllers</code>. The Kubernetes API includes a mechanism, the CRD, for defining new resources.</p>
<p>这2段话把一般通用控制器和operator的区别讲清楚了:</p>
<blockquote>
<p>The actions the ReplicaSet controller takes are intentionally general and application agnostic. It does not, should not, and truly cannot know the particulars of startup and shutdown sequences for every application that might run on a Kubernetes cluster.</p>
</blockquote>
<blockquote>
<p>An Operator is the application-specific combination of CRs and a custom controller that does know all the details about starting, scaling, recovering, and managing its application.</p>
</blockquote>
<p>Every Operator has one or more custom controllers implementing its application-specific management logic.</p>
<p>An Operator, in turn, can be limited to a namespace, or it can maintain its operand across an entire cluster.</p>
<p>For example, cluster-scoped operator:</p>
<blockquote>
<p>Istio operator: <a href="https://github.com/istio/operator" target="_blank" rel="noopener">https://github.com/istio/operator</a><br>cert-manager: <a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">https://github.com/jetstack/cert-manager</a></p>
</blockquote>
<p>A <code>service account</code> is a special type of cluster user for authorizing programs instead of people. An Operator is a program that uses the Kubernetes API, and most Operators should derive their access rights from a service account. </p>
<h1 id="Chapter-4-The-Operator-Framework"><a href="#Chapter-4-The-Operator-Framework" class="headerlink" title="Chapter 4 The Operator Framework"></a>Chapter 4 The Operator Framework</h1><p>This chapter introduced the three pillars of the Operator Framework: the Operator SDK for building and developing Operators; Operator Lifecycle Manager for distributing, installing, and upgrading them; and Operator Metering for measuring Operator performance and resource consumption.</p>
<p>The <code>Red Hat Operator Framework</code> makes it simpler to create and distribute Operators. It makes building Operators easier with a <code>software development kit (SDK)</code> that automates much of the repetitive implementation work. The Framework also provides mechanisms for deploying and managing Operators. <code>Operator Lifecycle Manager (OLM)</code> is an Operator that installs, manages, and upgrades other Operators. <code>Operator Metering</code> is a metrics system that accounts for Operators’ use of cluster resources.</p>
<p><code>Operator SDK</code>: <a href="https://github.com/operator-framework/operator-sdk" target="_blank" rel="noopener">https://github.com/operator-framework/operator-sdk</a><br>The SDK currently includes first-class support for constructing Operators in the <code>Go</code> programming language, with support for other languages planned. The SDK also offers what might be described as an adapter architecture for <code>Helm</code> charts or <code>Ansible</code> playbooks. </p>
<p><code>Operator Lifecycle Manager</code> takes the Operator pattern one level up the stack: it’s an Operator that acquires, deploys, and manages Operators on a Kubernetes cluster.</p>
<p><code>Operator Metering</code> is a system for analyzing the resource usage of the Operators running on Kubernetes clusters.</p>
<p><strong>Install operator SDK</strong>: <a href="https://sdk.operatorframework.io/docs/install-operator-sdk/" target="_blank" rel="noopener">https://sdk.operatorframework.io/docs/install-operator-sdk/</a><br>注意k8s version是否与当前operator sdk兼容，比如我实验的时候k8s version 1.13.2，它支持的crd api version is <code>apiextensions.k8s.io/v1beta1</code>, 而最近的operator sdk生成的crd api version is <code>apiextensions.k8s.io/v1</code>. 书中用的operator sdk version <code>0.11.0</code>.</p>
<h1 id="Chapter-5-Sample-Application-Visitors-Site"><a href="#Chapter-5-Sample-Application-Visitors-Site" class="headerlink" title="Chapter 5 Sample Application: Visitors Site"></a>Chapter 5 Sample Application: Visitors Site</h1><p>In the chapters that follow, we’ll create Operators to deploy this application using each of the approaches provided by the Operator SDK (<strong>Helm, Ansible, and Go</strong>), and explore the benefits and drawbacks of each.</p>
<p>读到这里，疑惑Helm是如何处理这个问题的，特别是对同一个charts之中的依赖:<br>When deploying applications through manifests, awareness of these relationships is required to ensure that the values line up.</p>
<p>The manifest-based installation for this demo:<br><a href="https://github.com/kubernetes-operators-book/chapters/tree/master/ch05" target="_blank" rel="noopener">https://github.com/kubernetes-operators-book/chapters/tree/master/ch05</a><br>Now deploying it manually with correct order:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f database.yaml</span><br><span class="line">kubectl create -f backend.yaml    </span><br><span class="line">kubectl create -f frontend.yaml</span><br></pre></td></tr></table></figure></p>
<p>Deletion:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete -f database.yaml</span><br><span class="line">kubectl delete -f backend.yaml    </span><br><span class="line">kubectl delete -f frontend.yaml</span><br></pre></td></tr></table></figure></p>
<h1 id="Chapter-6-Adapter-Operators"><a href="#Chapter-6-Adapter-Operators" class="headerlink" title="Chapter 6 Adapter Operators"></a>Chapter 6 Adapter Operators</h1><p>You would have to create <code>CRDs</code> to specify the interface for end users.<br>Kubernetes controllers would not only need to be written with the Operator’s domain-specific logic, but also be correctly hooked into a running cluster to receive the proper notifications. Roles and service accounts would need to be created to permit the Operator to function in the capacity it needs. An Operator is run as a pod inside of a cluster, so an <code>image</code> would need to be built, along with its accompanying deployment manifest.</p>
<p>这章节主要是利用已有的Helm or Ansibel去构造Adapter Operator:<br>The Operator SDK provides a solution to both these problems through its <code>Adapter Operators</code>. Through the command-line tool, the SDK generates the code necessary to run technologies such as Helm and Ansible in an Operator.</p>
<p>First understand the role of <code>CRDs</code>.</p>
<ul>
<li>A CRD is the specification of what constitutes a CR. In particular, the CRD defines the allowed configuration values and the expected output that describes the current state of the resource.</li>
<li>A CRD is created when a new Operator project is generated by the SDK.</li>
<li>The SDK prompts the user for two pieces of information about the CRD during project creation: <code>kind</code>, <code>api-version</code></li>
</ul>
<p>Official operator SDK sample:<br><a href="https://github.com/operator-framework/operator-sdk-samples" target="_blank" rel="noopener">https://github.com/operator-framework/operator-sdk-samples</a></p>
<h2 id="Helm-Operator"><a href="#Helm-Operator" class="headerlink" title="Helm Operator"></a>Helm Operator</h2><p>demo git repo to generate helm operator:<br><a href="https://github.com/kubernetes-operators-book/chapters/tree/master/ch06/visitors-helm" target="_blank" rel="noopener">https://github.com/kubernetes-operators-book/chapters/tree/master/ch06/visitors-helm</a></p>
<p>A Helm Operator can deploy each instance of an application with a different version of <code>values.yaml</code>. The Operator SDK generates Kubernetes controller code for a Helm Operator when it is passed the <code>--type=helm</code> argument.<br>As a prerequisite, be sure to install the <code>Helm</code> command-line tools on your machine. </p>
<h3 id="New-Chart"><a href="#New-Chart" class="headerlink" title="New Chart"></a>New Chart</h3><p>Generate a blank helm chart structure within the operator project code:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">OPERATOR_NAME=visitors-helm-operator</span><br><span class="line">operator-sdk new <span class="variable">$OPERATOR_NAME</span> --api-version=example.com/v1 --kind=VisitorsApp --<span class="built_in">type</span>=helm</span><br></pre></td></tr></table></figure></p>
<p>At this point, everything is in place to begin to implement your chart.</p>
<p>There are several direcotyies created:</p>
<ul>
<li>build: it contains Dockerfile for operator image</li>
<li>deploy: crds definition, role and rolebinding, service account</li>
<li>helm-charts: helm chart structure for your app</li>
<li>watches.yaml: maps each CR type to the specific Helm chart that is used to handle it. </li>
</ul>
<h3 id="Existing-Chart"><a href="#Existing-Chart" class="headerlink" title="Existing Chart"></a>Existing Chart</h3><p>Helm install command 其实有很多参数可以customize，比如选择values yaml file, 但这里没有这么灵活，用的是默认的values.yaml.</p>
<p>一定要事先检查template validation，比如对于helm3:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm template &lt;chart dir or archive file&gt; [--debug] | less</span><br></pre></td></tr></table></figure></p>
<p>查看每个rendering 是否格式正确，helm template对format issue并不会报错。</p>
<p>Generate Helm operator atop existing helm archive, 对于OpenShift，要先<code>oc login</code>，否则operator-sdk 不能获得cluster info:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">OPERATOR_NAME=visitors-helm-operator</span><br><span class="line"><span class="comment">## download existing chart archive</span></span><br><span class="line">wget https://github.com/kubernetes-operators-book/chapters/releases/download/1.0.0/visitors-helm.tgz</span><br><span class="line"><span class="comment">## generate helm operator</span></span><br><span class="line">operator-sdk new <span class="variable">$OPERATOR_NAME</span> --api-version=example.com/v1 --kind=VisitorsApp --<span class="built_in">type</span>=helm --helm-chart=./visitors-helm.tgz</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>--helm-chart</code>: A URL to a chart archive, The repository and name of a remote chart, or The location of a local directory</li>
<li><code>--helm-chart-repo</code>: Specifies a remote repository URL for the chart </li>
<li><code>--helm-chart-version</code>: Tells the SDK to fetch a specific version of the chart. If this is omitted, the latest available version is used.</li>
</ul>
<p>You will see <code>deploy/crds/example.com_v1_visitorsapp_cr.yaml</code> has the fields exactly the same as <code>values.yaml</code> in helm chart.</p>
<p>Before running the chart, the Operator will map the values found in the custom resource’s spec field to the <code>values.yaml</code> file.</p>
<p>如此生成的CRD 和 role (extremely permissive) 可以直接使用，但可能不满足具体要求，比如constraints 以及权限限制，需要自己调整:</p>
<ul>
<li><a href="https://kubernetes.io/docs/tasks/access-kubernetes-api/custom-resources/custom-resource-definitions/#specifying-a-structural-schema" target="_blank" rel="noopener">CRD structure schema</a></li>
</ul>
<h2 id="Ansible-Operator"><a href="#Ansible-Operator" class="headerlink" title="Ansible Operator"></a>Ansible Operator</h2><p>More or less the same as Helm operator generation.<br>Generate blank Ansible operator project:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">OPERATOR_NAME=visitors-ansible-operator</span><br><span class="line">operator-sdk new <span class="variable">$OPERATOR_NAME</span> --api-version=example.com/v1 --kind=VisitorsApp --<span class="built_in">type</span>=ansible</span><br></pre></td></tr></table></figure></p>
<h2 id="Test-Operator"><a href="#Test-Operator" class="headerlink" title="Test Operator"></a>Test Operator</h2><p>An Operator is delivered as a normal container image. However, during the development and testing cycle, it is often easier to skip the image creation process and simply run the Operator <strong>outside of the cluster</strong>.<br>这个用在开发测试的时候，它不会部署一个真正的operator deployment，只是一个process，但实验效果和真实的一样。这里只是针对helm and ansible的类型.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## go to root path of operator project</span></span><br><span class="line"><span class="comment">## set full path in `chart` field to chart</span></span><br><span class="line">cp watches.yaml <span class="built_in">local</span>-watches.yaml</span><br><span class="line">kubectl apply -f deploy/crds/*_crd.yaml</span><br><span class="line"><span class="comment">## start opeerator process</span></span><br><span class="line">operator-sdk up <span class="built_in">local</span> --watches-file ./<span class="built_in">local</span>-watches.yaml</span><br></pre></td></tr></table></figure>
<p>The process is up and running, next is to apply your <code>cr</code> yaml:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f deploy/crds/*_cr.yaml</span><br><span class="line">kubectl delete -f deploy/crds/*_cr.yaml</span><br></pre></td></tr></table></figure></p>
<p>你会看到log的变化，以及application在k8s cluster中的更新。<br>Once the test is complete, end the running process by pressing <code>Ctrl-C</code>.</p>
<p>During development, repeat this process to test changes. On each iteration, be sure to restart the Operator process to pick up any changes to the Helm or Ansible files</p>
<h2 id="Deploy-Operator"><a href="#Deploy-Operator" class="headerlink" title="Deploy Operator"></a>Deploy Operator</h2><p>Running an Operator outside of the cluster, is convenient for testing and debugging purposes, but production Operators run as Kubernetes deployments.</p>
<ol>
<li><p>Build the operator image. The Operator SDK’s <code>build</code> command chains to the underlying Docker daemon to build the Operator image, and takes the full image name and version when run:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">operator-sdk build jdob/visitors-operator:0.1</span><br></pre></td></tr></table></figure>
<p>You can check the Dockerfile, no additional changes are needed. the <code>${HOME}</code> is consistent with the path in <code>watches.yaml</code>.</p>
<p>Once built, push the image to an externally accessible repository</p>
</li>
<li><p>Configure the deployment. Update the <code>deploy/operator.yaml</code> file that the SDK generates with the name of the image. </p>
</li>
<li><p>Deploy CRD</p>
</li>
<li><p>Deploy Service account and Role</p>
</li>
<li><p>Deploy Operator deployment</p>
</li>
</ol>
<h1 id="Chapter-7-Operators-in-Go-with-the-Operator-SDK"><a href="#Chapter-7-Operators-in-Go-with-the-Operator-SDK" class="headerlink" title="Chapter 7 Operators in Go with the Operator SDK"></a>Chapter 7 Operators in Go with the Operator SDK</h1><p>这一节的code参考，没有把所有logic都写到一个文件下，而是针对不同的resource分开写的，还将公用的部分单独分出来了，很有参考价值, 我总结了一下实现，看这里:<br><a href="https://github.com/chengdol/k8s-operator-sdk-demo" target="_blank" rel="noopener">https://github.com/chengdol/k8s-operator-sdk-demo</a></p>
<p>The Operator SDK provides that flexibility by making it easy for developers to use the <code>Go</code> programming language, including its ecosystem of external libraries, in their Operators. Write acutall business logic of operator.</p>
<p>While you can write all these pieces manually, the Operator SDK provides commands that will automate the creation of much of the supporting code, allowing you to focus on implementing the actual <code>business logic</code> of the Operator.</p>
<p>We will explore the files that need to be edited with custom application logic and discuss some common practices for Operator development.</p>
<h2 id="Create-Go-Based-Operator"><a href="#Create-Go-Based-Operator" class="headerlink" title="Create Go Based Operator"></a>Create Go Based Operator</h2><p>关于如何command line创建go-based operator书中的表述不清楚，我参考了Red Hat的文档:</p>
<ul>
<li><a href="https://docs.openshift.com/container-platform/4.3/operators/operator_sdk/osdk-getting-started.html#building-memcached-operator-using-osdk_osdk-getting-started" target="_blank" rel="noopener">Building a Go-based Memcached Operator using the Operator SDK</a></li>
</ul>
<p>这描述太含糊了:<br>In particular, the Operator code <strong>must</strong> be located in your <code>$GOPATH</code>, 关键是怎么设置<code>$GOPATH</code>:</p>
<ul>
<li><a href="https://www.digitalocean.com/community/tutorials/understanding-the-gopath" target="_blank" rel="noopener">Understand the GOPATH</a></li>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-install-go-and-set-up-a-local-programming-environment-on-ubuntu-18-04" target="_blank" rel="noopener">Setting up local Go environment</a></li>
</ul>
<p>如果用<code>go env | grep GOPATH</code>，发现已经有默认值了<code>$HOME/go</code>，但还需要在bash env中export:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> GOPATH=<span class="variable">$HOME</span>/go</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$GOPATH</span>/bin</span><br><span class="line"><span class="comment">#export GO111MODULE=on</span></span><br><span class="line"></span><br><span class="line">OPERATOR_NAME=visitors-operator</span><br><span class="line"><span class="comment">## 这个路径和后面的controller import中的路径要一致！</span></span><br><span class="line">OPERATOR_PATH=<span class="variable">$GOPATH</span>/src/github.com/jdob</span><br><span class="line">mkdir -p <span class="variable">$OPERATOR_PATH</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$OPERATOR_PATH</span></span><br><span class="line"><span class="comment">## no --type specified, default is go</span></span><br><span class="line">operator-sdk new <span class="variable">$OPERATOR_NAME</span></span><br></pre></td></tr></table></figure></p>
<p>针对operator-sdk new出现的错误信息，我export了<code>GO111MODULE=on</code>，但后来重做一遍后这个错误又消失了:</p>
<ul>
<li><a href="https://dev.to/maelvls/why-is-go111module-everywhere-and-everything-about-go-modules-24k" target="_blank" rel="noopener">Why is GO111MODULE everywhere, and everything about Go Modules</a></li>
</ul>
<p>The generation can take a few minutes as all of the Go dependencies are downloaded. </p>
<h2 id="Add-CRDs"><a href="#Add-CRDs" class="headerlink" title="Add CRDs"></a>Add CRDs</h2><p>You can add new CRDs to an Operator using the SDK’s add api command. Run from the Operator project <code>root</code> directory to generate CRD: 这应该说明一个Operator可以有多个CRDs.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$OPERATOR_PATH</span>/<span class="variable">$OPERATOR_NAME</span></span><br><span class="line">operator-sdk add api --api-version=example.com/v1 --kind=VisitorsApp</span><br><span class="line"><span class="comment">## from command outputs, you will see what files are generated</span></span><br></pre></td></tr></table></figure></p>
<p>3 files are important:</p>
<ul>
<li><code>deploy/crds/*cr.yaml</code></li>
<li><code>deploy/crds/*crd.yaml</code></li>
<li><code>pkg/apis/example/v1/visitorsapp_types.go</code>: contains a number of struct objects that the Operator codebase leverages</li>
</ul>
<p>For example, in <code>pkg/apis/example/v1/visitorsapp_types.go</code> edit the Spec and Status struct:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// VisitorsAppSpec defines the desired state of VisitorsApp</span></span><br><span class="line"><span class="comment">// +k8s:openapi-gen=true</span></span><br><span class="line"><span class="keyword">type</span> VisitorsAppSpec <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">// INSERT ADDITIONAL SPEC FIELDS - desired state of cluster</span></span><br><span class="line">	<span class="comment">// Important: Run "operator-sdk generate k8s" to regenerate code after modifying this file</span></span><br><span class="line">	<span class="comment">// Add custom validation using kubebuilder tags: https://book.kubebuilder.io/beyond_basics/generating_crd.html</span></span><br><span class="line"></span><br><span class="line">	Size       <span class="keyword">int32</span>  <span class="string">`json:"size"`</span></span><br><span class="line">	Title      <span class="keyword">string</span> <span class="string">`json:"title"`</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// VisitorsAppStatus defines the observed state of VisitorsApp</span></span><br><span class="line"><span class="comment">// +k8s:openapi-gen=true</span></span><br><span class="line"><span class="keyword">type</span> VisitorsAppStatus <span class="keyword">struct</span> &#123;</span><br><span class="line">	<span class="comment">// INSERT ADDITIONAL STATUS FIELD - define observed state of cluster</span></span><br><span class="line">	<span class="comment">// Important: Run "operator-sdk generate k8s" to regenerate code after modifying this file</span></span><br><span class="line">	<span class="comment">// Add custom validation using kubebuilder tags: https://book.kubebuilder.io/beyond_basics/generating_crd.html</span></span><br><span class="line"></span><br><span class="line">	BackendImage  <span class="keyword">string</span> <span class="string">`json:"backendImage"`</span></span><br><span class="line">	FrontendImage <span class="keyword">string</span> <span class="string">`json:"frontendImage"`</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>After editing, run<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## After any change to a *_types.go file, you need to update any generated code</span></span><br><span class="line">operator-sdk generate k8s</span><br></pre></td></tr></table></figure></p>
<p>Then customize <code>deploy/crds/example_v1_visitorsapp_crd.yaml</code> file to reflect the struct content, for example:<br><a href="https://github.com/chengdol/chapters/tree/master/ch07/visitors-operator/deploy/crds" target="_blank" rel="noopener">https://github.com/chengdol/chapters/tree/master/ch07/visitors-operator/deploy/crds</a></p>
<p>这里并没有特意修改RBAC，用的默认Operator permission:<br><a href="https://github.com/chengdol/chapters/tree/master/ch07/visitors-operator/deploy" target="_blank" rel="noopener">https://github.com/chengdol/chapters/tree/master/ch07/visitors-operator/deploy</a></p>
<h2 id="Write-Control-Logic"><a href="#Write-Control-Logic" class="headerlink" title="Write Control Logic"></a>Write Control Logic</h2><p>Inside of the Operator pod itself, you need a controller to watch for changes to CRs and react accordingly. Similar to adding a CRD, you use the SDK to generate the controller’s skeleton code.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## generate controller code skeleton</span></span><br><span class="line">operator-sdk add controller --api-version=example.com/v1 --kind=VisitorsApp</span><br></pre></td></tr></table></figure>
<p>The file <code>pkg/controller/visitorsapp/visitorsapp_controller.go</code> will be created, the is the controller file that implements the Operator’s custom logic.</p>
<p>More information on K8s controller:<br><a href="https://kubernetes.io/docs/concepts/architecture/controller/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/architecture/controller/</a></p>
<p>主要有2个func需要customize: <code>add</code> and <code>Reconcile</code>，一个是watch也就是告诉K8s哪些resource需要监控，一个是控制逻辑.<br>While the bulk of the Operator logic resides in the controller’s <code>Reconcile</code> function, the <code>add</code> function establishes the watches that will trigger reconcile events:<br><a href="https://github.com/chengdol/chapters/tree/master/ch07/visitors-operator/pkg/controller/visitorsapp" target="_blank" rel="noopener">https://github.com/chengdol/chapters/tree/master/ch07/visitors-operator/pkg/controller/visitorsapp</a></p>
<p>The first watch listens for changes to the <code>primary resource</code> that the controller monitors. 也就是自定义的kind类型。<br>The second watch, or more accurately, series of watches, listens for changes to any <code>child resources</code> the Operator created to support the primary resource. 也就是自定义kind类型中间接的其他resources，比如deployment, sts, service等</p>
<p><strong>Reconcile function</strong><br>The Reconcile function, also known as the <code>reconcile loop</code>, is where the Operator’s logic resides:<br><a href="https://github.com/chengdol/chapters/blob/master/ch07/visitors-operator/pkg/controller/visitorsapp/visitorsapp_controller.go" target="_blank" rel="noopener">https://github.com/chengdol/chapters/blob/master/ch07/visitors-operator/pkg/controller/visitorsapp/visitorsapp_controller.go</a></p>
<p>The Reconcile function returns <code>two</code> objects: a ReconcileResult instance and an error.<br>有几种可能:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> reconcile.Result&#123;&#125;, <span class="literal">nil</span></span><br><span class="line"><span class="keyword">return</span> reconcile.Result&#123;&#125;, err</span><br><span class="line"><span class="keyword">return</span> reconcile.Result&#123;Requeue: <span class="literal">true</span>&#125;, <span class="literal">nil</span></span><br><span class="line"><span class="keyword">return</span> reconcile.Result&#123;RequeueAfter: time.Second*<span class="number">5</span>&#125;, <span class="literal">nil</span></span><br></pre></td></tr></table></figure></p>
<p>Since Go-based Operators make heavy use of the Go Kubernetes libraries, it may be useful to review:<br><a href="https://pkg.go.dev/k8s.io/api" target="_blank" rel="noopener">https://pkg.go.dev/k8s.io/api</a><br>the <code>core/v1</code> and <code>apps/v1</code> modules are frequently used to interact with the common Kubernetes resources.</p>
<p>这里提到了update status value，应该对应的是resource yaml中底部的status 信息:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">instance.Status.BackendImage = <span class="string">"example"</span></span><br><span class="line">err := r.client.Status().Update(context.TODO(), instance)</span><br></pre></td></tr></table></figure></p>
<p>如同我在这章开头提到的，作者将不同resource的逻辑分开到不同的go file了，可以仔细观察怎么写的.</p>
<p><strong>关于Child resource deletion:</strong><br>If the child resource’s owner type is correctly set to the primary resource, when the parent is deleted, Kubernetes garbage collection will automatically clean up all of its child resources</p>
<p>It is important to understand that when Kubernetes deletes a resource, it still calls the Reconcile function. </p>
<p>There are times, however, where specific cleanup logic is required. The approach in such instances is to block the deletion of the primary resource through the use of a <code>finalizer</code>. A finalizer is simply a series of strings on a resource, 感觉就是一个mark.</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">finalizer := <span class="string">"visitors.example.com"</span></span><br><span class="line"></span><br><span class="line">beingDeleted := instance.GetDeletionTimestamp() != <span class="literal">nil</span></span><br><span class="line"><span class="keyword">if</span> beingDeleted &#123;</span><br><span class="line">    <span class="keyword">if</span> contains(instance.GetFinalizers(), finalizer) &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Perform finalization logic. If this fails, leave the finalizer</span></span><br><span class="line">        <span class="comment">// intact and requeue the reconcile request to attempt the clean</span></span><br><span class="line">        <span class="comment">// up again without allowing Kubernetes to actually delete</span></span><br><span class="line">        <span class="comment">// the resource.</span></span><br><span class="line"></span><br><span class="line">        instance.SetFinalizers(remove(instance.GetFinalizers(), finalizer))</span><br><span class="line">        err := r.client.Update(context.TODO(), instance)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> reconcile.Result&#123;&#125;, err</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> reconcile.Result&#123;&#125;, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Idempotency"><a href="#Idempotency" class="headerlink" title="Idempotency"></a>Idempotency</h2><p>It is critical that Operators are idempotent. Multiple calls to reconcile an unchanged resource must produce the same effect each time.</p>
<ol>
<li><p>Before creating child resources, check to see if they already exist. Remember, Kubernetes may call the reconcile loop for a variety of reasons beyond when a user first creates a CR. Your controller should not duplicate the CR’s children on each iteration through the loop.</p>
</li>
<li><p>Changes to a resource’s spec (in other words, its configuration values) trigger the reconcile loop. Therefore, it is often not enough to simply check for the existence of expected child resources. The Operator also needs to verify that the child resource configuration matches what is defined in the parent resource at the time of reconciliation.</p>
</li>
<li><p>Reconciliation is not necessarily called for each change to the resource. It is possible that a single reconciliation may contain multiple changes. The Operator must be careful to ensure the entire state of the CR is represented by all of its child resources.</p>
</li>
<li><p>Just because an Operator does not need to make changes during a reconciliation request doesn’t mean it doesn’t need to update the CR’s Status field. Depending on what values are captured in the CR’s status, it may make sense to update these even if the Operator determines it doesn’t need to make any changes to the existing resources.</p>
</li>
</ol>
<h2 id="Operator-Impact"><a href="#Operator-Impact" class="headerlink" title="Operator Impact"></a>Operator Impact</h2><p>If the Operator incorrectly handles operations, they can negatively affect the performance of the entire cluster.</p>
<h2 id="Test-Operator-1"><a href="#Test-Operator-1" class="headerlink" title="Test Operator"></a>Test Operator</h2><blockquote>
<p>如果operator test有错误，则image build之后运行也会出现同样的错误！</p>
</blockquote>
<p>The process running the Operator may be outside of the cluster, but Kubernetes will treat it as it does any other controller.</p>
<p>Go to the root project directory:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## deploy CRD</span></span><br><span class="line">kubectl apply -f deploy/crds/*_crd.yaml</span><br><span class="line"><span class="comment">## start operator in local mode</span></span><br><span class="line">operator-sdk up <span class="built_in">local</span> --namespace default</span><br><span class="line"><span class="comment">## deploy CR</span></span><br><span class="line">kubectl apply -f deploy/crds/*_cr.yaml</span><br></pre></td></tr></table></figure></p>
<p>The Operator SDK uses credentials from the kubectl configuration file to connect to the cluster and attach the Operator. The running process acts as if it were an Operator pod running inside of the cluster and writes logging information to standard output.</p>
<h1 id="Chapter-8-Operator-Lifecycle-Manager"><a href="#Chapter-8-Operator-Lifecycle-Manager" class="headerlink" title="Chapter 8 Operator Lifecycle Manager"></a>Chapter 8 Operator Lifecycle Manager</h1><p>这章节概念性的东西较多，建议多读几遍。<br><code>OLM</code> git repo:<br><a href="https://github.com/operator-framework/operator-lifecycle-manager" target="_blank" rel="noopener">https://github.com/operator-framework/operator-lifecycle-manager</a></p>
<p>Once you have written an Operator, it’s time to turn your attention to its installation and management. As there are multiple steps involved in deploying an Operator, a management layer becomes necessary to facilitate the process. 就是管理Operator的东西.</p>
<p><code>OLM</code>’s benefits extend beyond installation into Day 2 operations, including managing upgrades to existing Operators, providing a means to convey Operator stability through version channels, and the ability to aggregate multiple Operator hosting sources into a single interface. OLM在Openshift 上是自带的，K8s上没有。OLM也是通过CRD实现的，在Openshift 中run <code>oc get crd</code> 就可以看到相关CRDs.</p>
<ol>
<li>ClusterServiceVersion<br>You can think of a CSV as analogous to a Linux package, such as a Red Hat Package Manager (RPM) file.</li>
</ol>
<p>Much like how a deployment describes the “pod template” for the pods it creates, a CSV contains a “deployment template” for the deployment of the Operator pod. </p>
<ol start="2">
<li><p>CatalogSource<br>A CatalogSource contains information for accessing a repository of Operators. OLM provides a utility API named packagemanifests for querying catalog sources, which provides a list of Operators and the catalogs in which they are found. </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl -n olm get packagemanifests</span><br></pre></td></tr></table></figure>
</li>
<li><p>Subscription<br>End users create a subscription to install, and subsequently update, the Operators that OLM provides. A subscription is made to a <code>channel</code>, which is a stream of Operator versions, such as “stable” or “nightly.”</p>
</li>
</ol>
<p>To continue with the earlier analogy to Linux packages, a subscription is equivalent to a command that installs a package, such as yum install.</p>
<ol start="4">
<li><p>InstallPlan<br>A subscription creates an InstallPlan, which describes the full list of resources that OLM will create to satisfy the CSV’s resource requirements.</p>
</li>
<li><p>OperatorGroup<br>An Operator belonging to an OperatorGroup will not react to custom resource changes in a namespace not indicated by the group.</p>
</li>
</ol>
<h2 id="Installing-OLM"><a href="#Installing-OLM" class="headerlink" title="Installing OLM"></a>Installing OLM</h2><p>version <code>v0.11.0</code>, 我用的k8s <code>v1.13.2</code>，最近的版本不兼容了<br><a href="https://github.com/operator-framework/operator-lifecycle-manager/releases" target="_blank" rel="noopener">https://github.com/operator-framework/operator-lifecycle-manager/releases</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https://github.com/operator-framework/operator-lifecycle-manager/releases/download/0.11.0/crds.yaml</span><br><span class="line">kubectl apply -f https://github.com/operator-framework/operator-lifecycle-manager/releases/download/0.11.0/olm.yaml</span><br></pre></td></tr></table></figure></p>
<p>After applying, The CRDs for OLM are created, the olm pods are up and running in <code>olm</code> namespace. OLM可以用于和<code>OperatorHub.io</code> 进行交互，如同Helm 和HelmHub, Docker 和DockerHub. 书中用了个例子说明如何部署etcd operator from operatorHub.</p>
<p>后面主要是讲如何publish自己的operator了, 目前用不到。</p>
<h1 id="Chapter-9-Operator-Philosophy"><a href="#Chapter-9-Operator-Philosophy" class="headerlink" title="Chapter 9 Operator Philosophy"></a>Chapter 9 Operator Philosophy</h1><p>Let’s try to connect those tactics to the strategic ideas that underpin them to understand an existential question: what are Operators for?</p>
<p>An Operator reduces human intervention bugs by automating the regular chores that keep its application running. <code>Operators: Kubernetes Application Reliability Engineering</code></p>
<p>有些启发价值:<br>You can build Operators that not only run and upgrade an application, but respond to errors or slowing performance.</p>
<p>Control loops in Kubernetes watch resources and react when they don’t match some desired state. Operators let you customize a control loop for resources that represent your application. The first Operator concerns are usually automatic deployment and self-service provisioning of the operand. Beyond that first level of the maturity model, an Operator should know its application’s critical state and how to repair it. The Operator can then be extended to observe key application metrics and act to tune, repair, or report on them.</p>
<p>Site Reliability Engineering lists the <code>four golden signals</code> as <code>latency</code>, <code>traffic</code>, <code>errors</code>, and <code>saturation</code>.</p>
<p>Highly Successful Operators:</p>
<ol>
<li>An Operator should run as a single Kubernetes deployment.</li>
<li>Operators should define new custom resource types on the cluster.</li>
<li>Operators should use appropriate Kubernetes abstractions whenever possible.</li>
<li>Operator termination should not affect the operand.</li>
<li>Operator termination should not affect the operand.</li>
<li>Operator termination should not affect the operand.</li>
<li>Operators should be thoroughly tested, including chaos testing.</li>
</ol>
<h1 id="Appendix"><a href="#Appendix" class="headerlink" title="Appendix"></a>Appendix</h1><h2 id="Running-an-Operator-as-a-Deployment-Inside-a-Cluster"><a href="#Running-an-Operator-as-a-Deployment-Inside-a-Cluster" class="headerlink" title="Running an Operator as a Deployment Inside a Cluster"></a>Running an Operator as a Deployment Inside a Cluster</h2><p>Please see my git repo for more details.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## build operator image</span></span><br><span class="line"><span class="comment">## go to project root directory</span></span><br><span class="line">operator-sdk build image:tag</span><br></pre></td></tr></table></figure></p>
<p>Then docker push image to docker registry, replace the image placeholder in <code>operator.yaml</code> file. Then apply the CR yaml.</p>
<p>书中另外2个appendix 是关于CRD validation and RBAC control的设置。</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>kubernetes</tag>
        <tag>operator</tag>
      </tags>
  </entry>
  <entry>
    <title>The Linux Command Line</title>
    <url>/2019/08/15/book-linux-command-line/</url>
    <content><![CDATA[<p>This is the latest version and the second time I read this book, record something that I forget, just for future quick review.</p>
<p>When we speak of the command line, we are really referring to the shell. The shell is a program that takes keyboard commands and passes them to the operating system to carry out.</p>
<p>If the last character of the prompt is a <code>hash mark(#)</code> rather than a <code>dollar sign</code>, the terminal session has superuser privileges.</p>
<h1 id="Chapter-2-Navigation"><a href="#Chapter-2-Navigation" class="headerlink" title="Chapter 2 Navigation"></a>Chapter 2 Navigation</h1><p><code>pwd, cd, ls</code>, basic things, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -ltrhF</span><br><span class="line">ls -lSrhF</span><br><span class="line">ls -Rla</span><br><span class="line">ls -ld</span><br></pre></td></tr></table></figure></p>
<h1 id="Chapter-3-Exploring-the-System"><a href="#Chapter-3-Exploring-the-System" class="headerlink" title="Chapter 3 Exploring the System"></a>Chapter 3 Exploring the System</h1><p>determine file type:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">file &lt;filename&gt;</span><br></pre></td></tr></table></figure></p>
<p><code>less -N</code> is more.</p>
<p>This is the supplement of <code>&lt;&lt;How Linux Works&gt;&gt;</code><br><strong>/boot</strong><br>Contains the <code>Linux kernel</code>, initial RAM disk image (for drivers needed at boot time), and the boot loader. Interesting files include <code>/boot/grub/grub.conf</code>, or <code>menu.lst</code>, which is used to configure the boot loader, and <code>/boot/vmlinuz</code> (or something similar), the Linux kernel.</p>
<p><strong>/dev</strong><br>This is a special directory that contains device nodes. “Everything is a file” also applies to devices. Here is where the kernel maintains a list of all the devices it understands.</p>
<p><strong>/etc</strong><br>The /etc directory contains all the system-wide configuration files. It also contains a collection of shell scripts that start each of the system services at boot time. Everything in this directory should be readable text. While everything in <code>/etc</code> is interesting, here are some all-time favorites: <code>/etc/crontab</code>, a file that defines when automated jobs will run; <code>/etc/fstab</code>, a table of storage devices and their associated mount points; and <code>/etc/passwd</code>, a list of the user accounts.</p>
<p><strong>/proc</strong><br>The <code>/proc</code> directory is special. It’s not a real file system in the sense of files stored on your hard drive. Rather, it is a <code>virtual file system</code> maintained by the Linux kernel. The <code>files</code> it contains are peepholes into the kernel itself. The files are readable and will give you a picture of how the kernel sees your computer.</p>
<p><strong>/var/log</strong><br><code>/var/log</code> contains log files, records of various system activity. These are important and should be monitored from time to time. The most useful ones are <code>/var/log/</code> messages and <code>/var/log/syslog</code>. Note that for security reasons on some systems, you must be the superuser to view log files.</p>
<h1 id="Chapter-4-Manipluating-Files-and-Directories"><a href="#Chapter-4-Manipluating-Files-and-Directories" class="headerlink" title="Chapter 4 Manipluating Files and Directories"></a>Chapter 4 Manipluating Files and Directories</h1><p><code>cp</code> command useful options:<br><code>-a</code>: same as <code>-dR --preserve=all</code><br><code>-u</code>: copy only when the SOURCE file is newer than the destination file or when the destination file is missing<br><code>-r/R</code>: copy directories recursively<br><code>-f</code>: if  an  existing destination file cannot be opened, remove it and try again, will overwrite existing files.<br><code>-p</code>: same as –preserve=mode,ownership,timestamps</p>
<p><code>hard link:</code><br>A hard link is indistinguishable from the file itself. Unlike a symbolic link, when you list a directory containing a hard link, you will see <strong>no</strong> special indication of the link. When a hard link is deleted, the link is removed, but the contents of the file itself continue to exist (that is, its space is not deallocated) <strong>until</strong> all links to the file are deleted.</p>
<blockquote>
<p>Hard links cannot reference directories, only files.</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -li</span><br><span class="line"></span><br><span class="line">269191713 -rw-------  2 root root      6614 Jul 28 20:53 config-hard.json</span><br><span class="line">269191713 -rw-------  2 root root      6614 Jul 28 20:53 config.json</span><br></pre></td></tr></table></figure>
<p>The first field is the inode number, they are the same.</p>
<p><code>symbolic link:</code><br>The same way as a Windows shortcut:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ln -s /root/config.json /tmp/config-link.json</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that should use absolute path! although relative is fine. <code>/root/config.yaml</code> is   the source<br>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  lrwxrwxrwx 1 root root 17 Aug 16 10:10 config-link.json -&gt; /root/config.json</span><br><span class="line">  ``` </span><br><span class="line"></span><br><span class="line">remove symbolic link:</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>rm -f /tmp/config-link.json<br><code>`</code></p>
<h1 id="Chapter-5-Working-with-Commands"><a href="#Chapter-5-Working-with-Commands" class="headerlink" title="Chapter 5 Working with Commands"></a>Chapter 5 Working with Commands</h1><p><code>type</code>: Indicate how a command name is interpreted<br><code>which</code>: Display which executable program will be executed<br><code>help</code>: Get help for shell builtins<br><code>man</code>: Display a command’s manual page<br><code>apropos</code>: Display a list of appropriate commands<br><code>info</code>: Display a command’s info entry<br><code>whatis</code>: Display one-line manual page descriptions<br><code>alias</code>: Create an alias for a command</p>
<h1 id="Chapter-6-Redirection"><a href="#Chapter-6-Redirection" class="headerlink" title="Chapter 6 Redirection"></a>Chapter 6 Redirection</h1>]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Modern Java in Action</title>
    <url>/2019/12/06/book-modern-java/</url>
    <content><![CDATA[<p>2019年12月6日，拿到了<code>&lt;&lt;Modern Java in Action&gt;&gt;</code>，主要介绍Lambdas, streams, functional and reactive programming. </p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>The Go Programming Language</title>
    <url>/2020/06/09/book-the-go-programming-lang/</url>
    <content><![CDATA[<p>Recently I am working on Kubernetes Operator, Go is required to implement complex business logic for operators, after having a brief understanding of Go value and Philosophy, and basic syntax, structure, this book is my next step.</p>
<p>There are additional, comprehensive resources on Go web site:<br><a href="https://golang.org/" target="_blank" rel="noopener">https://golang.org/</a><br>Go dev web site:<br><a href="https://go.dev/" target="_blank" rel="noopener">https://go.dev/</a></p>
<p>Other 2 Chinese Go programming books, looks good:</p>
<ul>
<li><a href="https://github.com/chai2010/go-ast-book" target="_blank" rel="noopener">Go语法树入门</a></li>
<li><a href="https://github.com/chai2010/advanced-go-programming-book" target="_blank" rel="noopener">Go语言高级编程</a></li>
</ul>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Python for Devops</title>
    <url>/2019/10/01/book-python-for-devops/</url>
    <content><![CDATA[<p>Good description for daily use:</p>
<p>One time I was in the ocean and a wave crashed on top of me and took my breath away as it pulled me deeper into the ocean. Just as I started to recover my breath, another wave dropped on top of me and extracted much of my remaining energy and pulled me even deeper into the ocean. Just as I started to recover, yet another wave crashed down on top of me. The more I would fight the waves and the ocean, the more energy I drained. I seriously wondered if I would die at that moment. I couldn’t breath, my body ached and I was terrified I was going to drown.</p>
<p>Being close to death helped me focus on the only thing that could save me, which was conserving my energy and using the waves not fighting them.</p>
<h1 id="Install-and-Configure"><a href="#Install-and-Configure" class="headerlink" title="Install and Configure"></a>Install and Configure</h1><p>Usually python2 is pre-installed, need to install <code>python3</code>, can refer this blog<br><a href="https://www.osradar.com/install-python-3-7-on-centos-7-and-fedora-27-28/" target="_blank" rel="noopener">Install Python 3.7 on centos 7</a><br>This installation will not disturb original <code>python2</code> pre-installed (it is the dependency of some other packages).</p>
<p><a href="https://pip.pypa.io/en/stable/installing/" target="_blank" rel="noopener">install pip3</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py</span><br><span class="line"><span class="comment">## install pip3</span></span><br><span class="line">python3 get-pip.py</span><br><span class="line"><span class="comment">## or install pip</span></span><br><span class="line">python get-pip.py</span><br></pre></td></tr></table></figure></p>
<p>then you can use <code>pip3</code> to install other packages, otherwise <code>pip</code> is still use <code>python2</code>.</p>
<p>Make <a href="https://askubuntu.com/questions/320996/how-to-make-python-program-command-execute-python-3" target="_blank" rel="noopener">python command execute python3</a>, you can use alias.</p>
<p><a href="https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/" target="_blank" rel="noopener">Installing packages using pip and virtual environments</a></p>
<h1 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1 Introduction"></a>Chapter 1 Introduction</h1><p>Install <code>ipython</code> or <code>ipython3</code>, powerful mixed interactive shell:<br><a href="https://ipython.org/index.html#" target="_blank" rel="noopener">https://ipython.org/index.html#</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install ipython</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">pip3 install ipython</span><br></pre></td></tr></table></figure></p>
<p>then run it as<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ipython</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">ipython3</span><br></pre></td></tr></table></figure></p>
<p>Python variables use dynamic typing. In practice, this means reassigned to values of different types or classes</p>
<h2 id="Built-in-Functions"><a href="#Built-in-Functions" class="headerlink" title="Built-in Functions"></a>Built-in Functions</h2><ul>
<li>print</li>
<li>range<br>Use spaces instead of tabs to indent.</li>
</ul>
<h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><p>functions can be object, can put it in the list.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>functions = [double, triple]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> function <span class="keyword">in</span> functions:</span><br><span class="line"><span class="meta">... </span>    print(function(<span class="number">3</span>))</span><br></pre></td></tr></table></figure></p>
<p>Wrapping Functions with Decorators, there are some other python command line build tools. <a href="https://click.palletsprojects.com" target="_blank" rel="noopener"><code>click</code> package</a>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install click</span><br></pre></td></tr></table></figure></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="string">'''A example of using the click package to develop a command line tool'''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> click</span><br><span class="line"></span><br><span class="line"><span class="meta">@click.command()</span></span><br><span class="line"><span class="meta">@click.argument('name')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">(name)</span>:</span></span><br><span class="line">    <span class="string">'''Say hello to name'''</span>    </span><br><span class="line">    print(<span class="string">f"Hello <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    hello()</span><br></pre></td></tr></table></figure>
<p>call it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python simple_cli.py Sue</span><br><span class="line">Hello Sue</span><br></pre></td></tr></table></figure></p>
<p>lambda function, just like <code>java</code> use lambda to create comparator for priority queue.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">sorted(items, key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<h2 id="RE-package"><a href="#RE-package" class="headerlink" title="RE package"></a>RE package</h2><p>The <code>re</code> module uses <code>\</code> to delineate special character for matching, for example <code>\.</code>, <code>\n</code>, etc. To avoid confusion with regular string escape sequences, <code>raw</code> strings are recommended in defining regular expressions. Raw strings are prepended with a <code>r</code> before the first quotation mark.</p>
<p>Similar as <code>grep</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">re.search(<span class="string">r'Rostam'</span>, cc_list)</span><br><span class="line">re.search(<span class="string">r'Chr[a-z][a-z]'</span>, cc_list)</span><br><span class="line">re.search(<span class="string">r'[A-Za-z]&#123;6&#125;'</span>, cc_list)</span><br><span class="line">re.search(<span class="string">r'[A-Za-z]+@[a-z]+\.[a-z]+'</span>, cc_list)</span><br></pre></td></tr></table></figure></p>
<h2 id="Lazy-Evaluation"><a href="#Lazy-Evaluation" class="headerlink" title="Lazy Evaluation"></a>Lazy Evaluation</h2><p>This will have footprint in memory, generate values as needed, will not take much memory.</p>
<p>Create generator, using <code>()</code> instead of <code>[]</code>(list comprehension)<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">gen_o_nums = (x <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">100</span>))</span><br></pre></td></tr></table></figure></p>
<h2 id="More-IPYTHON-features"><a href="#More-IPYTHON-features" class="headerlink" title="More IPYTHON features"></a>More IPYTHON features</h2><p>Using IPython To Run Unix Shell Commands, add <code>!</code> before command, but sometime does not need (default setting):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">In [2]: !ls -l</span><br></pre></td></tr></table></figure></p>
<p>can assign to a variable:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">In [6]: res = !df -h | head -n 7</span><br><span class="line"></span><br><span class="line"><span class="comment">## list format</span></span><br><span class="line">In [7]: res</span><br><span class="line">Out[7]:</span><br><span class="line">[<span class="string">'Filesystem                 Size  Used Avail Use% Mounted on'</span>,</span><br><span class="line"> <span class="string">'/dev/mapper/rhel-root      241G   73G  169G  31% /'</span>,</span><br><span class="line"> <span class="string">'devtmpfs                   3.9G     0  3.9G   0% /dev'</span>,</span><br><span class="line"> <span class="string">'tmpfs                      3.9G     0  3.9G   0% /dev/shm'</span>,</span><br><span class="line"> <span class="string">'tmpfs                      3.9G  403M  3.5G  11% /run'</span>,</span><br><span class="line"> <span class="string">'tmpfs                      3.9G     0  3.9G   0% /sys/fs/cgroup'</span>,</span><br><span class="line"> <span class="string">'/dev/vda1                 1014M  208M  807M  21% /boot'</span>]</span><br><span class="line"></span><br><span class="line">In [8]: res.grep(<span class="string">"dev"</span>)</span><br><span class="line">Out[8]:</span><br><span class="line">[<span class="string">'/dev/mapper/rhel-root      241G   73G  169G  31% /'</span>,</span><br><span class="line"> <span class="string">'devtmpfs                   3.9G     0  3.9G   0% /dev'</span>,</span><br><span class="line"> <span class="string">'tmpfs                      3.9G     0  3.9G   0% /dev/shm'</span>,</span><br><span class="line"> <span class="string">'/dev/vda1                 1014M  208M  807M  21% /boot'</span>]</span><br></pre></td></tr></table></figure></p>
<p>magic commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## enter bash </span></span><br><span class="line">In [13]: %%bash</span><br><span class="line"><span class="comment">## write into a file</span></span><br><span class="line">In [14]: %%writefile test.sh</span><br></pre></td></tr></table></figure></p>
<p><a href="https://www.quora.com/How-can-I-make-IPython-import-the-aliases-defined-in-my-bash-profile-upon-startup" target="_blank" rel="noopener">Make IPython import shell alias</a><br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line">c = get_config()</span><br><span class="line"><span class="keyword">with</span> open(os.path.expanduser(<span class="string">'~/.bashrc'</span>)) <span class="keyword">as</span> bashrc:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> bashrc:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> line.startswith(<span class="string">'alias'</span>):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        parts = re.match(<span class="string">r'^alias (\w+)=([\'"]?)(.+)\2$'</span>, line.strip())</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> parts:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        source, _, target = parts.groups()</span><br><span class="line">        c.AliasManager.user_aliases.append((source, target))</span><br></pre></td></tr></table></figure></p>
<p>Drop this code in <code>~/.ipython/profile_default/ipython_config.py</code>, just like <code>.bashrc</code> and <code>.vimrc</code>, the configuration file for ipython.</p>
<p>How to import shell functions in <code>.bashrc</code>? Or wirte python function instead.</p>
<h1 id="Chapter-2-Automating-Text-and-Files"><a href="#Chapter-2-Automating-Text-and-Files" class="headerlink" title="Chapter 2 Automating Text and Files"></a>Chapter 2 Automating Text and Files</h1><p>In the DevOps world, you are continually parsing, searching, and changing the text in files, whether it’s searching application logs or propagating configuration files.</p>
<p>read regular file:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## don't need to close explicitly</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"/root/DS/tmp.txt"</span>, <span class="string">"r"</span>) <span class="keyword">as</span> handler:</span><br><span class="line">  data = handler.read()</span><br><span class="line"></span><br><span class="line"><span class="comment">## one char</span></span><br><span class="line">data[<span class="number">0</span>]</span><br><span class="line"><span class="comment">## file size</span></span><br><span class="line">len(data)</span><br></pre></td></tr></table></figure></p>
<p>or use<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## this will parse lines by `\n`</span></span><br><span class="line">data = readlines()</span><br><span class="line"><span class="comment">## i-th line</span></span><br><span class="line">data[i]</span><br></pre></td></tr></table></figure></p>
<p>Different operating systems use different escaped characters to represent line-endings. Unix systems use <code>\n</code> and Windows systems use <code>\r\n</code>. Python converts these to <code>\n</code> when you open a file as text. If you are opening a binary file, such as a jpeg image, you are likely to corrupt the data by this conversion if you open it as text. You can, however, read binary files by appending a <code>b</code> to mode:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">file_path = <span class="string">'bookofdreamsghos00lang.pdf'</span></span><br><span class="line"><span class="keyword">with</span> open(file_path, <span class="string">'rb'</span>) <span class="keyword">as</span> open_file:</span><br><span class="line">  btext = open_file.read()</span><br></pre></td></tr></table></figure></p>
<p>write file:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">content=<span class="string">'''export a=123</span></span><br><span class="line"><span class="string">export b=456</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"/root/DS/.envrc"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> handler:</span><br><span class="line">  handler.write(content)</span><br></pre></td></tr></table></figure></p>
<p>The <code>open</code> function creates the file if it does not already exist and overwrites if it does. if want to append, use <code>a</code> mode instead of <code>w</code>. For binary file use <code>bw</code> or <code>ba</code>.</p>
<h2 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h2><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'xx.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> handler:</span><br><span class="line">  data = json.load(handler)</span><br><span class="line"></span><br><span class="line">json.load() <span class="keyword">is</span> used to load file</span><br><span class="line"><span class="comment">## Deserialize fp (a .read()-supporting text file or binary file containing a JSON document) to a Python object using this conversion table.</span></span><br><span class="line"></span><br><span class="line">json.loads() <span class="keyword">is</span> used to load other object</span><br><span class="line"><span class="comment">##Deserialize s (a str, bytes or bytearray instance containing a JSON document) to a Python object using this conversion table.</span></span><br><span class="line"></span><br><span class="line">pprint</span><br><span class="line">Pretty printing has been turned ON</span><br><span class="line"><span class="comment">## then print data is good</span></span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">print(json.dumps(data, indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">## update</span></span><br><span class="line">data[<span class="string">"workerNodeHosts"</span>][<span class="number">0</span>][<span class="string">"name"</span>] = <span class="string">"localhost"</span></span><br><span class="line"><span class="comment">## write file</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'xx.json'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> handler:</span><br><span class="line">  json.dump(data, handler, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same as load() and loads()</span></span><br><span class="line">json.dump() <span class="keyword">is</span> <span class="keyword">for</span> file</span><br><span class="line">json.dumps() <span class="keyword">is</span> <span class="keyword">for</span> general object</span><br></pre></td></tr></table></figure>
<p>actually you can use data pretty printer:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">pprint.pprint(data)</span><br></pre></td></tr></table></figure></p>
<h2 id="YAML"><a href="#YAML" class="headerlink" title="YAML"></a>YAML</h2><p>The most commonly used library for parsing YAML files in Python is <code>PyYAML</code>. It is not in the Python Standard Library, but you can install it using pip:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">pip install pyyaml</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="comment">## read</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"xx.yml"</span>, <span class="string">"r"</span>) <span class="keyword">as</span> handler: </span><br><span class="line">  data = yaml.safe_load(handler) </span><br><span class="line"></span><br><span class="line"><span class="comment">## python convert data as a dict, so you can edit it</span></span><br><span class="line"></span><br><span class="line">print(yaml.dump(data, indent=<span class="number">2</span>))</span><br><span class="line"><span class="comment">## write</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"xx.yml"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> handler:</span><br><span class="line">  yaml.dump(data, handler, indent=<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="XML"><a href="#XML" class="headerlink" title="XML"></a>XML</h2><p>Historically, many web systems used XML to transport data. One use is for <code>RSS</code> feeds. <code>RSS (Really Simple Syndication)</code> feeds are used to track and notify users of updates to websites. These feeds have been used to track the publication of articles from various sources. RSS uses XML formatted pages. Python offers the xml library for dealing with XML documents. It maps the XML documents hierarchical structure to a tree-like data structure.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line">tree = ET.parse(<span class="string">'/tmp/test.xml'</span>)</span><br><span class="line">root = tree.getroot()</span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> root:</span><br><span class="line">  print(child.tag, child.attrib)</span><br></pre></td></tr></table></figure></p>
<h2 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h2><p>data stored as comma-separated values.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">16</span>]: <span class="keyword">import</span> csv</span><br><span class="line">In [<span class="number">17</span>]: file_path = <span class="string">'/tmp/user.csv'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: <span class="keyword">with</span> open(file_path, newline=<span class="string">''</span>) <span class="keyword">as</span> handler:</span><br><span class="line">    ...:     off_reader = csv.reader(handler, delimiter=<span class="string">','</span>)</span><br><span class="line">    ...:     <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    ...:         print(next(off_reader))</span><br><span class="line">    ..</span><br></pre></td></tr></table></figure></p>
<p><code>pandas</code> packages is mainstay to do data science work.<br>Pandas has many more methods for analyzing and manipulating table like data, and there are many books on its use. You should be aware that it is available if you need to do data analysis.</p>
<h2 id="Search-Text"><a href="#Search-Text" class="headerlink" title="Search Text"></a>Search Text</h2><p>One widely used format is the <code>Common Log Format (CLF)</code>. A variety of log analysis tools can understand this format:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;IP Address&gt; &lt;Client Id&gt; &lt;User Id&gt; &lt;Time&gt; &lt;Request&gt; &lt;Status&gt; &lt;Size&gt;</span><br><span class="line">127.0.0.1 - swills [13/Nov/2019:14:43:30 -0800] &quot;GET /assets/234 HTTP</span><br></pre></td></tr></table></figure></p>
<p>Just give some examples:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">line = <span class="string">'127.0.0.1 - swills [13/Nov/2019:14:43:30 -0800] "GET /assets/234 HTTP/1.0" 200 2326'</span></span><br><span class="line"><span class="comment">## use name groups</span></span><br><span class="line">r = <span class="string">r'(?P&lt;IP&gt;\d+\.\d+\.\d+\.\d+) - (?P&lt;User&gt;\w+) \[(?P&lt;Time&gt;\d\d/\w&#123;3&#125;/\d&#123;4&#125;:\d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125; [-+]\d&#123;4&#125;)\] (?P&lt;Request&gt;".+")'</span></span><br><span class="line">m = re.search(r, line)</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: m.group(<span class="string">'IP'</span>)</span><br><span class="line">Out[<span class="number">11</span>]: <span class="string">'129.0.0.1'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: m.group(<span class="string">'Time'</span>)</span><br><span class="line">Out[<span class="number">12</span>]: <span class="string">'13/Nov/2019:14:43:30 -0800'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: m.group(<span class="string">'User'</span>)</span><br><span class="line">Out[<span class="number">13</span>]: <span class="string">'swills'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: m.group(<span class="string">'Request'</span>)</span><br><span class="line">Out[<span class="number">14</span>]: <span class="string">'"GET /assets/234 HTTP/1.0"'</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: Python automatically allocates and frees memory.The Python garbage collector can be controlled using the <code>gc</code> package, though this is rarely needed.</p>
</blockquote>
<p>For large files. If the files contain data that can be processed one line at a time, the task is easy with Python. You can read one line at a time, process the line, and then move to the next. The lines are removed from memory automatically by Python’s garbage collector, freeing up memory.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">23</span>]: <span class="keyword">with</span> open(<span class="string">'big-data.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> source_file:</span><br><span class="line">    ...:     <span class="keyword">with</span> open(<span class="string">'big-data-corrected.txt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> target_file:</span><br><span class="line">    ...:         <span class="keyword">for</span> line <span class="keyword">in</span> source_file:</span><br><span class="line">    ...:             target_file.write(line)</span><br></pre></td></tr></table></figure>
<h1 id="Chapter-3-Command-Line"><a href="#Chapter-3-Command-Line" class="headerlink" title="Chapter 3 Command Line"></a>Chapter 3 Command Line</h1><p>Python offers tools for interacting with systems and shells. You should become familiar with the <code>sys</code>, <code>os</code>, and <code>subprocess</code> modules, as are all essential tools.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment">## little or big endian</span></span><br><span class="line">sys.byteorder</span><br><span class="line"><span class="comment">## python object size</span></span><br><span class="line">sys.getsizeof(<span class="number">1</span>)</span><br><span class="line"><span class="comment">## platform</span></span><br><span class="line">sys.platform</span><br><span class="line"><span class="comment">## python version</span></span><br><span class="line">sys.version_info.major</span><br><span class="line">sys.version_info.minor</span><br></pre></td></tr></table></figure>
<p>The most common usage of the os module is to get settings from environment variables.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">## pwd and cd</span></span><br><span class="line">os.getcwd()</span><br><span class="line">os.chdir(<span class="string">'/tmp'</span>)</span><br><span class="line"><span class="comment">## get and set env var</span></span><br><span class="line">os.environ.get(<span class="string">'HOME'</span>)</span><br><span class="line">os.environ[<span class="string">'HOME'</span>] = <span class="string">'/tmp'</span></span><br><span class="line"><span class="comment">## login user</span></span><br><span class="line">os.getlogin()</span><br></pre></td></tr></table></figure></p>
<p>With <code>subprocess</code> you can run your favorite shell command or other command line software and collect its output from within Python. For the majority of use-cases, you should use the <code>subprocess.run</code> function to spawn processes<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="comment">## text = True: convert to string</span></span><br><span class="line">sub = subprocess.run([<span class="string">'ls'</span>, <span class="string">'-ltr'</span>], capture_output=<span class="keyword">True</span>, universal_newlines=<span class="keyword">True</span> [,text=<span class="keyword">True</span>, stdout=&lt;file&gt;])</span><br><span class="line">sub.stdout</span><br><span class="line">sub.stderr</span><br><span class="line">print(sub.stdout.decode())</span><br><span class="line"><span class="comment">## exception will be raised when use</span></span><br><span class="line">sub = subprocess.run([<span class="string">'ls'</span>, <span class="string">'/non'</span>], capture_output=<span class="keyword">True</span>, universal_newlines=<span class="keyword">True</span>, check=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="Creating-Command-Line-Tools"><a href="#Creating-Command-Line-Tools" class="headerlink" title="Creating Command Line Tools"></a>Creating Command Line Tools</h2><p>Invoke python script usually by:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python xx.py</span><br></pre></td></tr></table></figure></p>
<p>or you can eliminate python by adding <code>#!/usr/bin/env python</code>(or <code>python3</code>) at first line of the script, then <code>chmod</code> the script to executable:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./xx.py</span><br></pre></td></tr></table></figure></p>
<p>The simplest and most basic way to process arguments from the command line is to use the argv attribute of the <code>sys module</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Simple command line tool using sys.argv</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  <span class="comment">## sys.argv is a list</span></span><br><span class="line">  sys.argv[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> <span class="string">'--help'</span> <span class="keyword">in</span> sys.argv:</span><br><span class="line">    help_message = <span class="string">f"Usage: <span class="subst">&#123;sys.argv[<span class="number">0</span>]&#125;</span> ..."</span></span><br><span class="line">    print(help_message)</span><br><span class="line">    sys.exit()</span><br><span class="line"><span class="comment">## can get index</span></span><br><span class="line">idx = sys.argv.index(<span class="string">'--namespace'</span>)</span><br><span class="line">namespace = sys.argv[idx]</span><br></pre></td></tr></table></figure></p>
<p>This is not enough, we need argument parser! Luckily there are modules and packages designed for the creation of command line tools. These packages provide frameworks to design the user interface for your module when running in a shell. Three popular solutions <code>argparse</code>, <code>click</code>, and <code>fire</code>. All three include ways to design required arguments, optional flags, and means to display help documentation. The first, argparse, is part of the Python standard library, and the other two are third-party packages that need to be installed separately (using pip).</p>
<h3 id="argparse"><a href="#argparse" class="headerlink" title="argparse"></a>argparse</h3><p>这个有专门的tutorial，大概看了一下，it does take much work on your part but you get lots of control.</p>
<p>Automatically generates help and usage messages and issues errors when users give the program invalid arguments.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Command line tool using argparse</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Process some integers.'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'integers'</span>, metavar=<span class="string">'N'</span>, type=int, nargs=<span class="string">'+'</span>,</span><br><span class="line">                    help=<span class="string">'an integer for the accumulator'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## If the name begins with a dash, it is treated as an optional, flag, argument, otherwise as a position-dependent command. </span></span><br><span class="line">parser.add_argument(<span class="string">'--sum'</span>, dest=<span class="string">'accumulate'</span>, action=<span class="string">'store_const'</span>,</span><br><span class="line">                    const=sum, default=max,</span><br><span class="line">                    help=<span class="string">'sum the integers (default: find the max)'</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line">print(args.accumulate(args.integers))</span><br></pre></td></tr></table></figure></p>
<p>You can also define sub-commands, like <code>git stash ...</code>.</p>
<h3 id="click"><a href="#click" class="headerlink" title="click"></a>click</h3><p>It uses Python <code>Function Decorators</code> to bind the command line interface directly with your functions. </p>
<p>Python decorators are a special syntax for functions <strong>take other functions as arguments</strong>. Python functions are objects, so any function can take a function as an argument. The decorator syntax provides a clean and easy way to do this.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Simple Click example</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> click</span><br><span class="line"></span><br><span class="line"><span class="meta">@click.command()</span></span><br><span class="line"><span class="meta">@click.option('--greeting', default='Hiya', help='How do you want to greet?')</span></span><br><span class="line"><span class="meta">@click.option('--name', default='Tammy', help='Who do you want to greet?')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(greeting, name)</span>:</span></span><br><span class="line">    print(<span class="string">f"<span class="subst">&#123;greeting&#125;</span> <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    greet()</span><br></pre></td></tr></table></figure>
<p>Please refer to <a href="https://click.palletsprojects.com/en/7.x/" target="_blank" rel="noopener">click documents</a>.</p>
<h3 id="fire"><a href="#fire" class="headerlink" title="fire"></a>fire</h3><p><a href="https://github.com/google/python-fire" target="_blank" rel="noopener">fire document</a>.</p>
<p>for example:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Simple Fire example</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> fire</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(greeting=<span class="string">'Hiya'</span>, name=<span class="string">'Tammy'</span>)</span>:</span></span><br><span class="line">    print(<span class="string">f"<span class="subst">&#123;greeting&#125;</span> <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">goodbye</span><span class="params">(goodbye=<span class="string">'Bye'</span>, name=<span class="string">'Tammy'</span>)</span>:</span></span><br><span class="line">    print(<span class="string">f"<span class="subst">&#123;goodbye&#125;</span> <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    fire.Fire()</span><br></pre></td></tr></table></figure></p>
<p>An exciting feature of fire is the ability to enter an interactive mode easily. By using the <code>--interactive</code> flag, fire opens an IPython shell with the object and functions of your script available:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">./fire_example.py &lt;command&gt; &lt;args&gt; -- --interactive</span><br></pre></td></tr></table></figure></p>
<p>Overall, We recommend <code>click</code> for most use cases. It balances ease and control. In the case of complex interfaces where you want to separate the UI code from business logic, <code>argparse</code> is the way to go. Moreover, if you need to access code that does not have a command line interface quickly, <code>fire</code> is right for you.</p>
<h2 id="Implementing-plugins"><a href="#Implementing-plugins" class="headerlink" title="Implementing plugins"></a>Implementing plugins</h2><p>Once you’ve implemented your applications command line user interface you might want to consider a plugin system. Plugins are pieces of code supplied by the user of your program to extend functionality. </p>
<p>A key part of any plugin system is plugin discover. Your program needs to know what plugins are available to load and run. Create a file named <code>add_plugins.py</code><br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> fire</span><br><span class="line"><span class="keyword">import</span> pkgutil</span><br><span class="line"><span class="keyword">import</span> importlib</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_and_run_plugins</span><span class="params">(plugin_prefix)</span>:</span></span><br><span class="line">    plugins = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Discover and Load Plugins</span></span><br><span class="line">    print(<span class="string">f"Discovering plugins with prefix: <span class="subst">&#123;plugin_prefix&#125;</span>"</span>)</span><br><span class="line">    <span class="comment"># pkgutil.iter_modules returns all modules available in the current sys.path</span></span><br><span class="line">    <span class="keyword">for</span> _, name, _ <span class="keyword">in</span>  pkgutil.iter_modules():</span><br><span class="line">        <span class="comment"># Check if the module uses our plugin prefix</span></span><br><span class="line">        <span class="keyword">if</span> name.startswith(plugin_prefix):</span><br><span class="line">            <span class="comment"># Use importlib to load the module, saving it in a dict for later use.</span></span><br><span class="line">            module = importlib.import_module(name)</span><br><span class="line">            plugins[name] = module</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run Plugins</span></span><br><span class="line">    <span class="keyword">for</span> name, module <span class="keyword">in</span> plugins.items():</span><br><span class="line">        print(<span class="string">f"Running plugin <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line">        <span class="comment"># Call the run method on the plugin.</span></span><br><span class="line">        module.run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    fire.Fire()</span><br></pre></td></tr></table></figure></p>
<p>then you can wirte modules for example: <code>module1.py</code> and put it in <code>sys.path</code> directory. If you run <code>./add_plugins.py find_and_run_plugins module</code>, then it will search, load and run the <code>module1.py</code> module.</p>
<h2 id="Turbocharging-Python-with-Command-Line-Tools"><a href="#Turbocharging-Python-with-Command-Line-Tools" class="headerlink" title="Turbocharging Python with Command Line Tools"></a>Turbocharging Python with Command Line Tools</h2><p>Here are the raw ingredients that will be used to make several solutions:</p>
<ul>
<li>Click Framework</li>
<li>Python CUDA Framework</li>
<li>Numba Framework</li>
<li>Scikit-learn Machine Learning Framework</li>
</ul>
<p>These are tools to speed up the performance.</p>
<h1 id="Chapter-4-Useful-Linux-Utilities"><a href="#Chapter-4-Useful-Linux-Utilities" class="headerlink" title="Chapter 4 Useful Linux Utilities"></a>Chapter 4 Useful Linux Utilities</h1><p>This chapter will go through some common patterns in the shell and will include some useful Python commands that should enhance the ability to interact with a machine.</p>
<p>As a seasoned performance engineer once said, it depends on what is measured and how.</p>
<h2 id="disk-utility"><a href="#disk-utility" class="headerlink" title="disk utility"></a>disk utility</h2><p>If we had to work in an isolated environment with a server that doesn’t have access to the internet or that we don’t control and therefore can’t install packages, we would have to say that the <code>dd</code> tool can provide help.</p>
<p>This will get thoughput of the new device, for example, the throughput is 1.4GB/s<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dd if=/dev/zero of=&lt;new device&gt; count=10 bs=100M</span><br><span class="line"></span><br><span class="line">10+0 records in</span><br><span class="line">10+0 records out</span><br><span class="line">10506731520 bytes (11 GB) copied, 3.12099 s, 1.4 GB/s</span><br></pre></td></tr></table></figure></p>
<p>how to get IOPS, update every 1 second:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iostat -d &lt;device&gt; 1</span><br></pre></td></tr></table></figure></p>
<p>Other common test tool is <code>fio</code>, you may need to install this package. It can help clarify the performance behavior of a device in a read-heavy or write-heavy environment (and even adjust the percentages of reads vs. writes).</p>
<h2 id="network-utility"><a href="#network-utility" class="headerlink" title="network utility"></a>network utility</h2><ul>
<li>ssh tunneling (ssh port forwarding)</li>
</ul>
<p>For example, the server hello.com can only access by ssh with port 3345 and not exposed,let’s forward hello.com:3345 to a local port in my machine:<br><a href="https://www.youtube.com/watch?v=AtuAdk4MwWw" target="_blank" rel="noopener">https://www.youtube.com/watch?v=AtuAdk4MwWw</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -f -L 12333:hello.com:3345 root@hello.com -N</span><br></pre></td></tr></table></figure></p>
<p><code>-f</code> means run in bachground<br><code>-L</code> is forwarding rule<br><code>-N</code> means don’t get into remote shell<br><a href="mailto:`root@hello.com" target="_blank" rel="noopener">`root@hello.com</a>` is the username and address of that server</p>
<p>This tech can also be used to bypass firewall for some ports. Then we can access localhost:12333 to access the server.<br>疑问：如果port已经被firewall block了，ssh是怎么连接上的呢？</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Practical Vim, 2nd Edition</title>
    <url>/2019/08/06/book-vim/</url>
    <content><![CDATA[<p>看这种书挺枯燥，还是learn by doing 比较好，使用一段时间就很明确自己需要什么功能了。</p>
<blockquote>
<p>By default <code>oc/kubectl edit</code> will use <code>vi</code> in Linux if environment variable <code>OC _EDITOR</code> is empty, if you have <code>.vimrc</code> that is not compatible with <code>vi</code>, will get error message, to use <code>vim</code> set <code>export OC_EDITOR=vim</code> or <code>export KUBE_EDITOR=vim</code>.</p>
</blockquote>
<h1 id="Other-resources"><a href="#Other-resources" class="headerlink" title="Other resources"></a>Other resources</h1><p><a href="https://nvie.com/posts/how-i-boosted-my-vim/" target="_blank" rel="noopener">How I booted my Vim</a><br>Informative!! I grab lots of configurations from it, go and poke around the author’s vimrc file.</p>
<p><a href="http://derekwyatt.org/vim/tutorials/index.html" target="_blank" rel="noopener">Vim Tutorial Videos</a><br>There are a lot, see O`Reilly.</p>
<p>Actually you can learn <code>Vim</code> by running command <code>vimtutor</code> in your terminal, it is a simple and quick tutorial. For a quick review, just see summary after each lesson.</p>
<h1 id="Daily-Foundation"><a href="#Daily-Foundation" class="headerlink" title="Daily Foundation"></a>Daily Foundation</h1><p>掌握好这些操作基本上就满足日常需求了。</p>
<h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h2><p><code>.vimrc</code> is just like <code>.bashrc</code>. you create a <code>.vimrc</code> (even it’s empty) to tell vim use vim not vi-compatiable mode!</p>
<p>关于vimrc的配置，参考my github repo:<br><a href="https://github.com/chengdol/vim-configuration" target="_blank" rel="noopener">https://github.com/chengdol/vim-configuration</a></p>
<ol>
<li>Basic configuration</li>
<li>Custom key mapping</li>
<li>Vimscript plugin</li>
</ol>
<p>About mapping:</p>
<ul>
<li>nmap: normal mode</li>
<li>vmap: visual mode</li>
<li>imap: insert mode</li>
<li>map: normal, visual and operating-pending mode</li>
<li>map!: command and insert mode</li>
</ul>
<p>To list mapping: <code>:map</code> or more specific <code>:vmap</code></p>
<p>Which mode is currently use should be clear:  <code>Normal</code> mode, <code>Insert</code> mode and <code>Visual</code> mode, <code>Command-Line</code> mode, <code>Replace</code> mode, etc. <code>Visual</code> mode lets us select text in the <code>buffer</code> and then operate on the selection.</p>
<p>If you suspect that your customizations are causing interference, here’s a quick test. Try quitting Vim and then launching it with these options:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim -u NONE -N</span><br></pre></td></tr></table></figure></p>
<p>The <code>-u NONE</code> flag tells Vim not to source your <code>vimrc</code> on startup. That way, your customizations won’t be applied and plugins will be disabled. In older versions of Vim, not loading a <code>vimrc</code> file activates <code>vi</code> compatible mode, which causes many useful features to be disabled. The <code>-N</code> flag prevents this by setting the <code>nocompatible</code> option. Since version 8.0 of Vim, the <code>nocompatible</code> option is set by default, making the <code>-N</code> flag unnecessary.</p>
<p><code>vim -N file</code>: <code>-N</code> not using vi compatible mode, use newer vim mode. or can configuring in <code>.vimrc</code> file.</p>
<p><code>:set list</code>, <code>:set nolist</code>, <code>:set list?</code>, <code>:set list&amp;</code>: set, unset, check value, set as default. 以此类推.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set autochdir &quot;auto set current dir as working dir</span><br><span class="line">set wildmode=list:longest &quot;activate TAB auto-complete file path</span><br></pre></td></tr></table></figure></p>
<p><strong>Reload .vimrc</strong><br>Reload .vimrc without restarting vim: <code>:source ~/.vimrc</code>. 已经加入vimrc了。</p>
<h2 id="Plugin"><a href="#Plugin" class="headerlink" title="Plugin"></a>Plugin</h2><p>Vim 8.0 has its own built-in package manager. For Vim version less than 8.0, I use <code>vim-plug</code> as the plugin manager:<br><a href="https://github.com/junegunn/vim-plug" target="_blank" rel="noopener">https://github.com/junegunn/vim-plug</a><br>You can even specify git address of the plugin, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Plug &apos;https://github.com/tfnico/vim-gradle.git&apos;</span><br></pre></td></tr></table></figure></p>
<p>If the plugin does not get auto installed, run <code>:PlugInstall</code>, check the plug status by <code>:PlugStatus</code>. 这些在<code>vim-plug</code> README中都有说明。</p>
<blockquote>
<p>Please see my <a href="https://github.com/chengdol/vim-configuration" target="_blank" rel="noopener">vim-configuration git repo</a>, download the vimrc file.</p>
</blockquote>
<ul>
<li>nerdtree: file system explorer for vim editor</li>
<li>fuzzyfinder: fzf</li>
<li>buffer explorer: 比默认的buffer要好看</li>
<li>taglist: source code browser</li>
</ul>
<p>NERDTree，在目录界面中通过<code>m</code>启动常规文件/文件夹操作。<code>C</code>回车 进入子文件夹。</p>
<h2 id="Display-Management"><a href="#Display-Management" class="headerlink" title="Display Management"></a>Display Management</h2><p>Vim中切换编辑多个文件：<br><code>:cd /tmp</code> change vim working directory<br><code>:pwd</code> show current working directory<br><code>:set hidden</code> (put it in <code>.vimrc</code>): <a href="https://medium.com/usevim/vim-101-set-hidden-f78800142855" target="_blank" rel="noopener">https://medium.com/usevim/vim-101-set-hidden-f78800142855</a><br><code>:e .</code> browse current directory, select file to edit</p>
<p><code>:ls</code> list buffer (open files)</p>
<ul>
<li>%: buffer in current window</li>
<li>+: unsave changes</li>
<li>=: read-only</li>
</ul>
<p><code>:bn</code> go to next buffer<br><code>:bp</code> go to previous buffer<br><code>:bd</code> delete buffer, such as <code>:bd5</code><br><code>:bf</code> go to first buffer<br><code>:bl</code> go to last buffer<br><code>:b3</code> go to 3rd buffer<br><code>gf</code> jump to the file under the cursor, use <code>ctrl+o</code> jump back</p>
<p>可以在vim <code>:e &lt;path&gt;</code> 中直接创建，删除文件或者文件夹，显示long format, sort等</p>
<blockquote>
<p>在使用<code>vim-plug</code>加载插件后，这部分功能失效了, 不过可以使用command mode去做查看。</p>
<ul>
<li>i: long, thin, tree format</li>
<li>s: sort by name, time, file size</li>
<li>r: reverse sort order</li>
<li>gh: hide or unhide dotfiles</li>
<li>d: make a directory</li>
<li>D: delete file or directory</li>
<li>R: rename file or dir</li>
<li>-: go up a directory</li>
</ul>
</blockquote>
<h3 id="windows-amp-splits"><a href="#windows-amp-splits" class="headerlink" title="windows &amp; splits"></a>windows &amp; splits</h3><p>All start with <code>ctrl+w</code>:</p>
<ul>
<li>s: split horizontally </li>
<li>h: move focus left</li>
<li><p>l: move focus right</p>
</li>
<li><p>v: split vertically</p>
</li>
<li>j: move focus down</li>
<li><p>k: move focus up</p>
</li>
<li><p>w: cycle focus</p>
</li>
<li><p>p: focus previous win</p>
</li>
<li><p>c: close win current focus</p>
</li>
<li>o: close all win except current focus</li>
</ul>
<p><code>:h window-resize</code>, check for window resize.</p>
<ul>
<li>+: enlarge windows, <code>5+</code></li>
<li>-: reduce windows, <code>3-</code></li>
</ul>
<h3 id="Tab"><a href="#Tab" class="headerlink" title="Tab"></a>Tab</h3><p>各个文件单独的tab，不用划分window了, 这个部分是放在vimrc中的:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot; Tab mappings</span><br><span class="line">&quot; The default leader key is \</span><br><span class="line">let mapleader=&quot;,&quot;                        &quot; remap leader key to ,</span><br><span class="line">&quot; invoke for example: ,tt</span><br><span class="line">map &lt;leader&gt;tt :tabnew&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;te :tabedit</span><br><span class="line">map &lt;leader&gt;tc :tabclose&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;to :tabonly&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;tn :tabnext&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;tp :tabprevious&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;tf :tabfirst&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;tl :tablast&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;tm :tabmove</span><br></pre></td></tr></table></figure></p>
<p>What is <code>Leader key</code> in Vim?<br><a href="https://stackoverflow.com/questions/1764263/what-is-the-leader-in-a-vimrc-file" target="_blank" rel="noopener">https://stackoverflow.com/questions/1764263/what-is-the-leader-in-a-vimrc-file</a><br>The <code>Leader key</code> is a way of extending the power of VIM’s shortcuts by using sequences of keys to perform a command.</p>
<h2 id="Operation"><a href="#Operation" class="headerlink" title="Operation"></a>Operation</h2><p>Using <code>hjkl</code> (在后续许多命令中都有涉及) or <code>arrow</code> keys to move around, can have number ahead to indicate how many line to move.</p>
<p><code>:q!</code> quit without saving.<br><code>:wq</code> quit with saving, always retouch the timestamp.<br>sometimes using <code>:q!</code> and <code>:wq!</code>: <a href="https://unix.stackexchange.com/questions/88247/use-of-in-vim" target="_blank" rel="noopener">https://unix.stackexchange.com/questions/88247/use-of-in-vim</a></p>
<p><code>:x</code> the same as <code>:wq</code>, but write only when changes have been made.<br><code>:w filename</code> used to save file to <code>filename</code>.<br><code>:w !sudo tee %</code> write to sudo with current file name, <code>%</code> represent current file name. (用在保存更改read-only文件的内容)</p>
<p><a href="https://medium.com/usevim/vim-101-quick-movement-c12889e759e0" target="_blank" rel="noopener">Quick Movement</a><br><code>A</code> append at end of the line, <code>a</code> appends after cursor.<br><code>I</code> insert ata head of the line, <code>i</code> insert at cursor.<br><code>W</code> jump contiguous words, <code>w</code> jump one word.<br><code>o</code> will open a line below cursor, <code>O</code> open above.<br><code>3w</code> move 3 words forward, <code>0</code> move to the start of the line.<br><code>^</code> go to first non-empty char in line<br><code>3fn</code> find 3rd <code>n</code> char at this line. repeat by <code>;</code></p>
<h3 id="Screen-line-movement"><a href="#Screen-line-movement" class="headerlink" title="Screen line movement"></a>Screen line movement</h3><p>screen line指被terminal因宽度限制产生的行，并不是指原始的很长的那一行。<br><code>g0</code>, <code>gm</code>, <code>g$</code>: start, middle, end of a line.<br><code>gk</code>, <code>gj</code>: move up/down in screan line (can use arrow instead k/j ).</p>
<h3 id="Scrolling"><a href="#Scrolling" class="headerlink" title="Scrolling"></a>Scrolling</h3><p>Press <code>G</code> to move you to the bottom of the file.<br>Type <code>gg</code> to move you to the start of the file.<br><code>line number + G</code> or <code>line number + gg</code> will go to the line specified.<br>To go back to where you came from press <code>Ctrl-o</code> (Keep <code>Ctrl</code> down while pressing the letter <code>o</code>). To go forward <code>Ctrl-i</code><br><code>H</code>, <code>M</code> and <code>L</code> move the cursor to top, medium and bottom of current page<br><code>zt</code>, <code>zz</code>, <code>zb</code>: move cursor line to top, middle, bottom of screen</p>
<h3 id="Make-Mark"><a href="#Make-Mark" class="headerlink" title="Make Mark"></a>Make Mark</h3><p>For example, jump back and forth spots:<br><a href="https://www.linux.com/news/vim-tips-moving-around-using-marks-and-jumps/" target="_blank" rel="noopener">https://www.linux.com/news/vim-tips-moving-around-using-marks-and-jumps/</a><br><code>:marks</code></p>
<h3 id="Shift"><a href="#Shift" class="headerlink" title="Shift"></a>Shift</h3><p>Shift configuration is in <code>.vimrc</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot; shift with tab</span><br><span class="line">set tabstop=2                    &quot; Global tab width.</span><br><span class="line">set shiftwidth=2                 &quot; And again, related.</span><br><span class="line">set expandtab                    &quot; Use spaces instead of tabs</span><br><span class="line">&quot; extremely useful to edit yaml file</span><br><span class="line">set autoindent                   &quot; always set autoindenting on</span><br><span class="line">set copyindent                   &quot; copy the previous indentation on autoindentin</span><br></pre></td></tr></table></figure></p>
<p><code>:retab</code>: replace all tabs with spaces in current buffer.</p>
<p><code>&gt;&gt;</code>, <code>&lt;&lt;</code> shift current line, <code>4&gt;&gt;</code>, <code>4&lt;&lt;</code> block shift with 4 lines together.<br>In insert mode, can use tab itself to shift (now override by auto-complete in my vimrc file), or using <code>ctrl+t</code>, <code>ctrl+d</code>: shift right and left.</p>
<p>对于code block indention，我在.vimrc 中设置了vmap, 用visual mode选中后shift就很方便了。</p>
<h3 id="Search-and-Replace"><a href="#Search-and-Replace" class="headerlink" title="Search and Replace"></a>Search and Replace</h3><p><code>/</code> search forward, <code>?</code> search backword. when hit the search, <code>n</code> go forward, <code>N</code> go backword. If the cursor is at search word, use <code>*</code> to search forward, <code>#</code> search back, use <code>g*</code>, <code>g#</code> do partial match search.</p>
<p><code>/case\c</code> search case-insensitive, <code>/CaSe\C</code> search case-sensitive. <code>\c</code> and <code>\C</code> can be anywhere in pattern.</p>
<p><code>:s/old/new/g</code> to substitute <code>old</code> by <code>new</code> in a line for all occrurences. you must place the cursor in that line.<br>To change every occurrence of a character string between two lines,<br><code>:#,#s/old/new/g</code> where <code>#,#</code> are the line numbers of the range of lines where the substitution is to be done.<br><code>:%s/old/new/g</code>  to change every occurrence in the whole file.<br><code>:%s/old/new/gc</code> to find every occurrence in the whole file, with a prompt whether to substitute or not, <code>c</code> is confirmation.</p>
<p>For case-sensitive: <code>:%s/old/new/Igc</code>, but actually can be <code>:%s/old\C/new/gc</code>.</p>
<h3 id="Copy-and-Paste"><a href="#Copy-and-Paste" class="headerlink" title="Copy and Paste"></a>Copy and Paste</h3><p>这里和vim 的 register有关. Default is unnamed register, delete, change, substitute, search and yank all use registers.</p>
<blockquote>
<p>Pasting text into a terminal running Vim with automatic indentation enabled can destroy the indentation of the pasted text: <a href="https://vim.fandom.com/wiki/Toggle_auto-indenting_for_code_paste" target="_blank" rel="noopener">https://vim.fandom.com/wiki/Toggle_auto-indenting_for_code_paste</a>, use <code>vim-bracketed-paste</code> can fix this.</p>
</blockquote>
<p>Show register contents: <code>:registers</code></p>
<p><code>y</code> is copy operator, for example, <code>yw</code> copy one word, <code>y$</code> copy to end of the line and <code>yy</code> used to copy a line, then you can paste through <code>p</code>. you can use <code>v</code> to select and copy. By default it uses unnamed register. Register <code>0</code> always stores the yank content, so you can use <code>&quot;0p</code> to paste.</p>
<p><code>&quot;ayy</code>, <code>&quot;ap</code> use register <code>a</code> to yank and paste. Usually we use <code>a~z</code> and <code>A~Z</code> register, the uppercase register can append text to current content.</p>
<p>使用上不同文件之间copy/paste没啥问题，但如果需要copy到system clipboard，需要设置:<br><a href="https://stackoverflow.com/questions/3961859/how-to-copy-to-clipboard-in-vim" target="_blank" rel="noopener">https://stackoverflow.com/questions/3961859/how-to-copy-to-clipboard-in-vim</a><br>vim has to be compiled with clipboard support for any of the suggestions mentioned here to work. Mine wasn’t configured that way on Mac OS X by default and I had to rebuild vim. Use this the command to find out whether you have it or not:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim --version | grep &apos;clipboard&apos;</span><br></pre></td></tr></table></figure></p>
<p><code>+clipboard</code> means you’re good and the suggestions here will work for you, while <code>-clipboard</code> means you have to recompile and rebuild vim.</p>
<p><code>d</code> is the <strong>delete operator</strong>, use <strong>motion</strong> to specify the action, for example <code>dw</code>, <code>de</code>, <code>d$</code>. Without <code>d</code>, vim just move the cursor: <code>w</code>, <code>e</code>, <code>$</code><br><code>2dw</code> delete 2 words ahead<br><code>4dd</code> delete 4 lines in a row<br>Type <code>p</code> to put previously <code>deleted</code> text after the cursor. for example, you delete a line and replace it in another place</p>
<p><code>v</code> and then you move the cursor to select the text you want, if you want to delete them next, type <code>d</code>, if you want to save the selected text to another file, press <code>:</code>, then type <code>w filename</code>. <code>V</code> is moved linewise.</p>
<h3 id="Folding"><a href="#Folding" class="headerlink" title="Folding"></a>Folding</h3><p>这个非常有用，比如编辑yaml 文件。<br>Fold by syntax or indent (yaml). <code>:sed foldmethod=indent/syntax</code><br><code>zM</code>, <code>zR</code>: fold and unfold all<br><code>zi</code>: toggle fold all<br><code>zc</code>, <code>zo</code>: close, open fold block<br><code>za</code>: toggle fold block<br><code>zk</code>, <code>zj</code>: move fold focus up and down</p>
<p>还可以根据file type去设定, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot; Automatic fold settings for specific files. Uncomment to use.</span><br><span class="line">&quot; autocmd FileType ruby setlocal foldmethod=syntax</span><br><span class="line">&quot; autocmd FileType css  setlocal foldmethod=indent shiftwidth=2 tabstop=2</span><br></pre></td></tr></table></figure></p>
<h3 id="Recording"><a href="#Recording" class="headerlink" title="Recording"></a>Recording</h3><p>暂时没用到，对重复的复杂操作有用。</p>
<h3 id="Block-comment-and-uncomment"><a href="#Block-comment-and-uncomment" class="headerlink" title="Block comment and uncomment"></a>Block comment and uncomment</h3><p><a href="https://stackoverflow.com/questions/1676632/whats-a-quick-way-to-comment-uncomment-lines-in-vim" target="_blank" rel="noopener">quick way to comment and uncomment block of codes</a><br>comment:</p>
<ol>
<li>press <code>Esc</code></li>
<li>hit <code>ctrl+v</code>, enter visual block mode</li>
<li>use arrow keys select the lines, it won’t highlight everthing, it’s ok</li>
<li><code>shift+i</code></li>
<li>insert the text you want, e.g: #, //, %</li>
<li>press <code>Esc</code> twice</li>
</ol>
<p>uncomment:</p>
<ol>
<li>press <code>Esc</code></li>
<li>hit <code>ctrl+v</code>, enter visual block mode</li>
<li>use arrow keys select text you want to delete</li>
<li>press <code>x</code> to delete the text</li>
</ol>
<h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><p>Press <code>u</code> to undo the last commands, <code>U</code> to undo all the changes in a line.<br><code>crtl+r</code> to undo undo.</p>
<p>Type <code>rx</code> to replace the one character at the cursor with  <code>x</code>. <code>R</code> is used to replace more then one chars, type <code>R</code> then get into insert mode.</p>
<p><code>ce</code> deletes the word and places you in Insert mode, so you can type new word, it will replace old ones. <code>c</code> is <strong>change operator</strong>, just like <code>d</code>.<br>比如要更改3个连续的words 在某行中: <code>c3w</code>, then type.</p>
<p><code>Ctrl+g</code> will show cursor location in the file and the file status, also the file name.</p>
<p><code>%</code> is used tp match another part of <code>(, [ or {</code>. This is very useful in debugging a program with unmatched parentheses. 也可以用来match其他block语句，比如if-end。</p>
<p><code>:!&lt;commands&gt;</code> is used to execute external commands, for example <code>:!ls -ltr /tmp</code>. (the same as IPython)</p>
<p><code>:r filename</code> will retrive the file placed under the cursor. you can also read the output of an external command, <code>:r !ls -ltr</code>.</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>Renew Driver License</title>
    <url>/2019/09/19/car-driver-license/</url>
    <content><![CDATA[<p>我的临时驾照过期了快一周了，忘记去renew，新的驾照也没寄过来（也不知道是不是给我办的real ID？？），准备明天去DMV。仔细观察了一下，当时办事人员在我的临时驾照上写了一个Legal Presence号码（916-657-7790），应该是快过期的时候打过去查询进度和催促用的，但是我忘了。。。我印象里以为10月份才过期😌。。。</p>
<p>所以说，明天去了之后有几件事需要确认：</p>
<ol>
<li>继续renew</li>
<li>查询驾照审批进度</li>
<li>再次确认地址</li>
</ol>
<p>保险起见还是带上<a href="https://www.dmv.ca.gov/portal/wcm/connect/2db22455-e270-47a3-819c-d7c7716d5194/List_of_Docs_REALID.pdf?MOD=AJPERES" target="_blank" rel="noopener">必要的材料</a>：<br>护照，I-94，过期驾照，SSN，EAD, H1B。</p>
<p>后续：<br>上次去renew的时候用的是OPT学生身份，但在审批过程中我的身份变成了H1B，不一致导致了pending，这次去更新了一下，所以一定要用最新的身份去办理。</p>
<p>此外，每年renew car sticker也不要忘了，否则超时会被罚款。去DMV可以网上交钱renew然后过一两周就会给你寄过来了。</p>
<p>09/30/2019, 今天收到了新的driver license，居然不是Real ID, 之后还得再去更换，否则2020以后乘机还得带护照了。决定2020之后再去办理了，因为会搬家。记得要2份不同的住址证明，否则不给办。。。</p>
<p>10/18/2019, 过了一个月sticker还是没有收到，去DMV一问才知道地址居然还是以前的，原来car registration的地址和Drive license的地址都要修改。花了22刀现场办了一个，算是了结一件事。</p>
]]></content>
      <categories>
        <category>Car</category>
      </categories>
      <tags>
        <tag>car</tag>
      </tags>
  </entry>
  <entry>
    <title>Car Insurance</title>
    <url>/2020/06/04/car-insurance/</url>
    <content><![CDATA[<p>最近疫情比较严重，在家办公了，大家出行减少，于是上个月保险公司给我退了$11的汽车保费。今年我感觉疫情很难结束，并且wfh将会持续很长一段时间，平时出门也就买个菜，于是想把保险换成更便宜一些的。</p>
<p>我目前的投保的公司是Progressive，之前是Farmers。但我开车一向比较注意，所以从来没出过事故。</p>
<p>这里有篇文章介绍了一下美国汽车保险的情况:<br><a href="https://www.bangli.us/post/3842" target="_blank" rel="noopener">https://www.bangli.us/post/3842</a><br><a href="https://www.guruin.com/guides/car-insurance" target="_blank" rel="noopener">https://www.guruin.com/guides/car-insurance</a><br><a href="https://www.dealmoon.com/guide/773024" target="_blank" rel="noopener">https://www.dealmoon.com/guide/773024</a></p>
<p>去Quote了其他一些保险公司，价格也没有什么变化，有的很便宜，但去掉了很多项目。还是继续用Progressive了。</p>
]]></content>
      <categories>
        <category>Car</category>
      </categories>
      <tags>
        <tag>car</tag>
      </tags>
  </entry>
  <entry>
    <title>汽车的日常</title>
    <url>/2019/10/18/car-repair/</url>
    <content><![CDATA[<p>这篇blog主要记录一下汽车维修和保养方面的总结吧。</p>
<p>来美国的第一辆车是2009 Camry，主要是为了方便平时买菜，图个省心买了辆二手北美神车，到这篇blog创建的时候已经开了快3年，只能说名副其实，已经10年的车了，大毛病一个都没有。目前为止的车况我只能说非常棒，10年的车，接近16万公里，只有一些小部件损耗的更换，丰田，了不起。<br><img src="https://drive.google.com/uc?id=1ff9jmfxgTJhXn5TO8Y1kLf5jl-TjC5RW" alt=""></p>
<p>说实话，10年了，外形真没有过时😃，经济适用，打算还继续使用一段时间🌹。</p>
<p>02/04/2020 100k miles! 纪念一下<br><img src="https://drive.google.com/uc?id=1j9zDS1ZE-dnzIdN8IPTwXIIBmf9uN65c" alt=""></p>
<h2 id="目前遇到的问题："><a href="#目前遇到的问题：" class="headerlink" title="目前遇到的问题："></a>目前遇到的问题：</h2><ol>
<li><p>刹车尾灯<br><img src="https://drive.google.com/uc?id=1tfLBOmP_42bb07in1trmjCXbNxmbDU11" alt=""><br>某次出游发现右边的刹车尾灯不亮了，很好办，网上买一对和车型兼容的尾灯就行了，自己安装非常容易。花费$4.99.</p>
</li>
<li><p>遮阳挡板<br><img src="https://drive.google.com/uc?id=1a8Ocq57jXSBVqjD3h7RYE48J0zi-YRkC" alt=""><br>这个买来的时候就是破损的，我一直没管它，但有时阳光太强这个挡板活动有点问题导致体验不是很好，于是就在网上买了一个自己装上，花费$29.98.</p>
</li>
<li><p>胎压传感器<br>这种传感器的电池寿命一般在5~10年之间，看来这车之前都没换过，不巧被我遇到了。我在亚马逊上一次性买了4个兼容的传感器，准备把四个轮胎上的都换掉。<br><img src="https://drive.google.com/uc?id=1LONYlXCAsOcAX82hj2JQmMqUIKG3LCMw" alt=""></p>
</li>
</ol>
<p>需要注意的是，TPMS胎压传感器需要专业人士和工具更换，要先确认工具能正确的识别它，然后再安装。安装步骤一般是先将轮胎放气，卸载，然后更换。特别要注意传感器需兼容车载电脑。我买的是pre-programmed的产品，315MHz + 433MHz兼容，不过安装后仍需要relearn车载控制器。一定要仔细阅读说明书哦。</p>
<p>我找了Costco Tire Center帮我更换，很不幸，他们的工具无法识别我买的sensor (I doubt)…于是就只能使用他们的sensor了，价格$44.99/个。最后加上labor fee总共花了$252.61。之前我去咨询了其他的auto repair，有的4个要charge $500，呵呵😑。</p>
<p>要注意的是他们会询问车的年份和型号，以及发动机类型（几缸）。然后交钱，给你一个磁性号码牌，放在车顶上，然后你就可以到处闲逛，比如去Costco看看烤鸡，完事后会打电话叫你去取车。</p>
<p>还需要注意的是，随着气温骤降，TPMS warning light may go on，这是因为气温降低，轮胎里的空气收缩导致胎压下降。可以参考这篇文章: <a href="https://www.lesschwab.com/article/tpms-light-coming-on-in-cold-weather-heres-why.html" target="_blank" rel="noopener">https://www.lesschwab.com/article/tpms-light-coming-on-in-cold-weather-heres-why.html</a></p>
<p>可以去gas station去自己打气，最好自己买个tire gauge，Amazon上很多选择，感觉这很必要。<br><a href="https://www.dummies.com/home-garden/car-repair/wheels-tires/how-to-add-air-to-your-tires/" target="_blank" rel="noopener">https://www.dummies.com/home-garden/car-repair/wheels-tires/how-to-add-air-to-your-tires/</a><br>我仔细研究了一下Amazon上售卖的tire gauge with inflation and deflation，感觉一般般呀，特别是便携12DV车充的，看差评可能会烧保险丝。。。 最后就没买😂，不过可以考虑入手一个机械式测压的。</p>
<p>我直接去了costco，在 <a href="https://www.costcotireappointments.com" target="_blank" rel="noopener">https://www.costcotireappointments.com</a> 上进行预约即可。或者早上早点去直接听到garage门口让工作人员帮忙补补气即可，打气后一般过一会就正常了。</p>
<h2 id="车辆正常保养维护"><a href="#车辆正常保养维护" class="headerlink" title="车辆正常保养维护"></a>车辆正常保养维护</h2><p>又到了该保养的时候了，maintenance light blinks everyday! 为了做到心里有数，pre-research is a must! 最该看的，其实就是car manual了，每个车都会有的，里面会告诉你一些基本的使用和保养常识，当然了，很多人也不关心这个，反正交给4S店或者其他auto repair去做了。</p>
<p>就拿我的车来说吧，5k miles左右会做一个保养，我一般会做的项目包括:</p>
<ol>
<li>change engine oil (must)</li>
<li>change engine oil filter (must)</li>
<li>tire check, brake pads check</li>
<li>battery get tested</li>
<li>change engine air filter (depends, but should)</li>
<li>change cabin air filter (recommand)</li>
<li>washer fluid</li>
</ol>
<p>机油不说了，保养主要就是换机油，有的auto repair如果你不说，他不会给你换机油过滤器的。。。但最好换了。轮胎检查一下，特别是spare，没气了打气，否则爆胎了你拿啥顶上？刹车片看看需不需要更换。</p>
<p>电池看看是否正常，电压测测，现代车辆都是车载电脑操控，需要一个稳定输出的电池。</p>
<p>引擎滤网需要更换，我这几次观察了一下，如果汽车的使用环境比较好，污染物少，用了10k miles的滤网还算干净，但还是换了，很简单的操作. 车厢空气滤网，这个很容易脏，建议更换。更换engine air filter非常简单，工具只需要Ratchet Socket Wrench and Sockets, 注意socket的直径匹配就行:<br><img src="https://drive.google.com/uc?id=1T15bCJjRchNlHtuKXpvJGueovD54g0wl" alt=""><br>其他相关工具的如下:<br><img src="https://drive.google.com/uc?id=1fooPl36_amOsChHWWDYKEPydzg37EMjL" alt=""></p>
<p>雨刮水不够了，自己加满，但最好不要用tap water，网上有很多去污剂可以考虑混合一下，如果在零下的环境中使用，还需要加防冻剂。我买的是QWIX windshield washer fluid, 1/4 oz makes one gallon windshield washer fluid.</p>
<p>100k miles保养，还需要考虑:</p>
<ol>
<li>coolant</li>
<li>power steering fluid</li>
<li>transmission fluid</li>
<li>brake fluid</li>
<li>change spark plugin</li>
<li>tire rotate</li>
</ol>
<p>这些项目都有自己的更换周期，特别是那几个fluid。取决于你车的具体情况。<br>所有这些保养，经过研究，都可以自己完成😃，就是要自己买工具。这个以后准备妥当了再更新一下。</p>
<p>这次保养，我除了change engine oil (filter), spark-plugin, 检查rear brake pads磨损殆尽，也和brake fluid一起更新了，花费$420 (＃￣～￣＃)~ Coolant 和 power steering fluid 没有更换，说没什么必要，人工费也挺贵的。其实我觉得brake change去costco或许会便宜很多，但当时嫌麻烦就没去问，下次就注意了。</p>
]]></content>
      <categories>
        <category>Car</category>
      </categories>
      <tags>
        <tag>car</tag>
      </tags>
  </entry>
  <entry>
    <title>Car Registration Renewal</title>
    <url>/2020/09/13/car-registration-renewal/</url>
    <content><![CDATA[<p>前几天收到了vehicle registration renewal的通知，这次需要做smog check (对于比较老的非电动车辆，一般2年一次), 在google map上选择了一家评分较好又比较近的smog check station, 要知道美国这边smog check都是私人承包的，可以大概在评论中看一下价格如何，此外记得携带DMV的通知单去现场。</p>
<p>一共花了50刀，smog check做完之后你不需要做其他任何事情，只需要到网上缴付Renewal fee即可，但不要做完立即支付，因为DMV那里还没有收到你的smog check记录 (如果你去支付的页面，会发现有一个警告如此)。一般等待一天左右警告会消失，说明DMV已经收到记录，这时就可以进行支付了。</p>
<blockquote>
<p>Aside: 上次遇到过sticker被寄到了之前的地址的情况，所以在搬家renew驾照的时候一定要记得提醒更改renewal的地址。</p>
</blockquote>
]]></content>
      <categories>
        <category>Car</category>
      </categories>
      <tags>
        <tag>car</tag>
      </tags>
  </entry>
  <entry>
    <title>AWS Cloud</title>
    <url>/2020/07/17/cloud-aws/</url>
    <content><![CDATA[<p>//TODO:</p>
<ul>
<li><a href="https://app.pluralsight.com/course-player?clipId=8ada28fb-a440-477a-af89-84b1eceb5440" target="_blank" rel="noopener">https://app.pluralsight.com/course-player?clipId=8ada28fb-a440-477a-af89-84b1eceb5440</a></li>
</ul>
<p>From Pluralsight: <code>AWS Certified Developer – Associate (DVA-C01)</code></p>
<p>别人提到的:</p>
<ol>
<li>工作中经常用到， 需要花时间学习理解的: vpc, subset, security group, eni, route53, acm, IAM</li>
<li>其次: load balancer, auto scaling, ddb throttle, api gateway。</li>
<li>其他: lambda, step function, cloudformation, s3, ec2, sqs, sns, cloudwatch, ecs, ecr, code deploy 等等</li>
</ol>
<h1 id="Core-Services"><a href="#Core-Services" class="headerlink" title="Core Services"></a>Core Services</h1><p><code>EC2</code>: Elastic Cloud Compute<br><code>AMI</code>: Amazon Machine Image<br><code>EBS</code>: Elastic Block Storage, used for EC2 files systems<br><code>Security Group</code>: set of firewall rules that control the traffic for your <strong>single</strong> instance, for example, control who can ssh to EC2 instance, <code>VPC</code> is for <strong>groups</strong> of instance</p>
<p><code>S3</code>: Simple Storage Service, maxmium file size is 5T, bucket is accessed via URL, the same as gcloud storage. Can be used for hosting static web site.</p>
<p><code>RDS</code>: Relation Database Service<br><code>Route53</code>: Domain Name System (DNS) servics, you can register your domain name!</p>
<h2 id="EC2"><a href="#EC2" class="headerlink" title="EC2"></a>EC2</h2><h1 id="Enhancing-Services"><a href="#Enhancing-Services" class="headerlink" title="Enhancing Services"></a>Enhancing Services</h1><p><code>EB</code>: Elastic Beanstalk, application service running on EC2</p>
<p><code>Lambda</code>: Serverless option for executing code, function as a service, only pay when the code is running, significant cost savings if you have infrequent activity. Great for small, irregular tasks, for example, nightly ETL kickoffs, notification type functions</p>
<p><code>DynamoDB</code>: a managed NoSQL database, supports both key-values and document models</p>
<p><code>VPC</code>: for securing your services, components in the VPC can connect each through private IP. Multiple <code>subnets</code> can be in VPC, for example, you can configure public subnet and private subnet.</p>
<p>How does <code>VPC</code> work? </p>
<ul>
<li>route table: control what goes where</li>
<li>network ACL(access control list): act as subnet-level firewalls, control who can come and go </li>
</ul>
<p><code>CloudWatch</code>: monitoring resources and acting on alerts, for example, CPU usage on EC2 instances, DynamoDB read/write throughput, estimated billing charges</p>
<p><code>CloudFront</code>: super fast CDN, works seamlessly with S3, EC2, load balancing and route53</p>
<h2 id="CloudWatch"><a href="#CloudWatch" class="headerlink" title="CloudWatch"></a>CloudWatch</h2><p>For example, Increasing network traffic -&gt; EC2 -&gt; alarm CloudWatch -&gt; action -&gt; Auto Scaling Group -&gt; EC2. <code>SNS</code> can also be integrated to CloudWatch.</p>
<p><code>SNS</code>: simple notification service, Pub/sub messaging for microservices and serverless applications. First create <code>topic</code>, then subscribe this with from email or SMS, etc</p>
<h2 id="IAM"><a href="#IAM" class="headerlink" title="IAM"></a>IAM</h2><p><code>MFA</code>, multi-factor authentication, reuqire more than one factor to authenticate.<br>MFA process: password + device code (app generated code refresh every 60 seconds) 类似将军令, 要先在手机上下载一个MFA app.</p>
<p>After loging aws console, click the account user name -&gt; My security credentials -&gt; MFA</p>
<p>IAM <strong>policy</strong> make it easy to assign permissions to users or groups in an administrative way. Users have no permission by default. Policy properties:</p>
<ul>
<li>Effect: allow, deny</li>
<li>Action: operations user can perform</li>
<li>Resources: user performs on</li>
</ul>
<p>Root account permission is dangerious, follows amazon suggested best practices to have more securities. For example, create a admin grouo, attch policy to it, then add user to this group, use this user to login.</p>
<h1 id="Access-AWS"><a href="#Access-AWS" class="headerlink" title="Access AWS"></a>Access AWS</h1><ul>
<li>Web console</li>
<li>SDK, programming application uses: <a href="https://github.com/aws" target="_blank" rel="noopener">https://github.com/aws</a></li>
<li>Command line, great for shell scripting: <a href="https://github.com/aws/aws-cli" target="_blank" rel="noopener">https://github.com/aws/aws-cli</a></li>
</ul>
<p>To generate the access key for SDK and cli, after loging aws console, click the account user name -&gt; My security credentials -&gt; Access Keys.</p>
<p>Create <code>~/.aws/credentials</code> file with content from your access key:<br><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[default]</span></span><br><span class="line"><span class="attr">aws_access_key_id</span>=AKIAIVHU6XLsd3J7IAKA</span><br><span class="line"><span class="attr">aws_secret_access_key</span>=Vemdu3nD65uY1cWC0fznCEfUhvsUT9NIjMT790zqK</span><br><span class="line"><span class="attr">region</span>=us-west-<span class="number">2</span></span><br><span class="line"><span class="attr">output</span>=json</span><br></pre></td></tr></table></figure></p>
<p>I use aws cli docker to run the commands, the docker container is ephemeral for each command (for convenience, set alias for docker run command), you need to mount the <code>~/.aws</code> to container:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --rm -ti -v ~/.aws:/root/.aws amazon/aws-cli s3 ls</span><br></pre></td></tr></table></figure></p>
<p>For other methods installing</p>
<ul>
<li><a href="https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html</a></li>
</ul>
<p>To aviod installing dependencies, you can use virtual machine to setup environment.</p>
<h1 id="Demo-Components"><a href="#Demo-Components" class="headerlink" title="Demo Components"></a>Demo Components</h1><p>A pizza web site:</p>
<ul>
<li>EC2, host web application</li>
<li>DynamoDB, store users &amp; toppings</li>
<li>RDS, store pizza</li>
<li>S3, store images &amp; assets</li>
<li>ElastiCache, store sessions</li>
</ul>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>aws</tag>
        <tag>cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Azure Cloud</title>
    <url>/2020/07/17/cloud-azure/</url>
    <content><![CDATA[<p>//TODO<br>[ ] custom azure container: vim, zsh or startship, auto completion<br>[ ] Azure subscription and tenant IDs? In ~/.azure/credentials</p>
<h1 id="Setup-Azure-CLI"><a href="#Setup-Azure-CLI" class="headerlink" title="Setup Azure CLI"></a>Setup Azure CLI</h1><p>Using docker azure CLI container:<br><a href="https://docs.microsoft.com/en-us/cli/azure/run-azure-cli-docker" target="_blank" rel="noopener">https://docs.microsoft.com/en-us/cli/azure/run-azure-cli-docker</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull mcr.microsoft.com/azure-cli</span><br><span class="line"></span><br><span class="line">docker run -d \</span><br><span class="line">--name azure \</span><br><span class="line">--entrypoint=/bin/bash \</span><br><span class="line">mcr.microsoft.com/azure-cli:latest \</span><br><span class="line">-c <span class="string">"tail -f /dev/null"</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Commands"><a href="#Commands" class="headerlink" title="Commands"></a>Commands</h2><p>To access a aks cluster:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># similar to company in gcp</span></span><br><span class="line"><span class="comment"># list subscriptions</span></span><br><span class="line">az account list --output table</span><br><span class="line"></span><br><span class="line"><span class="comment"># set subscription</span></span><br><span class="line"><span class="comment"># you can see subscription from akz record</span></span><br><span class="line">az account <span class="built_in">set</span> -s <span class="string">"SUBSCRIPTION NAME"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># group, similar to project in gcp</span></span><br><span class="line"><span class="comment"># you can see group from akz record</span></span><br><span class="line"><span class="comment"># config default group</span></span><br><span class="line">az configure --defaults group=&lt;resource group name&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## or direct get zks credential by</span></span><br><span class="line">az aks get-credentials -n &lt;cluster name&gt; -g &lt;group name&gt; --subscription</span><br></pre></td></tr></table></figure></p>
<p>The command reference links:</p>
<ul>
<li><a href="https://docs.microsoft.com/en-us/cli/azure/account?view=azure-cli-latest" target="_blank" rel="noopener">subscription</a></li>
<li><a href="https://docs.microsoft.com/en-us/cli/azure/group?view=azure-cli-latest" target="_blank" rel="noopener">resource group</a></li>
<li><a href="https://docs.microsoft.com/en-us/cli/azure/aks?view=azure-cli-latest" target="_blank" rel="noopener">aks</a></li>
</ul>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>cloud</tag>
        <tag>azure</tag>
      </tags>
  </entry>
  <entry>
    <title>Cloud Init Quick Start</title>
    <url>/2020/12/21/cloud-init/</url>
    <content><![CDATA[<p>当时的项目用到了cloud-init 替代ansible的操作，在boot后进行本机系统的配置，加速到达可用状态。<br>各大云厂商都支持cloud-init, cloud-init可以通过传递一个<code>cloud-init.tpl</code> metadata file to Terraform instance resource <code>metadate</code>中的 <code>user-data</code> 进行设置. 这样在instance 启动时，就会自动配置了。</p>
<p>要点就是如何写这个<code>cloud-init.tpl</code> metadata file了。</p>
<h1 id="Cloud-init"><a href="#Cloud-init" class="headerlink" title="Cloud-init"></a>Cloud-init</h1><p><a href="https://cloudinit.readthedocs.io/en/latest/" target="_blank" rel="noopener">cloud-init</a> official document, <a href="https://cloudinit.readthedocs.io/en/latest/topics/examples.html" target="_blank" rel="noopener">User data</a> config example.</p>
<p>在构造user的password的时候，需要一个hash的数值:<br><a href="https://ma.ttias.be/how-to-generate-a-passwd-password-hash-via-the-command-line-on-linux/" target="_blank" rel="noopener">openssl passwd</a><br><a href="https://unix.stackexchange.com/questions/510990/why-is-the-output-of-openssl-passwd-different-each-time" target="_blank" rel="noopener">Why is the output of “openssl passwd” different each time?</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -1: MD5</span></span><br><span class="line">openssl passwd -l</span><br><span class="line"><span class="comment"># -salt: add salt</span></span><br><span class="line">openssl passwd -1 -salt yoursalt</span><br><span class="line"><span class="comment"># from stdin</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'admin'</span> | openssl passwd -1 -stdin -salt yoursalt</span><br></pre></td></tr></table></figure></p>
<p><a href="https://stackoverflow.com/questions/46173003/bootstrap-server-vs-zookeeper-in-kafka" target="_blank" rel="noopener">kafka command bootstrap-server vs zookeeper</a></p>
<p>jinja2 template:<br><a href="https://stackoverflow.com/questions/11974318/how-to-output-a-comma-delimited-list-in-jinja-python-template" target="_blank" rel="noopener">https://stackoverflow.com/questions/11974318/how-to-output-a-comma-delimited-list-in-jinja-python-template</a><br><a href="https://stackoverflow.com/questions/60137669/using-a-dynamic-group-name-in-an-ansible-template" target="_blank" rel="noopener">https://stackoverflow.com/questions/60137669/using-a-dynamic-group-name-in-an-ansible-template</a></p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cloud init</tag>
      </tags>
  </entry>
  <entry>
    <title>Google Cloud</title>
    <url>/2020/07/10/cloud-gcp/</url>
    <content><![CDATA[<p>From PluralSight Google Cloud path.<br>下载的配套slides 讲得很详细，可以参考，特别是讲解了如何选择资源组合, 每个课时中有Quick Labs.</p>
<h1 id="Commands"><a href="#Commands" class="headerlink" title="Commands"></a>Commands</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## after install gcloud SDK</span></span><br><span class="line"><span class="comment">## init</span></span><br><span class="line">gcloud init --console-only</span><br><span class="line"></span><br><span class="line"><span class="comment">## can login multiple accounts</span></span><br><span class="line">gcloud auth login</span><br><span class="line"><span class="comment">## authorize access to Google Cloud Platform with a service account</span></span><br><span class="line"><span class="comment">## recommended way to login</span></span><br><span class="line">gcloud auth activate-service-account</span><br><span class="line"></span><br><span class="line"><span class="comment">## list auth accounts or service account</span></span><br><span class="line">gcloud auth list</span><br><span class="line"><span class="comment">## switch account</span></span><br><span class="line">gcloud config <span class="built_in">set</span> account &lt;account name&gt;</span><br><span class="line"><span class="comment">## revoke account</span></span><br><span class="line">gcloud auth revoke &lt;account name&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## show and install components, i.e alpha, beta, kubectl...</span></span><br><span class="line">gcloud components list</span><br><span class="line">gcloud components install [beta]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## all projects under my account, not the used one</span></span><br><span class="line">gcloud projects list </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## set which project to use</span></span><br><span class="line">gcloud config <span class="built_in">set</span> project &lt;project name&gt;</span><br><span class="line"><span class="comment">## current project in use</span></span><br><span class="line">gcloud config list project</span><br><span class="line"><span class="comment">## get project ID</span></span><br><span class="line">gcloud config get-value project</span><br><span class="line"></span><br><span class="line"><span class="comment">## list service account in project</span></span><br><span class="line">gcloud iam service-accounts list [--project &lt;project ID&gt;]</span><br><span class="line"><span class="comment">## create service-account after auth login and set project</span></span><br><span class="line">gcloud iam service-accounts create &lt;SA name&gt;  [--display-name=&lt;<span class="string">"description"</span>&gt;] [--project &lt;project id&gt;]</span><br><span class="line"><span class="comment">## can update display name and description</span></span><br><span class="line">gcloud iam service-accounts update ...</span><br><span class="line"><span class="comment">## disable service account</span></span><br><span class="line">gcloud iam service-accounts <span class="built_in">enable</span>/<span class="built_in">disable</span> ... </span><br><span class="line"><span class="comment">## delete: When a service account is deleted, its role bindings </span></span><br><span class="line"><span class="comment">## are not immediately removed; they are automatically purged from </span></span><br><span class="line"><span class="comment">## the system after a maximum of 60 days.</span></span><br><span class="line">gcloud iam service-accounts delete ... </span><br><span class="line"><span class="comment">## generate credentials json file for terrform</span></span><br><span class="line"><span class="comment">## can also delete it</span></span><br><span class="line">gcloud iam service-accounts keys create ~/key.json \</span><br><span class="line">  --iam-account &lt;SA name&gt;@&lt;project ID&gt;.iam.gserviceaccount.com</span><br><span class="line"><span class="comment">## see the roles bind to service account</span></span><br><span class="line">gcloud iam service-accounts get-iam-policy &lt;SA&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## see available context</span></span><br><span class="line"><span class="comment">## -o name: show context name</span></span><br><span class="line">kubectl config get-contexts [-o name]</span><br><span class="line"><span class="comment">## switch context</span></span><br><span class="line">kubectl config use-context &lt;context name&gt;</span><br><span class="line"><span class="comment">## rename context to human readable</span></span><br><span class="line">kubectl config rename-context &lt;old&gt; &lt;new&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## export current configuration to yaml file</span></span><br><span class="line">kubectl config view --minify --flatten &gt; cluster.yaml</span><br><span class="line"><span class="comment">## the same as this gcloud command</span></span><br><span class="line"><span class="comment">## KUBECONFIG=clusters.yaml: specify cluster.yaml to store the credentials</span></span><br><span class="line">KUBECONFIG=clusters.yaml gcloud container clusters \</span><br><span class="line">get-credentials &lt;cluster name&gt; --zone=&lt;cluster zone&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## current enabled API list</span></span><br><span class="line">gcloud services list [--porject &lt;project ID&gt;]</span><br><span class="line">gcloud services <span class="built_in">enable</span> &lt;API&gt;</span><br><span class="line">gcloud services <span class="built_in">disable</span> &lt;API&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## create default VPC network</span></span><br><span class="line">gcloud compute networks create default</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## create K8s cluster in default network</span></span><br><span class="line">gcloud container clusters create gke-eu --zone europe-west1-c \</span><br><span class="line">  --release-channel stable --<span class="built_in">enable</span>-ip-alias</span><br><span class="line"><span class="comment">## list cluster</span></span><br><span class="line">gcloud container clusters list</span><br><span class="line">gcloud container clusters list \</span><br><span class="line">  --project &lt;project name&gt; \</span><br><span class="line">  --filter <span class="string">"name:cluster-name"</span> \</span><br><span class="line">  --format <span class="string">"get(location)"</span></span><br><span class="line"><span class="comment">## describe</span></span><br><span class="line">gcloud container clusters describe &lt;cluster name&gt; --region &lt;region/zone&gt;</span><br><span class="line"><span class="comment">## delete cluster</span></span><br><span class="line"><span class="comment">## -q: quiet</span></span><br><span class="line">gcloud container clusters delete gke-eu --zone=europe-west1-cd [-q]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## grant IAM roles to end user in project</span></span><br><span class="line"><span class="comment">## member can be serviceAccount:email</span></span><br><span class="line">gcloud projects add-iam-policy-binding &lt;project ID&gt; \</span><br><span class="line"> --member user:&lt;member&gt; \</span><br><span class="line"> --role=roles/gkehub.admin \</span><br><span class="line"> --role=roles/resourcemanager.projectIamAdmin</span><br></pre></td></tr></table></figure>
<h1 id="Terms"><a href="#Terms" class="headerlink" title="Terms"></a>Terms</h1><p>Cloud SDK commands:</p>
<ul>
<li>gcloud</li>
<li>kubectl</li>
<li>gsutil (google storage)</li>
<li>bq (big query)</li>
</ul>
<p>Cloud shell is acutally running on a ephemeral compute engine instance. 其实command line 操作创建各种资源 比UI 更方便 (这也是Terraform的基础)</p>
<p><code>Zone</code> is under <code>Region</code>, you can think of a zone as data center in a region.</p>
<p><code>Anthos</code> is google’s morden solution for hybird and multi-cloud systems and services management. (下面一章会专门总结一下)</p>
<p><code>GCP cloud functions</code>: serverless execution environment for building and connecting cloud services. With Cloud Functions you write simple, single-purpose functions that are attached to events emitted from your cloud infrastructure and services. Your Cloud Function is triggered when an event being watched is fired. Your code executes in a fully managed environment. There is no need to provision any infrastructure or worry about managing any servers.</p>
<p><code>GCP deployment manager</code>: like <code>Terraform</code>, infrastructure as code.</p>
<p><code>GCP Dataproc</code> for running Apache Spark and Apache Hadoop clusters.<br><code>GCP Dataflows</code> offers managed data pipelines, serverless fully managed data processing.<br><code>GCP Dataprep</code> visually explore, clean and prepare data for analysis and machine learning.</p>
<p><code>BigQuery</code> is fully managed data warehouse.<br><code>Pub/Sub</code> (publisher/subscriber) is scalable, reliable messaging.<br><code>DataLab</code> offers interactive data exploration. Build on Jupyter.</p>
<h1 id="Kubernetes-Architecting"><a href="#Kubernetes-Architecting" class="headerlink" title="Kubernetes Architecting"></a>Kubernetes Architecting</h1><p>Build on top of compute engine.<br>Container is isolated in user space to running application code, lightweight, represent as a process:</p>
<ul>
<li>process</li>
<li>linux namespace</li>
<li>cgroups</li>
<li>nuion file systems</li>
</ul>
<p>GKE abstracts away the master, only show the worker nodes on dashboard.<br>Use <code>Node Pool</code> to manage different kinds of nodes.<br>Google maintains a container registry: <code>gcr.io</code><br><code>Cloud Run</code>: build on <code>Knative</code>, for serverless workloads.</p>
<p><code>Cloud Build</code>: Build, test, and deploy on serverless CI/CD platform.</p>
<p><code>Private Cluster</code>, google products and authorized networks can access.</p>
<h1 id="Fundations"><a href="#Fundations" class="headerlink" title="Fundations"></a>Fundations</h1><p><code>Compute Engine</code> let you run virtual machine. In GCP, K8s nodes are actually virtual machine running in Compute Engine, just like IBM Fyre, you can see them in Compute Engine dashboard.</p>
<ul>
<li>Fully customized virtual machines</li>
<li>Persistent disk/SSD or optional local SSDs</li>
<li>Global load balancing and autoscaling</li>
<li>Per-second billing</li>
</ul>
<p>VM has built-in SDK commands.<br>A <code>vCPU</code> is equal to 1 hardware hyper-thread.</p>
<p><code>Preemptible VM</code>: can be terminated by GCP if the resources is needed in other places.<br>Cloud storage is binary large-object storage. 不同的storage针对不同的对象.</p>
<p><code>VPC</code>: virtual private cloud, VPC is global scope, subnet is regional, can have different zone on the same subnet. Each VPC network is contained in a GCP project. VPC make componets connect to each other or isolated from each other.</p>
<p>You control the VPC network, use its <code>route table</code> to forward traffic within network, even across subnets.</p>
<p><code>VPC</code>: 3 types:</p>
<ul>
<li>default mode </li>
<li>auto mode</li>
<li>custom mode (for production)</li>
</ul>
<p><code>VPN</code> can connect the on-premises network to GCP network.</p>
<p>VMs can be on the same subnet but different zones. Every subnet has four reserved IP addresses in its primary IP range: <code>.0</code> for subnet network itself, <code>.1</code> for subnet gateway, second-to-last address in the range and the last address.</p>
<p>The external IP is transparent to VM, managed by VPC. You will not see it by <code>ip a s</code> command.<br>In <code>/etc/hosts</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">10.128.0.2 instance-1.us-central1-a.c.terraform-k8s-282804.internal instance-1  <span class="comment"># Added by Google</span></span><br><span class="line"><span class="comment">## internal DNS reslover</span></span><br><span class="line">169.254.169.254 metadata.google.internal  <span class="comment"># Added by Google</span></span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nslookup instance-1</span><br><span class="line"></span><br><span class="line">Server:         169.254.169.254</span><br><span class="line">Address:        169.254.169.254<span class="comment">#53</span></span><br><span class="line"></span><br><span class="line">Non-authoritative answer:</span><br><span class="line">Name:   instance-1.us-central1-a.c.terraform-k8s-282804.internal</span><br><span class="line">Address: 10.128.0.2</span><br></pre></td></tr></table></figure></p>
<p>Setup VPC peering or VPN to allow internal network connection between VPCs.</p>
<p>You can delete the whole default network setting, and create your own, for example, auto or custom mode network.</p>
<p><code>Private google access</code> (for example to access cloud storage) and <code>Cloud NAT</code> (only outbound is allowed) help VM without external IP to access internet.</p>
<p><code>RAM Disk</code>: tmpfs, fast scratch disk or cache, faster then disk but slower then memory.</p>
<p>VM comes with a single root persistent disk, can attach additional disk to VM, it is network storage! The extended disk needs to be formated and mounted by yourself, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo mkfs.ext4 -F -E lazy_itable_init=0 \</span><br><span class="line">                     lazy_journal_init=0,discard \</span><br><span class="line">                     /dev/disk/by_id/&lt;disk name&gt;</span><br><span class="line"></span><br><span class="line">sudo mount -o discard,defaults /dev/disk/by_id/&lt;disk name&gt; /home/&lt;target directory&gt;</span><br></pre></td></tr></table></figure></p>
<p><code>App engine</code> is not like Compute engine, it does not comprise of virtual machines, instead get access a family of services that application needs. Container(K8s, hybird) is in the middle of Compute engine (IssA) and App engine (PaaS). You don’t want to focus on the infrastructure at all, just want to focus on your application code. Especially suited for for building scalable web application/web site and mobile backends, RESTful API.</p>
<p>App engine flexible environment is rely on container running in virtual machine in compute engine.</p>
<h1 id="Core-Services"><a href="#Core-Services" class="headerlink" title="Core Services"></a>Core Services</h1><h2 id="IAM"><a href="#IAM" class="headerlink" title="IAM"></a>IAM</h2><p>除了GCP, 其他public cloud也采取同样的RBAC策略。</p>
<p>忘了就多看几遍: <a href="https://app.pluralsight.com/library/courses/google-cloud-platform-iam-regulating-resource/table-of-contents" target="_blank" rel="noopener">Regulating Resource Usage Using Google Cloud IAM</a></p>
<p>首先理解<code>RBAC</code>，在很多场合都有应用: 分为3个部分: identity, roles and resources. Identity 可以是google account, google group and service account(not human). Role 有几种分类，比如primitive role, predefined role, custom role.</p>
<p><code>IAM</code>: identity and access management, who can do what on which resources. user of IAM can be person, group and application. Always select the least privilege to reduce the exposure to risk.</p>
<p>IAM add new member中 GCP 和 G suite  是共享用户(human)信息的。</p>
<p>Identities:</p>
<ul>
<li>google accounts</li>
<li>service accounts, beloings to your applications</li>
<li>google groups (collection of google accounts and service accounts)</li>
<li>G suite domains</li>
<li>Cloud identity domains</li>
</ul>
<p><code>Service Account</code>: used by application or virtual machine running code on your behalf, can have IAM policies attach to it:</p>
<ul>
<li>user-managed SA: for example <a href="mailto:`service-account-name@project-id.iam.gserviceaccount.com" target="_blank" rel="noopener">`service-account-name@project-id.iam.gserviceaccount.com</a>`, you choose the service account name.</li>
<li>default SA: 常见的比如使用App engine, compute engine时自动创建的service account. </li>
<li>google-managed SA: GCP 内部使用，不用管。</li>
</ul>
<p>IAM roles:</p>
<ul>
<li>primitive role: Owner, Editor, Viewer.</li>
<li>predefined role: 针对不同资源的roles，比如compite, gke, network等等.</li>
<li>custom role: 自定义的, user maintain, for more granular access.</li>
</ul>
<p>Bindings 就是把Identity 和 roles结合起来，形成一个<code>policy</code>. IAM把policy 赋予不同的对象, 比如: IAM hierarchy: Organization -&gt; folder -&gt; project -&gt; resource.</p>
<p>Project level policy operations (or organiation level)，意思是在project level上，这些member可以做规定的事情。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## add and revoke</span></span><br><span class="line"><span class="comment">## member can be user:xx or serviceAccount:xx</span></span><br><span class="line">gcloud projects add-iam-policy-binding &lt;project ID&gt; \</span><br><span class="line">  --member=member \</span><br><span class="line">  --role=&lt;role ID&gt;</span><br><span class="line">gcloud projects remove-iam-policy-binding &lt;project ID&gt; \</span><br><span class="line">  --member=member \</span><br><span class="line">  --role=&lt;role ID&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## batch operation, role bindings 都在yaml file中</span></span><br><span class="line">gcloud projects <span class="built_in">set</span>-iam-policy &lt;project id&gt; &lt;file path&gt;</span><br><span class="line">gcloud projects get-iam-policy &lt;project id&gt; [--format=json/yaml] &gt; [file path]</span><br></pre></td></tr></table></figure></p>
<p>注意这2个命令，这里service account被当做了resource而不是identity, 所以这里设置了其他identity去操作这个service account:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gcloud iam service-accounts <span class="built_in">set</span>/get-iam-policy &lt;service account&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Storage-and-Database"><a href="#Storage-and-Database" class="headerlink" title="Storage and Database"></a>Storage and Database</h2><p>Storage access control has many options, IAM is one of them and usually is enough. others like ACLs, signed URL and Signed policy document.</p>
<p><code>Cloud Storage</code>: fully managed object store. In the demo, <code>gsutil</code> command can do versioning, acl, set restrictions, etc.</p>
<p>The slide has info about how to choose which service: SQL, NoSQL …?</p>
<p><code>Cloud SQL</code>: a fully managed database service (MySQL or PostgreSQL), If the Cloud SQL located in the same VPC and the same region, connect it with private IP, otherwise using cloud SQL proxy connection (setup via a script).</p>
<p><code>Cloud Spanner</code>: Cloud Spanner combines the benefits of relational database structure with non-relational horizontal scale. Used for financial and inventory applications.</p>
<p><code>Cloud Firestore</code>: the next generation of Cloud Datastore. Cloud Firestore is a NoSQL document database</p>
<p><code>Cloud Bigtable</code>: a fully managed, wide-column NoSQL database that offers low latency and replication for high availability.</p>
<p><code>Cloud Memorystore</code>: creates and manages Redis instances on the Google Cloud Platform.</p>
<h2 id="Resource-Management"><a href="#Resource-Management" class="headerlink" title="Resource Management"></a>Resource Management</h2><p>Resource manager, quotas, labels and billing.</p>
<h2 id="Resource-Monitor"><a href="#Resource-Monitor" class="headerlink" title="Resource Monitor"></a>Resource Monitor</h2><p>From stackdriver collection.</p>
<h1 id="Scaling-and-Automation"><a href="#Scaling-and-Automation" class="headerlink" title="Scaling and Automation"></a>Scaling and Automation</h1><h2 id="Interconnecting-Networks"><a href="#Interconnecting-Networks" class="headerlink" title="Interconnecting Networks"></a>Interconnecting Networks</h2><p>In the demo, Two VMs in differen region and subnet, setup the <code>VPN tunnel</code> they can ping each other via private IP.</p>
<p>理解了这部分，可以自己搭建VPN翻墙了.<br><code>Cloud VPN</code>: securely connect your infrastructure to GCP VPC network, useful for low-volume data connections.</p>
<p>Options: IPsec VPN tunnel, dedicated interconnect (for large traffic) and partner interconnect (via other service provider network)</p>
<p>Configure cloud VPN gateway and on-premises VPN gateway, setup VPN tunnel (encrypted traffic), must be paired.</p>
<h2 id="Load-Balancing-and-Auto-Scaling"><a href="#Load-Balancing-and-Auto-Scaling" class="headerlink" title="Load Balancing and Auto Scaling"></a>Load Balancing and Auto Scaling</h2><p>Managed instance groups, typically used with autoscaler.</p>
<p>HTTP(s) load balancing: level 7 application layer load balancer.</p>
<p>In the demo, create VM with detached disk, install apach2 then keep the disk to create custom image, use this image to create instance template then creating instance groups.</p>
<h2 id="Infrastructure-Automation"><a href="#Infrastructure-Automation" class="headerlink" title="Infrastructure Automation"></a>Infrastructure Automation</h2><p>Deployment manager and Terraform, can also use Ansible, Chef, Puppet..</p>
<p>Terraform is integrated in Cloud Shell.</p>
<p>GCP marketplace, production-ready solutions.</p>
<h1 id="External-HTTP-S-Load-Balancing"><a href="#External-HTTP-S-Load-Balancing" class="headerlink" title="External HTTP(S) Load Balancing"></a>External HTTP(S) Load Balancing</h1><p><a href="https://cloud.google.com/load-balancing/docs/https" target="_blank" rel="noopener">https://cloud.google.com/load-balancing/docs/https</a></p>
<h1 id="Anthos"><a href="#Anthos" class="headerlink" title="Anthos"></a>Anthos</h1><p>建议把这个系列的slides下载复习。<br>Qucik Labs and slides are from <a href="https://app.pluralsight.com/paths/skills/architecting-hybrid-cloud-infrastructure-with-anthos" target="_blank" rel="noopener">PluralSight Anthos special</a></p>
<p>Built on open source technologies pioneered by Google—including Kubernetes, Istio, and Knative—Anthos enables consistency between on-premises and cloud environments.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">      On-premises                           Public Cloud</span><br><span class="line">|----------------------|               |-----------------------|</span><br><span class="line">|                       Config Management                      | Anthos Configuration Management</span><br><span class="line">|      &lt;==============================================&gt;        |</span><br><span class="line">|                       Service Mesh                           | Istio, communications &amp;</span><br><span class="line">|      &lt;==============================================&gt;        |        observability</span><br><span class="line">|-----------|           |              |                       |</span><br><span class="line">| Enterprise| |---------|              |-----------|           |</span><br><span class="line">| workload  | |Containers              |Containers |           | Kubernetes, deployment &amp;</span><br><span class="line">|           | |---------|              |-----------|           |             run-time platform</span><br><span class="line">|           |   K8s     |              |   GKE                 |</span><br><span class="line">|           | on-premise|              |                       |</span><br><span class="line">|-----------|-----------|              |-----------------------|</span><br></pre></td></tr></table></figure></p>
<p>这个系列先讲了Anthos是什么，组成结构，然后讲了service mesh, 最后讲了anthos config management (ACM).</p>
<p>几个要点:</p>
<ol>
<li>on-premises cluster中安装运行有一个agent pod, 用来主动注册该cluster到anthos control plane.</li>
<li>所有注册过的cluster是统一管理和可视的，在同一个control plane，cluster中的资源也可见.</li>
<li>Anthos中很重要的部分就是service mesh, 使用的是Istio，所以要理解这部分。见我的关于Istio的博客。</li>
<li>config management is the single source of truth, 可以把所有的policies都放在一个git repo中，是为desired state, 使用时会传播到所有被managed的objects中，是否被managed 在object manifest中有annotation标记.</li>
<li>multiple control planes DNS using Istio CoreDNS, not kube-dns (for local).</li>
</ol>
<h2 id="Ingress-of-Anthos"><a href="#Ingress-of-Anthos" class="headerlink" title="Ingress of Anthos"></a>Ingress of Anthos</h2><p><a href="https://cloud.google.com/kubernetes-engine/docs/concepts/ingress-for-anthos" target="_blank" rel="noopener">https://cloud.google.com/kubernetes-engine/docs/concepts/ingress-for-anthos</a><br>这里将ingress of anthos的概念，组成以及图示都列出来了，很清晰。<br>Ingress for Anthos is designed to meet the load balancing needs of multi-cluster, multi-regional environments. It’s a controller for the external HTTP(S) load balancer to provide ingress for traffic coming from the internet across one or more clusters.</p>
<p>Ingress for Anthos updates the load balancer, keeping it consistent with the environment and desired state of Kubernetes resources.</p>
<p>Ingress for Anthos uses a centralized Kubernetes API server to deploy Ingress across multiple clusters. This centralized API server is called the <code>config cluster</code>. Any GKE cluster can act as the config cluster. The config cluster uses two custom resource types: <code>MultiClusterIngress</code> and <code>MultiClusterService</code>. By deploying these resources on the config cluster, the Anthos Ingress Controller deploys load balancers across multiple clusters.</p>
<p>There can have multiple <code>mcs</code> and only one <code>mci</code>. <code>mcs</code> can select specific clusters with <code>clusters</code> field. <code>mci</code> can specify default backend and other backends with rules.</p>
<p>Clusters that you register to an <code>environ</code>(An environ is a domain that groups clusters and infrastructure, manages resources, and keeps a consistent policy across them) become visible to Ingress, so they can be used as backends for Ingress.</p>
<p>Environs possess a characteristic known as <code>namespace sameness</code> which assumes that resources with the identical names and same namespace across clusters are considered to be instances of the same resource. </p>
]]></content>
      <categories>
        <category>Cloud</category>
      </categories>
      <tags>
        <tag>cloud</tag>
        <tag>gcp</tag>
      </tags>
  </entry>
  <entry>
    <title>OOP Design</title>
    <url>/2020/03/29/design-OOD/</url>
    <content><![CDATA[<p>OOD 可以看成是 High Level System Design 后的具体实现。</p>
<p>This blog is for <code>Object Oriented Design</code>, please revisit frequently to refresh. The notes are mainly from <code>https://www.educative.io/</code>.</p>
<p><a href="https://www.youtube.com/watch?v=fJW65Wo7IHI&amp;list=PLGLfVvz_LVvS5P7khyR4xDp7T9lCk9PgE" target="_blank" rel="noopener">OOP Design video</a><br><code>OOP</code>: <code>Object-oriented programming</code><br><code>Design pattern</code>: singleton, factory, etc<br><code>Concurrency</code></p>
<p>The four principles of object-oriented programming are encapsulation, abstraction, inheritance, and polymorphism.</p>
<p>The process of OO analysis and design can be described as:</p>
<ol>
<li>Identifying the objects in a system;</li>
<li>Defining relationships between objects;</li>
<li>Establishing the interface of each object;</li>
<li>Making a design, which can be converted to executables using OO languages.</li>
</ol>
<p>要清楚如何定义enum, constants abstract class, interface. 如何选择他们.</p>
<p><code>UML</code> stands for <code>Unified Modeling Language</code> and is used to model the Object-Oriented Analysis of a software system. UML is a way of visualizing and documenting a software system by using a collection of diagrams.</p>
<p>Be familiar with:</p>
<ol>
<li>use case diagram (actors， 不是指所有的object: admin, customer, system…)</li>
<li>class diagram (relationships)</li>
<li>sequence diagram (emphasize on interaction between objects, time series)</li>
<li>activity diagram (emphasize on control of flow)</li>
</ol>
<p><strong>Summary</strong>:<br>总的来看，通过class diagram，设计好基本的abstract class, interface, base class，然后再延伸，实例化。实例化的class中设计好attributes, method的实现。</p>
<ul>
<li><p>定义好enum, constants.</p>
</li>
<li><p>把不同的系统分开设计，比如notifiation, payment…</p>
</li>
<li><p>对于actor people，有一个account class, 被包含在person abstract class中，然后这个person被实例化为其他诸如guest, admin, member等class. (有类似关系的以此类推)</p>
</li>
<li><p>对于有查询需求的任务, search interface中声明search方法，然后被search的对象类implements, 在这个对象内部实现search的各种method, 通常需要与database连接。</p>
</li>
<li><p>可能会用到设计模式</p>
</li>
</ul>
<h3 id="Design-a-Library-Management-System"><a href="#Design-a-Library-Management-System" class="headerlink" title="Design a Library Management System"></a>Design a Library Management System</h3><p>Library management systems help libraries keep track of the books and their checkouts, as well as members’ subscriptions and profiles.</p>
<ol>
<li>get clarity of the requirements, Be sure to ask questions to find the exact scope of the system that the interviewer has in mind</li>
</ol>
<p>找到actors之后，围绕actors就可以提出具体要求，可以做什么事情:<br>member can search book by title, name, date, category, author.<br>book has unique id, rack number, etc.<br>member can checkout, reserve book copies.<br>days a member can keep the book.<br>numbers a member can checkout.<br>collect fine if after due date.<br>system can send notification to user.<br>…</p>
<p>最后确认需具体要实现什么的功能？</p>
<ol start="2">
<li><p>use case diagram, define top use cases<br>从object角度, 看看各自可以有什么操作, 对具体的实现功能，画出具体的use case diagram。</p>
</li>
<li><p>class diagram<br>有几个问题:<br>要从high level考虑有哪些abstract class, enum, constant, interface等。<br>然后各自的依赖关系画一下。</p>
</li>
</ol>
<p>interface vs inheritace，什么时候谁合适?</p>
<p>在实现代码的时候，class diagram可以作为指导原则</p>
<ol start="4">
<li><p>activity diagram<br>画出具体实现<strong>某一</strong>功能的状态图</p>
</li>
<li><p>code<br>Since you are not required to write a fully executable code in an interview, you can assume parts of the code to interact with the database, payment system, etc..</p>
</li>
</ol>
<p>主要写出基本的部分:<br>Enums and Constants:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// enums</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> BookStatus</span><br><span class="line">&#123;</span><br><span class="line">  AVAILABLE,</span><br><span class="line">  RESERVED,</span><br><span class="line">  LOANED,</span><br><span class="line">  LOST</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> ReservationStatus</span><br><span class="line">&#123;</span><br><span class="line">  WAITING,</span><br><span class="line">  PENDING,</span><br><span class="line">  CANCELED,</span><br><span class="line">  NONE</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// constants</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Constants</span> </span>&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_BOOKS_ISSUED_TO_A_USER = <span class="number">5</span>;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_LENDING_DAYS = <span class="number">10</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后是abstrace class, interface 和其他继承，实现的类，根据class diagram去实现，举几个例子:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// For simplicity, we are not defining getter and setter functions. The reader can</span></span><br><span class="line"><span class="comment">// assume that all class attributes are private and accessed through their respective</span></span><br><span class="line"><span class="comment">// public getter methods and modified only through their public methods function.</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Book</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String ISBN;</span><br><span class="line">  <span class="keyword">private</span> String title;</span><br><span class="line">  <span class="keyword">private</span> String subject;</span><br><span class="line">  <span class="keyword">private</span> String publisher;</span><br><span class="line">  <span class="keyword">private</span> String language;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> numberOfPages;</span><br><span class="line">  <span class="keyword">private</span> List&lt;Author&gt; authors;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BookItem</span> <span class="keyword">extends</span> <span class="title">Book</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String barcode;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">boolean</span> isReferenceOnly;</span><br><span class="line">  <span class="keyword">private</span> Date borrowed;</span><br><span class="line">  <span class="keyword">private</span> Date dueDate;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">double</span> price;</span><br><span class="line">  <span class="keyword">private</span> BookFormat format;</span><br><span class="line">  <span class="keyword">private</span> BookStatus status;</span><br><span class="line">  <span class="keyword">private</span> Date dateOfPurchase;</span><br><span class="line">  <span class="keyword">private</span> Date publicationDate;</span><br><span class="line">  <span class="keyword">private</span> Rack placedAt;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">checkout</span><span class="params">(String memberId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(bookItem.getIsReferenceOnly()) &#123;</span><br><span class="line">      ShowError(<span class="string">"This book is Reference only and can't be issued"</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(!BookLending.lendBook(<span class="keyword">this</span>.getBarCode(), memberId))&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.updateBookItemStatus(BookStatus.LOANED);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Rack</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> number;</span><br><span class="line">  <span class="keyword">private</span> String locationIdentifier;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// interface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Search</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchByTitle</span><span class="params">(String title)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchByAuthor</span><span class="params">(String author)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchBySubject</span><span class="params">(String subject)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchByPubDate</span><span class="params">(Date publishDate)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Catalog</span> <span class="keyword">implements</span> <span class="title">Search</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">  <span class="keyword">private</span> HashMap&lt;String, List&lt;Book&gt;&gt; bookTitles;</span><br><span class="line">  <span class="keyword">private</span> HashMap&lt;String, List&lt;Book&gt;&gt; bookAuthors;</span><br><span class="line">  <span class="keyword">private</span> HashMap&lt;String, List&lt;Book&gt;&gt; bookSubjects;</span><br><span class="line">  <span class="keyword">private</span> HashMap&lt;String, List&lt;Book&gt;&gt; bookPublicationDates;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchByTitle</span><span class="params">(String query)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// return all books containing the string query in their title.</span></span><br><span class="line">    <span class="keyword">return</span> bookTitles.get(query);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchByAuthor</span><span class="params">(String query)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// return all books containing the string query in their author's name.</span></span><br><span class="line">    <span class="keyword">return</span> bookAuthors.get(query);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Design-parking-lot"><a href="#Design-parking-lot" class="headerlink" title="Design parking lot"></a>Design parking lot</h3><p><a href="https://www.youtube.com/watch?v=DSGsa0pu8-k&amp;t=814s" target="_blank" rel="noopener">https://www.youtube.com/watch?v=DSGsa0pu8-k&amp;t=814s</a><br>评论里有一些批评意见，可以参考。</p>
<ul>
<li><p>Identify the problem scope:<br>do you want me to come up a system design, or class hierarchy?<br>or should we get into certain specific question and wirte some methods?</p>
</li>
<li><p>How you approach the problem:<br>show a clear and systematic approach how you tackle this problem<br>how is the parking lot designed? building? open space? free or pay?<br>how many spots are we talking about? floors?<br>are there mutliple entrances or exits?<br>should we first fill out floor from top?<br>prices strategy? premium, general customer?</p>
</li>
</ul>
<p>进口的识别系统会识别plate number + vehicle type，然后再ticket上标明应该停放到哪个building，哪一层的哪个位置。(如果有多个entrance, 则有concurrency问题需要解决)</p>
<p>code some part of the design? which part do you want me to implement?<br>We have database backend but here for Simplicity can we assume we store the data in memory?</p>
<p>算法去实现spot -&gt; vehicle的分配。</p>
<ol>
<li><p>system requirements<br>multi-floors<br>multi-entries or exits<br>parking ticket<br>pay cash or credit card<br>pay at info panel or at exit<br>display message when full<br>different parking spots for different type car<br>electric car spots, charge station support<br>step price hourly</p>
</li>
<li><p>use case diagram<br>get clarity what functions we need to implement.</p>
</li>
<li><p>class diagram<br>ParkingLot<br>ParkingFloor<br>ParkingSpot<br>Account: admin and parking attendant<br>ParkingTicket<br>Vehicle: many types<br>Payment: credit card or cash<br>ParkingRate<br>ParkingDisplayBoard<br>ParkingAttendantPortal<br>CustomerInfoPortal<br>ElectricPanel</p>
</li>
<li><p>code<br>see: <a href="https://www.educative.io/courses/grokking-the-object-oriented-design-interview/gxM3gRxmr8Z" target="_blank" rel="noopener">https://www.educative.io/courses/grokking-the-object-oriented-design-interview/gxM3gRxmr8Z</a></p>
</li>
</ol>
<h3 id="Design-Amazon-online-shopping-system"><a href="#Design-Amazon-online-shopping-system" class="headerlink" title="Design Amazon online shopping system"></a>Design Amazon online shopping system</h3><ol>
<li>get clarity</li>
</ol>
<ul>
<li>what scope do you want me to focus on?</li>
<li>high level design or dive into a specific function component, wirte class and method.</li>
</ul>
<p><code>Objects</code>: guest, member, admin and system<br>分别讨论一下各自可以做什么操作。</p>
<p>几个主要的system:<br>register, search, review, order, shipment, payment, notification.</p>
<ol start="2">
<li>use case diagram</li>
<li>activity diagram</li>
<li>sequence diagram</li>
</ol>
<h4 id="Design-shopify"><a href="#Design-shopify" class="headerlink" title="Design shopify"></a>Design shopify</h4><p><a href="https://www.youtube.com/watch?v=lEL4F_0J3l8" target="_blank" rel="noopener">shopify eCommerce platform</a><br>类似于淘宝, 有自己的网店portal.</p>
<h3 id="Design-stack-overflow"><a href="#Design-stack-overflow" class="headerlink" title="Design stack overflow"></a>Design stack overflow</h3><p>Stack Overflow is one of the largest online communities for developers to learn and share their knowledge.</p>
<p>Users of Stack Overflow can earn reputation points and badges. For example, a person is awarded ten reputation points for receiving an “up” vote on an answer and five points for the “up” vote of a question. The can also receive badges for their valued contributions. A higher reputation lets users unlock new privileges like the ability to vote, comment on, and even edit other people’s posts.</p>
<p><code>Actors</code>: admin, guest, member, system, moderator(close,delete,undelete question)</p>
<h3 id="Design-a-Movie-Ticket-Booking-System"><a href="#Design-a-Movie-Ticket-Booking-System" class="headerlink" title="Design a Movie Ticket Booking System"></a>Design a Movie Ticket Booking System</h3><ol>
<li><p>high level overview<br>movie theater -&gt; halls -&gt; moive -&gt; shows<br>search movie<br>select show and boot ticket<br>select seat<br>notification<br>payment<br><strong>concurrency</strong> issue when booking:<br>在数据库层面实现的，没有使用Java的concurrency package<br>We can use transactions in SQL databases to avoid any clashes.<br>lock the rows before we update them<br>discount/coupon apply</p>
</li>
<li><p>use case diagram</p>
</li>
<li>class diagram</li>
<li>activity diagram</li>
</ol>
<h3 id="Design-ATM"><a href="#Design-ATM" class="headerlink" title="Design ATM"></a>Design ATM</h3><p>Automated teller machine (ATM)<br>withdraw and deposit money</p>
<p>components of ATM:<br>card reader<br>kaypad<br>screen<br>Cash dispenser<br>Deposit slot<br>printer<br>network</p>
<p>checking and saving account of user<br>都放在<strong>transaction中，保证原子性</strong>:<br>Balance inquiry<br>Deposit cash<br>Deposit check<br>Withdraw cash<br>Transfer funds</p>
<p>The ATM will maintain an internal log of transactions that contains information about hardware failures; this log will be used by the ATM operator to resolve any issues.</p>
<p><code>actors:</code><br>operator<br>customer<br>bank manager<br>system</p>
<h3 id="Design-an-Airline-Management-System"><a href="#Design-an-Airline-Management-System" class="headerlink" title="Design an Airline Management System"></a>Design an Airline Management System</h3><p>This system involves the scheduling of flights, air ticket reservations, flight cancellations, customer support, and staff management. Daily flights updates can also be retrieved by using the system.</p>
<p>roundtrip<br>one way<br>mutli-city</p>
<p>回忆一下预定的界面<br>departing<br>returning</p>
<h3 id="Design-a-Hotel-Management-System"><a href="#Design-a-Hotel-Management-System" class="headerlink" title="Design a Hotel Management System"></a>Design a Hotel Management System</h3><p>和ticket booking类似<br>a online portal, keep track of available rooms, book rooms and generate bill.<br>booking of different room types like standard, deluxe, family suite, etc<br>housekeeping log to keep track of all housekeeping tasks</p>
<ol>
<li><p>use case diagram<br>guest<br>manager<br>system<br>housekeeper<br>Receptionist</p>
</li>
<li><p>class diagram</p>
</li>
<li>activity diagram</li>
</ol>
<h3 id="Restaurant-Management-system"><a href="#Restaurant-Management-system" class="headerlink" title="Restaurant Management system"></a>Restaurant Management system</h3><p>同上，补充几个特点:<br>The system allows the manager to keep track of available tables in the system as well as the reservation of tables and bill generation.<br>这里是西餐的形式，没人一个座位，单独点餐。</p>
<p>menu -&gt; menu sections -&gt; items<br>rooms -&gt; tables (reservation or walk-in)</p>
<h3 id="Design-Facebook"><a href="#Design-Facebook" class="headerlink" title="Design Facebook"></a>Design Facebook</h3><p>Facebook is an online social networking service where users can connect with other users to post and read messages. Users access Facebook through their website interface or mobile apps.</p>
<h3 id="Design-LinkedIn"><a href="#Design-LinkedIn" class="headerlink" title="Design LinkedIn"></a>Design LinkedIn</h3><p>Similar to Facebook design but carter to professionals. 各种功能几乎就一样。</p>
<p>A LinkedIn member’s profile page, which emphasizes their skills, employment history, and education, has professional network news feeds with customizable modules.</p>
<ol>
<li><p>use case diagram<br>member<br>admin<br>system</p>
</li>
<li><p>class diagram</p>
</li>
<li>activity diagram</li>
</ol>
]]></content>
      <categories>
        <category>OOP Design</category>
      </categories>
      <tags>
        <tag>OOP design</tag>
      </tags>
  </entry>
  <entry>
    <title>Apache Cassandra</title>
    <url>/2020/06/28/database-cassandra/</url>
    <content><![CDATA[<p>//TODO<br>Single node cluster: practice CQL<br>Multiple node cluster/ multiple data center: verify replication strategy and tunable consistency</p>
<p>目前问题是Mac 如何与Virtual machine private IP 互相访问。<br>Seed for joining, private ip for each, config cassandra.yaml, use rpm to install cassadnra. Now I am using binary to run Cassandra:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## you will see the cluster node status</span></span><br><span class="line">./bin/nodetool status</span><br><span class="line"><span class="comment">## see token range and belongs to which node</span></span><br><span class="line">./bin/nodetool ring</span><br></pre></td></tr></table></figure></p>
<p>Token number is acutally the virtual node number in one physical node.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> CASSANDRA_SEEDS=ip or hostname?</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">nodetool join - Join the ring</span><br></pre></td></tr></table></figure>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Vagrant Cassandra lab environment:<br><a href="https://github.com/chengdol/vagrant-cassandra" target="_blank" rel="noopener">https://github.com/chengdol/vagrant-cassandra</a></p>
<p>Cassandra web site:<br><a href="https://cassandra.apache.org/" target="_blank" rel="noopener">https://cassandra.apache.org/</a></p>
<p>Open-source <strong>NoSQL</strong> Database, originally developed from Facebook. Data stored is associated with token.</p>
<p><code>Virtual node</code> concept. When new physical node is added, actually it is represented by multiple virtual nodes inserted randemly in the token range, the virtual node will talk to its neighbor to take over the data originally belongs to them.</p>
<p><code>Snitch</code>, let Cassandra know environment.</p>
<h2 id="Replication-Strategy"><a href="#Replication-Strategy" class="headerlink" title="Replication Strategy"></a>Replication Strategy</h2><p><code>Keyspace</code>: a namespace that defines data replication on nodes, one keyspace may have mutliple related tables, the <code>Replicatin Strategy</code> is keyspace-wide:</p>
<ul>
<li>simply strategy for single data center</li>
<li>network topology strategy for multiple data centers</li>
</ul>
<p>Data center can have multiple racks.</p>
<p>For example, one data center has 2 racks, rack1 has 2 nodes, rack2 has one node, if the simply strategy is 1, then rack1 owns 50% data, each node in rack1 owns 25%, rack2 owns 50%, since rack2 only contains 1 node, so that node owns 50%.</p>
<h2 id="Tunable-Consistency"><a href="#Tunable-Consistency" class="headerlink" title="Tunable Consistency"></a>Tunable Consistency</h2><p><code>Coordinator Node</code>: client connect to perform actions. Each connection to Cassandra may have a different coordinator node.</p>
<p>Consistency level for <strong>write</strong>: </p>
<ul>
<li><code>ONE</code>, <code>TWO</code>, <code>THREE</code> </li>
<li><code>QUORUM</code>(majority of nodes succeeds)</li>
<li><code>ALL</code>(must all good)</li>
<li><code>ANY</code>(include coordinator itself).</li>
</ul>
<p><code>Hinted Handoff</code>: when one write node is unavaiable, the data is written to coordinator node, the coordinator node will try repeatedly write to the unavailable node until succeeded.</p>
<p>Consistency level for <strong>read</strong>: how many nodes to consult to return the most current data to caller.</p>
<ul>
<li><code>ONE</code>, <code>TWO</code>, <code>THREE</code></li>
<li><code>QUORUM</code>(majority of nodes succeeds)</li>
<li><code>ALL</code> (must all good)</li>
</ul>
<p><code>Read Repair</code>: 当对一个node写失败了but back online later，在read时如果有多个replicas的数据可以参考，则对那个node可重新写入上次wirte失败的数据. Run <code>nodetool repair</code> periodically will resolve the inconsistencies in cluster.</p>
<p>Achieving strong consistency:</p>
<ul>
<li>write consistency + read consistency &gt; replication factor</li>
</ul>
<p>Multiple data center consistency level:</p>
<ul>
<li><code>EACH_QUORUM</code></li>
<li><code>LOCAL_QUORUM</code>: local means current coordinator node data center</li>
<li><code>LOCAL_ONE</code>: the same as <code>ONE</code></li>
</ul>
<h1 id="CQL"><a href="#CQL" class="headerlink" title="CQL"></a>CQL</h1><p>A single Vagrant Cassandra node is enough for CQL.<br>Cassandra Query Language:</p>
<ul>
<li><a href="https://cassandra.apache.org/doc/latest/cql/index.html" target="_blank" rel="noopener">https://cassandra.apache.org/doc/latest/cql/index.html</a></li>
<li>Keyspace, table and basic data type</li>
<li>CRUD operations</li>
<li>Counters</li>
<li>Aggregate functions</li>
</ul>
<p>With <code>cqlsh</code> script, you can specify remote Cassandra node with port to connect, by default it will connect to localhost 9042 port. (类似于consul, 连接本地服务即可作用于全局)</p>
<p>Keyspace -&gt; Tables -&gt; partitions -&gt; row.</p>
<p>In brief, each table requires a unique <code>primary key</code>. The first field listed is the <code>partition key</code>, since its hashed value is used to determine the node to store the data. If those fields are wrapped in parentheses then the partition key is composite. Otherwise the first field is the partition key. Any fields listed after the primary key are called <code>clustering columns</code>. These store data in ascending or descending order within the partition for the fast retrieval of similar values. All the fields together are the primary key.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## help</span></span><br><span class="line">cqlsh&gt; <span class="built_in">help</span></span><br><span class="line"></span><br><span class="line">Documented shell commands:</span><br><span class="line">===========================</span><br><span class="line">CAPTURE  CLS          COPY  DESCRIBE  EXPAND  LOGIN   SERIAL  SOURCE   UNICODE</span><br><span class="line">CLEAR    CONSISTENCY  DESC  EXIT      HELP    PAGING  SHOW    TRACING</span><br><span class="line"></span><br><span class="line">CQL <span class="built_in">help</span> topics:</span><br><span class="line">================</span><br><span class="line">AGGREGATES               CREATE_KEYSPACE           DROP_TRIGGER      TEXT     </span><br><span class="line">ALTER_KEYSPACE           CREATE_MATERIALIZED_VIEW  DROP_TYPE         TIME     </span><br><span class="line">ALTER_MATERIALIZED_VIEW  CREATE_ROLE               DROP_USER         TIMESTAMP</span><br><span class="line">ALTER_TABLE              CREATE_TABLE              FUNCTIONS         TRUNCATE </span><br><span class="line">ALTER_TYPE               CREATE_TRIGGER            GRANT             TYPES    </span><br><span class="line">ALTER_USER               CREATE_TYPE               INSERT            UPDATE   </span><br><span class="line">APPLY                    CREATE_USER               INSERT_JSON       USE      </span><br><span class="line">ASCII                    DATE                      INT               UUID     </span><br><span class="line">BATCH                    DELETE                    JSON            </span><br><span class="line">BEGIN                    DROP_AGGREGATE            KEYWORDS        </span><br><span class="line">BLOB                     DROP_COLUMNFAMILY         LIST_PERMISSIONS</span><br><span class="line">BOOLEAN                  DROP_FUNCTION             LIST_ROLES      </span><br><span class="line">COUNTER                  DROP_INDEX                LIST_USERS      </span><br><span class="line">CREATE_AGGREGATE         DROP_KEYSPACE             PERMISSIONS     </span><br><span class="line">CREATE_COLUMNFAMILY      DROP_MATERIALIZED_VIEW    REVOKE          </span><br><span class="line">CREATE_FUNCTION          DROP_ROLE                 SELECT          </span><br><span class="line">             DROP_TABLE                SELECT_JSON </span><br><span class="line"></span><br><span class="line"><span class="comment">## specified</span></span><br><span class="line">cqlsh&gt; <span class="built_in">help</span> consistency;</span><br></pre></td></tr></table></figure>
<p>Create a keyspace with:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> keyspace pluralsight <span class="keyword">with</span> <span class="keyword">replication</span> = &#123;<span class="string">'class'</span>:<span class="string">'SimpleStrategy'</span>, <span class="string">'replication_factor'</span>:<span class="number">1</span>&#125;;</span><br></pre></td></tr></table></figure></p>
<p>Create a table in this keyspace with:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> pluralsight;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> courses (<span class="keyword">id</span> <span class="built_in">varchar</span> primary <span class="keyword">key</span>);</span><br></pre></td></tr></table></figure></p>
<p>Optionally attempt to create the table again with:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">if</span> <span class="keyword">not</span> <span class="keyword">exists</span> courses (<span class="keyword">id</span> <span class="built_in">varchar</span> primary <span class="keyword">key</span>);</span><br></pre></td></tr></table></figure></p>
<p>(and note that you will not get an error as long as the ‘if not exists’ is present)</p>
<p>Add a few columns to the courses table with:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> courses <span class="keyword">add</span> <span class="keyword">duration</span> <span class="built_in">int</span>;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> courses <span class="keyword">add</span> released <span class="built_in">timestamp</span>;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> courses <span class="keyword">add</span> author <span class="built_in">varchar</span>;</span><br></pre></td></tr></table></figure></p>
<p>Add a comment to the table with:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> courses <span class="keyword">with</span> <span class="keyword">comment</span> = <span class="string">'A table of courses'</span>;</span><br></pre></td></tr></table></figure></p>
<p>View the complete table and all its default properties with:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- describe</span></span><br><span class="line">desc table courses;</span><br></pre></td></tr></table></figure></p>
<p>Drop and recreate a more complete courses table with:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> courses;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> courses (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">varchar</span> primary <span class="keyword">key</span>,</span><br><span class="line">    <span class="keyword">name</span> <span class="built_in">varchar</span>,</span><br><span class="line">    author <span class="built_in">varchar</span>,</span><br><span class="line">    audience <span class="built_in">int</span>,</span><br><span class="line">    <span class="keyword">duration</span> <span class="built_in">int</span>,</span><br><span class="line">    cc <span class="built_in">boolean</span>,</span><br><span class="line">    released <span class="built_in">timestamp</span></span><br><span class="line">    ) <span class="keyword">with</span> <span class="keyword">comment</span> = <span class="string">'A table of courses'</span>;</span><br></pre></td></tr></table></figure></p>
<p>(Note that when entering the lines as above cqlsh will automatically detect a multi-line CQL statement)</p>
<p>Exit cqlsh:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure></p>
<p>Load course data by running a series of CQL commands from an external file<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat courses.cql | cqlsh</span><br></pre></td></tr></table></figure></p>
<p>Verify that the CQL commands in the file were indeed executed:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> pluralsight;</span><br><span class="line">desc tables;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses;</span><br></pre></td></tr></table></figure></p>
<p>(The ‘desc tables’ should show a single ‘courses’ table, and the ‘select’ statement should show 5 rows of sample data.)</p>
<p>The ‘expand’ cqlsh command will display the query results in a ‘one column per line’ format:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- pretty format</span></span><br><span class="line">expand on;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses;</span><br><span class="line">expand off;</span><br></pre></td></tr></table></figure></p>
<p>You can display the time a piece of data was written with the ‘writetime’ function:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, cc, writetime(cc) <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'advanced-javascript'</span>;</span><br></pre></td></tr></table></figure></p>
<p>We can update this cc column with an ‘update’ statement:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">update</span> courses <span class="keyword">set</span> cc = <span class="literal">true</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'advanced-javascript'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Now re-run the select statement containing the ‘writetime’ function and notice that the time has changed.<br>You can prove to yourself that this write time is stored on a per column basis by selecting this for a different column:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span>, writetime(<span class="keyword">name</span>) <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'advanced-javascript'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Note that this writetime value is the same as the one returned by our first ‘cc’ query.</p>
<p>Cassandra also provides a function for returning the token associated with a partition key:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, token(<span class="keyword">id</span>) <span class="keyword">from</span> courses;</span><br></pre></td></tr></table></figure></p>
<p>If you try to select from a column other than the primary key, you’ll get an error:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> author = <span class="string">'Cory House'</span>;</span><br></pre></td></tr></table></figure></p>
<p>(We’ll show how to do this in a later module.)</p>
<p>Let’s create a users table:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> <span class="keyword">users</span> (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">varchar</span> primary <span class="keyword">key</span>,</span><br><span class="line">    first_name <span class="built_in">varchar</span>,</span><br><span class="line">    last_name <span class="built_in">varchar</span>,</span><br><span class="line">    email <span class="built_in">varchar</span>,</span><br><span class="line">    <span class="keyword">password</span> <span class="built_in">varchar</span></span><br><span class="line">    ) <span class="keyword">with</span> <span class="keyword">comment</span> = <span class="string">'A table of users'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Then we’ll insert and “upsert” two rows of data:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> <span class="keyword">users</span> (<span class="keyword">id</span>, first_name, last_name) <span class="keyword">values</span> (<span class="string">'john-doe'</span>, <span class="string">'John'</span>, <span class="string">'Doe'</span>);</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">users</span> <span class="keyword">set</span> first_name = <span class="string">'Jane'</span>, last_name = <span class="string">'Doe'</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'jane-doe'</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">users</span>;</span><br></pre></td></tr></table></figure></p>
<p>(Note that the net effect of the insert and update are the same.)</p>
<p>Now we’ll add a new ‘reset_token’ column to this table, and add a value to this column with a TTL:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> <span class="keyword">users</span> <span class="keyword">add</span> reset_token <span class="built_in">varchar</span>;</span><br><span class="line"><span class="keyword">update</span> <span class="keyword">users</span> <span class="keyword">using</span> ttl <span class="number">120</span> <span class="keyword">set</span> reset_token = <span class="string">'abc123'</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'john-doe'</span>;</span><br></pre></td></tr></table></figure></p>
<p>We can retrieve the time remaining for a ttl with the ‘ttl’ query function:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> ttl(reset_token) <span class="keyword">from</span> <span class="keyword">users</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'john-doe'</span>;</span><br></pre></td></tr></table></figure></p>
<p>We can turn on tracing and do a select to see that there are currently no tombstones:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">tracing on;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">users</span> <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'john-doe'</span>;</span><br></pre></td></tr></table></figure></p>
<p>(Re-run this several times until the 2 minutes have elasped and the token_value will be gone, and tracing will show a tombstone.)</p>
<p>Turn off tracing:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">tracing off;</span><br></pre></td></tr></table></figure></p>
<p>Create a ratings table with two counter columns:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> ratings (</span><br><span class="line">    course_id <span class="built_in">varchar</span> primary <span class="keyword">key</span>,</span><br><span class="line">    ratings_count counter,</span><br><span class="line">    ratings_total counter</span><br><span class="line">    ) <span class="keyword">with</span> <span class="keyword">comment</span> = <span class="string">'A table of course ratings'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Now let’s increment both counter columns to represent receiving a new course rating of 4:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">update</span> ratings <span class="keyword">set</span> ratings_count = ratings_count + <span class="number">1</span>, ratings_total = ratings_total + <span class="number">4</span> <span class="keyword">where</span> course_id = <span class="string">'nodejs-big-picture'</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> ratings;</span><br></pre></td></tr></table></figure></p>
<p>(The select should show the data we just upserted.)</p>
<p>Now let’s add a second course rating of 3:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">update</span> ratings <span class="keyword">set</span> ratings_count = ratings_count + <span class="number">1</span>, ratings_total = ratings_total + <span class="number">3</span> <span class="keyword">where</span> course_id = <span class="string">'nodejs-big-picture'</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> ratings;</span><br><span class="line">exit</span><br></pre></td></tr></table></figure></p>
<p>This should show the new values of “2” and “7” for ratings_count and ratings_total respectively.</p>
<p>Drop and re-create “ratings” to use with the “avg” aggregate function<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> ratings;</span><br><span class="line"></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> ratings (</span><br><span class="line">    course_id <span class="built_in">varchar</span>,</span><br><span class="line">    user_id <span class="built_in">varchar</span>,</span><br><span class="line">    rating <span class="built_in">int</span>,</span><br><span class="line">    primary <span class="keyword">key</span> (course_id, user_id)</span><br><span class="line">);</span><br></pre></td></tr></table></figure></p>
<p>Insert a few sample ratings<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> ratings (course_id, user_id, rating) <span class="keyword">values</span> (<span class="string">'cassandra-developers'</span>, <span class="string">'user1'</span>, <span class="number">4</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> ratings (course_id, user_id, rating) <span class="keyword">values</span> (<span class="string">'cassandra-developers'</span>, <span class="string">'user2'</span>, <span class="number">5</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> ratings (course_id, user_id, rating) <span class="keyword">values</span> (<span class="string">'cassandra-developers'</span>, <span class="string">'user3'</span>, <span class="number">4</span>);</span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> ratings (course_id, user_Id, rating) <span class="keyword">values</span> (<span class="string">'advanced-python'</span>, <span class="string">'user1'</span>, <span class="number">5</span>);</span><br></pre></td></tr></table></figure></p>
<p>You can select the average for a single course (across users):<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> course_id, <span class="keyword">avg</span>(rating) <span class="keyword">from</span> ratings <span class="keyword">where</span> course_id = <span class="string">'cassandra-developers'</span>;</span><br><span class="line"><span class="keyword">select</span> course_id, <span class="keyword">avg</span>(rating) <span class="keyword">from</span> ratings <span class="keyword">where</span> course_id = <span class="string">'advanced-python'</span>;</span><br></pre></td></tr></table></figure></p>
<p>However, you can’t apply aggregate functions across partition keys:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> course_id, <span class="keyword">avg</span>(rating) <span class="keyword">from</span> ratings;  <span class="comment">-- incorrect results</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Multi-Row-Partition"><a href="#Multi-Row-Partition" class="headerlink" title="Multi-Row Partition"></a>Multi-Row Partition</h1><h2 id="Composite-Key"><a href="#Composite-Key" class="headerlink" title="Composite Key"></a>Composite Key</h2><p>Previously we only have one primary key in table, that primary is the partition key. But it could be:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- composite key</span></span><br><span class="line">PRIMARY KEY (partition_key, clustering_key, ...)</span><br></pre></td></tr></table></figure></p>
<p><code>partition_key</code> can also be composite.</p>
<p>There is no <code>join</code> operation in Cassandra.</p>
<p>Drop this table and create a new one to hold both course and module data<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> courses;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> courses (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">varchar</span>,</span><br><span class="line">    <span class="keyword">name</span> <span class="built_in">varchar</span>,</span><br><span class="line">    author <span class="built_in">varchar</span>,</span><br><span class="line">    audience <span class="built_in">int</span>,</span><br><span class="line">    <span class="keyword">duration</span> <span class="built_in">int</span>,</span><br><span class="line">    cc <span class="built_in">boolean</span>,</span><br><span class="line">    released <span class="built_in">timestamp</span>,</span><br><span class="line">    module_id <span class="built_in">int</span>,</span><br><span class="line">    module_name <span class="built_in">varchar</span>,</span><br><span class="line">    module_duration <span class="built_in">int</span>,</span><br><span class="line">    primary <span class="keyword">key</span> (<span class="keyword">id</span>, module_id)</span><br><span class="line">) <span class="keyword">with</span> <span class="keyword">comment</span> = <span class="string">'A table of courses and modules'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Insert data for the course, plus the first two modules<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, <span class="keyword">name</span>, author, audience, <span class="keyword">duration</span>, cc, released, module_id, module_name, module_duration)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>,<span class="string">'Node.js: The Big Picture'</span>,<span class="string">'Paul O''Fallon'</span>, <span class="number">1</span>, <span class="number">3240</span>, <span class="literal">true</span>, <span class="string">'2019-06-03'</span>,<span class="number">1</span>,<span class="string">'Course Overview'</span>,<span class="number">70</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, <span class="keyword">name</span>, author, audience, <span class="keyword">duration</span>, cc, released, module_id, module_name, module_duration)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>,<span class="string">'Node.js: The Big Picture'</span>,<span class="string">'Paul O''Fallon'</span>, <span class="number">1</span>, <span class="number">3240</span>, <span class="literal">true</span>, <span class="string">'2019-06-03'</span>,<span class="number">2</span>,<span class="string">'Considering Node.js'</span>,<span class="number">900</span>);</span><br></pre></td></tr></table></figure></p>
<p>Select the data we just inserted<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- get same result</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Now we can include both id and module_id in our where clause<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span> <span class="keyword">and</span> module_id = <span class="number">2</span>;</span><br></pre></td></tr></table></figure></p>
<p>We can’t select by just module, unless we enable ‘ALLOW FILTERING’<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">-- if no partition_key, performance downgrade</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> module_id = <span class="number">2</span>;                  // fails</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> module_id = <span class="number">2</span> <span class="keyword">allow</span> filtering;   // succeeds</span><br></pre></td></tr></table></figure></p>
<p>Now insert the remaining modules for the course<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, <span class="keyword">name</span>, author, audience, <span class="keyword">duration</span>, cc, released, module_id, module_name, module_duration)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>,<span class="string">'Node.js: The Big Picture'</span>,<span class="string">'Paul O''Fallon'</span>, <span class="number">1</span>, <span class="number">3240</span>, <span class="literal">true</span>, <span class="string">'2019-06-03'</span>, <span class="number">3</span>, <span class="string">'Thinking Asynchronously'</span>, <span class="number">1304</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, <span class="keyword">name</span>, author, audience, <span class="keyword">duration</span>, cc, released, module_id, module_name, module_duration)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>,<span class="string">'Node.js: The Big Picture'</span>,<span class="string">'Paul O''Fallon'</span>, <span class="number">1</span>, <span class="number">3240</span>, <span class="literal">true</span>, <span class="string">'2019-06-03'</span>, <span class="number">4</span>, <span class="string">'Defining an Application and Managing Dependencies'</span>, <span class="number">525</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, <span class="keyword">name</span>, author, audience, <span class="keyword">duration</span>, cc, released, module_id, module_name, module_duration)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>,<span class="string">'Node.js: The Big Picture'</span>,<span class="string">'Paul O''Fallon'</span>, <span class="number">1</span>, <span class="number">3240</span>, <span class="literal">true</span>, <span class="string">'2019-06-03'</span>, <span class="number">5</span>, <span class="string">'Assembling a Development Toolset'</span>, <span class="number">489</span>);</span><br></pre></td></tr></table></figure></p>
<p>We can also use module_id as part of an “in” clause<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span> <span class="keyword">and</span> module_id <span class="keyword">in</span> (<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>);</span><br></pre></td></tr></table></figure></p>
<p>And we can order by module_id<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span> <span class="keyword">order</span> <span class="keyword">by</span> module_id <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure></p>
<p>We can “select distinct” just the id, but not the id and course name:<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> <span class="keyword">id</span> <span class="keyword">from</span> courses;         // succeeds</span><br><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> <span class="keyword">id</span>, <span class="keyword">name</span> <span class="keyword">from</span> courses;   // fails</span><br></pre></td></tr></table></figure></p>
<h2 id="Static-Columns"><a href="#Static-Columns" class="headerlink" title="Static Columns"></a>Static Columns</h2><p>Static Columns are static within the partition.<br>Its the common data in a partition.</p>
<p>From cqlsh, drop and recreate the courses table, using static columns<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> pluralsight;</span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> courses;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> courses (</span><br><span class="line">    <span class="keyword">id</span> <span class="built_in">varchar</span>,</span><br><span class="line">    <span class="keyword">name</span> <span class="built_in">varchar</span> <span class="keyword">static</span>,</span><br><span class="line">    author <span class="built_in">varchar</span> <span class="keyword">static</span>,</span><br><span class="line">    audience <span class="built_in">int</span> <span class="keyword">static</span>,</span><br><span class="line">    <span class="keyword">duration</span> <span class="built_in">int</span> <span class="keyword">static</span>,</span><br><span class="line">    cc <span class="built_in">boolean</span> <span class="keyword">static</span>,</span><br><span class="line">    released <span class="built_in">timestamp</span> <span class="keyword">static</span>,</span><br><span class="line">    module_id <span class="built_in">int</span>,</span><br><span class="line">    module_name <span class="built_in">varchar</span>,</span><br><span class="line">    module_duration <span class="built_in">int</span>,</span><br><span class="line">    primary <span class="keyword">key</span> (<span class="keyword">id</span>, module_id)</span><br><span class="line">) <span class="keyword">with</span> <span class="keyword">comment</span> = <span class="string">'A table of courses and modules'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Insert just the course data, and select it back<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, <span class="keyword">name</span>, author, audience, <span class="keyword">duration</span>, cc, released)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>,<span class="string">'Node.js: The Big Picture'</span>,<span class="string">'Paul O''Fallon'</span>, <span class="number">1</span>, <span class="number">3240</span>, <span class="literal">true</span>, <span class="string">'2019-06-03'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Now insert the module data for the first two modules<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, module_id, module_name, module_duration)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>,<span class="number">1</span>,<span class="string">'Course Overview'</span>,<span class="number">70</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, module_id, module_name, module_duration)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>,<span class="number">2</span>,<span class="string">'Considering Node.js'</span>,<span class="number">900</span>);</span><br></pre></td></tr></table></figure></p>
<p>Selecting from courses now returns both course and module data in each row<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span>;</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span> <span class="keyword">and</span> module_id = <span class="number">2</span>;</span><br></pre></td></tr></table></figure></p>
<p>Insert the third module, but also change the name of the course.  Select all rows to show the course title changed everywhere.<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, <span class="keyword">name</span>, module_id, module_name, module_duration)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>, <span class="string">'The Big Node.js Picture'</span>, <span class="number">3</span>, <span class="string">'Thinking Asynchronously'</span>, <span class="number">1304</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Insert the fourth module, and fix the course name<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, <span class="keyword">name</span>, module_id, module_name, module_duration)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>, <span class="string">'Node.js: The Big Picture'</span>, <span class="number">4</span>, <span class="string">'Defining an Application and Managing Dependencies'</span>, <span class="number">525</span>);</span><br></pre></td></tr></table></figure></p>
<p>Insert the remaining course module<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> courses (<span class="keyword">id</span>, module_id, module_name, module_duration)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>, <span class="number">5</span>, <span class="string">'Assembling a Development Toolset'</span>, <span class="number">489</span>);</span><br></pre></td></tr></table></figure></p>
<p>The ‘in’ and ‘order by’ clauses work the same as before<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span> <span class="keyword">and</span> module_id <span class="keyword">in</span> (<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span> <span class="keyword">order</span> <span class="keyword">by</span> module_id <span class="keyword">desc</span>;</span><br></pre></td></tr></table></figure></p>
<p>Select course info, repeated based on the number of modules in the course<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span>, author, audience, <span class="keyword">duration</span>, cc, released <span class="keyword">from</span> courses;</span><br></pre></td></tr></table></figure></p>
<p>Now “select distinct” course info and only get one row back<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> <span class="keyword">id</span>, <span class="keyword">name</span>, author, audience, <span class="keyword">duration</span>, cc, released <span class="keyword">from</span> courses;</span><br></pre></td></tr></table></figure></p>
<p>Select just the module information for the course<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> module_id, module_name, module_duration <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'nodejs-big-picture'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Load module-level course data by running a series of CQL commands from an external file<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat data/courses2.cql | cqlsh</span><br></pre></td></tr></table></figure></p>
<p>Select module information for the ‘advanced-javascript’ course<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> pluralsight;</span><br><span class="line"><span class="keyword">select</span> module_id, module_name, module_duration <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'advanced-javascript'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Select module information for the ‘docker-fundamentals’ course<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> module_id, module_name, module_duration <span class="keyword">from</span> courses <span class="keyword">where</span> <span class="keyword">id</span> = <span class="string">'advanced-python'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Select just the course-level information for all 5 courses<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> <span class="keyword">id</span>, <span class="keyword">name</span>, author <span class="keyword">from</span> courses;</span><br></pre></td></tr></table></figure></p>
<h2 id="Time-Series-Data"><a href="#Time-Series-Data" class="headerlink" title="Time Series Data"></a>Time Series Data</h2><p>Launch our one Cassandra node and (when it’s ready) load our sample course data<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat data/courses2.cql | cqlsh</span><br></pre></td></tr></table></figure></p>
<p>From cqlsh, create a new table to hold course page views<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">use</span> pluralsight;</span><br><span class="line"><span class="keyword">create</span> <span class="keyword">table</span> course_page_views (</span><br><span class="line">    course_id <span class="built_in">varchar</span>,</span><br><span class="line">    view_id timeuuid,</span><br><span class="line">    primary <span class="keyword">key</span> (course_id, view_id)</span><br><span class="line">) <span class="keyword">with</span> <span class="keyword">clustering</span> <span class="keyword">order</span> <span class="keyword">by</span> (view_id <span class="keyword">desc</span>);</span><br></pre></td></tr></table></figure></p>
<p>Insert a row into this table, using “now()” to create a timeuuid with the current date/time.  Include a one year TTL.<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course_page_views (course_id, view_id)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>, <span class="keyword">now</span>()) <span class="keyword">using</span> TTL <span class="number">31536000</span>;</span><br></pre></td></tr></table></figure></p>
<p>Insert another row into the table with a manually generated v1 UUID (also with a TTL)<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course_page_views (course_id, view_id)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>, bb9807aa-fb68<span class="number">-11e9</span><span class="number">-8</span>f0b<span class="number">-362</span>b9e155667) <span class="keyword">using</span> TTL <span class="number">31536000</span>;</span><br></pre></td></tr></table></figure></p>
<p>Insert two more rows using “now()”<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course_page_views (course_id, view_id)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>, <span class="keyword">now</span>()) <span class="keyword">using</span> TTL <span class="number">31536000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course_page_views (course_id, view_id)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>, <span class="keyword">now</span>()) <span class="keyword">using</span> TTL <span class="number">31536000</span>;</span><br></pre></td></tr></table></figure></p>
<p>Select the rows, and then use dateOf() to extract the date/time portion of the view_id<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> course_page_views;</span><br><span class="line"><span class="keyword">select</span> dateOf(view_id) <span class="keyword">from</span> course_page_views <span class="keyword">where</span> course_id = <span class="string">'nodejs-big-picture'</span>;</span><br></pre></td></tr></table></figure></p>
<p>Reverse the date order of the results<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> dateOf(view_id) <span class="keyword">from</span> course_page_views <span class="keyword">where</span> course_id = <span class="string">'nodejs-big-picture'</span> <span class="keyword">order</span> <span class="keyword">by</span> view_id <span class="keyword">asc</span>;</span><br></pre></td></tr></table></figure></p>
<p>Select only those dates based on Timeuuids that span a 2 day range<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> dateOf(view_id) <span class="keyword">from</span> course_page_views <span class="keyword">where</span> course_id = <span class="string">'nodejs-big-picture'</span></span><br><span class="line"><span class="keyword">and</span> view_id &gt;= maxTimeuuid(<span class="string">'2019-10-30 00:00+0000'</span>)</span><br><span class="line"><span class="keyword">and</span> view_id &lt; minTimeuuid(<span class="string">'2019-11-02 00:00+0000'</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">-- adjust these dates as necessary to match a more current date range</span></span><br></pre></td></tr></table></figure></p>
<p>Truncate the table, and add a static column<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">truncate</span> course_page_views;</span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> course_page_views <span class="keyword">add</span> last_view_id timeuuid <span class="keyword">static</span>;</span><br></pre></td></tr></table></figure></p>
<p>Now insert three rows, using “now()” for both Timeuuids (with TTLs)<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course_page_views (course_id, last_view_id, view_id)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>, <span class="keyword">now</span>(), <span class="keyword">now</span>()) <span class="keyword">using</span> TTL <span class="number">31536000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course_page_views (course_id, last_view_id, view_id)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>, <span class="keyword">now</span>(), <span class="keyword">now</span>()) <span class="keyword">using</span> TTL <span class="number">31536000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course_page_views (course_id, last_view_id, view_id)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'nodejs-big-picture'</span>, <span class="keyword">now</span>(), <span class="keyword">now</span>()) <span class="keyword">using</span> TTL <span class="number">31536000</span>;</span><br></pre></td></tr></table></figure></p>
<p>Selecting all rows shows different view_ids but the same last_view_id for all rows<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> course_page_views;</span><br></pre></td></tr></table></figure></p>
<p>Use ‘select distinct’ to get just the latest page view for this course<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> course_id, last_view_id <span class="keyword">from</span> course_page_views;</span><br></pre></td></tr></table></figure></p>
<p>For just one course, this can also be accomplished with the view_id and a LIMIT clause<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> course_id, view_id <span class="keyword">from</span> course_page_views <span class="keyword">where</span> course_id = <span class="string">'nodejs-big-picture'</span> <span class="keyword">limit</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure></p>
<p>However, a ‘limit’ won’t work across multiple courses.  Insert multiple views for another course.<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course_page_views (course_id, last_view_id, view_id)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'advanced-javascript'</span>, <span class="keyword">now</span>(), <span class="keyword">now</span>()) <span class="keyword">using</span> TTL <span class="number">31536000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course_page_views (course_id, last_view_id, view_id)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'advanced-javascript'</span>, <span class="keyword">now</span>(), <span class="keyword">now</span>()) <span class="keyword">using</span> TTL <span class="number">31536000</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> course_page_views (course_id, last_view_id, view_id)</span><br><span class="line"><span class="keyword">values</span> (<span class="string">'advanced-javascript'</span>, <span class="keyword">now</span>(), <span class="keyword">now</span>()) <span class="keyword">using</span> TTL <span class="number">31536000</span>;</span><br></pre></td></tr></table></figure></p>
<p>Select latest view_id from each course, using the limit clause<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> course_id, view_id <span class="keyword">from</span> course_page_views <span class="keyword">where</span> course_id = <span class="string">'nodejs-big-picture'</span> <span class="keyword">limit</span> <span class="number">1</span>;</span><br><span class="line"><span class="keyword">select</span> course_id, view_id <span class="keyword">from</span> course_page_views <span class="keyword">where</span> course_id = <span class="string">'advanced-javascript'</span> <span class="keyword">limit</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure></p>
<p>Retrieve the latest course page view for all courses with ‘select distinct’ and the static column<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="keyword">distinct</span> course_id, last_view_id <span class="keyword">from</span> course_page_views;</span><br></pre></td></tr></table></figure></p>
<p>Select all the individual views for each course, one at a time<br><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> course_id, view_id <span class="keyword">from</span> course_page_views <span class="keyword">where</span> course_id = <span class="string">'nodejs-big-picture'</span>;</span><br><span class="line"><span class="keyword">select</span> course_id, view_id <span class="keyword">from</span> course_page_views <span class="keyword">where</span> course_id = <span class="string">'advanced-javascript'</span>;</span><br></pre></td></tr></table></figure></p>
<p>课程后面的东西目前用不到，到时候再接着看。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>database</tag>
        <tag>cassandra</tag>
      </tags>
  </entry>
  <entry>
    <title>Lookup Bounded Memory Support</title>
    <url>/2018/09/18/design-pxengine-lookup/</url>
    <content><![CDATA[<h1 id="How-Does-lookup-operator-work-now"><a href="#How-Does-lookup-operator-work-now" class="headerlink" title="How Does lookup operator work now"></a>How Does lookup operator work now</h1><ol>
<li><p>Process every record that would compose to be a lookup table,  read one record at a time, and add the record to the memory (<code>may overflow here</code>). Until all the records are processed, then save the lookup table in the memory into disk. </p>
</li>
<li><p>Reads the lookup table file back to memory (<code>may overflow here</code>) to setup the hash bucket for each record (set next record offset) , then write to disk again.</p>
</li>
<li><p>Load the entire lookup table file from the disk to memory to do lookup(<code>may overflow here</code>).</p>
</li>
</ol>
<p>As we can see, there are 3 parts that will cause memory overflow, the main reason is that we load the <strong>whole</strong> lookup table into memory. </p>
<p>To solve this problem, the easy and straightforward way to do is to divide the lookup table into several parts (we call this as <code>section</code>), then process these sections accordingly.</p>
<h1 id="New-Design"><a href="#New-Design" class="headerlink" title="New Design"></a>New Design</h1><p>Let’s see the diagram to illustrate the workflow:<br><img src="https://drive.google.com/uc?id=1Dzv6L3U7TA_aqFxboe6h6mZaoH6N9UAB" alt=""></p>
<p><strong>Header</strong>: meta data about lookup table: address, offset…<br><strong>Bucket vector</strong>: speed up lookup by chaining the records to different bucket using hash. </p>
<p><img src="https://drive.google.com/uc?id=10fgUeAvzYKlp8YKlj3vjgPRypo7KUiQh" alt=""><br>Here assume we have 5 records and 2 buckets, so when we lookup record 4, after hashing, we search from bucket2, so we will only walk through record 2, skip record 1,3 and 5. Of course, the pointer is stored in each record, actually it’s an offset value.</p>
<p><strong>section file container</strong>: we fix the size of section file container in memory (can be configured by client or set by some logic according to the size of memory in client machine)</p>
<h2 id="Current-Design-to-minimize-the-memory-usage"><a href="#Current-Design-to-minimize-the-memory-usage" class="headerlink" title="Current Design to minimize the memory usage"></a>Current Design to minimize the memory usage</h2><ol>
<li><p>Set a max memory cap (section file container size).</p>
</li>
<li><p>Process each record as it got read in, add the size of the record, when the size will exceed or be the same as max memory cap, save the records that collected so far into a file (called section file, size of section file <code>&lt;=</code> max memory cap size).   </p>
</li>
<li><p>Repeat the step above until all records have been saved into section file. Therefore, one big lookup table file now has been divided into several chunks of section files.</p>
</li>
<li><p>Process the input record and use its key to get the hash bucket number, chain the records(namely add offect in placeholder left, then we need to wirte new content back to disk, need to swap section files with writing and reading operations).</p>
</li>
<li><p>when do lookup operation, hash the key and get the entry to lookup it, walk through and compare each record until find it or not, may need to read several section file from disk (now write operation).</p>
</li>
</ol>
<p>If the size of input data <code>&lt;=</code> 2 * available memory size (ignore other small overhead), we will only have 2 section files, the performance will be only corroded slightl(assume the read/write file operation is good).</p>
]]></content>
      <categories>
        <category>PXEngine</category>
      </categories>
      <tags>
        <tag>pxengine</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Runtime Capabilities</title>
    <url>/2019/05/15/docker-capability/</url>
    <content><![CDATA[<p>In my blog <a href="https://chengdol.github.io/2019/05/13/linux-capability/" target="_blank" rel="noopener"><code>&lt;&lt;Linux Capability&gt;&gt;</code></a>. I talk the basic and general knowlwdge about <code>Capability</code>. This blog will focus on Capability in Docker container.</p>
<p>In <code>docker run</code> command, there are some flags about runtime privilege and capabilities:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--cap-add: Add Linux capabilities</span><br><span class="line">--cap-drop: Drop Linux capabilities</span><br><span class="line">--privileged=false: Give extended privileges to this container</span><br><span class="line">--device=[]: Allows you to run devices inside the container without the --privileged flag.</span><br></pre></td></tr></table></figure></p>
<p>By default, Docker containers are <strong>unprivileged</strong> and cannot, for example, run a Docker daemon inside a Docker container. This is because by default a container is not allowed to access any devices (<code>/dev</code>) on host, but a “privileged” container is given access to all devices on host.</p>
<p>The <code>--privileged</code> flag gives <strong>all</strong> capabilities to the container, and it also lifts all the limitations enforced by the device cgroup controller. In other words, the container can then do almost everything that the host can do. This flag exists to allow special use-cases, like running Docker within Docker.</p>
<p>How to verify? you can run a busybox with <code>--privileged</code> enabled or not, first try enable it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --rm -it --privileged busybox sh</span><br></pre></td></tr></table></figure></p>
<p>then let’s check init process capabilities (busybox doesn’t have <code>getpcaps</code>):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat /proc/1/status | grep -i cap</span><br><span class="line"></span><br><span class="line">CapInh: 0000001fffffffff</span><br><span class="line">CapPrm: 0000001fffffffff</span><br><span class="line">CapEff: 0000001fffffffff</span><br><span class="line">CapBnd: 0000001fffffffff</span><br><span class="line">CapAmb: 0000000000000000</span><br></pre></td></tr></table></figure></p>
<p>then decode in another machine, we can see full capabilities here:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># capsh --decode=0000001fffffffff</span><br><span class="line"></span><br><span class="line">0x0000001fffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,</span><br><span class="line">cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,</span><br><span class="line">cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,</span><br><span class="line">cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,</span><br><span class="line">cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,</span><br><span class="line">cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,</span><br><span class="line">35,36</span><br></pre></td></tr></table></figure></p>
<p>if not enabled, only see default ones:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># capsh --decode=00000000a80425fb</span><br><span class="line"></span><br><span class="line">0x00000000a80425fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,</span><br><span class="line">cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,</span><br><span class="line">cap_audit_write,cap_setfcap</span><br></pre></td></tr></table></figure></p>
<p>By default, Docker has a default list of capabilities that are kept. The following table lists the Linux capability options which are allowed by default and can be dropped.</p>
<ol>
<li>SETPCAP: Modify process capabilities.</li>
<li>MKNOD: Create special files using mknod(2).</li>
<li>AUDIT_WRITE: Write records to kernel auditing log.</li>
<li>CHOWN: Make arbitrary changes to file UIDs and GIDs (see chown(2)).</li>
<li>NET_RAW: Use RAW and PACKET sockets.</li>
<li>DAC_OVERRIDE: Bypass file read, write, and execute permission checks.</li>
<li>FOWNER    Bypass: permission checks on operations that normally require the file system UID of the process to match the UID of the file.</li>
<li>FSETID: Don’t clear set-user-ID and set-group-ID permission bits when a file is modified.</li>
<li>KILL: Bypass permission checks for sending signals.</li>
<li>SETGID: Make arbitrary manipulations of process GIDs and supplementary GID list.</li>
<li>SETUID: Make arbitrary manipulations of process UIDs.</li>
<li>NET_BIND_SERVICE: Bind a socket to internet domain privileged ports (port numbers less than 1024).</li>
<li>SYS_CHROOT: Use chroot(2), change root directory.</li>
<li>SETFCAP: Set file capabilities.</li>
</ol>
<p>Further reference information is available on the <a href="http://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">capabilities(7) - Linux man page</a></p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p><a href="https://docs.docker.com/engine/reference/run/" target="_blank" rel="noopener">Docker run reference</a><br><a href="https://docs.docker.com/engine/security/security/" target="_blank" rel="noopener">Docker security</a></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>capability</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker USER Directive</title>
    <url>/2019/07/23/docker-USER/</url>
    <content><![CDATA[<p>From major security hardening items: <code>Try to explicitly set a USER/uid – to avoid even accidental startup as root</code>. This is a good point I agree. But in our case it’s impossible to use <code>USER</code> directive with non-root user in dockerfile at beginning, we need root user to install and configure services in containers, then alter the settings that cater to non-root user.</p>
<p>The solution is in the last <code>docker commit</code>, use <code>--change &#39;USER 1000&#39;</code> to set default user as non-root. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker commit --change &apos;USER 1000&apos; --change &apos;ENTRYPOINT [&quot;/opt/xx/initScripts/startcontainer.sh&quot;]&apos; -c &apos;ENV SETUPINPROGRESS &quot;&quot;&apos; $&#123;SERVICES_HOST&#125; $&#123;DOCKER_TEMPIMAGE_TAG_SERVICES&#125;:3</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that the non-root user must <strong>exist</strong> in image, if it belongs to multiple groups (one primary and several supplementaries), only specify <code>id</code> is enough.</p>
</blockquote>
<p>If later we need to run as root, just specify <code>runAsUser: 0</code> in K8s yaml or <code>--user 0</code> in <code>docker run</code> command, it will <strong>overwrite</strong> the default setting.</p>
<p>You can use <code>docker inspect</code> to check default <code>USER</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect &lt;image&gt;:&lt;tag&gt; | grep -i user</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Commit</title>
    <url>/2019/10/11/docker-commit/</url>
    <content><![CDATA[<p>When build docker images, sometimes we need to use some files to install some packages inside container, for example when build redhat docker image: <code>redhat.repo</code>, <code>entitlement/</code> and <code>rpm-gpg/</code> are needed for package installation.</p>
<p>But we don’t want to use <code>COPY</code> command in dockerfile to copy them into image, that will add layers to store them when run <code>docker build</code>, not safe. The solution is mount these files in <code>docker run</code>, after install then commit, <code>docker commit</code> <strong>will not</strong> include any data in volumes mounted inside the container.</p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## mount redhat repo and keys, install packages</span></span><br><span class="line">docker run --detach \</span><br><span class="line">  --name=serviceosbase \</span><br><span class="line">  --user 0 \</span><br><span class="line">  -v /etc/yum.repos.d/redhat.repo:/etc/yum.repos.d/redhat.repo \</span><br><span class="line">  -v /etc/pki/rpm-gpg:/etc/pki/rpm-gpg \</span><br><span class="line">  -v /etc/pki/entitlement:/etc/pki/entitlement \</span><br><span class="line">  --entrypoint=/bin/sh \</span><br><span class="line">  <span class="variable">$&#123;DOCKER_IMAGE_TAG&#125;</span>:1 \</span><br><span class="line">  -c <span class="string">'tail -f /dev/null'</span></span><br><span class="line"></span><br><span class="line">docker <span class="built_in">exec</span> serviceosbase /bin/sh -c <span class="string">"yum install -y glibc glibc-common systemd</span></span><br><span class="line"><span class="string">    systemd-libs openssl-libs &amp;&amp; yum update -y &amp;&amp; rm -rf /var/tmp/yum-* &amp;&amp; yum</span></span><br><span class="line"><span class="string">    makecache fast"</span></span><br><span class="line"></span><br><span class="line">docker commit serviceosbase <span class="variable">$&#123;DOCKER_IMAGE_TAG&#125;</span>:1</span><br></pre></td></tr></table></figure></p>
<p>You can check the layers with <code>docker history &lt;image&gt;</code> command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">IMAGE               CREATED              CREATED BY                                      SIZE                COMMENT</span><br><span class="line">1f6e112efb83        About a minute ago   /bin/sh -c <span class="comment">#(nop)  ENV LANG=en_US.UTF-8 LANGU   0 B</span></span><br><span class="line">6060bfb14056        About a minute ago   /bin/sh -c rm /etc/yum.repos.d/ubi.repo &amp;&amp;      10.83 MB</span><br><span class="line">543fa76542de        2 minutes ago        /bin/sh -c <span class="comment">#(nop)  MAINTAINER XXX               0 B</span></span><br><span class="line">6558c4297a5d        2 minutes ago        /bin/sh -c <span class="comment">#(nop)  LABEL name=IIS Services ve   0 B</span></span><br><span class="line">6fecccc91c83        5 weeks ago                                                          7.06 kB</span><br><span class="line">&lt;missing&gt;           5 weeks ago                                                          204.8 MB            Imported from -</span><br></pre></td></tr></table></figure></p>
<p>Compare with dockerfile, no layer is for mount data after commit.</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>System Design</title>
    <url>/2019/11/29/design-system/</url>
    <content><![CDATA[<p>This blog is for system design, please revisit frequently to refresh. The notes are mainly from <code>https://www.educative.io/</code> and Youtube channel.</p>
<p>有的系统设计主要是各功能部件合理组合:</p>
<ol>
<li>Design Instagarm</li>
<li>Design Dropbox</li>
<li>Design Twitter<br>post tweets(photos, videos), follow others, favorite tweets<br>generate timeline of top tweets<br>low latancy<br>highly available<br>consistency can take a hit</li>
</ol>
<p>storage: text + photo + video<br>ingress (write): new generated storage / sec<br>egress (read): read volume / sec</p>
<p>read heavy system<br>data sharding: user id -&gt; tweet id -&gt; (creation time + tweet id, sort by time)<br>query all servers and aggregate</p>
<p>cache for hot users and tweets</p>
<ol start="4">
<li>Designing Twitter Search</li>
<li><p>Designing a Web Crawler (BFS, modular, url frontier, DNS, fetcher, DIS, content filter, extractor, url filter)</p>
</li>
<li><p>Designing Facebook Messenger<br>each chat server serves a bunch of users, LB maps user to it’s chat server, chat server commuicate with each other to send/receive message<br>message handling: long polling to receive message<br>hashtable keep track of online user, if offline, notify delivery failure to sender<br>handle message order: 单独靠timestamp不行，use sequence number with every message for each user</p>
</li>
</ol>
<p>database: support high frequence write/read row, quick small updates, range based search: HBase, column-oriented key-value NoSQL database<br>partition by UserID, low latency</p>
<p>有的主要涉及到了数据结构和算法:</p>
<ol>
<li>Typeahead suggestion (trie, reference)</li>
<li>API rate limiter (dynamic sliding window)</li>
<li><p>Designing Facebook’s Newsfeed (offline feed generation)<br>contain updates, posts, video, photos from all people user follows<br>user average has 200 followers, 300M DAU, fetch 5 times a day, 1KB each post, so can get traffic.<br>cache each users’ news feed in mem for quick fetch.<br>feed generation:<br>retrieve, rank, store<br>offline generate by dedicated servers, <code>Map&lt;UserID, LikedHashMap/TreeMap&lt;PostID, PostItem&gt;&gt; + LastGenerateTime</code> in memory, LRU cache for user or find user’s activity pattern to help generate newsfeed<br>feed publishing:<br>push to notify, pull for serving</p>
</li>
<li><p>Designing Yelp (querying, objects don’t change often, QuadTree)<br>解释一下我的理解，这里partition讲的是partition quadtree.<br>从DB中读location id, 通过hashing map to different quadtree server (这个mapping其实就是quadtree index，可以在quadtree server fail后用来重新构造它的数据)，然后各自构造自己的quadtree.这些quadtree servers有一个aggregator server（它有自己的copies）。于是每次request要去所有quadtree server查询，然后聚合返回的数据。对于每个quadtree server，它所包含的location id也有一个本地的mapping, to know which DB servers contains this locatio id info. 这个mapping也使用的hashing实现。</p>
</li>
<li><p>Designing Uber backend (requirements, objects do change often, QuadTree)</p>
</li>
<li>Design Ticketmaster (first come first serve, highly concurrent, financial transactions ACID)</li>
</ol>
<h1 id="CAP-Theorem"><a href="#CAP-Theorem" class="headerlink" title="CAP Theorem"></a>CAP Theorem</h1><p>CAP theorem states that it is impossible for a distributed software system to simultaneously provide more than two out of three of the following guarantees (CAP): <code>Consistency</code>, <code>Availability</code>, and <code>Partition tolerance</code>.</p>
<p>When we design a distributed system, trading off among <code>CAP</code> is almost the first thing we want to consider.</p>
<h1 id="Thinking-process"><a href="#Thinking-process" class="headerlink" title="Thinking process"></a>Thinking process</h1><ol>
<li>requirements clarification</li>
<li>back of the envelope estimation: scale, storate, bandwidth.</li>
<li>system interface definition</li>
<li>defining data model</li>
<li>high level design</li>
<li>detailed design</li>
<li>identifying and resolving bottlenecks</li>
</ol>
<h1 id="Crucial-Components"><a href="#Crucial-Components" class="headerlink" title="Crucial Components"></a>Crucial Components</h1><p>这里的笔记主要根据以下几点展开:</p>
<ol>
<li>Database (book: 7 weeks 7 databases)</li>
<li>Cache system (redis, memcache)</li>
<li>Message queue (kafka &amp;&amp; zookeeper or others)</li>
<li>Load balancer (nginx, Round Robin approach)</li>
<li>Log systems</li>
<li>monitor system</li>
<li>My domain of knowledge k8s, docker, micro-services</li>
</ol>
<h1 id="Key-Characteristics-of-Distributed-Systems"><a href="#Key-Characteristics-of-Distributed-Systems" class="headerlink" title="Key Characteristics of Distributed Systems"></a>Key Characteristics of Distributed Systems</h1><p>Scalability: scaling without performance loss (but actually will).<br>Reliability: keep delivering services when some components fail.<br>Availability: reliable means available, but not vice versa<br>Efficiency: latency and (throughput)bandwidth.<br>Manageability: ease of diagnosing and understanding problems when they occur.</p>
<h1 id="常用技术知识"><a href="#常用技术知识" class="headerlink" title="常用技术知识"></a>常用技术知识</h1><h2 id="备份的说法"><a href="#备份的说法" class="headerlink" title="备份的说法:"></a>备份的说法:</h2><p>Standby replicas<br>Failover to other healthy copies<br>Duplicates<br>Backup (spare)<br>Redundancy (redundant secondary copy)</p>
<h2 id="NoSQL-Database"><a href="#NoSQL-Database" class="headerlink" title="NoSQL Database:"></a>NoSQL Database:</h2><p><a href="https://www.youtube.com/watch?v=uD3p_rZPBUQ" target="_blank" rel="noopener">An Introduction To NoSQL Databases</a><br><strong>Big Data</strong>: social network, search engine, traditional methods of processing and storage are inadequate.</p>
<ol>
<li>Key-value stores: Redis, Dynamo (redis can also be cache)</li>
<li>Document database: MongoDB, Couchbase</li>
<li><a href="https://www.youtube.com/watch?v=8KGVFB3kVHQ" target="_blank" rel="noopener">Wide-column database</a>: Cassandra, HBase</li>
<li>Graph database: Neo4J</li>
</ol>
<p>Advantage of NOSQL database：<br>no data models(no pre-defind schema), unstructed , easy to scale up and down (horizontal data sharding), high performance with big data.</p>
<p>Advantage of SQL database:<br>relational data, normalization (eliminate redundancy), SQL, data integrity, ACID compliance.</p>
<h2 id="Consistent-Hashing-with-virtual-replicas"><a href="#Consistent-Hashing-with-virtual-replicas" class="headerlink" title="Consistent Hashing (with virtual replicas)"></a>Consistent Hashing (with virtual replicas)</h2><p><a href="https://www.youtube.com/watch?v=ffE1mQWxyKM" target="_blank" rel="noopener">https://www.youtube.com/watch?v=ffE1mQWxyKM</a><br>Using hash <code>mod</code> strategy is not efficient, think about that add a new server, then original 20 % 3 = 2 now is 20 % 4 = 0. We have to <strong>re-organize</strong> all the existing mappings.</p>
<p><a href="https://www.youtube.com/watch?v=zaRkONvyGr8" target="_blank" rel="noopener">https://www.youtube.com/watch?v=zaRkONvyGr8</a><br>Consistent hashing can be used in many situations, like distributed cache, load balancing, database, etc.</p>
<p>For example, we have <code>n</code> servers.<br>Hash the request and get the location of it in the <code>ring</code>, find the server with hash value equal or larger than it and send this request to that server (clockwise move). But server may not distributed in ring evenly or the requests is not uniformly (thus server load factor is not <code>1/n</code>), so we can use <strong>virtual replicas</strong>, this can implement by other hash function.</p>
<p>With contsistent hashing, add or remove servers will not cause much overhead. The new added server will grab objects from its near servers and removed server, all original objects will move to next server after the removed one.</p>
<h2 id="Long-Polling-轮询"><a href="#Long-Polling-轮询" class="headerlink" title="Long Polling (轮询)"></a>Long Polling (轮询)</h2><p><a href="https://www.jianshu.com/p/d3f66b1eb748?from=timeline&amp;isappinstalled=0" target="_blank" rel="noopener">https://www.jianshu.com/p/d3f66b1eb748?from=timeline&amp;isappinstalled=0</a><br>和一般的polling都属于pull(拉模式)。</p>
<blockquote>
<p>题外话: push模式其实也是建立了一个持久的connection，但server一旦有新的信息就会push给client，而不会去在乎client的处理能力，这是一个缺点, long polling对于client要更灵活一些（因为client会request first）。</p>
</blockquote>
<p>This is a variation of the traditional polling technique that allows the server to push information to a client whenever the data is available. With Long-Polling, the client requests information from the server exactly as in normal polling, but with the expectation that the server may not respond immediately (keep the connection connected). That’s why this technique is sometimes referred to as a <code>Hanging GET</code>.</p>
<p>Each Long-Poll request has a <code>timeout</code>. The client has to reconnect periodically after the connection is closed due to timeouts or receive the disconnect from server.</p>
<p>如果client突然unavailable了，如何检测呢？这个connection是如何保持的？我猜想的是connection保持期间，并不需要额外的sync查看server client是否健在(我记得TCP有一个机制会检测这个connection是否健康？)。如果server 发送了message未收到acknowledge则说明client不在了，则connection中断。</p>
<h2 id="Data-Sharding"><a href="#Data-Sharding" class="headerlink" title="Data Sharding"></a>Data Sharding</h2><p><a href="https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6" target="_blank" rel="noopener">https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6</a><br><code>Horizontal partitioning</code> is also called as Data Sharding</p>
<h2 id="Web-Server-vs-Application-Server"><a href="#Web-Server-vs-Application-Server" class="headerlink" title="Web Server vs Application Server"></a>Web Server vs Application Server</h2><p><a href="https://stackoverflow.com/questions/936197/what-is-the-difference-between-application-server-and-web-server" target="_blank" rel="noopener">https://stackoverflow.com/questions/936197/what-is-the-difference-between-application-server-and-web-server</a></p>
<h2 id="proxy-server"><a href="#proxy-server" class="headerlink" title="proxy server"></a>proxy server</h2><p><a href="https://www.educative.io/courses/grokking-the-system-design-interview/N8G9MvM4OR2" target="_blank" rel="noopener">https://www.educative.io/courses/grokking-the-system-design-interview/N8G9MvM4OR2</a><br>A proxy server is an intermediate server between the client and the back-end server.</p>
<p>Typically, proxies are used to filter requests, log requests, or sometimes transform requests (by adding/removing headers, encrypting/decrypting, or compressing a resource). Another advantage of a proxy server is that its cache can serve a lot of requests.</p>
<ol>
<li>open (forwarding) proxy: hide clients</li>
<li>reverse proxy: hide servers</li>
</ol>
<h2 id="Map-Reduce"><a href="#Map-Reduce" class="headerlink" title="Map Reduce"></a>Map Reduce</h2><p>We can have a Map-Reduce (MR) set-up These MR jobs will calculate frequencies of all searched terms in the past hour.</p>
<h2 id="Exponential-Moving-Average-EMA"><a href="#Exponential-Moving-Average-EMA" class="headerlink" title="Exponential Moving Average (EMA)"></a>Exponential Moving Average (EMA)</h2><p>In EMA, we give more weight to the latest data. It’s also known as the exponentially weighted moving average.</p>
<h1 id="Some-Design-Bottlenecks"><a href="#Some-Design-Bottlenecks" class="headerlink" title="Some Design Bottlenecks"></a>Some Design Bottlenecks</h1><ol>
<li><p>data compression 需要吗, 如何选择？</p>
</li>
<li><p>capacity estimation: metadata + content 两方面都要考虑，high level estimations 主要包括: storage for each day, storage for years, incoming bandwidth, outgoing bandwidth. 这些主要来自于: Total user, Daily active user (DAU), size of each request, how many entries each user produce, data growth, 有时对某个量单独估计比较好。</p>
</li>
<li><p>read heavy or wirte heavy? bandwidth, ingress: 每日新增数据总量/秒; egress: 用户浏览或下载总量/秒.</p>
</li>
<li>database需要有哪些符合场景的特点? 比如quick small updates, ACID, range based search, etc.</li>
<li>how about consider the peak time read and wirte throughput.</li>
<li><p>hot user in database handle, 怎么设计database去减轻这个问题.</p>
</li>
<li><p>we may need aggregator server for fetching and process data from different DB or caches.</p>
</li>
<li><p>monitoring system, collect metrics: daily peak, latency.  we will realize if we need more replication, load balancing, or caching.</p>
</li>
<li><p>load balancer can sit: between client and web server, web server and application server (or cahce), application server and database. load balancer can be single point of failure, need redundancy to take over when main is down.</p>
</li>
<li><p>load balancer: Round Robin approach, or more intelligent.</p>
</li>
<li><p>cache policy, LRU, 80-20 rule.</p>
</li>
</ol>
<h1 id="Other-System-Design-Videos"><a href="#Other-System-Design-Videos" class="headerlink" title="Other System Design Videos:"></a>Other System Design Videos:</h1><h2 id="Introduce-to-System-Design"><a href="#Introduce-to-System-Design" class="headerlink" title="Introduce to System Design"></a>Introduce to System Design</h2><p><a href="https://www.youtube.com/watch?v=UzLMhqg3_Wc&amp;list=PLrmLmBdmIlps7GJJWW9I7N0P0rB0C3eY2" target="_blank" rel="noopener">Introduce to System Design</a><br>同样推荐了这本书<code>&lt;&lt;Designing Data Intensive Applications&gt;&gt;</code>, 会对这些topics有更深入的讲解。</p>
<ol>
<li>ask good question:<br>which features care about, which not?<br>how much to scale (data, request, latency)</li>
<li>don’t use buzzword (be clear about the tech you use)</li>
<li>clear and organized thinking</li>
<li>drive discussion (80% I talk)</li>
</ol>
<p><strong>Things to consider</strong>:</p>
<ol>
<li>Features</li>
<li>API</li>
<li>Availability</li>
<li>Latency</li>
<li>Scalability</li>
<li>Durability</li>
<li>Class Diagram</li>
<li>Security and Privacy</li>
<li>Cost-effective</li>
</ol>
<p><strong>Concepts to know</strong>:</p>
<ol>
<li>Vertical vs horizontal scaling</li>
<li>CAP theorem</li>
<li>ACID vs BASE</li>
<li>Partitioning/Sharding </li>
<li>Consistent Hashing</li>
<li>Optimistic vs pessimistic locking</li>
<li>Strong vs eventual consistency</li>
<li>RelationalDB vs NoSQL</li>
<li>Types of NoSQL<br>  Key value<br>  Wide column<br>  Document-based<br>  Graph-based</li>
<li>Caching</li>
<li>Data center/racks/hosts</li>
<li>CPU/memory/Hard drives/Network bandwidth</li>
<li>Random vs sequential read/writes to disk</li>
<li>HTTP vs http2 vs WebSocket</li>
<li>TCP/IP model</li>
<li>ipv4 vs ipv6</li>
<li>TCP vs UDP</li>
<li>DNS lookup</li>
<li>Http &amp; TLS</li>
<li>Public key infrastructure and certificate authority(CA)</li>
<li>Symmetric vs asymmetric encryption</li>
<li>Load Balancer</li>
<li>CDNs &amp; Edges</li>
<li>Bloom filters and Count-Min sketch</li>
<li>Paxos </li>
<li>Leader election</li>
<li>Design patterns and Object-oriented design</li>
<li>Virtual machines and containers</li>
<li>Pub-sub architecture </li>
<li>MapReduce</li>
<li>Multithreading, locks, synchronization, CAS(compare and set)</li>
</ol>
<p><strong>Tools</strong>:</p>
<ol>
<li>Cassandra</li>
<li>MongoDB/Couchbase</li>
<li>Mysql</li>
<li>Memcached</li>
<li>Redis</li>
<li>Zookeeper</li>
<li>Kafka</li>
<li>NGINX</li>
<li>HAProxy</li>
<li>Solr, Elastic search</li>
<li>Amazon S3</li>
<li>Docker, Kubernetes, Mesos</li>
<li>Hadoop/Spark and HDFS</li>
</ol>
<h2 id="Design-Spotify-Apple-Muisc-Youtube-Music"><a href="#Design-Spotify-Apple-Muisc-Youtube-Music" class="headerlink" title="Design Spotify| Apple Muisc | Youtube Music"></a>Design Spotify| Apple Muisc | Youtube Music</h2><p><a href="https://www.youtube.com/watch?v=ks-CS41AiQs" target="_blank" rel="noopener">Design Spotify| Apple Muisc | Youtube Music</a></p>
<ol>
<li>scope: cover and what else you are not going to cover</li>
<li>key components (具体分析了一下spotify工作的过程，比如存储，传输protocol转换，low latency, CDN)</li>
<li>data model</li>
<li>scaling</li>
</ol>
<p>if data size is high, consider compress audio data<br>quality, user use different device and network condition<br>distribution CDN</p>
<p>scaling group 比如一些stateless servers可以使用k8s, containers去管理。</p>
]]></content>
      <categories>
        <category>System Design</category>
      </categories>
      <tags>
        <tag>system design</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Compose Quick Start</title>
    <url>/2020/09/01/docker-compose-learn/</url>
    <content><![CDATA[<p><strong>Docker Compose vs Docker Swarm</strong><br>The difference lies mostly in the backend, where docker-compose deploys container on a <strong>single</strong> Docker host, Docker Swarm deploys it across <strong>multiple nodes</strong>.</p>
<p>现在想想，当时组员在本地搭建DataStage也应该用docker compose, it is especially good for web development:</p>
<ul>
<li>accelerate onboarding</li>
<li>eliminate app conflicts</li>
<li>environment consistency</li>
<li>ship software faster</li>
</ul>
<h1 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h1><p><a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener">https://docs.docker.com/compose/install/</a><br>For Mac docker-compose is self-contained with Docker desktop:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## check location</span></span><br><span class="line"><span class="built_in">which</span> docker-compose</span><br><span class="line"><span class="comment">## show version</span></span><br><span class="line">docker-compose version</span><br></pre></td></tr></table></figure></p>
<p>For Linux, first install <code>Docker Engine</code>, then download docker-compose to executable path:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 1.26.2 is current stable version</span></span><br><span class="line">sudo curl -L <span class="string">"https://github.com/docker/compose/releases/download/1.26.2/docker-compose-<span class="variable">$(uname -s)</span>-<span class="variable">$(uname -m)</span>"</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line">sudo chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br></pre></td></tr></table></figure></p>
<p>or download binary from github release directly:<br><a href="https://github.com/docker/compose/releases" target="_blank" rel="noopener">https://github.com/docker/compose/releases</a></p>
<p>Uninstall docker-compose, remove binary:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo rm -f /usr/local/bin/docker-compose</span><br></pre></td></tr></table></figure></p>
<h1 id="Getting-Started"><a href="#Getting-Started" class="headerlink" title="Getting Started"></a>Getting Started</h1><p><a href="https://docs.docker.com/compose/gettingstarted/" target="_blank" rel="noopener">https://docs.docker.com/compose/gettingstarted/</a><br>If you know how to write yaml file for Kubernetes, then quick easy to understand the <code>docker-compose.yml</code>.</p>
<p>Some basic commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## build or rebuild service images</span></span><br><span class="line"><span class="comment">## if not specify service name, will build all images</span></span><br><span class="line">docker-compose build [--no-cache] [service name]</span><br><span class="line"></span><br><span class="line"><span class="comment">## run services</span></span><br><span class="line"><span class="comment">## will build images if not yet</span></span><br><span class="line"><span class="comment">## -d: detch</span></span><br><span class="line"><span class="comment">## --no-deps: just bring up specified service</span></span><br><span class="line">docker-compose up [-d | --no-deps] [service name]</span><br><span class="line"></span><br><span class="line"><span class="comment">## check logs</span></span><br><span class="line">docker-compose logs [-f] &lt;service name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## see what is running</span></span><br><span class="line">docker-compose ps</span><br><span class="line"></span><br><span class="line"><span class="comment">## one-off command in container</span></span><br><span class="line">docker-compose run &lt;service name&gt; &lt;commands&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## start/stop service, will not remove container</span></span><br><span class="line">docker-compose start</span><br><span class="line">docker-compose stop</span><br><span class="line"></span><br><span class="line"><span class="comment">## remove stopped containers</span></span><br><span class="line">docker-compose rm [service name]</span><br><span class="line"></span><br><span class="line"><span class="comment">## shutdown, similar to docker rm -f ...</span></span><br><span class="line"><span class="comment">## -v,--volumes: remove the mounted data volume</span></span><br><span class="line"><span class="comment">## --rmi all: remove all images</span></span><br><span class="line">docker-compose down [-v] [--rmi all]</span><br></pre></td></tr></table></figure></p>
<h2 id="Command-Completion"><a href="#Command-Completion" class="headerlink" title="Command Completion"></a>Command Completion</h2><p><a href="https://docs.docker.com/compose/completion/#install-command-completion" target="_blank" rel="noopener">https://docs.docker.com/compose/completion/#install-command-completion</a><br>for oh-my-zsh, add <code>docker</code> and <code>docker-compose</code> to plugins list in <code>~/.zshrc</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">plugins=(... docker docker-compose)</span><br></pre></td></tr></table></figure></p>
<h2 id="Config-File"><a href="#Config-File" class="headerlink" title="Config File"></a>Config File</h2><p>遇到没见过的指令，查阅这里:<br><a href="https://docs.docker.com/compose/compose-file/" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/</a></p>
<p>Define services relationship in <code>docker-compose.yml</code> file.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## docker-compose.yml can parse env variables in current running environment</span></span><br><span class="line"><span class="comment">## 通过这些环境变量控制读取的文件类型,比如development, staging, production</span></span><br><span class="line"><span class="comment">## export APP_ENV=development</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 这里假设下面的文件夹和文件都存在，比如dockerfile 等等</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## docker-compuse version</span></span><br><span class="line"><span class="attr">version:</span> <span class="string">"3.7"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  web:</span></span><br><span class="line"><span class="attr">    container_name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">    build:</span></span><br><span class="line">      <span class="comment">## relative path is base on docker-compose.yml directory</span></span><br><span class="line">      <span class="comment">## can be url</span></span><br><span class="line"><span class="attr">      context:</span> <span class="string">.</span></span><br><span class="line">      <span class="comment">## args used in dockerfile, must declaure using ARG in dockerfile</span></span><br><span class="line">      <span class="comment">## only seen in build process!</span></span><br><span class="line"><span class="attr">      args:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">buildno=1</span></span><br><span class="line">      <span class="comment">## relative path to context</span></span><br><span class="line"><span class="attr">      dockerfile:</span> <span class="string">./web/web.dockerfile</span></span><br><span class="line">    <span class="comment">## specify built image and tag</span></span><br><span class="line">    <span class="comment">## if no image here, docker-compose will use it's name convension</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">webapp:v1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">## dependencies</span></span><br><span class="line">    <span class="comment">## docker-compose will start mongo and redis first</span></span><br><span class="line"><span class="attr">    depends_on:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">mongo</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">redis</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## host: container</span></span><br><span class="line">    <span class="comment">## 外界访问采用host port</span></span><br><span class="line">    <span class="comment">## container 之间互相访问port 不用在这里expose</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"80:80"</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"443:443"</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"9090-9100:8080-8100"</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">## add env vars from a file</span></span><br><span class="line"><span class="attr">    env_file:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">web.env/app.$&#123;APP_ENV&#125;.env</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">/opt/runtime_opts.env</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">## other form of env vars</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="attr">      RACK_ENV:</span> <span class="string">development</span></span><br><span class="line">      <span class="comment">## boolean muct be quoted</span></span><br><span class="line"><span class="attr">      SHOW:</span> <span class="string">'true'</span></span><br><span class="line">      <span class="comment">## value is from current running environment</span></span><br><span class="line"><span class="attr">      SESSION_SECRET:</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## short syntax</span></span><br><span class="line">    <span class="comment">## https://docs.docker.com/compose/compose-file/#short-syntax-3</span></span><br><span class="line"><span class="attr">    volumes:</span></span><br><span class="line">    <span class="comment">## host path, relative to docker-compose.yml</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"./web:/opt/web"</span></span><br><span class="line">    <span class="comment">## named volume</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"mydata:/opt/data"</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## overwrite WORKDIR in Dockerfile</span></span><br><span class="line"><span class="attr">    working_dir:</span> <span class="string">/opt/web</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## containers in the same network are reachable by others</span></span><br><span class="line"><span class="attr">    networks:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">nodeapp-network</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">  mongo:</span></span><br><span class="line"><span class="attr">    container_name:</span> <span class="string">mongo</span></span><br><span class="line"><span class="attr">    build:</span></span><br><span class="line"><span class="attr">      context:</span> <span class="string">.</span></span><br><span class="line"><span class="attr">      dockerfile:</span> <span class="string">mongo/mongo-dockerfile</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"27017"</span></span><br><span class="line"><span class="attr">    env_file:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">mongo.env/mongo.$&#123;APP_ENV&#125;.env</span></span><br><span class="line"><span class="attr">    networks:</span></span><br><span class="line"><span class="attr">     nodeapp-network:</span></span><br><span class="line">       <span class="comment">## can be accessed by `mongo` or `db` in nodeapp-network</span></span><br><span class="line"><span class="attr">       aliases:</span></span><br><span class="line"><span class="bullet">         -</span> <span class="string">db</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  redis:</span></span><br><span class="line"><span class="attr">    container_name:</span> <span class="string">redis</span></span><br><span class="line">    <span class="comment">## pull image from other places</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">redis:latest</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## long syntax</span></span><br><span class="line">    <span class="comment">## https://docs.docker.com/compose/compose-file/#long-syntax-3</span></span><br><span class="line"><span class="attr">    volumes:</span></span><br><span class="line"><span class="attr">    - type:</span> <span class="string">volume</span></span><br><span class="line"><span class="attr">      source:</span> <span class="string">dbdata</span></span><br><span class="line"><span class="attr">      target:</span> <span class="string">/data</span></span><br><span class="line"><span class="attr">      volume:</span></span><br><span class="line"><span class="attr">        nocopy:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">"6379"</span></span><br><span class="line"><span class="attr">    env_file:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">redis.env/redis.$&#123;APP_ENV&#125;.env</span></span><br><span class="line"><span class="attr">    networks:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">nodeapp-network</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line"><span class="attr"> nodeapp-network:</span></span><br><span class="line">   <span class="comment">## docker defaults to use bridge driver in single host</span></span><br><span class="line"><span class="attr">   driver:</span> <span class="string">bridge</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## named volumes</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="comment">## default use 'local' driver</span></span><br><span class="line"><span class="attr">  mydata:</span></span><br><span class="line"><span class="attr">  dbdata:</span></span><br></pre></td></tr></table></figure></p>
<p>More about environement variables:<br>By default, the docker-compose command will look for a file named <code>.env</code> in the directory you run the command. By passing the file as an argument, you can store it anywhere and name it appropriately, for example, <code>.env.ci</code>, <code>.env.dev</code>, <code>.env.prod</code>. Passing the file path is done using the <code>--env-file</code> option:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker-compose --env-file ./config/.env.dev up</span><br></pre></td></tr></table></figure></p>
<p><code>.env</code> contains <code>key=value</code> format equaltions.</p>
<h2 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h2><p>Image is set of read-only layers (shared), whereas container has its unique thin read write layer but it is ephemeral.</p>
<p>关于storage的讲解:<br><a href="https://docs.docker.com/storage/" target="_blank" rel="noopener">https://docs.docker.com/storage/</a><br>这里主要弄清楚volumes, bind mounts and tmpfs的区别和使用:</p>
<p>如果docker host的文件系统和docker container使用的不一样，bind mounts如何处理呢?<br>并且内外user, group都不一样，如果在docker container中新建一个文件，bind mounts 在host中如何映射呢?</p>
<p><strong>Docker Compose Volume:</strong><br><a href="https://docs.docker.com/compose/compose-file/#volumes" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/#volumes</a><br>这里讲了如何mount host path or named volumes.</p>
<h3 id="Volumes"><a href="#Volumes" class="headerlink" title="Volumes"></a>Volumes</h3><p><a href="https://docs.docker.com/storage/volumes/" target="_blank" rel="noopener">https://docs.docker.com/storage/volumes/</a><br>类似于K8s的volume claim, general preferred.</p>
<p>Stored in a part of the host filesystem which is managed by Docker (<code>/var/lib/docker/volumes/</code> on Linux). Non-Docker processes should not modify this part of the filesystem. Volumes are the best way to persist data in Docker.</p>
<p>A given volume can be mounted into multiple containers simultaneously. When no running container is using a volume, the volume is still available to Docker and is not removed automatically. </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker volume create &lt;volume name&gt;</span><br><span class="line">docker volume ls</span><br><span class="line">docker volume rm &lt;volume name&gt;</span><br><span class="line">docker volume inspect</span><br><span class="line"><span class="comment">## remove unused volumes</span></span><br><span class="line">docker volume prune</span><br></pre></td></tr></table></figure>
<p>When you mount a volume, it may be named or anonymous.</p>
<p>Volumes also support the use of volume drivers, which allow you to store your data on remote hosts or cloud providers, among other possibilities.</p>
<p>If you need to specify volume driver options, you must use <code>--mount</code>, <code>-v</code> 的表示比较局限, 这里只是一个简单的例子, 实际上用<code>--mount</code>的配置选项很多:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## docker will create volume myvol2 automatically if it does exist</span></span><br><span class="line">docker run -d \</span><br><span class="line">  --name devtest \</span><br><span class="line">  -v myvol2:/app[:ro] \</span><br><span class="line">  nginx:latest</span><br><span class="line"></span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">docker run -d \</span><br><span class="line">  --name devtest \</span><br><span class="line">  --mount <span class="built_in">source</span>=myvol2,target=/app[,<span class="built_in">readonly</span>] \</span><br><span class="line">  nginx:latest</span><br></pre></td></tr></table></figure></p>
<p>If the container has files or directories in the directory to be mounted (such as <code>/app/</code> above), the directory’s contents are copied into the volume, other containers which use the volume also have access to the pre-populated content.</p>
<h3 id="Bind-Mounts"><a href="#Bind-Mounts" class="headerlink" title="Bind Mounts"></a>Bind Mounts</h3><p><a href="https://docs.docker.com/storage/bind-mounts/" target="_blank" rel="noopener">https://docs.docker.com/storage/bind-mounts/</a><br>类似于K8s的hostpath, use case for example, mount source code for development.</p>
<p>May be stored anywhere on the host system. They may even be important system files or directories. Non-Docker processes on the Docker host or a Docker container can modify them at any time.</p>
<p>The file or directory does not need to exist on the Docker host already. It is created on demand if it does not yet exist.</p>
<p>Bind mounts are very performant, but they rely on the host machine’s filesystem having a specific directory structure available.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  -it \</span><br><span class="line">  --name devtest \</span><br><span class="line">  -v <span class="string">"<span class="variable">$(pwd)</span>"</span>/target:/app[:ro] \</span><br><span class="line">  nginx:latest</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">docker run -d \</span><br><span class="line">  -it \</span><br><span class="line">  --name devtest \</span><br><span class="line">  --mount <span class="built_in">type</span>=<span class="built_in">bind</span>,<span class="built_in">source</span>=<span class="string">"<span class="variable">$(pwd)</span>"</span>/target,target=/app[,<span class="built_in">readonly</span>] \</span><br><span class="line">  nginx:latest</span><br><span class="line"></span><br><span class="line"><span class="comment">## check Mounts section</span></span><br><span class="line">docker inspect devtest</span><br></pre></td></tr></table></figure>
<p>If you bind-mount into a non-empty directory on the container, the directory’s existing contents are obscured by the bind mount.</p>
<h3 id="tmpfs"><a href="#tmpfs" class="headerlink" title="tmpfs"></a>tmpfs</h3><p><a href="https://docs.docker.com/storage/tmpfs/" target="_blank" rel="noopener">https://docs.docker.com/storage/tmpfs/</a><br>Only Linux has this option, useful to temporarily store sensitive files.<br>Stored in the host system’s memory only, and are never written to the host system’s filesystem.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  -it \</span><br><span class="line">  --name tmptest \</span><br><span class="line">  --tmpfs /app \</span><br><span class="line">  nginx:latest</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">docker run -d \</span><br><span class="line">  -it \</span><br><span class="line">  --name tmptest \</span><br><span class="line">  --mount <span class="built_in">type</span>=tmpfs,destination=/app,tmpfs-mode=1770,tmpfs-size=1024 \</span><br><span class="line">  nginx:latest</span><br></pre></td></tr></table></figure>
<h2 id="Network"><a href="#Network" class="headerlink" title="Network"></a>Network</h2><p>这个章节讲到了所有docker network的类型，作用，区别:<br><a href="https://docs.docker.com/network/" target="_blank" rel="noopener">https://docs.docker.com/network/</a></p>
<p>Docker network labs:<br><a href="https://github.com/docker/labs/tree/master/networking" target="_blank" rel="noopener">https://github.com/docker/labs/tree/master/networking</a></p>
<p>From docker’s perspective, Steps to create a container network:</p>
<ol>
<li><p>create a custom bridge network</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create a bridge network isolated_network</span></span><br><span class="line">docker network create --driver bridge isolated_network</span><br><span class="line"></span><br><span class="line"><span class="comment">## see created network, the driver is bridge</span></span><br><span class="line"><span class="comment">## you can see host and none are there</span></span><br><span class="line">docker network ls</span><br><span class="line"></span><br><span class="line"><span class="comment">## inspect </span></span><br><span class="line">docker network inspect isolated_network</span><br></pre></td></tr></table></figure>
</li>
<li><p>run containers in the network and ping each other by container name</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create 2 busybox in the same network</span></span><br><span class="line">docker run -d --name=test1  --net=isolated_network --entrypoint=/bin/sh busybox -c <span class="string">"tail -f /dev/null"</span></span><br><span class="line">docker run -d --name=test2  --net=isolated_network --entrypoint=/bin/sh busybox -c <span class="string">"tail -f /dev/null"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## you can see containers in this network</span></span><br><span class="line">docker network inspect isolated_network</span><br><span class="line"></span><br><span class="line"><span class="comment">## ping each other</span></span><br><span class="line">docker <span class="built_in">exec</span> test1 ping -c 5 test2</span><br><span class="line">docker <span class="built_in">exec</span> test2 ping -c 5 test1</span><br></pre></td></tr></table></figure>
</li>
<li><p>remove network created</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker network rm isolated_network</span><br><span class="line">docker network ls</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>同样的思路，可以用docker command查看docker-compose中建立的network的信息。</p>
<p>列出了docker compose中top-level networks 创建时的options, after creating top-level networks, they can be referenced by service-level to use:<br><a href="https://docs.docker.com/compose/compose-file/#network-configuration-reference" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/#network-configuration-reference</a></p>
<p>这篇文章说得很明白, docker compose中network是如何作为的:<br><a href="https://docs.docker.com/compose/networking/" target="_blank" rel="noopener">https://docs.docker.com/compose/networking/</a></p>
<p>这个例子很有意思，把frontend, backend的网络分开了, only app can reach both networks:<br><a href="https://docs.docker.com/compose/networking/#specify-custom-networks" target="_blank" rel="noopener">https://docs.docker.com/compose/networking/#specify-custom-networks</a><br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">"3"</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  proxy:</span></span><br><span class="line"><span class="attr">    build:</span> <span class="string">./proxy</span></span><br><span class="line"><span class="attr">    networks:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">  app:</span></span><br><span class="line"><span class="attr">    build:</span> <span class="string">./app</span></span><br><span class="line"><span class="attr">    networks:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">frontend</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">backend</span></span><br><span class="line"><span class="attr">  db:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">postgres</span></span><br><span class="line"><span class="attr">    networks:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">backend</span></span><br><span class="line"></span><br><span class="line"><span class="attr">networks:</span></span><br><span class="line"><span class="attr">  frontend:</span></span><br><span class="line">    <span class="comment"># Use a custom driver</span></span><br><span class="line"><span class="attr">    driver:</span> <span class="string">custom-driver-1</span></span><br><span class="line"><span class="attr">  backend:</span></span><br><span class="line">    <span class="comment"># Use a custom driver which takes special options</span></span><br><span class="line"><span class="attr">    driver:</span> <span class="string">custom-driver-2</span></span><br><span class="line"><span class="attr">    driver_opts:</span></span><br><span class="line"><span class="attr">      foo:</span> <span class="string">"1"</span></span><br><span class="line"><span class="attr">      bar:</span> <span class="string">"2"</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p>类似于K8s, 也有quota的配置在deploy key下面，但是docker compose file v3 并不支持: <code>ignored by docker-compose up and docker-compose run</code>，虽然可以转换成v2，比如:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker-compose --compatibility up</span><br></pre></td></tr></table></figure></p>
<p>但是是best effort , 见这里讨论: <a href="https://stackoverflow.com/questions/42345235/how-to-specify-memory-cpu-limit-in-docker-compose-version-3" target="_blank" rel="noopener">How to specify Memory &amp; CPU limit in docker compose version 3</a></p>
<p>Docker Compose file version 2是支持quote设置的:<br><a href="https://docs.docker.com/compose/compose-file/compose-file-v2/#cpu-and-other-resources" target="_blank" rel="noopener">https://docs.docker.com/compose/compose-file/compose-file-v2/#cpu-and-other-resources</a></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Daemon Log</title>
    <url>/2019/12/02/docker-daemon-log/</url>
    <content><![CDATA[<p>When I was working on securing docker registry, I followed the instructions but when run <code>docker push</code> I always get <code>x509: certificate signed by unknown authority</code> error, this means the self-signed certificate is not identified by docker daemon.</p>
<p>This time to get more detail information, need to check the docker daemon log.</p>
<h1 id="How-to-Enable-Debug-Mode"><a href="#How-to-Enable-Debug-Mode" class="headerlink" title="How to Enable Debug Mode?"></a>How to Enable Debug Mode?</h1><p>By default, the debug mode is off, check here to enable debugging section:<br><a href="https://docs.docker.com/config/daemon/" target="_blank" rel="noopener">https://docs.docker.com/config/daemon/</a></p>
<p>Edit the <code>daemon.json</code> file, which is usually located in <code>/etc/docker/</code>. You may need to create this file if it is not there.<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"debug"</span>: <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Then send a <code>HUP</code> signal to the daemon to cause it to reload its configuration. On Linux hosts, use the following command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo kill -SIGHUP $(pidof dockerd)</span><br></pre></td></tr></table></figure></p>
<h1 id="Where-is-The-Log"><a href="#Where-is-The-Log" class="headerlink" title="Where is The Log?"></a>Where is The Log?</h1><p><a href="https://stackoverflow.com/questions/30969435/where-is-the-docker-daemon-log" target="_blank" rel="noopener">https://stackoverflow.com/questions/30969435/where-is-the-docker-daemon-log</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Ubuntu (old using upstart ) - /var/<span class="built_in">log</span>/upstart/docker.log</span><br><span class="line">Ubuntu (new using systemd ) - sudo journalctl -fu docker.service</span><br><span class="line">Amazon Linux AMI - /var/<span class="built_in">log</span>/docker</span><br><span class="line">Boot2Docker - /var/<span class="built_in">log</span>/docker.log</span><br><span class="line">Debian GNU/Linux - /var/<span class="built_in">log</span>/daemon.log</span><br><span class="line">CentOS - /var/<span class="built_in">log</span>/daemon.log | grep docker</span><br><span class="line">CoreOS - journalctl -u docker.service</span><br><span class="line">Fedora - journalctl -u docker.service</span><br><span class="line">Red Hat Enterprise Linux Server - /var/<span class="built_in">log</span>/messages | grep docker</span><br></pre></td></tr></table></figure></p>
<p>In Red Hat, from <code>/var/log/messages</code> file I clearly see that the docker daemon pick certificate under <code>/etc/docker/certs.d/&lt;domain, no port number!&gt;</code> folder.</p>
<p>If your OS is using <code>systemd</code>, the <code>journalctl</code> command can help, but the output from container is also dumping here, see this issue: <a href="https://github.com/moby/moby/issues/23339" target="_blank" rel="noopener">https://github.com/moby/moby/issues/23339</a>.</p>
<p>You can filter it by (works fine in Red Hat):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">journalctl -fu docker _TRANSPORT=stdout + OBJECT_EXE=docker</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Configuring Container DNS</title>
    <url>/2019/07/30/docker-dnsdomainname/</url>
    <content><![CDATA[<p>I have some doubts about <code>dnsdomainname</code> command in docker container when I developed non-root DataStage, in <code>Engine Conductor</code> tier.</p>
<p>References to <a href="https://docs.docker.com/v17.09/engine/userguide/networking/default_network/configure-dns/" target="_blank" rel="noopener">Configure container DNS</a></p>
<p>How can Docker supply each container a <code>hostname</code> and <code>DNS configuration</code> without having to build a custom image with the hostname written inside? The trick is to <strong>overlay</strong> three crucial <code>/etc</code> files inside the container with virtual files where it can write fresh information.</p>
<p>In container, run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># mount | grep etc</span><br><span class="line"></span><br><span class="line">/dev/mapper/rhel-root on /etc/resolv.conf type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/mapper/rhel-root on /etc/hostname type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/mapper/rhel-root on /etc/hosts type xfs (rw,relatime,attr2,inode64,noquota)</span><br></pre></td></tr></table></figure></p>
<p>Four different options affect container domain name services, please see official documentation for explanation:</p>
<ul>
<li><code>-h HOSTNAME</code> or <code>--hostname=HOSTNAME</code></li>
<li><code>--link=CONTAINER_NAME</code> or <code>ID:ALIAS</code></li>
<li><code>--dns=IP_ADDRESS</code></li>
<li><code>--dns-search=DOMAIN</code></li>
<li><code>--dns-opt=OPTION</code></li>
</ul>
<p>So what should <code>dnsdomainname</code> return exactly? for non-root engine docker container, the hostname is <code>is-en-conductor-0.en-cond</code>, but why sometimes <code>dnsdomainname</code> return empty but sometimes return <code>en.cond</code>.</p>
<p>I find the return depends on <code>/etc/hosts</code> file first non-self-loop IP hostname pair, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">9.30.223.186    is-en-conductor-0.en-cond is-servicesdocker is-xmetadocker</span><br></pre></td></tr></table></figure></p>
<p>the <code>dnsdomainname</code> will return <code>en-cond</code>, but if change to<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">9.30.223.186    is-xmetadocker is-en-conductor-0.en-cond is-servicesdocker</span><br></pre></td></tr></table></figure></p>
<p>the command returns empty, and if you run <code>hostname -f</code> (long host name), it returns <code>is-xmetadocker</code>.</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Entrypoint Script</title>
    <url>/2020/09/23/docker-entrypoint/</url>
    <content><![CDATA[<p>I have a post <a href="https://chengdol.github.io/2019/09/17/shell-argument-format/" target="_blank" rel="noopener"><code>Shell Arguments Format</code></a> talked about <code>exec &quot;$@&quot;</code> (当时并没有在意为什么在docker中这么使用), the script <code>docker-entrypoint.sh</code> is a very common and flexible way to accept different parameters when start docker container and run application as <code>PID 1</code>, this allows the application to receive any Unix signals sent to the container (之前遇到过这个问题, 非PID 1的进程在对container 的终止signal 没有反应).</p>
<p>See this docker best practice about entrypoint:<br><a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#entrypoint" target="_blank" rel="noopener">https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#entrypoint</a></p>
<p>The same pattern in envoy image, see this <a href="https://github.com/envoyproxy/envoy/blob/master/ci/docker-entrypoint.sh" target="_blank" rel="noopener"><code>docker-entrypoint.sh</code> link</a>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env sh</span></span><br><span class="line"><span class="built_in">set</span> -e</span><br><span class="line"></span><br><span class="line"><span class="comment">## shell parameter expansion</span></span><br><span class="line"><span class="comment">## if loglevel is null or unset, then assign null to it</span></span><br><span class="line"><span class="comment">## value can set from `-e` with docker run</span></span><br><span class="line">loglevel=<span class="string">"<span class="variable">$&#123;loglevel:-&#125;</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># if the first argument look like a parameter (i.e. start with '-'), run Envoy</span></span><br><span class="line"><span class="comment">## $&#123;1#-&#125; 的意思是对于第一个positional parameter, 开是不是以-开头</span></span><br><span class="line"><span class="comment">## $&#123;1#-&#125; expand 的结果是去掉最短的match部分</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;1#-&#125;</span>"</span> != <span class="string">"<span class="variable">$1</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">	<span class="built_in">set</span> -- envoy <span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$1</span>"</span> = <span class="string">'envoy'</span> ]; <span class="keyword">then</span></span><br><span class="line">	<span class="comment"># set the log level if the $loglevel variable is set</span></span><br><span class="line">	<span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$loglevel</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="comment">## 更新位置参数</span></span><br><span class="line">		<span class="built_in">set</span> -- <span class="string">"<span class="variable">$@</span>"</span> --<span class="built_in">log</span>-level <span class="string">"<span class="variable">$loglevel</span>"</span></span><br><span class="line">	<span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ENVOY_UID is the environment variables you specified</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$ENVOY_UID</span>"</span> != <span class="string">"0"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$ENVOY_UID</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">	usermod -u <span class="string">"<span class="variable">$ENVOY_UID</span>"</span> envoy</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="keyword">if</span> [ -n <span class="string">"<span class="variable">$ENVOY_GID</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">	groupmod -g <span class="string">"<span class="variable">$ENVOY_GID</span>"</span> envoy</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="comment"># Ensure the envoy user is able to write to container logs</span></span><br><span class="line">    chown envoy:envoy /dev/stdout /dev/stderr</span><br><span class="line"></span><br><span class="line">    <span class="comment">## su-exec switch user exec</span></span><br><span class="line">    <span class="comment">## https://github.com/ncopa/su-exec</span></span><br><span class="line">    su-exec envoy <span class="string">"<span class="variable">$&#123;@&#125;</span>"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="comment">## becomes PID 1</span></span><br><span class="line">    <span class="comment">## 注意有double quote</span></span><br><span class="line">    <span class="built_in">exec</span> <span class="string">"<span class="variable">$&#123;@&#125;</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<p>The new thing to me is <code>set --</code>, see this question:<br><a href="https://unix.stackexchange.com/questions/308260/what-does-set-do-in-this-dockerfile-entrypoint/308263" target="_blank" rel="noopener">What does “set –” do in this Dockerfile entrypoint?</a></p>
<p>The <code>set --</code> command sets the positional parameters and link new tokens with existing position parameters, The <code>--</code> is the standard “don’t treat anything following this as an option”，也就是说这是要排列位置参数了，而不是重置位置参数:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span> a b c</span><br><span class="line"><span class="comment">## output "a b c"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$1</span> <span class="variable">$2</span> <span class="variable">$3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 相当于$@ = newToken "$@"</span></span><br><span class="line"><span class="built_in">set</span> -- newToken <span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line"><span class="comment">## it actually exec "newToken a b c"</span></span><br><span class="line"><span class="built_in">exec</span> <span class="string">"<span class="variable">$&#123;@&#125;</span>"</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Container IPC Share</title>
    <url>/2019/07/31/docker-ipc/</url>
    <content><![CDATA[<p>I have a post talks about IPC <a href="https://chengdol.github.io/2019/05/01/linux-ipc/" target="_blank" rel="noopener"><code>&lt;&lt;Linux IPC&gt;&gt;</code></a>, it’s about IPC resource requirements for DB2 and how to adjust the ipc parameters permanently or temporarily. This time we face different ipc issue, interesting.</p>
<h2 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h2><p>We bring up DataStage container in particular order to make them function correctly, but when Engine is running, Xmeta DB2 went down silently whihout any warning or error messages. unquiesce will make DB2 up again, but it’s not stable.</p>
<p>This did not happen in K8s cluster, things get weired.</p>
<h2 id="Reason"><a href="#Reason" class="headerlink" title="Reason"></a>Reason</h2><p>We update docker run command for Xmeta and Engine with <code>--ipc=host</code>, so they will share the ipc resouces with host machine (They reside on the same machine) and each other. </p>
<p>The trick is there are some <code>ipcrm -a</code> in the Engine start and quiesce scripts. So when Engine is up, it cleans host ipc resource and DB2 goes down.</p>
<p>we remove all <code>ipcrm -a</code> commands inside container and things get work.</p>
<p>Another thing is before start up the containers, <strong>make sure the ipc is clean</strong>, we encountered the problem that the old non-used ipc overstep in new containers, so run <code>ipcrm -a</code> in host machine to clean them.</p>
<p><strong>Why K8s does not have this problem?</strong> Because we schedule Xmeta and Engine in different nodes, the <code>ipcrm -a</code> will not affect each other, but docker we hold all containers in one node.</p>
<p>Some usefully commands<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ipcs -l      <span class="comment">## list ipc configuration</span></span><br><span class="line"></span><br><span class="line">ipcrm -a     <span class="comment">## remove all ipc resources</span></span><br><span class="line">ipcs -a      <span class="comment">## list ipc in use</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux</tag>
        <tag>ipc</tag>
      </tags>
  </entry>
  <entry>
    <title>Podman</title>
    <url>/2020/02/26/docker-podman/</url>
    <content><![CDATA[<p><a href="https://podman.io/" target="_blank" rel="noopener"><code>Podman</code></a> is a pod manager tool, a daemonless container engine for developing, managing, and running OCI Containers on your Linux System. Containers can either be run as <strong>root</strong> or in <strong>rootless</strong> mode. Simply put: <code>alias docker=podman</code>.</p>
<blockquote>
<p>实际使用中发现podman commit命令和docker格式有不同，且commit后的image使用上有不正常的地方，比如HOSTNAME不见了。</p>
</blockquote>
<p><a href="https://github.com/containers/buildah/tree/master/docs/containertools" target="_blank" rel="noopener"><code>Container tool guide</code></a>, it shows the difference between <code>buildha</code> and <code>podman</code>:</p>
<p>Both Buildah and Podman are command line tools that work on OCI images and containers. The two projects differentiate in their specialization.</p>
<p>Buildah specializes in building OCI images. Buildah’s commands replicate all of the commands that are found in a Dockerfile. Buildah’s goal is also to provide a lower level coreutils interface to build images, allowing people to build containers without requiring a Dockerfile. The intent with Buildah is to allow other scripting languages to build container images, without requiring a daemon.</p>
<p>Podman specializes in all of the commands and functions that help you to maintain and modify OCI images, such as pulling and tagging. It also allows you to create, run, and maintain containers created from those images.</p>
<p>A major difference between Podman and Buildah is their concept of a container. Podman allows users to create “traditional containers” where the intent of these containers is to be long lived. While Buildah containers are really just created to allow content to be added back to the container image. An easy way to think of it is the buildah run command emulates the RUN command in a Dockerfile while the podman run command emulates the docker run command in functionality. Because of this you cannot see Podman containers from within Buildah or vice versa.</p>
<blockquote>
<p>so buildah mainly is used to <strong>build</strong> images (to build images you need to run containers before commit updates), podman is used to <strong>run</strong> container in production environment.</p>
</blockquote>
<p>In short Buildah is an efficient way to create OCI images while Podman allows you to manage and maintain those images and containers in a production environment using familiar container cli commands.</p>
<blockquote>
<p>Some commands overlaps between the projecs</p>
</blockquote>
<p>Let’s see some example when I was working on deploy ds assembly on portworx:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install podman in redhat/centos</span></span><br><span class="line">yum install podman -y</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same as docker login</span></span><br><span class="line">podman login -u &lt;user name&gt; -p &lt;password&gt; docker.io</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same as docker pull/tag/push</span></span><br><span class="line">podman pull k8s.gcr.io/pause:3.1</span><br><span class="line">podman tag k8s.gcr.io/pause:3.1 &lt;regisrty path&gt;/pause:3.1</span><br><span class="line"></span><br><span class="line"><span class="comment">## --tls-verify=false </span></span><br><span class="line"><span class="comment">## disable HTTPS and verify certificates when contacting registry</span></span><br><span class="line"><span class="comment">## you may also need is when login</span></span><br><span class="line">podman push &lt;registry path&gt;/pause:3.1 --tls-verify=<span class="literal">false</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>podman</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Image Default Parameters</title>
    <url>/2019/05/15/docker-image-default/</url>
    <content><![CDATA[<p>This blog is a subsection from <a href="https://chengdol.github.io/2019/05/15/docker-run/" target="_blank" rel="noopener"><code>&lt;&lt;Docker Run Reference&gt;&gt;</code></a>.</p>
<p>When a developer builds an image from a Dockerfile or when commits it, the developer can set a number of default parameters that take effect when the image starts up as a container.</p>
<p>Four of the Dockerfile commands cannot be overridden at runtime: <code>FROM</code>, <code>MAINTAINER</code>, <code>RUN</code>, and <code>ADD</code>. Everything else has a corresponding override in <code>docker run</code>.</p>
<h2 id="CMD-default-command-or-options"><a href="#CMD-default-command-or-options" class="headerlink" title="CMD [default command or options]"></a>CMD [default command or options]</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]</span><br></pre></td></tr></table></figure>
<p>This command is optional because the person who created the IMAGE may have already provided a default <code>COMMAND</code> using the Dockerfile <code>CMD</code> instruction. </p>
<p>If the image also specifies an <code>ENTRYPOINT</code> then the <code>CMD</code> or <code>COMMAND</code> get appended as arguments to the <code>ENTRYPOINT</code>(see nect section).</p>
<p>For example, we override the <code>CMD</code> in busybox by <code>/bin/sh -c ls -ltr</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -it --rm  busybox /bin/sh -c ls -ltr</span><br></pre></td></tr></table></figure></p>
<p>You can use<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect -f &quot;&#123;&#123;.Config.Cmd&#125;&#125;&quot; busybox</span><br></pre></td></tr></table></figure></p>
<p>to check the default <code>CMD</code> in image, it shows the default <code>CMD</code> for busybox is <code>[sh]</code>. If you override it by <code>/bin/sh -c ls -ltr</code> like above example, then you run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker ps -a --no-trunc</span><br></pre></td></tr></table></figure></p>
<p>You can see under the <code>COMMAND</code> column, it changes to <code>/bin/sh -c ls -ltr</code>, easy to verify.</p>
<h2 id="ENTRYPOINT-default-command-to-execute-at-runtime"><a href="#ENTRYPOINT-default-command-to-execute-at-runtime" class="headerlink" title="ENTRYPOINT [default command to execute at runtime]"></a>ENTRYPOINT [default command to execute at runtime]</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--entrypoint=&quot;&quot;: Overwrite the default entrypoint set by the image</span><br></pre></td></tr></table></figure>
<p>The <code>ENTRYPOINT</code> of an image is similar to a <code>COMMAND</code> because it specifies what executable to run when the container starts, but it is (purposely) more difficult to override. The <code>ENTRYPOINT</code> gives a container its default nature or behavior, so that when you set an ENTRYPOINT you can run the container as if it was that binary, complete with default options, and you can pass in more options via the <code>COMMAND</code>.</p>
<p>you can check the default entrypoint of a image by:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect -f &quot;&#123;&#123;.Config.Entrypoint&#125;&#125;&quot; is-services-image:1</span><br></pre></td></tr></table></figure></p>
<p>If I want to override the default one and pass parameters <code>tail -f /dev/null</code> to entrypoint <code>/bin/bash</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d --entrypoint=/bin/bash is-services-image:1 -c &quot;tail -f /dev/null&quot;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: Passing <code>--entrypoint</code> will clear out any default command set on the image</p>
</blockquote>
<h2 id="EXPOSE-incoming-ports"><a href="#EXPOSE-incoming-ports" class="headerlink" title="EXPOSE [incoming ports]"></a>EXPOSE [incoming ports]</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--expose=[]: Expose a port or a range of ports inside the container.</span><br><span class="line">             These are additional to those exposed by the `EXPOSE` instruction</span><br><span class="line">-P         : Publish all exposed ports to the host interfaces</span><br><span class="line">-p=[]      : Publish a container&apos;s port or a range of ports to the host</span><br><span class="line">               format: ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort | containerPort</span><br><span class="line">               Both hostPort and containerPort can be specified as a</span><br><span class="line">               range of ports. When specifying ranges for both, the</span><br><span class="line">               number of container ports in the range must match the</span><br><span class="line">               number of host ports in the range, for example:</span><br><span class="line">                   -p 1234-1236:1234-1236/tcp</span><br><span class="line"></span><br><span class="line">               When specifying a range for hostPort only, the</span><br><span class="line">               containerPort must not be a range.  In this case the</span><br><span class="line">               container port is published somewhere within the</span><br><span class="line">               specified hostPort range. (e.g., `-p 1234-1236:1234/tcp`)</span><br><span class="line"></span><br><span class="line">               (use &apos;docker port&apos; to see the actual mapping)</span><br><span class="line"></span><br><span class="line">--link=&quot;&quot;  : Add link to another container (&lt;name or id&gt;:alias or &lt;name or id&gt;)</span><br></pre></td></tr></table></figure>
<p>With the exception of the <code>EXPOSE</code> directive, an image developer hasn’t got much control over networking. The <code>EXPOSE</code> instruction defines the initial <strong>incoming</strong> ports (listens on specific network ports) that provide services. These ports are available to processes inside the container. An operator can use the –expose option to add to the exposed ports.</p>
<blockquote>
<p><code>EXPOSE</code> will not allow communication via the defined ports to containers outside of the same network or to the host machine. To allow this to happen you need to publish the ports.</p>
</blockquote>
<p>To expose a container’s internal port, an operator can start the container with the <code>-P</code> or <code>-p</code> flag. The exposed port is accessible on the host and the ports are available to any client that can reach the host.</p>
<blockquote>
<p>Note that in K8s, if the pods in the same namespace, the pods can communicate with each others if the ports are running, no additional setting needed except you want to access the applications from outside the cluster.</p>
</blockquote>
<h2 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-u=&quot;&quot;, --user=&quot;&quot;: Sets the username or UID used and optionally the groupname or GID for the specified command.</span><br><span class="line"></span><br><span class="line">The followings examples are all valid:</span><br><span class="line">--user=[ user | user:group | uid | uid:gid | user:gid | uid:group ]</span><br></pre></td></tr></table></figure>
<p>root (id = 0) is the <strong>default</strong> user within a container. The image developer can create additional users. Those users are accessible by name. When passing a numeric ID, the user does not have to exist in the container.</p>
<h2 id="ENV-environment-variables"><a href="#ENV-environment-variables" class="headerlink" title="ENV [environment variables]"></a>ENV [environment variables]</h2><p>Docker automatically sets some environment variables when creating a Linux container. Docker does not set any environment variables when creating a Windows container.</p>
<p>The following environment variables are set for Linux containers:</p>
<ul>
<li>HOME: Set based on the value of USER</li>
<li>HOSTNAME: The hostname associated with the container</li>
<li>PATH: Includes popular directories, for example:<br><code>/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</code></li>
<li>TERM: xterm if the container is allocated a pseudo-TTY</li>
</ul>
<p>Additionally, the operator can set any environment variable in the container by using one or more <code>-e</code> flags, even overriding those mentioned above, or already defined by the developer with a Dockerfile <code>ENV</code>. If the operator names an environment variable without specifying a value, then the current value of the named variable is propagated into the container’s environment.</p>
<h2 id="VOLUME-shared-filesystems"><a href="#VOLUME-shared-filesystems" class="headerlink" title="VOLUME [shared filesystems]"></a>VOLUME [shared filesystems]</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-v, --volume=[host-src:]container-dest[:&lt;options&gt;]: Bind mount a volume.</span><br><span class="line">The comma-delimited `options` are [rw|ro], [z|Z],</span><br><span class="line">[[r]shared|[r]slave|[r]private], and [nocopy].</span><br><span class="line">The &apos;host-src&apos; is an absolute path or a name value.</span><br><span class="line"></span><br><span class="line">If neither &apos;rw&apos; or &apos;ro&apos; is specified then the volume is mounted in</span><br><span class="line">read-write mode.</span><br><span class="line"></span><br><span class="line">The `nocopy` mode is used to disable automatically copying the requested volume</span><br><span class="line">path in the container to the volume storage location.</span><br><span class="line">For named volumes, `copy` is the default mode. Copy modes are not supported</span><br><span class="line">for bind-mounted volumes.</span><br><span class="line"></span><br><span class="line">--volumes-from=&quot;&quot;: Mount all volumes from the given container(s)</span><br></pre></td></tr></table></figure>
<p>The volumes commands are complex enough to have their own <a href="https://docs.docker.com/storage/volumes/" target="_blank" rel="noopener">documentation</a>. </p>
<p>he <code>container-dest</code> must always be an absolute path such as <code>/src/docs</code>. The <code>host-src</code> can either be an absolute path or a name value. If you supply an absolute path for the <code>host-src</code>, Docker bind-mounts to the path you specify. If you supply a name, Docker creates a named volume by that name.</p>
<p>For example, you can specify either <code>/foo</code> or <code>foo</code> for a <code>host-src</code> value. If you supply the <code>/foo</code> value, Docker creates a bind mount. If you supply the <code>foo</code> specification, Docker creates a named volume.</p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p><a href="https://docs.docker.com/engine/reference/run/" target="_blank" rel="noopener">Docker run reference</a><br><a href="https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact" target="_blank" rel="noopener">Dockerfile reference</a><br><a href="https://medium.freecodecamp.org/expose-vs-publish-docker-port-commands-explained-simply-434593dbc9a3" target="_blank" rel="noopener">Expose vs publish: Docker port commands explained simply</a></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Non-Root Docker Update Summary</title>
    <url>/2019/05/06/docker-nonroot-update-summary/</url>
    <content><![CDATA[<p>I haven’t got time to learn Docker systematically so far, but I still gain a lot from daily tasks. This post is a brief summary for what I have done to upgrade the container from owned by root to noon-root for security reason required by our customers.</p>
<p>I will talk the development workflow instead of the detail about how to set and modify the configurations inside the container:</p>
<p>I have a base image at beginning, let’s say <code>root_is_engine.tar.gz</code>, load it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker load -i root_is_engine.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>you can check the loaded image by running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure></p>
<p>Now I am going to create the container from this image, but wait, I don’t want the container to run any script or program when it starts, what I need is it just hangs without doing anything.</p>
<p>That means I need to override the default <code>entrypoint</code> (entrypoint sets the command and parameters that will be executed first when spin up a container) in docker run command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --detach \</span><br><span class="line">         --cap-add=SYS_ADMIN \</span><br><span class="line">         --privileged=false --name=$&#123;ENGINE_HOST&#125; --hostname=$&#123;ENGINE_HOST&#125; \</span><br><span class="line">         --restart=always --add-host=&quot;$&#123;SERVICES_HOST&#125; $&#123;DB2_XMETA_HOST&#125; $&#123;ENGINE_HOST&#125;&quot;:$&#123;ENGINE_HOST_IP&#125; \</span><br><span class="line">         -p 8449:8449 \</span><br><span class="line">         -v $&#123;DEDICATED_ENGINE_VOLPATH&#125;/$&#123;ENGINE_HOST&#125;/EngineClients/db2_client/dsadm:/home/dsadm \</span><br><span class="line">         --entrypoint=/bin/sh \</span><br><span class="line">         $&#123;DOCKER_IMAGE_TAG_ENGINE&#125;:$&#123;DOCKER_IMAGE_VERSION&#125; \</span><br><span class="line">         -c &apos;tail -f /dev/null&apos;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that place the arguments to your entrypoint at the <strong>end</strong> of your docker command <code>-c &#39;tail -f /dev/null&#39;</code></p>
</blockquote>
<p>Run <code>docker ps</code> command, you can see under <code>COMMAND</code> column the entrypoint is what I specified:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CONTAINER ID        IMAGE                   COMMAND                  CREATED             STATUS              PORTS                     NAMES</span><br><span class="line">b462f6123684        is-engine-image:1       &quot;/bin/sh -c &apos;tail -f...&quot;   2 days ago          Up 2 days           0.0.0.0:8449-&gt;8449/tcp   is-en-conductor-0.en-cond</span><br></pre></td></tr></table></figure></p>
<p>Then get into the container by running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker exec -it &lt;container id or container name&gt; [bash|sh]</span><br></pre></td></tr></table></figure></p>
<p>Then if you check the process status, you can see the init process with PID #1 is running <code>tail</code> command to track <code>/dev/null</code> device file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux</span><br><span class="line"></span><br><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root         1  0.0  0.0   5968   616 ?        Ss   16:47   0:00 tail -f /dev/null</span><br><span class="line">root        27  1.5  0.0  13420  1992 pts/0    Ss   16:50   0:00 bash</span><br><span class="line">root        45  0.0  0.0  53340  1864 pts/0    R+   16:50   0:00 ps aux</span><br></pre></td></tr></table></figure></p>
<p>OK, now I can make changes, for example, create and switch to ordinary user with specified user id and group id, grant them privileges, modify the owner and permission of some files, run and update startup script line by line to see if the applications setup correctly with non-root.</p>
<blockquote>
<p>Note if you have mount path in host machine, you may need to <code>chown</code> correct uid and gid, otherwise ordinary user in container may get permission denied issue.</p>
</blockquote>
<p>After running some tests and they succeed, I need to <strong>commit</strong> the changes into a new image. </p>
<ul>
<li><p>First understand how does <code>docker commit</code> work? what will be committed into new image?</p>
<p>The container has a writable layer that stacks on top of the image layers. This writable layer allows you to <em>make changes</em> to the container since the lower layers in the image are read-only.</p>
<p>From the docker documentation, it said: It can be useful to commit a container’s <strong>file</strong> changes or <strong>settings</strong> into a new image.</p>
<p>The commit operation will <strong>not</strong> include any data contained in volumes mounted inside the container.</p>
<p>By default, the container being committed and its processes will be paused while the image is committed. This reduces the likelihood of encountering data corruption during the process of creating the commit. If this behavior is undesired, set the <code>--pause</code> option to false.</p>
<p>The <code>--change</code> option will apply Dockerfile instructions to the image that is created. Supported Dockerfile instructions: <code>CMD|ENTRYPOINT|ENV|EXPOSE|LABEL|ONBUILD|USER|VOLUME|WORKDIR</code></p>
</li>
<li><p>How about processes in the running container?</p>
<p>When you start container from image then process will start here - processes exists <strong>only</strong> in executing container, when container stops there are no processes anymore - only files from container’s filesystem.</p>
</li>
</ul>
<blockquote>
<p>Note that before committing, you need to quiesce the services and remove the mount path content to unlink all broken symbolic links.</p>
</blockquote>
<p>Also remember to put the old entrypoint back:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker commit \</span><br><span class="line">       --change &apos;ENTRYPOINT [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;/opt/xx/initScripts/startcontainer.sh&quot;]&apos; \</span><br><span class="line">       &lt;container ID&gt; is-engine-image:1</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>podman</code> commit format is different.</p>
</blockquote>
<blockquote>
<p>Note that you may use <code>bin/sh</code> instead of <code>/bin/bash</code>.</p>
</blockquote>
<p>OK, now start to run the new image with non-root user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --detach \</span><br><span class="line">         --user 1000 \</span><br><span class="line">         --cap-add=SYS_ADMIN \</span><br><span class="line">         --privileged=false --name=$&#123;ENGINE_HOST&#125; --hostname=$&#123;ENGINE_HOST&#125; \</span><br><span class="line">         --restart=always --add-host=&quot;$&#123;SERVICES_HOST&#125; $&#123;DB2_XMETA_HOST&#125; $&#123;ENGINE_HOST&#125;&quot;:$&#123;ENGINE_HOST_IP&#125; \</span><br><span class="line">         -p 8449:8449 \</span><br><span class="line">         -v $&#123;DEDICATED_ENGINE_VOLPATH&#125;/$&#123;ENGINE_HOST&#125;/EngineClients/db2_client/dsadm:/home/dsadm \</span><br><span class="line">         $&#123;DOCKER_IMAGE_TAG_ENGINE&#125;:$&#123;DOCKER_IMAGE_VERSION&#125;</span><br></pre></td></tr></table></figure></p>
<p>Let’s see the processes in the non-root container:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">dsadm        1  0.0  0.0  13288  1604 ?        Ss   18:29   0:00 /bin/bash /opt/xx/initScripts/startcontainer.sh</span><br><span class="line">dsadm      540  0.0  0.0   5968   620 ?        S    18:29   0:00 tail -f /dev/null</span><br><span class="line">dsadm      568  0.1  0.3 2309632 24792 ?       Sl   18:29   0:00 /opt/xx/../../jdk</span><br><span class="line">dsadm      589  2.5  0.0  13420  2012 pts/0    Ss   18:36   0:00 bash</span><br><span class="line">dsadm      610  0.0  0.0  53340  1868 pts/0    R+   18:36   0:00 ps aux</span><br></pre></td></tr></table></figure></p>
<p>If all things are in good shape, save the image into tar.gz format, of course you can use a new tag before saving:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker save is-engine-image:1 | gzip &gt; ~/nonroot_is_engine.tar.gz</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that there is a <code>gzip</code> to compress the image.</p>
</blockquote>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>entry point</tag>
        <tag>docker commit</tag>
        <tag>docker save</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Registry Configure</title>
    <url>/2019/06/16/docker-registry-config/</url>
    <content><![CDATA[<p>From JFrog:</p>
<ul>
<li>A Docker <code>repository</code> is a hosted collection of tagged images that, together, create the file system for a container</li>
<li>A Docker <code>registry</code> is a host that stores Docker repositories</li>
<li>An <code>Artifactory repository</code> is a hosted collection of Docker repositories, effectively, a Docker registry in every way, and one that you can access transparently with the Docker client.</li>
</ul>
<p><a href="https://docs.docker.com/registry/configuration/" target="_blank" rel="noopener">https://docs.docker.com/registry/configuration/</a></p>
<p>If you change the setting in docker registry running container, try<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker restart &lt;container id&gt;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>registry</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Run Reference</title>
    <url>/2019/05/15/docker-run/</url>
    <content><![CDATA[<p>This is a summary from <a href="https://docs.docker.com/engine/reference/run/#entrypoint-default-command-to-execute-at-runtime" target="_blank" rel="noopener">Docker run reference</a></p>
<p>Docker runs processes in isolated containers. <strong>A container is a process</strong> which runs on a host. The host may be local or remote. When an operator executes <code>docker run</code>, the container process that runs is isolated in that it has its own file system, its own networking, and its own isolated process tree separate from the host.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]</span><br></pre></td></tr></table></figure>
<p>The <code>docker run</code> command can override nearly all the defaults set by the Docker runtime itself.</p>
<p>Let’s first see the <code>docker run</code> command I encountered:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --detach \</span><br><span class="line">      --name=$&#123;DB2_XMETA_HOST&#125; \</span><br><span class="line">      --restart=always \</span><br><span class="line">      --privileged=false \</span><br><span class="line">      --cap-add=SYS_NICE --cap-add=IPC_OWNER --cap-add=SETFCAP  \</span><br><span class="line">      --user 1000 \</span><br><span class="line">      -e MY_POD_NAMESPACE=$&#123;MY_POD_NAMESPACE&#125; \</span><br><span class="line">      -e SHARED_VOL=$&#123;SHARED_REPOS_VOLPATH&#125; \</span><br><span class="line">      --hostname=$&#123;DB2_XMETA_HOST&#125; \</span><br><span class="line">      -p $&#123;DB2_XMETA_PORT&#125;:$&#123;DB2_XMETA_PORT&#125; \</span><br><span class="line">      -v $&#123;SHARED_VOL&#125;:$&#123;SHARED_VOL&#125; \</span><br><span class="line">      is-xmetadocker:11.7.1 \</span><br></pre></td></tr></table></figure></p>
<h2 id="Detched-d"><a href="#Detched-d" class="headerlink" title="Detched [-d]"></a>Detched [-d]</h2><p>To start a container in detached mode, you use <code>-d=true</code> or just <code>-d</code> option. By design, containers started in detached mode exit when the root process used to run the container exits, unless you also specify the <code>--rm</code> option. If you use <code>-d</code> with <code>--rm</code>, the container is removed when it exits or when the daemon exits, whichever happens first.</p>
<blockquote>
<p>This is why we specify <code>tail -f /dev/null</code> at end of start script in container.</p>
</blockquote>
<h2 id="Foreground"><a href="#Foreground" class="headerlink" title="Foreground"></a>Foreground</h2><p>In foreground mode (the default when <code>-d</code> is not specified), docker run can start the process in the container and attach the console to the process’s standard input, output, and standard error. It can even pretend to be a TTY (this is what most command line executables expect) and pass along signals.</p>
<p>For interactive processes (like a shell), you must use <code>-it</code> together in order to allocate a tty for the container process. </p>
<p>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -it --rm busybox /bin/sh</span><br></pre></td></tr></table></figure></p>
<p>This will directly open a shell to operate on container, once exit, container will be removed.</p>
<h2 id="Name-name"><a href="#Name-name" class="headerlink" title="Name [--name]"></a>Name [<code>--name</code>]</h2><p>Specify container name. If you do not assign a container name with the <code>--name</code> option, then the daemon generates a random string name for you. Defining a name can be a handy way to add meaning to a container.</p>
<h3 id="IPC-settings-ipc"><a href="#IPC-settings-ipc" class="headerlink" title="IPC settings [--ipc]"></a>IPC settings [<code>--ipc</code>]</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--ipc=&quot;MODE&quot;  : Set the IPC mode for the container</span><br></pre></td></tr></table></figure>
<p>IPC (POSIX/SysV IPC) namespace provides separation of named shared memory segments, semaphores and message queues.</p>
<p>Shared memory segments are used to accelerate inter-process communication at memory speed, rather than through pipes or through the network stack. </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--ipc=&lt;Value&gt;</span><br></pre></td></tr></table></figure>
<p>Value    Description</p>
<ul>
<li>“”:    Use daemon’s default.</li>
<li>“none”:    Own private IPC namespace, with /dev/shm not mounted.</li>
<li>“private”:    Own private IPC namespace.</li>
<li>“shareable”:Own private IPC namespace, with a possibility to share it with other containers.</li>
<li>“container: &lt;<em>name-or-ID</em>&gt;”: Join another (“shareable”) container’s IPC namespace.</li>
<li>“*host”: Use the host system’s IPC namespace.</li>
</ul>
<p>If not specified, daemon default is used, which can either be <code>private</code> or <code>shareable</code>, depending on the daemon version and configuration.</p>
<p>If these types of applications are broken into multiple containers, you might need to share the IPC mechanisms of the containers, using “shareable” mode for the main container, and <code>container:&lt;donor-name-or-ID&gt;</code> for other containers.</p>
<h2 id="Network-settings"><a href="#Network-settings" class="headerlink" title="Network settings"></a>Network settings</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--dns=[]           : Set custom dns servers for the container</span><br><span class="line">--network=&quot;bridge&quot; : Connect a container to a network</span><br><span class="line">                      &apos;bridge&apos;: create a network stack on the default Docker bridge</span><br><span class="line">                      &apos;none&apos;: no networking</span><br><span class="line">                      &apos;container:&lt;name|id&gt;&apos;: reuse another container&apos;s network stack</span><br><span class="line">                      &apos;host&apos;: use the Docker host network stack</span><br><span class="line">                      &apos;&lt;network-name&gt;|&lt;network-id&gt;&apos;: connect to a user-defined network</span><br><span class="line">--network-alias=[] : Add network-scoped alias for the container</span><br><span class="line">--add-host=&quot;&quot;      : Add a line to /etc/hosts (host:IP)</span><br><span class="line">--mac-address=&quot;&quot;   : Sets the container&apos;s Ethernet device&apos;s MAC address</span><br><span class="line">--ip=&quot;&quot;            : Sets the container&apos;s Ethernet device&apos;s IPv4 address</span><br><span class="line">--ip6=&quot;&quot;           : Sets the container&apos;s Ethernet device&apos;s IPv6 address</span><br><span class="line">--link-local-ip=[] : Sets one or more container&apos;s Ethernet device&apos;s link local IPv4/IPv6 addresses</span><br></pre></td></tr></table></figure>
<p>I meet <code>--add-host</code> flag in service docker:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--add-host=&quot;$&#123;SERVICES_HOST&#125; $&#123;DB2_XMETA_HOST&#125; $&#123;ENGINE_HOST&#125;&quot;:$&#123;SERVICES_HOST_IP&#125; \</span><br></pre></td></tr></table></figure></p>
<h2 id="Restart-policies-restart"><a href="#Restart-policies-restart" class="headerlink" title="Restart policies (--restart)"></a>Restart policies (<code>--restart</code>)</h2><p>Using the <code>--restart</code> flag on Docker run you can specify a restart policy for how a container should or should not be restarted on exit.</p>
<p>When a restart policy is active on a container, it will be shown as either <code>Up</code> or <code>Restarting</code> in <code>docker ps</code>.</p>
<h2 id="Exit-Status"><a href="#Exit-Status" class="headerlink" title="Exit Status"></a>Exit Status</h2><p>The exit code from <code>docker run</code> gives information about why the container failed to run or why it exited. When <code>docker run</code> exits with a non-zero code, the exit codes follow the chroot standard.</p>
<h2 id="Clean-up-rm"><a href="#Clean-up-rm" class="headerlink" title="Clean up [--rm]"></a>Clean up [<code>--rm</code>]</h2><p>By default a container’s file system persists even after the container exits. This makes debugging a lot easier (since you can inspect the final state) and you retain all your data by default. But if you are running <strong>short-term</strong> foreground processes, these container file systems can really pile up. If instead you’d like Docker to automatically clean up the container and remove the file system when the container exits, you can add the <code>--rm</code> flag.</p>
<h2 id="HOSTNAME-hostname"><a href="#HOSTNAME-hostname" class="headerlink" title="HOSTNAME [--hostname]"></a>HOSTNAME [<code>--hostname</code>]</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--hostname=&quot;xxx&quot;		Container host name</span><br></pre></td></tr></table></figure>
<p>Set the hostname of the container.</p>
<h2 id="Runtime-privilege-and-Linux-capabilities"><a href="#Runtime-privilege-and-Linux-capabilities" class="headerlink" title="Runtime privilege and Linux capabilities"></a>Runtime privilege and Linux capabilities</h2><p>I separate this section to the blog <a href="https://chengdol.github.io/2019/05/15/docker-capability/" target="_blank" rel="noopener"><code>&lt;&lt;Docker Capability&gt;&gt;</code></a> since it’s important to me.</p>
<h2 id="Logging-drivers-log-driver"><a href="#Logging-drivers-log-driver" class="headerlink" title="Logging drivers [--log-driver]"></a>Logging drivers [<code>--log-driver</code>]</h2><p>The container can have a different logging driver than the Docker daemon. Use the <code>--log-driver=VALUE</code> with the <code>docker run</code> command to configure the container’s logging driver.</p>
<p>Default logging driver is json format. The <code>docker logs</code> command is available only for the <code>json-file</code> and <code>journald</code> logging drivers.</p>
<h2 id="Overriding-Dockerfile-image-defaults"><a href="#Overriding-Dockerfile-image-defaults" class="headerlink" title="Overriding Dockerfile image defaults"></a>Overriding Dockerfile image defaults</h2><p>I separate this section to the blog <a href="https://chengdol.github.io/2019/05/15/docker-image-default/" target="_blank" rel="noopener"><code>&lt;&lt;Docker Image Defaults&gt;&gt;</code></a> since it’s important to me.</p>
<h2 id="p"><a href="#p" class="headerlink" title="-p"></a>-p</h2><p>Remember, the first part of the -p value is the host port and the second part is the port within the container</p>
<h2 id="VOLUME-shared-filesystems"><a href="#VOLUME-shared-filesystems" class="headerlink" title="VOLUME (shared filesystems)"></a>VOLUME (shared filesystems)</h2><p>When use <code>-v</code> option binds mount a volume from host machine to inside container, if the container originally has contents inside the mount target folder, they will all be removed when mount and replaced by contents from source host machine folder.</p>
<blockquote>
<p>Note that <code>docker commit</code> will not include any data contained in volumes mounted inside the container.</p>
</blockquote>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Registry API</title>
    <url>/2019/06/10/docker-registry-api/</url>
    <content><![CDATA[<p>How to list images and tags in the docker registory? How to delete image(layers) in docker registory? These are general demands in my daily work, let’s figure them out.</p>
<p>A brife digression: The <code>OpenShift</code> platform has web UI to deal with images in integrated docker registry (it is called <code>imagestream</code> in OpenShift), usually after you login to terminal, run <code>oc version</code> will show you the web address. You can list and delete imagestream there.</p>
<p>For example, I use <code>OpenShift</code> integrated docker registry and push my docker images to a project called <code>datastage</code> (I configuring the setting so other project can pull images from this project):<br><img src="https://drive.google.com/uc?id=1T55Gro5-_WZDTkP3lNuIrDUk6C7f8qWl" alt=""></p>
<h2 id="Resurces"><a href="#Resurces" class="headerlink" title="Resurces"></a>Resurces</h2><p><a href="https://docs.docker.com/registry/spec/api/" target="_blank" rel="noopener">Docker Registry HTTP API V2</a><br><a href="https://blog.csdn.net/qq_35904833/article/details/80807592" target="_blank" rel="noopener">Registry 清理镜像</a><br><a href="https://github.com/docker/distribution/blob/master/docs/spec/auth/token.md" target="_blank" rel="noopener">v2 Docker registry authentication</a><br><a href="https://github.com/byrnedo/docker-reg-tool" target="_blank" rel="noopener">Registry tool Git project</a><br><a href="https://medium.com/@mcvidanagama/cleanup-your-docker-registry-ef0527673e3a" target="_blank" rel="noopener">Cleanup Your Docker Registry</a></p>
<h2 id="Quick-Set-up"><a href="#Quick-Set-up" class="headerlink" title="Quick Set up"></a>Quick Set up</h2><p>After installing docker, get and run docker registry from <a href="https://hub.docker.com/_/registry" target="_blank" rel="noopener">Docker Offical Images - registry</a>.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull registry</span><br></pre></td></tr></table></figure>
<p>you will get:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images</span><br><span class="line"></span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">registry            latest              f32a97de94e1        3 months ago        25.8MB</span><br></pre></td></tr></table></figure></p>
<p>then run it locally with image deletion enabled:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d -p 5000:5000 -e REGISTRY_STORAGE_DELETE_ENABLED=true --restart always --name registry registry</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>To remove images, you need to setup docker registry with <strong>delete enabled</strong>(by default it’s off), see my blog <a href="https://chengdol.github.io/2019/06/16/docker-registry-config/" target="_blank" rel="noopener">Docker Registry Configure</a></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker ps</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES</span><br><span class="line">3021266dca1f        registry            &quot;/entrypoint.sh /etc...&quot;   2 seconds ago       Up 1 second         0.0.0.0:5000-&gt;5000/tcp   registry</span><br></pre></td></tr></table></figure>
<p>Next, let’s use busybox to illustrate:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull busybox</span><br><span class="line">docker tag busybox localhost:5000/busybox:v1</span><br><span class="line">docker push localhost:5000/busybox:v1</span><br></pre></td></tr></table></figure></p>
<h2 id="Insecure-Docker-Registry"><a href="#Insecure-Docker-Registry" class="headerlink" title="Insecure Docker Registry"></a>Insecure Docker Registry</h2><p>Quick set up will give you a insecure private docker registry (means no <code>docker login</code> and use <code>http</code> to access API).</p>
<blockquote>
<p>Note that you can use <code>-v</code> option in <code>curl</code> command to get verbose message such as HEADER information.</p>
</blockquote>
<h3 id="Check-Availability"><a href="#Check-Availability" class="headerlink" title="Check Availability"></a>Check Availability</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k --head -X GET http://localhost:5000/v2/</span><br><span class="line"></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Length: 2</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Docker-Distribution-Api-Version: registry/2.0</span><br><span class="line">X-Content-Type-Options: nosniff</span><br><span class="line">Date: Sun, 23 Jun 2019 05:20:01 GMT</span><br></pre></td></tr></table></figure>
<p>This means registry is accessable and user has permission.</p>
<h3 id="List-Images"><a href="#List-Images" class="headerlink" title="List Images"></a>List Images</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k -X GET http://localhost:5000/v2/_catalog</span><br><span class="line"></span><br><span class="line">&#123;&quot;repositories&quot;:[&quot;busybox&quot;]&#125;</span><br></pre></td></tr></table></figure>
<h3 id="List-Image-Tags"><a href="#List-Image-Tags" class="headerlink" title="List Image Tags"></a>List Image Tags</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k -X GET http://localhost:5000/v2/busybox/tags/list</span><br><span class="line"></span><br><span class="line">&#123;&quot;name&quot;:&quot;busybox&quot;,&quot;tags&quot;:[&quot;v1&quot;]&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Delete-Images"><a href="#Delete-Images" class="headerlink" title="Delete Images"></a>Delete Images</h3><p>Deletion of unused digests of docker images to avoid unnecessary space growth in a private docker registry</p>
<p>Deletion is more complicated than list, from <a href="https://docs.docker.com/registry/spec/api/#deleting-an-image" target="_blank" rel="noopener">Deleting an Image API</a>, there are 2 main steps:</p>
<h4 id="Delete-through-API"><a href="#Delete-through-API" class="headerlink" title="Delete through API"></a>Delete through API</h4><ol>
<li>Get the <code>digest</code> of the image with tag <code>v1</code><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k --head -H &quot;Accept: application/vnd.docker.distribution.manifest.v2+json&quot; -X GET http://localhost:5000/v2/busybox/manifests/v1</span><br><span class="line"></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Length: 527</span><br><span class="line">Content-Type: application/vnd.docker.distribution.manifest.v2+json</span><br><span class="line">Docker-Content-Digest: sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff</span><br><span class="line">Docker-Distribution-Api-Version: registry/2.0</span><br><span class="line">Etag: &quot;sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff&quot;</span><br><span class="line">X-Content-Type-Options: nosniff</span><br><span class="line">Date: Sun, 16 Jun 2019 20:12:07 GMT</span><br></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p>Note when deleting a manifest from a registry version 2.3 or later, the following header must be used when HEAD or GET-ing the manifest to obtain the correct digest to delete: <code>Accept: application/vnd.docker.distribution.manifest.v2+json</code>.</p>
<p>You can refer this <a href="https://docs.docker.com/registry/spec/manifest-v2-2/" target="_blank" rel="noopener">Image Manifest V 2, Schema 2</a> to get more header details.</p>
</blockquote>
<p>Here, we use the digest from <code>Docker-Content-Digest</code> field in the header, the vaule is <code>sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff</code>.</p>
<p>Actually, if the docker image is loaded, you can inspect it by:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect localhost:5000/busybox:v1 | less</span><br></pre></td></tr></table></figure></p>
<p>There is a <code>RepoDigests</code> field that also contains the same digest:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">        &quot;RepoDigests&quot;: [</span><br><span class="line">            &quot;busybox@sha256:7a4d4ed96e15d6a3fe8bfedb88e95b153b93e230a96906910d57fc4a13210160&quot;,</span><br><span class="line">            &quot;localhost:5000/busybox@sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff&quot;</span><br><span class="line">        ],</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<ol start="2">
<li>Issue delete command<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k -v -X DELETE http://localhost:5000/v2/busybox/manifests/sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff</span><br><span class="line"></span><br><span class="line">* About to connect() to localhost port 5000 (#0)</span><br><span class="line">*   Trying 127.0.0.1...</span><br><span class="line">* Connected to localhost (127.0.0.1) port 5000 (#0)</span><br><span class="line">&gt; DELETE /v2/busybox/manifests/sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff HTTP/1.1</span><br><span class="line">&gt; User-Agent: curl/7.29.0</span><br><span class="line">&gt; Host: localhost:5000</span><br><span class="line">&gt; Accept: */*</span><br><span class="line">&gt;</span><br><span class="line">&lt; HTTP/1.1 202 Accepted</span><br><span class="line">&lt; Docker-Distribution-Api-Version: registry/2.0</span><br><span class="line">&lt; X-Content-Type-Options: nosniff</span><br><span class="line">&lt; Date: Sun, 16 Jun 2019 20:27:05 GMT</span><br><span class="line">&lt; Content-Length: 0</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>The response <code>HTTP/1.1 202 Accepted</code> means the deletion succeeds, let’s check the tag again:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k -X GET http://localhost:5000/v2/busybox/tags/list</span><br><span class="line"></span><br><span class="line">&#123;&quot;name&quot;:&quot;busybox&quot;,&quot;tags&quot;:null&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that if the docker registry deletion is not enabled, you will get response<br><code>{&quot;errors&quot;:[{&quot;code&quot;:&quot;UNSUPPORTED&quot;,&quot;message&quot;:&quot;The operation is unsupported.&quot;}]}</code>.</p>
</blockquote>
<h4 id="Delete-in-File-System"><a href="#Delete-in-File-System" class="headerlink" title="Delete in File System"></a>Delete in File System</h4><blockquote>
<p>Note this way doesn’t required docker registry is deletion enabled!</p>
</blockquote>
<p>Actually, docker registry stores image in <code>/var/lib/registry/docker/registry/v2/</code>, there are <code>blobs</code> and <code>repositories</code> directories. <code>blobs</code> directory is where images reside and <code>repositories</code> is where metadata and reference locate.</p>
<p>You need to delete two dirs if you mount docker registry storage in host:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &lt;mount path&gt;/registry/v2/repositories/busybox/_manifests/tags/v1/index/sha256/&lt;hash dir&gt;</span><br><span class="line"></span><br><span class="line">rm -rf &lt;mount path&gt;/registry/v2/repositories/busybox/_manifests/revisions/sha256/&lt;hash dir&gt;</span><br></pre></td></tr></table></figure></p>
<p>At the time of deleting those dirs; the docker registry should be in read only mode. Nobody should push to registry.</p>
<h4 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h4><p>However, the API and file system deletions above only remove the <strong>metadata</strong> or dereference the connection between manifest with layers data in disk, we need to run <strong>garbage collection</strong> in docker registry to remove layers:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker exec -it registry sh</span><br></pre></td></tr></table></figure></p>
<p>check space used before clean:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">du -sch /var/lib/registry/docker/</span><br><span class="line"></span><br><span class="line">764.0K  /var/lib/registry/docker/</span><br><span class="line">764.0K  total</span><br></pre></td></tr></table></figure></p>
<p>then run garbage collection:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin/registry garbage-collect /etc/docker/registry/config.yml</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>/etc/docker/registry/config.yml</code> is the configuration file for docker registry.</p>
</blockquote>
<p>then if you check space used again<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">du -sch /var/lib/registry/docker/</span><br><span class="line"></span><br><span class="line">8.0K    /var/lib/registry/docker/</span><br><span class="line">8.0K    total</span><br></pre></td></tr></table></figure></p>
<h3 id="Other-Notice"><a href="#Other-Notice" class="headerlink" title="Other Notice"></a>Other Notice</h3><p>If you have one image with multiple tags and the digests are the same, delete one of them will remove them all.</p>
<p>If you have one image with multiple tags and the digests are different for each tag, deletion is tag-separate.</p>
<h2 id="Secure-Docker-Registry"><a href="#Secure-Docker-Registry" class="headerlink" title="Secure Docker Registry"></a>Secure Docker Registry</h2><p>In ICP4D cluster, we use secure docker registry with <code>https</code> and login credentials. But first let’s understand how to set up secure docker registry, see my blog <a href="https://chengdol.github.io/2019/06/16/docker-secure-registry/" target="_blank" rel="noopener"><code>&lt;&lt;Secure Docker Registry&gt;&gt;</code></a>.</p>
<p>login, see .docker/config<br>curl works?</p>
<h3 id="Check-Availability-1"><a href="#Check-Availability-1" class="headerlink" title="Check Availability"></a>Check Availability</h3><p>If you don’t have authentication, you will get <code>401</code> Unauthorized status, for example, here <code>https://mycluster.icp:8500</code> is the private secure docker registry location:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl --head -k -X GET https://mycluster.icp:8500/v2/</span><br><span class="line"></span><br><span class="line">HTTP/1.1 401 Unauthorized</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Docker-Distribution-Api-Version: registry/2.0</span><br><span class="line">Www-Authenticate: Bearer realm=&quot;https://mycluster.icp:8600/image-manager/api/v1/auth/token&quot;,service=&quot;token-service&quot;</span><br><span class="line">Date: Mon, 24 Jun 2019 16:14:10 GMT</span><br><span class="line">Content-Length: 87</span><br></pre></td></tr></table></figure></p>
<p>Here <code>Www-Authenticate</code> tells you Auth Server address.</p>
<p>In my <code>OpenShift</code> cluster:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k --head -X GET https://172.30.159.11:5000/v2/</span><br><span class="line"></span><br><span class="line">HTTP/1.1 401 Unauthorized</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Docker-Distribution-Api-Version: registry/2.0</span><br><span class="line">Www-Authenticate: Bearer realm=&quot;https://172.30.159.11:5000/openshift/token&quot;</span><br><span class="line">X-Registry-Supports-Signatures: 1</span><br><span class="line">Date: Mon, 24 Jun 2019 16:37:40 GMT</span><br><span class="line">Content-Length: 87</span><br><span class="line"></span><br><span class="line">&#123;&quot;errors&quot;:[&#123;&quot;code&quot;:&quot;UNAUTHORIZED&quot;,&quot;message&quot;:&quot;authentication required&quot;,&quot;detail&quot;:null&#125;]&#125;</span><br></pre></td></tr></table></figure></p>
<p>Need to apply token from Auth Server.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">======================================================================================</span><br><span class="line">I think I get stuck here...</span><br><span class="line">the situation is:</span><br><span class="line">1. I have docker login ability</span><br><span class="line">2. where can I get the token to do API access? auth server, where, how?</span><br><span class="line">3. the platform use what to secure docker registry?</span><br><span class="line"></span><br><span class="line">icp4d cluster is more transparent the Openshfit</span><br><span class="line">======================================================================================</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u openshift:NOyEoOrA0FDm2IgYqlHCDkDepQ7I0vw-7Sx8RzPUmzw -X GET &quot;https://172.30.159.11:5000/openshift/token?service=172.30.159.11:5000&amp;scope=repository:demo1-ds/busybox:pull,push&quot;</span><br></pre></td></tr></table></figure>
<p><a href="https://docs.docker.com/registry/spec/auth/token/" target="_blank" rel="noopener">https://docs.docker.com/registry/spec/auth/token/</a></p>
<h3 id="List-Images-1"><a href="#List-Images-1" class="headerlink" title="List Images"></a>List Images</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="List-Tags"><a href="#List-Tags" class="headerlink" title="List Tags"></a>List Tags</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Remove-Images"><a href="#Remove-Images" class="headerlink" title="Remove Images"></a>Remove Images</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>registry</tag>
      </tags>
  </entry>
  <entry>
    <title>Set up Secure Docker Registry Container</title>
    <url>/2019/06/16/docker-secure-registry/</url>
    <content><![CDATA[<p>This post is about configuring secure docker registry as <strong>docker container</strong>, check <a href="https://chengdol.github.io/2020/01/06/k8s-secure-registry/" target="_blank" rel="noopener">this</a> for setting up secure docker registry pod in K8s. </p>
<blockquote>
<p>More about SSL please check my blog <a href="https://chengdol.github.io/2019/11/29/ssl-demystify/" target="_blank" rel="noopener"><code>SSL Demystify</code></a>. It contains the theory, workflow and practice.</p>
</blockquote>
<p>Securing access to your hosted images is paramount, the registry natively supports <code>TLS</code> and <code>basic authentication</code>, let’s do it.</p>
<p>The Registry GitHub repository includes additional information about advanced authentication and authorization methods. Only very large or public deployments are expected to extend the Registry in this way.</p>
<p>Finally, the Registry ships with a robust notification system, calling webhooks in response to activity, and both extensive logging and reporting, mostly useful for large installations that want to collect metrics.</p>
<h2 id="Generate-Self-signed-Certificate"><a href="#Generate-Self-signed-Certificate" class="headerlink" title="Generate Self-signed Certificate"></a>Generate Self-signed Certificate</h2><p>See <a href="https://docs.docker.com/registry/deploying/#run-an-externally-accessible-registry" target="_blank" rel="noopener">document</a> from docker.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/certs</span><br><span class="line"></span><br><span class="line"><span class="comment">## generate domain.key and self-signed domain.crt</span></span><br><span class="line"><span class="comment">## I use -days 3650</span></span><br><span class="line">openssl req \</span><br><span class="line">      -newkey rsa:4096 -nodes -x509 -sha256\</span><br><span class="line">      -keyout certs/domain.key -out certs/domain.crt -days 3650 \</span><br><span class="line">      -subj <span class="string">"/C=US/ST=CA/L=San Jose/O=&lt;Company Name&gt;/OU=Org/CN=chengdol.registry.com"</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Notice that the <code>CN=chengdol.registry.com</code> must be the registry access url, no port number suffix needed.</p>
</blockquote>
<p>Parameters explanation from <a href="https://linux.die.net/man/1/req" target="_blank" rel="noopener">here</a>:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">openssl</span> <span class="attr">req:</span> </span><br><span class="line">  <span class="string">The</span> <span class="string">req</span> <span class="string">command</span> <span class="string">primarily</span> <span class="string">creates</span> <span class="string">and</span> <span class="string">processes</span> <span class="string">certificate</span> <span class="string">requests</span> <span class="string">in</span> <span class="string">PKCS#10</span> <span class="string">format.</span> <span class="string">It</span> <span class="string">can</span> <span class="string">additionally</span> <span class="string">create</span> <span class="string">self</span> <span class="string">signed</span> <span class="string">certificates</span> <span class="string">for</span> <span class="string">use</span> <span class="string">as</span> <span class="string">root</span> <span class="string">CAs</span> <span class="string">for</span> <span class="string">example.</span></span><br><span class="line"><span class="attr">-newkey:</span> </span><br><span class="line">   <span class="string">this</span> <span class="string">option</span> <span class="string">creates</span> <span class="string">a</span> <span class="string">new</span> <span class="string">certificate</span> <span class="string">request</span> <span class="string">and</span> <span class="string">a</span> <span class="string">new</span> <span class="string">private</span> <span class="string">key.</span> </span><br><span class="line"><span class="attr">  rsa:</span><span class="attr">nbits:</span> </span><br><span class="line">    <span class="string">where</span> <span class="string">nbits</span> <span class="string">is</span> <span class="string">the</span> <span class="string">number</span> <span class="string">of</span> <span class="string">bits,</span> <span class="string">generates</span> <span class="string">an</span> <span class="string">RSA</span> <span class="string">key</span> <span class="string">nbits</span> <span class="string">in</span> <span class="string">size.</span></span><br><span class="line"><span class="attr">-nodes:</span></span><br><span class="line">  <span class="string">if</span> <span class="string">this</span> <span class="string">option</span> <span class="string">is</span> <span class="string">specified</span> <span class="string">then</span> <span class="string">if</span> <span class="string">a</span> <span class="string">private</span> <span class="string">key</span> <span class="string">is</span> <span class="string">created</span> <span class="string">it</span> <span class="string">will</span> <span class="string">not</span> <span class="string">be</span> <span class="string">encrypted.</span></span><br><span class="line"><span class="attr">-x509:</span> </span><br><span class="line">  <span class="string">this</span> <span class="string">option</span> <span class="string">outputs</span> <span class="string">a</span> <span class="string">self</span> <span class="string">signed</span> <span class="string">certificate</span> <span class="string">instead</span> <span class="string">of</span> <span class="string">a</span> <span class="string">certificate</span> <span class="string">request.</span> <span class="string">This</span> <span class="string">is</span> <span class="string">typically</span> <span class="string">used</span> <span class="string">to</span> <span class="string">generate</span> <span class="string">a</span> <span class="string">test</span> <span class="string">certificate</span> <span class="string">or</span> <span class="string">a</span> <span class="string">self</span> <span class="string">signed</span> <span class="string">root</span> <span class="string">CA</span> <span class="string">.</span></span><br><span class="line"><span class="bullet">-</span><span class="string">[digest]:</span></span><br><span class="line">  <span class="string">this</span> <span class="string">specifies</span> <span class="string">the</span> <span class="string">message</span> <span class="string">digest</span> <span class="string">to</span> <span class="string">sign</span> <span class="string">the</span> <span class="string">request</span> <span class="string">with</span> <span class="string">(such</span> <span class="string">as</span> <span class="bullet">-md5,</span> <span class="bullet">-sha1,</span> <span class="bullet">-sha256)</span></span><br><span class="line"><span class="attr">-keyout:</span></span><br><span class="line">  <span class="string">this</span> <span class="string">gives</span> <span class="string">the</span> <span class="string">filename</span> <span class="string">to</span> <span class="string">write</span> <span class="string">the</span> <span class="string">newly</span> <span class="string">created</span> <span class="string">private</span> <span class="string">key</span> <span class="string">to.</span></span><br><span class="line"><span class="attr">-out:</span></span><br><span class="line">  <span class="string">this</span> <span class="string">specifies</span> <span class="string">the</span> <span class="string">output</span> <span class="string">filename</span> <span class="string">to</span> <span class="string">write</span> <span class="string">to</span> <span class="string">or</span> <span class="string">standard</span> <span class="string">output</span> <span class="string">by</span> <span class="string">default.</span></span><br><span class="line"><span class="attr">-days:</span></span><br><span class="line">  <span class="string">when</span> <span class="string">the</span> <span class="bullet">-x509</span> <span class="string">option</span> <span class="string">is</span> <span class="string">being</span> <span class="string">used</span> <span class="string">this</span> <span class="string">specifies</span> <span class="string">the</span> <span class="string">number</span> <span class="string">of</span> <span class="string">days</span> <span class="string">to</span> <span class="string">certify</span> <span class="string">the</span> <span class="string">certificate</span> <span class="string">for.</span> <span class="string">The</span> <span class="string">default</span> <span class="string">is</span> <span class="number">30</span> <span class="string">days.</span></span><br><span class="line"><span class="attr">-subj:</span></span><br><span class="line">  <span class="string">replaces</span> <span class="string">subject</span> <span class="string">field</span> <span class="string">of</span> <span class="string">input</span> <span class="string">request</span> <span class="string">with</span> <span class="string">specified</span> <span class="string">data</span> <span class="string">and</span> <span class="string">outputs</span> <span class="string">modified</span> <span class="string">request.</span> <span class="string">The</span> <span class="string">arg</span> <span class="string">must</span> <span class="string">be</span> <span class="string">formatted</span> <span class="string">as</span> <span class="string">/type0=value0/type1=value1/type2=...,</span> <span class="string">characters</span> <span class="string">may</span> <span class="string">be</span> <span class="string">escaped</span> <span class="string">by</span> <span class="string">\</span> <span class="string">(backslash),</span> <span class="literal">no</span> <span class="string">spaces</span> <span class="string">are</span> <span class="string">skipped.</span></span><br></pre></td></tr></table></figure></p>
<p>There are mutli-way to do the same thing，一步一步的构造self-signed certificate:<br><a href="https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs" target="_blank" rel="noopener">OpenSSL Essentials: Working with SSL Certificates, Private Keys and CSRs</a></p>
<h2 id="Setup-Secure-Docker-Registry"><a href="#Setup-Secure-Docker-Registry" class="headerlink" title="Setup Secure Docker Registry"></a>Setup Secure Docker Registry</h2><p>see <a href="https://docs.docker.com/registry/deploying/#run-the-registry-as-a-service" target="_blank" rel="noopener">document</a> from docker.</p>
<p>We have the <code>certs</code> folder with crt and key created by openssl.<br>Start the docker registry container, using TLS certificate:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --restart=always \</span><br><span class="line">  --name registry \</span><br><span class="line">  -v /root/certs:/certs \</span><br><span class="line">  -e REGISTRY_HTTP_ADDR=0.0.0.0:443 \</span><br><span class="line">  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \</span><br><span class="line">  -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \</span><br><span class="line">  -p 443:443 \</span><br><span class="line">  registry:2</span><br></pre></td></tr></table></figure></p>
<p>Here we overwrite some env variables to change the default configuration.</p>
<p>Also follow the instruction in docker web, instruct <code>every</code> docker daemon to trust that certificate. The way to do this depends on your OS, for Linux:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/docker/certs.d/&lt;docker registry domain&gt;/</span><br><span class="line"><span class="comment">## copy domain.crt (generate by openssl) to this folder on every Docker host</span></span><br><span class="line">cp /root/certs/domain.crt /etc/docker/certs.d/&lt;docker registry domain&gt;/</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意，Docker官方文档中用的是<code>&lt;docker registry domain&gt;:5000/</code>文件夹名，但如果你配置的是443端口,则会出错，通过Docker daemon中的log，发现对于443端口，这里不需要<code>:5000</code>. 但如果设置了basic authentication且用的是5000端口，则需要了。</p>
</blockquote>
<blockquote>
<p>当时还发生了奇怪的事情，我发现不需要这个trust操作居然也能进行push，后来才发现原来是旧配置在docker daemon json 文件中设置了insecure registry，这样一来根本就不会检查证书了。</p>
</blockquote>
<p>If you don’t do this, when run docker push you will get this error:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Error response from daemon: Get https://chengdol.registry.com/v2/: x509: certificate signed by unknown authority</span><br></pre></td></tr></table></figure></p>
<p>If docker still complains about the certificate when using authentication?<br>When using authentication, some versions of Docker also require you to trust the certificate at the OS level.</p>
<p>For RedHat, do:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp certs/domain.crt /etc/pki/ca-trust/<span class="built_in">source</span>/anchors/myregistrydomain.com.crt</span><br><span class="line">update-ca-trust</span><br></pre></td></tr></table></figure></p>
<p>Now you can push and pull like below, no need to specify port number, it will use 443 port:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull ubuntu</span><br><span class="line">docker tag ubuntu chengdol.registry.com/ubuntu:v1</span><br><span class="line">docker push chengdol.registry.com/ubuntu:v1</span><br><span class="line">docker pull chengdol.registry.com/ubuntu:v1</span><br></pre></td></tr></table></figure></p>
<p>So far, secure configuration is done, now the docker registry will use <code>HTTPS</code> in <code>443</code> port to communciate with docker client. If you want to setup basic authentication, see below:</p>
<h2 id="Setup-Basic-Authrntication"><a href="#Setup-Basic-Authrntication" class="headerlink" title="Setup Basic Authrntication"></a>Setup Basic Authrntication</h2><blockquote>
<p>Warning: You cannot enable authentication that send credentials as clear text. You <strong>must</strong> configure <code>TLS</code> first for authentication to work.</p>
</blockquote>
<p>Use <code>htpasswd</code> to create the user info:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/auth</span><br><span class="line">htpasswd -Bbn demo demo &gt; /root/auth/htpasswd</span><br></pre></td></tr></table></figure></p>
<p>Then, we switch back to <code>5000</code> port: (注意这里没用443端口)<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  -p 5000:5000 \</span><br><span class="line">  --restart=always \</span><br><span class="line">  --name registry \</span><br><span class="line">  -v /root/auth:/auth \</span><br><span class="line">  -e &quot;REGISTRY_AUTH=htpasswd&quot; \</span><br><span class="line">  -e &quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm&quot; \</span><br><span class="line">  -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \</span><br><span class="line">  -v /root/certs:/certs \</span><br><span class="line">  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \</span><br><span class="line">  -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \</span><br><span class="line">  registry:2</span><br></pre></td></tr></table></figure></p>
<p>Do the same trust thing in <code>every</code> docker host, under <code>/etc/docker/certs.d/</code> directory, we create a folder <code>&lt;docker registry domain&gt;:5000</code> and put domain.crt in it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/docker/certs.d/&lt;docker registry domain&gt;:5000/</span><br><span class="line"><span class="comment">## copy domain.crt (generate by openssl) to this folder on every Docker host</span></span><br><span class="line">cp domain.crt /etc/docker/certs.d/&lt;docker registry domain&gt;:5000/</span><br></pre></td></tr></table></figure></p>
<p>Then, you need to first login to push or pull:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker login &lt;docker registry domain&gt;:5000 -u demo -p demo</span><br></pre></td></tr></table></figure></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>OK, now a secure docker registry container with basic authentication is up and running. You can push and pull after docker login.</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>registry</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Smart Use</title>
    <url>/2020/09/15/docker-smart-use/</url>
    <content><![CDATA[<p>这里主要记录一下docker container 一些有意思的用法。</p>
<p>把一些需要依赖的tool build到docker image中，然后运行docker container去工作，把需要处理的资源mount到container中:<br>比如 helm linter cv:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run \</span><br><span class="line">      --rm \</span><br><span class="line">      -it \</span><br><span class="line">      -v pathto/chart:/chart \</span><br><span class="line">      cv:latest cv lint helm /chart</span><br></pre></td></tr></table></figure></p>
<p>Logs may also be captured by passing an additional volume: <code>-v ~/path/to/logs:/tmp/cv</code></p>
<p>再比如jsonnet，搭建本地运行环境比较困难:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># convert chart.yaml.jsonnet to chart.yaml</span></span><br><span class="line"><span class="comment"># -V version="1": pass parameters to chart.yaml.jsonnet</span></span><br><span class="line"><span class="comment"># sed -e 's/"//g': remove double quotes</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># the entrypoint of this image is running jsonnet command</span></span><br><span class="line">docker run \</span><br><span class="line">      --rm \</span><br><span class="line">      -v pathto/chart.yaml.jsonnet:/chart.yaml.jsonnet \</span><br><span class="line">      bitnami/jsonnet:latest /chart.yaml.jsonnet -V version=<span class="string">"1"</span> -S | sed -e <span class="string">'s/"//g'</span></span><br></pre></td></tr></table></figure></p>
<p>来到新组后发现对所有的repo 源码都是封装到docker 中，通过gitlab-ci pipeline 发布，然后在jenkins pipeline中使用。</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Skopeo</title>
    <url>/2019/09/26/docker-skopeo/</url>
    <content><![CDATA[<p><code>skopeo</code> is a command line utility that performs various operations on container images and image repositories. see it’s <a href="https://github.com/containers/skopeo" target="_blank" rel="noopener">git repos</a>. This is really a fantastic tool! Other two complementaries are <code>buildah</code> and <code>podman</code>.</p>
<p>Command usage see <a href="https://github.com/containers/skopeo/tree/master/docs" target="_blank" rel="noopener">here</a>.</p>
<p>In Red Hat/Centos, you can use <code>yum</code> to install skopeo.</p>
<blockquote>
<p>Note the docker registry should be secured by SSL/TLS, basic authentication can also apply.</p>
</blockquote>
<blockquote>
<p>Skopeo can do paralelly copy, you can run several skopeo processes in background then wait.</p>
</blockquote>
<h2 id="Docker-Installed"><a href="#Docker-Installed" class="headerlink" title="Docker Installed"></a>Docker Installed</h2><p>In docker environmet, skopeo will check <code>$HOME/.docker/config.json</code> file for authentication (created by docker login command). If the auth file is there, you are good and you can directly copy image tar (or gzip tar) to docker registry and copy image directly from docker registry to local docker daemon for example (can use docker hub to do test):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo copy \</span><br><span class="line">       docker-archive:&lt;absolute or relative path&gt;/&lt;tar name&gt;.tar.gz \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br><span class="line"></span><br><span class="line">skopeo copy \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag \</span><br><span class="line">       docker-daemon:&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<p>This is extremely efficient compare to old load/tag/push method. Many other benefits like no docker daemon needed, rootless please see doc.</p>
<p>Inspect docker image in registry:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo inspect \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<p>Delete image in registry<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo delete \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>You must enable deletion in docker registry <a href="https://docs.docker.com/registry/configuration/#override-specific-configuration-options" target="_blank" rel="noopener">configuration</a>: </p>
</blockquote>
<h2 id="No-Docker-Installed"><a href="#No-Docker-Installed" class="headerlink" title="No Docker Installed"></a>No Docker Installed</h2><p>If there is no docker daemon, skopeo will still work, but you need to explicitly give the auth creds and ssl/tls certificates path of the target registry, for example, the destination registry login user name and password are both <code>demo</code>, and the certificates path for ssl/tls is <code>/root/certs</code> (<strong>must</strong> include *.key, *.crt and *.cert, the *.crt and *.cert could be the same content if it’s self-signed).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo copy \</span><br><span class="line">       --dest-creds demo:demo \</span><br><span class="line">       --dest-cert-dir /root/certs \</span><br><span class="line">       docker-archive:&lt;absolute or relative path&gt;/&lt;tar name&gt;.tar.gz \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br><span class="line"></span><br><span class="line">skopeo copy \</span><br><span class="line">       --src-creds demo:demo \</span><br><span class="line">       --src-cert-dir /root/certs \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag \</span><br><span class="line">       docker-daemon:&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<p>Inspect docker image in registry:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo inspect \</span><br><span class="line">       --creds demo:demo \</span><br><span class="line">       --cert-dir /root/certs \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<p>Delete image in registry<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo delete \</span><br><span class="line">       --creds demo:demo \</span><br><span class="line">       --cert-dir /root/certs \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>You must enable deletion in docker registry <a href="https://docs.docker.com/registry/configuration/#override-specific-configuration-options" target="_blank" rel="noopener">configuration</a>: </p>
</blockquote>
<h2 id="Other-Use-Case"><a href="#Other-Use-Case" class="headerlink" title="Other Use Case"></a>Other Use Case</h2><p>One important use case is we pre-load image to target host machine because we pre-assign some application runs on some dedicated nodes. Pre-load will save much time from pull if the image is big, the application pod will up and run instantly.</p>
<p>So, how to copy image tarball from local to remote machine docker daemon? Yes there are <code>--src-daemon-host</code> and <code>--dest-daemon-host</code> options, but how?</p>
<p>Refer <a href="https://docs.docker.com/install/linux/linux-postinstall/#configure-where-the-docker-daemon-listens-for-connections" target="_blank" rel="noopener">document</a> from docker:<br>By default, the Docker daemon listens for connections on a <code>UNIX socket</code> to accept requests from local clients. It is possible to allow Docker to accept requests from remote hosts by configuring it to <code>listen</code> on an IP address and port as well as the UNIX socket.</p>
<p>So, let first open the port in target host:<br>It is conventional to use port <code>2375</code> for un-encrypted, and port <code>2376</code> for encrypted communication with the daemon.</p>
<blockquote>
<p>注意，这里我只考虑了un-encrypted，因为设置encrypted connection可能会影响kubelet对docker的操控，我在使用完后关闭了这一端口，并且如果集群有单独的网关且访问worker nodes的IP是内部的，影响也不大。</p>
</blockquote>
<p>Here we can configure remote access with <strong>systemd unit file</strong> or with <strong>daemon.json</strong>, I prefer the second one, because after systemd unit file update, I need to reload then restart docker:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></p>
<p>Using daemon json file only need to restart, just add this line to it:<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"hosts"</span>: [<span class="string">"unix:///var/run/docker.sock"</span>, <span class="string">"tcp://0.0.0.0:2375"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>You can listen on port <code>2375</code> on all network interfaces(eg: <code>0.0.0.0</code>), or on a particular network interface using its IP address(eg: <code>172.192.10.1</code>). </p>
<p>After restart docker service, check the port status:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">netstat -lntp | grep 2375</span><br></pre></td></tr></table></figure></p>
<p>Now we can execute copy:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo copy \</span><br><span class="line">       --dest-daemon-host http://&lt;target machine hostname or ip&gt;:2375 \</span><br><span class="line">       docker-archive:&lt;path&gt;/&lt;image tarball name&gt;.tar.gz \</span><br><span class="line">       docker-daemon:&lt;image name&gt;:&lt;tag&gt;</span><br></pre></td></tr></table></figure></p>
<p>Check these articles:<br><a href="https://www.redhat.com/en/blog/skopeo-copy-rescue" target="_blank" rel="noopener">Skopeo Copy to the Rescue</a></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>skopeo</tag>
      </tags>
  </entry>
  <entry>
    <title>Drone View</title>
    <url>/2019/12/04/drone-view/</url>
    <content><![CDATA[<p>2019年12月4日，我拿到了DJI Mavic 2 Pro，其他配件正在陆续抵达中。很高兴，要开始一个体验生活的新分支了，并且是从一个前所未有的角度看世界。我准备用几年时间打造一个自己的channel，分享鸟瞰美景，记录足迹。很多东西要学，除了维护保养，操控，还有摄影，剪辑等等目前我也是几乎没有经验，Let’s go!</p>
<p>在这里我会记录一些关于无人机拍摄的技巧，以及其他相关的方面，当然，还有我的作品。<br>我想提醒的是无人机是一件复杂设备，前期学习很重要，否则会对产品，人身安全或其他财产造成伤害。</p>
<blockquote>
<p>02/01/2020 还未首飞😑，还在忙其他非常重要的事情！春天已经来了.</p>
</blockquote>
<blockquote>
<p>04/09/2020 还未首飞😌，新冠肺炎疫情爆发了，重要的事情还没忙完！唉。。。</p>
</blockquote>
<p>Some references:<br><a href="https://www.youtube.com/watch?v=tYrnNYgbglY" target="_blank" rel="noopener">DJI mavic 2 pro beginner guide</a></p>
<h1 id="电池指南"><a href="#电池指南" class="headerlink" title="电池指南"></a>电池指南</h1><p>一定要仔细阅读大疆的电池手册，挺多注意事项的，总结一下:</p>
<h2 id="使用注意"><a href="#使用注意" class="headerlink" title="使用注意"></a>使用注意</h2><ol>
<li>禁止接触任何液体</li>
<li>不要使用非大疆官方电池</li>
<li>不要给abnormal电池充电</li>
<li>不要在电池turn on时从无人机上安装或拆卸</li>
<li>使用温度范围-10 ~ 40摄氏度，温度过高请自然冷却后使用</li>
<li>远离强电磁环境，可能损害电池控制板</li>
<li>不要重压</li>
<li>不要exhaust电池</li>
<li>注意电池的隔离，防止接口短路</li>
<li>飞行前确保电池充满</li>
</ol>
<h2 id="充电注意"><a href="#充电注意" class="headerlink" title="充电注意"></a>充电注意</h2><ol>
<li>使用大疆认证的充电器</li>
<li>充电前请turn off电池</li>
<li>不要在充电时离开</li>
<li>不要飞行后立马充电，防止温度过高，理想充电温度22 ~ 28摄氏度</li>
<li>大疆充电器会在充满后自己切断，但最好人为及时断开</li>
</ol>
<h2 id="存放注意"><a href="#存放注意" class="headerlink" title="存放注意"></a>存放注意</h2><ol>
<li>长期存贮确保充电至40 ~ 60%</li>
<li>不要在天热时将电池放在车内</li>
<li>电池在10天未使用时会自动发热放电至60%</li>
<li>每3个月至少完整充放电一次</li>
<li>电池存储温度-10 ~ 45摄氏度</li>
<li>长期不使用电池会休眠，充电唤醒</li>
<li>将电池从无人机上取下单独长期存放</li>
</ol>
<h2 id="旅行注意"><a href="#旅行注意" class="headerlink" title="旅行注意"></a>旅行注意</h2><ol>
<li>登机前，将电池释放至30%以下，可以通过飞行消耗实现</li>
</ol>
<h1 id="安全须知"><a href="#安全须知" class="headerlink" title="安全须知"></a>安全须知</h1><h2 id="飞行环境"><a href="#飞行环境" class="headerlink" title="飞行环境"></a>飞行环境</h2><ol>
<li>飞行远离复杂电磁环境</li>
<li>飞行高度在6000米以上可能影响性能</li>
<li>飞行环境温度:-10 ~ 40摄氏度</li>
<li>环境风速小于10m/s</li>
<li>注意所在地是否允许无人机飞行</li>
</ol>
<h2 id="飞前检查"><a href="#飞前检查" class="headerlink" title="飞前检查"></a>飞前检查</h2><ol>
<li>检查传感器无遮挡</li>
<li>遥控器以及无人机电池充满状态</li>
<li>电池安装正确牢固</li>
<li>螺旋桨臂正确展开</li>
<li>螺旋桨无破损，安装牢固</li>
<li>摄像头清洁无污染，伸缩旋转无阻碍</li>
<li>仅在设备要求时校准罗盘</li>
<li>熟悉选择的飞行模式，理解各项功能以及航行警报</li>
</ol>
<h2 id="飞行操作"><a href="#飞行操作" class="headerlink" title="飞行操作"></a>飞行操作</h2><ol>
<li>在智能飞行模式时，不要靠近强反射面，比如水面或雪地，传感器或受影响</li>
<li>降落后，首先关闭引擎，然后依次关闭电池，遥控器</li>
</ol>
]]></content>
      <categories>
        <category>Drone View</category>
      </categories>
      <tags>
        <tag>drone</tag>
      </tags>
  </entry>
  <entry>
    <title>Ceph</title>
    <url>/2020/01/20/fs-ceph/</url>
    <content><![CDATA[<h2 id="ceph-github"><a href="#ceph-github" class="headerlink" title="ceph github"></a>ceph github</h2><p><a href="https://github.com/ceph/ceph" target="_blank" rel="noopener">https://github.com/ceph/ceph</a></p>
<h2 id="Ceph-for-object-storage-block-storage-and-network-file-system"><a href="#Ceph-for-object-storage-block-storage-and-network-file-system" class="headerlink" title="Ceph for object storage, block storage and network file system"></a>Ceph for object storage, block storage and network file system</h2><p>Ceph uniquely delivers object, block, and file storage in one unified system.<br>differences:<br><a href="https://cloudian.com/blog/object-storage-vs-block-storage/" target="_blank" rel="noopener">https://cloudian.com/blog/object-storage-vs-block-storage/</a></p>
<h2 id="for-cephFS-https-docs-ceph-com-docs-master"><a href="#for-cephFS-https-docs-ceph-com-docs-master" class="headerlink" title="for cephFS, https://docs.ceph.com/docs/master/"></a>for cephFS, <a href="https://docs.ceph.com/docs/master/" target="_blank" rel="noopener">https://docs.ceph.com/docs/master/</a></h2><p>what does NFS/CIFS deployable mean?</p>
<h2 id="how-to-begin"><a href="#how-to-begin" class="headerlink" title="how to begin:"></a>how to begin:</h2><p><a href="https://docs.ceph.com/docs/master/start/intro/" target="_blank" rel="noopener">https://docs.ceph.com/docs/master/start/intro/</a><br>Whether you want to provide Ceph Object Storage and/or Ceph Block Device services to Cloud Platforms, deploy a Ceph File System or use Ceph for another purpose, all Ceph Storage Cluster deployments begin with setting up each Ceph Node, your network, and the Ceph Storage Cluster. </p>
<blockquote>
<p>ceph ansible playbook?</p>
</blockquote>
<h2 id="ceph-can-be-installed-by-cephadm-like-k8s-by-kubeadm-："><a href="#ceph-can-be-installed-by-cephadm-like-k8s-by-kubeadm-：" class="headerlink" title="ceph can be installed by cephadm (like k8s by kubeadm)："></a>ceph can be installed by cephadm (like k8s by kubeadm)：</h2><p><a href="https://docs.ceph.com/docs/master/bootstrap/#installation-cephadm" target="_blank" rel="noopener">https://docs.ceph.com/docs/master/bootstrap/#installation-cephadm</a><br>cannot get cephadm from yum install, need to install ceph repos and get rpms</p>
<p>构造好ceph cluster，现在的问题是怎么和k8s联合起来？</p>
]]></content>
      <categories>
        <category>Storage</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ceph</tag>
        <tag>filesystem</tag>
      </tags>
  </entry>
  <entry>
    <title>NFS Server and Client Setup</title>
    <url>/2019/05/27/fs-nfs/</url>
    <content><![CDATA[<p>This blog only sets up one NFS server that may be single point of failure.</p>
<p>NFS allows remote hosts to mount <code>filesystems</code>(can be any) over a network and interact with those filesystems as though they are mounted locally. </p>
<blockquote>
<p>NFS是一个概念，它不是一个文件系统，它是一种文件系统的共享方式, 这里默认使用本地Linux的文件系统了。</p>
</blockquote>
<p>NFS lets you leverage storage space in a different location and allows you to write onto the same space from multiple servers or clients in an effortless manner. It, thus, works fairly well for directories that users need to access frequently.</p>
<h1 id="Server-Setup"><a href="#Server-Setup" class="headerlink" title="Server Setup"></a>Server Setup</h1><p>Acutally there are many other package may needed, this <a href="https://www.youtube.com/watch?v=MBqZe5d9BNQ" target="_blank" rel="noopener">video</a> may give you more details.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install nfs package</span></span><br><span class="line">yum -y install nfs-utils</span><br></pre></td></tr></table></figure></p>
<p>Then enable and start nfs server:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># the rpc by default should be on, but may not</span></span><br><span class="line"><span class="comment"># rpc is called remote producture call</span></span><br><span class="line"><span class="comment"># nfs server needs this to access and operate on others</span></span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl start rpcbind</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> nfs-server.service</span><br><span class="line">systemctl start nfs-server.service</span><br><span class="line"><span class="comment"># create server side shared folder</span></span><br><span class="line">mkdir –p /data</span><br><span class="line">chmod –R 755 /data</span><br></pre></td></tr></table></figure></p>
<p>Edit <code>/etc/exports</code> file to expose shared folder<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/exports </span><br><span class="line"></span><br><span class="line"><span class="comment"># any client can access this folder</span></span><br><span class="line">/data *(rw,insecure,async,no_root_squash)   </span><br><span class="line"><span class="comment"># or specific client can access this folder</span></span><br><span class="line">/data &lt;client ip&gt;(rw,insecure,async,no_root_squash)</span><br></pre></td></tr></table></figure></p>
<p>Then export the shared folder:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">exportfs -a</span><br><span class="line">systemctl restart nfs-server.service</span><br></pre></td></tr></table></figure></p>
<p>Check shared folder is up <code>showmount -e &lt;server ip&gt;</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">showmount -e localhost</span><br></pre></td></tr></table></figure></p>
<p>If you change the content in <code>/etc/exports</code>, need to reload:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">exportfs -ra</span><br></pre></td></tr></table></figure></p>
<p>Check mount options:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">exportfs -v</span><br></pre></td></tr></table></figure></p>
<h1 id="Client-Setup"><a href="#Client-Setup" class="headerlink" title="Client Setup"></a>Client Setup</h1><p>First create or using existing folder as folder to mount, here I use <code>/mntiis</code> folder in client machine<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install nfs package</span></span><br><span class="line">yum -y install nfs-utils</span><br><span class="line"></span><br><span class="line"><span class="comment"># create client side shared folder</span></span><br><span class="line">mkdir -p /mntiis</span><br><span class="line">chmod -R 0755 /mntiis</span><br></pre></td></tr></table></figure></p>
<p>If you use non-persistent mount in command line, this connection will disappear after rebooting:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mount &lt;server ip&gt;:/data     /mntiis</span><br></pre></td></tr></table></figure></p>
<p>For persistent mount, go to <code>/etc/fstab</code> file, add this line<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;server ip&gt;:/data /mntiis nfs defaults 0 0</span><br><span class="line"><span class="comment"># or with other mount options</span></span><br><span class="line">&lt;server ip&gt;:/data /mntiis nfs defaults,timeo=10,retrans=3,rsize=1048576,wsize=1048576 0 0</span><br></pre></td></tr></table></figure></p>
<p>Enable mount:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mount /mntiis</span><br><span class="line"><span class="comment"># or reload all in fstab file</span></span><br><span class="line">mount -a</span><br></pre></td></tr></table></figure></p>
<p>Verify all set, you can see the <code>/mntiis</code> in the output:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -hk</span><br></pre></td></tr></table></figure></p>
<p>When you remove the entry in <code>/etc/fstab</code> filem, also unmount the folder, otherwise you will see <code>/mntiis</code> is marked by <code>?</code> in filesystem:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">umount /mntiis</span><br></pre></td></tr></table></figure></p>
<h1 id="Autofs"><a href="#Autofs" class="headerlink" title="Autofs"></a>Autofs</h1><p>You can set NFS auto mount on-demand via <code>autofs</code>, this can avoid wasting resources by unmounting mount point when not using and mounting it when access again.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y autofs</span><br><span class="line">systemctl start autofs</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Storage</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>filesystem</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Clean Local Working Branch</title>
    <url>/2019/06/28/git-clean-reset/</url>
    <content><![CDATA[<p>Sometimes if the local working branch mess up and you want to sync up with your remote branch, for example origin master, first remove all untracked files:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -d: remove untracked dirs</span></span><br><span class="line"><span class="comment"># -f: force</span></span><br><span class="line">git clean -df</span><br><span class="line"><span class="comment"># -x: remove ignored files as well</span></span><br><span class="line">git clean -dfx</span><br></pre></td></tr></table></figure></p>
<p>you can have a dry-run first to see what files will be removed<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -n: dry run</span></span><br><span class="line">git clean -dfn</span><br></pre></td></tr></table></figure></p>
<p>Check the commit logsin current branch:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># verbose</span></span><br><span class="line"><span class="comment"># -n: commit number</span></span><br><span class="line">git <span class="built_in">log</span> -n 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># oneline and color</span></span><br><span class="line"><span class="comment"># color: show color</span></span><br><span class="line">git <span class="built_in">log</span> --oneline --color -n 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># -p: show diff for each commit</span></span><br><span class="line">git <span class="built_in">log</span> -p --oneline --color -n 10</span><br><span class="line"></span><br><span class="line"><span class="comment"># show branch relationship</span></span><br><span class="line"><span class="comment"># --graph: show ascii graph</span></span><br><span class="line">git <span class="built_in">log</span> --graph --oneline --color -n 10</span><br></pre></td></tr></table></figure></p>
<p>Then properly select one good commit that also appears in remote master branch, run<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git reset --hard &lt;good commit <span class="built_in">hash</span>&gt;</span><br></pre></td></tr></table></figure></p>
<p>All the commits after the specified good commit hash will be removed, then you can just run the command below to sync up remote master branch.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git pull origin master</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that it’s safe to do git reset here because only I use this branch and I want to clean</p>
</blockquote>
<p>Sometimes I see people use:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># reset to current commit, discard all uncommitted changes</span></span><br><span class="line">git reset --hard HEAD</span><br><span class="line"><span class="comment"># HEAD~1: move to the commit immediately before HEAD</span></span><br><span class="line">git reset --hard HEAD~1</span><br></pre></td></tr></table></figure></p>
<p><code>HEAD</code> points to your current commit, check by:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get HEAD short hash</span></span><br><span class="line">git rev-parse --short HEAD</span><br></pre></td></tr></table></figure></p>
<p>so all that <code>git reset --hard HEAD</code> will do is to throw away any uncommitted changes you have and point to your latest commit.</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Repository Browser</title>
    <url>/2019/06/28/git-gitk/</url>
    <content><![CDATA[<blockquote>
<p>Note in order to run <code>gitk</code> from terminal you need to have a Desktop GUI environment (for example VNC).</p>
</blockquote>
<p><code>gitk</code> is a graphical history viewer. Think of it like a powerful GUI shell over git log and git grep. This is the tool to use when you’re trying to find something that happened in the past, or visualize your project’s history</p>
<h2 id="Install-gitk"><a href="#Install-gitk" class="headerlink" title="Install gitk"></a>Install gitk</h2><p>For CentOS and RedHat:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y gitk</span><br></pre></td></tr></table></figure></p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p><code>gitk</code> is easy to invoke from the command-line. Just <code>cd</code> into your target git repository, and type:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitk</span><br></pre></td></tr></table></figure></p>
<p>Then a dedicated GUI will be launched for you:<br><img src="https://drive.google.com/uc?id=19b_uKeMXctg0QPFTqjzQCmL7b4VA3x4R" alt=""></p>
<p>You can get a brief usage introduction from <code>man gitk</code>, for example, if I want to see the commit history of <code>hello.sh</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitk &lt;path to file&gt;/hello.sh</span><br></pre></td></tr></table></figure></p>
<p>Show all branches:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitk --all</span><br></pre></td></tr></table></figure></p>
<h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h2><p><a href="https://lostechies.com/joshuaflanagan/2010/09/03/use-gitk-to-understand-git/" target="_blank" rel="noopener">Use gitk to understand git</a></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>gitk</tag>
      </tags>
  </entry>
  <entry>
    <title>Create Pull Request</title>
    <url>/2019/12/24/git-create-pull-request/</url>
    <content><![CDATA[<p>In my blog <a href="https://chengdol.github.io/2019/09/12/git-create-working-branch/" target="_blank" rel="noopener">Create Working Branch</a>, when run <code>git push origin &lt;non-master&gt;</code>, we actually create a pull request.</p>
<p>More <a href="https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request" target="_blank" rel="noopener">references</a>, it also talks about create  pull request from fork</p>
<p>I am sometimes confusing about the term, why is called <code>pull request</code> not <code>push request</code> (because I push my code to other repo)? And I am not alone, a reasonable explanation see <a href="https://stackoverflow.com/questions/21657430/why-is-a-git-pull-request-not-called-a-push-request" target="_blank" rel="noopener">here</a>: Because You are asking the target repository grab your changes, stand on their side it is a pulling operation.</p>
<p>If the changes in local branch <code>develop</code> are ready, but the remote branch <code>develop</code> is out of date, after <code>git pull origin develop</code> your local get messy, you can use <code>git reset --hard</code> roll back to the last commit you made, next delete remote one on git web, then do the <code>git push origin develop</code>.</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Versioning Large File in Git</title>
    <url>/2019/02/24/git-lfs/</url>
    <content><![CDATA[<p>I want to introduce you <a href="https://git-lfs.github.com/" target="_blank" rel="noopener">Git LFS</a>, it is a command line extension and <a href="https://github.com/git-lfs/git-lfs/blob/master/docs/spec.md" target="_blank" rel="noopener">specification</a> for managing large files with Git. LFS is great for <strong>large, changing files</strong>, there is basically a text pointer to the large file archived some place else.</p>
<p>Usually we store large file or object in artifactory, for example: <code>jFrog</code>, <code>Nexus</code>, etc.</p>
<h3 id="Install-Git-LFS"><a href="#Install-Git-LFS" class="headerlink" title="Install Git LFS"></a>Install Git LFS</h3><blockquote>
<p>Note: you need to install <code>Git LFS</code> if you <code>git pull</code> from a remote repository that has it</p>
</blockquote>
<p>For example, I am working on a RHEL machine.<br>First go to source page, follow the installation guide to install:</p>
<p><img src="https://drive.google.com/uc?id=1c2hUDmTQwOnD3GNz8S1QHfkyGwLzO5ur" alt=""></p>
<p><img src="https://drive.google.com/uc?id=1Zhnjd815gHSBJFySqdAyvfqSDeZtd0oc" alt=""></p>
<p>This will create a yum repos for git-lfs:</p>
<p><img src="https://drive.google.com/uc?id=1BtoVGRjTz1PHXplO5OuJnhYMy8oJPzKl" alt=""></p>
<p><img src="https://drive.google.com/uc?id=1F4NO7fUTtq0cP0bfgm8EGNlIrvKAjp1T" alt=""></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y git-lfs</span><br></pre></td></tr></table></figure>
<p>you can see git-lfs is installed in your machine:<br><img src="https://drive.google.com/uc?id=12xtxpkkbAzSjSXAecwjqb-dV0SFEt_qz" alt=""></p>
<p>Once downloaded and installed, set up Git LFS and its respective hooks by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git lfs install</span><br></pre></td></tr></table></figure></p>
<p><img src="https://drive.google.com/uc?id=1gTK8WwQi7i1Vfjq7_ysTU5H9jXN4w_Jo" alt=""></p>
<blockquote>
<p>Note: You’ll need to run this in your repository directory, once per repository.</p>
</blockquote>
<h3 id="Track-Large-File"><a href="#Track-Large-File" class="headerlink" title="Track Large File"></a>Track Large File</h3><p>Select the file types you’d like Git LFS to manage (or directly edit your <code>.gitattributes</code>). You can configure additional file extensions at anytime.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git lfs track <span class="string">"*.tar.gz"</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: run this track command at the top level of your repository, then you need to git add <code>.gitattributes</code> file</p>
</blockquote>
<h3 id="Manage-Large-File"><a href="#Manage-Large-File" class="headerlink" title="Manage Large File"></a>Manage Large File</h3><p>Then, just do normal <code>git add</code> and <code>git commit</code> to manage your large size file.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git add *.tar.gz</span><br><span class="line">git commit -m <span class="string">"add tar.gz file"</span></span><br><span class="line">git push origin &lt;your branch&gt;</span><br></pre></td></tr></table></figure></p>
<p><img src="https://drive.google.com/uc?id=1x9TX8NBIEZaaG51_dQxEKljdeL0ziKK8" alt=""></p>
<p>Actually, you can check the large files you managed by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git lfs ls-files</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git-lfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Create Working Branch</title>
    <url>/2019/09/12/git-create-working-branch/</url>
    <content><![CDATA[<p>Let me record the workflow about how to create your own working branch from master.</p>
<p>I <code>git clone</code> the original repo to local, then <code>git checkout -b</code> to a <code>develop</code> branch on top of <code>master</code> branch, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(<span class="built_in">cd</span> /GitRepos; git <span class="built_in">clone</span> git@github.xxx.com:xxx.git)</span><br></pre></td></tr></table></figure></p>
<p>Then go to local git repository<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git checkout -b develop</span><br></pre></td></tr></table></figure></p>
<p>After checkout to new branch, if you do nothing and get files changed, this is sometimes a format issue, go to edit <code>.gitattributes</code>, comment out the regex, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># * text=auto</span><br></pre></td></tr></table></figure></p>
<p>Save and run <code>git status</code>, you will see the change now is on <code>.gitattributes</code>, then undo the change and save.</p>
<p>Now you are in <code>develop</code> branch, let’s check the config information:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --list</span><br></pre></td></tr></table></figure></p>
<p>Focus on the <code>user.name</code> and <code>user.email</code>, if they are empty, set them by<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --global user.name xxx</span><br><span class="line">git config --global user.email xxx</span><br><span class="line">git commit --amend --reset-author</span><br></pre></td></tr></table></figure></p>
<p>Then working on <code>develop</code> branch, when you run <code>git push origin develop</code>, this will create a pull request (you can decide merge to which branch) and a remote <code>develop</code> branch, then you can review and merge to <code>master</code> branch on git web.</p>
<p>Because there is no git repos fork, so run <code>git pull origin master</code> in <code>develop</code> branch to get sync up with latest updates from <code>master</code> branch.</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Disable Pull Prompt</title>
    <url>/2019/06/27/git-mute-pull-prompt/</url>
    <content><![CDATA[<p>When run <code>git pull origin master</code> to make your local branch up-to-date, if there are files need to be merged, you will get prompt to confirm the merge and make commit. This is not good for automation, need to mute this prompt.</p>
<blockquote>
<p>Note this method fits this situation, but not sure if this is a general way to go, because <code>git pull</code> has different syntax format.</p>
</blockquote>
<p>Actually, <code>git pull</code> does a <code>git fetch</code> followed by <code>git merge</code>, so can sepetate it into two steps:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git pull origin master</span><br></pre></td></tr></table></figure></p>
<p>Changes to<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git fetch origin master</span><br><span class="line">git merge FETCH_HEAD --no-edit</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that The <code>--no-edit</code> option can be used to accept the auto-generated message (this is generally discouraged).</p>
</blockquote>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Issue Layout</title>
    <url>/2020/02/26/git-issue-layout/</url>
    <content><![CDATA[<p>What should be the layout for a good issue, can configure this as template:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!---</span><br><span class="line">Please read this!</span><br><span class="line"></span><br><span class="line">Before opening a new issue, make sure to search for keywords in the issues</span><br><span class="line">and verify the issue you&apos;re about to submit isn&apos;t a duplicate.</span><br><span class="line">---&gt;</span><br><span class="line"></span><br><span class="line">## Environment information</span><br><span class="line">(cluster info, system info)</span><br><span class="line"></span><br><span class="line">## Problem Description</span><br><span class="line">(Summarize the bug encountered concisely)</span><br><span class="line"></span><br><span class="line">## Steps to reproduce</span><br><span class="line">(How one can reproduce the issue - this is very important)</span><br><span class="line"></span><br><span class="line">## Expected behaviour</span><br><span class="line">(what you should see?)</span><br><span class="line"></span><br><span class="line">## Observed behaviour</span><br><span class="line">(what actually happens?))</span><br><span class="line"></span><br><span class="line">## Additional info or screenshots</span><br><span class="line">(Paste any relevant logs - please use code blocks (```) to format console output,</span><br><span class="line">logs, and code as it&apos;s very hard to read otherwise.)</span><br><span class="line"></span><br><span class="line">## Workaround available</span><br><span class="line">(If you can, link to the line of code that might be responsible for the problem)</span><br><span class="line"></span><br><span class="line">## Per Meeting Minutes</span><br><span class="line"></span><br><span class="line">## TO-DO&apos;s</span><br></pre></td></tr></table></figure></p>
<p>More:</p>
<ol>
<li>add right pipelines</li>
<li>add right labels</li>
<li>@people when reply</li>
</ol>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Merge and Rebase</title>
    <url>/2019/09/11/git-merge-rebase/</url>
    <content><![CDATA[<p>之前其实很少用到<code>git merge</code> and <code>git rebase</code>，一般都是通过Github UI Pull Request merges feature branch’s updates into master.</p>
<p>也可在CLI 中merge feature branch into master，但这样master中的git history不是线性的，并且会制造一个merge commit:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># merge feature to master, first go to master</span></span><br><span class="line">git checkout master</span><br><span class="line"><span class="comment"># squash will summary all commits in feature branch into merge commit</span></span><br><span class="line">git merge --squash feature</span><br><span class="line"><span class="comment"># or 不用fast-forward merge, 用普通的recursive merge</span></span><br><span class="line"><span class="comment"># by default is --ff (try fast-forward first, not create merge commit)</span></span><br><span class="line">git merge --no-ff feature</span><br><span class="line"></span><br><span class="line"><span class="comment"># need to commit this merge</span></span><br><span class="line">git commit -m <span class="string">"feature and master merged"</span></span><br><span class="line"><span class="comment"># then push to master</span></span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure></p>
<p>Highlight:</p>
<ul>
<li>fast-forward merge: less commits, no merge commit will be generated.</li>
<li>recusive merge: has merge commit, can do revert, clear what was done on a branch.</li>
</ul>
<p>关于rebase的使用，可以参考这篇文章，它构造了一个线性的git history，方便以后查看:<br><a href="https://www.jianshu.com/p/6960811ac89c" target="_blank" rel="noopener">https://www.jianshu.com/p/6960811ac89c</a><br>注意，这篇文章的例子是将dev branch 本地合并到master 再提交，并不是merge request的方式。</p>
<ol>
<li>先将本地master 更新, git pull origin master</li>
<li>进入需要rebase的分支, git checkout dev</li>
<li>执行rebase, git rebase master. 这样就把master的commits 线性的合并到dev 分支了</li>
<li>rebase可能遇到conflicts, 参考这里去修复<a href="https://docs.github.com/en/github/using-git/resolving-merge-conflicts-after-a-git-rebase" target="_blank" rel="noopener">Resolving merge conflicts after a Git rebase</a></li>
<li>dev 中rebase 完成后，切换到master执行merge, git checkout master, git merge dev (github/gitlab UI就是做了这一步)</li>
</ol>
<p>这样就把dev合并到master中了，实际上还是先rebase 再 merge.</p>
<p>这个文章讲了更多的rebase 特性:<br><a href="https://baijiahao.baidu.com/s?id=1633418495146592435" target="_blank" rel="noopener">https://baijiahao.baidu.com/s?id=1633418495146592435</a></p>
<ol>
<li>git pull –rebase (will not use merge)</li>
<li>修改commit 历史</li>
<li>合并commit</li>
<li>分解commit</li>
<li>重新排序commit</li>
</ol>
<p><a href="https://thoughtbot.com/blog/git-interactive-rebase-squash-amend-rewriting-history#squash-commits-together" target="_blank" rel="noopener">Git Interactive Rebase, Squash, Amend and Other Ways of Rewriting History</a><br>实际遇到一个要求，存在多次的commits在dev branch中，需要squash multiple commits into one, 解决办法:<br>在本地rebase 然后再提交, for example I use <code>dev</code> branch:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 如果dev branch不干净</span></span><br><span class="line"><span class="comment"># later can run `git stash pop`</span></span><br><span class="line">git stash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可以先在dev中squash一下多个commits</span></span><br><span class="line"><span class="comment"># HEAD~5: rebase HEAD 向下的5个commits</span></span><br><span class="line"><span class="comment"># HEAD 可以用git log看一下位置</span></span><br><span class="line">git checkout dev</span><br><span class="line">git rebase -i HEAD~5</span><br><span class="line"></span><br><span class="line"><span class="comment"># pull latest to master branch</span></span><br><span class="line"><span class="comment"># because it may be updated by others</span></span><br><span class="line">git checkout master</span><br><span class="line">git pull origin master</span><br><span class="line"></span><br><span class="line"><span class="comment"># current in dev branch, reword commits on top of master history</span></span><br><span class="line">git checkout dev</span><br><span class="line"><span class="comment"># rebase against master，这样之后create pull/merge request就不会产生冲突了</span></span><br><span class="line"><span class="comment"># -i: interactively</span></span><br><span class="line">git rebase -i master</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># may have conflicts, fix conflicts as prompted</span></span><br><span class="line">git add &lt;fixed files&gt;</span><br><span class="line">git rebase --<span class="built_in">continue</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># abort rebase</span></span><br><span class="line">git rebase --abort</span><br><span class="line"></span><br><span class="line"><span class="comment"># after rebase (squash), check commit log changes</span></span><br><span class="line">git <span class="built_in">log</span> -n 5</span><br><span class="line"></span><br><span class="line"><span class="comment"># update merge request on github</span></span><br><span class="line"><span class="comment"># 之前的merge request就会被重写</span></span><br><span class="line"><span class="comment"># -f: force override merge request on remote</span></span><br><span class="line">git push -f origin dev</span><br></pre></td></tr></table></figure></p>
<h2 id="Other-GitHub-tutorials"><a href="#Other-GitHub-tutorials" class="headerlink" title="Other GitHub tutorials:"></a>Other GitHub tutorials:</h2><p>GitHub.com Help Documentation:<br><a href="https://docs.github.com/en/github" target="_blank" rel="noopener">https://docs.github.com/en/github</a></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Origin Vs Upstream</title>
    <url>/2019/07/09/git-origin-upstream/</url>
    <content><![CDATA[<p>Using Git everyday and pull push everyday, let’s spend time to undestand the concept <code>origin</code> and <code>upstream</code> fully. </p>
<p>You can edit the upstream and origin in this file for your local repo only:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># see local config in your repo</span></span><br><span class="line">vim .git/config</span><br></pre></td></tr></table></figure></p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p><a href="https://stackoverflow.com/questions/9257533/what-is-the-difference-between-origin-and-upstream-on-github" target="_blank" rel="noopener">Difference Upstream and Origin</a></p>
<ul>
<li><code>upstream</code> generally refers to the original repo that you forked from</li>
<li><code>origin</code> is your fork: your own repo on GitHub, clone of the original repo of GitHub</li>
</ul>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Rename Limit</title>
    <url>/2019/10/22/git-rename-limit/</url>
    <content><![CDATA[<p>I encounter a git issue when I run these commands, they are used to sync up with origin/master:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">git_clean</span></span>() &#123;</span><br><span class="line">  git reset --hard HEAD</span><br><span class="line">  sed -i -e <span class="string">'s/^\(\*[ ][ ]*text.*\)/#\1/'</span> .gitattributes</span><br><span class="line">  git status</span><br><span class="line">  git clean -fdx</span><br><span class="line">  git checkout -- .</span><br><span class="line">  sed -i -e <span class="string">'s/^#\(\*[ ][ ]*text.*\)/\1/'</span> .gitattributes</span><br><span class="line">  git status</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>I get errors:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">warning: inexact rename detection was skipped due to too many files.</span><br><span class="line">warning: you may want to set your merge.renamelimit variable to at least 12454 and retry the command.</span><br><span class="line">Automatic merge failed; fix conflicts and then commit the result.</span><br></pre></td></tr></table></figure></p>
<p>Try to set <code>rename.limit</code> to larger value and run commands again but that does not help, <a href="https://stackoverflow.com/questions/4722423/how-to-merge-two-branches-with-different-directory-hierarchies-in-git" target="_blank" rel="noopener">https://stackoverflow.com/questions/4722423/how-to-merge-two-branches-with-different-directory-hierarchies-in-git</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config merge.renameLimit 999999</span><br><span class="line">git merge --abort</span><br><span class="line">git config --unset merge.renameLimit</span><br></pre></td></tr></table></figure></p>
<p>So far these commands help:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git reset --hard origin/master</span><br><span class="line">git fetch -p</span><br><span class="line">git pull origin master</span><br><span class="line"></span><br><span class="line"><span class="comment">## if failed again, run</span></span><br><span class="line">git merge --abort</span><br><span class="line">git reset --hard origin/master</span><br><span class="line">git pull origin master</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Pull Not Clean</title>
    <url>/2019/06/14/git-pull-not-clean/</url>
    <content><![CDATA[<p>Sometimes after I <code>git pull</code> from the master branch, if I run <code>git status</code>, there are some files (for me it’s mainly <code>xxx.dsx</code>) are modified that need to be added and committed, that’s strange.</p>
<p>It seems the format issue that can be solved by editting the top level <code>.gitattributes</code> in your local repository. Open <code>.gitattributes</code>, comment out the formulas, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#* text=auto</span><br></pre></td></tr></table></figure></p>
<p>Now if I run <code>git status</code> again, the clutters are gone and git outputs only show<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">modified:   .gitattributes</span><br></pre></td></tr></table></figure></p>
<p>Then revert back to origin in <code>.gitattributes</code> and run <code>git status</code> again, the branch will be clean.</p>
<p>Acutally there are some commands can exterminate editor operation:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -i -e &apos;s/^\(\*[ ][ ]*text.*\)/#\1/&apos; .gitattributes</span><br><span class="line">git status</span><br><span class="line">sed -i -e &apos;s/^#\(\*[ ][ ]*text.*\)/\1/&apos; .gitattributes</span><br><span class="line">git status</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>gitattributes</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Partial Merge</title>
    <url>/2019/07/10/git-partial-merge/</url>
    <content><![CDATA[<p>I was previously working on a separate branch <code>branch-tmp</code>, now I want to merge some files in that branch into my main personal branch <code>chengdol_master</code>, and finally create a pull request to merge int <code>master</code>.</p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p><a href="https://jasonrudolph.com/blog/2009/02/25/git-tip-how-to-merge-specific-files-from-another-branch/" target="_blank" rel="noopener">Git tip: How to “merge” specific files from another branch</a><br><a href="https://stackoverflow.com/questions/18115411/how-to-merge-specific-files-from-git-branches" target="_blank" rel="noopener">Interactive merge</a></p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><blockquote>
<p>Notice that in my case, the target files in <code>branch-tmp</code> are completely applicable for <code>chengdol_master</code>, so I just want to overwrite corresponding files in <code>chengdol_master</code>. If we need to pick some changes and leave others in the file, do an <code>interactive merge</code>, run this from <code>chengdol_master</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git checkout --patch brach-tmp &lt;relative path to target file&gt;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>First check if you have <code>origin/branch-tmp</code> locally<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git branch -r | grep branch-tmp</span><br></pre></td></tr></table></figure></p>
<p>If not, you need to fetch it alone or fetch all origin branches:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git fetch origin branch-tmp</span><br><span class="line">git fetch origin</span><br></pre></td></tr></table></figure></p>
<p>Then go to your target branch <code>chengdol_master</code>, use <code>git checkout</code> command to do the job:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git checkout origin/branch-tmp &lt;relative path to target file&gt;</span><br></pre></td></tr></table></figure></p>
<p>then the merged files from <code>branch-tmp</code> are in staging phase, you can directly commit or unstage them in the <code>chengdol_master</code> branch, then push and handle the pull request.</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Release Tag and Branch</title>
    <url>/2020/12/09/git-tag-branch/</url>
    <content><![CDATA[<h1 id="Release-Tag"><a href="#Release-Tag" class="headerlink" title="Release Tag"></a>Release Tag</h1><p>When to use tag: every time you push to production, tag the release.<br>Release tag points to a specific commit in history.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fetch all remote tags</span></span><br><span class="line">git fetch --tags</span><br><span class="line"><span class="comment"># list all tags</span></span><br><span class="line">git tag [--list]</span><br><span class="line"><span class="comment"># delete tag</span></span><br><span class="line">git tag -d &lt;tag name&gt;</span><br><span class="line"><span class="comment"># Delete a tag from the server with push tags</span></span><br><span class="line">git push --delete origin &lt;tag name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># in your current branch tag latest commit</span></span><br><span class="line"><span class="comment"># create annotated tag, add more info</span></span><br><span class="line"><span class="comment"># will open editor</span></span><br><span class="line">git tag -a 0.1.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># tag specific commit</span></span><br><span class="line">git tag -a 0.1.0 &lt;commit <span class="built_in">hash</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># push tag to remote</span></span><br><span class="line">git push origin &lt;branch&gt; --tags</span><br></pre></td></tr></table></figure>
<p>这个git command很有用<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## can see commit detail, tag annotation, and so on.</span></span><br><span class="line">git show [tag|or anything]</span><br></pre></td></tr></table></figure></p>
<p>References:<br><a href="https://stackoverflow.com/questions/35979642/what-is-git-tag-how-to-create-tags-how-to-checkout-git-remote-tags" target="_blank" rel="noopener">what is tag</a><br><a href="https://stackoverflow.com/questions/11514075/what-is-the-difference-between-an-annotated-and-unannotated-tag" target="_blank" rel="noopener">annotated and non-annotated tag</a><br><a href="https://stackoverflow.com/questions/8044583/how-can-i-move-a-tag-on-a-git-branch-to-a-different-commit" target="_blank" rel="noopener">move a tag on a branch to different commit</a></p>
<h1 id="Release-Branch"><a href="#Release-Branch" class="headerlink" title="Release Branch"></a>Release Branch</h1><p>Generally you only need tags for releases.<br>But when you need to make changes to production release without affecting master, you need release branch. For example, make hotfix. Release branch can be updated with new commits.</p>
<p>Use cases for release branches:</p>
<ul>
<li>Manual QA.</li>
<li>Long running releases.</li>
<li>On demand hot fixes.</li>
</ul>
<p>Workflow is like<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># we have some hot fixes on release branch, then create a release tag on it for production</span></span><br><span class="line"><span class="comment"># finally merge into master</span></span><br><span class="line">master ------ + ----- + -----+ --- + --------------- + ------&gt;</span><br><span class="line">               \                               /</span><br><span class="line">                \       hotfix   hotfix       /</span><br><span class="line">                 \-------- + ----- + --------/</span><br><span class="line">      release branch           (release tag)</span><br></pre></td></tr></table></figure></p>
<p>[x] This is why we have double-commit back to master branch. 我们把release tag放在master branch中了。</p>
<p>You can also create release branch on the fly from release tags, the workflow:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># on master branch</span></span><br><span class="line"><span class="comment"># checkout to a tag (detched HEAD)</span></span><br><span class="line">git checkout v1.1</span><br><span class="line"><span class="comment"># create release branch on release tag</span></span><br><span class="line">git checkout -b rb1.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># or in one command to checkout a tag to a new branch</span></span><br><span class="line">git checkout tags/v1.1 -b rb1.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># make fix</span></span><br><span class="line">&lt;hot fix&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># commit</span></span><br><span class="line">git commit -m <span class="string">"hotfix"</span></span><br><span class="line">git tag -a v1.1.1 -m <span class="string">"hotfix"</span></span><br><span class="line"><span class="comment"># merge</span></span><br><span class="line">git checkout master</span><br><span class="line"><span class="comment"># or rebase/squash or fast-forward</span></span><br><span class="line">git merge rb1.1 -m <span class="string">"merged hotfix"</span></span><br><span class="line"><span class="comment"># delete branch, the tag is still there, because you merged to master</span></span><br><span class="line">git branch -d rb1.1</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang OOP</title>
    <url>/2020/11/15/golang-OOP/</url>
    <content><![CDATA[<p>Go 用<code>struct</code> 实现OOP, 匿名字段可看作实现了继承关系，子类也可以重写父类的方法。<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Person 在Student中成为了匿名字段</span></span><br><span class="line"><span class="comment">// 直接被访问，也叫提升字段</span></span><br><span class="line"><span class="keyword">type</span> Person <span class="keyword">struct</span> &#123;</span><br><span class="line">    name <span class="keyword">string</span></span><br><span class="line">    age <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Student <span class="keyword">struct</span> &#123;</span><br><span class="line">    Person <span class="comment">// 匿名字段，模拟继承结构</span></span><br><span class="line">    school <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Student <span class="keyword">struct</span> &#123;</span><br><span class="line">    person Person <span class="comment">// 普通嵌套字段，必须逐层访问</span></span><br><span class="line">    school <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// method，会自动关联</span></span><br><span class="line"><span class="comment">// 也可以写成(p Persion) 不用指针类型</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Person)</span> <span class="title">getName</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="comment">// p 就是调用这个方法的对象</span></span><br><span class="line">    <span class="keyword">return</span> p.name</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Person)</span> <span class="title">getAge</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> p.age</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Student子类重写了 Person 父类的方法</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(s *Student)</span> <span class="title">getName</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">"studnet "</span> + s.name</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line"></span><br><span class="line">    s1 := Student&#123;Person: Person&#123;name: <span class="string">"xxx"</span>, age:<span class="number">12</span>&#125;, school: <span class="string">"yyy"</span>&#125;</span><br><span class="line">    <span class="comment">// 匿名字段 和 嵌套字段的访问</span></span><br><span class="line">    s1.name or s1.Person.name</span><br><span class="line">    s1.age  or s1.Person.age</span><br><span class="line">    s1.school</span><br><span class="line"></span><br><span class="line">    <span class="comment">// call method</span></span><br><span class="line">    <span class="comment">// 因为提升字段的原因，可以把Person省掉</span></span><br><span class="line">    s1.getName()</span><br><span class="line">    s1.getAge()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在Go中，<code>interface</code> 定义方法的声明，具体类型实现方法的定义.<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// interface define</span></span><br><span class="line"><span class="keyword">type</span> Usb <span class="keyword">interface</span> &#123;</span><br><span class="line">    <span class="comment">// normal function definition</span></span><br><span class="line">    start()</span><br><span class="line">    end()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Mouse <span class="keyword">struct</span> &#123;</span><br><span class="line">    name <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实现接口，会自动关联</span></span><br><span class="line"><span class="comment">// 相当于Java 中 class xxx implements xxx</span></span><br><span class="line"><span class="comment">// 不能写成(m *Mouse)</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m Mouse)</span> <span class="title">start</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"Mouse start"</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(m Mouse)</span> <span class="title">end</span><span class="params">()</span></span> &#123;</span><br><span class="line">    fmt.Println(<span class="string">"Mouse end"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 测试使用接口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">testUsb</span><span class="params">(usb Usb)</span></span> &#123;</span><br><span class="line">    <span class="comment">// usb 实际上就是实现了接口的Mouse</span></span><br><span class="line">    usb.start()</span><br><span class="line">    usb.end()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">m := Mouse &#123;name: <span class="string">"xxx"</span>&#125;</span><br><span class="line">testUsb(m)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 或者声明interface 变量</span></span><br><span class="line"><span class="keyword">var</span> u Usb</span><br><span class="line"><span class="comment">// u 不能访问 m 的字段</span></span><br><span class="line">u = m</span><br><span class="line">u.start()</span><br><span class="line">u.end()</span><br></pre></td></tr></table></figure></p>
<p>空接口，没有方法，所以可以认为所有类型都实现了它，可以用作函数的参数去接收任何数据类型。<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> A <span class="keyword">interface</span> &#123;&#125;</span><br><span class="line"><span class="comment">// 接收任意类型</span></span><br><span class="line"><span class="keyword">var</span> a1 A = <span class="string">"hello"</span></span><br><span class="line"><span class="keyword">var</span> a2 A = <span class="number">123</span></span><br><span class="line"><span class="keyword">var</span> a3 A = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// map value存储任意类型</span></span><br><span class="line"><span class="keyword">var</span> map1 = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">interface</span>&#123;&#125;)</span><br><span class="line"><span class="comment">// slice 存储任意类型</span></span><br><span class="line"><span class="keyword">var</span> slice1 = <span class="built_in">make</span>([]<span class="keyword">interface</span>&#123;&#125;)</span><br></pre></td></tr></table></figure></p>
<p>注意<code>fmt.Println()</code> 就是这么实现的，用的匿名的空接口。<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 可变参数 + 匿名空接口</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Println</span><span class="params">(a ...<span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> Fprintln(os.Stdout, a...)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如果判断空接口对应的具体类型呢，语法:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// instance: 解析后的实际类型</span></span><br><span class="line"><span class="comment">// ok: true or false</span></span><br><span class="line"><span class="comment">// 接口对象: 接口名</span></span><br><span class="line"><span class="comment">// 实际类型: 猜测的实际类型</span></span><br><span class="line">instance := 接口对象.(实际类型) <span class="comment">// panic may occur</span></span><br><span class="line">instance, ok := 接口对象.(实际类型) <span class="comment">// safe way</span></span><br><span class="line"></span><br><span class="line">swithc instance := 接口对象.(<span class="keyword">type</span>) &#123;</span><br><span class="line">    <span class="keyword">case</span> 实际类型<span class="number">1</span>:</span><br><span class="line">        ...</span><br><span class="line">    <span class="keyword">case</span> 实际类型<span class="number">2</span>:</span><br><span class="line">        ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>举例:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> A <span class="keyword">interface</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 实例的指针值也可以传进来</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getType</span><span class="params">(a A)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 判断a 具体是什么类型</span></span><br><span class="line">    <span class="keyword">if</span> ins, ok := a.(<span class="keyword">int</span>), ok &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 结构体类型</span></span><br><span class="line">    <span class="comment">// 如果传进来的是指针，则写成，a.(*Person)</span></span><br><span class="line">    <span class="keyword">if</span> ins, ok := a.(Person), ok &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 或者用switch</span></span><br><span class="line">    <span class="keyword">switch</span> ins := a.(<span class="keyword">type</span>) &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="keyword">int</span>:</span><br><span class="line">            <span class="comment">// pass</span></span><br><span class="line">        <span class="keyword">case</span> Person:</span><br><span class="line">            <span class="comment">// pass</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>接口还可以多继承, 实现<code>C</code>的类型必须要实现<code>C</code>中自身和继承的所有的方法:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> A <span class="keyword">interface</span> &#123;</span><br><span class="line">    testA()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> B <span class="keyword">interface</span> &#123;</span><br><span class="line">    testB()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> C <span class="keyword">interface</span> &#123;</span><br><span class="line">    A</span><br><span class="line">    B</span><br><span class="line">    testC()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Golang Quick Start</title>
    <url>/2020/08/22/golang-learn/</url>
    <content><![CDATA[<p>//TODO<br>[x] 千锋教育golang，<a href="https://www.youtube.com/playlist?list=PLwDQt7s1o9J4fQLO5J9caXmBZ8lAtDp9H" target="_blank" rel="noopener">基础</a><br>[x] <a href="https://blog.csdn.net/GUDUzhongliang" target="_blank" rel="noopener">千峰CSDN</a></p>
<p>[ ] pluralsight<br>[ ] Go web site doc<br>[ ] Go books</p>
<h1 id="Go-Related-Projects"><a href="#Go-Related-Projects" class="headerlink" title="Go Related Projects"></a>Go Related Projects</h1><p>beego:<br><a href="https://beego.me/" target="_blank" rel="noopener">https://beego.me/</a></p>
<p>Go terminal UI:<br><a href="https://github.com/gizak/termui" target="_blank" rel="noopener">https://github.com/gizak/termui</a></p>
<p>go micro:<br><a href="https://github.com/micro/go-micro" target="_blank" rel="noopener">https://github.com/micro/go-micro</a></p>
<p>nsq:<br><a href="https://github.com/nsqio/nsq" target="_blank" rel="noopener">https://github.com/nsqio/nsq</a></p>
<p>groupcahce:<br><a href="https://github.com/golang/groupcache" target="_blank" rel="noopener">https://github.com/golang/groupcache</a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Go features:</p>
<ul>
<li>modules self-contained</li>
<li>network aware and concurrency</li>
<li>cross-platform</li>
</ul>
<p>Go users: <a href="https://github.com/golang/go/wiki/GoUsers" target="_blank" rel="noopener">https://github.com/golang/go/wiki/GoUsers</a><br>web services, web server, devops: docker + k8s</p>
<p>Visual Studio Code go-plugin, vim go-plugin<br>go web framework collection:<br><a href="https://github.com/mingrammer/go-web-framework-stars" target="_blank" rel="noopener">https://github.com/mingrammer/go-web-framework-stars</a></p>
<p>Resources:</p>
<ul>
<li><a href="https://golang.org/doc/effective_go.html" target="_blank" rel="noopener">effective go</a> 这个更深入了，特别是用法方面</li>
<li><a href="https://blog.golang.org/index" target="_blank" rel="noopener">go blog</a></li>
<li><p><a href="https://www.amazon.com/s?k=effective+go&amp;ref=nb_sb_noss" target="_blank" rel="noopener">go packages</a></p>
</li>
<li><p><a href="https://gobyexample.com/" target="_blank" rel="noopener">Go by Example</a></p>
</li>
<li><a href="https://gobyexample-cn.github.io/" target="_blank" rel="noopener">Go by Example Chinese</a></li>
<li><a href="https://yourbasic.org/" target="_blank" rel="noopener">Other people web site</a></li>
<li><a href="https://studygolang.com/" target="_blank" rel="noopener">Go语言中文网</a></li>
</ul>
<p>Installation is simple, download from <a href="https://golang.org/dl/" target="_blank" rel="noopener">https://golang.org/dl/</a> to PATH:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## set go env vars</span></span><br><span class="line"><span class="built_in">export</span> GOROOT=/usr/<span class="built_in">local</span>/go</span><br><span class="line"><span class="built_in">export</span> GOBIN=<span class="variable">$GOROOT</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="comment">## go path is the project workspace</span></span><br><span class="line"><span class="comment">## it has src (user create), pkg and bin (auto create for you when build or install)</span></span><br><span class="line"><span class="built_in">export</span> GOPATH=<span class="variable">$HOME</span>/go</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$GOBIN</span></span><br><span class="line"><span class="comment">## check</span></span><br><span class="line">go env</span><br><span class="line">go version</span><br></pre></td></tr></table></figure></p>
<p>Example:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// main is entrypoint of Go</span></span><br><span class="line"><span class="comment">// one package can only have one main entry</span></span><br><span class="line"><span class="keyword">package</span> main</span><br><span class="line"><span class="comment">// comments</span></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">  . <span class="string">"fmt"</span> <span class="comment">// call fmt funcs directly withou fmt prefix</span></span><br><span class="line">  err <span class="string">"errors"</span> <span class="comment">// alias</span></span><br><span class="line">  <span class="string">"os"</span></span><br><span class="line">  <span class="string">"net/http"</span></span><br><span class="line">  <span class="string">"regexp"</span></span><br><span class="line">  <span class="string">"builtin"</span> <span class="comment">// no need to import</span></span><br><span class="line">  _ <span class="string">"github.com/ziutek/mysql"</span> <span class="comment">// call init in the package</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">// auto append ;, so let &#123; at the same line</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span></span> &#123;</span><br><span class="line">  fmt.Println(<span class="string">"Hello world"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>package</code> name in go file should be the same as folder name. </p>
<p>Understand <code>run</code>, <code>build</code>, <code>install</code>, <code>get</code> subcommands. pluralsight has <code>Go CLI playbook</code> course.<br>Compile or run go program:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -n: dry run</span></span><br><span class="line">go run -n main.go</span><br><span class="line"><span class="comment">## -work: print $WORK temp folder</span></span><br><span class="line"><span class="comment">## you will see the intermediary files created</span></span><br><span class="line">go run -work main.go</span><br><span class="line"><span class="comment">## run directly, only for main entry file</span></span><br><span class="line">go run main.go</span><br><span class="line"></span><br><span class="line"><span class="comment">## build and run executable</span></span><br><span class="line"><span class="comment">## go install will look at GOROOT and GOPATH</span></span><br><span class="line"><span class="comment">## `hello` is a folder (package) under src</span></span><br><span class="line"><span class="comment">## it will install the binary under $GOBIN</span></span><br><span class="line">go install hello</span><br><span class="line"></span><br><span class="line"><span class="comment">## only build(compile) not install</span></span><br><span class="line">go build hello</span><br><span class="line"></span><br><span class="line"><span class="comment">## it will create executable in bin folder</span></span><br><span class="line"><span class="built_in">cd</span> <span class="variable">$GOPATH</span>/bin</span><br><span class="line"><span class="comment">## executable name is the same as folder name</span></span><br><span class="line">./hello</span><br><span class="line"></span><br><span class="line"><span class="comment">## -x: verbose</span></span><br><span class="line">go get -x github.com/go-errors/errors</span><br><span class="line"><span class="comment">## simliar to python dir()/help()</span></span><br><span class="line">go doc net/http</span><br><span class="line">go doc fmt Println</span><br><span class="line"><span class="comment">## local golang web site, search API, etc</span></span><br><span class="line">godoc -http=:9876</span><br><span class="line"></span><br><span class="line"><span class="comment">## linter, but VSC will auto does that when save go files</span></span><br><span class="line">go fmt</span><br></pre></td></tr></table></figure></p>
<h1 id="Packages"><a href="#Packages" class="headerlink" title="Packages"></a>Packages</h1><p><a href="https://golang.org/pkg/" target="_blank" rel="noopener">https://golang.org/pkg/</a><br><code>fmt</code>:<br>Common use placeholder: %d, %c(one string), %T(type), %p(address).<br>Can print and scan.</p>
<p><code>bufio</code>:<br>Some help for textual I/O.</p>
<p><code>math/rand</code></p>
<h2 id="How-to-build-custom-package"><a href="#How-to-build-custom-package" class="headerlink" title="How to build custom package"></a>How to build custom package</h2><h1 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h1><p>和C语言比较相似, Please see <a href="https://drive.google.com/file/d/1DHLvvKsLwSZujckvExvnmiBcveQrZ6YB/view?usp=sharing" target="_blank" rel="noopener">千峰课件</a>:</p>
<h2 id="编码规范"><a href="#编码规范" class="headerlink" title="编码规范"></a>编码规范</h2><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>基本数据类型:<br>int32, float64, bool, string(没有char type)<br>复合数据类型:<br>array, slice, map, function, pointer, struct, interface</p>
<p>&amp;(取地址符，没有地址的算数运算), *t</p>
<h2 id="变量赋值方式"><a href="#变量赋值方式" class="headerlink" title="变量赋值方式"></a>变量赋值方式</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> xx = <span class="number">23</span></span><br><span class="line"><span class="keyword">var</span> xx <span class="keyword">int</span> = <span class="number">23</span> </span><br><span class="line"><span class="keyword">var</span> xx <span class="keyword">float32</span> = <span class="number">2.32</span></span><br><span class="line"><span class="comment">// 简短写法</span></span><br><span class="line">a := <span class="string">"hello"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// swap</span></span><br><span class="line">b := <span class="string">"world"</span></span><br><span class="line">a, b = b, a</span><br><span class="line"></span><br><span class="line"><span class="comment">// 全局变量不支持简短写法</span></span><br><span class="line"><span class="keyword">var</span> GLOBAL <span class="keyword">int</span> = <span class="number">100</span></span><br></pre></td></tr></table></figure>
<h2 id="常量使用"><a href="#常量使用" class="headerlink" title="常量使用"></a>常量使用</h2><p>Use all upper cases</p>
<h2 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">str1 := <span class="string">"abc"</span></span><br><span class="line">str2 := <span class="string">`abc`</span></span><br></pre></td></tr></table></figure>
<h2 id="强制类型转换"><a href="#强制类型转换" class="headerlink" title="强制类型转换"></a>强制类型转换</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>()</span><br></pre></td></tr></table></figure>
<h2 id="算数运算符"><a href="#算数运算符" class="headerlink" title="算数运算符"></a>算数运算符</h2><h2 id="关系运算符"><a href="#关系运算符" class="headerlink" title="关系运算符"></a>关系运算符</h2><p>&lt;, &gt;, &lt;=, &gt;=, ==, !=</p>
<p>##逻辑运算符<br>&amp;&amp;, ||, !</p>
<h2 id="位运算符"><a href="#位运算符" class="headerlink" title="位运算符"></a>位运算符</h2><p>&amp;, | , ^, &amp;^(位清空), &lt;&lt;, &gt;&gt;</p>
<h2 id="If-else"><a href="#If-else" class="headerlink" title="If-else"></a>If-else</h2><p>condition 没有括号, no ternary<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// if 还可以有初值，和for loop类似了</span></span><br><span class="line"><span class="comment">// 写到外面一样的</span></span><br><span class="line"><span class="keyword">if</span> err := file.Chmod(<span class="number">0664</span>); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Print(err)</span><br><span class="line">    <span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Switch"><a href="#Switch" class="headerlink" title="Switch"></a>Switch</h2><p>每个case 自带break。<br>关键字 <code>fallthrough</code> 只能放case最后一行, 连接执行2个case且一定执行。<br>case 后的数据类型必须和switch一致, case 可无序，多个condition可用逗号分开。<br>switch 省略条件相当于<code>switch true</code>, 也可省略后，把condition 写在case 后面，就像if-else if了<br>也可以有初值<code>switch t = 100 {..}</code>, <code>t</code> only use in switch block</p>
<h2 id="For-loop"><a href="#For-loop" class="headerlink" title="For loop"></a>For loop</h2><p>no while loop<br>语法和C一样: <code>for init; conditionl; post {}</code><br>condition no bracket<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> ;; &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> key, value := <span class="keyword">range</span> <span class="keyword">map</span> &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> index, value := <span class="keyword">range</span> [slice, array, <span class="keyword">string</span>] &#123;&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Goto"><a href="#Goto" class="headerlink" title="Goto"></a>Goto</h2><p>前后跳都可以</p>
<h2 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h2><p>没赋值的默认值和C语言一样:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> a [<span class="number">10</span>]<span class="keyword">int</span> <span class="comment">// element default is 0</span></span><br><span class="line"><span class="keyword">var</span> a = [<span class="number">10</span>]<span class="keyword">int</span>&#123;&#125;</span><br><span class="line"><span class="keyword">var</span> a = [<span class="number">3</span>]<span class="keyword">float64</span> &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">a := [<span class="number">3</span>]<span class="keyword">float64</span> &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line"><span class="comment">// 可以设置index对应的值</span></span><br><span class="line">a := [<span class="number">3</span>]<span class="keyword">float64</span> &#123;<span class="number">0</span>:<span class="number">32</span>, <span class="number">2</span>:<span class="number">99</span>&#125;</span><br><span class="line">a := [...]<span class="keyword">float64</span> &#123;<span class="number">0</span>:<span class="number">32</span>, <span class="number">2</span>:<span class="number">99</span>&#125;</span><br><span class="line"><span class="built_in">len</span>(a)</span><br><span class="line"><span class="built_in">cap</span>(a)</span><br><span class="line"><span class="comment">// ascending sort </span></span><br><span class="line">sort.Ints(a)</span><br></pre></td></tr></table></figure></p>
<p>对于数组 len(a) 长度= cap(a) 容量</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// same address usage as C language</span></span><br><span class="line"><span class="keyword">var</span> arr = [<span class="number">3</span>]<span class="keyword">int32</span>&#123;<span class="number">99</span>, <span class="number">100</span>, <span class="number">101</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 数组是值传递，改变arr2中的值不会改变arr,函数中注意，除非传递的是地址</span></span><br><span class="line"><span class="comment">// 可直接复制</span></span><br><span class="line">arr2 := arr</span><br><span class="line"><span class="comment">// true</span></span><br><span class="line">fmt.Println(arr2 == arr)</span><br><span class="line"><span class="comment">// type [3]int</span></span><br><span class="line">fmt.Printf(<span class="string">"%T\n"</span>, arr2)</span><br><span class="line"><span class="comment">// 注意在go中数组名不是地址了，要专门用取地址符号</span></span><br><span class="line"><span class="comment">// 这2个值一样的</span></span><br><span class="line">fmt.Printf(<span class="string">"%p\n"</span>, &amp;arr)</span><br><span class="line">fmt.Printf(<span class="string">"%p\n"</span>, &amp;arr[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">// t1 其实是指针类型 *[3]int32</span></span><br><span class="line">t1 := &amp;arr</span><br><span class="line">fmt.Printf(<span class="string">"%d\n"</span>, (*t1)[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>二维数组<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> arr := [<span class="number">3</span>][<span class="number">3</span>]<span class="keyword">int</span>&#123;&#123;&#125;,&#123;&#125;,&#123;&#125;&#125;</span><br><span class="line"><span class="built_in">len</span>(arr)</span><br><span class="line"><span class="built_in">len</span>(arr[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></p>
<h2 id="Slice"><a href="#Slice" class="headerlink" title="Slice"></a>Slice</h2><p>动态数组，大小可变，背后有一个底层数组.<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 不写长度, slice = nil 但是由于有底层数组，所以可以直接使用</span></span><br><span class="line"><span class="keyword">var</span> slice1 []<span class="keyword">int</span></span><br><span class="line"><span class="keyword">var</span> slice1 = []<span class="keyword">float64</span> &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line"><span class="comment">// or</span></span><br><span class="line"><span class="comment">// make(type, len, capacity) len 必须小于或等于 cap</span></span><br><span class="line"><span class="comment">// make function is in builtin package</span></span><br><span class="line"><span class="comment">// used to create object</span></span><br><span class="line">slice1 := <span class="built_in">make</span>([]<span class="keyword">int</span>, <span class="number">0</span>, <span class="number">2</span>)</span><br><span class="line"><span class="comment">// slice1中存的就是切片的地址，不需要取地址符了</span></span><br><span class="line"><span class="comment">// 而数组的地址则是&amp;arr</span></span><br><span class="line">fmt.Printf(<span class="string">"%p\n"</span>, slice1)</span><br><span class="line"></span><br><span class="line">slice1 = <span class="built_in">append</span>(slice1, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>)</span><br><span class="line">slice2 := []<span class="keyword">int</span>&#123;<span class="number">10</span>, <span class="number">11</span>&#125;</span><br><span class="line"><span class="comment">// 注意这里用...，类似于python的分解操作，如果查看append的定义，其实它的末尾参数是个可变参数...type</span></span><br><span class="line"><span class="comment">// 当append超过容量后，生成新的切片的，地址就变了</span></span><br><span class="line"><span class="comment">// 自动扩容是之前的2倍</span></span><br><span class="line">slice1 = <span class="built_in">append</span>(slice1, slice2...)</span><br><span class="line"></span><br><span class="line"><span class="comment">// map, slice 是地址传递</span></span><br><span class="line"><span class="comment">// 指向同一个地址</span></span><br><span class="line">slice3 := slice1</span><br><span class="line"></span><br><span class="line"><span class="comment">// create slice from array</span></span><br><span class="line"><span class="comment">// slice1和arr1指向同一个地址，共享数据，除非slice1扩容则会新生成一个内存地址</span></span><br><span class="line">arr1 := [<span class="number">10</span>]<span class="keyword">int</span></span><br><span class="line"><span class="comment">// [start, end)</span></span><br><span class="line">slice1 := arr1[:]</span><br><span class="line">slice1 := arr1[<span class="number">0</span>:<span class="number">10</span>]</span><br><span class="line">slice1 := arr1[<span class="number">2</span>:<span class="number">4</span>]</span><br><span class="line"><span class="comment">// 这时候slice1地址和arr1不一样了</span></span><br><span class="line">slice1 = <span class="built_in">append</span>(slice1, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// deep copy, for []type</span></span><br><span class="line"><span class="built_in">copy</span>(dst, src)</span><br><span class="line"><span class="built_in">copy</span>(slice2[<span class="number">2</span>:], slice[<span class="number">1</span>:])</span><br></pre></td></tr></table></figure></p>
<h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// nil map, 不能直接用，</span></span><br><span class="line"><span class="keyword">var</span> map1 <span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">float64</span></span><br><span class="line">fmt.Println(map1 == <span class="literal">nil</span>)</span><br><span class="line"></span><br><span class="line">map1 := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">int</span>]<span class="keyword">string</span>)</span><br><span class="line">map1 := <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>&#123;&#125;</span><br><span class="line">map1 := <span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">int</span>&#123;<span class="string">"hello"</span>: <span class="number">100</span>, <span class="string">"Java"</span>: <span class="number">99</span>&#125;</span><br><span class="line"></span><br><span class="line">map1[<span class="string">"see"</span>] = <span class="number">-34</span></span><br><span class="line">val1 := map1[<span class="string">"hello"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果map没有key，取出来的是value类型的"0"值</span></span><br><span class="line"><span class="comment">// 怎么判断呢? ok is bool, if true, then exist</span></span><br><span class="line">val, ok := <span class="keyword">map</span>[<span class="string">"key"</span>]</span><br><span class="line"></span><br><span class="line"><span class="built_in">delete</span>(map1[<span class="string">"see"</span>])</span><br><span class="line"><span class="built_in">len</span>(map1)</span><br></pre></td></tr></table></figure>
<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// UTF-8 coding</span></span><br><span class="line">str := <span class="string">"hello"</span></span><br><span class="line">str := <span class="string">`hello`</span></span><br><span class="line"><span class="comment">// string is acutally byte sequence</span></span><br><span class="line">slice := []<span class="keyword">byte</span>&#123;<span class="number">65</span>, <span class="number">66</span>, <span class="number">67</span>, <span class="number">68</span>&#125;</span><br><span class="line">str := <span class="keyword">string</span>(slice1)</span><br><span class="line">slice := []<span class="keyword">byte</span>(str1)</span><br><span class="line"></span><br><span class="line">substr := str[<span class="number">1</span>:<span class="number">3</span>]</span><br><span class="line"><span class="comment">// strings package 主要是字符串 操作函数</span></span><br><span class="line"><span class="comment">// strconv package 主要是字符串 和 基本数据类型之间相互转换</span></span><br><span class="line"><span class="comment">// go '+' operands must have same type</span></span><br><span class="line"><span class="string">"123"</span> + strconv.Itoa(<span class="number">100</span>)</span><br><span class="line">b1, err := strconv.ParseBool(<span class="string">"true"</span>)</span><br><span class="line">str1 := strconv.FormatBool(b1)</span><br></pre></td></tr></table></figure>
<h2 id="defer"><a href="#defer" class="headerlink" title="defer"></a>defer</h2><p>用于延迟函数或方法的执行, 用<code>defer</code> 控制的调用会等到它的containing function执行完了之后再执行，并且当所有延迟的部分执行结束之后，containing function才执行return 语句。</p>
<p>如果有多个<code>defer</code>,则按照后进先出的顺序。<br>用法：</p>
<ul>
<li>关闭连接，文件，比如defer close() 在函数的开头.</li>
<li>panic, recover，defer函数执行完毕后，异常才会被抛出到上一层.</li>
</ul>
<p>注意，延迟函数的参数的值，在<code>defer</code>的时候就固定了，值也可能是地址，则复合对象的内部值可能被改变了。<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">deferTest</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">defer</span> fmt.Println(<span class="string">"1"</span>)</span><br><span class="line">  <span class="keyword">defer</span> fmt.Println(<span class="string">"2"</span>)</span><br><span class="line">  fmt.Println(<span class="string">"3"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h1><p>函数也是一种复合数据类型，可以用<code>%T</code> 查看。<br>注意函数的参数类型和参数名是反过来写的，且返回值类型列表也写在最后。<br>函数名如果大写开头 表示公共函数，可被其他package调用，比如fmt.Println()，否则只能package内部访问。<br>参数传递没有python这么多形式。</p>
<p>参数传递也有值传递和引用(地址)传递.<br>值传递: int, float, string, bool, array, struct<br>引用传递: slice, map, chan<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// (int, int) 对应了 return val1, val2的类型</span></span><br><span class="line"><span class="comment">// 注意这里p2是slice, p3是array</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">funcName</span><span class="params">(p1 <span class="keyword">int</span>, p2 []float, p3 [10]<span class="keyword">int</span>, p4 <span class="keyword">map</span>)</span> <span class="params">(<span class="keyword">int</span>, <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">  <span class="comment">// logic</span></span><br><span class="line">  <span class="keyword">return</span> val1, val2</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 或者只写return，返回列表里已经有了返回值名字了</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">funcName</span><span class="params">(p1 <span class="keyword">int</span>, p2 []float, p3 [10]<span class="keyword">int</span>, p4 <span class="keyword">map</span>)</span> <span class="params">(val1 <span class="keyword">int</span>, val2 <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">  <span class="comment">// logic</span></span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 或者return 单纯用来结束函数</span></span><br><span class="line"><span class="comment">// 注意这里没有定义返回值列表</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">funcName</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 如果只有一个返回值，可以不写括号</span></span><br><span class="line"><span class="comment">// 多个参数类型一致，可以把类型写在后边一起</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">funcName</span><span class="params">(p1, p2 <span class="keyword">int</span>, p3 <span class="keyword">string</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> val1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>可变参数<code>...</code>，只能放到参数列表的最后，且只能有一个可变参数:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ...type，0个到多个参数都可以，比如Println()就是</span></span><br><span class="line"><span class="comment">// nums 是个slice类型</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">funcName</span><span class="params">(p1 <span class="keyword">int</span>, nums ...<span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">  <span class="comment">// pass</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 调用的时候注意，如果是复合类型数据需要分解</span></span><br><span class="line">funcName(<span class="number">100</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>)</span><br><span class="line">funcName(<span class="number">100</span>, []<span class="keyword">int</span> &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;...)</span><br></pre></td></tr></table></figure></p>
<p>可以定义函数变量，然后赋值，其实赋值的是函数的地址:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> c <span class="function"><span class="keyword">func</span><span class="params">(a ...<span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span></span><br><span class="line"><span class="function"><span class="title">c</span> = <span class="title">fmt</span>.<span class="title">Println</span></span></span><br></pre></td></tr></table></figure></p>
<p>匿名函数，没有函数名，可以赋值给变量 或 直接调用. 所以说Go是支持函数式编程的，匿名函数可以作为其他函数的参数(这个作为参数的函数就叫回调函数)，注意不是函数执行的返回值作为参数，是函数本身! 匿名函数也可以作为返回值(闭包)<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// no function name and call</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">()</span></span> &#123;</span><br><span class="line">  fmt.Println()</span><br><span class="line">&#125;()</span><br><span class="line"><span class="comment">// or</span></span><br><span class="line">fun3 := <span class="function"><span class="keyword">func</span> <span class="params">()</span></span> &#123;</span><br><span class="line">  fmt.Println()</span><br><span class="line">&#125;</span><br><span class="line">fun3()</span><br></pre></td></tr></table></figure></p>
<p>回调函数:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// callback function</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">add</span><span class="params">(a, b <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> a + b</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// calling function</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">operate</span><span class="params">(a, b <span class="keyword">int</span>, fun <span class="keyword">func</span>(<span class="keyword">int</span>, <span class="keyword">int</span>)</span><span class="title">int</span>) <span class="title">int</span></span> &#123;</span><br><span class="line">  <span class="keyword">return</span> fun(a, b)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// call</span></span><br><span class="line">operate(<span class="number">1</span>, <span class="number">3</span>, add)</span><br></pre></td></tr></table></figure></p>
<p>闭包closure, 这里外部函数返回后，匿名函数把外部函数内部的资源<code>i</code>保留了下来。Python中local function一样的道理。<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">increment</span><span class="params">()</span> <span class="title">func</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">  <span class="comment">// stay alive in closure function</span></span><br><span class="line">  i := <span class="number">0</span></span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">func</span> <span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    i++</span><br><span class="line">    <span class="keyword">return</span> i</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">res := increment()</span><br><span class="line"><span class="comment">// 1</span></span><br><span class="line">fmt.Println(res())</span><br><span class="line"><span class="comment">// 2</span></span><br><span class="line">fmt.Println(res())</span><br><span class="line"><span class="comment">// 3</span></span><br><span class="line">fmt.Println(res())</span><br></pre></td></tr></table></figure></p>
<h1 id="Pointer"><a href="#Pointer" class="headerlink" title="Pointer"></a>Pointer</h1><p>指针类型符号<code>*</code>, 和C语言一样.<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// nil is pointer's default vaule</span></span><br><span class="line"><span class="keyword">var</span> p1 *<span class="keyword">int</span></span><br><span class="line">a := <span class="number">10</span></span><br><span class="line">p1 = &amp;a</span><br><span class="line"><span class="comment">// print pointer value</span></span><br><span class="line">fmt.Println(p1)</span><br><span class="line">fmt.Printf(<span class="string">"%p\n"</span>, p1)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 指针的指针</span></span><br><span class="line"><span class="keyword">var</span> pp1 **<span class="keyword">int</span></span><br><span class="line">pp1 = &amp;p1</span><br></pre></td></tr></table></figure></p>
<p>数组指针，指向数组的指针<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">arr := [<span class="number">3</span>]<span class="keyword">int</span> &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line"><span class="keyword">var</span> pa *[<span class="number">3</span>]<span class="keyword">int</span></span><br><span class="line">pa = &amp;arr</span><br><span class="line"><span class="comment">// 这个输出注意，并不是输出的地址数值，而是一种形式</span></span><br><span class="line"><span class="comment">// 如果要输出地址数值，用%p</span></span><br><span class="line">fmt.Println(pa) <span class="comment">// &amp;[1 2 3]</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// the address of arr</span></span><br><span class="line">fmt.Printf(<span class="string">"%p\n"</span>, pa)</span><br><span class="line">fmt.Printf(<span class="string">"%p\n"</span>, &amp;arr)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 相同的表达</span></span><br><span class="line">(*pa)[<span class="number">0</span>]</span><br><span class="line">pa[<span class="number">0</span>] <span class="comment">// (*pa)[0] 的简化写法</span></span><br><span class="line">arr[<span class="number">0</span>]</span><br></pre></td></tr></table></figure></p>
<p>指针数组，元素是指针的数组<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">a := <span class="number">1</span></span><br><span class="line">b := <span class="number">2</span></span><br><span class="line">c := <span class="number">3</span></span><br><span class="line">arr := [<span class="number">3</span>]*<span class="keyword">int</span> &#123;&amp;a, &amp;b, &amp;c&#125;</span><br><span class="line">fmt.Println(arr)</span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 指向 指针数组的指针</span></span><br><span class="line">*[<span class="number">3</span>]*<span class="keyword">int</span></span><br><span class="line"><span class="comment">// 指向 数组指针的指针</span></span><br><span class="line">**[<span class="number">5</span>]<span class="keyword">string</span></span><br><span class="line"><span class="comment">// 指向 指针数组指针的指针</span></span><br><span class="line">**[<span class="number">3</span>]*<span class="keyword">string</span></span><br></pre></td></tr></table></figure></p>
<p>函数指针，指向函数的指针, Go中函数名就是函数的地址，如同slice, map一样:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> c <span class="function"><span class="keyword">func</span><span class="params">(a ...<span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span></span><br><span class="line"><span class="function"><span class="title">c</span> = <span class="title">fmt</span>.<span class="title">Println</span></span></span><br></pre></td></tr></table></figure></p>
<p>指针函数，返回指针值的函数:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 2个地址输出是一样的</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">getArr</span><span class="params">()</span> *<span class="title">int</span>[4]</span> &#123;</span><br><span class="line">  arr := [<span class="number">3</span>]<span class="keyword">int</span> &#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;</span><br><span class="line">  fmt.Printf(<span class="string">"%p\n"</span>, &amp;arr)</span><br><span class="line">  <span class="keyword">return</span> &amp;arr</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">arr := getArr()</span><br><span class="line">fmt.Printf(<span class="string">"%p\n"</span>, &amp;arr)</span><br><span class="line"><span class="string">``</span><span class="string">` </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># Struct</span></span><br><span class="line"><span class="string">`</span><span class="string">``</span><span class="keyword">go</span></span><br><span class="line"><span class="keyword">type</span> Person <span class="keyword">struct</span> &#123;</span><br><span class="line">  name <span class="keyword">string</span></span><br><span class="line">  age <span class="keyword">int</span></span><br><span class="line">  sex <span class="keyword">string</span></span><br><span class="line">  address <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 几种创建方式</span></span><br><span class="line"><span class="comment">// p1 is an empty struct object with default values</span></span><br><span class="line"><span class="keyword">var</span> p1 Person</span><br><span class="line"><span class="comment">// same as p1</span></span><br><span class="line"><span class="comment">// 可以拿到外面赋值， 比如p2.age = 34</span></span><br><span class="line">p2 := Person&#123;&#125;</span><br><span class="line"></span><br><span class="line">p3 := Person (name: <span class="string">"XXX"</span>, age: <span class="number">23</span>, sex: <span class="string">"female"</span>, address: <span class="string">"YYY"</span>)</span><br><span class="line">p4 := Person &#123;</span><br><span class="line">  name: <span class="string">"XXX"</span>, </span><br><span class="line">  age: <span class="number">23</span>, </span><br><span class="line">  sex: <span class="string">"female"</span>, </span><br><span class="line">  address: <span class="string">"YYY"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// order matters</span></span><br><span class="line">p3 := Person (<span class="string">"XXX"</span>, <span class="number">23</span>, <span class="string">"female"</span>, <span class="string">"YYY"</span>)</span><br></pre></td></tr></table></figure></p>
<p>结构体是值类型的，和array一样，结构体名不是它的地址。<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这是内容复制</span></span><br><span class="line">p4 := p1</span><br><span class="line"></span><br><span class="line"><span class="comment">// 这是地址赋值</span></span><br><span class="line"><span class="keyword">var</span> pp1 *Person</span><br><span class="line">pp1 = &amp;p1</span><br><span class="line"><span class="comment">// 访问字段，以下都可以</span></span><br><span class="line">pp1.name</span><br><span class="line">(*pp1).name</span><br></pre></td></tr></table></figure></p>
<p><code>make</code>只能创建map, slice, chan等<br><code>make</code> vs <code>new</code>: <a href="https://www.godesignpatterns.com/2014/04/new-vs-make.html" target="_blank" rel="noopener">https://www.godesignpatterns.com/2014/04/new-vs-make.html</a><br><code>new</code> returns pointer:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// they are the same</span></span><br><span class="line"><span class="keyword">var</span> p1 Person</span><br><span class="line">pp1 := &amp;p1</span><br><span class="line"></span><br><span class="line">pp1 := &amp;Persion&#123;&#125;</span><br><span class="line">pp1 := <span class="built_in">new</span>(Persion)</span><br></pre></td></tr></table></figure></p>
<p><code>new</code>可以创建任意类型空间 和 返回任意类型的指针:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line">pint := <span class="built_in">new</span>(<span class="keyword">int</span>)</span><br></pre></td></tr></table></figure></p>
<p>匿名结构体，和匿名函数类似的定义用法<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这里定义了一个匿名结构体 同时进行赋值</span></span><br><span class="line">s2 := <span class="keyword">struct</span> &#123;</span><br><span class="line">  name <span class="keyword">string</span></span><br><span class="line">  age <span class="keyword">int</span></span><br><span class="line">&#125;&#123;</span><br><span class="line">  name: <span class="string">"xxx"</span>,</span><br><span class="line">  age: <span class="number">18</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>匿名字段，字段没有名字，且字段类型不能重复:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> Worker <span class="keyword">struct</span> &#123;</span><br><span class="line">  <span class="comment">// 只能有一个string</span></span><br><span class="line">  <span class="keyword">string</span></span><br><span class="line">  <span class="comment">// 只能有一个int</span></span><br><span class="line">  <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">w1 := Worker &#123;<span class="string">"xxx"</span>, <span class="number">11</span>&#125;</span><br><span class="line"><span class="comment">// 默认使用数据类型作为访问的名字</span></span><br><span class="line">fmt.Println(w1.<span class="keyword">string</span>)</span><br><span class="line">fmt.Println(w1.<span class="keyword">int</span>)</span><br></pre></td></tr></table></figure></p>
<p>结构体嵌套:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> A <span class="keyword">struct</span> &#123;</span><br><span class="line">  a <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> B <span class="keyword">struct</span> &#123;</span><br><span class="line">  b <span class="keyword">string</span></span><br><span class="line">  c A</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">s := B &#123;b: <span class="string">"from B"</span>, c: A &#123;a: <span class="string">"from A"</span>&#125;&#125;</span><br><span class="line"><span class="comment">// access field</span></span><br><span class="line">s.b</span><br><span class="line">s.c.a</span><br></pre></td></tr></table></figure></p>
<p>如果对嵌套结构体使用了匿名字段，则相当于融合到了当前结构体，访问的时候不用中间层了。这在OOP 中使用到了:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> A <span class="keyword">struct</span> &#123;</span><br><span class="line">  a <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> B <span class="keyword">struct</span> &#123;</span><br><span class="line">  b <span class="keyword">string</span></span><br><span class="line">  A</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注意这里匿名字段初始化A: A&#123;a: "from A"&#125;</span></span><br><span class="line">s := B&#123;b: <span class="string">"from B"</span>, A: A&#123;a: <span class="string">"from A"</span>&#125;&#125;</span><br><span class="line"><span class="comment">// access field</span></span><br><span class="line">s.b</span><br><span class="line"><span class="comment">// 中间层被省略了</span></span><br><span class="line">s.a</span><br></pre></td></tr></table></figure></p>
<h1 id="Type"><a href="#Type" class="headerlink" title="Type"></a>Type</h1><p><code>type</code> 除了定义结构体，接口，还可以定义全新的类型 或者 别名:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// myint, mystr 就是全新的类型了 </span></span><br><span class="line"><span class="keyword">type</span> myint <span class="keyword">int</span></span><br><span class="line"><span class="keyword">type</span> mystr <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 不能和原类型相互赋值！</span></span><br><span class="line"><span class="keyword">var</span> myint = <span class="number">23</span></span><br><span class="line"><span class="keyword">var</span> mystr = <span class="string">"hello"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// myint, mystr 只是一个别名，注意和上面的区别</span></span><br><span class="line"><span class="keyword">type</span> myint = <span class="keyword">int</span></span><br><span class="line"><span class="keyword">type</span> mystr = <span class="keyword">string</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 可以和原类型相互赋值！</span></span><br><span class="line"><span class="keyword">var</span> a <span class="keyword">int</span> = <span class="number">10</span></span><br><span class="line"><span class="keyword">var</span> b myint = a</span><br></pre></td></tr></table></figure></p>
<p>Go语言实现函数式编程的时候，如果函数复杂，可以用<code>type</code> 简化，这里的例子是作为返回值，也可以作为参数:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 把func(string, string) string 整体别名叫做myfun</span></span><br><span class="line"><span class="keyword">type</span> myfun <span class="function"><span class="keyword">func</span><span class="params">(<span class="keyword">string</span>, <span class="keyword">string</span>)</span> <span class="title">string</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">// <span class="title">myfun</span> 作为<span class="title">fun1</span> 的返回值类型，就不用写一大堆了</span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="title">fun1</span><span class="params">()</span> <span class="title">myfun</span></span> &#123;</span><br><span class="line">  <span class="comment">// 返回一个函数</span></span><br><span class="line">  <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">(a, b <span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> a + b</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用, res得到一个函数定义</span></span><br><span class="line">res := fun1()</span><br><span class="line"><span class="comment">// "100100"</span></span><br><span class="line">fmt.Println(res(<span class="string">"100"</span>, <span class="string">"100"</span>))</span><br></pre></td></tr></table></figure></p>
<p>还需要注意的是，一个package中定义的别名，不能在其他包中为它添加method.</p>
<h1 id="Error"><a href="#Error" class="headerlink" title="Error"></a>Error</h1><p>Go中不要把错误 和 异常弄混了，这个还要单独看其他文章区分一下使用环境。</p>
<p>Go中错误也是一种数据类型<code>error</code>, 惯例是<code>error</code> 在函数中返回值的最后一个位置, error其实是一个接口:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> error <span class="keyword">interface</span> &#123;</span><br><span class="line">    Error() <span class="keyword">string</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>使用:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123;</span><br><span class="line">  <span class="string">"os"</span></span><br><span class="line">  <span class="string">"log"</span></span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="comment">// 很多包中的函数都会有错误信息返回，特别是文件，网络操作</span></span><br><span class="line">  f, err := os.Open(<span class="string">"./test.txt"</span>)</span><br><span class="line">  <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Fatal(err)</span><br><span class="line">    <span class="comment">// 得到具体的错误类型，输出其他字段</span></span><br><span class="line">    <span class="comment">// *os.PathError 是这个函数返回的错误类型</span></span><br><span class="line">    <span class="keyword">if</span> ins, ok := err.(*os.PathError); ok &#123;</span><br><span class="line">      <span class="comment">// 错误中的字段</span></span><br><span class="line">      fmt.Println(ins.Op)</span><br><span class="line">      fmt.Println(ins.Path)</span><br><span class="line">      fmt.Println(ins.Err)</span><br><span class="line">      <span class="comment">// 如果错误实现了自己的方法，调用方法也行</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// pass</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>自己如何创建错误呢, 通过<code>errors.New</code>这个package提供的函数 或者<code>fmt.Errorf</code>:<br><figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> &#123;</span><br><span class="line">  <span class="string">"errors"</span></span><br><span class="line">  <span class="string">"fmt"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  err1 := errors.New(<span class="string">"my error"</span>)</span><br><span class="line">  fmt.Println(err1)</span><br><span class="line">  <span class="comment">// 是 *errors.errorString 类型</span></span><br><span class="line">  fmt.Printf(<span class="string">"%T\n"</span>, err1)</span><br><span class="line"></span><br><span class="line">  err2 := fmt.Errorf(<span class="string">"my error is %d"</span>, <span class="number">100</span>)</span><br><span class="line">  fmt.Println(err2)</span><br><span class="line">  <span class="comment">// 是 *errors.errorString 类型</span></span><br><span class="line">  fmt.Printf(<span class="string">"%T\n"</span>, err2)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>以上只是简单的例子，复杂的error 是通过结构体实现的，里面包含了错误的具体信息，然后实现了<code>error</code> 这个接口.</p>
<h1 id="Panic-and-Recover"><a href="#Panic-and-Recover" class="headerlink" title="Panic and Recover"></a>Panic and Recover</h1><p>和<code>defer</code> 一起使用较多，遇到<code>panic</code>，函数后续会停止执行，然后逆序执行所有已经遇到的当前层的<code>defer</code>函数，没遇到的不会执行，因为中断了，最后往上层抛出异常，<br><code>defer</code> 函数中可能包含<code>recover</code> 来恢复<code>panic</code>。</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">A</span><span class="params">()</span></span> &#123;</span><br><span class="line">  fmt.Println(<span class="string">"from A"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">B</span><span class="params">()</span></span> &#123;</span><br><span class="line">  fmt.Println(<span class="string">"from B"</span>)</span><br><span class="line">  <span class="keyword">defer</span> fmt.Println(<span class="string">"from B defer 1"</span>)</span><br><span class="line">  <span class="keyword">for</span> i := <span class="number">0</span>; i &lt;= <span class="number">10</span>; i++ &#123;</span><br><span class="line">    fmt.Println(<span class="string">"i = "</span>, i)</span><br><span class="line">    <span class="keyword">if</span> i == <span class="number">5</span> &#123;</span><br><span class="line">      <span class="comment">// panic throw</span></span><br><span class="line">      <span class="built_in">panic</span>(<span class="string">"panic happened"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// will not execute this defer</span></span><br><span class="line">  <span class="keyword">defer</span> fmt.Println(<span class="string">"from B defer 2"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">  <span class="comment">// 捕捉恢复了panic</span></span><br><span class="line">  <span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> msg := <span class="built_in">recover</span>(); msg != <span class="literal">nil</span> &#123;</span><br><span class="line">      fmt.Println(<span class="string">"from recover"</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  A()</span><br><span class="line">  <span class="keyword">defer</span> fmt.Println(<span class="string">"from main defer 1"</span>)</span><br><span class="line">  B()</span><br><span class="line">  <span class="comment">// 这后面不会被执行了</span></span><br><span class="line">  <span class="keyword">defer</span> fmt.Println(<span class="string">"from main defer 2"</span>)</span><br><span class="line">  fmt.Println(<span class="string">"from main end"</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>哪些场景适合使用panic呢?</p>
<ul>
<li>空指针</li>
<li>下标越界</li>
<li>除数为0</li>
<li>分支没有出现</li>
<li>错误输入</li>
</ul>
]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title>Gitlab CI</title>
    <url>/2020/12/05/gitlab-ci/</url>
    <content><![CDATA[<p>目前使用的source code management tool 是gitlab, 除了行使git 的功能外，对每次 merge request 都做了额外的CI/CD操作，这里记录一下相关语法和总结 from course <a href="https://www.linkedin.com/learning/continuous-delivery-with-gitlab/use-gitlab-for-code-management?u=56685617" target="_blank" rel="noopener">Continuous Delivery with GitLab</a></p>
<p><code>CI</code>: code and feature integraion, combining updates into existing code base, testing with automation. </p>
<p><code>CD</code>: delivery can mean deployment, the process of building and deploying the app, for example, upload the object to somewhere that customer can download.</p>
<p>Gitlab uses pipelines to do both <code>CI/CD</code>, defined in <code>.gitlab-ci.yml</code> file at your branch.</p>
<h1 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h1><p>[x] To navigate the source code in gitlab repo, try launch the <code>Web IDE</code>, will show you a structure tree on left side of the files.<br>[x] Use snippet to share code or file block for issue solving, the same as gPaste.<br>[x] To-do list is someone mentions you in some events.<br>[x] Milestone is a goal that needs to track.<br>[x] Merge request (pull request in github) after merged can auto close the issue, deponds on setting.</p>
<h1 id="Setup-self-managed-Gitlab"><a href="#Setup-self-managed-Gitlab" class="headerlink" title="Setup self-managed Gitlab"></a>Setup self-managed Gitlab</h1><p>You can experiment with gitlab community edition locally by bringing up a gitlab server through Vagrant.<br>For example, Vagrantfile, there are 2 VMs, one VM for configuring docker gitlab runner:<br><figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- mode: ruby -*-</span></span><br><span class="line"><span class="comment"># vi: set ft=ruby :</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># server static ip</span></span><br><span class="line">GITLAB_IP = <span class="string">"192.168.50.10"</span></span><br><span class="line"><span class="comment"># worker static ip</span></span><br><span class="line">GITLAB_RUNNER_IP = <span class="string">"192.168.50.11"</span></span><br><span class="line"></span><br><span class="line">Vagrant.configure(<span class="string">"2"</span>) <span class="keyword">do</span> <span class="params">|config|</span></span><br><span class="line">  <span class="comment"># gitlab server VM</span></span><br><span class="line">  config.vm.define <span class="string">"server"</span>, <span class="symbol">primary:</span> <span class="literal">true</span> <span class="keyword">do</span> <span class="params">| server|</span></span><br><span class="line">    server.vm.hostname = <span class="string">"gitlab"</span></span><br><span class="line">    server.vm.box = <span class="string">"bento/ubuntu-16.04"</span></span><br><span class="line">    <span class="comment">## private network</span></span><br><span class="line">    server.vm.network <span class="string">"private_network"</span>, <span class="symbol">ip:</span> GITLAB_IP</span><br><span class="line"></span><br><span class="line">    server.vm.provider <span class="string">"virtualbox"</span> <span class="keyword">do</span> <span class="params">|v|</span></span><br><span class="line">      v.memory = <span class="number">2048</span></span><br><span class="line">      v.cpus = <span class="number">2</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># gitlab runner VM with docker installed</span></span><br><span class="line">  config.vm.define <span class="string">"runner"</span>, <span class="symbol">primary:</span> <span class="literal">true</span> <span class="keyword">do</span> <span class="params">| runner|</span></span><br><span class="line">    runner.vm.hostname = <span class="string">"runner"</span></span><br><span class="line">    runner.vm.box = <span class="string">"bento/ubuntu-16.04"</span></span><br><span class="line">    <span class="comment">## private network</span></span><br><span class="line">    runner.vm.network <span class="string">"private_network"</span>, <span class="symbol">ip:</span> GITLAB_RUNNER_IP</span><br><span class="line"></span><br><span class="line">    runner.vm.provider <span class="string">"virtualbox"</span> <span class="keyword">do</span> <span class="params">|v|</span></span><br><span class="line">      v.memory = <span class="number">1024</span></span><br><span class="line">      v.cpus = <span class="number">2</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<p>Vagrant quick commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vagrant up</span><br><span class="line"><span class="comment"># ssh to server</span></span><br><span class="line">vagrant ssh [gitlab]</span><br><span class="line"><span class="comment"># ssh to worker</span></span><br><span class="line">vagrant ssh runner</span><br><span class="line"><span class="comment"># destroy uses</span></span><br><span class="line">vagrant destroy -f</span><br></pre></td></tr></table></figure></p>
<p>Install the packages references from <a href="https://about.gitlab.com/install/#ubuntu" target="_blank" rel="noopener">there</a>, but it uses enterprise edition, we use community edition.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Update package manager and install prerequisites</span></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y curl openssh-server ca-certificates</span><br><span class="line"><span class="comment"># we don't need email in this case, so skip it</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up gitlab apt repository</span></span><br><span class="line">curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install gitlab</span></span><br><span class="line"><span class="comment"># this is the IP address in vagrant file</span></span><br><span class="line"><span class="comment"># gitlab-ce is community edition</span></span><br><span class="line">sudo EXTERNAL_URL=<span class="string">"http://192.168.50.10"</span> apt-get install gitlab-ce</span><br></pre></td></tr></table></figure></p>
<p>After install, go to browser and hit <code>http://192.168.50.10</code>, reset root password and login as <code>root</code> with the reseted password.</p>
<h1 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h1><p>[1] Create a new project <code>hello world</code> (You can also create it by setting jenkins pipeline)<br>Use root user to create a private project, check RAEDME added option.</p>
<p>[2] Create a admin user, so don’t need to use <code>root</code> user anymore.<br>Grant the new user as <code>admin</code>, edit the password that will be used as temporary password next time you login.<br>sign out and sign in again with new admin user.</p>
<p>[3] Setup SSH for your user<br>The same process as setup SSH on github, go to setting -&gt; SSH keys.</p>
<p>[4] Create new project under admin user, set as priviate scope.</p>
<p>[4] Create anthos vagrant VM as gitlab client<br>To avoid messing up system git global configuration, then vagrant ssh and git clone the project.</p>
<p>Go to project dashboard, in the left menu:<br>The <code>CI/CD</code> tab is what we will focus on<br>The <code>Operations</code> tab is where gitlab integrate other systems in your stack, for example kubernetes.<br>The <code>Settings -&gt; CI/CD</code> is about configuration.</p>
<h1 id="CI-CD"><a href="#CI-CD" class="headerlink" title="CI/CD"></a>CI/CD</h1><p>[x] SonarQube, code quality testing tool.</p>
<p><code>.gitlab-ci.yml</code> 通过设计stage 搭配完成了both CI/CD 的操作。可以通过不同的条件判断，对特定的branch 进行不同的CI/CD. 每次MR 之前和之后都各有一个 pipeline，针对的是MR前后的branch. 设置了jenkins pipeline double-commit 到master branch, 因为如果需要修改<code>gitlab-ci.yml</code> 只会checked in 到 master中， 所以变化要在master中得到体现。</p>
<p><code>CI</code> test levels, each of them is a stage in pipeline, should fail early and fail often.</p>
<ul>
<li>syntax and linting</li>
<li>unit and integration</li>
<li>acceptance</li>
</ul>
<p>Gitlab runner is similar to jenkins, support run on VM, bare metal system or docker container or kubernetes.<br>Here we use docker, so install docker first, can reference <a href="https://docs.docker.com/engine/install/ubuntu/" target="_blank" rel="noopener">here</a></p>
<p>Here we install docker on gitlab server VM.<br>[x] You can spin up another VM with 2GB, install docker and run gitlab runner container there. But make sure the VM can ping each other, just like what I did in Vagrantfile.</p>
<p>This docker install is on <code>Ubuntu</code>, <code>Centos</code> or other linux distro please see different way to install docker:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line"></span><br><span class="line">sudo apt-get install -y \</span><br><span class="line">    apt-transport-https \</span><br><span class="line">    ca-certificates \</span><br><span class="line">    curl \</span><br><span class="line">    gnupg-agent \</span><br><span class="line">    software-properties-common</span><br><span class="line"></span><br><span class="line"><span class="comment"># add docker's official GPG key</span></span><br><span class="line">curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -</span><br><span class="line"></span><br><span class="line"><span class="comment"># add stable repository</span></span><br><span class="line">sudo add-apt-repository \</span><br><span class="line">   <span class="string">"deb [arch=amd64] https://download.docker.com/linux/ubuntu \</span></span><br><span class="line"><span class="string">   <span class="variable">$(lsb_release -cs)</span> \</span></span><br><span class="line"><span class="string">   stable"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># install docker</span></span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y docker-ce docker-ce-cli containerd.io</span><br><span class="line"></span><br><span class="line"><span class="comment"># verify install good</span></span><br><span class="line">sudo docker run hello-world</span><br></pre></td></tr></table></figure></p>
<p>Install docker gitlab runner, reference is <a href="https://docs.gitlab.com/runner/install/docker.html" target="_blank" rel="noopener">here</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># name is gitlab-runner</span></span><br><span class="line"><span class="comment"># -v: will create folder automatically</span></span><br><span class="line">sudo docker run -d --name gitlab-runner --restart always \</span><br><span class="line">    -v /srv/gitlab-runner/config:/etc/gitlab-runner \</span><br><span class="line">    -v /var/run/docker.sock:/var/run/docker.sock \</span><br><span class="line">    gitlab/gitlab-runner:latest</span><br></pre></td></tr></table></figure></p>
<p>Then register the runner to your gitlab project, go to gitlab project Settings -&gt; CI/CD -&gt; Runners expand to see the registeration token.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># later gitlab-runner is command</span></span><br><span class="line"><span class="comment"># register is argument</span></span><br><span class="line">sudo docker <span class="built_in">exec</span> -it gitlab-runner gitlab-runner register</span><br><span class="line"></span><br><span class="line"><span class="comment"># command prompt:</span></span><br><span class="line">Enter the GitLab instance URL (<span class="keyword">for</span> example, https://gitlab.com/):</span><br><span class="line"><span class="comment"># from runner expand</span></span><br><span class="line">http://192.168.50.10/</span><br><span class="line">Enter the registration token:</span><br><span class="line"><span class="comment"># from runner expand</span></span><br><span class="line">K5G9S5e5wmcdoANUGLF4</span><br><span class="line">Enter a description <span class="keyword">for</span> the runner:</span><br><span class="line">[5922b65a9261]: docker</span><br><span class="line">Enter tags <span class="keyword">for</span> the runner (comma-separated):</span><br><span class="line"><span class="comment"># gitlab-ci will refer this tag</span></span><br><span class="line">docker-tag</span><br><span class="line">Registering runner... succeeded                     runner=K5G9S5e5</span><br><span class="line">Enter an executor: docker, docker-ssh, virtualbox, docker+machine, docker-ssh+machine, custom, parallels, shell, ssh, kubernetes:</span><br><span class="line">docker</span><br><span class="line">Enter the default Docker image (<span class="keyword">for</span> example, ruby:2.6):</span><br><span class="line"><span class="comment"># this can be overrided later</span></span><br><span class="line">alpine:latest</span><br></pre></td></tr></table></figure></p>
<p>Then reload the gitlab runner page, you will see the registered runner is there, click runner name to see specific. This runner is locked to this project, but you can alter it (the edit icon right near runner).</p>
<p>Create <code>.gitlab-ci.yml</code> in your repo to specify the pipeline, if you create it on web IDE, you can choose a template for it, for example the bash template, more advanced syntax please see gitlab-ci doc:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># will override the image alpine:latest above</span></span><br><span class="line"><span class="attr">image:</span> <span class="attr">busybox:latest</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># global variable, used by $&#123;CHART_NAME&#125;</span></span><br><span class="line"><span class="attr">variables:</span></span><br><span class="line"><span class="attr">  CHART_NAME:</span> <span class="string">xxxx</span></span><br><span class="line"><span class="attr">  VERSION_NUM:</span> <span class="string">xxxx</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># specify order or skip some stages</span></span><br><span class="line"><span class="attr">stages:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">test</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">build</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">deploy</span></span><br><span class="line"></span><br><span class="line"><span class="attr">before_script:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">echo</span> <span class="string">"Before script section"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">echo</span> <span class="string">"For example you might run an update here or install a build dependency"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">echo</span> <span class="string">"Or perhaps you might print out some debugging details"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">after_script:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">echo</span> <span class="string">"After script section"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">echo</span> <span class="string">"For example you might do some cleanup here"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># execute in order if no stages list</span></span><br><span class="line"><span class="attr">build1:</span></span><br><span class="line">  <span class="comment"># tags means run on the docker runner I installed above that taged as `docker-tag`</span></span><br><span class="line"><span class="attr">  tags:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">docker-tag</span></span><br><span class="line"><span class="attr">  stage:</span> <span class="string">build</span></span><br><span class="line"><span class="attr">  script:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">echo</span> <span class="string">"Do your build here"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">test1:</span></span><br><span class="line"><span class="attr">  tags:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">docker-tag</span></span><br><span class="line"><span class="attr">  stage:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">  script:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">echo</span> <span class="string">"Do a test here"</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">echo</span> <span class="string">"For example run a test suite"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">test2:</span></span><br><span class="line"><span class="attr">  tags:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">docker-tag</span></span><br><span class="line"><span class="attr">  stage:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">  script:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">echo</span> <span class="string">"Do another parallel test here"</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">echo</span> <span class="string">"For example run a lint test"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">deploy1:</span></span><br><span class="line"><span class="attr">  tags:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">docker-tag</span></span><br><span class="line"><span class="attr">  stage:</span> <span class="string">deploy</span></span><br><span class="line"><span class="attr">  script:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">echo</span> <span class="string">"Do your deploy here"</span></span><br></pre></td></tr></table></figure></p>
<p>In the Pipeline page, <code>CI Lint</code> is the tool can edit and validate the <code>.gitlab-ci</code> yaml file syntax.<br>You can also use Settings -&gt; CI/CD -&gt; Environment variables expand to set the env variables.</p>
<p>[x] where is the run-dev-check.sh script hosted? it is git cloned from another repo.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">script:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">git</span> <span class="string">clone</span> <span class="bullet">-v</span> <span class="string">$CLOUDSIMPLE_CI_REPO_URL</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">ci-cd/common-jobs/run-dev-check.sh</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Gitlab</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo Quick Start</title>
    <url>/2019/01/27/hexo-setup/</url>
    <content><![CDATA[<p>[x] 另一个静态文件转换工具<a href="https://jekyllrb.com/" target="_blank" rel="noopener">jekyll</a>, you can use AWS s3 to host statuc website or use git page as well.</p>
<p>Several weeks ago I decided to summarize and post what I have learned to online Blog platform, I struggled several days to choose which platform is better. Finally I think create my own blog and host it somewhere is a good way to go.</p>
<h1 id="Hexo-and-GitHub-Pages"><a href="#Hexo-and-GitHub-Pages" class="headerlink" title="Hexo and GitHub Pages"></a>Hexo and GitHub Pages</h1><p>First understand what is <strong>GitHub Pages</strong> and <strong>Hexo</strong>.</p>
<p><strong><a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a></strong>  is a website for you and your project that hosted directly from your GitHub repository. There is no Database to setup and no server to configure, you even don’t need to know HTML, CSS and other web development toolkits. You just follow the basic git add, commit and push operations and it will automatically build and deploy your blog site for you.</p>
<p> <strong><a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a></strong> is a open source blog framework that transfers plain text files into static website with beautiful theme. You associate it with your GitHub Pages repository, then use <a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet" target="_blank" rel="noopener">Markdown</a> write posts and deploy. Hexo provides basic features for manage the blog site, such as <em>categories</em>, <em>tag</em>, <em>profile</em>, etc. There are a lot of extensions and customizations for Hexo, more details please refer it’s website.</p>
<p>There is a Chinese version explanation, refer this <a href="https://www.yuque.com/skyrin/coding/tm8yf5" target="_blank" rel="noopener">link</a></p>
<h1 id="Set-up-GitHub-Pages"><a href="#Set-up-GitHub-Pages" class="headerlink" title="Set up GitHub Pages"></a>Set up GitHub Pages</h1><p>Head over to <a href="https://github.com/" target="_blank" rel="noopener">GitHub</a> and <a href="https://github.com/new" target="_blank" rel="noopener">create a new repository</a> named <em>username</em>.github.io, where <em>username</em> is your username (or organization name) on GitHub.</p>
<p>If the first part of the repository doesn’t exactly match your username, it won’t work, so make sure to get it right.<br><img src="https://drive.google.com/uc?id=18TZ7ee5zWHLS_aaP-pLC6BrevrAaRpA8" alt=""></p>
<h1 id="Set-up-Hexo"><a href="#Set-up-Hexo" class="headerlink" title="Set up Hexo"></a>Set up Hexo</h1><p>You need first install <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git" target="_blank" rel="noopener">Git</a> and <a href="https://nodejs.org/en/" target="_blank" rel="noopener">Node.js</a>, at the time build this blog I use Node version <code>10.15.2</code>, download and install it:<br><img src="https://drive.google.com/uc?id=1IWR24a6-IJirz1o_f9r7LmceSFUdSoS3" alt=""></p>
<blockquote>
<p>Note: for Mac users, you may encounter some other problems, please refer this <a href="https://hexo.io/docs/index.html" target="_blank" rel="noopener">link</a>. </p>
</blockquote>
<p>Once all requirements are set, install Hexo by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo npm install -g hexo-cli</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: for Mac users, you need to <a href="https://support.apple.com/en-us/HT204012" target="_blank" rel="noopener">enable root user privilege</a> first.</p>
</blockquote>
<p>The installation process may generate some warnings even errors, do a sanity check to see if it is good:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo -v</span><br><span class="line"></span><br><span class="line">hexo-cli: 1.1.0</span><br><span class="line">os: Darwin 18.2.0 darwin x64</span><br><span class="line">http_parser: 2.8.0</span><br><span class="line">node: 10.15.0</span><br><span class="line">v8: 6.8.275.32-node.45</span><br><span class="line">uv: 1.23.2</span><br><span class="line">zlib: 1.2.11</span><br><span class="line">ares: 1.15.0</span><br><span class="line">modules: 64</span><br><span class="line">nghttp2: 1.34.0</span><br><span class="line">napi: 3</span><br><span class="line">openssl: 1.1.0j</span><br><span class="line">icu: 62.1</span><br><span class="line">unicode: 11.0</span><br><span class="line">cldr: 33.1</span><br><span class="line">tz: 2018e</span><br></pre></td></tr></table></figure></p>
<h1 id="Initialize-blog"><a href="#Initialize-blog" class="headerlink" title="Initialize blog"></a>Initialize blog</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/Desktop/</span><br><span class="line"><span class="comment">## create a directory called `chengdol.blog`</span></span><br><span class="line">hexo init chengdol.blog</span><br></pre></td></tr></table></figure>
<p>Go to <code>chengdol.blog</code> and <code>hexo server</code> and open the URL<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server</span><br><span class="line"></span><br><span class="line">INFO  Start processing</span><br><span class="line">INFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure></p>
<p>If you see this webpage, congratulations! you now have a workable blog with default setting:<br><img src="https://drive.google.com/uc?id=15FS4S4Lfi33giFDmf7NzeWMTq4N8p65M" alt=""></p>
<h1 id="Customize-blog"><a href="#Customize-blog" class="headerlink" title="Customize blog"></a>Customize blog</h1><p>Let’s open the <code>chengdol.blog</code> directory<br><img src="https://drive.google.com/uc?id=1UkhbU2jxwuw6Kd14YDPcBCc80kSXL5Jr" alt=""></p>
<p>The Hexo offical <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> contains lots of configuration setting you can follow, Here I just go through what I have applied.</p>
<p>由于写的Blog越来越多了，查找的需求就来了，刚好Hexo有search plugin, 就用上了。</p>
<h2 id="Word-count"><a href="#Word-count" class="headerlink" title="Word count"></a>Word count</h2><p>The is the word count and read time plug:<br><a href="https://github.com/theme-next/hexo-symbols-count-time" target="_blank" rel="noopener">https://github.com/theme-next/hexo-symbols-count-time</a></p>
<p>这个插件好像有点问题，阅读时间总是显示InfinityNA。</p>
<h2 id="Search"><a href="#Search" class="headerlink" title="Search"></a>Search</h2><p>This will generate local search DB and create a new search UI in webpage<br><a href="https://github.com/theme-next/hexo-generator-searchdb" target="_blank" rel="noopener">https://github.com/theme-next/hexo-generator-searchdb</a></p>
<p>不需要对Next的_config.yml进行改动，初次安装后需要run <code>hexo g</code>去生成数据库。部署的操作不变。</p>
<h1 id="Backup"><a href="#Backup" class="headerlink" title="Backup"></a>Backup</h1><p>有时候需要在不同的电脑上写作，这样同步和备份就不太方便。<br>可以仅仅将最重要的文章部分备份下来，也就是<code>source</code>文件夹下的内容，创建一个private git repo即可。<br>在top-level的gitignore中选择忽略:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.source/.git</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>gitpage</tag>
      </tags>
  </entry>
  <entry>
    <title>HTTP Quick Start</title>
    <url>/2020/08/27/http-learn/</url>
    <content><![CDATA[<p>最近在做migrating Squid to Envoy的工作，其中涉及到了很多HTTP的内容。趁着这次机会深入学习一下，还有就是一些proxy的内容，已经单独拿出来总结了。</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>非常不错的Tutorial, 把各部分都讲得很详细:<br><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP" target="_blank" rel="noopener">MDN web docs: HTTP</a></p>
<p>很快速的把基础部分过了一下:<br><a href="https://www.youtube.com/watch?v=iYM2zFP3Zn0" target="_blank" rel="noopener">HTTP Crash Course &amp; Exploration</a><br>The typical HTTP format:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">METHOD PATH PROTOCOL</span><br><span class="line">HEADERS</span><br><span class="line"></span><br><span class="line">BODY</span><br></pre></td></tr></table></figure></p>
<p>HTTP status code:</p>
<ul>
<li>1xx, informational</li>
<li>2xx, success</li>
<li>3xx, redirect</li>
<li>4xx, client error</li>
<li>5xx, server error</li>
</ul>
<p>HTTP/2, faster and more efficient &amp; secure, request and response multiplexing.</p>
<h2 id="Other-Tools"><a href="#Other-Tools" class="headerlink" title="Other Tools"></a>Other Tools</h2><ol>
<li><a href="https://github.com/postmanlabs/httpbin" target="_blank" rel="noopener">httpbin</a>: A simple HTTP/HTTPS Request &amp; Response Service.</li>
<li><a href="http://ip4.me/" target="_blank" rel="noopener">ip4.me</a>: check your public IPv4 address.</li>
<li><a href="https://www.noip.com/" target="_blank" rel="noopener">noip.com</a>, free hostame + domain <-> public IP mapping. 如果要配置这个hostname对应到router的public IP, 需要设置router把这个流量转移到自己的笔记本某个端口上。</-></li>
</ol>
<h1 id="CONNECT-Method"><a href="#CONNECT-Method" class="headerlink" title="CONNECT Method"></a>CONNECT Method</h1><p>Connect主要是用在建立Tunnel. Tunneling can allow communication using a protocol that normally wouldn’t be supported on the restricted network. Tunnel 只是一个通道，里面可以支持一些传输协议, 并不是说tunnel 必须是ssl/tls. 举个例子，你通过一个forward proxy 访问一个服务器，使用HTTPS协议，假设Proxy是一个善良的中间人，它并不知道加密后的流量内容是什么，就不可能像HTTP一样去窥探，拆解packet，于是client会发送一个CONNECT HTTP请求，设立一个Tunnel经过proxy和server进行通信。</p>
<p>–&gt;&gt; <a href="https://stackoverflow.com/questions/11697943/when-should-one-use-connect-and-get-http-methods-at-http-proxy-server" target="_blank" rel="noopener">When should one use CONNECT</a><br>With SSL(HTTPS), only the two remote end-points understand the requests, and the proxy cannot decipher them. Hence, all it does is open that tunnel using CONNECT, and lets the two end-points (webserver and client) talk to each other directly.</p>
<p>–&gt;&gt; <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/CONNECT" target="_blank" rel="noopener">MDN web docs: CONNECT</a><br>Some proxy servers might need authority to create a tunnel. See also the <code>Proxy-Authorization</code> header.</p>
<p>For example, the CONNECT method can be used to access websites that use SSL (HTTPS). The client asks an HTTP Proxy server to <code>tunnel</code> the TCP connection to the desired destination. The server then proceeds to make the connection on behalf of the client. Once the connection has been established by the server, the Proxy server continues to proxy the TCP stream to and from the client.</p>
<p>这篇文章很不错:<br>–&gt;&gt; <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Proxy_servers_and_tunneling" target="_blank" rel="noopener">MDN web docs: proxy servers and tunneling</a><br>There are two types of proxies: forward proxies (or tunnel, or gateway) and reverse proxies (used to control and protect access to a server for load-balancing, authentication, decryption or caching).</p>
<p>Forward proxies can hide the identities of clients whereas reverse proxies can hide the identities of servers.</p>
<p>The HTTP protocol specifies a request method called CONNECT. It starts two-way communications with the requested resource and can be used to open a <code>tunnel</code>. This is how a client behind an HTTP proxy can access websites using SSL (i.e. HTTPS, port 443). Note, however, that not all proxy servers support the CONNECT method or limit it to port 443 only.</p>
<h1 id="Basic-Authorization"><a href="#Basic-Authorization" class="headerlink" title="Basic Authorization"></a>Basic Authorization</h1><p>这里提一下<code>authz</code> and <code>authn</code>的区别:</p>
<ul>
<li><code>authz</code>: authorization，授权, what are allowed to do.</li>
<li><code>authn</code>: authentication, 鉴权, who you are.</li>
</ul>
<p>这里是讲了HTTP 基本的<code>authz</code>操作.<br><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Authentication" target="_blank" rel="noopener">https://developer.mozilla.org/en-US/docs/Web/HTTP/Authentication</a><br>HTTP provides a general framework for access control and authentication. This page is an introduction to the HTTP framework for authentication, and shows how to restrict access to your server using the HTTP “Basic” schema.</p>
<p>The Basic authz is not secure, send in plain text, although base64. can be decode for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> &lt;base64 string&gt; | base64 --decode</span><br></pre></td></tr></table></figure></p>
<p>But if over https, the traffic is encrypted. You can demonstrate it in wireshark locally.<br><a href="https://security.stackexchange.com/questions/988/is-basic-auth-secure-if-done-over-https" target="_blank" rel="noopener">Is BASIC-Auth secure if done over HTTPS?</a></p>
]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title>Packer Quick Start</title>
    <url>/2020/07/07/infra-packer/</url>
    <content><![CDATA[<p>[x] template <a href="https://www.packer.io/docs/templates/user-variables.html" target="_blank" rel="noopener">user variable</a><br>[x] builder <a href="https://www.packer.io/docs/builders/googlecompute" target="_blank" rel="noopener">google cloud</a>, authentication, etc.<br>[x] provisioner <a href="https://www.packer.io/docs/provisioners/ansible" target="_blank" rel="noopener">ansible</a></p>
<p>Build Images for cloud and on-premise, Packer template is <code>JSON</code> format (easily source control).</p>
<ul>
<li>variables</li>
<li>builders: can have multiple builders run parallelly.</li>
<li>provisioners: run in order, need <code>only</code> to specify where to run.</li>
<li>post-processors: auto post-build tasks, eg: compression.</li>
</ul>
<p>A machine image is a single static unit that contains a pre-configured operating system and installed software which is used to quickly create new running machines. Machine image formats change for each platform. Some examples include AMIs for EC2, VMDK/VMX files for VMware, OVF exports for VirtualBox, etc.</p>
<p><code>-debug</code> flag in build can help run steps one by one, parallel build in debug mode is running sequentially.</p>
<p>To build Ubuntu VirtualBox image VOF, ISO is download from Ubuntu web site then Packer will launch it to run provisioner. Then use post-processor to compress VOF to tar.gz, or convert to Vagrant box.</p>
<p>What are the differences between Packer and Docker?</p>
<ul>
<li><a href="https://stackoverflow.com/questions/47169353/how-are-docker-and-packer-different-and-which-one-should-i-prefer-when-provisio" target="_blank" rel="noopener">How docker and packer are different</a></li>
</ul>
<p>Transition from Packer to Docker is easy, but the docker builder may not efficient as the docker native tool.</p>
<p>Example of packer json file, use ansibe as provisioner on google cloud:<br><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"variables"</span>: &#123;</span><br><span class="line">    <span class="attr">"project_id"</span>: <span class="string">"xxxxxx"</span>,</span><br><span class="line">    <span class="attr">"source_image"</span>: <span class="string">"xxxxxx"</span>,</span><br><span class="line">    <span class="attr">"subnetwork"</span>: <span class="string">"xxxxxx"</span>,</span><br><span class="line">    <span class="attr">"zone"</span>: <span class="string">"xxxxxx"</span>,</span><br><span class="line">    <span class="attr">"image_name"</span>: <span class="string">"xxxxxx"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"builders"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"googlecompute"</span>,</span><br><span class="line">      <span class="attr">"project_id"</span>: <span class="string">"&#123;&#123;user `project_id`&#125;&#125;"</span>,</span><br><span class="line">      <span class="attr">"source_image"</span>: <span class="string">"&#123;&#123;user `source_image`&#125;&#125;"</span>,</span><br><span class="line">      <span class="attr">"subnetwork"</span>: <span class="string">"&#123;&#123;user `subnetwork`&#125;&#125;"</span>,</span><br><span class="line">      <span class="attr">"ssh_username"</span>: <span class="string">"xxxxxx"</span>,</span><br><span class="line">      <span class="attr">"zone"</span>: <span class="string">"&#123;&#123;user `zone`&#125;&#125;"</span>,</span><br><span class="line">      <span class="attr">"use_internal_ip"</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="attr">"omit_external_ip"</span>: <span class="literal">true</span>,</span><br><span class="line">      <span class="attr">"image_description"</span>: <span class="string">"xxxxxx"</span>,</span><br><span class="line">      <span class="attr">"image_name"</span>: <span class="string">"&#123;&#123;user `image_name`&#125;&#125;"</span></span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"provisioners"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"ansible"</span>,</span><br><span class="line">      <span class="attr">"max_retries"</span>: <span class="number">0</span>,</span><br><span class="line">      <span class="attr">"pause_before"</span>: <span class="string">"5s"</span>,</span><br><span class="line">      <span class="attr">"playbook_file"</span>: <span class="string">"setup.yml"</span>,</span><br><span class="line">      // acts on target instance</span><br><span class="line">      "extra_arguments": ["--become", "-e ansible_python_interpreter=/usr/bin/python3", "-v"],</span><br><span class="line">      "user": "xxxxxx"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Some useful commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># illustrate packer.json file</span></span><br><span class="line">packer inspect</span><br><span class="line"></span><br><span class="line"><span class="comment"># validate packer.json syntax</span></span><br><span class="line">packer validate &lt;file.json&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># build image</span></span><br><span class="line"><span class="comment"># -de<span class="doctag">bug:</span> pause for each step, clear</span></span><br><span class="line">packer build [-debug] &lt;file.json&gt;</span><br><span class="line"><span class="comment"># -force: delete existing artifact then build</span></span><br><span class="line">packer build -force [-debug] &lt;file.json&gt;</span><br></pre></td></tr></table></figure></p>
<p>When using <code>-debug</code> flag, Packer will show you the private pem file in current directory, you can use that pem file ssh to running VM, for example, in google cloud:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># jenkins is the ssh_username you set in template</span></span><br><span class="line">ssh -i gce_googlecompute.pem jenkins@172.16.160.49</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Infra</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>packer</tag>
      </tags>
  </entry>
  <entry>
    <title>Terraform Quick Start</title>
    <url>/2020/05/16/infra-terraform/</url>
    <content><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>To alter a planet for the purpose of sustaining life.</p>
<p>This article from IBM can give you a good overview:<br><a href="https://www.ibm.com/cloud/learn/terraform" target="_blank" rel="noopener">https://www.ibm.com/cloud/learn/terraform</a></p>
<ul>
<li>Terraform vs Kubernetes</li>
<li>Terraform vs Ansible</li>
</ul>
<p>From Hashicorp, removing manual build process, adopting declarative approach to deploy <strong>infrastructure as code</strong>, reusable, idempotent and consistent repeatable deployment.</p>
<p>Use gcloud, API or client binary can do the same work as Terraform, so what are the <code>benefits</code>:</p>
<ul>
<li><p>unified workflow: If you are already deploying infrastructure to Google Cloud with Terraform, your resources can fit into that workflow.</p>
</li>
<li><p>full lifecycle management: Terraform doesn’t only create resources, it updates, and deletes tracked resources without requiring you to inspect the API to identify those resources.</p>
</li>
<li><p>graph of relationships: Terraform understands dependency relationships between resources.</p>
</li>
</ul>
<p>CSDN:</p>
<ul>
<li><a href="https://www.cnblogs.com/sparkdev/p/10052310.html" target="_blank" rel="noopener">https://www.cnblogs.com/sparkdev/p/10052310.html</a></li>
</ul>
<p>Terraform 文档非常informative，结构清晰:</p>
<ul>
<li><a href="https://www.terraform.io/docs/" target="_blank" rel="noopener">https://www.terraform.io/docs/</a></li>
</ul>
<p>Terraform之于cloud infra就相当于 helm之于K8s, 大大简化了操作复杂性，自动快速部署，同时做到了复用，versioning等特性。但首先得去了解cloud provider中提供的资源的用途，搭配。</p>
<h2 id="Github-Repo"><a href="#Github-Repo" class="headerlink" title="Github Repo"></a>Github Repo</h2><p>resource files in github:<br><a href="https://github.com/ned1313/Getting-Started-Terraform" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Terraform</a></p>
<h2 id="Composition"><a href="#Composition" class="headerlink" title="Composition"></a>Composition</h2><p>Terraform executable: download from web<br>Terraform files: using hashicorp configure language DSL<br>Terraform plugin: interact with provider: AWS, GCP, Azure, etc<br>Terraform state file: json and don’t touch it</p>
<p>You can have multiple terraform files: <code>.tf</code>, when run terraform it will stitch them together to form a single configuration. 比如把variables, outputs, resources, tfvars分开。</p>
<p>tfvars file by default named as <code>terraform.tfvars</code>, otherwise when run <code>plan</code> you need to specify the file path.</p>
<h1 id="Commands"><a href="#Commands" class="headerlink" title="Commands"></a>Commands</h1><p>To execute terraform command, build a docker image and mount cloud account credentials when start container.<br>If you update the terraform file with different configuration, rerun <code>init</code>, <code>plan</code> and <code>apply</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list all commands</span></span><br><span class="line">terraform --<span class="built_in">help</span></span><br><span class="line">terraform version</span><br><span class="line"><span class="comment">## create workspace, see below section</span></span><br><span class="line">terraform workspace</span><br><span class="line"><span class="comment">## linter</span></span><br><span class="line">terraform validate</span><br><span class="line"><span class="comment">## show a tree of providers</span></span><br><span class="line">terraform providers</span><br><span class="line"></span><br><span class="line"><span class="comment">## init will download plugin, for example, aws, gcp or azure..</span></span><br><span class="line">terraform init</span><br><span class="line"><span class="comment">## will show you the diff if you update your terraform file</span></span><br><span class="line"><span class="comment">## load terraform.tfvars by default</span></span><br><span class="line"><span class="comment">## not necessary for terrafrom &gt;= 0.12</span></span><br><span class="line">terraform plan -out plan.tfplan</span><br><span class="line"></span><br><span class="line"><span class="comment">## will generate a tfstate file</span></span><br><span class="line"><span class="comment">## perform creation as much parallel as possible</span></span><br><span class="line"><span class="comment">## --auto-approve: for script, no interactive</span></span><br><span class="line">terraform apply <span class="string">"plan.tfplan"</span> [--auto-approve]</span><br><span class="line"><span class="comment">## you can run apply directly rather than plan first</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## Manually mark a resource as tainted, forcing a destroy and recreate</span></span><br><span class="line"><span class="comment">## on the next plan/apply.</span></span><br><span class="line">terraform taint &lt;google_compute_instance.vm_instance&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## output terraform state or plan file in a human-readable form</span></span><br><span class="line"><span class="comment">## show what has been created</span></span><br><span class="line">terraform show</span><br><span class="line"></span><br><span class="line"><span class="comment">## show output variable value</span></span><br><span class="line"><span class="comment">## useful for scripts to extract outputs from your configuration</span></span><br><span class="line">terraform output [output name]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## refresh your state by comparing it to your cloud infrastructure</span></span><br><span class="line"><span class="comment">## for example, populate the output variable</span></span><br><span class="line">terraform refresh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## show objects being managed by state file</span></span><br><span class="line">terraform state list</span><br><span class="line"></span><br><span class="line"><span class="comment">## destroy Terraform-managed infrastructure</span></span><br><span class="line">terraform destroy [--auto-approve]</span><br></pre></td></tr></table></figure></p>
<h2 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h2><p>Hashicorp configuration language:<br><a href="https://www.terraform.io/docs/configuration/index.html" target="_blank" rel="noopener">https://www.terraform.io/docs/configuration/index.html</a><br>Basic block syntax:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">block_type label_one label_two &#123;</span><br><span class="line">    key = value</span><br><span class="line"></span><br><span class="line">    embedded_block &#123;</span><br><span class="line">        key = value</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>怎么知道resource的名称呢? find the provider, then search the resources:<br><a href="https://www.terraform.io/docs/configuration/resources.html" target="_blank" rel="noopener">https://www.terraform.io/docs/configuration/resources.html</a><br>还有random provider，比如产生随机数</p>
<h1 id="Provisioner"><a href="#Provisioner" class="headerlink" title="Provisioner"></a>Provisioner</h1><p>类似于ansible的配置操作，在deploy infrastructure 之后.<br>post-deployment configuration and last resort, prefer ansible/puppet or chef.</p>
<p>Provisioner can be ran in creation or destruction stage, you can also have multi-provisioner in one resources and they execute in order in resource.</p>
<p>Provisioner can be local or remote:</p>
<ul>
<li>file: copy file from local to remove VM instance.</li>
<li>local-exec: executes a command locally on the machine running Terraform, not the VM instance itself. </li>
<li>remote-exec: executes on remote VM instance.</li>
</ul>
<p>Terraform treats provisioners differently from other arguments. Provisioners only run when a resource is created, but adding a provisioner does not force that resource to be destroyed and recreated. Use <code>terraform taint</code> to tell Terraform to recreate the instance.</p>
<h1 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h1><p><a href="https://www.terraform.io/docs/configuration/functions.html" target="_blank" rel="noopener">https://www.terraform.io/docs/configuration/functions.html</a></p>
<p>You can experiment with functions in Terraform console, this can help with troubleshooting.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## first run terraform init</span></span><br><span class="line"><span class="comment">## it will auto load tfvars file and variables</span></span><br><span class="line">terraform console</span><br><span class="line">&gt; lower(<span class="string">"HELLO"</span>)</span><br><span class="line">&gt; merge(map1, map2)</span><br><span class="line">&gt; file(path)</span><br><span class="line">&gt; min(2,5,90)</span><br><span class="line">&gt; timestamp()</span><br><span class="line"><span class="comment">## modular</span></span><br><span class="line">&gt; 34 % 2</span><br><span class="line">&gt; cidrsubnet(var.network_address_space, 8, 0)</span><br><span class="line"><span class="comment">## lookup value in a map</span></span><br><span class="line">&gt; lookup(local.common_tags, <span class="string">"Bill"</span>, <span class="string">"Unknown"</span>)</span><br></pre></td></tr></table></figure></p>
<p>for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">variable network_info &#123;</span><br><span class="line">    default = <span class="string">"10.1.0.0/16"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## split network range by adding 8 bits, fetch the first one subnet</span></span><br><span class="line"><span class="comment">## 10.1.0.0/24</span></span><br><span class="line">cidr_block = cidrsubnet(var.network_info, 8, 0)</span><br></pre></td></tr></table></figure></p>
<h1 id="Provider"><a href="#Provider" class="headerlink" title="Provider"></a>Provider</h1><p>Support mutliple providers, all written in Go.<br><a href="https://www.terraform.io/docs/providers/index.html" target="_blank" rel="noopener">https://www.terraform.io/docs/providers/index.html</a></p>
<h1 id="Resource-arguments"><a href="#Resource-arguments" class="headerlink" title="Resource arguments"></a>Resource arguments</h1><p><a href="https://www.terraform.io/docs/configuration/resources.html#meta-arguments" target="_blank" rel="noopener">https://www.terraform.io/docs/configuration/resources.html#meta-arguments</a><br>common ones:</p>
<ul>
<li>depends_on: make sure terraform creates things in right order</li>
<li>count: create similar resources</li>
<li>for_each: create resources not similar</li>
<li>provider: which provider should create the resource</li>
</ul>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">resource <span class="string">"aws_instance"</span> <span class="string">"web"</span> &#123;</span><br><span class="line">    <span class="comment">## index start from 0</span></span><br><span class="line">    count = 3</span><br><span class="line">    tags &#123;</span><br><span class="line">        Name = <span class="string">"web-<span class="variable">$&#123;count.index + 1&#125;</span>"</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    depends_on = [aws_iam_role_policy.custom_name]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">resource <span class="string">"aws_s3_bucket"</span> <span class="string">"storage"</span> &#123;</span><br><span class="line">    for_each = &#123;</span><br><span class="line">        food = <span class="string">"public-read"</span></span><br><span class="line">        cash = <span class="string">"private"</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">## access key and value</span></span><br><span class="line">    bucket = <span class="string">"<span class="variable">$&#123;each.key&#125;</span>-<span class="variable">$&#123;var.bucket_suffix&#125;</span>"</span></span><br><span class="line">    acl = each.value</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h1><p>Other way to use variables rather than specifying in single <code>.tf</code> file.</p>
<p>The scenario, we need development, QA(Quality Assurance)/UAT(User Acceptance Testing), production environment, how to implement with one configuration and multiple inputs?</p>
<p>The variable can be from, precedence low to high:</p>
<ul>
<li>environment variable: <code>TF_VAR_&lt;var name&gt;</code>.</li>
<li>file: <code>terraform.tfvars</code> or specify by <code>-var-file</code> in terraform command.</li>
<li>terraform command flags <code>-var</code>.</li>
</ul>
<p>You can override variables and precedence, select value based on environment, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## specify default value in tf file</span></span><br><span class="line">variable <span class="string">"env_name"</span> &#123;</span><br><span class="line">  <span class="built_in">type</span> = string</span><br><span class="line">  default = <span class="string">"development"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## specify in tfvars file</span></span><br><span class="line">env_name = <span class="string">"uat"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## specify in command line</span></span><br><span class="line">terraform plan -var <span class="string">'env_name=production'</span></span><br></pre></td></tr></table></figure></p>
<p>Variable types:</p>
<ul>
<li>string, the default type if no explicitly specified</li>
<li>bool: true, false</li>
<li>number (integer/decimal)</li>
<li>list (index start from 0)</li>
<li>map, value type can be number, string and bool</li>
</ul>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">variable <span class="string">"project"</span> &#123;</span><br><span class="line">  <span class="built_in">type</span> = string</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">variable <span class="string">"web_instance_count"</span> &#123;</span><br><span class="line">  <span class="built_in">type</span>    = number</span><br><span class="line">  default = 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## list</span></span><br><span class="line">variable <span class="string">"cidrs"</span> &#123; default = [] &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## map</span></span><br><span class="line">variable <span class="string">"machine_types"</span> &#123;</span><br><span class="line">  <span class="comment">## map type and key is string</span></span><br><span class="line">  <span class="built_in">type</span>    = map(string)</span><br><span class="line">  default = &#123;</span><br><span class="line">    dev  = <span class="string">"f1-micro"</span></span><br><span class="line">    <span class="built_in">test</span> = <span class="string">"n1-highcpu-32"</span></span><br><span class="line">    prod = <span class="string">"n1-highcpu-32"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">machine_resource = lookup(var.machine_types, var.environment_name)</span><br></pre></td></tr></table></figure></p>
<p>In terraform, the same syntax <code>${}</code> for interpolation as bash:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## local variable definition</span></span><br><span class="line">locals &#123;</span><br><span class="line">  <span class="comment">## random_integer is a terraform resource</span></span><br><span class="line">  tags = <span class="string">"<span class="variable">$&#123;var.bucket_name_prefix&#125;</span>-<span class="variable">$&#123;var.environment_tag&#125;</span>-<span class="variable">$&#123;random_integer.rand.result&#125;</span>"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## use</span></span><br><span class="line">resource <span class="string">"aws_instance"</span> <span class="string">"example"</span> &#123;</span><br><span class="line">  tags = local.tags</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Workspace"><a href="#Workspace" class="headerlink" title="Workspace"></a>Workspace</h1><p>Workspace is the recommended way to working with multiple environments, for example:</p>
<ul>
<li>state management</li>
<li>variables data</li>
<li>credentials management</li>
</ul>
<p>State file example, we have dev, QA, prod three environments, put them each into separate folder, when run command, specify the input and output:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## for dev environment</span></span><br><span class="line"><span class="comment">## -state: where to write state file</span></span><br><span class="line"><span class="comment">## -var-file: load file</span></span><br><span class="line">terraform plan -state=<span class="string">"./dev/dev.state"</span> \</span><br><span class="line">               -var-file=<span class="string">"common.tfvars"</span> \</span><br><span class="line">               -var-file=<span class="string">"./dev/dev.tfvars"</span></span><br></pre></td></tr></table></figure></p>
<p>Workspace example, there is a <code>terraform.workspace</code> built-in variable can be used to indicate the workspace currently in, then use it in map variable to select right value for different environment. (不用再去分别创建不同的folder for different environment了)<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create dev workspace and switch to it</span></span><br><span class="line"><span class="comment">## 类似于Python venv, py文件没变化，但Python version 和 packages 变了</span></span><br><span class="line">terraform workspace new dev</span><br><span class="line"><span class="comment">## show workspace</span></span><br><span class="line">terraform workspace list</span><br><span class="line">terraform plan -out dev.tfplan</span><br><span class="line">terraform apply <span class="string">"dev.tfplan"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## now create QA workspace</span></span><br><span class="line">terraform workspace new QA</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment">## switch workspace</span></span><br><span class="line">terraform workspace select dev</span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">locals &#123;</span><br><span class="line">  <span class="comment">## special terraform variable to get workspace name</span></span><br><span class="line">  env_name = lower(terraform.workspace)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Managing-secrets"><a href="#Managing-secrets" class="headerlink" title="Managing secrets"></a>Managing secrets</h1><p>Hashicorp <strong>vault</strong> is for this purpose. it can hand over credentials from cloud provider to terraform and set ttl for the secrets.</p>
<p>Or you can use environment variable to specify the credentials, terraform will pick it automatically, but bear in mind to use the right env var name. For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 注意这个前面的TF_VAR_&lt;var name&gt; 不一样，这里是secret</span></span><br><span class="line"><span class="built_in">export</span> AWS_ACCESS_KEY_ID=xxx</span><br><span class="line"><span class="built_in">export</span> AWS_SECRET_ACCESS_KEY=xxx</span><br></pre></td></tr></table></figure></p>
<h1 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h1><p>Make code reuse eaiser:<br><a href="https://www.terraform.io/docs/configuration/modules.html" target="_blank" rel="noopener">https://www.terraform.io/docs/configuration/modules.html</a></p>
<p>Terraform registry, similar concept with Helm, Docker:<br><a href="https://registry.terraform.io/" target="_blank" rel="noopener">https://registry.terraform.io/</a><br>Using module block to invoke local or remote modules.</p>
<ol>
<li>root module</li>
<li>support versioning</li>
<li>provider inheritance</li>
</ol>
<p>Module components:</p>
<ul>
<li>variables input</li>
<li>resources</li>
<li>output values (calling part will take this in)</li>
</ul>
<h1 id="Google-Cloud-Platform"><a href="#Google-Cloud-Platform" class="headerlink" title="Google Cloud Platform"></a>Google Cloud Platform</h1><p>Good tutorial:<br><a href="https://learn.hashicorp.com/tutorials/terraform/google-cloud-platform-build" target="_blank" rel="noopener">https://learn.hashicorp.com/tutorials/terraform/google-cloud-platform-build</a></p>
<p>If run <code>terraform apply</code> get permission issues, add the service account used to IAM, than grant it roles. Then retry the apply command.</p>
<p>用Terraform 建造的VM instance network 没有ssh allow firewall rule, 要自己添加:<br><a href="https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-ssh" target="_blank" rel="noopener">https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-ssh</a></p>
<p>Terrafrom provisions <code>GKE</code> with additional node pool:<br><a href="https://learn.hashicorp.com/terraform/kubernetes/provision-gke-cluster" target="_blank" rel="noopener">https://learn.hashicorp.com/terraform/kubernetes/provision-gke-cluster</a></p>
<h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h2><p>Commonly use reource types for terraform <code>resource</code> block:</p>
<ul>
<li>google_compute_network</li>
<li>google_compute_instance</li>
<li>google_compute_address</li>
<li>google_storage_bucket</li>
<li>google_container_cluster</li>
<li>google_container_node_pool</li>
</ul>
]]></content>
      <categories>
        <category>Infra</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>terraform</tag>
      </tags>
  </entry>
  <entry>
    <title>Vagrant Quick Start</title>
    <url>/2020/06/13/infra-vagrant/</url>
    <content><![CDATA[<p>My Vagrant singleton virtual machine and cluster setup for different usage, see this <a href="https://github.com/chengdol/InfraTree" target="_blank" rel="noopener">git repo</a>.</p>
<p>早在2019年使用Ansible (from Book <code>&lt;&lt;Ansible: Up and Running&gt;&gt;</code>)的时候就了解到了Vagrant，知道它能非常方便的provisioning virtual machine cluster for testing and demo purpose (比如测试Ansible的功能模块, Jenkins, Nginx).这次系统地学习了，这样在本地部署实验集群也很方便了(还有一个选择是docker compose)。</p>
<p>Ansible playbooks are a great way to specify how to configure a Vagrant machine so new comers on your team can get up and running on day one. Of course you can use other provisioners.</p>
<p><a href="https://app.vagrantup.com/boxes/search" target="_blank" rel="noopener">Vagrant Box Search</a> 提供诸如 Windows, MacOS等许多操作系统的box image. 还有Openshift, Kubernetes all-in-one box等, 但是可能有的配置过于繁杂，可以自己使用root image build your custom image via Packer.</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>First read the <a href="https://www.vagrantup.com/" target="_blank" rel="noopener">Vagrant web site</a>.<br><a href="https://www.hashicorp.com/blog/category/vagrant" target="_blank" rel="noopener">Vagrant Blog</a> (from HashiCorp). To see what’s new in latest version.</p>
<p>It leverages a <code>declarative</code> configuration file which describes all your software requirements, packages, operating system configuration, users, and more.</p>
<p>Vagrant also integrates with your existing configuration management tooling like Ansible, Chef, Docker, Puppet or Salt, so you can use the same scripts to configure Vagrant as production.</p>
<p><a href="https://www.vagrantup.com/intro/vs" target="_blank" rel="noopener">Vagrant vs. Other Software</a><br>Compare with VirutalBox CLI tools, Docker and Terraform.</p>
<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><p>Installation is easy, Vagrant and VirtualBox, other providers are possible, for example, Docker, VMware.</p>
<p>Download and install VirtualBox:<br><a href="https://www.virtualbox.org/wiki/Downloads" target="_blank" rel="noopener">https://www.virtualbox.org/wiki/Downloads</a></p>
<p>Download and install Vagrant:<br><a href="https://www.vagrantup.com/downloads" target="_blank" rel="noopener">https://www.vagrantup.com/downloads</a></p>
<h2 id="Project"><a href="#Project" class="headerlink" title="Project"></a>Project</h2><p>The <code>Vagrantfile</code> is meant to be committed to <code>version control</code> with your project, if you use version control. This way, every person working with that project can benefit from Vagrant without any upfront work.</p>
<p>The syntax of Vagrantfiles is <code>Ruby</code>, but knowledge of the Ruby programming language is not necessary to make modifications to the Vagrantfile, since it is mostly simple variable assignment.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># init project</span></span><br><span class="line">mkdir vagrant_getting_started</span><br><span class="line"><span class="built_in">cd</span> vagrant_getting_started</span><br><span class="line"></span><br><span class="line"><span class="comment"># --minimal: generate minimal Vagrantfile</span></span><br><span class="line"><span class="comment"># hashicorp/bionic64: the box name</span></span><br><span class="line"><span class="comment"># if you have Vagrantfile, no need this</span></span><br><span class="line">vagrant init hashicorp/bionic64 [--minimal]</span><br></pre></td></tr></table></figure></p>
<p>Of course you can create a <code>Vagrantfile</code> manually.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># download box image</span></span><br><span class="line"><span class="comment"># you don't need to explicitly do this, vagrant will handle download from Vagrantfile</span></span><br><span class="line">vagrant box add hashicorp/bionic64</span><br></pre></td></tr></table></figure>
<p>In the above command, you will notice that boxes are namespaced. Boxes are broken down into two parts - the username and the box name - separated by a slash. In the example above, the username is “hashicorp”, and the box is “bionic64”.</p>
<p>Editing Vagrantfile, this is a simple example to bring up a jenkins cluster:<br><figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -*- mode: ruby -*-</span></span><br><span class="line"><span class="comment"># vi: set ft=ruby :</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># image info for all machines</span></span><br><span class="line">IMAGE_NAME = <span class="string">"generic/centos7"</span></span><br><span class="line">IMAGE_VERSION = <span class="string">"3.0.10"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># server static ip</span></span><br><span class="line">SERVER_IP = <span class="string">"192.168.3.2"</span></span><br><span class="line"><span class="comment"># agent static ip, start from 192.168.50.1x</span></span><br><span class="line">AGENT_IP = <span class="string">"192.168.3.1"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Vagrantfile for Jenkins</span></span><br><span class="line">Vagrant.configure(<span class="string">"2"</span>) <span class="keyword">do</span> <span class="params">|config|</span></span><br><span class="line">  <span class="comment"># box for virtual machines</span></span><br><span class="line">  config.vm.box = IMAGE_NAME</span><br><span class="line">  config.vm.box_version = IMAGE_VERSION</span><br><span class="line"></span><br><span class="line">  <span class="comment"># virtualbox configuration for virtual machines</span></span><br><span class="line">  config.vm.provider <span class="string">"virtualbox"</span> <span class="keyword">do</span> <span class="params">|v|</span></span><br><span class="line">    v.memory = <span class="number">512</span></span><br><span class="line">    v.cpus = <span class="number">2</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># synced folder</span></span><br><span class="line">  config.vm.synced_folder <span class="string">"."</span>, <span class="string">"/vagrant"</span>,</span><br><span class="line">    <span class="symbol">owner:</span> <span class="string">"root"</span>, <span class="symbol">group:</span> <span class="string">"root"</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># Jenkins server, set as primary</span></span><br><span class="line">  config.vm.define <span class="string">"server"</span>, <span class="symbol">primary:</span> <span class="literal">true</span> <span class="keyword">do</span> <span class="params">|server|</span></span><br><span class="line">    server.vm.hostname = <span class="string">"jenkins-server"</span></span><br><span class="line">    <span class="comment"># private network</span></span><br><span class="line">    <span class="comment"># jenkins uses port 8080 in browser</span></span><br><span class="line">    server.vm.network <span class="string">"private_network"</span>, <span class="symbol">ip:</span> SERVER_IP</span><br><span class="line">    <span class="comment"># provisioning</span></span><br><span class="line">    server.vm.provision <span class="symbol">:shell</span>, <span class="symbol">path:</span> <span class="string">"./provision/server.sh"</span>, <span class="symbol">privileged:</span> <span class="literal">true</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># agents setup</span></span><br><span class="line">  (<span class="number">1</span>..<span class="number">2</span>).each <span class="keyword">do</span> <span class="params">|i|</span></span><br><span class="line">    config.vm.define <span class="string">"agent<span class="subst">#&#123;i&#125;</span>"</span> <span class="keyword">do</span> <span class="params">|agent|</span></span><br><span class="line">      agent.vm.hostname = <span class="string">"jenkins-agent<span class="subst">#&#123;i&#125;</span>"</span></span><br><span class="line">      <span class="comment"># private network</span></span><br><span class="line">      agent.vm.network <span class="string">"private_network"</span>, <span class="symbol">ip:</span> <span class="string">"<span class="subst">#&#123;AGENT_IP&#125;</span><span class="subst">#&#123;i&#125;</span>"</span></span><br><span class="line">      <span class="comment"># provisioning</span></span><br><span class="line">      agent.vm.provision <span class="symbol">:shell</span>, <span class="symbol">path:</span> <span class="string">"./provision/agent.sh"</span>, <span class="symbol">privileged:</span> <span class="literal">true</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<p>使用了private IP后，不再需要port forwarding了，比如VM中有apache server listening on port 80，则可以在host browser上直接访问<code>http://192.168.2.2</code>. 查看virtualbox当前VM的网络配置，对应的adapter用的是Host-only adapter.</p>
<blockquote>
<p>注意，在使用private IP的时候，一般遵循private network的<a href="https://en.wikipedia.org/wiki/Private_network#Private_IPv4_address_spaces" target="_blank" rel="noopener">范围限制</a>, 我发现chrome上可能无法访问，可以使用firefox or chrome 匿名模式。或直接使用curl, wget等命令。</p>
</blockquote>
<p>还有一点要注意，防火墙firewall是否关闭或设置相应的rules，否则也可能访问不到port:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/5984217/vagrants-port-forwarding-not-working" target="_blank" rel="noopener">Vagrant’s port forwarding not working</a></li>
</ul>
<p>同一网段的private IP是集群必备，否则不能相互SSH访问。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># assign private IP</span></span><br><span class="line">config.vm.network <span class="string">"private_network"</span>, ip: <span class="string">"192.168.2.2"</span></span><br></pre></td></tr></table></figure></p>
<p>This configuration uses a Vagrant private network. The machine can be accessed <code>only</code> from the machine that runs Vagrant. You won’t be able to connect to this IP address from another physical machine, even if it’s on the same network as the machine running Vagrant. However, different Vagrant machines <strong>can</strong> connect to each other.</p>
<p>Public network, allow general public access to VM, 但本地测试使用意义不大。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># when start, it will prompt you select which interface to use</span></span><br><span class="line">config.vm.network <span class="string">"public_network"</span>, ip: <span class="string">"192.173.2.2"</span></span><br></pre></td></tr></table></figure></p>
<p>SSH agent forwarding, for example, git clone from VM using the private key of host<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">config.ssh.forward_agent = <span class="literal">true</span></span><br></pre></td></tr></table></figure></p>
<p>Bring up the environment:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># validate syntax</span></span><br><span class="line">vagrant validate</span><br><span class="line"><span class="comment"># check machine status</span></span><br><span class="line">vagrant status</span><br><span class="line"><span class="comment"># at your project root directory</span></span><br><span class="line">vagrant up</span><br><span class="line"><span class="comment"># ssh to primary machine in your project</span></span><br><span class="line">vagrant ssh [vm name]</span><br><span class="line"></span><br><span class="line"><span class="comment"># when you finish working</span></span><br><span class="line"><span class="comment"># destroy machine</span></span><br><span class="line"><span class="comment"># -f: confirm</span></span><br><span class="line">vagrant destroy -f</span><br><span class="line"><span class="comment"># remove the box</span></span><br><span class="line">vagrant box remove</span><br></pre></td></tr></table></figure></p>
<p>Note that by default <code>vagrant ssh</code> login as user <code>vagrant</code>, not <code>root</code> user, you can use <code>sudo</code> to execute command or run <code>sudo su -</code> first.</p>
<p><a href="https://stackoverflow.com/questions/10864372/how-to-ssh-to-vagrant-without-actually-running-vagrant-ssh" target="_blank" rel="noopener">可不可以直接使用ssh command呢</a>？也是可以的, 在project中有个<code>.vagrant</code> folder，the private key is in the path <code>.vagrant/machines/&lt;VM name&gt;/virtualbox/private_key</code>, 可以用这个private key to ssh:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -i &lt;path to private key&gt; -p 2222 vagrant@127.0.0.1</span><br></pre></td></tr></table></figure></p>
<p>这些信息可以通过<code>vagrant ssh-config</code>查看到:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vagrant must be running</span></span><br><span class="line">vagrant ssh-config</span><br><span class="line"></span><br><span class="line">Host default</span><br><span class="line">  HostName 127.0.0.1</span><br><span class="line">  User vagrant</span><br><span class="line">  Port 2222</span><br><span class="line">  UserKnownHostsFile /dev/null</span><br><span class="line">  StrictHostKeyChecking no</span><br><span class="line">  PasswordAuthentication no</span><br><span class="line">  IdentityFile .../.vagrant/machines/default/virtualbox/private_key</span><br><span class="line">  IdentitiesOnly yes</span><br><span class="line">  LogLevel FATAL</span><br></pre></td></tr></table></figure></p>
<p>这个ssh是如何创建的呢？在创建VM后只有NAT，host并不能访问VM，vagrant会自动设置NAT port forwarding 映射SSH port 22 on VM, 然后生成SSH public-private key等内容，之后使用<code>vagrant ssh</code>就可以访问了。</p>
<p>By using <code>synced folders</code>, Vagrant will automatically sync your files to and from the guest machine. By default, Vagrant shares your <code>project directory</code> (remember, that is the one with the Vagrantfile) to the <code>/vagrant</code> directory in your guest machine.</p>
<p>Synced folder will be mapped <strong>before</strong> provisioning would run.</p>
<p>Vagrant also support rsync, primarily in situations where other synced folder mechanisms are not available:<br><a href="https://www.vagrantup.com/docs/synced-folders/rsync.html" target="_blank" rel="noopener">https://www.vagrantup.com/docs/synced-folders/rsync.html</a></p>
<p>Vagrant has built-in support for <code>automated provisioning</code>. Using this feature, Vagrant will automatically install software when you vagrant up so that the guest machine can be repeatably created and ready-to-use.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># use Ansible provisioner</span></span><br><span class="line">VAGRANTFILE_API_VERSION = <span class="string">"2"</span></span><br><span class="line">Vagrant.configure(VAGRANTFILE_API_VERSION) <span class="keyword">do</span> |config|</span><br><span class="line">  config.vm.box = <span class="string">"ubuntu/trusty64"</span></span><br><span class="line">  config.vm.provision <span class="string">"ansible"</span> <span class="keyword">do</span> |ansible|</span><br><span class="line">    ansible.playbook = <span class="string">"playbook.yml"</span></span><br><span class="line">  end</span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<p>Vagrant will not run it a second time only if you force it.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># reboot machine and reload provision setting if machine is already running</span></span><br><span class="line"><span class="comment"># if no provision needed, just run vagrant reload</span></span><br><span class="line"><span class="comment"># --provision: force run provision again</span></span><br><span class="line">vagrant reload --provision</span><br><span class="line"><span class="comment"># force rerun provision when machine is running</span></span><br><span class="line">vagrant provision</span><br></pre></td></tr></table></figure></p>
<p>可以软连接synced folder中的文件或文件夹到需要的地方，这样方便在host machine中编辑.</p>
<p>Methods to teardown:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># hibernate, save states in disk</span></span><br><span class="line">vagrant <span class="built_in">suspend</span></span><br><span class="line">vagrant resume</span><br><span class="line"></span><br><span class="line"><span class="comment"># normal power off</span></span><br><span class="line">vagrant halt</span><br><span class="line"><span class="comment"># reclaim all resources</span></span><br><span class="line">vagrant destroy</span><br><span class="line"><span class="comment"># boot again</span></span><br><span class="line">vagrant up</span><br></pre></td></tr></table></figure></p>
<p><a href="https://stackoverflow.com/questions/42549087/in-vagrant-which-is-better-out-of-halt-and-suspend" target="_blank" rel="noopener">When to use suspend vs halt</a></p>
<h2 id="Multi-Machine"><a href="#Multi-Machine" class="headerlink" title="Multi-Machine"></a>Multi-Machine</h2><p>这个是非常实用的部分，对于测试ansible 以及 jenkins:<br><a href="https://www.vagrantup.com/docs/multi-machine" target="_blank" rel="noopener">https://www.vagrantup.com/docs/multi-machine</a></p>
<h2 id="Convert-ova-to-box"><a href="#Convert-ova-to-box" class="headerlink" title="Convert ova to box"></a>Convert ova to box</h2><p>Convert a Virtualbox ova to a Vagrant box<br><a href="https://gist.github.com/chengdol/315d3cbb83cf224c3b34913095b7fff9" target="_blank" rel="noopener">https://gist.github.com/chengdol/315d3cbb83cf224c3b34913095b7fff9</a></p>
<h1 id="VirtualBox"><a href="#VirtualBox" class="headerlink" title="VirtualBox"></a>VirtualBox</h1><p>Start from PluralSight 2014年的Vagrant课程，记录的时候会有一些更新。<br>Virtualbox command line tool:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># list VMs</span></span><br><span class="line">vboxmanage list vms</span><br><span class="line"><span class="comment"># show running VMs</span></span><br><span class="line">vboxmanage list runningvms</span><br></pre></td></tr></table></figure></p>
<p><a href="https://www.virtualbox.org/manual/ch06.html" target="_blank" rel="noopener">Networks types</a>:<br><a href="https://www.youtube.com/watch?v=cDF4X7RmV4Q" target="_blank" rel="noopener">Networks types video</a></p>
<ul>
<li><p><code>Not attached</code>. In this mode, Oracle VM VirtualBox reports to the guest that a network card is present, but that there is no connection. This is as if no Ethernet cable was plugged into the card. 断网模式。</p>
</li>
<li><p><code>Network Address Translation (NAT)</code>. If all you want is to browse the Web, download files, and view email <strong>inside</strong> the guest, then this default mode should be sufficient for you. 从VM内部可以上网，如果外界或host要访问VM的服务，需要port forwarding. (host is used as a proxy for VM)</p>
</li>
<li><p><code>Host-only networking</code>. This can be used to create a network containing the host and a set of virtual machines, without the need for the host’s physical network interface. Instead, a virtual network interface, similar to a loopback interface, is created on the host, providing connectivity among virtual machines and the host. 可以确保host和VMs 相互通信，但VM不能访问外界。</p>
</li>
<li><p><code>Bridged networking</code>. This is for more advanced networking needs, such as network simulations and running servers in a guest. When enabled, Oracle VM VirtualBox connects to one of your installed network cards and exchanges network packets directly, circumventing your host operating system’s network stack. 这个是最全的访问模式，VM, host, 外界均可互访。Docker, Docker compose的默认网络就是这种类型。</p>
</li>
<li><p><code>Internal networking</code>. This can be used to create a different kind of software-based network which is visible to selected virtual machines, but not to applications running on the host or to the outside world. 只能选中的VMs之间互访。</p>
</li>
<li><p><code>NAT Network</code>. A NAT network is a type of internal network that allows outbound connections. 选中的VMs之间互访，加上outbound.</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Infra</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>vagrant</tag>
      </tags>
  </entry>
  <entry>
    <title>Inprogress</title>
    <url>/2019/01/01/inprogress/</url>
    <content><![CDATA[<p><strong>This is the blog incubator and TODO list</strong><br>保持记忆的熟练的唯一方式就是复习 和 刷题，特别是语言类。<br>最近在做一些pipeline的工作，需要快速上手，主要涉及到的:<br>Terraform<br>Python<br>Jenkins<br>gradle  (一种build tool, others like Blaze, Make)<br>Groovy  (JVM language, similar to Java, for declarative Jenkins pipeline)<br>现在不清楚的地方是各自文件的语法。<br>先从groovy，gradle入手，然后jenkins。</p>
<h1 id="CI-CD"><a href="#CI-CD" class="headerlink" title="CI/CD"></a>CI/CD</h1><p>[ ] travis.yml and inspiration: 大概能看出来是怎么回事了<br><a href="https://gitlab.corp.cloudsimple.com/-/ide/project/gcloud/devops/electric-poc/tree/master/-/roles/ansible-jdk-8/.travis.yml/" target="_blank" rel="noopener">https://gitlab.corp.cloudsimple.com/-/ide/project/gcloud/devops/electric-poc/tree/master/-/roles/ansible-jdk-8/.travis.yml/</a></p>
<h1 id="Envoy-Migration"><a href="#Envoy-Migration" class="headerlink" title="Envoy Migration"></a>Envoy Migration</h1><p>最近几天发现的缺失:<br>[x] <a href="https://app.pluralsight.com/library/courses/ssh-telnet-protocol-deep-dive/table-of-contents" target="_blank" rel="noopener">SSH config and proxy</a> config file, proxy jump, ssh-add.<br>[x] Gitlab, see linkedin learning, gitlab-ci and web dashboard general use.<br>[ ] <a href="https://app.pluralsight.com/library/courses/jira-getting-started/table-of-contents" target="_blank" rel="noopener">Jira</a><br>[ ] pagerduty: resolve -&gt;<br>[x] <a href="https://app.pluralsight.com/channels/details/6f5b8c32-a2a9-472e-bac2-3f2fc198982b" target="_blank" rel="noopener">Http header</a>, CONNECT method, CRLF, browser debug<br>[x] <a href="https://app.pluralsight.com/library/courses/docker-web-development/table-of-contents" target="_blank" rel="noopener">docker compose</a> for testing, why not docker?<br>[x] <a href="https://app.pluralsight.com/library/courses/linux-encryption-security-lpic-3-303/table-of-contents" target="_blank" rel="noopener">SSL/TLS</a>, cloud computing use cases, see udemy<br>[ ] ip/iptables, vagrant + envoy docker does not work, linkedin learning<br>ip route table vs iptables filter/nat table???<br>[x] curl flags and testing, pluralsight<br>[x] linux tips weekly, proxy sections<br>[x] Unix domain socket, websocket, co-routine?<br>[x] proxy, http proxy, reverse proxy?? ssl/tls?</p>
<p>[x] envoy tcp proxy and how to test? 设置好socket server, client，然后client connect to proxy port, in proxy, it driect to server address and port. 解决了！upstream cluster IP 没设置好。。对于docker 不是127.0.0.1!!<br>[ ] for now, understand: http proxy (connect support), tcp proxy, socks proxy.<br>[x] proxy的模拟测试环境 -&gt; docker compose + flask + python other packages<br>[ ] socks how to setup in gcloud or aws –&gt; VPN</p>
<p>[ ] Using golang write tcp, http server.<br>[ ] container runtime varies, search youtube<br>[ ] device42<br>[ ] tower<br>[ ] packer</p>
<p>[x] shell parameter expansion<br>variable pattern match: <code>${1##*/}</code> <code>${USAGE%/*}</code> <code>${1:1:1}</code>, etc</p>
<p>[ ] network traffic school, internally! see my SRE week note.</p>
<p>[ ] 养老金扩展: <a href="https://www.transglobalus.com/zh/services_zh/" target="_blank" rel="noopener">https://www.transglobalus.com/zh/services_zh/</a></p>
<p>[ ] python click必须掌握，很重要！对于advanced script!! click echo color support: <code>click.echo(click.style(&#39;Some more text&#39;, bg=&#39;blue&#39;, fg=&#39;white&#39;))</code><br>这样可以为以后log中重点高亮<br>[ ] python logging 更高级的用法</p>
<p>[x] <a href="https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files" target="_blank" rel="noopener">systemd init file</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## some fields</span></span><br><span class="line">network-online.target</span><br><span class="line">Environment=</span><br><span class="line">OOMScoreAdjust=-1000 ~ 1000</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Type=forking | simple</span><br></pre></td></tr></table></figure></p>
<p>[ ] cloud init<br>passes a userdata file to boot process<br><a href="https://www.youtube.com/watch?v=1joQfUZQcPg" target="_blank" rel="noopener">cloud-init talk</a><br>[ ] LXD container, 用来做了cloud init的应用的例子</p>
<p>后来讲了一下<a href="https://youtu.be/1joQfUZQcPg?t=1472" target="_blank" rel="noopener">cloud init test framework</a><br>[ ] what are smoke &amp; nightly testing</p>
<p>[ ] blue/green deployment</p>
<p>[ ] Linux LPIC-1/2/3 <a href="https://www.lpi.org/" target="_blank" rel="noopener">exams</a><br>[ ] Linux LFCE <a href="https://app.pluralsight.com/paths/certificate/linux-foundation-certified-engineer-lfce" target="_blank" rel="noopener">training</a><br>[ ] CCNA Cisco network certifiate, see pluralsight my channel <code>network</code></p>
<p>[ ] 重读how linux works book<br>[ ] rsyslogd</p>
<h1 id="K8s"><a href="#K8s" class="headerlink" title="K8s"></a>K8s</h1><p>kubectl wait command:<br><a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#port-forward" target="_blank" rel="noopener">https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#port-forward</a></p>
<p>kubectl-images:<br><a href="https://github.com/chenjiandongx/kubectl-images" target="_blank" rel="noopener">https://github.com/chenjiandongx/kubectl-images</a></p>
<p>kubectl krew:<br><a href="https://github.com/kubernetes-sigs/krew" target="_blank" rel="noopener">https://github.com/kubernetes-sigs/krew</a></p>
<p>[ ] k8s is <a href="https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/" target="_blank" rel="noopener">deprecating docker in upcoming release</a>. switch to other common docker runtime: containerd and CRI-O.<br>There are lots of options out there for this specific use case including things like <code>kaniko</code>, <code>img</code>, and <code>buildah</code>.</p>
<h1 id="Squid"><a href="#Squid" class="headerlink" title="Squid"></a>Squid</h1><p>这个对forward proxy支持挺好, long history proxy -_-|||, old<br>[ ] squid proxy</p>
<h1 id="Groovy"><a href="#Groovy" class="headerlink" title="Groovy"></a>Groovy</h1><p>掌握基本data type, control structure, function definition 就可以了. 因为目前主要是用在Jenkins中。<br>和Java 通用的.</p>
<p>Groovy quick start:<br><a href="https://www.youtube.com/watch?v=B98jc8hdu9g" target="_blank" rel="noopener">https://www.youtube.com/watch?v=B98jc8hdu9g</a></p>
<p>Books, course and presentations, recommend:<br><a href="https://groovy-lang.org/learn.html#books" target="_blank" rel="noopener">https://groovy-lang.org/learn.html#books</a><br>O’relly course</p>
<p><a href="http://groovy-lang.org/syntax.html" target="_blank" rel="noopener">http://groovy-lang.org/syntax.html</a><br>alternative java language</p>
<p><code>DSL</code>: domain specific language<br><code>sdkman</code> very good installation toolkit (also for gradle!)<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## must have jdk installed first</span></span><br><span class="line">yum install java-1.8.0-openjdk-devel -y</span><br><span class="line"><span class="comment">## specify version 2.5.2</span></span><br><span class="line">sdk install groovy 2.5.2</span><br></pre></td></tr></table></figure></p>
<p>Utilize vagrant VM to setup groovy runtime with SDKMAN, sync folder to work with VSC.<br>groovy closure:<br><a href="https://groovy-lang.org/closures.html" target="_blank" rel="noopener">https://groovy-lang.org/closures.html</a></p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="comment">// each</span></span><br><span class="line"><span class="keyword">def</span> names = [<span class="string">"alice"</span>, <span class="string">"bob"</span>, <span class="string">"michael"</span>];</span><br><span class="line"><span class="comment">// using closure</span></span><br><span class="line">names.each &#123; println it &#125;;</span><br></pre></td></tr></table></figure>
<p>OOP, the class can be no constructor.</p>
<p>String interpolation:<br><a href="https://groovy-lang.org/syntax.html#_string_interpolation" target="_blank" rel="noopener">https://groovy-lang.org/syntax.html#_string_interpolation</a></p>
<h1 id="Gradle"><a href="#Gradle" class="headerlink" title="Gradle"></a>Gradle</h1><p>don’t see latest book,  please refer to official doc<br><a href="https://gradle.org/guides/" target="_blank" rel="noopener">https://gradle.org/guides/</a><br>Ant and Maven are also build tools, gradle wrapper, incremental builds.</p>
<ol>
<li>build by convention</li>
<li>Groovy DSL</li>
<li>supports dependencies</li>
<li>support mutli-project build</li>
<li>easily customizable</li>
</ol>
<p>To install Gradle, using <code>sdkman</code> tool.</p>
<p>有几个概念搞清楚:</p>
<ol>
<li>gradle wrapper -&gt; gradlew (version control)</li>
<li>build.gradle: syntax, plugin</li>
<li>gradle.properties</li>
<li>extract env variable </li>
</ol>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">apply <span class="string">plugin:</span> <span class="string">'java'</span></span><br><span class="line"></span><br><span class="line">task &#123;</span><br><span class="line">  doLast &#123;</span><br><span class="line">    <span class="comment">// groovy syntax</span></span><br><span class="line">    println <span class="string">"hello, gradle!"</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><p>using use/passowrd instead of ssh<br>need to setup personal access credential:<br><a href="https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line" target="_blank" rel="noopener">https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line</a></p>
<p>for example,  mypersonal access token<br><code>456f6facec85415b91588f581sfsdfssfe56c0</code><br>I can embed the user/cred to push command:<br><a href="https://stackoverflow.com/questions/29776439/username-and-password-in-command-for-git-push" target="_blank" rel="noopener">https://stackoverflow.com/questions/29776439/username-and-password-in-command-for-git-push</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git push <span class="string">'https://chengdol%40ibm.com:456f6facec85415b91588f58182dd1cfe27e56c0@github.ibm.com/repo/hello.git'</span></span><br></pre></td></tr></table></figure></p>
<p>use <code>%40</code> replace <code>@</code>.<br><code>github.ibm.com/repo/hello.git</code> is the url to your repo</p>
<p>[x] git tag, see my blog<br>[ ] <a href="https://cli.github.com/" target="_blank" rel="noopener">github CLI</a>: <code>gh</code>, very similar to <code>git</code> command, can make alias to it.</p>
<p>[ ] pluralsight git training in my channel<br>[ ] unfinished, <a href="https://app.pluralsight.com/course-player?clipId=ab0678e7-3784-4f9e-a118-d42fc36adf4d" target="_blank" rel="noopener">fork operation</a></p>
<p>[ ] <a href="https://googlepluralsight-run.qwiklabs.com/focuses/12920544?parent=lti_session" target="_blank" rel="noopener">gitlab on GKE lab</a></p>
<p>[ ] git commands more<br>git rewrite:<br><a href="https://jonhnnyweslley.net/blog/how-to-rewrite-git-urls-to-clone-faster-and-push-safer/" target="_blank" rel="noopener">https://jonhnnyweslley.net/blog/how-to-rewrite-git-urls-to-clone-faster-and-push-safer/</a><br><a href="https://paste.googleplex.com/6716960572178432" target="_blank" rel="noopener">https://paste.googleplex.com/6716960572178432</a></p>
<h2 id="deploy-keys"><a href="#deploy-keys" class="headerlink" title="deploy keys"></a>deploy keys</h2><p><a href="https://github.blog/2015-06-16-read-only-deploy-keys/" target="_blank" rel="noopener">https://github.blog/2015-06-16-read-only-deploy-keys/</a></p>
<h1 id="Gitbook"><a href="#Gitbook" class="headerlink" title="Gitbook"></a>Gitbook</h1><p><a href="https://www.gitbook.com/" target="_blank" rel="noopener">https://www.gitbook.com/</a><br>这个写东西还可以, but not free</p>
<h1 id="承上启下"><a href="#承上启下" class="headerlink" title="承上启下"></a>承上启下</h1><p>interpersonal skill, BQ<br><a href="https://mail.google.com/mail/u/1/#inbox/FMfcgxwHNMbchDhFLQBnSltwkxBJVLbX" target="_blank" rel="noopener">https://mail.google.com/mail/u/1/#inbox/FMfcgxwHNMbchDhFLQBnSltwkxBJVLbX</a></p>
<p>As an “intro” project, I would recommend deploying <code>Kubernetes using Terraform</code>. You can use any provider such as <code>GKE</code>, AKS or <code>EKS</code>.</p>
<p>Once the Terraform template is working, extend it to install some applications inside Kubernetes, such as <code>Vault, Elastic, Cassandra</code>, etc. using the <code>Helm and Helmfile</code>.</p>
<p>You may want to integrate the database applications inside Kubernetes with a <code>Vault instance such that they would use it for authentication backend</code>.</p>
<p>You can either build the Helm Charts yourself or use existing ones (perhaps you would want to modify them..)</p>
<p>Further, you can extend the application deployment to emit some metrics and setup monitoring using <code>Prometheus and Grafana</code>.</p>
<p>Once you are happy with the runtime stack, introduce some <code>CI/CD pipelines using Jenkins and/or Gitlab</code>.</p>
<p>现在能接触到的基础打好<br>k8s, docker, jenkins (groovy + gradle), ansible, helm<br>git -&gt; gitlab (with jenkins)</p>
<ul>
<li><p>常用工具:<br>vim<br>visual studio<br>bash (中文版教程可以), zsh</p>
</li>
<li><p>composing database layer:<br>cassandra<br>elasticsearch (monitoring + log system)<br>consul<br>vault</p>
</li>
<li><p>monitoring:<br>prometheus<br>grafana<br>kibana</p>
</li>
<li><p>others:<br>kafka<br>zookeeper<br>istio<br>golang<br>RabbitMQ<br>redis<br>Python</p>
</li>
</ul>
<p>load balancer: nginx, haproxy</p>
<ul>
<li>cloud 基本结构，应用，组件:<br>AWS, ok<br>GCP, ok<br>Azure</li>
</ul>
<p>我猜工作流程:<br>用terraform 构造k8s 环境 或其他， 用ansible增加或更改配置，然后在k8s中部署应用(prometheus + grafana and elk for logs)，最后集成CI/CD<br>development -&gt; QA/UAT - &gt; production</p>
<h2 id="understand"><a href="#understand" class="headerlink" title="understand"></a>understand</h2><p>如果不清楚这些则看不懂配置的含义, 要清楚各个cloud中resource的类型，配置，如何搭配:<br>instance, vpc, lb, dns, storage, routing, subnet, gateway</p>
<p>terraform -&gt; deploy k8s (EKS or GKS) -&gt; install vault, elasticsearch, cassandra by helm (need modify though)<br>-&gt;<br>Prometheus<br>Grafana<br>Kibana<br>-&gt;<br>CI/CD: jenkins + gitlab</p>
<p>把完全不知道是什么的快速过一遍。<br>先学terraform -&gt; elasticsearch -&gt; vault, cassandra -&gt; monitoring tools<br>packer -&gt; gitlab, tower -&gt; helmfile</p>
<h2 id="steps"><a href="#steps" class="headerlink" title="steps"></a>steps</h2><ol>
<li>terrform provision k8s on aws and gcp</li>
<li>k8s on fyre to test other components via helm</li>
<li>monitoring system: prometheus + grafana, deployed by operator</li>
<li>log system: elasticsearch, kibaba, logstash, beats</li>
</ol>
<p>实验: 在k8s中部署prometheus + elastic stack, by helm or yaml，监控系统状态</p>
<ol start="5">
<li>Hashicorp: consul, vault</li>
<li>cassandra</li>
</ol>
<p>实验: 在k8s中部署cassandra<br>实验: 在k8s中部署jenkins pipeline + gitlab</p>
]]></content>
      <categories>
        <category>InPorgress</category>
      </categories>
      <tags>
        <tag>inprogress</tag>
      </tags>
  </entry>
  <entry>
    <title>Consul Quick Start</title>
    <url>/2020/06/13/infra-consul/</url>
    <content><![CDATA[<h2 id="Lab-Environment-Setup"><a href="#Lab-Environment-Setup" class="headerlink" title="Lab Environment Setup"></a>Lab Environment Setup</h2><p>Consul is easy to install, just a executable binary, put it in <code>/usr/local/bin</code>:<br><a href="https://www.consul.io/downloads" target="_blank" rel="noopener">https://www.consul.io/downloads</a></p>
<p>我修改了一下课程的demo，做了一个consul lab cluster via Vagrant:<br><a href="https://github.com/chengdol/vagrant-consul" target="_blank" rel="noopener">https://github.com/chengdol/vagrant-consul</a></p>
<p>Glossary:<br><a href="https://github.com/chengdol/vagrant-consul/blob/master/glossary.md" target="_blank" rel="noopener">https://github.com/chengdol/vagrant-consul/blob/master/glossary.md</a></p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Consul web site:<br><a href="https://www.consul.io/" target="_blank" rel="noopener">https://www.consul.io/</a></p>
<p>Challenges in managing services:</p>
<ul>
<li>Service discovery</li>
<li>Failure Detection</li>
<li>Mutli-Data center</li>
<li>Service configuration</li>
</ul>
<p>一个应用服务架构中，一般有API tier增加灵活性，同时提供额外的服务，比如以下应用就可以直接拿来API使用:</p>
<ul>
<li><a href="https://www.mailgun.com/homepage/" target="_blank" rel="noopener">Mailgun</a></li>
<li><a href="https://stripe.com/" target="_blank" rel="noopener">Stripe</a></li>
<li><a href="https://www.loggly.com/" target="_blank" rel="noopener">Loggly</a></li>
<li><a href="https://www.datadoghq.com/" target="_blank" rel="noopener">Datadog</a></li>
</ul>
<p>Consul is <code>distributed</code>.</p>
<p>These services need to be discovered by each other. 对于越来越复杂的内部组织结构，比如很多internal load balancer, Consul can come and play, 比如提供内部的DNS服务, Service discovery.</p>
<p>Failure Dectection, Consul running lightweight Consul agent (server or client mode) on each of node in your environment. The agent will diagnose all services running locally.</p>
<p>Reacting configuration via key/value store, reflecting changes quickly in near real time. </p>
<p>Multi-Data center aware.</p>
<p>Consul vs Other softwares:<br><a href="https://www.consul.io/intro/vs" target="_blank" rel="noopener">https://www.consul.io/intro/vs</a><br>Especailly Consul vs Istio:<br><a href="https://www.consul.io/intro/vs/istio" target="_blank" rel="noopener">https://www.consul.io/intro/vs/istio</a></p>
<p>Consul UI online demo:<br><a href="https://demo.consul.io" target="_blank" rel="noopener">https://demo.consul.io</a></p>
<h2 id="Monitor-Nodes"><a href="#Monitor-Nodes" class="headerlink" title="Monitor Nodes"></a>Monitor Nodes</h2><p>在这一章的例子中提供了一个很好的建模思路！在vagrant virutal machine中安装docker，然后用container的方式运行一些服务(比如这里的Nginx web and HAProxy LB)，再expose这些端口(对machine iptables做了更改)，这样就避免了很多的virtual machine上的安装配置工作。</p>
<p>可以去Vagrant box catalog中找别人配置好的box 直接使用。</p>
<p>Start consul server agent:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -dev: development agent, server mode will be turned on this agent, for quick start</span></span><br><span class="line"><span class="comment">## in production, don't use -dev</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## -advertise: specify one ipv4 interface</span></span><br><span class="line"><span class="comment">## -client: specify client access ip, usually 0.0.0.0</span></span><br><span class="line">consul agent -dev -<span class="built_in">bind</span> 0.0.0.0 -advertise 172.20.20.31 -client 127.0.0.1</span><br><span class="line"></span><br><span class="line"><span class="comment">## log output</span></span><br><span class="line">==&gt; Starting Consul agent...</span><br><span class="line">           Version: <span class="string">'v1.8.0'</span></span><br><span class="line">           Node ID: <span class="string">'95b60a36-f350-8a2b-b1cb-54f7b79657dc'</span></span><br><span class="line">         Node name: <span class="string">'consul-server'</span></span><br><span class="line">        Datacenter: <span class="string">'dc1'</span> (Segment: <span class="string">'&lt;all&gt;'</span>)</span><br><span class="line">            Server: <span class="literal">true</span> (Bootstrap: <span class="literal">false</span>)</span><br><span class="line">       Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, gRPC: 8502, DNS: 8600)</span><br><span class="line">      Cluster Addr: 172.20.20.31 (LAN: 8301, WAN: 8302)</span><br><span class="line">           Encrypt: Gossip: <span class="literal">false</span>, TLS-Outgoing: <span class="literal">false</span>, TLS-Incoming: <span class="literal">false</span>, Auto-Encrypt-TLS: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">==&gt; Log data will now stream <span class="keyword">in</span> as it occurs:</span><br><span class="line">    ...</span><br><span class="line">    2020-06-19T23:59:25.729Z [INFO]  agent.server: New leader elected: payload=consul-server</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p>
<p>我改动了一下Vagrantfile， 我估计是routing table出了问题，在MacOS host上无法访问private network中的virtual machine via private IP:<br><a href="https://stackoverflow.com/questions/23497855/unable-to-connect-to-vagrant-private-network-from-host" target="_blank" rel="noopener">https://stackoverflow.com/questions/23497855/unable-to-connect-to-vagrant-private-network-from-host</a></p>
<p>于是我增加了一个VM <code>ui</code> 去显示consul 的UI with port forwarding, but still does not work, from the log the port 8500 is bound with 127.0.0.1:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Client Addr: [127.0.0.1] (HTTP: 8500, HTTPS: -1, gRPC: -1, DNS: 8600)</span><br><span class="line">Cluster Addr: 172.20.20.41 (LAN: 8301, WAN: 8302)</span><br></pre></td></tr></table></figure></p>
<p>首先，我想到了更改Client Addr 为 172.20.20.41，因为这是我在Vagrantfile中设置的private IP:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">consul agent -config-file /vagrant/ui.consul.json -advertise 172.20.20.41 -client 172.20.20.41</span><br></pre></td></tr></table></figure></p>
<p>但还是不行, 主机上<code>localhost:8500</code> 无法连接，当然为了确认<code>-client</code> flag的使用的正确性，用netstat查看一下是否端口在改interface上。后来我就想到应该是iptables的问题了，没有这个interface上的流量forward出去，那就改成<code>0.0.0.0</code>好了(specify “any IPv4 address at all”):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## /vagrant/ui.consul.json set ui is true</span></span><br><span class="line">consul agent -config-file /vagrant/ui.consul.json -advertise 172.20.20.41 -client 0.0.0.0</span><br><span class="line"></span><br><span class="line"><span class="comment">## output</span></span><br><span class="line">==&gt; Starting Consul agent...</span><br><span class="line">           Version: <span class="string">'v1.8.0'</span></span><br><span class="line">           Node ID: <span class="string">'10ccbe63-bef0-3cf6-b24b-e0a53bdef213'</span></span><br><span class="line">         Node name: <span class="string">'ui'</span></span><br><span class="line">        Datacenter: <span class="string">'dc1'</span> (Segment: <span class="string">''</span>)</span><br><span class="line">            Server: <span class="literal">false</span> (Bootstrap: <span class="literal">false</span>)</span><br><span class="line">       Client Addr: [0.0.0.0] (HTTP: 8500, HTTPS: -1, gRPC: -1, DNS: 8600)</span><br><span class="line">      Cluster Addr: 172.20.20.41 (LAN: 8301, WAN: 8302)</span><br><span class="line">           Encrypt: Gossip: <span class="literal">false</span>, TLS-Outgoing: <span class="literal">false</span>, TLS-Incoming: <span class="literal">false</span>, Auto-Encrypt-TLS: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">==&gt; Log data will now stream <span class="keyword">in</span> as it occurs:</span><br><span class="line">...</span><br><span class="line">==&gt; Consul agent running!</span><br><span class="line">...</span><br><span class="line">    2020-06-20T03:38:12.476Z [INFO]  agent: (LAN) joining: lan_addresses=[172.20.20.31]</span><br><span class="line">    2020-06-20T03:38:12.477Z [WARN]  agent.client.manager: No servers available</span><br><span class="line">    2020-06-20T03:38:12.477Z [ERROR] agent.anti_entropy: failed to sync remote state: error=<span class="string">"No known Consul servers"</span></span><br><span class="line">    2020-06-20T03:38:12.480Z [INFO]  agent.client.serf.lan: serf: EventMemberJoin: consul-server 172.20.20.31</span><br><span class="line">    2020-06-20T03:38:12.480Z [INFO]  agent: (LAN) joined: number_of_nodes=1</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>或者可以在config json中定义<code>client_addr</code>:<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"retry_join"</span>: [<span class="string">"172.20.20.31"</span>],</span><br><span class="line">  <span class="attr">"data_dir"</span>: <span class="string">"/tmp/consul"</span>,</span><br><span class="line">  <span class="attr">"client_addr"</span>: <span class="string">"0.0.0.0"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>虽然通过的ui virtual machine暴露的web，但是所有信息都来自consul server! 和k8s nodeport的模式类似。</p>
<p>Can access via HTTP API: <a href="https://www.consul.io/api-docs" target="_blank" rel="noopener">https://www.consul.io/api-docs</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http://localhost:8500/v1/catalog/nodes</span><br><span class="line"><span class="comment">## format readable</span></span><br><span class="line">http://localhost:8500/v1/catalog/nodes?pretty</span><br></pre></td></tr></table></figure></p>
<p>DNS query, go to <code>ui</code> node, when we run consul agent, the DNS port is 8600:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## query node</span></span><br><span class="line">dig @localhost -p 8600 consul-server.node.consul</span><br><span class="line"><span class="comment">## query service</span></span><br><span class="line">dig @localhost -p 8600 consul.service.consul</span><br><span class="line"><span class="comment">## query service record, will show you the server port, such as 8300</span></span><br><span class="line">dig @localhost -p 8600 consul.service.consul SRV</span><br></pre></td></tr></table></figure></p>
<p>The RPC Protocol is deprecated and support was removed in Consul <code>0.8</code>. Please use the <code>HTTP API</code>, which has support for all features of the RPC Protocol.</p>
<h3 id="Consul-Commands"><a href="#Consul-Commands" class="headerlink" title="Consul Commands"></a>Consul Commands</h3><p>这里提到了2个有用的commands, 本来是用RPC实现的，但现在改了:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## can specify target point</span></span><br><span class="line"><span class="comment">## provide debug info</span></span><br><span class="line">consul info [-http-addr=172.20.20.31:8500]</span><br><span class="line"><span class="comment">## get log message, 这样就可以在某一agent上查看任意其他的agent log了</span></span><br><span class="line">consul monitor [-http-addr=172.20.20.31:8500]</span><br></pre></td></tr></table></figure></p>
<p>Here <code>172.20.20.31</code> is consul server, you must start it by <code>-client 0.0.0.0</code>, otherwise the port is bound with loopback interface and cannot access.</p>
<p>Other commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## maintain node</span></span><br><span class="line"><span class="comment">## enable maintaince, service will not show in consul DNS</span></span><br><span class="line"><span class="comment">## -service: maintain for a specific service</span></span><br><span class="line">consul maint -<span class="built_in">enable</span> -reason <span class="string">"Because..."</span></span><br><span class="line">consul maint</span><br><span class="line">consul maint -<span class="built_in">disable</span></span><br><span class="line"><span class="comment">## validate config file</span></span><br><span class="line"><span class="comment">## the config file must complete! cannot separate to several parts!</span></span><br><span class="line">consul validate [config file]</span><br><span class="line"><span class="comment">## show members</span></span><br><span class="line">consul members</span><br><span class="line"><span class="comment">## similar to docker/k8s exec</span></span><br><span class="line">consul <span class="built_in">exec</span> uptime</span><br></pre></td></tr></table></figure></p>
<p>Note that <code>consul exec</code> is by default disabled:<br><a href="https://www.consul.io/docs/agent/options.html#disable_remote_exec" target="_blank" rel="noopener">https://www.consul.io/docs/agent/options.html#disable_remote_exec</a><br>这个命令挺危险，就相当于ssh到node执行command line. 比如在node上用的docker container提供服务，则可以exec到node <code>docker stop xxx</code>.</p>
<p>BTY, graceful exit the consul process will not cause warning or error in UI display. If you force kill it, the node will be marked as critical.</p>
<h2 id="Service-Discovery"><a href="#Service-Discovery" class="headerlink" title="Service Discovery"></a>Service Discovery</h2><p>One way to register service to consul is use <strong>Service definition:</strong><br><a href="https://www.consul.io/docs/agent/services" target="_blank" rel="noopener">https://www.consul.io/docs/agent/services</a><br>比如register LB service to consul，这样的好处就是前面提到了，consul会根据其他agent反馈的web nginx的情况及时修改HAProxy的config信息，更新配置, 接下来会看到:</p>
<p>Regsiter service does not mean the service is healthy, also need to do healthy check:<br>For example:<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"service"</span>: &#123;</span><br><span class="line">    <span class="attr">"name"</span>: <span class="string">"web"</span>,</span><br><span class="line">    <span class="attr">"port"</span>: <span class="number">8080</span>,</span><br><span class="line">    <span class="attr">"check"</span>: &#123;</span><br><span class="line">      <span class="attr">"http"</span>: <span class="string">"http://localhost:8080"</span>,</span><br><span class="line">      <span class="attr">"interval"</span>: <span class="string">"10s"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Then launch consul client agent, add one more service config file <code>web.service.json</code> for registration, for example, in <code>web1</code> node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">consul agent -config-file /vagrant/common.json \</span><br><span class="line">             -advertise 172.20.20.21 \</span><br><span class="line">             -config-file /vagrant/web.service.json</span><br></pre></td></tr></table></figure></p>
<p>Then check the consul UI, you will see the node is good but service is unhealthy because now there is no nginx running, so create nginx in <code>web1</code> node:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/vagrant/setup.web.sh</span><br></pre></td></tr></table></figure></p>
<p>Then refresh the web page, everything is good.</p>
<p>You can <code>dig</code> the web service from <code>ui</code> node, this is so called <strong>internal</strong> <code>service discovery</code>, not facing public. 这些数据对于LB来说可以用来direct traffic, 这就是Consul自带DNS的好处，没有什么额外的设置了，并且还提供了health check，就非常方便了. 并且public facing LB也在Consul中注册了，这样一旦LB goes down，就能被马上监测到。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dig @localhost -p 8600 web.service.consul SRV</span><br><span class="line"><span class="comment">## you will see exactly the number of web service running</span></span><br></pre></td></tr></table></figure></p>
<p>Except query DNS from <code>dig</code>, consul HTTP API also can do it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## services list</span></span><br><span class="line">curl http://localhost:8500/v1/catalog/services?pretty</span><br><span class="line"><span class="comment">## service web detail</span></span><br><span class="line">curl http://localhost:8500/v1/catalog/service/web?pretty</span><br><span class="line"><span class="comment">## health check</span></span><br><span class="line"><span class="comment">## see the Status field: passing or critical</span></span><br><span class="line">curl http://localhost:8500/v1/health/service/web?pretty</span><br></pre></td></tr></table></figure></p>
<p>前面用到了service definition去register service，这只是一种方法，还可以用HTTP API 注册.<br>这里还有一些自动注册的工具:<br><a href="https://www.consul.io/downloads_tools" target="_blank" rel="noopener">https://www.consul.io/downloads_tools</a></p>
<ul>
<li><a href="https://github.com/gliderlabs/registrator" target="_blank" rel="noopener">docker container registrator</a></li>
<li>consul aware app: using HTTP API</li>
</ul>
<h2 id="LB-Dynamic-Config"><a href="#LB-Dynamic-Config" class="headerlink" title="LB Dynamic Config"></a>LB Dynamic Config</h2><p>HAProxy: The Reliable, High Performance TCP/HTTP Load Balancer<br><a href="http://www.haproxy.org/" target="_blank" rel="noopener">http://www.haproxy.org/</a></p>
<p>HAProxy config file <code>haproxy.cfg</code> example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global</span><br><span class="line">    maxconn 4096</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    mode http</span><br><span class="line">    timeout connect 5s</span><br><span class="line">    timeout client 50s</span><br><span class="line">    timeout server 50s</span><br><span class="line"></span><br><span class="line">listen http-in</span><br><span class="line">    bind *:80</span><br><span class="line">    server web1 172.20.20.21:8080</span><br><span class="line">    server web2 172.20.20.22:8080</span><br></pre></td></tr></table></figure></p>
<p><code>8080</code> port is where nginx web service from, <code>bind *:80</code> is meant to expose port for health check, 意思是外界通过LB上的<code>80</code> 端口访问后台web servers, 这也就是为啥consul中LB的health check输出 居然是<code>welcome to Nginx!</code>，因为那是后台返回的页面. </p>
<p>In the demo, we run HAProxy container in <code>lb</code> machine. How to verify it is up and running?<br>In any machine:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dig @localhost -p 8600 lb.service.consul SRV</span><br><span class="line"><span class="comment">## the lb record will show</span></span><br></pre></td></tr></table></figure></p>
<p>Now let’s verify LB is actually working:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## try several times, LB will cycling through backend servers</span></span><br><span class="line"><span class="comment">## you will see different ip returned</span></span><br><span class="line">curl http://localhost/ip.html</span><br></pre></td></tr></table></figure></p>
<p>如果这时关掉一个web server，在HAProxy没有enable health check功能的情况下，仍然会把请求发往已经挂掉的server，则用户得到503 error. 这也是很多LB的问题，需要设置自身的health check。但如果用consul的DNS，由于各个server的health check已经集成进去了，consul会返回健康的server进行服务. So we can feed information to LB from consul dynamically.</p>
<h3 id="Consul-Template"><a href="#Consul-Template" class="headerlink" title="Consul Template"></a>Consul Template</h3><p>Consul template is go template format:<br><a href="https://github.com/hashicorp/consul-template" target="_blank" rel="noopener">https://github.com/hashicorp/consul-template</a><br>这个不仅仅用于config LB, any application with config file can utilize this tool!</p>
<p><strong>Workflow:</strong><br>consul template will listen changes from consul, as changes occur it will be pushed to the consul template daemon (run in <code>lb</code> machine). consul template daemon will generate HAProxy new config file from a template for HAProxy, then we tell docker to restart HAProxy (or HAProxy reload config).</p>
<p>This is the <code>haproxy.ctmpl</code> file<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global</span><br><span class="line">    maxconn 4096</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    mode http</span><br><span class="line">    timeout connect 5s</span><br><span class="line">    timeout client 50s</span><br><span class="line">    timeout server 50s</span><br><span class="line"></span><br><span class="line">listen http-in</span><br><span class="line">    bind *:80&#123;&#123;range service &quot;web&quot;&#125;&#125;</span><br><span class="line">    server &#123;&#123;.Node&#125;&#125; &#123;&#123;.Address&#125;&#125;:&#123;&#123;.Port&#125;&#125;&#123;&#123;end&#125;&#125;</span><br><span class="line"></span><br><span class="line">    stats enable</span><br><span class="line">    stats uri /haproxy</span><br><span class="line">    stats refresh 5s</span><br></pre></td></tr></table></figure></p>
<p>This part means in the web display HAProxy statistic report! 这个统计图挺直观的，但我这里由于route原因看不到, access from <code>http://&lt;Load balancer IP&gt;/haproxy</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stats enable</span><br><span class="line">stats uri /haproxy</span><br><span class="line">stats refresh 5s</span><br></pre></td></tr></table></figure></p>
<p>Next, install consul-template in <code>lb</code> machine, run some tests with template file:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## dry run</span></span><br><span class="line">consul-template -template /vagrant/provision/haproxy.ctmpl -dry</span><br></pre></td></tr></table></figure></p>
<p>At meanwhile, go to <code>web1</code> machine, run <code>docker stop/start web</code>, you will see the real time updates in output from consul-template command above.</p>
<p>Then, create consul-template template file <code>lb.consul-template.hcl</code>, used to tell consul-template how to do its job.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">consul-template -config /vagrant/provision/lb.consul-template.hcl</span><br><span class="line"><span class="comment">## you will see the haproxy.cfg is replaced by new one</span></span><br></pre></td></tr></table></figure></p>
<p>Then we can provision the daemon run in background in <code>lb</code> machine:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(consul-template -config /vagrant/provision/lb.consul-template.hcl &gt;/dev/null 2&gt;&amp;1)&amp;</span><br></pre></td></tr></table></figure></p>
<p>Open the consul UI, in terminal go to <code>web1</code> or <code>web2</code> machine, stop/start the docker, see the updates. Also in <code>lb</code> machine, run below command to see the LB still works good, it will not return the unhealthy server to you:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl http://localhost/ip.html</span><br></pre></td></tr></table></figure></p>
<h3 id="Other-tools"><a href="#Other-tools" class="headerlink" title="Other tools"></a>Other tools</h3><ul>
<li><p><a href="https://github.com/hashicorp/envconsul" target="_blank" rel="noopener">Envconsul</a><br>Envconsul provides a convenient way to launch a subprocess with environment variables populated from HashiCorp Consul and Vault.<br>前面提到了config file for process, here Envconsul set env variables for process and kick off for us.</p>
</li>
<li><p><a href="https://github.com/kelseyhightower/confd" target="_blank" rel="noopener">confd</a><br>confd is a lightweight configuration management tool</p>
</li>
<li><p><a href="https://github.com/fabiolb/fabio" target="_blank" rel="noopener">fabio</a><br>fabio is a fast, modern, zero-conf load balancing HTTP(S) and TCP router for deploying applications managed by consul</p>
</li>
</ul>
<h2 id="Reactive-Configuration"><a href="#Reactive-Configuration" class="headerlink" title="Reactive Configuration"></a>Reactive Configuration</h2><p>One of primary use case is to update app configuration. for example, when services changes inject the changes to consul key/value pairs and have it pushed into our application.</p>
<p>注意key/value不要用来当Database, it’s not intended for! 但是运作的方式几乎和<code>etcd</code>一样！<br><a href="https://etcd.io/" target="_blank" rel="noopener">https://etcd.io/</a></p>
<p>Go to Consul UI to add key/value pairs, create a folder path <code>/prod/portal/haproxy</code>, then create key/value pair in it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">maxconn 2048</span><br><span class="line">stats enable</span><br><span class="line">timeout-client 50s</span><br><span class="line">timeout-connect 5s</span><br><span class="line">timeout-server 50s</span><br></pre></td></tr></table></figure></p>
<p>SSH to <code>ui</code> node, let’s read the key/value stored:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list all pairs</span></span><br><span class="line">curl http://localhost:8500/v1/kv/?recurse<span class="string">'&amp;'</span>pretty</span><br><span class="line"></span><br><span class="line"><span class="comment">## add key/value via HTTP API</span></span><br><span class="line"><span class="comment">## /prod/portal/haproxy is path we created before</span></span><br><span class="line">curl -X PUT -d <span class="string">'50s'</span> http://localhost:8500/v1/kv/prod/portal/haproxy/timeout-server</span><br><span class="line"><span class="comment">## delete</span></span><br><span class="line">curl -X DELETE http://localhost:8500/v1/kv/prod/portal/haproxy/timeout-server</span><br><span class="line"><span class="comment">## get one</span></span><br><span class="line">curl -X GET http://localhost:8500/v1/kv/prod/portal/haproxy/timeout-server?pretty</span><br><span class="line">curl -X GET http://localhost:8500/v1/kv/prod/portal/haproxy/timeout-server?raw</span><br></pre></td></tr></table></figure></p>
<p>The API will return JSON data, you can use <code>jq</code> to parse it.</p>
<p>Update the LB config template <code>haproxy.ctmpl</code> as:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">global</span><br><span class="line">    maxconn &#123;&#123;key &quot;prod/portal/haproxy/maxconn&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">    mode http</span><br><span class="line">    timeout connect &#123;&#123;key &quot;prod/portal/haproxy/timeout-connect&quot;&#125;&#125;</span><br><span class="line">    timeout client &#123;&#123;key &quot;prod/portal/haproxy/timeout-client&quot;&#125;&#125;</span><br><span class="line">    timeout server &#123;&#123;key &quot;prod/portal/haproxy/timeout-server&quot;&#125;&#125;</span><br><span class="line"></span><br><span class="line">listen http-in</span><br><span class="line">    bind *:80&#123;&#123;range service &quot;web&quot;&#125;&#125;</span><br><span class="line">    server &#123;&#123;.Node&#125;&#125; &#123;&#123;.Address&#125;&#125;:&#123;&#123;.Port&#125;&#125;&#123;&#123;end&#125;&#125;</span><br><span class="line"></span><br><span class="line">    stats &#123;&#123;key &quot;prod/portal/haproxy/stats&quot;&#125;&#125;</span><br><span class="line">    stats uri /haproxy</span><br><span class="line">    stats refresh 5s</span><br></pre></td></tr></table></figure></p>
<p>Then make consul-template process reload without killing it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## HUP signal will make consul-tempalte reload</span></span><br><span class="line">killall -HUP consul-template</span><br></pre></td></tr></table></figure></p>
<p>Then you will see the <code>haproxy.cfg</code> file is regenerated!</p>
<p>来谈谈为什么这个key/value setting如此重要:<br>有时候实现并不知道具体设置参数，在production环境，你可能想real time更新参数，比如这里LB中<code>maxconn</code>，实际使用中可能由于machine CPU, memory等因素，不得不调小，你可以用consul maint或其他方式去调节, but that would be a pain and the change will take time to converge across the infrastructure.</p>
<p>Use Key/Value store is really a reactive confiuration!</p>
<h3 id="Blocking-query"><a href="#Blocking-query" class="headerlink" title="Blocking query"></a>Blocking query</h3><p><a href="https://www.consul.io/api-docs/features/blocking" target="_blank" rel="noopener">https://www.consul.io/api-docs/features/blocking</a></p>
<p>A blocking query is used to wait for a potential change using <code>long polling</code>. Not all endpoints support blocking, but each endpoint uniquely documents its support for blocking queries in the documentation.</p>
<p>Endpoints that support blocking queries return an HTTP header named <code>X-Consul-Index</code>. This is a unique identifier representing the current state of the requested resource.</p>
<p>Use <code>curl -v</code> to check HEADER info to see if it has <code>X-Consul-Index</code>.</p>
<p>这个功能可以用在比如自己的app long polling consul API, 去等待changes happen, reactive listen to changes of consul. 这比周期性的探测节省很多资源。for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -v http://localhost:8500/v1/kv/prod/portal/haproxy/stats?index=&lt;X-Consul-Index value <span class="keyword">in</span> header&gt;<span class="string">'&amp;'</span><span class="built_in">wait</span>=40s</span><br></pre></td></tr></table></figure></p>
<p>如果有change发生，每次<code>X-Consul-Index</code> value 都会变化.</p>
<h2 id="Health-Check"><a href="#Health-Check" class="headerlink" title="Health Check"></a>Health Check</h2><p>Gossip pool via <code>Serf</code> and Edge triggered updates, peer to peer.<br>Serf: <a href="https://www.serfdom.io/" target="_blank" rel="noopener">https://www.serfdom.io/</a> (在UI中每个node都有Serf health status)</p>
<p>If you kill and start the consul agent in one node, you will see the log something like:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">serf: EventMemberFailed ...</span><br><span class="line">serf: EventMemberJoin ...</span><br></pre></td></tr></table></figure></p>
<p>There are LAN gossip and WAN gossip.</p>
<p>Information disseminated:</p>
<ul>
<li>Membership (discovery, joining) - joining the cluster entails only knowing the address of one other node (not required to be a server)</li>
<li>Failure detection - affords distributed health checks, no need for centralized health checking</li>
<li>Event broadcast - i.e. leader elected, custom events</li>
</ul>
<h3 id="System-Level-Check"><a href="#System-Level-Check" class="headerlink" title="System-Level Check"></a>System-Level Check</h3><p>非常类似于K8s的 liveness probe.</p>
<p><a href="https://www.consul.io/docs/agent/checks.html" target="_blank" rel="noopener">https://www.consul.io/docs/agent/checks.html</a><br>One of the primary roles of the agent is management of <code>system-level</code> and <code>application-level</code> health checks. A health check is considered to be application-level if it is associated with a service. If not associated with a service, the check monitors the health of the entire node.</p>
<p>前面都是用到了service check, 这里增加check node status. For example, disk usage, memory usage, etc.</p>
<p>Update <code>common.json</code> config file, this config file will take effect on <code>lb</code> and <code>web</code> machines, 这部分配置在最近的新版本已经变化了:<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"retry_join"</span>: [</span><br><span class="line">    <span class="string">"172.20.20.31"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"data_dir"</span>: <span class="string">"/tmp/consul"</span>,</span><br><span class="line">  <span class="attr">"client_addr"</span>: <span class="string">"0.0.0.0"</span>,</span><br><span class="line">  <span class="attr">"enable_script_checks"</span>: <span class="literal">true</span>,</span><br><span class="line">  <span class="attr">"checks"</span>: [</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"id"</span>: <span class="string">"check_cpu_utilization"</span>,</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"CPU Utilization"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: [<span class="string">"/vagrant/provision/hc/cpu_utilization.sh"</span>],</span><br><span class="line">      <span class="attr">"interval"</span>: <span class="string">"10s"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"id"</span>: <span class="string">"check_mem_utilization"</span>,</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"MEM Utilization"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: [<span class="string">"/vagrant/provision/hc/mem_utilization.sh"</span>],</span><br><span class="line">      <span class="attr">"interval"</span>: <span class="string">"10s"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="attr">"id"</span>: <span class="string">"check_hdd_utilization"</span>,</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"HDD Utilization"</span>,</span><br><span class="line">      <span class="attr">"args"</span>: [<span class="string">"/vagrant/provision/hc/hdd_utilization.sh"</span>],</span><br><span class="line">      <span class="attr">"interval"</span>: <span class="string">"10s"</span></span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Let’s see the <code>mem_utilization.sh</code> file:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">AVAILABLE_RAM=`grep MemAvailable /proc/meminfo | awk <span class="string">'&#123;print $2&#125;'</span>`</span><br><span class="line">TOTAL_RAM=`grep MemTotal /proc/meminfo | awk <span class="string">'&#123;print $2&#125;'</span>`</span><br><span class="line">RAM_UTILIZATION=$(<span class="built_in">echo</span> <span class="string">"scale = 2; 100-<span class="variable">$AVAILABLE_RAM</span>/<span class="variable">$TOTAL_RAM</span>*100"</span> | bc)</span><br><span class="line">RAM_UTILIZATION=<span class="variable">$&#123;RAM_UTILIZATION%.*&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"RAM: <span class="variable">$&#123;RAM_UTILIZATION&#125;</span>%, <span class="variable">$&#123;AVAILABLE_RAM&#125;</span> available of <span class="variable">$&#123;TOTAL_RAM&#125;</span> total "</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (( <span class="variable">$RAM_UTILIZATION</span> &gt; 95 ));</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exit</span> 2</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (( <span class="variable">$RAM_UTILIZATION</span> &gt; 70 ));</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure></p>
<p>The system-level health check sections will be displayed in consul UI.<br>For stress test, install <code>stress</code> software in <code>web1</code> machine (in the demo code it is added):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install</span></span><br><span class="line">sudo apt-get install stress</span><br></pre></td></tr></table></figure></p>
<p>CPU stress test, then you will see in the consul UI the node is unhealthy and is cycled out from LB:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">stress -c 1</span><br></pre></td></tr></table></figure></p>
<p>Watching the consul UI for <code>web1</code>, you will see CPU check failed:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CPU: 100%</span><br><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">vagrant   3122 97.2  0.0   7312   100 pts/0    R+   21:26   0:14 stress -c 1</span><br><span class="line">root       822  1.4 10.7 578220 53828 ?        Ssl  21:19   0:06 /usr/bin/docker daemon --raw-logs</span><br><span class="line">vagrant   2121  0.6 11.1 785204 55636 ?        Sl   21:20   0:02 consul agent -config-file /vagrant/config/common.json -config-file /vagrant/config/web.service.json -advertise 172.20.20.21</span><br><span class="line">vagrant   3099  0.2  1.1  23012  5724 pts/0    Ss   21:26   0:00 -bash</span><br><span class="line">root         1  0.1  0.7  33604  3792 ?        Ss   21:19   0:00 /sbin/init</span><br></pre></td></tr></table></figure></p>
<p>Once it recover, node will itself back into the pool. 这个功能非常有用，可以提前预警可能会发生问题的node. 比如某个web server overloaded，检测出unhealthy，则会被LB 移出，待恢复后又会自动加进去！</p>
]]></content>
      <categories>
        <category>Infra</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>consul</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Deque</title>
    <url>/2020/04/11/java-deque/</url>
    <content><![CDATA[<p>关于Deque，之前我的总结是，如果要当作Stack使用，则stick to Stack methods，比如push, pop, peek。如果当作Queue使用，则stick to Queue method，比如add/offer, poll/remove, peek。在实现上，我一般使用的是ArrayDeque, a resizable double-ended array。</p>
<p>今天突然想到一个问题，用Deque实现的Queue或者Stack，在使用enhanced for loop的时候，Java是怎么知道元素弹出的正确顺序呢? 或者如果混用Queue和Stack的方法，peek会弹出什么结果？iterator会给出什么顺序的结果呢？</p>
<p>我们来看看ArrayDeque的源码:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> head;</span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> tail;</span><br></pre></td></tr></table></figure></p>
<p>这里有2个pointers, head和tail，当arraydeque是empty的时候，head和tail重叠。</p>
<p>对于push来说，移动的是head，head的值减1再使用，并且用的是modulus circularly decrement。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Pushes an element onto the stack represented by this deque.  In other</span></span><br><span class="line"><span class="comment">* words, inserts the element at the front of this deque.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* &lt;p&gt;This method is equivalent to &#123;<span class="doctag">@link</span> #addFirst&#125;.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> e the element to push</span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> NullPointerException if the specified element is null</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">push</span><span class="params">(E e)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    addFirst(e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Inserts the specified element at the front of this deque.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> e the element to add</span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> NullPointerException if the specified element is null</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addFirst</span><span class="params">(E e)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="keyword">final</span> Object[] es = elements;</span><br><span class="line">    es[head = dec(head, es.length)] = e;</span><br><span class="line">    <span class="keyword">if</span> (head == tail)</span><br><span class="line">        grow(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Circularly decrements i, mod modulus.</span></span><br><span class="line"><span class="comment">* Precondition and postcondition: 0 &lt;= i &lt; modulus.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">dec</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> modulus)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (--i &lt; <span class="number">0</span>) i = modulus - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>对于add/offer来说，tail的值用了再加1，并且用的是modulus circularl increment。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Inserts the specified element at the end of this deque.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* &lt;p&gt;This method is equivalent to &#123;<span class="doctag">@link</span> #addLast&#125;.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> e the element to add</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span> &#123;<span class="doctag">@code</span> true&#125; (as specified by &#123;<span class="doctag">@link</span> Collection#add&#125;)</span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> NullPointerException if the specified element is null</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    addLast(e);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Inserts the specified element at the end of this deque.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* &lt;p&gt;This method is equivalent to &#123;<span class="doctag">@link</span> #add&#125;.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> e the element to add</span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> NullPointerException if the specified element is null</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addLast</span><span class="params">(E e)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="keyword">final</span> Object[] es = elements;</span><br><span class="line">    es[tail] = e;</span><br><span class="line">    <span class="keyword">if</span> (head == (tail = inc(tail, es.length)))</span><br><span class="line">        grow(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Circularly increments i, mod modulus.</span></span><br><span class="line"><span class="comment">* Precondition and postcondition: 0 &lt;= i &lt; modulus.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">inc</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> modulus)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (++i &gt;= modulus) i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>peek总是从head pointer取值<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Retrieves, but does not remove, the head of the queue represented by</span></span><br><span class="line"><span class="comment">* this deque, or returns &#123;<span class="doctag">@code</span> null&#125; if this deque is empty.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* &lt;p&gt;This method is equivalent to &#123;<span class="doctag">@link</span> #peekFirst&#125;.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span> the head of the queue represented by this deque, or</span></span><br><span class="line"><span class="comment">*         &#123;<span class="doctag">@code</span> null&#125; if this deque is empty</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">peek</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> peekFirst();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>iterator总是从head pointer -&gt; tail pointer<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Returns an iterator over the elements in this deque.  The elements</span></span><br><span class="line"><span class="comment">* will be ordered from first (head) to last (tail).  This is the same</span></span><br><span class="line"><span class="comment">* order that elements would be dequeued (via successive calls to</span></span><br><span class="line"><span class="comment">* &#123;<span class="doctag">@link</span> #remove&#125; or popped (via successive calls to &#123;<span class="doctag">@link</span> #pop&#125;).</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span> an iterator over the elements in this deque</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Iterator&lt;E&gt; <span class="title">iterator</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> DeqIterator();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>所以现在情形就很清楚了，来看一个例子。首先按照顺序push [1 2 3], 这时peek是3，然后再add/offer [4 5 6], 这时peek还是3，然后iterator的结果是: [3 2 1 4 5 6]<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Deque&lt;Integer&gt; dq = <span class="keyword">new</span> ArrayDeque&lt;&gt;();</span><br><span class="line">dq.push(<span class="number">1</span>);</span><br><span class="line">dq.push(<span class="number">2</span>);</span><br><span class="line">dq.push(<span class="number">3</span>);</span><br><span class="line"><span class="comment">// now peek is 3</span></span><br><span class="line">dq.add(<span class="number">4</span>);</span><br><span class="line">dq.add(<span class="number">5</span>);</span><br><span class="line">dq.add(<span class="number">6</span>);</span><br><span class="line"><span class="comment">// now peek is still 3</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> ele: dq)</span><br><span class="line">&#123;</span><br><span class="line">    System.out.println(ele);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 3 2 1 4 5 6</span></span><br></pre></td></tr></table></figure></p>
<p><img src="https://drive.google.com/uc?id=1KaVUCoUDu-3o7_hqEyCwKyDEstJc-9_z" alt=""></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java equals Method</title>
    <url>/2019/11/03/java-overwrite-equals/</url>
    <content><![CDATA[<p>This is the first Java post in my blog, actually I have lots of summaries about Java in recently years, they just get accumulated so I decide to post here.</p>
<p>Also, start from next week, I will dive into API work.</p>
<p>When you define a new class and it will deal with hash thing, don’t forget to overwrite the <code>equals</code> method, or <code>compare</code> method if they need to be sorted in natural order, or implement <code>Comparator</code> interface for ordering by other rules.</p>
<p>For example:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Complex</span> </span>&#123; </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">double</span> re, im; </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Complex</span><span class="params">(<span class="keyword">double</span> re, <span class="keyword">double</span> im)</span> </span>&#123; </span><br><span class="line">        <span class="keyword">this</span>.re = re; </span><br><span class="line">        <span class="keyword">this</span>.im = im; </span><br><span class="line">    &#125; </span><br><span class="line">    <span class="comment">// Overriding equals() to compare two Complex objects </span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123; </span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123; <span class="keyword">return</span> <span class="keyword">false</span>; &#125;</span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">this</span>) &#123; <span class="keyword">return</span> <span class="keyword">true</span>; &#125; </span><br><span class="line">        <span class="keyword">if</span> (!(o <span class="keyword">instanceof</span> Complex)) &#123; <span class="keyword">return</span> <span class="keyword">false</span>; &#125; </span><br><span class="line">        Complex c = (Complex) o; </span><br><span class="line">        <span class="comment">// Compare the data members and return accordingly  </span></span><br><span class="line">        <span class="keyword">return</span> Double.compare(re, c.re) == <span class="number">0</span></span><br><span class="line">                &amp;&amp; Double.compare(im, c.im) == <span class="number">0</span>; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><a href="https://stackoverflow.com/questions/16970210/java-treeset-remove-and-contains-not-working" target="_blank" rel="noopener">https://stackoverflow.com/questions/16970210/java-treeset-remove-and-contains-not-working</a></p>
<p>One thing I want to emphasize is <code>TreeSet</code>, the object in tree set use its compareTo (or compare) method, so two elements that are deemed equal by this method are, from the standpoint of the set, equal. The behavior of a set is well-defined even if its ordering is inconsistent with equals; it just fails to obey the general contract of the Set interface.</p>
<p>To be more accurate, <code>TreeSet</code> is an implementation of <code>SortedSet</code><br>If you want a <code>.equals()/.hashCode()</code> compatible set, use, for instance, a HashSet.</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Vault Quick Start</title>
    <url>/2020/06/21/infra-vault/</url>
    <content><![CDATA[<p>Course git repo, this repo has useful Vault commands:<br><a href="https://github.com/ned1313/Getting-Started-Vault" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Vault</a></p>
<p>My Vault vagrant demo:<br><a href="https://github.com/chengdol/InfraTree/tree/master/vagrant-vault" target="_blank" rel="noopener">https://github.com/chengdol/InfraTree/tree/master/vagrant-vault</a></p>
<h1 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h1><p><a href="https://www.reddit.com/r/devops/comments/ejfzhl/kubernetes_secrets_vs_hashicorp_vault/" target="_blank" rel="noopener">Vault vs K8s secrets?</a><br>Examples of what Vault can do that k8s secrets cannot:<br>With Vault you can rotate secrets and have secrets with short TTL<br>With Vault you can access secrets across namespaces (or outside the k8s cluster)<br>Vault can provide a PKI for signing certs (enabling for example automation of cert generation for mtls)<br>Vault can use LDAP, oauth, IAM, etc as identity providers</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Vault web site:<br><a href="https://www.vaultproject.io/" target="_blank" rel="noopener">https://www.vaultproject.io/</a></p>
<p>Secure, store and tightly control access to tokens, passwords, certificates, encryption keys for protecting secrets and other sensitive data using a UI, CLI, or HTTP API.<br>注意API的path，并不是和UI上的path一样！</p>
<p>Vault works well with Consul, for example, set Consul as storage backend.</p>
<p>Start a Vault server:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## same as consul in development mode, don't use this in production!</span></span><br><span class="line"><span class="comment">## 0.0.0.0:8200, used for vagrant port fordwarding access from host</span></span><br><span class="line">vault server -dev-listen-address 0.0.0.0:8200 -dev</span><br></pre></td></tr></table></figure></p>
<p>Output as below:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">WARNING! dev mode is enabled! In this mode, Vault runs entirely in-memory</span><br><span class="line">and starts unsealed with a single unseal key. The root token is already</span><br><span class="line">authenticated to the CLI, so you can immediately begin using Vault.</span><br><span class="line"></span><br><span class="line">You may need to set the following environment variable:</span><br><span class="line"></span><br><span class="line">    $ export VAULT_ADDR=&apos;http://0.0.0.0:8200&apos;</span><br><span class="line"></span><br><span class="line">The unseal key and root token are displayed below in case you want to</span><br><span class="line">seal/unseal the Vault or re-authenticate.</span><br><span class="line"></span><br><span class="line">## these two are critical</span><br><span class="line">Unseal Key: pLNBmZQRHvspdy5unZcTjm1jOVQ81Z0pO6ywYHNP1zQ=</span><br><span class="line">Root Token: s.hfnmMkgG7cggWDOmPfHC1jIe</span><br><span class="line"></span><br><span class="line">Development mode should NOT be used in production installations!</span><br></pre></td></tr></table></figure></p>
<p><code>unseal</code> key在production mode中用来解除对Vault server的封锁，否则无法login as root.</p>
<p>注意，这里VAULT_ADDR是本地的，vault server当然可以在其他地方，设置对应的地址即可.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Vault API access</span></span><br><span class="line"><span class="built_in">export</span> VAULT_ADDR=<span class="string">'http://0.0.0.0:8200'</span></span><br><span class="line"><span class="built_in">export</span> VAULT_TOKEN=s.ttlDcetbJe3uLt0FF5rSidg3</span><br><span class="line"></span><br><span class="line"><span class="comment">## login to vault server need VAULT_TOKEN to login</span></span><br><span class="line">vault login</span><br></pre></td></tr></table></figure></p>
<p>Vault web UI access: <code>http://localhost:8200</code></p>
<p>So, just like Consul, there are 3 ways to interact with Vault server: UI, API, CLI (actually running API under the hood). </p>
<p><code>secret</code> is a pre-existing secret engine folder in Vault storage path, you can see it in UI:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Write a secret</span></span><br><span class="line">vault kv put secret/hg2g answer=42</span><br><span class="line"><span class="comment">#For Linux</span></span><br><span class="line"><span class="comment"># marvin.json is a json file</span></span><br><span class="line">curl --header <span class="string">"X-Vault-Token: <span class="variable">$VAULT_TOKEN</span>"</span> --request POST \</span><br><span class="line"> --data @marvin.json <span class="variable">$VAULT_ADDR</span>/v1/secret/data/marvin</span><br></pre></td></tr></table></figure></p>
<p>marvin.json is as follow:<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"data"</span>: &#123;</span><br><span class="line">        <span class="attr">"paranoid"</span>: <span class="literal">true</span>,</span><br><span class="line">        <span class="attr">"status"</span>: <span class="string">"bored"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Get a secret</span></span><br><span class="line">vault kv get secret/hg2g</span><br><span class="line"><span class="comment">#specify format</span></span><br><span class="line">vault kv get -format=json secret/hg2g</span><br><span class="line">vault kv get -format=yaml secret/hg2g</span><br><span class="line"><span class="comment">#For Linux</span></span><br><span class="line"><span class="comment">#Install jq if necessary</span></span><br><span class="line">sudo yum install jq -y</span><br><span class="line">curl --header <span class="string">"X-Vault-Token: <span class="variable">$VAULT_TOKEN</span>"</span> <span class="variable">$VAULT_ADDR</span>/v1/secret/data/marvin | jq</span><br><span class="line"></span><br><span class="line"><span class="comment">#Put a new secret in and a new value for an existing secret</span></span><br><span class="line">vault kv put secret/hg2g answer=54 ford=prefect</span><br><span class="line">vault kv get secret/hg2g</span><br><span class="line"></span><br><span class="line"><span class="comment">#Delete the secrets</span></span><br><span class="line">vault kv delete secret/hg2g</span><br><span class="line">vault kv get secret/hg2g</span><br><span class="line"></span><br><span class="line"><span class="comment">#For Linux</span></span><br><span class="line">curl --header <span class="string">"X-Vault-Token: <span class="variable">$VAULT_TOKEN</span>"</span> --request DELETE <span class="variable">$VAULT_ADDR</span>/v1/secret/data/marvin</span><br></pre></td></tr></table></figure>
<h1 id="Working-with-Secrets"><a href="#Working-with-Secrets" class="headerlink" title="Working with Secrets"></a>Working with Secrets</h1><p>Secret lifecycle:</p>
<ul>
<li>Create</li>
<li>Read</li>
<li>Update</li>
<li>Delete (soft or hard unrecoverable)</li>
<li>Destroy</li>
</ul>
<p>There is version <code>1</code> and version <code>2</code> of <code>secret engine server</code>, version <code>2</code> is more recoverable and versioning but less performance then version <code>1</code> if you need to scale. <code>secret</code> folder 就是默认创建的secret engine, version <code>2</code>, 可以去UI 查看configuration.</p>
<p>Demo code about secrets lifecycle:<br><a href="https://github.com/ned1313/Getting-Started-Vault/blob/master/m3/m3-secretslifecycle.sh" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Vault/blob/master/m3/m3-secretslifecycle.sh</a></p>
<p>Everytime you update the key, the version increment by 1:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## pick value by version</span></span><br><span class="line">vault kv get -version=3 secret/hg2g</span><br><span class="line"><span class="comment">## from API</span></span><br><span class="line">curl -X GET --header <span class="string">"X-Vault-Token: <span class="variable">$VAULT_TOKEN</span>"</span> <span class="variable">$VAULT_ADDR</span>/v1/secret/data/hg2g?version=3 | jq .data.data</span><br></pre></td></tr></table></figure></p>
<p>If you delete version 3, you still can get version 1 or 2:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vault kv delete secret/hg2g</span><br><span class="line">vault kv get -version=2 secret/hg2g</span><br><span class="line"><span class="comment">## undelete version 3</span></span><br><span class="line"><span class="comment">## -versions not -version, you can undelete multiple: -versions=2,3</span></span><br><span class="line">vault kv undelete -versions=3 secret/hg2g</span><br><span class="line"></span><br><span class="line"><span class="comment">## API</span></span><br><span class="line"><span class="comment">#For Linux</span></span><br><span class="line">curl --header <span class="string">"X-Vault-Token: <span class="variable">$VAULT_TOKEN</span>"</span> --request POST \</span><br><span class="line">  <span class="variable">$VAULT_ADDR</span>/v1/secret/undelete/hg2g  --data <span class="string">'&#123;"versions": [2]&#125;'</span></span><br></pre></td></tr></table></figure></p>
<p>Destroy, can no longer undelete:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Destroy the secrets</span></span><br><span class="line">vault kv destroy -versions=1,2 secret/hg2g</span><br><span class="line"></span><br><span class="line"><span class="comment">#For Linux</span></span><br><span class="line"><span class="comment">## metadata is still there</span></span><br><span class="line">curl --header <span class="string">"X-Vault-Token: <span class="variable">$VAULT_TOKEN</span>"</span> --request POST \</span><br><span class="line">  <span class="variable">$VAULT_ADDR</span>/v1/secret/destroy/hg2g --data <span class="string">'&#123;"versions": [1,2]&#125;'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#Remove all data about secrets</span></span><br><span class="line">vault kv metadata delete secret/hg2g</span><br><span class="line">vault kv get secret/hg2g</span><br><span class="line"></span><br><span class="line"><span class="comment">#For Linux</span></span><br><span class="line">curl --header <span class="string">"X-Vault-Token: <span class="variable">$VAULT_TOKEN</span>"</span> --request DELETE \</span><br><span class="line">  <span class="variable">$VAULT_ADDR</span>/v1/secret/metadata/hg2g</span><br></pre></td></tr></table></figure></p>
<h2 id="Create-New-Secret-Engine"><a href="#Create-New-Secret-Engine" class="headerlink" title="Create New Secret Engine"></a>Create New Secret Engine</h2><p>Demo about secret engine, 我这里就不贴出来了, 如果用API，还有一些配置用的json文件，见这个的上层目录中的比如<code>dev-b.json</code>:<br><a href="https://github.com/ned1313/Getting-Started-Vault/blob/master/m3/m3-secretengine.sh" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Vault/blob/master/m3/m3-secretengine.sh</a></p>
<h2 id="Create-Mysql-DB-Secret-Engine"><a href="#Create-Mysql-DB-Secret-Engine" class="headerlink" title="Create Mysql DB Secret Engine"></a>Create Mysql DB Secret Engine</h2><p>Vault official reference:<br><a href="https://www.vaultproject.io/docs/secrets" target="_blank" rel="noopener">https://www.vaultproject.io/docs/secrets</a></p>
<p>Vault在这里类似一个中间层，在user 和 Mysql instance之间，保存和传递credential和请求. 这个demo在AZure上spin up了一个bitnami Mysql instance，和本地的vault mysql secret engine关联，然后通过Vault联系Mysql 产生一个dynamic user，并授予这个临时user权限，我们通过这个临时user就可以操作Mysql 数据库了。</p>
<p>这个dynamic user lifecycle also managed by Vault, as well as the permission the user has.<br><a href="https://github.com/ned1313/Getting-Started-Vault/blob/master/m3/m3-mysqlengine.sh" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Vault/blob/master/m3/m3-mysqlengine.sh</a></p>
<p>Besides Mysql example, Vault secrets can be used for certificates, for SSH credentials, etc.<br>Secrets engine make Vault extensible, there are different plugin to handle different needs.</p>
<h1 id="Controlling-Access"><a href="#Controlling-Access" class="headerlink" title="Controlling Access"></a>Controlling Access</h1><p>Similar to RBAC in K8s, authentication method to control login, policies to control what is able to do, managing client tokens.</p>
<h2 id="Vault-Auth-Method"><a href="#Vault-Auth-Method" class="headerlink" title="Vault Auth Method"></a>Vault Auth Method</h2><p>Vault has internal authentication (called <code>userpass</code>) and support external, multiple authrntication methods.<br><a href="https://github.com/ned1313/Getting-Started-Vault/blob/master/m4/m4-basicauth.sh" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Vault/blob/master/m4/m4-basicauth.sh</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list current auth methods</span></span><br><span class="line"><span class="comment">## by default, we only have token auth method</span></span><br><span class="line">vault auth list</span><br><span class="line"><span class="comment">## enable new auth method</span></span><br><span class="line">vault auth <span class="built_in">enable</span> userpass</span><br><span class="line"><span class="comment">## create user</span></span><br><span class="line">vault write auth/userpass/users/arthur password=dent</span><br><span class="line"><span class="comment">## list user</span></span><br><span class="line">vault list auth/userpass/users</span><br></pre></td></tr></table></figure>
<p>You will see the changes in UI <code>Access</code> section.</p>
<p>Once you create a user/password, then you can run for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 这里使用的是user/password login，不是用token</span></span><br><span class="line">vault login -method=userpass username=arthur</span><br><span class="line"><span class="comment">## then input password</span></span><br><span class="line">Password (will be hidden): </span><br><span class="line"><span class="comment">## 这个warning是因为，做实验的时候之前export了root token</span></span><br><span class="line">WARNING! The VAULT_TOKEN environment variable is <span class="built_in">set</span>! This takes precedence</span><br><span class="line">over the value <span class="built_in">set</span> by this <span class="built_in">command</span>. To use the value <span class="built_in">set</span> by this <span class="built_in">command</span>,</span><br><span class="line"><span class="built_in">unset</span> the VAULT_TOKEN environment variable or <span class="built_in">set</span> it to the token displayed</span><br><span class="line">below.</span><br><span class="line"></span><br><span class="line">Success! You are now authenticated. The token information displayed below</span><br><span class="line">is already stored <span class="keyword">in</span> the token helper. You <span class="keyword">do</span> NOT need to run <span class="string">"vault login"</span></span><br><span class="line">again. Future Vault requests will automatically use this token.</span><br><span class="line"></span><br><span class="line">Key                    Value</span><br><span class="line">---                    -----</span><br><span class="line">token                  s.z52FGzn78XynKlxeS0Akt0t7</span><br><span class="line">token_accessor         90LaRNNtsCUEg6yDd9ldRi3v</span><br><span class="line">token_duration         768h</span><br><span class="line">token_renewable        <span class="literal">true</span></span><br><span class="line">token_policies         [<span class="string">"default"</span>]</span><br><span class="line">identity_policies      []</span><br><span class="line">policies               [<span class="string">"default"</span>]</span><br><span class="line">token_meta_username    arthur</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## will show you where is the token from, not root token any more</span></span><br><span class="line"><span class="comment">## see `path` field where is the token from</span></span><br><span class="line">vault token lookup</span><br></pre></td></tr></table></figure></p>
<p>Token represents who you are and what you can do, for example, the user itself cannot update its password via its token:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## update password</span></span><br><span class="line">vault write auth/userpass/users/arthur/password password=tricia</span><br><span class="line"><span class="comment">## output</span></span><br><span class="line">Error writing data to auth/userpass/users/arthur/password: Error making API request.</span><br><span class="line"></span><br><span class="line">URL: PUT http://0.0.0.0:8200/v1/auth/userpass/users/arthur/password</span><br><span class="line">Code: 403. Errors:</span><br><span class="line"></span><br><span class="line">* 1 error occurred:</span><br><span class="line">	* permission denied</span><br></pre></td></tr></table></figure></p>
<p>Can do this after export root token.</p>
<p>Delete auth:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#Remove account</span></span><br><span class="line">vault delete auth/userpass/users/arthur</span><br></pre></td></tr></table></figure></p>
<p>这里介绍了2个新概念: <code>LDAP</code> and <code>Active Directory</code><br><a href="https://stackoverflow.com/questions/663402/what-are-the-differences-between-ldap-and-active-directory" target="_blank" rel="noopener">What are the differences between LDAP and Active Directory?</a><br>Active Directory is a database based system that provides authentication, directory, policy, and other services in a Windows environment</p>
<p>LDAP (Lightweight Directory Access Protocol) is an application protocol for querying and modifying items in directory service providers like Active Directory, which supports a form of LDAP.</p>
<p>Short answer: AD is a directory services database, and LDAP is one of the protocols you can use to talk to it.</p>
<p>见下面vault policy章节的例子.<br>Case: 在外部设置了<code>AD</code> as authentication method, enable <code>LDAP</code> auth in Vault. Then user login Vault with AD credentials against LDAP talk to AD, AD talk to Vault and determine the policy about what the user can do, then user will get the right token from vault to access the store.</p>
<h2 id="Vault-Policy"><a href="#Vault-Policy" class="headerlink" title="Vault Policy"></a>Vault Policy</h2><p>Similar to K8s role.<br><a href="https://github.com/ned1313/Getting-Started-Vault/blob/master/m4/m4-activedirectory.sh" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Vault/blob/master/m4/m4-activedirectory.sh</a></p>
<p>这个例子，远程登录了一个Vault server, login as root, create <code>devkv</code> store with key and value pair, then create policy <code>dev</code> with HCL file for user to access the <code>devkv</code>. </p>
<p>Enable LDAP auth, configure it with Active Directory remotely. Then assign the <code>developers</code> group in LDAP with <code>dev</code> policy.</p>
<p>Then user <code>adent</code> login vault against <code>ldap</code> method. The user is in the <code>developers</code> group so it will get token with permission specified by <code>dev</code> policy.</p>
<h2 id="Client-Token"><a href="#Client-Token" class="headerlink" title="Client Token"></a>Client Token</h2><p><a href="https://www.vaultproject.io/docs/concepts/tokens" target="_blank" rel="noopener">https://www.vaultproject.io/docs/concepts/tokens</a></p>
<h2 id="Wrapping-Response"><a href="#Wrapping-Response" class="headerlink" title="Wrapping Response"></a>Wrapping Response</h2><p><a href="https://github.com/ned1313/Getting-Started-Vault/blob/master/m4/m4-tokenwrapping.sh" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Vault/blob/master/m4/m4-tokenwrapping.sh</a></p>
<h1 id="Operating-Vaule-Server"><a href="#Operating-Vaule-Server" class="headerlink" title="Operating Vaule Server"></a>Operating Vaule Server</h1><p>主要讲了production Vault server setup.</p>
<ul>
<li>Vault server architecture</li>
<li>Storage backend options</li>
<li>Vault server operations</li>
</ul>
<p>这里例子用Consul作为 storage backend(不是说it’s not intended for this吗😂), 在Vault 主机上运行有Consul agent 和 远处的Consul server通信 (gossip tcp: 8301, RPC tcp: 8300) ，Consul server可以有多个以实现HA。Vault通过本地的Consul agent port 8500和其交互，外界访问Vault 用默认的port 8200:<br><a href="https://github.com/ned1313/Getting-Started-Vault/tree/master/m5" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Vault/tree/master/m5</a></p>
<p>可以留意一下这里的Consul配置，之前用的一直是dev mode，这里是production mode了, 把Consul 包装成了一个service, run as daemon, in <code>consul</code> folder:</p>
<ul>
<li>consul-deploy.sh</li>
<li>consul.hcl</li>
<li>server.hcl</li>
<li>consul.service</li>
</ul>
<p>注意把 <code>.hcl</code> and <code>.service</code> 文件内容paste到 <code>consul-deploy.sh</code> 创建的文件中。script中的<code>useradd</code> command也值得借鉴。<code>consul keygen</code> 是用来产生encrypt string的，用在server 和 client的 <code>.hcl</code>中。</p>
<p>Consul agent setup:</p>
<ul>
<li>consul-deploy-agent.sh</li>
<li>consul-agent.hcl</li>
</ul>
<p>好了，这里引出一个有意思的东西: <strong>Create Custom Systemd Service</strong>，之前从来没有这么做过，原来systemd是可以自己配置的！<br><a href="https://medium.com/@benmorel/creating-a-linux-service-with-systemd-611b5c8b91d6" target="_blank" rel="noopener">https://medium.com/@benmorel/creating-a-linux-service-with-systemd-611b5c8b91d6</a></p>
<p>Vault server Config, also set Vault as systemd service, in <code>vault</code> folder:</p>
<ul>
<li>vault-deploy.sh</li>
<li>vault.hcl</li>
<li>vault.service</li>
</ul>
<p>在 <code>.hcl</code> 中就配置了Consul 为storage backend，看上去本来就有这种特性，所以不需要过多的设置。</p>
<h2 id="Server-Operations"><a href="#Server-Operations" class="headerlink" title="Server Operations"></a>Server Operations</h2><p>Operator command:<br><a href="https://www.vaultproject.io/docs/commands/operator" target="_blank" rel="noopener">https://www.vaultproject.io/docs/commands/operator</a></p>
<p>Setup production Vault server, sealed and need to unseal:<br><a href="https://github.com/ned1313/Getting-Started-Vault/blob/master/m5/m5-serveroperations.sh" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Vault/blob/master/m5/m5-serveroperations.sh</a></p>
<h1 id="Auditing"><a href="#Auditing" class="headerlink" title="Auditing"></a>Auditing</h1><p>Everything is audited, sensitive data is hashed unless you explicitly set false.<br><a href="https://github.com/ned1313/Getting-Started-Vault/tree/master/m6" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Vault/tree/master/m6</a></p>
<p>Auditing device type:</p>
<ul>
<li>File, JSON format</li>
<li>Syslog</li>
<li>Socket: TCP/UDP</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## enable auditing device</span></span><br><span class="line">vault audit <span class="built_in">enable</span> [<span class="built_in">type</span>] [-path=valut_path]</span><br><span class="line"><span class="comment">## log_raw=true means no encrypt sensitive data</span></span><br><span class="line">vault audit <span class="built_in">enable</span> file file_path=/var/<span class="built_in">log</span>/vault/vault_audit.log log_raw=<span class="literal">true</span></span><br><span class="line">vault audit <span class="built_in">enable</span> -path=file2 file file_path=/var/<span class="built_in">log</span>/vault/vault_audit2.log</span><br><span class="line">vault audit <span class="built_in">enable</span> syslog tag=<span class="string">"vault"</span> facility=<span class="string">"LOCAL7"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## disable</span></span><br><span class="line">vault audit <span class="built_in">disable</span> [vault_path]</span><br><span class="line"><span class="comment">## disable file2 created above</span></span><br><span class="line">vault audit <span class="built_in">disable</span> file2</span><br><span class="line"><span class="comment">## list</span></span><br><span class="line">vault audit list -detailed</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Infra</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>vault</tag>
      </tags>
  </entry>
  <entry>
    <title>Java LinkedList</title>
    <url>/2019/11/07/java-linkedlist/</url>
    <content><![CDATA[<p>About LinkedList operation time complexity:</p>
<p>Adding to either end of a linked list does not require a traversal, as long as you keep a reference to both ends of the list. This is what Java does for its <code>add</code> and <code>addFirst</code>/<code>addLast</code> methods.</p>
<p>Same goes for parameterless <code>remove</code> and <code>removeFirst</code>/<code>removeLast</code> methods - they operate on list ends.</p>
<p><code>remove(int)</code> and <code>remove(Object)</code> operations, on the other hand, are not O(1). They requires traversal, so their costs are O(n).</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Commands Alias</title>
    <url>/2019/06/15/k8s-alias/</url>
    <content><![CDATA[<p>It’s very tedious to type full command when you operate on K8s cluster, this blog is the summary of alias I adopt in daily work.</p>
<p>Put these alias to <code>$HOME/.bashrc</code>, then source it or next time when you login they will take effect.</p>
<p>Some qucik commands used to create resources:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## --type default is ClusterIP</span></span><br><span class="line"><span class="comment">## --target-port default is --port</span></span><br><span class="line">kubectl expose pod &lt;podname&gt; [--<span class="built_in">type</span>=NodePort] --port=80 [--target-port=80] --name=&lt;svcname&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## run command in pod</span></span><br><span class="line">kubectl <span class="built_in">exec</span> -n &lt;namespace&gt; &lt;podname&gt; -- bash -c <span class="string">"commands"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## check log</span></span><br><span class="line">kubectl logs -f &lt;pod name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## scale up/down</span></span><br><span class="line">kubectl scale deploy &lt;deploy name&gt; --replicas=5</span><br></pre></td></tr></table></figure></p>
<p>These are some alias used to run test:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## exit will delete the pod automatically</span></span><br><span class="line"><span class="comment">## --restart=Never means create a pod instead of deployment</span></span><br><span class="line"><span class="comment">## praqma/network-multitool: network tools image</span></span><br><span class="line"><span class="built_in">alias</span> kbt=<span class="string">'kubectl run testpod -it --rm --restart=Never --image=praqma/network-multitool -- /bin/sh'</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## docker shortcut</span></span><br><span class="line"><span class="built_in">alias</span> di=<span class="string">'docker images'</span></span><br><span class="line"><span class="built_in">alias</span> dp=<span class="string">'docker ps -a'</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">alias</span> kbc=<span class="string">'kubectl'</span></span><br><span class="line"><span class="built_in">alias</span> kbn=<span class="string">'kubectl get nodes'</span></span><br><span class="line"><span class="comment">## can replace with your working namespace</span></span><br><span class="line"><span class="comment">## pods</span></span><br><span class="line"><span class="built_in">alias</span> kbp=<span class="string">'kubectl get pods --all-namespaces'</span></span><br><span class="line"><span class="comment">## deployments</span></span><br><span class="line"><span class="built_in">alias</span> kbd=<span class="string">'kubectl get deploy -n zen | grep -E "xmeta|services"'</span></span><br><span class="line"><span class="comment">## statefulsets</span></span><br><span class="line"><span class="built_in">alias</span> kbsts=<span class="string">'kubectl get sts -n zen | grep -E "conductor|compute"'</span></span><br><span class="line"><span class="comment">## services</span></span><br><span class="line"><span class="built_in">alias</span> kbs=<span class="string">'kubectl get svc -n test-1'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## get into pods</span></span><br><span class="line">kbl()</span><br><span class="line">&#123;</span><br><span class="line">  pod=<span class="variable">$1</span></span><br><span class="line">  <span class="comment">## get namepace</span></span><br><span class="line">  ns=$(kubectl get pod --all-namespaces | grep <span class="variable">$pod</span> | awk &#123;<span class="string">'print $1'</span>&#125;)</span><br><span class="line">  kubectl <span class="built_in">exec</span> -it <span class="variable">$pod</span> sh -n <span class="variable">$ns</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">### for fixed pod name</span></span><br><span class="line"><span class="built_in">alias</span> gocond=<span class="string">'kubectl exec -it is-en-conductor-0 bash -n test-1'</span></span><br><span class="line"><span class="built_in">alias</span> gocomp0=<span class="string">'kubectl exec -it is-engine-compute-0 bash -n test-1'</span></span><br><span class="line"><span class="comment">### for dynamic pod name</span></span><br><span class="line">goxmeta()</span><br><span class="line">&#123;</span><br><span class="line">  isxmetadockerpod=`kubectl get pods --field-selector=status.phase=Running -n <span class="built_in">test</span>-1 | grep is-xmetadocker-pod | awk &#123;<span class="string">'print $1'</span>&#125;`</span><br><span class="line">  kubectl <span class="built_in">exec</span> -it <span class="variable">$&#123;isxmetadockerpod&#125;</span> bash -n <span class="built_in">test</span>-1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gosvc()</span><br><span class="line">&#123;</span><br><span class="line">  isservicesdockerpod=`kubectl get pods --field-selector=status.phase=Running -n <span class="built_in">test</span>-1 | grep is-servicesdocker-pod | awk &#123;<span class="string">'print $1'</span>&#125;`</span><br><span class="line">  kubectl <span class="built_in">exec</span> -it <span class="variable">$&#123;isservicesdockerpod&#125;</span> bash -n <span class="built_in">test</span>-1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## clean pods</span></span><br><span class="line"><span class="built_in">alias</span> rmxmeta=<span class="string">'kubectl delete svc is-xmetadocker -n test-1; kubectl delete deploy is-xmetadocker-pod -n test-1; rm -rf /mnt/IIS_test-1/Repository/*'</span></span><br><span class="line"><span class="built_in">alias</span> rmsvc=<span class="string">'kubectl delete svc is-servicesdocker -n test-1; kubectl delete deploy is-servicesdocker-pod -n test-1; rm -rf /mnt/IIS_test-1/Services/*'</span></span><br><span class="line"><span class="built_in">alias</span> rmcond=<span class="string">'kubectl delete svc is-en-conductor-0 -n test-1; kubectl delete svc en-cond -n test-1; kubectl delete statefulset is-en-conductor -n test-1; rm -rf /mnt/IIS_test-1/Engine/test-1/is-en-conductor-0/'</span></span><br><span class="line"><span class="built_in">alias</span> rmcomp=<span class="string">'kbc delete svc conductor-0 -n test-1; kbc delete statefulset is-engine-compute -n test-1; rm -rf /mnt/IIS_test-1/Engine/test-1/is-engine-compute*'</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes API curl Access</title>
    <url>/2019/11/06/k8s-api/</url>
    <content><![CDATA[<p>In the situation that issue k8s instructions from inside the container, usually we use <code>curl</code> command to do that (if you have kubectl binary in container’s execution path, you can use kubectl command as well).</p>
<p>First you need credentials and api server information:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## MY_POD_NAMESPACE</span></span><br><span class="line">NAMESPACE=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)</span><br><span class="line">K8S=https://<span class="variable">$KUBERNETES_SERVICE_HOST</span>:<span class="variable">$KUBERNETES_SERVICE_PORT</span></span><br><span class="line">CACERT=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)</span><br></pre></td></tr></table></figure></p>
<p>You can get these all from environment variables, when create the pod, k8s has already injected these information into the containers.</p>
<p>Of course, if the service account you use does not have full privilege, the API access is limited.</p>
<p>then for example, get the detail of current pod:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POD_NAME=<span class="string">"<span class="variable">$MY_POD_NAME</span>"</span></span><br><span class="line">NS=<span class="string">"<span class="variable">$MY_POD_NAMESPACE</span>"</span></span><br><span class="line">OUT_FILE=$(mktemp /tmp/pod-schedule.XXXX)</span><br><span class="line"></span><br><span class="line"><span class="comment">## http_code is the return status code</span></span><br><span class="line">http_code=$(curl -w  <span class="string">"%&#123;http_code&#125;"</span> -sS  --cacert <span class="variable">$CACERT</span>  -H <span class="string">"Content-Type: application/json"</span> -H <span class="string">"Accept: application/json, */*"</span> -H <span class="string">"Authorization: Bearer <span class="variable">$TOKEN</span>"</span> <span class="string">"<span class="variable">$K8S</span>/api/v1/namespaces/<span class="variable">$NS</span>/pods/<span class="variable">$POD_NAME</span>"</span> -o <span class="variable">$OUT_FILE</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$http_code</span> -ne 200 ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"&#123;\"result\": \"Failure\", \"httpReturnCode\":<span class="variable">$http_code</span>&#125;"</span> |<span class="variable">$&#123;JQ&#125;</span> <span class="string">'.'</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">image=$(cat <span class="variable">$OUT_FILE</span> |jq <span class="string">'.spec.containers[] | select(.name=="xxx") | .image'</span>)</span><br></pre></td></tr></table></figure></p>
<p>How do I know the curl path to request?<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod -v 10</span><br></pre></td></tr></table></figure></p>
<p>this will show you verbose message (curl under the hood), then you can get the path and use it in your curl command.</p>
<p>Not all kubectl commands are clearly with curl, for example <code>kubectl exec</code>, still need some efforts to know.</p>
<p>references:<br><a href="https://blog.openshift.com/executing-commands-in-pods-using-k8s-api/" target="_blank" rel="noopener">https://blog.openshift.com/executing-commands-in-pods-using-k8s-api/</a><br><a href="https://docs.okd.io/latest/rest_api/api/v1.Pod.html#Post-api-v1-namespaces-namespace-pods-name-exec" target="_blank" rel="noopener">https://docs.okd.io/latest/rest_api/api/v1.Pod.html#Post-api-v1-namespaces-namespace-pods-name-exec</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Exception</title>
    <url>/2020/04/11/java-exception/</url>
    <content><![CDATA[<p>Reference: <a href="https://docs.oracle.com/javase/tutorial/essential/exceptions/definition.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/tutorial/essential/exceptions/definition.html</a></p>
<p>Code that fails to honor the Catch or Specify Requirement will not compile.</p>
<p>Not all exceptions are subject to the Catch or Specify Requirement. To understand why, we need to look at the three basic categories of exceptions, only one of which is subject to the Requirement.</p>
<h2 id="The-Three-Kinds-of-Exceptions"><a href="#The-Three-Kinds-of-Exceptions" class="headerlink" title="The Three Kinds of Exceptions"></a>The Three Kinds of Exceptions</h2><p>The first kind of exception is the <code>checked exception</code>.</p>
<p>Checked exceptions are subject to the <code>Catch or Specify Requirement</code>. <strong>All</strong> exceptions are checked exceptions, except for those indicated by Error, RuntimeException, and their subclasses.</p>
<p>The second kind of exception is the <code>error</code>. These are exceptional conditions that are external to the application, and that the application usually cannot anticipate or recover from.<br>Errors are not subject to the Catch or Specify Requirement. Errors are those exceptions indicated by Error and its subclasses.</p>
<p>The third kind of exception is the <code>runtime exception</code>.<br>Runtime exceptions are not subject to the Catch or Specify Requirement. Runtime exceptions are those indicated by RuntimeException and its subclasses.</p>
<p>Errors and runtime exceptions are collectively known as <code>unchecked exceptions</code>.</p>
<blockquote>
<p>unchecked exception 也可以被catch，只要match就行，也可以被throws, but we don’t have to do that: <a href="https://stackoverflow.com/questions/8104407/cant-java-unchecked-exceptions-be-handled-using-try-catch-block" target="_blank" rel="noopener">https://stackoverflow.com/questions/8104407/cant-java-unchecked-exceptions-be-handled-using-try-catch-block</a></p>
</blockquote>
<p><a href="https://crunchify.com/better-understanding-on-checked-vs-unchecked-exceptions-how-to-handle-exception-better-way-in-java/" target="_blank" rel="noopener">Better Understanding on Checked Vs. Unchecked Exceptions</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// code that could throw an exception</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// check in order</span></span><br><span class="line"><span class="keyword">catch</span> (IOException | SQLException ex)</span><br><span class="line">&#123;</span><br><span class="line">    logger.log(ex);</span><br><span class="line">    <span class="keyword">throw</span> ex;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span> (IndexOutOfBoundsException e) </span><br><span class="line">&#123;</span><br><span class="line">    System.err.println(<span class="string">"IndexOutOfBoundsException: "</span> + e.getMessage());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// The finally block always executes when the try block exits.</span></span><br><span class="line"><span class="keyword">finally</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (out != <span class="keyword">null</span>) &#123; </span><br><span class="line">        System.out.println(<span class="string">"Closing PrintWriter"</span>);</span><br><span class="line">        out.close(); </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">        System.out.println(<span class="string">"PrintWriter not open"</span>);</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>finally</code> block it allows the programmer to avoid having cleanup code accidentally bypassed by a return, continue, or break. Putting cleanup code in a finally block is always a good practice, even when no exceptions are anticipated.</p>
<p>The <code>try-with-resources</code> statement ensures that each resource is closed at the end of the statement. Any object that implements <code>java.lang.AutoCloseable</code>, which includes all objects which implement <code>java.io.Closeable</code>, can be used as a resource.<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> String <span class="title">readFirstLineFromFile</span><span class="params">(String path)</span> <span class="keyword">throws</span> IOException </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">try</span> (BufferedReader br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(path))) </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// try block</span></span><br><span class="line">        <span class="keyword">return</span> br.readLine();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: A try-with-resources statement can have catch and finally blocks just like an ordinary try statement. In a try-with-resources statement, any catch or finally block is run <strong>after</strong> the resources declared have been closed.</p>
</blockquote>
<h2 id="Throw-exception"><a href="#Throw-exception" class="headerlink" title="Throw exception"></a>Throw exception</h2><p>declare throws exception for method<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeList</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;&#125;</span><br></pre></td></tr></table></figure></p>
<p>throw an exception<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (size == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> EmptyStackException();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Create custom exception: <a href="https://www.baeldung.com/java-new-custom-exception" target="_blank" rel="noopener">https://www.baeldung.com/java-new-custom-exception</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// create custom exception</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IncorrectFileNameException</span> <span class="keyword">extends</span> <span class="title">Exception</span> </span>&#123; </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">IncorrectFileNameException</span><span class="params">(String errorMessage)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(errorMessage);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Dashboard</title>
    <url>/2019/09/15/k8s-dashboard/</url>
    <content><![CDATA[<p>//TODO:<br>[ ] how to setup dashboard can be accessed from outside of the cluster<br>[ ] cert things?<br>[ ] user admission, for example: cluster admin vs regular user<br>[ ] authenticate method: token or kubeconfig</p>
<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Dashboard relies on Metrics Server or Heapster to sample and provide running parameters of the cluster.<br><a href="https://github.com/kubernetes/dashboard" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard</a></p>
<p>Metrics server:<br><a href="https://github.com/kubernetes-incubator/metrics-server" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/metrics-server</a><br>other tools:<br><a href="https://blog.containership.io/kubernetes-metrics-collection-options/" target="_blank" rel="noopener">https://blog.containership.io/kubernetes-metrics-collection-options/</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Calico Bandwidth Explore</title>
    <url>/2019/07/30/k8s-calico-bandwidth/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>I have talked about setting up pod network in Kubernetes cluster using <code>Calico</code> network add-on in this post <a href="https://chengdol.github.io/2018/12/17/k8s-kubeadm-setup/" target="_blank" rel="noopener"><code>&lt;&lt;Set Up K8s Cluster by Kubeadm&gt;&gt;</code></a>. Recently I was involved in one issue from performance team, they complained that the network has bottleneck in calico, let’s see what happened and learn new things!</p>
<h2 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h2><p>The performance team set up a 6 nodes cluster with 1 master and 5 workers. Each machine has 48 cpu cores, 128GB memory, 2T+ disk and 10000Mb/s network speed.</p>
<p>These are the test cases:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">10</span> <span class="string">jobs</span> <span class="string">for</span> <span class="string">each</span> <span class="string">user(8</span> <span class="string">small</span> <span class="string">jobs,</span> <span class="number">1</span> <span class="string">middle</span> <span class="string">job</span> <span class="string">and</span> <span class="number">1</span> <span class="string">large</span> <span class="string">job)</span></span><br><span class="line"></span><br><span class="line"><span class="number">8</span> <span class="string">small</span> <span class="string">jobs(RowGen</span> <span class="bullet">-&gt;</span> <span class="string">XX</span> <span class="bullet">-&gt;</span> <span class="string">Peek),</span> <span class="number">1</span> <span class="string">job</span> <span class="string">unit</span></span><br><span class="line"><span class="string">aggregate</span> <span class="string">job</span>                         <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">filter</span> <span class="string">job</span>                            <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">funnel_continuous</span>                     <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">funnel</span> <span class="string">sort</span>                           <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">join</span> <span class="string">job</span>                              <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">lookup</span>                                <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">sort</span> <span class="string">job</span>                              <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">Transformation</span>                        <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="string">middle</span> <span class="string">job,</span> <span class="number">2</span> <span class="string">job</span> <span class="string">units</span></span><br><span class="line"><span class="string">Middle_Job</span>                            <span class="bullet">--</span> <span class="number">50</span> <span class="string">million</span> <span class="string">records(nearly</span> <span class="number">11</span><span class="string">G)</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="string">Large</span> <span class="string">job,</span> <span class="number">3</span> <span class="string">job</span> <span class="string">units</span></span><br><span class="line"><span class="string">Large</span> <span class="string">job</span>                             <span class="bullet">--</span> <span class="number">10</span> <span class="string">million</span> <span class="string">records(nearly</span> <span class="number">2.1</span><span class="string">GB)</span></span><br></pre></td></tr></table></figure></p>
<p>They ran concurrent users with N compute pods and found that the bottleneck is in calico network:<br><img src="https://drive.google.com/uc?id=1FMc1eRf_FCG2TI1TRWeLLKE2GJ6qysBf" alt=""></p>
<p>BTY, there are still enough resources(CPU, Memory and Disk I/O) to support DataStage scale up for DS concurrent users to run jobs on nodes and pods. But the network bandwidth between pods is not enough to support it.</p>
<h2 id="iperf3-Command"><a href="#iperf3-Command" class="headerlink" title="iperf3 Command"></a>iperf3 Command</h2><p>They use <code>iperf3</code>, a TCP, UDP, and SCTP network bandwidth measurement tool, measure memory-to-memory performance access a network. Github <a href="https://github.com/esnet/iperf/blob/master/README.md" target="_blank" rel="noopener">link</a></p>
<p>The <a href="https://fasterdata.es.net/performance-testing/network-troubleshooting-tools/iperf/" target="_blank" rel="noopener">Usage</a> is simple, <code>wget</code> one version tar ball from release page, untar and build it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./configure; make; make install</span><br></pre></td></tr></table></figure></p>
<p>The <code>iperf3</code> will be added to exectution <code>PATH</code> automatically.</p>
<p>More simple <a href="https://datapacket.com/blog/10gbps-network-bandwidth-test-iperf-tutorial/" target="_blank" rel="noopener">demos</a></p>
<h3 id="Node-to-Node"><a href="#Node-to-Node" class="headerlink" title="Node to Node"></a>Node to Node</h3><p>in one node, set up server on default port 5201<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iperf3 -s</span><br></pre></td></tr></table></figure></p>
<p>in another node, set up client and run test:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iperf3 -c &lt;server IP&gt; -P &lt;parallel number&gt;</span><br></pre></td></tr></table></figure></p>
<p>more specific, this will transfer /large_file in client to /large_file in server, time interval is 40 seconds<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## server</span></span><br><span class="line">iperf3 -s -F /large_file</span><br><span class="line"><span class="comment">## client</span></span><br><span class="line">iperf3 -c &lt;server ip&gt; -i 1 -t 40 -F /large_file</span><br></pre></td></tr></table></figure></p>
<h3 id="Pod-to-Pod"><a href="#Pod-to-Pod" class="headerlink" title="Pod to Pod"></a>Pod to Pod</h3><p>The same as <code>Node to Node</code>, but wget and build <code>iperf3</code> inside pod container and use the container’s IP (in container run <code>hostname -I</code>), for example, I flood data from <code>is-en-conductor-0</code> pod to <code>is-engine-compute-12</code> pod, they reside in different host machine.<br><img src="https://drive.google.com/uc?id=1WPt2oBzL0bvq1_vCzF9eUqZXiwNfNzOX" alt=""><br><img src="https://drive.google.com/uc?id=1Y8nbhUAR0BBbdEcFeNqSG9g2xk8UjyEo" alt=""></p>
<h2 id="Thinking"><a href="#Thinking" class="headerlink" title="Thinking"></a>Thinking</h2><p>After I reproducing the tests, I was thinking <code>Calico</code> is a widely used add-on that shouldn’t have such obvious bottleneck, otherwise many people will complain and improve it.</p>
<p>Is there any improper configuration?</p>
<ul>
<li><p>Configuring IP-in-IP<br>By default, the manifests enable <code>IP-in-IP</code> encapsulation across subnets (additional overhead compare to non <code>IP-in-IP</code>), if don’t need it (when? I am not very clear), disable it in calico manifest yaml file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Enable IPIP</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">CALICO_IPV4POOL_IPIP</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">"off"</span></span><br></pre></td></tr></table></figure>
<p>See this <a href="https://github.com/projectcalico/calico/issues/922" target="_blank" rel="noopener"><code>IP-in-IP</code> issue</a><br>I am using <code>Calico</code> version 3.3, <a href="https://docs.projectcalico.org/v3.3/usage/configuration/ip-in-ip" target="_blank" rel="noopener">document</a> about <code>IP-in-IP</code></p>
</li>
<li><p>Which Network Interface is Used<br>Another question I have is which network interface is used for <code>node-to-node</code> and <code>pod-to-pod</code> test?</p>
<p>There are several network interfaces in host machine, one is for public IP with <code>MTU 9000</code> and in K8s we use private IP interface with <code>MTU 1500</code>. This will have impact on <code>iperf3</code> testing.</p>
<p>It shows that <code>pod-to-pod</code> test uses <code>MTU 1500</code> but <code>node-to-node</code> uses <code>MTU 9000</code>.</p>
<p>Need to test after enlarging MTU size to see if that change improves network throughput, also remember to update <code>Calico</code> manifest yaml, refer this <a href="https://docs.projectcalico.org/v3.3/usage/configuration/mtu" target="_blank" rel="noopener">document</a></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Configure the MTU to use</span></span><br><span class="line"><span class="attr">veth_mtu:</span> <span class="string">"9000"</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="ethtool-Command"><a href="#ethtool-Command" class="headerlink" title="ethtool Command"></a>ethtool Command</h2><p>The <code>ethtool</code> can display speed property of the network interface, for example:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ethtool eno1</span></span><br><span class="line"></span><br><span class="line"><span class="string">Settings</span> <span class="string">for</span> <span class="attr">eno1:</span></span><br><span class="line">        <span class="string">Supported</span> <span class="attr">ports:</span> <span class="string">[</span> <span class="string">TP</span> <span class="string">]</span></span><br><span class="line">        <span class="string">Supported</span> <span class="string">link</span> <span class="attr">modes:</span>   <span class="number">10</span><span class="string">baseT/Half</span> <span class="number">10</span><span class="string">baseT/Full</span></span><br><span class="line">                                <span class="number">100</span><span class="string">baseT/Half</span> <span class="number">100</span><span class="string">baseT/Full</span></span><br><span class="line">                                <span class="number">1000</span><span class="string">baseT/Half</span> <span class="number">1000</span><span class="string">baseT/Full</span></span><br><span class="line">        <span class="string">Supported</span> <span class="string">pause</span> <span class="string">frame</span> <span class="attr">use:</span> <span class="literal">No</span></span><br><span class="line">        <span class="string">Supports</span> <span class="attr">auto-negotiation:</span> <span class="literal">Yes</span></span><br><span class="line">        <span class="string">Supported</span> <span class="string">FEC</span> <span class="attr">modes:</span> <span class="string">Not</span> <span class="string">reported</span></span><br><span class="line">        <span class="string">Advertised</span> <span class="string">link</span> <span class="attr">modes:</span>  <span class="number">10</span><span class="string">baseT/Half</span> <span class="number">10</span><span class="string">baseT/Full</span></span><br><span class="line">                                <span class="number">100</span><span class="string">baseT/Half</span> <span class="number">100</span><span class="string">baseT/Full</span></span><br><span class="line">                                <span class="number">1000</span><span class="string">baseT/Half</span> <span class="number">1000</span><span class="string">baseT/Full</span></span><br><span class="line">        <span class="string">Advertised</span> <span class="string">pause</span> <span class="string">frame</span> <span class="attr">use:</span> <span class="string">Symmetric</span></span><br><span class="line">        <span class="string">Advertised</span> <span class="attr">auto-negotiation:</span> <span class="literal">Yes</span></span><br><span class="line">        <span class="string">Advertised</span> <span class="string">FEC</span> <span class="attr">modes:</span> <span class="string">Not</span> <span class="string">reported</span></span><br><span class="line">        <span class="string">Link</span> <span class="string">partner</span> <span class="string">advertised</span> <span class="string">link</span> <span class="attr">modes:</span>  <span class="number">10</span><span class="string">baseT/Full</span></span><br><span class="line">                                             <span class="number">100</span><span class="string">baseT/Full</span></span><br><span class="line">                                             <span class="number">1000</span><span class="string">baseT/Full</span></span><br><span class="line">        <span class="string">Link</span> <span class="string">partner</span> <span class="string">advertised</span> <span class="string">pause</span> <span class="string">frame</span> <span class="attr">use:</span> <span class="string">Transmit-only</span></span><br><span class="line">        <span class="string">Link</span> <span class="string">partner</span> <span class="string">advertised</span> <span class="attr">auto-negotiation:</span> <span class="literal">Yes</span></span><br><span class="line">        <span class="string">Link</span> <span class="string">partner</span> <span class="string">advertised</span> <span class="string">FEC</span> <span class="attr">modes:</span> <span class="string">Not</span> <span class="string">reported</span></span><br><span class="line"><span class="attr">        Speed:</span> <span class="number">1000</span><span class="string">Mb/s</span></span><br><span class="line"><span class="attr">        Duplex:</span> <span class="string">Full</span></span><br><span class="line"><span class="attr">        Port:</span> <span class="string">Twisted</span> <span class="string">Pair</span></span><br><span class="line"><span class="attr">        PHYAD:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">        Transceiver:</span> <span class="string">internal</span></span><br><span class="line"><span class="attr">        Auto-negotiation:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">        MDI-X:</span> <span class="string">on</span></span><br><span class="line">        <span class="string">Supports</span> <span class="attr">Wake-on:</span> <span class="string">g</span></span><br><span class="line"><span class="attr">        Wake-on:</span> <span class="string">d</span></span><br><span class="line">        <span class="string">Current</span> <span class="string">message</span> <span class="attr">level:</span> <span class="number">0x000000ff</span> <span class="string">(255)</span></span><br><span class="line">                               <span class="string">drv</span> <span class="string">probe</span> <span class="string">link</span> <span class="string">timer</span> <span class="string">ifdown</span> <span class="string">ifup</span> <span class="string">rx_err</span> <span class="string">tx_err</span></span><br><span class="line">        <span class="string">Link</span> <span class="attr">detected:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure></p>
<p>The output depends on the what the network driver can provide, you may get nothing if the <strong>virtual machine</strong> does not have much data available (for example, in IBM softlayer cluster), refer to this <a href="https://serverfault.com/questions/447939/why-is-ethtool-not-showing-me-all-the-properties-for-a-nic" target="_blank" rel="noopener">question</a> </p>
<p>In a virtual machine the link speed or duplex mode is usually meaningless, as the network interface is most often just a <strong>virtual link</strong> to the host system, with no actual physical Ethernet layer. The speed is as high as the CPU and memory can handle (or as low, as the connection rate limit is configured), cabling type does no exist, as there is no cable, etc. This virtual interface is bridged or routed to the actual physical network by the host system and only on the host system the physical port parameters can be obtained.</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ol>
<li>Performance test big picture</li>
<li>iperf3, node-to-node, pod-to-pod tests</li>
<li>ethtool</li>
<li>Calico configutation: IP-in-IP, MTU</li>
<li>calicoctl, haven’t got time to learn</li>
</ol>
<h2 id="Other-Blogs"><a href="#Other-Blogs" class="headerlink" title="Other Blogs"></a>Other Blogs</h2><p><a href="https://www.jianshu.com/p/cfc4e62ff3ea" target="_blank" rel="noopener">k8s calico flannel cilium 网络性能测试</a><br><a href="https://itnext.io/benchmark-results-of-kubernetes-network-plugins-cni-over-10gbit-s-network-36475925a560" target="_blank" rel="noopener">Benchmark results of Kubernetes network plugins (CNI) over 10Gbit/s network</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>calico</tag>
      </tags>
  </entry>
  <entry>
    <title>Container Command and Args</title>
    <url>/2019/09/10/k8s-cmd-args-format/</url>
    <content><![CDATA[<p>The format of <code>command</code> and <code>args</code> syntax in kubernetes yaml really make me crazy, when the entrypoint has long or multiple arguments, can be wrote in multiple lines instead of one line for better view:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">  container:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">["/bin/bash",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"--"</span><span class="string">]</span></span><br><span class="line"><span class="attr">    args:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">echo</span> <span class="string">"start"</span><span class="string">;</span></span><br><span class="line">      <span class="string">while</span> <span class="literal">true</span><span class="string">;</span> <span class="string">do</span></span><br><span class="line">        <span class="string">echo</span> <span class="string">$(hostname)</span> <span class="string">$(date)</span> <span class="string">&gt;&gt;</span> <span class="string">/html/index.html;</span></span><br><span class="line">        <span class="string">sleep</span> <span class="number">10</span><span class="string">;</span></span><br><span class="line">      <span class="string">done;</span></span><br><span class="line">      <span class="string">echo</span> <span class="string">"done!"</span><span class="string">;</span></span><br></pre></td></tr></table></figure></p>
<p>Another format:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">myapp-container</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">["/bin/bash",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"--"</span><span class="string">]</span></span><br><span class="line"><span class="attr">    args:</span></span><br><span class="line">       <span class="string">["echo</span> <span class="string">\"check</span> <span class="string">something...\";</span></span><br><span class="line">        <span class="string">if</span> <span class="string">[[</span> <span class="string">!</span> <span class="bullet">-f</span> <span class="string">/root/.link</span> <span class="string">]];</span> <span class="string">then</span></span><br><span class="line">          <span class="string">echo</span> <span class="string">\"file</span> <span class="string">does</span> <span class="string">not</span> <span class="string">exist!\";</span></span><br><span class="line">          <span class="string">echo</span> <span class="string">\"no!\";</span></span><br><span class="line">        <span class="string">else</span></span><br><span class="line">          <span class="string">echo</span> <span class="string">\"file</span> <span class="string">is</span> <span class="string">there!\";</span></span><br><span class="line">        <span class="string">fi;</span></span><br><span class="line">        <span class="string">echo</span> <span class="string">\"done!\""]</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that the format is error-prone, every command should end with <code>;</code>, for example the <code>while</code> and <code>if</code> above. I separate them into several lines for good looking, but they actually are one line command.</p>
</blockquote>
<p>For one command with multiple options or parameters, can be described as below, no <code>args</code> field:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="attr">- command:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">/usr/local/bin/etcd</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">--data-dir=/var/etcd/data</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">--name=example-etcd-cluster-65zvs2mt8b</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">--initial-advertise-peer-urls=http://example-etcd-cluster-65zvs2mt8b.example-etcd-cluster.default.svc:2380</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">--listen-peer-urls=http://0.0.0.0:2380</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">--listen-client-urls=http://0.0.0.0:2379</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes NodePort vs LoadBalancer vs Ingress</title>
    <url>/2019/03/26/k8s-external-access/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>This <a href="https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0" target="_blank" rel="noopener">blog</a> talks about the ways that provide external access to kubernetes cluster and their difference.</p>
<p>This <a href="https://www.nginx.com/blog/wait-which-nginx-ingress-controller-kubernetes-am-i-using/" target="_blank" rel="noopener">blog</a> is about <code>NGINX</code> ingress controller.</p>
<p>I need to do further demo and research on them.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>ingress</tag>
      </tags>
  </entry>
  <entry>
    <title>External Provisioner</title>
    <url>/2019/12/10/k8s-external-provisioner/</url>
    <content><![CDATA[<p>Github <a href="https://github.com/kubernetes-incubator/external-storage" target="_blank" rel="noopener">external provisioner</a>.</p>
<p>The external provisioner can be backed by  many type of filesystem, here we focus on <code>nfs-client</code>.</p>
<blockquote>
<p>Notice that in this project, you will see <code>nfs-client</code> and <code>nfs</code> directories, <code>nfs-client</code> means we already has a nfs server and use it on client. <code>nfs</code> means we don’t have a nfs server, but we share other filesystem in nfs way.</p>
</blockquote>
<p>Another tool very similar is <a href="https://rook.io/" target="_blank" rel="noopener">Rook</a>, see my blog <a href="https://chengdol.github.io/2020/01/20/k8s-rook/" target="_blank" rel="noopener"><code>Rook Storage Orchestrator</code></a>.</p>
<p>The <code>Rook</code> is more heavy and this project is lightweight.</p>
<ol>
<li>Setup NFS server</li>
<li><p>Install nfs-utils on all worker nodes<br>See my blog <a href="https://chengdol.github.io/2019/05/27/fs-nfs-setup/" target="_blank" rel="noopener">NFS Server and Client Setup</a>, this <code>Server Setup</code> chapter.</p>
</li>
<li><p>Setup NFS provisioner<br>This blog give me clear instruction on how to adopt the <code>nfs-client</code> provisioner: <a href="https://medium.com/faun/openshift-dynamic-nfs-persistent-volume-using-nfs-client-provisioner-fcbb8c9344e" target="_blank" rel="noopener">openshift dynamic NFS persistent volume using NFS-client-provisioner</a>.</p>
</li>
</ol>
<p><strong>Notces</strong>:</p>
<ol>
<li><p>I find a bug in this project, when set rbac, you need to specify <code>-n test-1</code>, otherwise the role was created in <code>test-1</code> but rolebinding is created in default namespace.</p>
</li>
<li><p>The NFS provisioner is global scoped.</p>
</li>
<li><p>The <code>NFS_SERVER</code> env in deployment.yaml can be hostname or IP address.</p>
</li>
<li><p>If several pods use the same PVC, they share the same PV.</p>
</li>
<li><p>you can customize the storage class if it’s available. For example, set the reclaim policy as <code>retain</code> instead of <code>delete</code>. see <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">doc</a>.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">standard</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">kubernetes.io/aws-ebs</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">gp2</span></span><br><span class="line"><span class="comment">## default is delete</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line"><span class="comment">## allow resize the volume by editing the corresponding PVC object</span></span><br><span class="line"><span class="comment">## cannot shrink</span></span><br><span class="line"><span class="attr">allowVolumeExpansion:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">volumeBindingMode:</span> <span class="string">Immediate</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>external provisioner</tag>
      </tags>
  </entry>
  <entry>
    <title>Completely Delete K8s Cluster</title>
    <url>/2019/03/02/k8s-delete-cluster/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Today I spend some time to investigate how to remove nodes from the k8s cluster that built by <code>kubeadm</code>.</p>
<p>For example, I have a 3 nodes cluster called <code>k8stest</code>, I deploy the application in <code>namespace</code> <code>test-1</code>, each worker node (<code>k8stest2</code> and <code>k8stest3</code>) holds some pods:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods -n <span class="built_in">test</span>-1 -o wide</span><br><span class="line"></span><br><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE     IP            NODE                    NOMINATED NODE   READINESS GATES</span><br><span class="line">is-en-conductor-0                        1/1     Running   0          5h40m   192.168.1.2   k8stest3.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-engine-compute-0                      1/1     Running   0          5h39m   192.168.1.3   k8stest3.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-engine-compute-1                      1/1     Running   0          5h38m   192.168.2.4   k8stest2.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-servicesdocker-pod-7b4d9d5c48-vvfn6   1/1     Running   0          5h41m   192.168.2.3   k8stest2.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-xmetadocker-pod-5ff59fff46-tkmqn      1/1     Running   0          5h42m   192.168.2.2   k8stest2.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="Drain-and-delete-worker-nodes"><a href="#Drain-and-delete-worker-nodes" class="headerlink" title="Drain and delete worker nodes"></a>Drain and delete worker nodes</h3><p>You can use <code>kubectl drain</code> to safely evict all of your pods from a node before you perform maintenance on the node (e.g. kernel upgrade, hardware maintenance, etc.). Safe evictions allow the pod’s containers to <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods" target="_blank" rel="noopener">gracefully terminate</a> and will respect the <code>PodDisruptionBudgets</code> you have specified.</p>
<p>The <code>drain</code> evicts or deletes all pods except mirror pods (which cannot be deleted through the API server). If there are DaemonSet-managed pods, drain will not proceed without <code>--ignore-daemonsets</code>, and regardless it will not delete any DaemonSet-managed pods, because those pods would be immediately replaced by the DaemonSet controller, which ignores unschedulable markings. If there are any pods that are neither mirror pods nor managed by <code>ReplicationController</code>, <code>ReplicaSet</code>, <code>DaemonSet</code>, <code>StatefulSet</code> or <code>Job</code>, then drain will not delete any pods unless you use <code>--force</code>. <code>--force</code> will also allow deletion to proceed if the managing resource of one or more pods is missing.</p>
<p>Let’s first drain <code>k8stest2</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl drain k8stest2.fyre.ibm.com --delete-local-data --force --ignore-daemonsets</span><br><span class="line"></span><br><span class="line">node/k8stest2.fyre.ibm.com cordoned</span><br><span class="line">WARNING: Ignoring DaemonSet-managed pods: calico-node-txjpn, kube-proxy-52njn</span><br><span class="line">pod/is-engine-compute-1 evicted</span><br><span class="line">pod/is-xmetadocker-pod-5ff59fff46-tkmqn evicted</span><br><span class="line">pod/is-servicesdocker-pod-7b4d9d5c48-vvfn6 evicted</span><br><span class="line">node/k8stest2.fyre.ibm.com evicted</span><br></pre></td></tr></table></figure></p>
<p>When <code>kubectl drain</code> returns successfully, that indicates that all of the pods (except the ones excluded as described in the previous paragraph) have been safely evicted (respecting the desired graceful termination period, and without violating any application-level disruption SLOs). It is then safe to bring down the node by powering down its physical machine or, if running on a cloud platform, deleting its virtual machine.</p>
<p>Let’s ssh to <code>k8stest2</code> node and see what happens here, the payloads were gone:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh k8stest2.fyre.ibm.com</span><br><span class="line">docker ps</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">0fbbb64d93d0        fa6f35a1c14d           <span class="string">"/install-cni.sh"</span>        6 hours ago         Up 6 hours                              k8s_install-cni_calico-node-txjpn_kube-system_4b916269-3d49-11e9-b6b3-00163e01eecc_0</span><br><span class="line">b78013d4f454        427a0694c75c           <span class="string">"start_runit"</span>            6 hours ago         Up 6 hours                              k8s_calico-node_calico-node-txjpn_kube-system_4b916269-3d49-11e9-b6b3-00163e01eecc_0</span><br><span class="line">c6aaf7cbf713        01cfa56edcfc           <span class="string">"/usr/local/bin/kube..."</span>   6 hours ago         Up 6 hours                              k8s_kube-proxy_kube-proxy-52njn_kube-system_4b944a11-3d49-11e9-b6b3-00163e01eecc_0</span><br><span class="line">542bc4662ee4        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 6 hours ago         Up 6 hours                              k8s_POD_calico-node-txjpn_kube-system_4b916269-3d49-11e9-b6b3-00163e01eecc_0</span><br><span class="line">86ee508f0aa1        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 6 hours ago         Up 6 hours                              k8s_POD_kube-proxy-52njn_kube-system_4b944a11-3d49-11e9-b6b3-00163e01eecc_0</span><br></pre></td></tr></table></figure></p>
<p>The given node will be marked <code>unschedulable</code> to prevent new pods from arriving.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">NAME                    STATUS                     ROLES    AGE     VERSION</span><br><span class="line">k8stest1.fyre.ibm.com   Ready                      master   6h11m   v1.13.2</span><br><span class="line">k8stest2.fyre.ibm.com   Ready,SchedulingDisabled   &lt;none&gt;   5h57m   v1.13.2</span><br><span class="line">k8stest3.fyre.ibm.com   Ready                      &lt;none&gt;   5h57m   v1.13.2</span><br></pre></td></tr></table></figure></p>
<p>Because the dedicated node <code>k8stest2</code> was drained, so <code>is-servicesdocker</code> and <code>is-xmetadocker</code> keep pending:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE     IP            NODE                    NOMINATED NODE   READINESS GATES</span><br><span class="line">is-en-conductor-0                        1/1     Running   0          6h3m    192.168.1.2   k8stest3.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-engine-compute-0                      1/1     Running   0          6h2m    192.168.1.3   k8stest3.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-engine-compute-1                      1/1     Running   0          9m26s   192.168.1.4   k8stest3.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-servicesdocker-pod-7b4d9d5c48-vz7x4   0/1     Pending   0          9m39s   &lt;none&gt;        &lt;none&gt;                  &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-xmetadocker-pod-5ff59fff46-m4xj2      0/1     Pending   0          9m39s   &lt;none&gt;        &lt;none&gt;                  &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure></p>
<p>Now it’s safe to delete node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete node k8stest2.fyre.ibm.com</span><br><span class="line"></span><br><span class="line">node <span class="string">"k8stest2.fyre.ibm.com"</span> deleted</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">NAME                    STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8stest1.fyre.ibm.com   Ready    master   6h22m   v1.13.2</span><br><span class="line">k8stest3.fyre.ibm.com   Ready    &lt;none&gt;   6h8m    v1.13.2</span><br></pre></td></tr></table></figure>
<p>Repeat the steps above for worker node <code>k8stest3</code> then only master node survives:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">NAME                    STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8stest1.fyre.ibm.com   Ready    master   6h25m   v1.13.2</span><br></pre></td></tr></table></figure></p>
<h3 id="Drain-master-node"><a href="#Drain-master-node" class="headerlink" title="Drain master node"></a>Drain master node</h3><p>It’s time to deal with master node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl drain k8stest1.fyre.ibm.com --delete-local-data --force --ignore-daemonsets</span><br><span class="line"></span><br><span class="line">node/k8stest1.fyre.ibm.com cordoned</span><br><span class="line">WARNING: Ignoring DaemonSet-managed pods: calico-node-vlqh5, kube-proxy-5tfgr</span><br><span class="line">pod/docker-registry-85577757d5-952wq evicted</span><br><span class="line">pod/coredns-86c58d9df4-kwjr8 evicted</span><br><span class="line">pod/coredns-86c58d9df4-4p7g2 evicted</span><br><span class="line">node/k8stest1.fyre.ibm.com evicted</span><br></pre></td></tr></table></figure></p>
<p>Let’s see what happens for infrastructure pods, some of them were gone:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods -n kube-system</span><br><span class="line"></span><br><span class="line">NAME                                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">calico-node-vlqh5                               2/2     Running   0          6h31m</span><br><span class="line">coredns-86c58d9df4-5ctw2                        0/1     Pending   0          2m15s</span><br><span class="line">coredns-86c58d9df4-mg8rf                        0/1     Pending   0          2m15s</span><br><span class="line">etcd-k8stest1.fyre.ibm.com                      1/1     Running   0          6h31m</span><br><span class="line">kube-apiserver-k8stest1.fyre.ibm.com            1/1     Running   0          6h31m</span><br><span class="line">kube-controller-manager-k8stest1.fyre.ibm.com   1/1     Running   0          6h30m</span><br><span class="line">kube-proxy-5tfgr                                1/1     Running   0          6h31m</span><br><span class="line">kube-scheduler-k8stest1.fyre.ibm.com            1/1     Running   0          6h31m</span><br></pre></td></tr></table></figure></p>
<p>Note that don’t do delete for master node.</p>
<h3 id="Reset-cluster"><a href="#Reset-cluster" class="headerlink" title="Reset cluster"></a>Reset cluster</h3><p>Run this in every node to revert any changes made  by <code>kubeadm init</code> or <code>kubeadm join</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubeadm reset -f</span><br></pre></td></tr></table></figure></p>
<p>All container were gone and also check if <code>kubectl</code> still works?<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker ps</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">The connection to the server 9.30.219.224:6443 was refused - did you specify the right host or port?</span><br></pre></td></tr></table></figure>
<h3 id="Delete-rpm-and-files"><a href="#Delete-rpm-and-files" class="headerlink" title="Delete rpm and files"></a>Delete rpm and files</h3><p>Finally, we need to delete rpms and remove residue in every node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum erase -y kubeadm.x86_64 kubectl.x86_64 kubelet.x86_64 kubernetes-cni.x86_64 cri-tools socat</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## calico</span></span><br><span class="line">/bin/rm -rf /opt/cni/bin/*</span><br><span class="line">/bin/rm -rf /var/lib/calico</span><br><span class="line">/bin/rm -rf /run/calico</span><br><span class="line"><span class="comment">## config</span></span><br><span class="line">/bin/rm -rf /root/.kube</span><br><span class="line"><span class="comment">## etcd</span></span><br><span class="line">/bin/rm -rf /var/lib/etcd/*</span><br><span class="line"><span class="comment">## kubernetes</span></span><br><span class="line">/bin/rm -rf /etc/kubernetes/</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>kubeadm</tag>
        <tag>drain</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Feature Gates</title>
    <url>/2019/08/27/k8s-feature-gates/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Sometimes you will find the demo run in your kubernetes cluster doesn’t work exactly or doesn’t fit your expectation from official documentation. That maybe a feature gate you didn’t enable it or you don’t have it.</p>
<p>See this issue, I encountered the exactly the same:<br><a href="https://github.com/coreos/prometheus-operator/issues/2439" target="_blank" rel="noopener">https://github.com/coreos/prometheus-operator/issues/2439</a></p>
<p>This is the <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/" target="_blank" rel="noopener">Feature Gates link</a>.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Force Delete StatefulSet and Pods</title>
    <url>/2019/02/16/k8s-force-delete-statefulset/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<h2 id="Issue-description"><a href="#Issue-description" class="headerlink" title="Issue description"></a>Issue description</h2><p>I encountered the problem that when delete <code>statefulset</code> the execution hangs, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete statefulset is-en-conductor</span><br></pre></td></tr></table></figure></p>
<p>it cannot delete the <code>statefulset</code> and associated <code>pods</code> at all<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@opsft-lb-1 OpenShift] oc get all</span><br><span class="line">NAME                             DESIRED   CURRENT   AGE</span><br><span class="line">statefulsets/is-en-conductor     0         1         5h</span><br><span class="line">statefulsets/is-engine-compute   0         2         5h</span><br><span class="line"></span><br><span class="line">NAME                     READY     STATUS        RESTARTS   AGE</span><br><span class="line">po/is-en-conductor-0     0/1       Terminating   2          1h</span><br><span class="line">po/is-engine-compute-0   1/1       Running       0          5h</span><br><span class="line">po/is-engine-compute-1   0/1       Terminating   0          5h</span><br></pre></td></tr></table></figure></p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete statefulsets &lt;statefulset name&gt; --force --grace-period=0 --cascade=<span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>now we only have hanging pods, force delete them<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NAME                     READY     STATUS        RESTARTS   AGE</span><br><span class="line">po/is-en-conductor-0     0/1       Terminating   2          1h</span><br><span class="line">po/is-engine-compute-0   1/1       Running       0          5h</span><br><span class="line">po/is-engine-compute-1   0/1       Terminating   0          5h</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete pod &lt;pod name&gt; --force --grace-period=0</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>statefulset</tag>
      </tags>
  </entry>
  <entry>
    <title>Helm Tiller Server Deploy</title>
    <url>/2019/07/19/k8s-helm-tiller/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Helm 3 removes the Tiller server, see this <a href="https://developer.ibm.com/technologies/containers/blogs/kubernetes-helm-3/" target="_blank" rel="noopener">post</a></p>
<p>This blog primarily talks about <code>Tiller</code> server, especially creating service account and cluster role binding for it.<br>还有一种解决办法是<code>Tillerless</code>, 将Tiller server 运行在本地的container中，见我的 <code>&lt;&lt;Helm Quick Start&gt;&gt;</code></p>
<p>Zen uses <code>Helm</code> to install in ICP4D cluster. <code>Helm</code> is a tool for managing Kubernetes charts. <code>Charts</code> are packages of pre-configured Kubernetes resources. Think of <code>Helm</code> like apt(deb), yum(rpm), homebrew for Kubernetes.</p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p><a href="https://github.com/helm/helm" target="_blank" rel="noopener">Helm Git Repos</a></p>
<h2 id="Download-Helm-Installer"><a href="#Download-Helm-Installer" class="headerlink" title="Download Helm Installer"></a>Download Helm Installer</h2><p>Download the Latest release from <a href="https://github.com/helm/helm/releases" target="_blank" rel="noopener">Helm Release</a>. For example in Linux, we use:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Linux amd64 (checksum / 9f50e69cf5cfa7268b28686728ad0227507a169e52bf59c99ada872ddd9679f0)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><code>Helm</code> needs to be put in the control node that already configured with <code>kubectl</code>.</p>
</blockquote>
<p>Untar the file and you can move <code>helm</code> binary to one of the exectuable path, such as <code>/usr/local/bin</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># which helm</span></span><br><span class="line">/usr/<span class="built_in">local</span>/bin/helm</span><br></pre></td></tr></table></figure></p>
<h2 id="Deploy-Tiller-Server"><a href="#Deploy-Tiller-Server" class="headerlink" title="Deploy Tiller Server"></a>Deploy Tiller Server</h2><p>Helm client needs to talk to <code>Tiller</code> server, which will be deploied in the K8s cluster.</p>
<p>Most cloud providers enable a feature called Role-Based Access Control - <code>RBAC</code> for short. If your cloud provider enables this feature, you will need to create a service account for Tiller with the right roles and permissions to access resources.</p>
<p>From <a href="https://helm.sh/docs/using_helm/#tiller-and-role-based-access-control" target="_blank" rel="noopener">here</a>, you need to create a <code>cluster role binding</code> which specifies a role and a <code>service account</code> name that have been set up in advance <code>rbac-config.yaml</code>:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tiller</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tiller</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">  - kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">tiller</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure></p>
<p>Then install <code>Helm</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f rbac-config.yaml</span><br><span class="line">helm init --service-account tiller --<span class="built_in">history</span>-max 200</span><br></pre></td></tr></table></figure></p>
<p>If you forget to create <code>service account</code> and <code>cluster role binding</code> before you initiate <code>Helm</code>, no worries, create <code>rbac-config.yaml</code> objects and patch it by:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl patch deploy --namespace kube-system tiller-deploy -p <span class="string">'&#123;"spec":&#123;"template":&#123;"spec":&#123;"serviceAccount":"tiller"&#125;&#125;&#125;&#125;'</span></span><br></pre></td></tr></table></figure></p>
<p>Then check <code>Tiller</code> pod is running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods -n kube-system -l app=helm</span><br><span class="line"></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">tiller-deploy-845fb7cfc6-rn4nq   1/1     Running   0          20h</span><br></pre></td></tr></table></figure></p>
<p>Now, we are in good shape, actually I can config <code>SSL/TLS</code> between <code>Helm</code> and <code>Tiller</code>, not covered in this blog.</p>
<h2 id="Uninstall-Tiller-Server"><a href="#Uninstall-Tiller-Server" class="headerlink" title="Uninstall Tiller Server"></a>Uninstall Tiller Server</h2><p>There are 2 ways to uninstall:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">helm reset</span><br><span class="line">helm delete deploy tiller-deploy -n kube-system</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>helm</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Ingress</title>
    <url>/2019/10/21/k8s-ingress/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>First understand basis:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/45079988/ingress-vs-load-balancer" target="_blank" rel="noopener">Ingress vs Load Balancer</a></li>
<li><a href="https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0" target="_blank" rel="noopener">Kubernetes NodePort vs LoadBalancer vs Ingress? When should I use what?</a></li>
</ul>
<p>This <a href="https://docs.microsoft.com/en-us/azure/aks/ingress-tls" target="_blank" rel="noopener">link</a> show you the instructions about how to setup ingress in an Azure Kubernetes Service (AKS) cluster.<br>It contains <a href="https://github.com/kubernetes/ingress-nginx" target="_blank" rel="noopener"><code>NGINX ingress controller</code></a> and <a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener"><code>cert-manager project</code></a> (used to automatically generate and configure <a href="https://letsencrypt.org/" target="_blank" rel="noopener"><code>Let&#39;s Encrypt</code></a> certificates).</p>
<p>First understand what is forward proxy and reverse proxy:<br><a href="https://www.linuxbabe.com/it-knowledge/differences-between-forward-proxy-and-reverse-proxy" target="_blank" rel="noopener">https://www.linuxbabe.com/it-knowledge/differences-between-forward-proxy-and-reverse-proxy</a></p>
<p>There’re many different kinds of forward proxy such as web proxy, HTTP proxy, SOCKS proxy etc. Please keep mind that using forward proxy to browse the Internet usually slows down your overall Internet speed. Another thing to be aware of is that there’re many free forward proxies which is built by hackers for malicious purpose. If you happen to be using one of these proxies, they will log every activity you do on the Internet.</p>
<p>Nginx can be acting both a web server and a reverse proxy at the same time. HAProxy is another well-known open-source reverse proxy software.</p>
<p>TLS termination proxy:<br><a href="https://en.wikipedia.org/wiki/TLS_termination_proxy" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/TLS_termination_proxy</a></p>
<p>A TLS termination proxy (or SSL termination proxy) is a proxy server that is used by an institution to handle incoming TLS connections, decrypting the TLS and passing on the unencrypted request to the institution’s other servers (it is assumed that the institution’s own network is secure so the user’s session data does not need to be encrypted on that part of the link). TLS termination proxies are used to reduce the load on the main servers by offloading the cryptographic processing to another machine, and to support servers that do not support SSL, like Varnish.</p>
<h2 id="Create-an-ingress-controller"><a href="#Create-an-ingress-controller" class="headerlink" title="Create an ingress controller"></a>Create an ingress controller</h2><p>To create the ingress controller, use <code>Helm</code> to install nginx-ingress (or use yaml). For added redundancy, two replicas of the NGINX ingress controllers are deployed with the <code>--set controller.replicaCount parameter</code>.</p>
<p>This is for AKS cluster, for bare-metal it’s different, since bare-metal does not have existing loadbalancer (please refer <a href="https://kubernetes.github.io/ingress-nginx/)" target="_blank" rel="noopener">https://kubernetes.github.io/ingress-nginx/)</a>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install stable/nginx-ingress \</span><br><span class="line">    --namespace &lt;the namespace as your application&gt; \</span><br><span class="line">    --<span class="built_in">set</span> controller.replicaCount=2 \</span><br><span class="line">    --<span class="built_in">set</span> controller.nodeSelector.<span class="string">"beta\.kubernetes\.io/os"</span>=linux \</span><br><span class="line">    --<span class="built_in">set</span> defaultBackend.nodeSelector.<span class="string">"beta\.kubernetes\.io/os"</span>=linux</span><br></pre></td></tr></table></figure></p>
<p>Then go to get the public IP assigned for ingress controller:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAME                                             TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)                      AGE</span><br><span class="line">billowing-kitten-nginx-ingress-controller        LoadBalancer   10.0.182.160   51.145.155.210  80:30920/TCP,443:30426/TCP   20m</span><br><span class="line">billowing-kitten-nginx-ingress-default-backend   ClusterIP      10.0.255.77    &lt;none&gt;          80/TCP                       20m</span><br></pre></td></tr></table></figure></p>
<p>Until, we just set up a ingress controller, no ingress rules are specified.</p>
<h3 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## find helm release name</span></span><br><span class="line">helm list</span><br><span class="line"><span class="comment">## delete</span></span><br><span class="line">helm delete --purge &lt;name&gt;</span><br></pre></td></tr></table></figure>
<h2 id="Config-DNS-name"><a href="#Config-DNS-name" class="headerlink" title="Config DNS name"></a>Config DNS name</h2><p>For the HTTPS certificates to work correctly, configure an FQDN(fully qualified domain name) for the ingress controller IP address.</p>
<p>for Azure it is:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Public IP address of your ingress controller</span></span><br><span class="line">IP=<span class="string">"51.145.155.210"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name to associate with public IP address</span></span><br><span class="line">DNSNAME=<span class="string">"demo-aks-ingress"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the resource-id of the public ip</span></span><br><span class="line">PUBLICIPID=$(az network public-ip list --query <span class="string">"[?ipAddress!=null]|[?contains(ipAddress, '<span class="variable">$IP</span>')].[id]"</span> --output tsv)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update public ip address with DNS name</span></span><br><span class="line">az network public-ip update --ids <span class="variable">$PUBLICIPID</span> --dns-name <span class="variable">$DNSNAME</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Install-cert-manager"><a href="#Install-cert-manager" class="headerlink" title="Install cert-manager"></a>Install cert-manager</h2><p>The NGINX ingress controller supports TLS termination.<br>see here <a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">https://github.com/jetstack/cert-manager</a>.<br>cert-manager is a Kubernetes add-on to automate the management and issuance of TLS certificates from various issuing sources.<br>It will ensure certificates are valid and up to date periodically, and attempt to renew certificates at an appropriate time before expiry</p>
<p>To install the cert-manager controller in an RBAC-enabled cluster, use the following helm install command (this is not the latest version)<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Install the CustomResourceDefinition resources separately</span></span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/jetstack/cert-manager/release-0.8/deploy/manifests/00-crds.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the namespace for cert-manager</span></span><br><span class="line">kubectl create namespace cert-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># Label the cert-manager namespace to disable resource validation</span></span><br><span class="line">kubectl label namespace cert-manager certmanager.k8s.io/<span class="built_in">disable</span>-validation=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the Jetstack Helm repository</span></span><br><span class="line">helm repo add jetstack https://charts.jetstack.io</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update your local Helm chart repository cache</span></span><br><span class="line">helm repo update</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install the cert-manager Helm chart</span></span><br><span class="line">helm install \</span><br><span class="line">  --name cert-manager \</span><br><span class="line">  --namespace cert-manager \</span><br><span class="line">  --version v0.8.0 \</span><br><span class="line">  jetstack/cert-manager</span><br></pre></td></tr></table></figure></p>
<h3 id="Create-a-CA-cluster-issuer"><a href="#Create-a-CA-cluster-issuer" class="headerlink" title="Create a CA cluster issuer"></a>Create a CA cluster issuer</h3><p>Create a cluster issuer yaml then run <code>kubectl apply -f</code>, more details see:<br><a href="https://cert-manager.readthedocs.io/en/latest/reference/issuers.html" target="_blank" rel="noopener">https://cert-manager.readthedocs.io/en/latest/reference/issuers.html</a></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">certmanager.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterIssuer</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">letsencrypt-prod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  acme:</span></span><br><span class="line"><span class="attr">    server:</span> <span class="attr">https://acme-v02.api.letsencrypt.org/directory</span></span><br><span class="line"><span class="attr">    email:</span> <span class="string">&lt;your</span> <span class="string">email</span> <span class="string">address&gt;</span></span><br><span class="line"><span class="attr">    privateKeySecretRef:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">letsencrypt-prod</span></span><br><span class="line"><span class="attr">    http01:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="Delete-1"><a href="#Delete-1" class="headerlink" title="Delete"></a>Delete</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm list</span><br><span class="line">helm delete --purge &lt;name&gt;</span><br><span class="line">kubectl delete -f https://raw.githubusercontent.com/jetstack/cert-manager/release-0.8/deploy/manifests/00-crds.yaml</span><br><span class="line">kubectl delete -f cluster-issuer.yaml</span><br><span class="line">kubectl delete ns cert-manager</span><br></pre></td></tr></table></figure>
<h2 id="Create-ingress-route"><a href="#Create-ingress-route" class="headerlink" title="Create ingress route"></a>Create ingress route</h2><p>The apiVersion may update to stable, usually, if the AKS demo works but your application not, that means there are some miss configurations in the ingress annotations, please adjust according to your situation.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">&lt;ingress</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">&lt;ns&gt;</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">kubernetes.io/ingress.class:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="string">certmanager.k8s.io/cluster-issuer:</span> <span class="string">letsencrypt-prod</span></span><br><span class="line">    <span class="comment">## if inside cluster use HTTPS</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="string">"HTTPS"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment">## this part is for add ssl/tls to ingress</span></span><br><span class="line"><span class="attr">  tls:</span></span><br><span class="line"><span class="attr">  - hosts:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">&lt;URL&gt;</span></span><br><span class="line"><span class="attr">    secretName:</span> <span class="string">tls-secret</span></span><br><span class="line">  <span class="comment">## routing rules</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line"><span class="attr">  - host:</span> <span class="string">&lt;URL&gt;</span></span><br><span class="line"><span class="attr">    http:</span></span><br><span class="line"><span class="attr">      paths:</span></span><br><span class="line"><span class="attr">      - path:</span> <span class="string">/mbi/sii</span></span><br><span class="line"><span class="attr">        backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">is-servicesdocker</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">9446</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Delete-2"><a href="#Delete-2" class="headerlink" title="Delete"></a>Delete</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete -f ingress.yaml</span><br></pre></td></tr></table></figure>
<h2 id="Create-a-certificate-object"><a href="#Create-a-certificate-object" class="headerlink" title="Create a certificate object"></a>Create a certificate object</h2><p>Next, a certificate resource must be created. The certificate resource defines the desired X.509 certificate. For more information, see <a href="https://cert-manager.readthedocs.io/en/latest/reference/certificates.html" target="_blank" rel="noopener">https://cert-manager.readthedocs.io/en/latest/reference/certificates.html</a></p>
<p>Cert-manager has likely automatically created a certificate object for you using ingress-shim, which is automatically deployed with cert-manager since v0.2.2.<br>see <a href="https://docs.cert-manager.io/en/latest/tasks/issuing-certificates/ingress-shim.html" target="_blank" rel="noopener">https://docs.cert-manager.io/en/latest/tasks/issuing-certificates/ingress-shim.html</a></p>
<h2 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h2><p>If the things are going good, check the URL address in the browser:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;URL&gt;/mbi/sii/launchpad</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Helm Quick Start</title>
    <url>/2020/04/30/k8s-helm-quick-start/</url>
    <content><![CDATA[<h1 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h1><p>Now, let’s understand the basic concepts of Helm:<br><a href="https://helm.sh/docs/intro/using_helm/" target="_blank" rel="noopener">https://helm.sh/docs/intro/using_helm/</a></p>
<p><a href="https://helm.sh/docs/" target="_blank" rel="noopener">Official Document</a><br>To install helm in the control node, download the corresponding binary and untar to execution path, or using container and mount necessary k8s credentials.</p>
<p>Package manager analogy:</p>
<ul>
<li>helm (charts)</li>
<li>apt (deb)</li>
<li>yum (rpm)</li>
<li>maven (Jar)</li>
<li>npm (node modules)</li>
<li>pip (python packages)</li>
</ul>
<p><strong>Helm v3.2.0</strong></p>
<blockquote>
<p>Helm3 does not have Tiller server, see <a href="https://developer.ibm.com/technologies/containers/blogs/kubernetes-helm-3/" target="_blank" rel="noopener">what’s new in Helm 3</a></p>
</blockquote>
<h2 id="Plugins"><a href="#Plugins" class="headerlink" title="Plugins"></a>Plugins</h2><p><a href="https://www.sohu.com/a/304655993_120019946" target="_blank" rel="noopener">十六种实用的Kubernetes Helm Charts工具</a></p>
<h3 id="Tillerless"><a href="#Tillerless" class="headerlink" title="Tillerless"></a>Tillerless</h3><p>For <code>helm2</code>, Tiller server in cluster may not stable and secure, another workaround is run it locally, it talks to remote k8s cluster via kuebctl config.</p>
<ul>
<li><a href="https://github.com/rimusz/helm-tiller" target="_blank" rel="noopener">Tillerless Helm v2 plugin</a>, read this article <a href="https://rimusz.net/tillerless-helm" target="_blank" rel="noopener">Why tillerless is needed</a>.</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install tillerless plugin</span></span><br><span class="line">helm plugin install https://github.com/rimusz/helm-tiller</span><br></pre></td></tr></table></figure>
<p>A good practice is to have helm, helm plugin, kubectl and cloud SDK in one container, for example:<br><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FROM</span> python:<span class="number">3.7</span>.<span class="number">7</span>-alpine3.<span class="number">11</span></span><br><span class="line"><span class="keyword">LABEL</span><span class="bash"> version=<span class="string">"3.14"</span></span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">USER root</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment">## version number</span></span></span><br><span class="line"><span class="bash">ENV KUBCTL_VER=<span class="string">"1.16.11"</span></span></span><br><span class="line"><span class="bash">ENV KUBCTL=<span class="string">"/bin/kubectl"</span></span></span><br><span class="line"><span class="bash">ENV HELM_VER=<span class="string">"v2.16.9"</span></span></span><br><span class="line"><span class="bash">ENV HELMFILE_VER=<span class="string">"v0.119.0"</span></span></span><br><span class="line"><span class="bash">ENV HELMDIFF_VER=<span class="string">"v3.1.1"</span></span></span><br><span class="line"><span class="bash">ENV GCLOUD_SDK_VER=<span class="string">"318.0.0"</span></span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment"># Install fetch deps</span></span></span><br><span class="line"><span class="bash">RUN apk add --no-cache \</span></span><br><span class="line"><span class="bash">    ca-certificates \</span></span><br><span class="line"><span class="bash">    bash \</span></span><br><span class="line"><span class="bash">    jq \</span></span><br><span class="line"><span class="bash">    git \</span></span><br><span class="line"><span class="bash">    curl \</span></span><br><span class="line"><span class="bash">    unzip \</span></span><br><span class="line"><span class="bash">    tar \</span></span><br><span class="line"><span class="bash">    libgit2 \</span></span><br><span class="line"><span class="bash">    openssl-dev \</span></span><br><span class="line"><span class="bash">    libffi-dev \</span></span><br><span class="line"><span class="bash">    gcc \</span></span><br><span class="line"><span class="bash">    musl-dev \</span></span><br><span class="line"><span class="bash">    python3-dev \</span></span><br><span class="line"><span class="bash">    make \</span></span><br><span class="line"><span class="bash">    openssh \</span></span><br><span class="line"><span class="bash">    tini \</span></span><br><span class="line"><span class="bash">    shadow \</span></span><br><span class="line"><span class="bash">    su-exec \</span></span><br><span class="line"><span class="bash">    vim</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">RUN curl -L https://storage.googleapis.com/kubernetes-release/release/v<span class="variable">$&#123;KUBCTL_VER&#125;</span>/bin/linux/amd64/kubectl \</span></span><br><span class="line"><span class="bash">    -o <span class="variable">$KUBCTL</span> &amp;&amp; chmod 0755 <span class="variable">$KUBCTL</span></span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment"># install helm &amp;&amp; plugins &amp;&amp; helmfile</span></span></span><br><span class="line"><span class="bash">RUN curl -L https://storage.googleapis.com/kubernetes-helm/helm-<span class="variable">$&#123;HELM_VER&#125;</span>-linux-amd64.tar.gz | tar xz \</span></span><br><span class="line"><span class="bash">    &amp;&amp; cp linux-amd64/helm /bin &amp;&amp; rm -rf linux-amd64 \</span></span><br><span class="line"><span class="bash">    \</span></span><br><span class="line"><span class="bash">    &amp;&amp; curl -O -L https://github.com/roboll/helmfile/releases/download/<span class="variable">$&#123;HELMFILE_VER&#125;</span>/helmfile_linux_amd64 \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mv helmfile_linux_amd64 /usr/<span class="built_in">local</span>/bin/helmfile &amp;&amp; chmod 755 /usr/<span class="built_in">local</span>/bin/helmfile</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment"># Install GCloud SDK</span></span></span><br><span class="line"><span class="bash">RUN curl -L https://dl.google.com/dl/cloudsdk/channels/rapid/downloads/google-cloud-sdk-<span class="variable">$&#123;GCLOUD_SDK_VER&#125;</span>-linux-x86_64.tar.gz | tar zx \</span></span><br><span class="line"><span class="bash">    &amp;&amp; mv google-cloud-sdk /usr/<span class="built_in">local</span>/ &amp;&amp; /usr/<span class="built_in">local</span>/google-cloud-sdk/install.sh -q \</span></span><br><span class="line"><span class="bash">    &amp;&amp; /usr/<span class="built_in">local</span>/google-cloud-sdk/bin/gcloud components install beta --quiet</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">ENV PATH=<span class="string">"/usr/local/google-cloud-sdk/bin:<span class="variable">$&#123;PATH&#125;</span>"</span></span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">RUN helm init -c \</span></span><br><span class="line"><span class="bash">    &amp;&amp; helm plugin install https://github.com/chartmuseum/helm-push \</span></span><br><span class="line"><span class="bash">    &amp;&amp; helm plugin install https://github.com/databus23/helm-diff --version <span class="variable">$&#123;HELMDIFF_VER&#125;</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; helm plugin install https://github.com/rimusz/helm-tiller</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment">#Test</span></span></span><br><span class="line"><span class="bash">Run kubectl version --client \</span></span><br><span class="line"><span class="bash">    &amp;&amp; helm version --client \</span></span><br><span class="line"><span class="bash">    &amp;&amp; helm plugin list \</span></span><br><span class="line"><span class="bash">    &amp;&amp; helmfile -v \</span></span><br><span class="line"><span class="bash">    &amp;&amp; gcloud version</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">ENTRYPOINT [<span class="string">"/bin/bash"</span>,<span class="string">"-c"</span>, <span class="string">"tail -f /dev/null"</span>]</span></span><br></pre></td></tr></table></figure></p>
<p>Then run it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># go to tillerless folder that with the dockerfile above</span></span><br><span class="line">docker build -f tillerless.dockerfile -t tillerless:1.0 .</span><br><span class="line">docker run -d --name=xxx \</span><br><span class="line">        <span class="comment">## something you want to mount</span></span><br><span class="line">        <span class="comment">## gcloud config</span></span><br><span class="line">        -v ~/.config:/root/.config \</span><br><span class="line">        <span class="comment">## kubectl connect</span></span><br><span class="line">        -v ~/.kube:/root/.kube \</span><br><span class="line">        -v $(<span class="built_in">pwd</span>)/../envoy-proxy:/envoy-proxy \</span><br><span class="line">        <span class="comment">## tillerless env vars</span></span><br><span class="line">        <span class="comment">## by default tiller uses secret</span></span><br><span class="line">        -e HELM_TILLER_STORAGE=configmap \</span><br><span class="line">        -e HELM_HOST=127.0.0.1:44134 \</span><br><span class="line">        --entrypoint=/bin/bash \</span><br><span class="line">        tillerless:1.0 \</span><br><span class="line">        -c <span class="string">"tail -f /dev/null"</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>If switch k8s context, please <strong>stop and restart</strong> tillerless to adopt change.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## export if they are gone</span></span><br><span class="line"><span class="built_in">export</span> HELM_TILLER_STORAGE=configmap</span><br><span class="line"><span class="built_in">export</span> HELM_HOST=127.0.0.1:44134</span><br><span class="line"><span class="comment">## by default tiller namespace is kube-system</span></span><br><span class="line">helm tiller start [tiller namespace]</span><br><span class="line">[deploy objects]</span><br><span class="line">helm list</span><br><span class="line">helm install..</span><br><span class="line">helm delete..</span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>or<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## export if they are gone</span></span><br><span class="line"><span class="built_in">export</span> HELM_TILLER_STORAGE=configmap</span><br><span class="line"><span class="built_in">export</span> HELM_HOST=127.0.0.1:44134</span><br><span class="line"><span class="comment">## by default tiller namespace is kube-system</span></span><br><span class="line">helm tiller start-ci [tiller namespace]</span><br><span class="line">[<span class="built_in">export</span> env vars (I have <span class="keyword">done</span> this <span class="keyword">in</span> docker run <span class="built_in">command</span>)]</span><br><span class="line">[deploy objects]</span><br><span class="line">helm list</span><br><span class="line">helm install..</span><br><span class="line">helm delete..</span><br><span class="line"></span><br><span class="line">helm tiller stop</span><br></pre></td></tr></table></figure></p>
<p>or<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm tiller run &lt;<span class="built_in">command</span>&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="helmfile"><a href="#helmfile" class="headerlink" title="helmfile"></a>helmfile</h3><p><a href="https://github.com/roboll/helmfile" target="_blank" rel="noopener">https://github.com/roboll/helmfile</a></p>
<p><a href="https://tanzu.vmware.com/developer/guides/kubernetes/helmfile-what-is/" target="_blank" rel="noopener">Helmfile: What is it?</a><br>Helmfile adds additional functionality to Helm by wrapping it in a declarative spec that allows you to compose several charts together to create a comprehensive deployment artifact for anything from a single application to your entire infrastructure stack.</p>
<p>In <code>helmfile.yaml</code>:<br>helmfiles 是一些dependencies, 本质上它们也是helmfile<br>release中如果用values, 则chart archive中的values.yaml被覆盖了</p>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>helm3 does not have default repo, usually we use <code>https://kubernetes-charts.storage.googleapis.com/</code> as our stable repo. helm2 can skip this it has default stable repo.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## add stable repo to local repo</span></span><br><span class="line"><span class="comment">## 'stable' is your custom repo name</span></span><br><span class="line">helm repo add stable https://kubernetes-charts.storage.googleapis.com/</span><br><span class="line"><span class="comment">## display local repo list</span></span><br><span class="line">helm repo list</span><br><span class="line"><span class="comment">## remove repo 'stable'</span></span><br><span class="line">helm repo remove stable</span><br><span class="line"></span><br><span class="line"><span class="comment">## create charts sacffold</span></span><br><span class="line">helm create &lt;chart name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## install charts</span></span><br><span class="line"><span class="comment">## Make sure we get the latest list of charts</span></span><br><span class="line">helm repo update </span><br><span class="line">helm install stable/mysql --generate-name</span><br><span class="line">helm install &lt;release name&gt; stable/mysql -n &lt;namespace&gt;</span><br><span class="line">helm install &lt;path to unpacked/packed chart&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## show status of your release</span></span><br><span class="line">helm status &lt;release name&gt;</span><br></pre></td></tr></table></figure></p>
<p>Whenever you install a chart, a new release is created. So one chart can be installed multiple times into the same cluster. Each can be independently managed and upgraded.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show deployed release</span></span><br><span class="line">helm ls -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## uninstall</span></span><br><span class="line"><span class="comment">## with --keep-history, you can check the status of release</span></span><br><span class="line"><span class="comment">## or even undelete it</span></span><br><span class="line">helm uninstall &lt;release name&gt; [--keep-history] -n &lt;namespace&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Install-order"><a href="#Install-order" class="headerlink" title="Install order"></a>Install order</h2><p>Install in certain order, click to see. Or you can split the chart into different part or using init container.</p>
<ul>
<li><a href="https://stackoverflow.com/questions/51957676/helm-install-in-certain-order" target="_blank" rel="noopener">Helm install in certain order</a></li>
<li>using <a href="https://github.com/roboll/helmfile" target="_blank" rel="noopener">helmfile</a></li>
</ul>
<h1 id="Chart-file-structure"><a href="#Chart-file-structure" class="headerlink" title="Chart file structure"></a>Chart file structure</h1><p><a href="https://helm.sh/docs/topics/charts/#the-chart-file-structure" target="_blank" rel="noopener">https://helm.sh/docs/topics/charts/#the-chart-file-structure</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;chart name&gt;/</span><br><span class="line">  Chart.yaml          <span class="comment"># A YAML file containing information about the chart</span></span><br><span class="line">  LICENSE             <span class="comment"># OPTIONAL: A plain text file containing the license for the chart</span></span><br><span class="line">  README.md           <span class="comment"># OPTIONAL: A human-readable README file</span></span><br><span class="line">  values.yaml         <span class="comment"># The default configuration values for this chart</span></span><br><span class="line">  values.schema.json  <span class="comment"># OPTIONAL: A JSON Schema for imposing a structure on the values.yaml file, values.yaml 必须遵守这个结构, 否则不会通过</span></span><br><span class="line">  charts/             <span class="comment"># other dependent</span></span><br><span class="line">  requirements.yaml   <span class="comment"># other dependent (for helm2)</span></span><br><span class="line">  crds/               <span class="comment"># Custom Resource Definitions</span></span><br><span class="line">  templates/          <span class="comment"># A directory of templates that, when combined with values,</span></span><br><span class="line">                      <span class="comment"># will generate valid Kubernetes manifest files.</span></span><br><span class="line">     xxx.yaml</span><br><span class="line">     _xx.tpl          <span class="comment"># functions</span></span><br><span class="line">     NOTES.txt        <span class="comment"># show description after run helm install </span></span><br><span class="line">  templates/NOTES.txt <span class="comment"># OPTIONAL: A plain text file containing short usage notes</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>To drop a dependency into your <code>charts/</code> directory, use the <code>helm pull</code> command</p>
</blockquote>
<ol>
<li>Chart.yaml<br><code>apiVersion</code>, helm3 is <code>v2</code>, helm2 is <code>v1</code><br><code>appVersion</code>, application verion<br><code>version</code>, charts version, for example, chart file/structure changed<br><code>keywords</code> field is used for helm search<br><code>type</code>, we have application and library chart</li>
</ol>
<h1 id="Managing-dependencies"><a href="#Managing-dependencies" class="headerlink" title="Managing dependencies"></a>Managing dependencies</h1><p>Package the charts to archive, you can use <code>tar</code> but helm has special command for this purpose:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## it will create .tgz suffix</span></span><br><span class="line"><span class="comment">## and append chart verion to archive name</span></span><br><span class="line"><span class="comment">## chart version is from Chart.yaml</span></span><br><span class="line">helm package &lt;chart_name&gt;</span><br></pre></td></tr></table></figure></p>
<p>Publishing chart in repos, chartmuseum (like docker hub..), just like private docker registry, you can create a private chartmuseum in your host (有专门的安装包).<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## go to the dir that contains chart archive</span></span><br><span class="line"><span class="comment">## this will generate a index.yaml file</span></span><br><span class="line">helm repo index .</span><br><span class="line"><span class="comment">## for security can be signed and verified</span></span><br><span class="line"><span class="comment">## for verification, we need provenance file</span></span><br><span class="line">helm package --sign</span><br><span class="line">helm verify &lt;chart&gt;</span><br><span class="line"><span class="comment">## verify when install</span></span><br><span class="line">helm install --verify ...</span><br></pre></td></tr></table></figure></p>
<p>关于dependency，甚至可以只有charts文件夹，里面放所有的chart archive，外面也不需要templates了。<br>但这样不好管理版本，还是在Chart.yaml中定义依赖比较好。<br>在定义中还可以指定版本的范围，用的是semver语法: <code>~1.2.3</code>, <code>^0.3.4</code>, <code>1.2-3.4.5</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## will download dependency charts archive to your charts folder</span></span><br><span class="line"><span class="comment">## according to the definition in Chart.yaml</span></span><br><span class="line">helm dependency update &lt;chart name&gt;</span><br><span class="line"><span class="comment">## list dependency, their version, repo and status</span></span><br><span class="line">helm dependency list &lt;chart name&gt;</span><br></pre></td></tr></table></figure></p>
<p>You can also use <code>conditions and tags</code> to control which dependency is needed or not, for example, in <code>Chart.yaml</code> file<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v2</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">guestbook</span></span><br><span class="line"><span class="attr">appVersion:</span> <span class="string">"2.0"</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">A</span> <span class="string">Helm</span> <span class="string">chart</span> <span class="string">for</span> <span class="string">Guestbook</span> <span class="number">2.0</span> </span><br><span class="line"><span class="attr">version:</span> <span class="number">1.2</span><span class="number">.2</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">application</span></span><br><span class="line"><span class="attr">dependencies:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">backend</span></span><br><span class="line"><span class="attr">    version:</span> <span class="string">~1.2.2</span></span><br><span class="line"><span class="attr">    repository:</span> <span class="attr">http://localhost:8080</span></span><br><span class="line"><span class="attr">    condition:</span> <span class="string">backend.enabled</span></span><br><span class="line"><span class="attr">    tags:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">api</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">    version:</span> <span class="string">^1.2.0</span></span><br><span class="line"><span class="attr">    repository:</span> <span class="attr">http://localhost:8080</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">database</span></span><br><span class="line"><span class="attr">    version:</span> <span class="string">~1.2.2</span></span><br><span class="line"><span class="attr">    repository:</span> <span class="attr">http://localhost:8080</span></span><br><span class="line"><span class="attr">    condition:</span> <span class="string">database.enabled</span></span><br><span class="line"><span class="attr">    tags:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">api</span></span><br></pre></td></tr></table></figure></p>
<p>Then in <code>values.yaml</code> file:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## can be true or false</span></span><br><span class="line"><span class="attr">backend:</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">database:</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">tags:</span></span><br><span class="line"><span class="attr">  api:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Using-existing-charts"><a href="#Using-existing-charts" class="headerlink" title="Using existing charts"></a>Using existing charts</h1><p>Helm web: <a href="https://hub.helm.sh/" target="_blank" rel="noopener">https://hub.helm.sh/</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## add and remove repo</span></span><br><span class="line">helm add repo ...</span><br><span class="line">helm remove repo ...</span><br><span class="line"><span class="comment">## list repo's name and URL</span></span><br><span class="line">helm repo list</span><br><span class="line"></span><br><span class="line"><span class="comment">## search chart you want,for example</span></span><br><span class="line"><span class="comment">## mysql, nfs, mongodb, prometheus, redis, dashboard, wordpress</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## for mysql, you need to specify storage provisioner</span></span><br><span class="line"><span class="comment">## see inspect readme or values</span></span><br><span class="line">helm search [hub | repo] &lt;keyword&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## inspect the chart, like docker inspect</span></span><br><span class="line"><span class="comment">## readme: usage 去网上看更清晰</span></span><br><span class="line"><span class="comment">## values: default config</span></span><br><span class="line"><span class="comment">## chart: Chart.yaml</span></span><br><span class="line">helm inspect [all | readme | values | chart] &lt;chart name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same as 'helm inspect values'</span></span><br><span class="line">helm show values</span><br><span class="line"></span><br><span class="line"><span class="comment">## download chart without dependencies</span></span><br><span class="line"><span class="comment">## for example, looking into the source code</span></span><br><span class="line">helm fetch &lt;chart name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## download dependencies specified in Chart.yaml</span></span><br><span class="line"><span class="comment">## specify char name unpacked</span></span><br><span class="line">helm dependency update &lt;chart name&gt;</span><br></pre></td></tr></table></figure>
<h1 id="Customizig-existing-charts"><a href="#Customizig-existing-charts" class="headerlink" title="Customizig existing charts"></a>Customizig existing charts</h1><p>if you want to override <code>child</code> chart’s values.yaml, then in your <code>partent</code> chart values.yaml, 这是常用的，比如你有个dependency 是 mongodb chart, 要改它的默认配置:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 'mongodb' is child chart name</span></span><br><span class="line"><span class="attr">mongodb:</span></span><br><span class="line"><span class="attr">  persistence:</span></span><br><span class="line"><span class="attr">    size:</span> <span class="number">100</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure></p>
<p>还可以child chart中的values.yaml override parent的，但很少这样用，用法很tricky.</p>
<h1 id="Chart-template-guide"><a href="#Chart-template-guide" class="headerlink" title="Chart template guide"></a>Chart template guide</h1><p><a href="https://helm.sh/docs/chart_template_guide/getting_started/" target="_blank" rel="noopener">https://helm.sh/docs/chart_template_guide/getting_started/</a><br>Helm Chart templates are written in the <code>Go template language</code>, with the addition of 50 or so add-on template functions from the <a href="http://masterminds.github.io/sprig/" target="_blank" rel="noopener"><code>Sprig library</code></a> and a few other specialized functions.</p>
<h2 id="Template-and-values"><a href="#Template-and-values" class="headerlink" title="Template and values"></a>Template and values</h2><p><a href="https://helm.sh/docs/topics/charts/#templates-and-values" target="_blank" rel="noopener">https://helm.sh/docs/topics/charts/#templates-and-values</a></p>
<p>Where are the configuration values from, precdence low to high from top to bottom:</p>
<ol>
<li>values.yaml (default use)</li>
<li>other-file.yaml: <code>helm install -f &lt;other-file.yaml&gt; ...</code></li>
<li>command: <code>helm install --set key=val ...</code></li>
</ol>
<p>Helm template built-in objects:</p>
<ol>
<li>Chart.yaml: <code>.Chart.Name</code> (use upper case)</li>
<li>Release data: <code>.Release.Name</code></li>
<li>K8s data: <code>.Capabilities.KubeVersion</code></li>
<li>File data: <code>.Files.Get. conf.ini</code></li>
<li>Template data: <code>.Template.Name</code></li>
</ol>
<p>In <code>values.yaml</code>:</p>
<ol>
<li>use <code>_</code> instead of <code>-</code></li>
<li>decimal number wrapped by <code>&quot;&quot;</code>, <code>&quot;2.0&quot;</code>, integer number no need</li>
</ol>
<p>使用placeholder 是最基本的操作，let’s see functions and logic.</p>
<ol>
<li><p>use functions and pipelines, they are interchangeable<br><a href="https://helm.sh/docs/chart_template_guide/functions_and_pipelines/" target="_blank" rel="noopener">https://helm.sh/docs/chart_template_guide/functions_and_pipelines/</a><br>commonly used functions and correspinding pipelines</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">      <span class="keyword">function</span> usage         --       pipeline usage</span><br><span class="line">================================================================</span><br><span class="line">default default_value value  -- value | default default_value</span><br><span class="line">quote value                  -- value | quote</span><br><span class="line">upper value                  -- value | upper</span><br><span class="line">trunc value 20               -- value | trunc 20</span><br><span class="line">trimSuffix <span class="string">"-"</span> value         -- value | trimSuffix <span class="string">"-"</span></span><br><span class="line">b64enc value                 -- value | b64enc</span><br><span class="line">randAlphaNum 10              -- value | randAlphaNum 10 </span><br><span class="line">toYaml value                 -- value | toYaml</span><br><span class="line"><span class="built_in">printf</span> format value          -- list value | join <span class="string">"-"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>modify scope using <code>with</code> to simpify the directives，就不用写一长串引用了</p>
</li>
<li><p>control whitespaces and indent<br>use <code>-</code> to remove whitespace (newline is treated as white space!)</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&#123;&#123;-</span> <span class="string">with</span> <span class="string">...</span> <span class="bullet">-&#125;&#125;</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&#123;&#123;-</span> <span class="string">end&#125;&#125;</span></span><br><span class="line"><span class="comment">## indent 6 space ahead</span></span><br><span class="line"><span class="string">&#123;&#123;</span> <span class="string">indent</span> <span class="number">6</span> <span class="string">.Value.tcp</span> <span class="string">&#125;&#125;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>logical operators and flow control<br>if-else and loop</p>
</li>
<li><p>use variables<br>define the variable</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;&#123;- <span class="variable">$defaultPortNum</span> := .Values.defaultPortNum -&#125;&#125;</span><br><span class="line">&#123;&#123; <span class="variable">$defaultPortNum</span> &#125;&#125;</span><br><span class="line"><span class="comment">## . means global scope</span></span><br><span class="line">&#123;&#123; $.Release.Name&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>use sub-template<br>define function in <code>_helper.tpl</code> file then use <code>include</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;&#123; include <span class="string">"fun_name"</span> . | indent 4&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Debug-template"><a href="#Debug-template" class="headerlink" title="Debug template"></a>Debug template</h2><p>Locally rendering template:<br><a href="https://helm.sh/docs/helm/helm_template/" target="_blank" rel="noopener">https://helm.sh/docs/helm/helm_template/</a><br><a href="https://helm.sh/docs/chart_template_guide/debugging/" target="_blank" rel="noopener">https://helm.sh/docs/chart_template_guide/debugging/</a></p>
<blockquote>
<p>Usually first use the static check then dynamic check.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## static</span></span><br><span class="line"><span class="comment">## works without k8s cluster</span></span><br><span class="line"><span class="comment">## you can also specify which values yaml file</span></span><br><span class="line">helm template &lt;chart dir or archive file&gt; [--debug] | less</span><br><span class="line"><span class="comment">## for helm2</span></span><br><span class="line">helm template --tiller-namespace tiller --values ./xxx/values.second.yaml --debug &lt;chart dir or archive file&gt; |less</span><br><span class="line"></span><br><span class="line"><span class="comment">## dynamic</span></span><br><span class="line"><span class="comment">## real helm install but without commit</span></span><br><span class="line"><span class="comment">## can generate a release name as [release]</span></span><br><span class="line">helm install [release] &lt;chart&gt; --dry-run --debug 2&gt;&amp;1 | less</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h1 id="Helm-commands"><a href="#Helm-commands" class="headerlink" title="Helm commands"></a>Helm commands</h1><p><a href="https://helm.sh/docs/helm/" target="_blank" rel="noopener">https://helm.sh/docs/helm/</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install with specified release name</span></span><br><span class="line">helm install [release name] [chart] -n &lt;namespace&gt; --values &lt;path to values yaml&gt;</span><br><span class="line"><span class="comment">## check release status</span></span><br><span class="line">helm list -n &lt;namespace&gt;</span><br><span class="line"><span class="comment">## display yaml files</span></span><br><span class="line">helm get manifest [release] -n &lt;namespace&gt; | less</span><br><span class="line"></span><br><span class="line"><span class="comment">## check release specification and revision numbers</span></span><br><span class="line">helm status [release] -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## get all info</span></span><br><span class="line"><span class="comment">## helm2: helm get [release]</span></span><br><span class="line">helm get all [release] -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## upgrade</span></span><br><span class="line">helm upgrade [release] [chart] -n &lt;namespace&gt;</span><br><span class="line"><span class="comment">## check revision</span></span><br><span class="line">helm <span class="built_in">history</span> [release] -n &lt;namespace&gt;</span><br><span class="line"><span class="comment">## rollback</span></span><br><span class="line"><span class="comment">## revision number can get from helm history</span></span><br><span class="line">helm rollback [release] [revision] -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## if abort the helm install, check helm list then uninstall the broken release</span></span><br><span class="line"><span class="comment">## helm2: helm delete --purge [release] </span></span><br><span class="line">helm uninstall [release] -n &lt;namespace&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="PluralSight-Supplement"><a href="#PluralSight-Supplement" class="headerlink" title="PluralSight Supplement"></a>PluralSight Supplement</h1><p>github: <a href="https://github.com/phcollignon/helm3" target="_blank" rel="noopener">https://github.com/phcollignon/helm3</a></p>
<h2 id="Helm-context"><a href="#Helm-context" class="headerlink" title="Helm context"></a>Helm context</h2><p>Helm use the same configuration as kubectl<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## helm env, repos, config, cache info</span></span><br><span class="line">helm env</span><br><span class="line"><span class="comment">## check helm version</span></span><br><span class="line">helm version --short</span><br><span class="line"><span class="comment">## helm uses the same current context</span></span><br><span class="line">kubectl config view</span><br></pre></td></tr></table></figure></p>
<p>Helm stores release configuration and history in k8s as secrets. In helm3, it is stored in each corresponding namepsace.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## in your working namespace</span></span><br><span class="line">kubectl get secret -n &lt;ns&gt;</span><br><span class="line"><span class="comment">## helm secret is something like:</span></span><br><span class="line">sh.helm.release.v1.demomysql.v1      helm.sh/release.v1                    1      110s</span><br></pre></td></tr></table></figure></p>
<p><a href="https://helm.sh/docs/faq/#improved-upgrade-strategy-3-way-strategic-merge-patches" target="_blank" rel="noopener">Improved Upgrade Strategy: 3-way Strategic Merge Patches</a><br>In Helm3, Helm considers the <code>old manifest</code>, its <code>live state</code>, and the <code>new manifest</code> when generating a patch.</p>
<p>In helm2, helm client uses <code>gRPC</code> protocol to access Tiller server (in production secure connection is required, set TLS/SSL), then Tiller (need service account with privilege) will call K8s API to instantiate the charts. In helm3, no Tiller no security issue.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>helm</tag>
      </tags>
  </entry>
  <entry>
    <title>Init Container</title>
    <url>/2019/06/10/k8s-initContainer/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>In ICP4D non-root development, I see in each tier the pod contains init container, for example:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">is-xmetadocker</span></span><br><span class="line"><span class="attr">    hostIPC:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    initContainers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">load-data</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">"mycluster.icp:8500/zen/is-db2xmeta-image:11.7.1-1.0"</span></span><br><span class="line"><span class="attr">      imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">      securityContext:</span></span><br><span class="line"><span class="attr">        capabilities:</span></span><br><span class="line"><span class="attr">         add:</span> <span class="string">["SETFCAP",</span> <span class="string">"SYS_NICE"</span><span class="string">,</span> <span class="string">"IPC_OWNER"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">['/bin/bash',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'--'</span><span class="string">]</span></span><br><span class="line"><span class="attr">      args:</span> <span class="string">[</span> <span class="string">" set -x;</span></span><br><span class="line"><span class="string">              ...</span></span><br><span class="line"><span class="string">              "</span></span><br><span class="line">             <span class="string">]</span></span><br><span class="line"><span class="attr">      env:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">DEDICATED_REPOS_VOLPATH</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">/mnt/dedicated_vol/Repository</span></span><br><span class="line"><span class="attr">      volumeMounts:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">xmeta-pv-volume</span></span><br><span class="line"><span class="attr">        mountPath:</span> <span class="string">"/mnt/dedicated_vol/Repository"</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Understanding"><a href="#Understanding" class="headerlink" title="Understanding"></a>Understanding</h2><p>What is this and what is it for? Let’s take a look. First reference to <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" target="_blank" rel="noopener">official documentation</a>.</p>
<p>Init Containers, which are <strong>specialized</strong> Containers that run <strong>before</strong> app Containers and can <strong>contain</strong> utilities or setup scripts not present in an app image.</p>
<p>A Pod can have multiple Containers running apps within it, but it can also have one or more Init Containers, which are run before the app Containers are started.</p>
<p>Init Containers are exactly like regular Containers, except:</p>
<ul>
<li>They always run to completion.</li>
<li>Each one must complete successfully before the next one is started.</li>
</ul>
<p>If an Init Container fails for a Pod, Kubernetes restarts the Pod repeatedly until the Init Container succeeds. However, if the Pod has a restartPolicy of Never, it is not restarted.</p>
<h3 id="Differences-from-Regular-Containers"><a href="#Differences-from-Regular-Containers" class="headerlink" title="Differences from Regular Containers"></a>Differences from Regular Containers</h3><p>Init Containers support all the fields and features of app Containers, including resource limits, volumes, and security settings. However, the resource requests and limits for an Init Container are handled slightly differently.</p>
<p>Init Containers do not support readiness probes because they must run to completion before the Pod can be ready.</p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>Init Containers have separate images from app Containers (actually they can have the same), they have some advantages for start-up related code:</p>
<ul>
<li>They can contain and run utilities that are not desirable to include in the app Container image for security reasons.</li>
<li>They can contain utilities or custom code for setup that is not present in an app image. For example, there is no need to make an image FROM another image just to use a tool like sed, awk, python, or dig during setup.</li>
<li>The application image builder and deployer roles can work independently without the need to jointly build a single app image.</li>
<li>They use Linux namespaces so that they have different filesystem views from app Containers. Consequently, they can be given access to Secrets that app Containers are not able to access.</li>
<li>They run to completion before any app Containers start, whereas app Containers run in parallel, so Init Containers provide an easy way to block or delay the startup of app Containers until some set of preconditions are met.</li>
</ul>
<p>You can check the logs of init container:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl logs &lt;pod name&gt; -c &lt;init container&gt; -n test-1</span><br></pre></td></tr></table></figure></p>
<p>During the startup of a Pod, the Init Containers are started <strong>in order</strong>, after the network and volumes are initialized. Each Container must exit successfully before the next is started.</p>
<p>If the Pod is restarted, all Init Containers must execute again. Init Container code should be idempotent. </p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>initContainer</tag>
      </tags>
  </entry>
  <entry>
    <title>Istio</title>
    <url>/2019/12/05/k8s-istio/</url>
    <content><![CDATA[<p>//TODO<br>[ ] read official document<br>[ ] udemy course</p>
<p>主讲Anthos的，由于service mesh是其中重要组成，所以讲了很多service mesh的内容, 并且讲得还很好。<br>Qucik Labs and slides are from <a href="https://app.pluralsight.com/paths/skills/architecting-hybrid-cloud-infrastructure-with-anthos" target="_blank" rel="noopener">PluralSight Anthos special</a><br>关于service mesh的实验可以回顾一下是如何在GCloud中操作的。slides也可以下载看看。</p>
<p><a href="https://istio.io/docs/concepts/what-is-istio/" target="_blank" rel="noopener"><code>Istio</code></a> is the implementation of a <code>service mesh</code> that improves application resilience as you connect, manage, and secure microservices. It provides operational control and performance insights for a network of containerized applications. It can work across environments(think about Google Anthos)!</p>
<p>Important network functions as below, <code>service mesh</code> decouple them from applications:</p>
<ul>
<li>authn</li>
<li>authz</li>
<li>latency</li>
<li>fault tolerance</li>
<li>circuit breaking</li>
<li>quota</li>
<li>rate limiting</li>
<li>load balancing</li>
<li>logging</li>
<li>metrics</li>
<li>distributed tracing</li>
<li>topology</li>
</ul>
<p>So summarize there are 3 parts: </p>
<ul>
<li>Traffic control </li>
<li>Observability (dashboard: prometheus, grafana, jaeger, kiali)</li>
<li>Security</li>
</ul>
<p><code>Istio</code> uses <a href="https://www.envoyproxy.io/" target="_blank" rel="noopener"><code>envoy</code></a> and sidecar pattern in the K8s pods.</p>
<p>Istio main components:</p>
<ul>
<li><code>Pilot</code>: control plane manages the distributed proxies across the either environment, push service communication policies, just like a software defined network.<ul>
<li>service discovery</li>
<li>traffic management</li>
<li>intelligent routing</li>
<li>resiliency</li>
</ul>
</li>
<li><code>Mixer</code>: collect info and send telemetry, logs and traces to your system of choice (prometheus, influxDB, Stackdriver, etc)</li>
<li><code>Citadel</code>: policies management, service to service auth[n,z], using mutual TLS, credential management.</li>
</ul>
<p>How does Istio work, for example, life of a request in the mesh:</p>
<ol>
<li>service A comes up.</li>
<li>envoy is deployed with it and fetches service information, routing and configuration policy from Pilot.</li>
<li>If Citadel is being used, TLS certs are securely distriuted as well.</li>
<li>service A calls service B.</li>
<li>client-side envoy intercepts the call.</li>
<li>envoy consults config to know how/where to route call to service B.</li>
<li>envoy forwards to appropriate instance of service B, the envoy on server side intercepts the request.</li>
<li>server-side envoy checks with Mixer to validate the call should be allowed.</li>
<li>server-side envoy forwards request to service B for response.</li>
<li>envoy forwards response to the original caller, the response is intercepted by envoy on the caller side.</li>
<li>envoy reports telemetry to Mixer, which in turn notifies appropriate plugins.</li>
<li>client-side envoy forwards response to service A</li>
<li>client-side envoy reports telemetry to Mixer, which in turn notifies appropriate plugins.</li>
</ol>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>istio</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Job and CronJob</title>
    <url>/2019/08/12/k8s-job-cronjob/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Recently I use Job to run some one time tasks (later switch back to regular pod because we want to control it’s start point), it’s just like other pod controller in K8s.</p>
<h2 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h2><p>Job setup pod, note that:<br>hostname<br>job-name, check<br>env pass</p>
<p>volume mount</p>
<p>Job type</p>
<p>In upgrade, usage</p>
<h2 id="CronJob"><a href="#CronJob" class="headerlink" title="CronJob"></a>CronJob</h2><p>crontab</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Specify Kubernetes API Server IP</title>
    <url>/2019/11/04/k8s-kubeadm-init-apiserver/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>When I was working on softlayer cluster, after installing kubernetes the kubectl command get stuck and return time execeeds error.</p>
<p>The issue is the master node has 3 IP address, but only one of them is accessable from client, if not specified, the <code>kubeadm init</code> command will choose the default network interface, sometimes it’s good but here does not fit.</p>
<p>the solution is use <code>--apiserver-advertise-address &lt;IP&gt;</code> in <code>kubeadm init</code>, then everything is good.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubectx and Kubens</title>
    <url>/2019/02/17/k8s-kubectx-kubens/</url>
    <content><![CDATA[<p>I want to introduce you two useful tools for kubernetes development, <a href="https://github.com/ahmetb/kubectx" target="_blank" rel="noopener">github link</a> with detail.</p>
<blockquote>
<p>Note: this is not an official Google product.</p>
</blockquote>
<h1 id="kubectx"><a href="#kubectx" class="headerlink" title="kubectx"></a>kubectx</h1><p><code>kubectx</code> helps you switching between clusters back and forth.</p>
<h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><p>Since kubectx/kubens are written in Bash, you should be able to install them to any POSIX environment that has Bash installed.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/ahmetb/kubectx /opt/kubectx</span><br></pre></td></tr></table></figure></p>
<p>Make sure kubectx script is executable:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] ls /opt/kubectx/ -ltr</span><br><span class="line">total 40</span><br><span class="line">-rw-r--r-- 1 root root 11357 Feb 17 21:25 LICENSE</span><br><span class="line">-rw-r--r-- 1 root root   968 Feb 17 21:25 CONTRIBUTING.md</span><br><span class="line">-rw-r--r-- 1 root root  7784 Feb 17 21:25 README.md</span><br><span class="line">drwxr-xr-x 2 root root   121 Feb 17 21:25 completion</span><br><span class="line">drwxr-xr-x 2 root root    84 Feb 17 21:25 img</span><br><span class="line">drwxr-xr-x 3 root root   100 Feb 17 21:25 test</span><br><span class="line">-rwxr-xr-x 1 root root  5273 Feb 17 21:25 kubens</span><br><span class="line">-rwxr-xr-x 1 root root  5218 Feb 17 21:25 kubectx</span><br></pre></td></tr></table></figure></p>
<p>Create symlinks to kubectx/kubens from somewhere in your PATH, like /usr/local/bin<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ln -s /opt/kubectx/kubectx /usr/<span class="built_in">local</span>/bin/kubectx</span><br></pre></td></tr></table></figure></p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>You should first understand how to switch among different clusters by using configuration files. please investigate this <a href="https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/" target="_blank" rel="noopener">link</a>, actually <code>kubectx</code> is built on top of it.</p>
<p>For example, I have one cluster on AWS and one cluster on Fyre, in each cluster there is a <code>~/.kube/config</code> file, rename it as <code>config.aws</code> and <code>config.fyre</code> and put them to another client machine <code>~/.kube/</code> folder with  kubectl installed.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@centctl1 .kube]<span class="comment"># ls -ltr</span></span><br><span class="line">total 16</span><br><span class="line">drwxr-xr-x 3 root root   23 Nov 26 16:38 cache</span><br><span class="line">-rw-r--r-- 1 root root 2214 Dec  6 10:16 config.aws</span><br><span class="line">drwxr-xr-x 2 root root   73 Dec  6 10:16 kubens</span><br><span class="line">drwxr-xr-x 3 root root 4096 Feb 17 22:05 http-cache</span><br><span class="line">-rw------- 1 root root 5474 Feb 17 22:22 config.fyre</span><br></pre></td></tr></table></figure></p>
<p>Append config files to environment variable <code>KUBECONFIG</code>, you can add export to <code>.bashrc</code> file.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KUBECONFIG=<span class="variable">$KUBECONFIG</span>:<span class="variable">$HOME</span>/.kube/config.aws:<span class="variable">$HOME</span>/.kube/config.fyre</span><br></pre></td></tr></table></figure></p>
<p>Now if you run <code>kubectx</code> you will see there are 2 contexts:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@centctl1 .kube] kubectx</span><br><span class="line">arn:aws:eks:us-west-2:296744932886:cluster/IIS-Test-Cluster</span><br><span class="line">kubernetes-admin@kubernetes</span><br></pre></td></tr></table></figure></p>
<p>Jump to <code>kubernetes-admin@kubernetes</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@centctl1 .kube] kubectx kubernetes-admin@kubernetes</span><br><span class="line">Switched to context <span class="string">"kubernetes-admin@kubernetes"</span>.</span><br></pre></td></tr></table></figure></p>
<p>Jump back:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@centctl1 .kube] kubectx -</span><br><span class="line">Switched to context <span class="string">"arn:aws:eks:us-west-2:296744932886:cluster/IIS-Test-Cluster"</span>.</span><br></pre></td></tr></table></figure></p>
<p>It is the same as you run below commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl config view</span><br><span class="line">kubectl config --kubeconfig=config.fyre use-context kubernetes-admin@kubernetes</span><br></pre></td></tr></table></figure></p>
<h1 id="kubens"><a href="#kubens" class="headerlink" title="kubens"></a>kubens</h1><p><code>kubens</code> helps you switch between Kubernetes namespaces smoothly, so you don’t need to add <code>-n &lt;namespace&gt;</code> in every command.</p>
<h2 id="Install-1"><a href="#Install-1" class="headerlink" title="Install"></a>Install</h2><p>Download the same Github repository as <code>kubectx</code>, add symlinks:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ln -s /opt/kubectx/kubens /usr/<span class="built_in">local</span>/bin/kubens</span><br></pre></td></tr></table></figure></p>
<h2 id="Usage-1"><a href="#Usage-1" class="headerlink" title="Usage"></a>Usage</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] kubens</span><br><span class="line">default</span><br><span class="line">kube-public</span><br><span class="line">kube-system</span><br><span class="line">[root@myk8s1 ~] kubens kube-system</span><br><span class="line">Context <span class="string">"kubernetes-admin@kubernetes"</span> modified.</span><br><span class="line">Active namespace is <span class="string">"kube-system"</span>.</span><br><span class="line">[root@myk8s1 ~] kubens -</span><br><span class="line">Context <span class="string">"kubernetes-admin@kubernetes"</span> modified.</span><br><span class="line">Active namespace is <span class="string">"default"</span>.</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubens</tag>
        <tag>kubectx</tag>
      </tags>
  </entry>
  <entry>
    <title>Local Persistent Volume</title>
    <url>/2020/04/02/k8s-local-persistent-volume/</url>
    <content><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><a href="https://kubernetes.io/blog/2019/04/04/kubernetes-1.14-local-persistent-volumes-ga/" target="_blank" rel="noopener">Kubernetes 1.14: Local Persistent Volumes GA</a><br><strong>Recap:</strong><br>A local persistent volume represents a local disk directly-attached to a single Kubernetes Node. With the Local Persistent Volume plugin, Kubernetes workloads can now consume high performance local storage using the same volume APIs that app developers have become accustomed to.</p>
<p>一个和hostPath的重要区别:<br>The biggest difference is that the Kubernetes scheduler understands which node a Local Persistent Volume belongs to. With HostPath volumes, a pod referencing a HostPath volume may be moved by the scheduler to a different node resulting in data loss. But with Local Persistent Volumes, the Kubernetes scheduler ensures that a pod using a Local Persistent Volume is <strong>always</strong> scheduled to the same node.</p>
<p>While HostPath volumes may be referenced via a Persistent Volume Claim (PVC) or directly inline in a pod definition, Local Persistent Volumes can only be referenced via a PVC. This provides additional security benefits since Persistent Volume objects are managed by the administrator, preventing Pods from being able to access any path on the host.</p>
<p>Additional benefits include support for formatting of block devices during mount, and volume ownership using fsGroup.</p>
<p>注意: 实际上emptyDir + fsGroup也可以实现类似hostPath的效果，emptyDir用的是<code>/sysroot</code> (RedHat Linux), 比如多个pods 使用emptyDir在同一个Node, 我在各自的emptyDir中touch了一个file: compute-0 和compute-3, 进入Node使用find command就可以看到了:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/sysroot/ostree/deploy/rhcos/var/lib/kubelet/pods/68e65ed4-4e62-4588-9269-8947dea9dd46/volumes/kubernetes.io~empty-dir/compute-dedicated-scratch/compute-0</span><br><span class="line"></span><br><span class="line">/sysroot/ostree/deploy/rhcos/var/lib/kubelet/pods/92b26b37-92f3-4609-83cb-da8cb8727ca2/volumes/kubernetes.io~empty-dir/compute-dedicated-scratch/compute-3</span><br></pre></td></tr></table></figure></p>
<p>还需要注意的是，local storage provisioning 在每个node上只会provision attach的disk个数一样的PV，并且这个PV会被一个PVC占据，尽管PV大小是500G但是PVC只请求5G。（不知道这个以后是否会有改进）</p>
<h2 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h2><blockquote>
<p>Only test on OCP <code>4.3</code> version</p>
</blockquote>
<p><a href="https://docs.openshift.com/container-platform/4.3/storage/persistent_storage/persistent-storage-local.html" target="_blank" rel="noopener">OpenShift persistent storage using local volumes</a><br><a href="https://github.com/openshift/local-storage-operator/blob/master/docs/deploy-with-olm.md" target="_blank" rel="noopener">Deploy local-storage Operator</a></p>
<ol>
<li>install local storage operator (it is by default set in <code>local-storage</code> namespace)</li>
<li>provision the local storage</li>
<li>create local volume persistentVolumeClaim and attach to pod</li>
</ol>
<p>After deploy the operator, then<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## get hostname of each worker node</span></span><br><span class="line"><span class="comment">## can use label -l to filter worker node if needed</span></span><br><span class="line">kbc describe node | grep hostname</span><br></pre></td></tr></table></figure></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">"local.storage.openshift.io/v1"</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">"LocalVolume"</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">"local-disks"</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">"local-storage"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  nodeSelector:</span></span><br><span class="line"><span class="attr">    nodeSelectorTerms:</span></span><br><span class="line"><span class="attr">    - matchExpressions:</span></span><br><span class="line"><span class="attr">        - key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line"><span class="attr">          operator:</span> <span class="string">In</span></span><br><span class="line"><span class="attr">          values:</span></span><br><span class="line">          <span class="comment">## put hostname above here</span></span><br><span class="line"><span class="bullet">          -</span> <span class="string">worker0.jc-portworx.os.xx.com</span></span><br><span class="line"><span class="bullet">          -</span> <span class="string">worker1.jc-portworx.os.xx.com</span></span><br><span class="line"><span class="bullet">          -</span> <span class="string">worker2.jc-portworx.os.xx.com</span></span><br><span class="line"><span class="attr">  storageClassDevices:</span></span><br><span class="line"><span class="attr">    - storageClassName:</span> <span class="string">"local-sc"</span></span><br><span class="line"><span class="attr">      volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">      <span class="comment">## The file system that will be formatted when the local volume is mounted</span></span><br><span class="line"><span class="attr">      fsType:</span> <span class="string">xfs</span></span><br><span class="line"><span class="attr">      devicePaths:</span></span><br><span class="line">        <span class="comment">## use blkid command to get this devicePath</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">/dev/vdc</span></span><br></pre></td></tr></table></figure>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">blkid</span><br><span class="line"><span class="comment">## for clarity I remove unrelated output</span></span><br><span class="line"><span class="comment">## First colume is the device path</span></span><br><span class="line">/dev/vdc: LABEL=<span class="string">"mdvol"</span> UUID=<span class="string">"fdac344f-8d5f-48bd-9101-99cb416bb93d"</span> TYPE=<span class="string">"xfs"</span></span><br></pre></td></tr></table></figure></p>
<p>let’s check <code>/dev/vdc</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsblk /dev/vdc</span><br><span class="line"></span><br><span class="line">NAME MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">vdc  252:32   0  500G  0 disk</span><br></pre></td></tr></table></figure></p>
<p>After apply the CR <code>LocalVolume</code>, let’s check <code>local-storage</code> namespace status, you should see lcoal diskmaker and provisioner pods are up and running, corresponding PVs are ready as well.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-diskmaker-6787r         1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-diskmaker-jvwnq         1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-diskmaker-lfzq9         1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-provisioner-fzgs2       1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-provisioner-mqd86       1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-provisioner-t2bvz       1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-storage-operator-7f8dbfb95c-7brlv   1/1     Running   0          16h</span><br><span class="line"></span><br><span class="line"><span class="comment">## PV</span></span><br><span class="line"><span class="built_in">local</span>-pv-38162728                          500Gi      RWO            Delete           Available                                                     <span class="built_in">local</span>-sc                7m45s</span><br><span class="line"><span class="built_in">local</span>-pv-64bcf276                          500Gi      RWO            Delete           Available                                                     <span class="built_in">local</span>-sc                7m45s</span><br><span class="line"><span class="built_in">local</span>-pv-bd2d227                           500Gi      RWO            Delete           Available</span><br></pre></td></tr></table></figure></p>
<p>If things are all set, we can consume the local storage provisioned by local-sc. Here I use <code>volumeClaimTemplates</code> instead of create separate PVC (这里应该不能使用分开的PVC，因为PVC的创建和pod位于的node有关，事先并不知道). </p>
<blockquote>
<p>Notice that if there is one PV per node, then one PVC will consume the whole PV. So if use statefulset with volume claim template, we will only have one pod per node.</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-local-sc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">nginx</span> <span class="comment"># has to match .spec.template.metadata.labels</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span> <span class="comment"># by default is 1</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nginx</span> <span class="comment"># has to match .spec.selector.matchLabels</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">      securityContext:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">      serviceAccount:</span> <span class="string">wkc-iis-sa</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">wkc-iis-sa</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">xxx.swg.com/compute-image:b994-11_7_1_1-b191</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          allowPrivilegeEscalation:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">          privileged:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">          readOnlyRootFilesystem:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">          runAsNonRoot:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">          runAsUser:</span> <span class="number">10032</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">['/bin/sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'tail -f /dev/null'</span><span class="string">]</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">my-scratch</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/opt/xx/Scratch2</span></span><br><span class="line"><span class="attr">  volumeClaimTemplates:</span></span><br><span class="line"><span class="attr">  - metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">my-scratch</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">      storageClassName:</span> <span class="string">local-sc</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          storage:</span> <span class="number">5</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure>
<p>Now let’s check <code>/dev/vdc</code> again by <code>lsblk</code>, you will see it is associated with the pod.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>K8s No Route to Host</title>
    <url>/2019/08/19/k8s-no-route-to-host/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Today I set up a 4 nodes cluster that 3 nodes belong to the same group and one node from another group. It works fine:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAME                   STATUS   ROLES    AGE     VERSION</span><br><span class="line">dstest1.fyre.xxx.com   Ready    master   4h22m   v1.13.2</span><br><span class="line">dstest2.fyre.xxx.com   Ready    &lt;none&gt;   4h15m   v1.13.2</span><br><span class="line">dstest3.fyre.xxx.com   Ready    &lt;none&gt;   4h15m   v1.13.2</span><br><span class="line">opsf3.fyre.xxx.com     Ready    &lt;none&gt;   4h15m   v1.13.2</span><br></pre></td></tr></table></figure></p>
<p>After I scheduling a pod in <code>opsf3.fyre.xxx.com</code> and run <code>kubectl exec -it</code>, I get this error:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Error from server: error dialing backend: dial tcp 172.16.11.239:10250: connect: no route to host</span><br></pre></td></tr></table></figure></p>
<p>The reason is the firewall is active in <code>opsf3.fyre.xxx.com</code> if you check by running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl status firewalld</span><br></pre></td></tr></table></figure></p>
<p>Run below commands to stop and disable it, then thing get works.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Manages NFS</title>
    <url>/2020/01/21/k8s-nfs-example/</url>
    <content><![CDATA[<h2 id="Entry"><a href="#Entry" class="headerlink" title="Entry"></a>Entry</h2><p><a href="https://kubernetes.io/docs/concepts/storage/volumes/#nfs" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/storage/volumes/#nfs</a></p>
<p>这个demo很有意思，从之前来看，如果需要为K8s设置NFS，则我们需要一个physical NFS server，然后create PV based on that NFS server then PVC claim from PV. 这样需要自己去维护NFS的健康保证high availability.</p>
<p>这个例子完全将NFS交给了K8s来管理，它先提供一块存储去构造PVC(这块存储可能来自provisioner或者其他PV)，然后用这个PVC构造了一个NFS server pod以及给这个pod绑定了一个cluster IP，这样就相当于一个虚拟的physical NFS server node了。当我们需要PV的时候，就从这个NFS server pod中取(本质就是从一个PV中构造另一些PV)。</p>
<p>当然为了满足NFS的特性，这个NFS server的镜像必须要特别的构造，安装了NFS的组件，暴露相关端口，以及在初始化启动程序中配置好<code>/etc/export</code>的相关参数。以及当NFS server pod被重新构造时，保证之前的share不受影响。</p>
<p>这样的好处就是完全交给K8s去管理，不用担心NFS高可用性的问题，也不用自己去搭建物理的NFS cluster了，只要提供一块存储，就可以构造成NFS。</p>
<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>写这个blog的时候这个demo yaml中有一些错误参数，以我的blog准，这是demo git repository:<br><a href="https://github.com/kubernetes/examples/tree/master/staging/volumes/nfs" target="_blank" rel="noopener">https://github.com/kubernetes/examples/tree/master/staging/volumes/nfs</a></p>
<p>Under provisioner folder, it uses storageclass (internal provisioner) to create a PV, for example, in GCE:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-pv-provisioning-demo</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    demo:</span> <span class="string">nfs-pv-provisioning</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      storage:</span> <span class="number">20</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure></p>
<p>If no internal provisioner is available, you can create an external provisioner (for example: NFS), or just create a PV with hostPath:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-pv-provisioning-demo</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    demo:</span> <span class="string">nfs-pv-provisioning</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  capacity:</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="string">"20Gi"</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteOnce</span></span><br><span class="line"><span class="attr">  hostPath:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">"/nfs-server-pv"</span></span><br></pre></td></tr></table></figure></p>
<p>This <code>/nfs-server-pv</code> folder will be created on the host where nfs server pod reside. </p>
<p>Then it creates a <code>replicationController</code> for <strong>NFS server</strong> (just like a physical NFS server):<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-server</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    role:</span> <span class="string">nfs-server</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        role:</span> <span class="string">nfs-server</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nfs-server</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">k8s.gcr.io/volume-nfs:0.8</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">            containerPort:</span> <span class="number">2049</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">mountd</span></span><br><span class="line"><span class="attr">            containerPort:</span> <span class="number">20048</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">rpcbind</span></span><br><span class="line"><span class="attr">            containerPort:</span> <span class="number">111</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          privileged:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line">            <span class="comment">## the nfs exports folder</span></span><br><span class="line"><span class="attr">          - mountPath:</span> <span class="string">/exports</span></span><br><span class="line"><span class="attr">            name:</span> <span class="string">mypvc</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">mypvc</span></span><br><span class="line"><span class="attr">          persistentVolumeClaim:</span></span><br><span class="line">            <span class="comment">## mount the pvc from provisioner</span></span><br><span class="line"><span class="attr">            claimName:</span> <span class="string">nfs-pv-provisioning-demo</span></span><br></pre></td></tr></table></figure></p>
<p>Notice that the image is dedicated with nfs-utils pre-installed, and it expose some nfs dedicated ports, see the dockerfile:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">FROM</span> <span class="string">centos</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">yum</span> <span class="bullet">-y</span> <span class="string">install</span> <span class="string">/usr/bin/ps</span> <span class="string">nfs-utils</span> <span class="string">&amp;&amp;</span> <span class="string">yum</span> <span class="string">clean</span> <span class="string">all</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">mkdir</span> <span class="bullet">-p</span> <span class="string">/exports</span></span><br><span class="line"><span class="string">ADD</span> <span class="string">run_nfs.sh</span> <span class="string">/usr/local/bin/</span></span><br><span class="line"><span class="string">ADD</span> <span class="string">index.html</span> <span class="string">/tmp/index.html</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">chmod</span> <span class="number">644</span> <span class="string">/tmp/index.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## expose mountd 20048/tcp and nfsd 2049/tcp and rpcbind 111/tcp</span></span><br><span class="line"><span class="string">EXPOSE</span> <span class="number">2049</span><span class="string">/tcp</span> <span class="number">20048</span><span class="string">/tcp</span> <span class="number">111</span><span class="string">/tcp</span> <span class="number">111</span><span class="string">/udp</span></span><br><span class="line"><span class="comment">## init script to set up this nfs server</span></span><br><span class="line"><span class="string">ENTRYPOINT</span> <span class="string">["/usr/local/bin/run_nfs.sh",</span> <span class="string">"/exports"</span><span class="string">]</span></span><br></pre></td></tr></table></figure></p>
<p>Then create a service with cluster IP to expose the NFS server pod.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">  </span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-server</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">      port:</span> <span class="number">2049</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">mountd</span></span><br><span class="line"><span class="attr">      port:</span> <span class="number">20048</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">rpcbind</span></span><br><span class="line"><span class="attr">      port:</span> <span class="number">111</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    role:</span> <span class="string">nfs-server</span></span><br></pre></td></tr></table></figure></p>
<p>Then we can create application PV and PVC from this service:<br>refer to DNS for <a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/" target="_blank" rel="noopener">service and pod</a>.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  capacity:</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="number">1</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  nfs:</span></span><br><span class="line">    <span class="comment">## service name</span></span><br><span class="line">    <span class="comment">## 这里需要cluster IP，如果有其他DNS配置，可以直接用service name</span></span><br><span class="line"><span class="attr">    server:</span> <span class="string">&lt;nfs</span> <span class="string">server</span> <span class="string">service</span> <span class="string">cluster</span> <span class="string">IP&gt;</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">"/exports"</span></span><br></pre></td></tr></table></figure></p>
<p>Then you can create PVC bind this PV for other use.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Operator Learning</title>
    <url>/2020/01/23/k8s-operator/</url>
    <content><![CDATA[<p>我有另一篇blog专门记录了Kubernetes Operators这本书的总结:<br><a href="https://chengdol.github.io/2020/06/03/book-k8s-operator/" target="_blank" rel="noopener">Kubernetes Operators</a></p>
<p>根据书中资料总结的demo:<br><a href="https://github.com/chengdol/k8s-operator-sdk-demo" target="_blank" rel="noopener">https://github.com/chengdol/k8s-operator-sdk-demo</a></p>
<p>最近安排我去写一个operator的任务，最开始是helm-based operator, then evolve to Go-based, 挺有意思。How to explain Kubernetes Operators in plain English:<br><a href="https://enterprisersproject.com/article/2019/2/kubernetes-operators-plain-english" target="_blank" rel="noopener">https://enterprisersproject.com/article/2019/2/kubernetes-operators-plain-english</a></p>
<p>Brief introduction:<br><a href="https://www.youtube.com/watch?v=DhvYfNMOh6A" target="_blank" rel="noopener">https://www.youtube.com/watch?v=DhvYfNMOh6A</a></p>
<p>首先，从K8s官网上粗略地了解一下什么是:</p>
<ul>
<li><p><a href="https://docs.openshift.com/container-platform/4.4/operators/operator_sdk/osdk-getting-started.html" target="_blank" rel="noopener">Getting started with the Operator SDK</a><br>This is from Red Hat, excellent!</p>
</li>
<li><p><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/" target="_blank" rel="noopener">Operator pattern</a></p>
<p>Advanced Operators are designed to handle upgrades seamlessly, react to failures automatically, and not take shortcuts, like skipping a software backup process to save time.</p>
<p>Complex and stateful applications are where an Operator can shine. The cloud-like capabilities that are encoded into the Operator code can provide an advanced user experience, automating such features as updates, backups and scaling.</p>
</li>
<li><p><a href="https://coreos.com/blog/introducing-operators.html" target="_blank" rel="noopener">Introducing Operators: Putting Operational Knowledge into Software</a></p>
</li>
<li><p><a href="https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-building-kubernetes-operators-and-stateful-apps" target="_blank" rel="noopener">Best practices for building Kubernetes Operators and stateful apps</a></p>
</li>
<li><p><a href="https://www.openshift.com/blog/tag/operators" target="_blank" rel="noopener">OpenShift operator special</a></p>
</li>
</ul>
<p>CNCF:</p>
<ul>
<li><p><a href="https://www.youtube.com/watch?v=wMqzAOp15wo" target="_blank" rel="noopener">Writing a Kubernetes Operator: the Hard Parts</a></p>
</li>
<li><p><a href="https://www.openshift.com/blog/build-kubernetes-operators-from-helm-charts-in-5-steps" target="_blank" rel="noopener">Build Kubernetes Operators from Helm Charts in 5 steps</a><br>However when it comes to stateful applications there is more to the upgrade process than upgrading the application itself.</p>
<p>Helm Charts often are insufficient for upgrading stateful applications and services (e.g. PostgreSQL or Elasticsearch) which require a complex and controlled upgrade processes beyond upgrading the application version. </p>
</li>
</ul>
<p>一些中文资料，最近在看书Kuberneter Operators，然后被Go卡主了，准备开始学习:</p>
<ul>
<li><a href="https://studygolang.com/articles/22798?fr=sidebar" target="_blank" rel="noopener">如何在kubernetes中开发自己的Operator</a><br>提到了如何用go去写，但很简略，只能给个大致图像</li>
<li><a href="https://studygolang.com/topics" target="_blank" rel="noopener">Go 语言中文网</a></li>
<li><a href="http://dockone.io/article/8733" target="_blank" rel="noopener">自己动手写Operator</a></li>
<li><a href="https://www.jianshu.com/p/27fc6834479b" target="_blank" rel="noopener">Kubernetes API 与 Operator，不为人知的开发者战争</a></li>
<li><a href="https://www.jianshu.com/p/628aac3e6758" target="_blank" rel="noopener">Kubernetes Operator 快速入门教程</a></li>
</ul>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Set Up K8s Cluster by Kubeadm</title>
    <url>/2018/12/17/k8s-kubeadm-setup/</url>
    <content><![CDATA[<p>How to be a contribution beginner on k8s?<br><a href="https://youtu.be/o68ff5NokR8" target="_blank" rel="noopener">https://youtu.be/o68ff5NokR8</a></p>
<ol>
<li>find issues, search label <code>good first issue</code></li>
<li>communication</li>
<li>build relationships</li>
</ol>
<p><strong>Kubernetes version 1.13.2</strong><br>This article mainly talks about setting up k8s cluster by <code>kubeadm</code> manually. As far as I know there are no coming changes that will significantly impact the validity of these steps.</p>
<h2 id="Cluster-Info"><a href="#Cluster-Info" class="headerlink" title="Cluster Info"></a>Cluster Info</h2><p>I have a 3 nodes bare-metal cluster called <code>myk8s</code> with <strong>CentOS</strong> version 7.5, the <code>/etc/hosts</code> file in each node:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">172.16.158.44    myk8s1.fyre.ibm.com myk8s1</span><br><span class="line">172.16.171.110   myk8s2.fyre.ibm.com myk8s2</span><br><span class="line">172.16.171.227   myk8s3.fyre.ibm.com myk8s3</span><br></pre></td></tr></table></figure></p>
<p>Let’ see the network interface on master node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## ifconfig -a</span></span><br><span class="line"></span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.16.158.44  netmask 255.255.0.0  broadcast 172.16.255.255</span><br><span class="line">        ether 00:16:3e:01:9e:2c  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 1617615790  bytes 203050237209 (189.1 GiB)</span><br><span class="line">        RX errors 0  dropped 1  overruns 0  frame 0</span><br><span class="line">        TX packets 436  bytes 50037 (48.8 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 9.30.97.218  netmask 255.255.254.0  broadcast 9.30.97.255</span><br><span class="line">        ether 00:20:09:1e:61:da  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 13350021  bytes 1424223654 (1.3 GiB)</span><br><span class="line">        RX errors 0  dropped 5  overruns 0  frame 0</span><br><span class="line">        TX packets 246436  bytes 45433438 (43.3 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h2 id="Configure"><a href="#Configure" class="headerlink" title="Configure"></a>Configure</h2><blockquote>
<p>For <strong>every</strong> node in cluster, following instruction below</p>
</blockquote>
<h3 id="Install-utilities"><a href="#Install-utilities" class="headerlink" title="Install utilities"></a>Install utilities</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum update -y</span><br><span class="line">yum install -y vim</span><br><span class="line">yum install -y git</span><br></pre></td></tr></table></figure>
<h3 id="Disable-firewall"><a href="#Disable-firewall" class="headerlink" title="Disable firewall"></a>Disable firewall</h3><p>Check firewall status and disable it if active<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl status firewalld</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure>
<h3 id="Install-kubeadm-kubectl-and-kubelet"><a href="#Install-kubeadm-kubectl-and-kubelet" class="headerlink" title="Install kubeadm kubectl and kubelet"></a>Install kubeadm kubectl and kubelet</h3><blockquote>
<p><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/" target="_blank" rel="noopener">Install kubeadm</a> </p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span><br><span class="line">exclude=kube*</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set SELinux in permissive mode (effectively disabling it)</span></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">'s/^SELINUX=enforcing$/SELINUX=permissive/'</span> /etc/selinux/config</span><br><span class="line"></span><br><span class="line">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> --now kubelet</span><br></pre></td></tr></table></figure>
<p>Setting SELinux in permissive mode by running <code>setenforce 0</code> and <code>sed ...</code> effectively disables it. This is required to allow containers to access the host filesystem, which is needed by pod networks for example. You have to do this until SELinux support is improved in the kubelet.</p>
<p>Currently installed:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Installed:</span><br><span class="line">  kubeadm.x86_64 0:1.13.3-0               kubectl.x86_64 0:1.13.3-0               kubelet.x86_64 0:1.13.3-0</span><br></pre></td></tr></table></figure></p>
<p>check <code>/etc/sysctl.conf</code> file, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">net.ipv6.conf.all.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 1</span><br><span class="line">net.ipv4.ip_forward = 0</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>ensure that these 3 options exist and set to 1, because some users on RHEL/CentOS 7 have reported issues with traffic being routed incorrectly due to iptables being bypassed<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure></p>
<p>if these 3 items not set, edit <code>net.ipv4.ip_forward = 1</code> and append <code>net.bridge.bridge-nf-call-ip6tables = 1</code> and <code>net.bridge.bridge-nf-call-iptables = 1</code> in <code>sysctl.conf</code> file</p>
<p>then make sure that the <code>net.bridge.bridge-nf-call</code> is enabled, check if <code>br_netfilter</code> module is loaded. This can be done by running<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsmod | grep br_netfilter</span><br></pre></td></tr></table></figure></p>
<p>if not, to load it explicitly call<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">modprobe br_netfilter</span><br></pre></td></tr></table></figure></p>
<p>next run this command to reload setting<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl --system</span><br></pre></td></tr></table></figure></p>
<p>then you can check the final setting:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sysctl -a | grep -E <span class="string">"net.bridge|net.ipv4.ip_forward"</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Install-docker"><a href="#Install-docker" class="headerlink" title="Install docker"></a>Install docker</h3><blockquote>
<p><a href="https://kubernetes.io/docs/setup/cri/#docker" target="_blank" rel="noopener">CRI installation in Kubernetes</a></p>
</blockquote>
<h4 id="Uninstall-old-versions"><a href="#Uninstall-old-versions" class="headerlink" title="Uninstall old versions"></a>Uninstall old versions</h4><p>Older versions of Docker were called docker or docker-engine. If these are installed, uninstall them, along with associated dependencies.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><a href="https://docs.docker.com/install/linux/docker-ce/centos/" target="_blank" rel="noopener">Official Docker installation guides</a></p>
</blockquote>
<h4 id="Install-Docker-CE"><a href="#Install-Docker-CE" class="headerlink" title="Install Docker CE"></a>Install Docker CE</h4><p>currently Docker version <code>18.06.2</code> is recommended, but 1.11, 1.12, 1.13 and 17.03 are known to work as well. Keep track of the latest verified Docker version in the Kubernetes release notes<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Set up the repository</span></span><br><span class="line">yum install yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"></span><br><span class="line"><span class="comment">## Add docker repository.</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line"><span class="comment">## Install docker ce.</span></span><br><span class="line">yum update &amp;&amp; yum install docker-ce-18.06.2.ce</span><br><span class="line"></span><br><span class="line"><span class="comment">## Create /etc/docker directory.</span></span><br><span class="line">mkdir /etc/docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup daemon.</span></span><br><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line">  <span class="string">"log-driver"</span>: <span class="string">"json-file"</span>,</span><br><span class="line">  <span class="string">"log-opts"</span>: &#123;</span><br><span class="line">    <span class="string">"max-size"</span>: <span class="string">"100m"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"storage-driver"</span>: <span class="string">"overlay2"</span>,</span><br><span class="line">  <span class="string">"storage-opts"</span>: [</span><br><span class="line">    <span class="string">"overlay2.override_kernel_check=true"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">mkdir -p /etc/systemd/system/docker.service.d</span><br><span class="line"></span><br><span class="line"><span class="comment"># Restart docker.</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></p>
<p>check result<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] docker version</span><br><span class="line">Client:</span><br><span class="line"> Version:           18.06.2-ce</span><br><span class="line"> API version:       1.38</span><br><span class="line"> Go version:        go1.10.3</span><br><span class="line"> Git commit:        6d37f41</span><br><span class="line"> Built:             Sun Feb 10 03:46:03 2019</span><br><span class="line"> OS/Arch:           linux/amd64</span><br><span class="line"> Experimental:      false</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          18.06.2-ce</span><br><span class="line">  API version:      1.38 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.10.3</span><br><span class="line">  Git commit:       6d37f41</span><br><span class="line">  Built:            Sun Feb 10 03:48:29 2019</span><br><span class="line">  OS/Arch:          linux/amd64</span><br><span class="line">  Experimental:     false</span><br></pre></td></tr></table></figure></p>
<h3 id="Disable-swap"><a href="#Disable-swap" class="headerlink" title="Disable swap"></a>Disable swap</h3><p><a href="https://serverfault.com/questions/881517/why-disable-swap-on-kubernetes" target="_blank" rel="noopener"><strong>why we need to disable swap?</strong> </a><br>The idea of Kubernetes is to tightly pack instances to as close to 100% utilized as possible. All deployments should be pinned with CPU/memory limits. So if the scheduler sends a pod to a machine it should never use swap at all. You don’t want to swap since it’ll slow things down. It’s mainly for performance.</p>
<p>in <code>/etc/fstab</code> file, comment out swap setting<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/dev/mapper/centos-swap swap                    swap    defaults        0 0</span><br></pre></td></tr></table></figure></p>
<p>activate new configuration and check<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">swapoff -a</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s3 ~] free -h</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           7.6G        189M        5.7G        136M        1.8G        7.0G</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure>
<blockquote>
<p> for <code>worker</code> nodes in cluster, stop here. Continue steps in <code>master</code> node:</p>
</blockquote>
<h2 id="Initialize-kubernetes-cluster"><a href="#Initialize-kubernetes-cluster" class="headerlink" title="Initialize kubernetes cluster"></a>Initialize kubernetes cluster</h2><p>I will use <code>Calico</code> as the container network solution, in master node, run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm init --pod-network-cidr=192.168.0.0/16</span><br></pre></td></tr></table></figure></p>
<p>you can specify the version by using <code>--kubernetes-version v1.13.3</code>, otherwise it will pull latest version from Internet.</p>
<p>you can see the output like this<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">[kubeconfig] Using kubeconfig folder <span class="string">"/etc/kubernetes"</span></span><br><span class="line">[kubeconfig] Writing <span class="string">"admin.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"kubelet.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"controller-manager.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"scheduler.conf"</span> kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-apiserver"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-controller-manager"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-scheduler"</span></span><br><span class="line">[etcd] Creating static Pod manifest <span class="keyword">for</span> <span class="built_in">local</span> etcd <span class="keyword">in</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of machines by running the following on each node</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 9.30.97.218:6443 --token jjkiw2.n478eree0wrr3bmc --discovery-token-ca-cert-hash sha256:79659fb0b3fb0044f382ab5a5e317d4f775e821a61d0df4a401a4cbd8d8c5a7f</span><br></pre></td></tr></table></figure></p>
<p>keep the last command for joining worker node later<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubeadm join 9.30.97.218:6443 --token jjkiw2.n478eree0wrr3bmc --discovery-token-ca-cert-hash sha256:79659fb0b3fb0044f382ab5a5e317d4f775e821a61d0df4a401a4cbd8d8c5a7f</span><br></pre></td></tr></table></figure></p>
<p>then run following command in master node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure></p>
<p>now if you run <code>kubectl version</code>, you will get something like below:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] kubectl version</span><br><span class="line">Client Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;13&quot;, GitVersion:&quot;v1.13.3&quot;, GitCommit:&quot;721bfa751924da8d1680787490c54b9179b1fed0&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2019-02-01T20:08:12Z&quot;, GoVersion:&quot;go1.11.5&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;</span><br><span class="line">Server Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;13&quot;, GitVersion:&quot;v1.13.3&quot;, GitCommit:&quot;721bfa751924da8d1680787490c54b9179b1fed0&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2019-02-01T20:00:57Z&quot;, GoVersion:&quot;go1.11.5&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;</span><br></pre></td></tr></table></figure></p>
<p>let’s check what kind of docker images pulled from network to create the cluster in master<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] docker images</span><br><span class="line">REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">k8s.gcr.io/kube-apiserver            v1.13.3             fe242e556a99        2 weeks ago         181MB</span><br><span class="line">k8s.gcr.io/kube-controller-manager   v1.13.3             0482f6400933        2 weeks ago         146MB</span><br><span class="line">k8s.gcr.io/kube-proxy                v1.13.3             98db19758ad4        2 weeks ago         80.3MB</span><br><span class="line">k8s.gcr.io/kube-scheduler            v1.13.3             3a6f709e97a0        2 weeks ago         79.6MB</span><br><span class="line">k8s.gcr.io/coredns                   1.2.6               f59dcacceff4        3 months ago        40MB</span><br><span class="line">k8s.gcr.io/etcd                      3.2.24              3cab8e1b9802        4 months ago        220MB</span><br><span class="line">k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        14 months ago       742kB</span><br></pre></td></tr></table></figure></p>
<h2 id="Launch-cluster-network"><a href="#Launch-cluster-network" class="headerlink" title="Launch cluster network"></a>Launch cluster network</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## kubectl get pods --all-namespaces</span></span><br><span class="line">NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-86c58d9df4-5dfh9                      0/1     Pending   0          9m30s</span><br><span class="line">kube-system   coredns-86c58d9df4-d9bfm                      0/1     Pending   0          9m30s</span><br><span class="line">kube-system   etcd-myk8s1.fyre.ibm.com                      1/1     Running   0          8m52s</span><br><span class="line">kube-system   kube-apiserver-myk8s1.fyre.ibm.com            1/1     Running   0          8m37s</span><br><span class="line">kube-system   kube-controller-manager-myk8s1.fyre.ibm.com   1/1     Running   0          8m34s</span><br><span class="line">kube-system   kube-proxy-wxjx8                              1/1     Running   0          9m31s</span><br><span class="line">kube-system   kube-scheduler-myk8s1.fyre.ibm.com            1/1     Running   0          8m46s</span><br></pre></td></tr></table></figure>
<p>you can find some pods are not ready, for example <code>coredns-86c58d9df4-5dfh9</code> and <code>coredns-86c58d9df4-d9bfm</code>, also the master node<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] kubectl get nodes</span><br><span class="line">NAME                  STATUS     ROLES    AGE   VERSION</span><br><span class="line">myk8s1.fyre.ibm.com   NotReady   master   11m   v1.13.3</span><br></pre></td></tr></table></figure></p>
<p>it’s time to set up network, you should first figure out which <code>Calico</code> version you need, check kubernetes <a href="https://kubernetes.io/docs/setup/release/notes/" target="_blank" rel="noopener">release note</a>, we see currently it support <code>Calico</code> version 3.3.1:</p>
<p><img src="https://drive.google.com/uc?id=1pl6EV9YwD604U1ItoMKnqlAp0cjwEOAd" alt=""></p>
<p> you can also refer this <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network" target="_blank" rel="noopener">link</a> to install, it’s the same setting as below:<br><img src="https://drive.google.com/uc?id=11R3h2G2oknDcN3sY1cTdwUHQCnxwRysn" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml</span><br><span class="line">kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml</span><br></pre></td></tr></table></figure>
<p>after applying <code>rbac-kdd.yaml</code> and <code>calico.yaml</code>, now you can see<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## kubectl get pods --all-namespaces</span></span><br><span class="line">NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-node-4vm2c                             2/2     Running   0          45s</span><br><span class="line">kube-system   coredns-86c58d9df4-5dfh9                      1/1     Running   0          37m</span><br><span class="line">kube-system   coredns-86c58d9df4-d9bfm                      1/1     Running   0          37m</span><br><span class="line">kube-system   etcd-myk8s1.fyre.ibm.com                      1/1     Running   0          36m</span><br><span class="line">kube-system   kube-apiserver-myk8s1.fyre.ibm.com            1/1     Running   0          36m</span><br><span class="line">kube-system   kube-controller-manager-myk8s1.fyre.ibm.com   1/1     Running   0          36m</span><br><span class="line">kube-system   kube-proxy-wxjx8                              1/1     Running   0          37m</span><br><span class="line">kube-system   kube-scheduler-myk8s1.fyre.ibm.com            1/1     Running   0          36m</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## kubectl get nodes</span></span><br><span class="line">NAME                  STATUS   ROLES    AGE   VERSION</span><br><span class="line">myk8s1.fyre.ibm.com   Ready    master   38m   v1.13.3</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note that I encountered the problem that when join the worker nodes, the <code>calico-node</code> becomes not ready<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## kubectl get pods --all-namespaces</span></span><br><span class="line">NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-node-4vm2c                             1/2     Running   0          11m</span><br><span class="line">kube-system   calico-node-zsbjj                             1/2     Running   0          96s</span><br><span class="line">kube-system   coredns-86c58d9df4-5dfh9                      1/1     Running   0          48m</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>The reason is my master node has multiple <code>eth</code>, I need to specify which one to use in order to be consistent among all nodes.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml</span><br></pre></td></tr></table></figure></p>
<p>delete the previous <code>Calico</code> deployment and then edit and apply yaml file again:</p>
<p><img src="https://drive.google.com/uc?id=1bPLxrrlLLyFvNn6cBdSIJbWpANy-ht4h" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] kubectl get pods --all-namespaces</span><br><span class="line">NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-node-dpcsp                             2/2     Running   0          6m15s</span><br><span class="line">kube-system   calico-node-gc5hs                             2/2     Running   0          6m15s</span><br><span class="line">kube-system   coredns-86c58d9df4-5dfh9                      1/1     Running   0          81m</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="Join-worker-nodes"><a href="#Join-worker-nodes" class="headerlink" title="Join worker nodes"></a>Join worker nodes</h2><p>Join worker nodes is pretty easy, run this command on all worker nodes:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubeadm join 9.30.97.218:6443 --token jjkiw2.n478eree0wrr3bmc --discovery-token-ca-cert-hash sha256:79659fb0b3fb0044f382ab5a5e317d4f775e821a61d0df4a401a4cbd8d8c5a7f</span><br></pre></td></tr></table></figure></p>
<p>Check node status<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## kubectl get nodes</span></span><br><span class="line">NAME                  STATUS   ROLES    AGE   VERSION</span><br><span class="line">myk8s1.fyre.ibm.com   Ready    master   83m   v1.13.3</span><br><span class="line">myk8s2.fyre.ibm.com   Ready    &lt;none&gt;   36m   v1.13.3</span><br><span class="line">myk8s3.fyre.ibm.com   Ready    &lt;none&gt;   33s   v1.13.3</span><br></pre></td></tr></table></figure></p>
<p>By default, tokens expire after 24 hours. If you are joining a node to the cluster after the current token has expired, you can create a new token by running the following command on the master node<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm token create</span><br></pre></td></tr></table></figure></p>
<p>If you don’t have the value of <code>--discovery-token-ca-cert-hash</code>, you can get it by running the following command chain on the master node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openssl x509 -pubkey -<span class="keyword">in</span> /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | \</span><br><span class="line">   openssl dgst -sha256 -hex | sed <span class="string">'s/^.* //'</span></span><br></pre></td></tr></table></figure></p>
<p>Now a fresh kubernetes cluster with 1 master and 2 worker nodes is created.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>calico</tag>
        <tag>kubeadm</tag>
      </tags>
  </entry>
  <entry>
    <title>RBAC Authorization for K8s API Access</title>
    <url>/2019/01/27/k8s-role-rbac/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>We want to <strong>scale the compute pods by calling k8s API from inside the engine conductor container</strong>, this definitely need to be authorized and we need to grant privilege for this action.</p>
<p>There are some concepts you need to know in order to achieve the goal.</p>
<h2 id="Service-Account"><a href="#Service-Account" class="headerlink" title="Service Account"></a>Service Account</h2><blockquote>
<p><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/" target="_blank" rel="noopener">what is Service Account</a></p>
</blockquote>
<p>Processes in containers inside pods can contact the apiserver. When they do, they are authenticated as a particular service account (for example, by default is <code>default</code> service account).</p>
<p>Once you create a namespace, for example <code>test-1</code>, there is a <code>default</code> service account automatically generated.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get sa -n <span class="built_in">test</span>-1</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NAME      SECRETS   AGE</span><br><span class="line">default   1         139m</span><br></pre></td></tr></table></figure>
<p>let’s see what is inside the service account<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl describe sa default -n <span class="built_in">test</span>-1</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Name:                default</span><br><span class="line">Namespace:           <span class="built_in">test</span>-1</span><br><span class="line">Labels:              &lt;none&gt;</span><br><span class="line">Annotations:         &lt;none&gt;</span><br><span class="line">Image pull secrets:  &lt;none&gt;</span><br><span class="line">Mountable secrets:   default-token-mtv4n</span><br><span class="line">Tokens:              default-token-mtv4n</span><br><span class="line">Events:              &lt;none&gt;</span><br></pre></td></tr></table></figure>
<p>Here we see there is a mountable secret <code>default-token-mtv4n</code>, that is the credentials to access the apiserver.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl describe secret default-token-mtv4n -n <span class="built_in">test</span>-1</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Name:         default-token-mtv4n</span><br><span class="line">Namespace:    <span class="built_in">test</span>-1</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: default</span><br><span class="line">              kubernetes.io/service-account.uid: 387381d3-2272-11e9-91a2-00163e0196e7</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  6 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrd...</span><br></pre></td></tr></table></figure>
<h2 id="ClusterRole"><a href="#ClusterRole" class="headerlink" title="ClusterRole"></a>ClusterRole</h2><blockquote>
<p><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#role-and-clusterrole" target="_blank" rel="noopener">what is Role and ClusterRole</a></p>
</blockquote>
<p>A <code>ClusterRole</code> can be used to grant the same permissions as a <code>Role</code>, but because they are <code>cluster-scoped</code>, they can also be used to grant access to</p>
<ul>
<li>cluster-scoped resources (like nodes)</li>
<li>non-resource endpoints (like “/healthz”)</li>
<li>namespaced resources (like pods) across all namespaces</li>
</ul>
<p>Here we use a cluster role called <code>cluster-admin</code>, it’s generated by default<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get clusterrole | grep cluster-admin</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cluster-admin                        174m</span><br></pre></td></tr></table></figure>
<h2 id="ClusterRole-Binding"><a href="#ClusterRole-Binding" class="headerlink" title="ClusterRole Binding"></a>ClusterRole Binding</h2><blockquote>
<p><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#rolebinding-and-clusterrolebinding" target="_blank" rel="noopener">what is RoleBinding and ClusterRole Binding</a></p>
</blockquote>
<p>A role binding grants the permissions defined in a role to a user or set of users. It holds a list of subjects (users, groups, or service accounts), and a reference to the role being granted. Permissions can be granted within a namespace with a <code>RoleBinding</code>, or cluster-wide with a <code>ClusterRoleBinding</code>.</p>
<p>below we grant service account <code>default</code> in namespace <code>test-1</code> the <code>cluster-admin</code> level privilege.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">&lt;cluster</span> <span class="string">role</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">&lt;key:value&gt;</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"> <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">   name:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">   namespace:</span> <span class="string">&lt;namespace</span> <span class="string">of</span> <span class="string">sa&gt;</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-admin</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure></p>
<p>then we can write a script, using <code>curl</code> to call K8s API, for example, to scale the number of compute pods:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http_code=$(curl -w <span class="string">"%&#123;http_code&#125;"</span> -sS  --cacert <span class="variable">$CACERT</span>  -XPATCH -H <span class="string">"Content-Type: application/strategic-merge-patch+json"</span> -H <span class="string">"Accept: application/json"</span> -H <span class="string">"Authorization: Bearer <span class="variable">$TOKEN</span>"</span> <span class="string">"https://kubernetes.default/apis/apps/v1/namespaces/<span class="variable">$NAMESPACE</span>/statefulsets/is-engine-compute"</span> --data <span class="string">"&#123;\"spec\":&#123;\"replicas\":<span class="variable">$REP</span>&#125;&#125;"</span> -o <span class="variable">$OUT_FILE</span>)</span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$http_code</span> -ne 200 ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="variable">$&#123;JQ&#125;</span> <span class="string">'&#123; result:.status, code: .code,  message: .message &#125;'</span> <span class="variable">$OUT_FILE</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<p>Where are these <code>CACERT</code>, <code>TOEKN</code> and <code>NAMESPACE</code> from? Actually each container has a default mount point reside in:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/var/run/secrets/kubernetes.io/serviceaccount</span><br></pre></td></tr></table></figure></p>
<p>You can see this when you run <code>kubectl describe pod</code>. Just like other mount files, there are 3 files, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">total 0</span><br><span class="line">lrwxrwxrwx 1 root root 13 Sep 14 16:21 ca.crt -&gt; ..data/ca.crt</span><br><span class="line">lrwxrwxrwx 1 root root 16 Sep 14 16:21 namespace -&gt; ..data/namespace</span><br><span class="line">lrwxrwxrwx 1 root root 12 Sep 14 16:21 token -&gt; ..data/token</span><br></pre></td></tr></table></figure></p>
<p>All of them are used in <code>curl</code> command above.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAMESPACE=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)</span><br><span class="line">CACERT=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>RBAC</tag>
        <tag>service account</tag>
      </tags>
  </entry>
  <entry>
    <title>Patch K8s Objects in Place</title>
    <url>/2020/02/07/k8s-patch-object/</url>
    <content><![CDATA[<p>For updating components secret or configmap, you can do complete replace:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get secret docker-registry-auth -o yaml -n default \</span><br><span class="line">        | sed -e <span class="string">"/htpasswd/c\  htpasswd: <span class="variable">$&#123;AUTH_BASE64&#125;</span>"</span> \</span><br><span class="line">        | kubectl replace -f -</span><br><span class="line">kubectl get configmap repl-pod-map -n <span class="variable">$NAMESPACE</span> -o yaml </span><br><span class="line">        | sed -e <span class="string">"/<span class="variable">$&#123;POD_NAME&#125;</span>/d"</span> </span><br><span class="line">        | kubectl replace -f-</span><br></pre></td></tr></table></figure></p>
<p>For patching pod controller like deployment and statefulset, see:<br><a href="https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/</a></p>
<h2 id="Strategic-merge-patch"><a href="#Strategic-merge-patch" class="headerlink" title="Strategic merge patch"></a>Strategic merge patch</h2><p>For example, add one more containers in the pod, give the yaml file <code>patch-file.yaml</code>:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">patch-demo-ctr-2</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">redis</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># this command use default patch strategy for containers field: merge</span></span><br><span class="line">kubectl patch deployment patch-demo --patch <span class="string">"<span class="variable">$(cat patch-file.yaml)</span>"</span></span><br></pre></td></tr></table></figure>
<p>This will get merged not replaced (the original container is kept), but not all fields have <code>merge</code> strategy, some use default strategy that is <code>replace</code>, for example: tolerations field.</p>
<p>How to know the patch strategy of each field?<br>see <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/" target="_blank" rel="noopener">API document</a><br>It seems not all fields have specified patch strategy, for example, I don’t see that on configmap.</p>
<h2 id="Json-merge-patch"><a href="#Json-merge-patch" class="headerlink" title="Json merge patch"></a>Json merge patch</h2><p>A strategic merge patch is different from a JSON merge patch. With a JSON merge patch, if you want to update a list, you have to specify the <code>entire new list</code>. And the new list completely replaces the existing list.</p>
<p>The <code>kubectl patch</code> command has a <code>--type</code> parameter that you can set to one of these values:</p>
<ol>
<li>json (json patch)</li>
<li>merge (json merge patch)</li>
<li>strategic (default)</li>
</ol>
<blockquote>
<p>这里文档有问题，如果用json merge patch on configmap，其实还是做的merge操作(之前的数据被保留)，并不是replace.这个值得注意，比如以下2个commands效果是一样的:<br>  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## json merge patch</span></span><br><span class="line">kubectl patch configmap repl-pod-map -n pines --<span class="built_in">type</span> merge -p <span class="string">"&#123;\"data\": &#123;\"test1\":\"test1key\"&#125;&#125;"</span></span><br><span class="line"><span class="comment">## defaul strategic patch</span></span><br><span class="line">kubectl patch configmap repl-pod-map -n pines  -p <span class="string">"&#123;\"data\": &#123;\"test1\":\"test1key\"&#125;&#125;"</span></span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>  我猜可能是configmap没有明确的patch strategy定义，但对于其他有明确定义的field，则json merge patch会replace之前的数据。</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>patch</tag>
      </tags>
  </entry>
  <entry>
    <title>Set up Secure Docker Registry in K8s</title>
    <url>/2020/01/06/k8s-secure-registry/</url>
    <content><![CDATA[<p>The step to set up secure docker registry service in K8s is different from docker. There are some adjustments and changes to apply.</p>
<p>Toolkits we need to achieve our goal:</p>
<ol>
<li>openssl</li>
<li>htpasswd</li>
<li>skopeo</li>
</ol>
<h2 id="Create-SSL-TLS-Certificate-and-Key"><a href="#Create-SSL-TLS-Certificate-and-Key" class="headerlink" title="Create SSL/TLS Certificate and Key"></a>Create SSL/TLS Certificate and Key</h2><p>Use openssl command to generate certificate and private key for setup secure connection:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create certs</span></span><br><span class="line">mkdir -p /root/registry-certs</span><br><span class="line"><span class="comment">## get from master</span></span><br><span class="line"></span><br><span class="line">DOCKER_REGISTRY_URL=blair1.fyre.com</span><br><span class="line"><span class="comment">## make a copy of .crt and give suffix .cert</span></span><br><span class="line">openssl req \</span><br><span class="line">        -newkey rsa:4096 -nodes -x509 -sha256 \</span><br><span class="line">        -keyout /root/registry-certs/tls.key \</span><br><span class="line">        -out /root/registry-certs/tls.cert \</span><br><span class="line">        -days 3650 \</span><br><span class="line">        -subj <span class="string">"/C=US/ST=CA/L=San Jose/O=IBM/OU=Org/CN=<span class="variable">$&#123;DOCKER_REGISTRY_URL&#125;</span>"</span></span><br><span class="line"></span><br><span class="line">cp /root/registry-certs/tls.cert /root/registry-certs/tls.crt</span><br></pre></td></tr></table></figure></p>
<p>Then copy the crt file to every host under <code>/etc/docker/certs.d/&lt;${DOCKER_REGISTRY_URL}&gt;:5000</code> folder for self-signed certificate trust.</p>
<blockquote>
<p>Notice that if the docker daemon json file has enabled the insecure registry, it will not verify the ssl/tls cert! You get docker user account and password, then you can login without certs!</p>
</blockquote>
<h2 id="Create-Docker-User-Info"><a href="#Create-Docker-User-Info" class="headerlink" title="Create Docker User Info"></a>Create Docker User Info</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">##  create auth file</span></span><br><span class="line">DOCKER_USER=demo</span><br><span class="line">DOCKER_PASSWORD=demo</span><br><span class="line"></span><br><span class="line">mkdir -p /tmp/registry-auth</span><br><span class="line">htpasswd -Bbn <span class="variable">$&#123;DOCKER_USER&#125;</span> <span class="variable">$&#123;DOCKER_PASSWORD&#125;</span> &gt; /tmp/registry-auth/htpasswd</span><br></pre></td></tr></table></figure>
<h2 id="Generate-Secret"><a href="#Generate-Secret" class="headerlink" title="Generate Secret"></a>Generate Secret</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create secrets</span></span><br><span class="line"><span class="comment">## we want to setup docker registry in default namespace</span></span><br><span class="line">kubectl create secret tls docker-registry-tls  \</span><br><span class="line">    --key=/root/registry-certs/tls.key  \</span><br><span class="line">    --cert=/root/registry-certs/tls.cert \</span><br><span class="line">    -n default</span><br><span class="line"></span><br><span class="line">kubetctl create secret generic docker-registry-auth \</span><br><span class="line">    --from-file=htpasswd=/tmp/registry-auth/htpasswd \</span><br><span class="line">    -n default</span><br><span class="line"></span><br><span class="line"><span class="comment">## Assume the working namespace is test-1</span></span><br><span class="line">WORKING_NAME_SPACE=<span class="built_in">test</span>-1</span><br><span class="line">DOCKER_REGISTRY_SERVER=<span class="string">"<span class="variable">$&#123;DOCKER_REGISTRY_URL&#125;</span>:5000"</span></span><br><span class="line"></span><br><span class="line">kubectl create namespace <span class="variable">$&#123;NAME_SPACE&#125;</span></span><br><span class="line">kubectl create secret docker-registry docker-registry-creds \</span><br><span class="line">        --docker-server=<span class="variable">$DOCKER_REGISTRY_SERVER</span> \</span><br><span class="line">        --docker-username=<span class="variable">$DOCKER_USER</span> \</span><br><span class="line">        --docker-password=<span class="variable">$DOCKER_PASSWORD</span> \</span><br><span class="line">        -n <span class="variable">$&#123;WORKING_NAME_SPACE&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="Bind-Image-Pull-Secret-to-Service-Account"><a href="#Bind-Image-Pull-Secret-to-Service-Account" class="headerlink" title="Bind Image Pull Secret to Service Account"></a>Bind Image Pull Secret to Service Account</h2><p>see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account" target="_blank" rel="noopener">document</a> in K8s.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## patch creds to default service account in test-1</span></span><br><span class="line"><span class="comment">## assume we use default service account in yaml</span></span><br><span class="line">kubectl patch serviceaccount default \</span><br><span class="line">        -p <span class="string">'&#123;"imagePullSecrets": [&#123;"name": "docker-registry-creds"&#125;]&#125;'</span> \</span><br><span class="line">        -n <span class="variable">$&#123;WORKING_NAME_SPACE&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>Or you can specify imagePullSecrets in yaml explicitly, for example:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">private-reg</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">private-reg-container</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">&lt;your-private-image&gt;</span></span><br><span class="line"><span class="attr">  imagePullSecrets:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">&lt;secret</span> <span class="string">name&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Create-Secure-Docker-Registry"><a href="#Create-Secure-Docker-Registry" class="headerlink" title="Create Secure Docker Registry"></a>Create Secure Docker Registry</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## notice the </span></span><br><span class="line"><span class="comment">##        env field</span></span><br><span class="line"><span class="comment">##        secret mount field</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## deletion is enabled</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">docker-registry</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">docker-registry</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">docker-registry</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">docker-registry</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      affinity:</span></span><br><span class="line"><span class="attr">        nodeAffinity:</span></span><br><span class="line"><span class="attr">          requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line"><span class="attr">            nodeSelectorTerms:</span></span><br><span class="line"><span class="attr">            - matchExpressions:</span></span><br><span class="line"><span class="bullet">              -</span> <span class="string">&#123;key:</span> <span class="string">docker-registry,</span> <span class="attr">operator:</span> <span class="string">In,</span> <span class="attr">values:</span> <span class="string">["true"]&#125;</span></span><br><span class="line"><span class="attr">      hostNetwork:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      tolerations:</span></span><br><span class="line"><span class="attr">      - key:</span> <span class="string">"node-role.kubernetes.io/master"</span></span><br><span class="line"><span class="attr">        operator:</span> <span class="string">"Exists"</span></span><br><span class="line"><span class="attr">        effect:</span> <span class="string">"NoSchedule"</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">docker-registry</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">localhost:5000/registry:2.7.1</span>        </span><br><span class="line"><span class="attr">        imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_STORAGE_DELETE_ENABLED</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_AUTH</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">"htpasswd"</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_AUTH_HTPASSWD_REALM</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">"Registry Realm"</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_AUTH_HTPASSWD_PATH</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">"/auth/htpasswd"</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_HTTP_TLS_CERTIFICATE</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">/certs/tls.crt</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_HTTP_TLS_KEY</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">/certs/tls.key</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">          containerPort:</span> <span class="number">5000</span></span><br><span class="line"><span class="attr">          hostPort:</span> <span class="number">5000</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">docker-data</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/var/lib/registry</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">docker-tls</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/certs</span></span><br><span class="line"><span class="attr">          readOnly:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">docker-auth</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/auth</span></span><br><span class="line"><span class="attr">          readOnly:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">docker-data</span></span><br><span class="line"><span class="attr">        persistentVolumeClaim:</span></span><br><span class="line"><span class="attr">          claimName:</span> <span class="string">registry-pv-claim</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">docker-tls</span></span><br><span class="line"><span class="attr">        secret:</span></span><br><span class="line"><span class="attr">          secretName:</span> <span class="string">docker-registry-tls</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">docker-auth</span></span><br><span class="line"><span class="attr">        secret:</span></span><br><span class="line"><span class="attr">          secretName:</span> <span class="string">docker-registry-auth</span></span><br></pre></td></tr></table></figure>
<p>So far the secure docker registry in K8s is up and running in default namespace, it’s host network true so can be accessed from remote. Later can expose it by ingress.</p>
<h2 id="Update-Docker-User-Info"><a href="#Update-Docker-User-Info" class="headerlink" title="Update Docker User Info"></a>Update Docker User Info</h2><p>See this <a href="https://stackoverflow.com/questions/38216278/update-k8s-configmap-or-secret-without-deleting-the-existing-one" target="_blank" rel="noopener">post</a>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create new htpasswd file</span></span><br><span class="line">DOCKER_USER=demonew</span><br><span class="line">DOCKER_PASSWORD=demonew</span><br><span class="line"></span><br><span class="line">mkdir -p /tmp/registry-auth</span><br><span class="line">htpasswd -Bbn <span class="variable">$&#123;DOCKER_USER&#125;</span> <span class="variable">$&#123;DOCKER_PASSWORD&#125;</span> &gt; /tmp/registry-auth/htpasswd</span><br><span class="line"><span class="comment">## then encode base64</span></span><br><span class="line">AUTH_BASE64=$(cat /tmp/registry-auth/htpasswd | base64 -w 0)</span><br><span class="line"><span class="comment">## replace old auth secret</span></span><br><span class="line"><span class="comment">## the change will be populated to registry pod</span></span><br><span class="line">kubectl get secret docker-registry-auth -o yaml -n default \</span><br><span class="line">        | sed -e <span class="string">"/htpasswd/c\  htpasswd: <span class="variable">$&#123;AUTH_BASE64&#125;</span>"</span> \</span><br><span class="line">        | kubectl replace -f -</span><br><span class="line"></span><br><span class="line"><span class="comment">## replace old docker config creds secret in used working namespaces</span></span><br><span class="line">NEW_REGISTRY_CREDS=$(kubectl create secret docker-registry docker-registry-creds \</span><br><span class="line">        --docker-server=<span class="variable">$DOCKER_REGISTRY_SERVER</span> \</span><br><span class="line">        --docker-username=<span class="variable">$DOCKER_USER</span> \</span><br><span class="line">        --docker-password=<span class="variable">$DOCKER_PASSWORD</span> \</span><br><span class="line">        -n default \</span><br><span class="line">        -o yaml --dry-run \</span><br><span class="line">        | grep <span class="string">"\.dockerconfigjson"</span> | cut -d<span class="string">":"</span> -f2)</span><br><span class="line"></span><br><span class="line">kubectl get secret docker-registry-creds -o yaml -n <span class="variable">$&#123;WORKING_NAME_SPACE&#125;</span> \</span><br><span class="line">        | sed -e <span class="string">"/\.dockerconfigjson/c\  .dockerconfigjson: <span class="variable">$&#123;NEW_REGISTRY_CREDS&#125;</span>"</span> \</span><br><span class="line">        | kubectl replace -f -</span><br></pre></td></tr></table></figure></p>
<h2 id="Skopeo-Operation"><a href="#Skopeo-Operation" class="headerlink" title="Skopeo Operation"></a>Skopeo Operation</h2><p>Please refer my skopeo <a href="https://chengdol.github.io/2019/09/26/docker-skopeo/" target="_blank" rel="noopener">blog</a> for more details.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">skopeo copy \</span><br><span class="line">       --dest-creds <span class="variable">$&#123;DOCKER_USER&#125;</span>:<span class="variable">$&#123;DOCKER_PASSWORD&#125;</span> \</span><br><span class="line">       --dest-cert-dir /root/registry-certs \</span><br><span class="line">       docker-archive:/root/busybox.tar.gz \</span><br><span class="line">       docker://<span class="variable">$&#123;DOCKER_REGISTRY_SERVER&#125;</span>/busybox:latest</span><br><span class="line"></span><br><span class="line">skopeo inspect \</span><br><span class="line">       --creds <span class="variable">$&#123;DOCKER_USER&#125;</span>:<span class="variable">$&#123;DOCKER_PASSWORD&#125;</span> \</span><br><span class="line">       --cert-dir /root/registry-certs \</span><br><span class="line">       docker://<span class="variable">$&#123;DOCKER_REGISTRY_SERVER&#125;</span>/busybox:latest</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Rook Storage Orchestrator</title>
    <url>/2020/01/20/k8s-rook/</url>
    <content><![CDATA[<p><a href="https://medium.com/flant-com/to-rook-in-kubernetes-df13465ff553" target="_blank" rel="noopener">https://medium.com/flant-com/to-rook-in-kubernetes-df13465ff553</a></p>
<p><a href="https://rook.io/" target="_blank" rel="noopener">Rook</a> turns distributed storage systems into self-managing, self-scaling, self-healing storage services. It automates the tasks of a storage administrator: deployment, bootstrapping, configuration, provisioning, scaling, upgrading, migration, disaster recovery, monitoring, and resource management.</p>
<p>Rook uses the power of the Kubernetes platform to deliver its services: cloud-native container management, scheduling, and orchestration.</p>
<p>Another similar tool is <a href="https://chengdol.github.io/2019/12/10/k8s-external-provisioner/" target="_blank" rel="noopener">Kubernetes External Provisioner</a>.</p>
<h2 id="NFS"><a href="#NFS" class="headerlink" title="NFS"></a>NFS</h2><p>Now is <strong>alpha version</strong><br>in order to use rool NFS, we must have a NFS provisioner or PV first, then rook will work on top of that, manage the NFS storage and provision it again to other application.</p>
<p><a href="https://rook.io/docs/rook/v1.2/nfs.html" target="_blank" rel="noopener">https://rook.io/docs/rook/v1.2/nfs.html</a><br>好好理解一下这段话：<br>The desired volume to export needs to be attached to the NFS server pod via a PVC. Any type of PVC can be attached and exported, such as Host Path, AWS Elastic Block Store, GCP Persistent Disk, CephFS, Ceph RBD, etc. The limitations of these volumes also apply while they are shared by NFS. You can read further about the details and limitations of these volumes in the Kubernetes docs.</p>
<blockquote>
<p>NFS is just a pattern, the file system can be any.</p>
</blockquote>
<p>NFS client packages must be installed on all nodes where Kubernetes might run pods with NFS mounted. Install nfs-utils on CentOS nodes or nfs-common on Ubuntu nodes.</p>
<h2 id="Ceph"><a href="#Ceph" class="headerlink" title="Ceph"></a>Ceph</h2><p>rook will create a soft ceph cluster for us.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>rook</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes sysctl</title>
    <url>/2019/05/07/k8s-sysctl/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>In my article <a href="https://chengdol.github.io/2019/05/01/linux-ipcs/" target="_blank" rel="noopener"><code>&lt;&lt;Linux IPC&gt;&gt;</code></a>, I mentioned that there is a workaround to set IPC kernel parameters using <code>sysctl</code> in Kubernetes cluster if <code>SYS_RESOURCE</code> is not allowed.</p>
<h3 id="Clarification"><a href="#Clarification" class="headerlink" title="Clarification"></a>Clarification</h3><p>From the Kubernetes <a href="https://v1-14.docs.kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/" target="_blank" rel="noopener">document</a>, we see:</p>
<p>Sysctls are grouped into safe and unsafe sysctls. This means that setting a safe sysctl for one pod:</p>
<ul>
<li>must not have any influence on any other pod on the node</li>
<li>must not allow to harm the node’s health</li>
<li>must not allow to gain CPU or memory resources outside of the resource limits of a pod.</li>
</ul>
<p>By far, most of the namespaced sysctls are not necessarily considered safe (please check latest Kubernetes document to figure out), now it supports:</p>
<ul>
<li>kernel.shm_rmid_forced,</li>
<li>net.ipv4.ip_local_port_range,</li>
<li>net.ipv4.tcp_syncookies.</li>
</ul>
<p>This list will be extended in future Kubernetes versions when the kubelet supports better isolation mechanisms.</p>
<p>All <code>safe</code> sysctls are enabled by default (you can use it directly without additional configuration in kubelet).</p>
<p>All <code>unsafe</code> sysctls are disabled by default and must be allowed manually by the cluster admin on a per-node basis. Pods with disabled unsafe sysctls will be scheduled, but will fail to launch:</p>
<p><img src="https://drive.google.com/uc?id=1ROz7A1kQPzeaBtpLiYPyFHjii0jIvJ52" alt=""></p>
<p>If you describe the failed pod, you get:<br><img src="https://drive.google.com/uc?id=1T7tUI4jIgGXt_qURYSNME-Qtz2RZc-XI" alt=""></p>
<p>A number of sysctls are <code>namespaced</code> in today’s Linux kernels. This means that they can be set independently for each pod on a node. <strong>Only</strong> namespaced sysctls are configurable via the pod securityContext within Kubernetes.</p>
<p>The following sysctls are known to be namespaced. This list could change in future versions of the Linux kernel.</p>
<ul>
<li>kernel.shm*</li>
<li>kernel.msg*</li>
<li>kernel.sem</li>
<li>fs.mqueue.*</li>
<li>net.*</li>
</ul>
<p>Sysctls with no namespace are called <code>node-level</code> sysctls. If you need to set them, you must manually configure them on each node’s operating system, or by using a DaemonSet with privileged containers.</p>
<p>As with node-level sysctls it is recommended to use taints and toleration feature or taints on nodes to schedule those pods onto the right nodes.</p>
<p>Use the pod securityContext to configure namespaced sysctls. The securityContext applies to <strong>all</strong> containers in the same pod.</p>
<h3 id="Configure-kubelet"><a href="#Configure-kubelet" class="headerlink" title="Configure kubelet"></a>Configure kubelet</h3><p>If you need to use <strong>unsafe</strong> sysctls, configure kubelet in target node (configure the node that the unsafe sysctls pod will reside) is a must. Go to edit <code>10-kubeadm.conf</code> file in <code>/etc/systemd/system/kubelet.service.d/</code>, add<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Environment=&quot;KUBELET_UNSAFE_SYSCTLS=--allowed-unsafe-sysctls=&apos;kernel.shm*,kernel.sem,kernel.msg*&apos;&quot;</span><br></pre></td></tr></table></figure></p>
<p>Here I need <code>kernel.shm*</code>, <code>kernel.sem</code> and <code>kernel.msg*</code>.</p>
<p><img src="https://drive.google.com/uc?id=11mDU4EZv5p6MJJYahaRblXICFBUY52aD" alt=""></p>
<p>then run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure></p>
<p>verify changes, you can see <code>--allowed-unsafe-sysctls</code> is there:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep kubelet</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>A brief digress: the kubelet service unit file is in <code>/etc/systemd/system/kubelet.service</code>.</p>
</blockquote>
<p>Then you can edit YAML file to add <code>sysctls</code> option:</p>
<p><img src="https://drive.google.com/uc?id=122vY73xveFwkFrtsipVJb50WTCiwgjUq" alt=""></p>
<p>Sometimes you need to disable <code>hostIPC</code>, if not you will get this problem:</p>
<p><img src="https://drive.google.com/uc?id=1s1sLiMy_FCCu_ClNJlX9r8C3k_Kw6c_E" alt=""></p>
<p>After things done, get into the container to check the kernel parameter vaule, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl -a | grep -i kernel.sem</span><br></pre></td></tr></table></figure></p>
<h3 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h3><p><a href="https://blog.csdn.net/horsefoot/article/details/53007177?utm_source=blogxgwz5" target="_blank" rel="noopener">kubernetes 1.4 new feature: support sysctls</a><br><a href="https://yq.aliyun.com/articles/603745?utm_content=m_1000003747" target="_blank" rel="noopener">configure kernel parameters in k8s cluster</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>sysctl</tag>
      </tags>
  </entry>
  <entry>
    <title>Set systemd as Cgroup Driver</title>
    <url>/2019/03/09/k8s-systemd-cgroup-driver/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>We want to use <code>systemd</code> as cgroup driver for docker and kubelet, let’s see how to achieve that.</p>
<p>First you need to understand what is <code>systemd</code> and <code>cgroup</code>?<br>You can refer to <a href="https://linuxaria.com/article/how-to-manage-processes-with-cgroup-on-systemd" target="_blank" rel="noopener">this article</a>. </p>
<p><code>systemd</code> is a suite of system management daemons, libraries, and utilities designed as a central management and configuration platform for the GNU/Linux computer operating system. It provides a system and service manager that runs as PID <code>1</code> and starts the rest of the system as alternative to the traditional sysVinit.</p>
<p>systemd organizes processes with <code>cgroups</code>, this is a Linux kernel feature to limit, police and account the resource usage of certain processes (actually process groups).</p>
<h3 id="Configure-docker"><a href="#Configure-docker" class="headerlink" title="Configure docker"></a>Configure docker</h3><p>After you install and start docker, by default it will use <code>cgroupfs</code> as the cgroup driver, check by running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker info | grep Cgroup</span><br><span class="line"></span><br><span class="line">Cgroup Driver: cgroupfs</span><br></pre></td></tr></table></figure></p>
<p>Edit <code>/usr/lib/systemd/system/docker.service</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ExecStart=/usr/bin/dockerd --exec-opt native.cgroupdriver=systemd</span><br></pre></td></tr></table></figure></p>
<p>Then reload daemon and restart docker<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></p>
<p>Verify the change<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker info | grep Cgroup</span><br><span class="line"></span><br><span class="line">Cgroup Driver: systemd</span><br></pre></td></tr></table></figure></p>
<h3 id="Configure-kubelet"><a href="#Configure-kubelet" class="headerlink" title="Configure kubelet"></a>Configure kubelet</h3><p>Currently, the kubelet cannot automatically detects the cgroup driver used by the CRI runtime, but the value of <code>--cgroup-driver</code> must match the cgroup driver used by the CRI runtime to ensure the health of the kubelet.</p>
<p><strong>Note</strong>: interesting thing is <code>kubeadm init</code> now can automatically detect and set kubelet with the same cgroup driver as docker (I use version <code>1.13.x</code>). </p>
<p>There is a file:  <code>/var/lib/kubelet/kubeadm-flags.env</code>, that <code>kubeadm init</code> and <code>kubeadm join</code> generates at runtime, populating the <code>KUBELET_KUBEADM_ARGS</code> variable dynamically, in <code>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</code> you can see it:<br><img src="https://drive.google.com/uc?id=1Wn2J8wk_7e36Z-W_x5lgM93nFBkGJ7EV" alt=""></p>
<p>you will see <code>systemd</code> resides in <code>/var/lib/kubelet/kubeadm-flags.env</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.1</span><br></pre></td></tr></table></figure></p>
<p>Anyway let’s see how to do the configuration manually. After install kubelet, go to edit <code>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</code> file, add this line:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Environment=&quot;KUBELET_CGROUP_ARGS=--cgroup-driver=systemd&quot;</span><br></pre></td></tr></table></figure></p>
<p>Append <code>$KUBELET_CGROUP_ARGS</code> at end of <code>ExecStart=/usr/bin/kubelet</code> statement:</p>
<p><img src="https://drive.google.com/uc?id=1AiZ-y12HevZivQm5TwIYYzY-OX7lfzho" alt=""></p>
<blockquote>
<p>Note: in the file <code>/etc/systemd/system/kubelet.service</code>, it seems you can also configure here: <code>ExecStart=/usr/bin/kubelet --cgroup-driver=systemd</code>, not very clear the difference.</p>
</blockquote>
<p>Then when you complete <code>kubeadm init</code>,  verify the change:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep kubelet</span><br><span class="line"></span><br><span class="line">root     19864  4.5  0.6 2326996 104192 ?      Ssl  01:21  32:49 /usr/bin/kubelet</span><br><span class="line">--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf </span><br><span class="line">--kubeconfig=/etc/kubernetes/kubelet.conf </span><br><span class="line">--config=/var/lib/kubelet/config.yaml </span><br><span class="line">--cgroup-driver=systemd </span><br><span class="line">--network-plugin=cni </span><br><span class="line">--pod-infra-container-image=k8s.gcr.io/pause:3.1 </span><br><span class="line">--cgroup-driver=systemd</span><br></pre></td></tr></table></figure></p>
<p>You see, there are 2 <code>--cgroup-driver=systemd</code> options, so I think manually configure kubelet service file is needless.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>systemd</tag>
        <tag>cgroup driver</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Security</title>
    <url>/2019/06/24/k8s-security/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>I believe security is an unavoidable topic in Kubernetes or OpenShift, I have encountered lots of SCCs and restricted settings.</p>
<p><a href="https://stackoverflow.com/questions/52700507/k8s-what-is-the-difference-between-security-context-and-security-policy" target="_blank" rel="noopener">https://stackoverflow.com/questions/52700507/k8s-what-is-the-difference-between-security-context-and-security-policy</a></p>
<p><a href="https://kubernetes-security.info/" target="_blank" rel="noopener">https://kubernetes-security.info/</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title>K8s NFS Mount Volume Permission</title>
    <url>/2019/08/20/k8s-volumeMount-permission-problem/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>This is an interesting issue which involves 4 topices: <code>Volume</code>, <code>Security Context</code>, <code>NFS</code> and <code>initContainer</code>.</p>
<p>The issue comes from the <code>permission denied</code> error. The process fail to create the file under the mount path, I check the owner and group of that path, they are both <code>root</code>.</p>
<p>In the yaml file, I specify the <code>fsGroup</code> field as id <code>9092</code>, from the official document <a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod" target="_blank" rel="noopener">here</a> (The example use id <code>2000</code>):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Since fsGroup field is specified, all processes of the container are also part of the supplementary group ID 2000. The owner for volume /data/demo and any files created in that volume will be Group ID 2000.</span><br></pre></td></tr></table></figure></p>
<p>so the owner of the volume should be <code>9092</code>, but they don’t.</p>
<p>I searched online and met the same issue from others:<br><a href="https://github.com/kubernetes/examples/issues/260" target="_blank" rel="noopener">https://github.com/kubernetes/examples/issues/260</a></p>
<p>It seems <code>fsGroup</code> securityContext <strong>does not</strong> apply to nfs mount especially we run the containers as non-root user we cannot access the mount. This issue may be solved in later version, need to take care.</p>
<blockquote>
<p>!!! Why this happens? Because we use <code>hostPath</code>, it by default will create root owned path if <code>path</code> does not exist. Here the <code>NFS</code> is not the <code>NFS</code> way kubernetes use, we use <code>hostPath</code> then manually nfs the nodes externally, not by the setting of K8s(need to do experiment).</p>
</blockquote>
<p>The workaround is using <code>initContainers</code> with <code>busybox</code> run as root and <code>chown</code> to the nfs mount with expected id, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">initContainers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: xxx.com:5000/busybox:latest</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    command: [&quot;sh&quot;, &quot;-c&quot;, &quot;chown 9092:9092 /mnt&quot;]</span><br><span class="line">    securityContext:</span><br><span class="line">      runAsUser: 0</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: &lt;volume name from Volumes&gt;</span><br><span class="line">      mountPath: /mnt</span><br></pre></td></tr></table></figure></p>
<p>then we are good.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Lose Connection to K8s Server</title>
    <url>/2019/06/11/k8s-server-missing/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<h2 id="Server-Login-Failed"><a href="#Server-Login-Failed" class="headerlink" title="Server Login Failed"></a>Server Login Failed</h2><p>This morning I find I lose the connection with my icp4d kubernetes server (it was good last night), if I run:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get pods</span></span><br><span class="line"><span class="attr">error:</span> <span class="string">the</span> <span class="string">server</span> <span class="string">doesn't</span> <span class="string">have</span> <span class="string">a</span> <span class="string">resource</span> <span class="string">type</span> <span class="string">"pods"</span></span><br></pre></td></tr></table></figure></p>
<p>then:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl version</span></span><br><span class="line"><span class="string">Client</span> <span class="attr">Version:</span> <span class="string">version.Info&#123;Major:"1",</span> <span class="attr">Minor:"12",</span> <span class="attr">GitVersion:"v1.12.4+icp-ee",</span> <span class="attr">GitCommit:"d03f6421b5463042d87aa0211f116ba4848a0d0f",</span> <span class="attr">GitTreeState:"clean",</span> <span class="attr">BuildDate:"2019-01-17T13:14:09Z",</span> <span class="attr">GoVersion:"go1.10.4",</span> <span class="attr">Compiler:"gc",</span> <span class="attr">Platform:"linux/amd64"&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">error:</span> <span class="string">You</span> <span class="string">must</span> <span class="string">be</span> <span class="string">logged</span> <span class="string">in</span> <span class="string">to</span> <span class="string">the</span> <span class="string">server</span> <span class="string">(the</span> <span class="string">server</span> <span class="string">has</span> <span class="string">asked</span> <span class="string">for</span> <span class="string">the</span> <span class="string">client</span> <span class="string">to</span> <span class="string">provide</span> <span class="string">credentials)</span></span><br></pre></td></tr></table></figure></p>
<p>But it seems kubectl config is good, the token is there:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl config view</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">clusters:</span></span><br><span class="line"><span class="attr">- cluster:</span></span><br><span class="line"><span class="attr">    insecure-skip-tls-verify:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    server:</span> <span class="attr">https://172.16.3.23:8001</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">icp-cluster1</span></span><br><span class="line"><span class="attr">- cluster:</span></span><br><span class="line"><span class="attr">    certificate-authority:</span> <span class="string">mycluster/ca.pem</span></span><br><span class="line"><span class="attr">    server:</span> <span class="attr">https://172.16.3.23:8001</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">contexts:</span></span><br><span class="line"><span class="attr">- context:</span></span><br><span class="line"><span class="attr">    cluster:</span> <span class="string">icp-cluster1</span></span><br><span class="line"><span class="attr">    user:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">- context:</span></span><br><span class="line"><span class="attr">    cluster:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">    user:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">- context:</span></span><br><span class="line"><span class="attr">    cluster:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">zen</span></span><br><span class="line"><span class="attr">    user:</span> <span class="string">mycluster-user</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">mycluster-context</span></span><br><span class="line"><span class="attr">current-context:</span> <span class="string">mycluster-context</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Config</span></span><br><span class="line"><span class="attr">preferences:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">users:</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">  user:</span></span><br><span class="line"><span class="attr">    client-certificate:</span> <span class="string">/etc/cfc/conf/kubecfg.crt</span></span><br><span class="line"><span class="attr">    client-key:</span> <span class="string">/etc/cfc/conf/kubecfg.key</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">  user:</span></span><br><span class="line"><span class="attr">    client-certificate:</span> <span class="string">/ibm/InstallPackage/ibm-cp-app/cluster/cfc-certs/kubernetes/kubecfg.crt</span></span><br><span class="line"><span class="attr">    client-key:</span> <span class="string">/ibm/InstallPackage/ibm-cp-app/cluster/cfc-certs/kubernetes/kubecfg.key</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">mycluster-user</span></span><br><span class="line"><span class="attr">  user:</span></span><br><span class="line"><span class="attr">    token:</span> <span class="string">eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdF9oYXNoIjoiYjVkNDMxZDMwNGZmMGUyYWM0NWJlOTY1NjU5YTQyN2ViOWUwNzE5NCIsInJlYWxtTmFtZSI6ImN1c3RvbVJlYWxtIiwidW5pcXVlU2VjdXJpdHlOYW1lIjoiYWRtaW4iLCJpc3MiOiJodHRwczovL215Y2x1c3Rlci5pY3A6OTQ0My9vaWRjL2VuZHBvaW50L09QIiwiYXVkIjoiYTc1ZTZmZjQ3YzQyZTJhZDA3YjZiMjUzMTVmZTExMTQiLCJleHAiOjE1NjAyMzkwNzEsImlhdCI6MTU2MDIxMDI3MSwic3ViIjoiYWRtaW4iLCJ0ZWFtUm9sZU1hcHBpbmdzIjpbXX0.cwGioosvwjONIllJExWRADicgibShbSl2x05r3hpiMpXQQia_4HDuvfUCNNyvLiFkBfz1xvuoz9JeAkOdRa7QVR0RD8TGVnYyu10S50AQ5b_LjGaTNoxdGJjLLEGkBt5gzJCsZaVw49ttd-lzDV28badpUBtm1cih4-3o-wbM6inJqCqR97ujgImRW0BS0Jj1pbENAEidAquyZscGMje5vyyRc9A67VWWJxZXo0J1fG081yhvaryRWbvinLLSPRm8_eley1GqItUMvRmIpzC-X7xsg4zIvCE8QhPoKrJp2xRFjDwsvCN44wJv9hdkfx3cGxjjOBdg6ofsVkNND5njg</span></span><br></pre></td></tr></table></figure></p>
<p>I check the docker and kubelet status, all are active:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl status docker</span><br><span class="line">systemctl status kubelet</span><br></pre></td></tr></table></figure></p>
<p>Then I try to reboot all nodes, and it set up correctly. Don’t know how to reproduce this issue, no idea what happened and how to fix it (without rebooting), sadly.</p>
<h2 id="Server-Connection-Refused-6443"><a href="#Server-Connection-Refused-6443" class="headerlink" title="Server Connection Refused 6443"></a>Server Connection Refused 6443</h2><p>Similar issue happened again in my <code>dstest</code> cluster:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get pods -n test-1</span></span><br><span class="line"><span class="string">The</span> <span class="string">connection</span> <span class="string">to</span> <span class="string">the</span> <span class="string">server</span> <span class="number">9.30</span><span class="number">.188</span><span class="number">.95</span><span class="string">:6443</span> <span class="string">was</span> <span class="string">refused</span> <span class="bullet">-</span> <span class="string">did</span> <span class="string">you</span> <span class="string">specify</span> <span class="string">the</span> <span class="string">right</span> <span class="string">host</span> <span class="string">or</span> <span class="string">port?</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl version</span></span><br><span class="line"><span class="string">Client</span> <span class="attr">Version:</span> <span class="string">version.Info&#123;Major:"1",</span> <span class="attr">Minor:"13",</span> <span class="attr">GitVersion:"v1.13.2",</span> <span class="attr">GitCommit:"cff46ab41ff0bb44d8584413b598ad8360ec1def",</span> <span class="attr">GitTreeState:"clean",</span> <span class="attr">BuildDate:"2019-01-10T23:35:51Z",</span> <span class="attr">GoVersion:"go1.11.4",</span> <span class="attr">Compiler:"gc",</span> <span class="attr">Platform:"linux/amd64"&#125;</span></span><br><span class="line"><span class="string">The</span> <span class="string">connection</span> <span class="string">to</span> <span class="string">the</span> <span class="string">server</span> <span class="number">9.30</span><span class="number">.188</span><span class="number">.95</span><span class="string">:6443</span> <span class="string">was</span> <span class="string">refused</span> <span class="bullet">-</span> <span class="string">did</span> <span class="string">you</span> <span class="string">specify</span> <span class="string">the</span> <span class="string">right</span> <span class="string">host</span> <span class="string">or</span> <span class="string">port?</span></span><br></pre></td></tr></table></figure></p>
<p>Check this <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#check-required-ports" target="_blank" rel="noopener">required ports list</a>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># netstat -tunlp | grep 6443</span><br><span class="line">tcp6       0      0 :::6443                 :::*                    LISTEN      27047/kube-apiserve</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note, there is no <code>kube-apiserver</code> service in <code>systemctl</code>, so how to restart it? The <code>kube-apiserver</code> is from a static pod, so I think I can restart the container directly by <code>docker restart &lt;container ID&gt;</code>:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker ps -a | grep apiserver</span></span><br><span class="line"><span class="number">8</span><span class="string">f661411fa02</span>        <span class="number">177</span><span class="string">db4b8e93a</span>           <span class="string">"kube-apiserver --au..."</span>   <span class="string">About</span> <span class="string">an</span> <span class="string">hour</span> <span class="string">ago</span>   <span class="string">Up</span> <span class="number">4</span> <span class="string">minutes</span>                            <span class="string">k8s_kube-apiserver_kube-apiserver-dstest1.fyre.ibm.com_kube-system_d175f38c007e23cc443d6ba50ba15533_0</span></span><br><span class="line"><span class="number">0</span><span class="string">f05946a8a59</span>        <span class="string">k8s.gcr.io/pause:3.1</span>   <span class="string">"/pause"</span>                 <span class="string">About</span> <span class="string">an</span> <span class="string">hour</span> <span class="string">ago</span>   <span class="string">Up</span> <span class="string">About</span> <span class="string">an</span> <span class="string">hour</span>                        <span class="string">k8s_POD_kube-apiserver-dstest1.fyre.ibm.com_kube-system_d175f38c007e23cc443d6ba50ba15533_0</span></span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>Haven’t got chance to reproduce this issue, this solution may not work…</p>
<p>In a health cluster:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kbc cluster-info</span></span><br><span class="line"><span class="string">Kubernetes</span> <span class="string">master</span> <span class="string">is</span> <span class="string">running</span> <span class="string">at</span> <span class="attr">https://9.30.188.95:6443</span></span><br><span class="line"><span class="string">KubeDNS</span> <span class="string">is</span> <span class="string">running</span> <span class="string">at</span> <span class="attr">https://9.30.188.95:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span></span><br><span class="line"></span><br><span class="line"><span class="string">To</span> <span class="string">further</span> <span class="string">debug</span> <span class="string">and</span> <span class="string">diagnose</span> <span class="string">cluster</span> <span class="string">problems,</span> <span class="string">use</span> <span class="string">'kubectl cluster-info dump'</span><span class="string">.</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Server-Connection-Refused-8080"><a href="#Server-Connection-Refused-8080" class="headerlink" title="Server Connection Refused 8080"></a>Server Connection Refused 8080</h2><p>This issue is similar to 6443 one, but it shows:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">The</span> <span class="string">connection</span> <span class="string">to</span> <span class="string">the</span> <span class="string">server</span> <span class="attr">localhost:8080</span> <span class="string">was</span> <span class="string">refused</span> <span class="bullet">-</span> <span class="string">did</span> <span class="string">you</span> <span class="string">specify</span> <span class="string">the</span> <span class="string">right</span> <span class="string">host</span> <span class="string">or</span> <span class="string">port?</span></span><br></pre></td></tr></table></figure></p>
<p>Recall that when we set up K8s cluster by <code>kubeadm</code>, we run:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">[kubeconfig]</span> <span class="string">Using</span> <span class="string">kubeconfig</span> <span class="string">folder</span> <span class="string">"/etc/kubernetes"</span></span><br><span class="line"><span class="string">[kubeconfig]</span> <span class="string">Writing</span> <span class="string">"admin.conf"</span> <span class="string">kubeconfig</span> <span class="string">file</span></span><br><span class="line"><span class="string">[kubeconfig]</span> <span class="string">Writing</span> <span class="string">"kubelet.conf"</span> <span class="string">kubeconfig</span> <span class="string">file</span></span><br><span class="line"><span class="string">[kubeconfig]</span> <span class="string">Writing</span> <span class="string">"controller-manager.conf"</span> <span class="string">kubeconfig</span> <span class="string">file</span></span><br><span class="line"><span class="string">[kubeconfig]</span> <span class="string">Writing</span> <span class="string">"scheduler.conf"</span> <span class="string">kubeconfig</span> <span class="string">file</span></span><br><span class="line"><span class="string">[control-plane]</span> <span class="string">Using</span> <span class="string">manifest</span> <span class="string">folder</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line"><span class="string">[control-plane]</span> <span class="string">Creating</span> <span class="string">static</span> <span class="string">Pod</span> <span class="string">manifest</span> <span class="string">for</span> <span class="string">"kube-apiserver"</span></span><br><span class="line"><span class="string">[control-plane]</span> <span class="string">Creating</span> <span class="string">static</span> <span class="string">Pod</span> <span class="string">manifest</span> <span class="string">for</span> <span class="string">"kube-controller-manager"</span></span><br><span class="line"><span class="string">[control-plane]</span> <span class="string">Creating</span> <span class="string">static</span> <span class="string">Pod</span> <span class="string">manifest</span> <span class="string">for</span> <span class="string">"kube-scheduler"</span></span><br><span class="line"><span class="string">[etcd]</span> <span class="string">Creating</span> <span class="string">static</span> <span class="string">Pod</span> <span class="string">manifest</span> <span class="string">for</span> <span class="string">local</span> <span class="string">etcd</span> <span class="string">in</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">Your</span> <span class="string">Kubernetes</span> <span class="string">master</span> <span class="string">has</span> <span class="string">initialized</span> <span class="string">successfully!</span></span><br><span class="line"></span><br><span class="line"><span class="string">To</span> <span class="string">start</span> <span class="string">using</span> <span class="string">your</span> <span class="string">cluster,</span> <span class="string">you</span> <span class="string">need</span> <span class="string">to</span> <span class="string">run</span> <span class="string">the</span> <span class="string">following</span> <span class="string">as</span> <span class="string">a</span> <span class="string">regular</span> <span class="attr">user:</span></span><br><span class="line"></span><br><span class="line">  <span class="string">mkdir</span> <span class="bullet">-p</span> <span class="string">$HOME/.kube</span></span><br><span class="line">  <span class="string">sudo</span> <span class="string">cp</span> <span class="bullet">-i</span> <span class="string">/etc/kubernetes/admin.conf</span> <span class="string">$HOME/.kube/config</span></span><br><span class="line">  <span class="string">sudo</span> <span class="string">chown</span> <span class="string">$(id</span> <span class="bullet">-u):$(id</span> <span class="bullet">-g)</span> <span class="string">$HOME/.kube/config</span></span><br></pre></td></tr></table></figure></p>
<p>I can reproduce this issue if the environment variable <code>KUBECONFIG</code> is missing, so try to export it, both ways are fine:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KUBECONFIG=<span class="variable">$HOME</span>/.kube/config</span><br><span class="line"><span class="built_in">export</span> KUBECONFIG=/etc/kubernetes/admin.conf</span><br></pre></td></tr></table></figure></p>
<p>A good <code>/etc/kubernetes</code> folder has these items:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ls -ltr /etc/kubernetes/</span></span><br><span class="line"><span class="string">total</span> <span class="number">36</span></span><br><span class="line"><span class="string">drwxr-xr-x</span> <span class="number">3</span> <span class="string">root</span> <span class="string">root</span> <span class="number">4096</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">pki</span></span><br><span class="line"><span class="bullet">-</span><span class="string">rw-------</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">5447</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">admin.conf</span></span><br><span class="line"><span class="bullet">-</span><span class="string">rw-------</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">5539</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">kubelet.conf</span></span><br><span class="line"><span class="bullet">-</span><span class="string">rw-------</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">5483</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">controller-manager.conf</span></span><br><span class="line"><span class="bullet">-</span><span class="string">rw-------</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">5435</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">scheduler.conf</span></span><br><span class="line"><span class="string">drwxr-xr-x</span> <span class="number">2</span> <span class="string">root</span> <span class="string">root</span>  <span class="number">113</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">manifests</span></span><br></pre></td></tr></table></figure></p>
<p>The <code>manifests</code> contains yaml files for creating etcd, kube-apiserver and kube-controller-manager, kube-scheduler.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux LPIC-1 Training</title>
    <url>/2020/04/15/linux-LPIC1-training/</url>
    <content><![CDATA[<p>//TODO<br>这篇总结是来自PluralSight上的<code>LPIC-1</code>课程的Essential章节。<br>备注:2020年4月份pluralsight在搞活动，免费注册学习！这次lock down是个机会补补课。</p>
<p>Environment: <code>CentOS 7 Enterprise Linux</code> or <code>RedHat</code>.</p>
<h1 id="Essentials"><a href="#Essentials" class="headerlink" title="Essentials"></a>Essentials</h1><p>Reading OS data<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># system version</span></span><br><span class="line"><span class="comment"># softlink actually</span></span><br><span class="line">cat /etc/os-release</span><br><span class="line">cat /etc/system-release</span><br><span class="line">cat /etc/redhat-release</span><br><span class="line"></span><br><span class="line"><span class="comment"># kernel release number</span></span><br><span class="line">uname -r</span><br><span class="line">cat /proc/version</span><br></pre></td></tr></table></figure></p>
<h2 id="Shutdown"><a href="#Shutdown" class="headerlink" title="Shutdown"></a>Shutdown</h2><p>Send message to others<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># send to individual user terminal</span></span><br><span class="line">write dsadm</span><br><span class="line">&gt; xxx</span><br><span class="line"></span><br><span class="line"><span class="comment"># send to all user in terminals</span></span><br><span class="line">wall &lt; message.txt</span><br></pre></td></tr></table></figure></p>
<p>Shutdown system and prompt<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># reboot now</span></span><br><span class="line">shutdown -r now</span><br><span class="line"><span class="comment"># halt/poweroff in 10 mins and use wall send message to login users</span></span><br><span class="line">shutdown -h 10 <span class="string">"The system is going down in 10 min"</span></span><br><span class="line"><span class="comment"># cancel shutdown</span></span><br><span class="line">shutdown -c</span><br></pre></td></tr></table></figure></p>
<p>Changing runlevels<br>what is <code>runlevel</code> in linux?<br><a href="https://www.liquidweb.com/kb/linux-runlevels-explained/" target="_blank" rel="noopener">https://www.liquidweb.com/kb/linux-runlevels-explained/</a><br>比如<br>runlevel 1 就只能root user且没有network enabled，也叫作rescue.target，可以做一些需要隔离的操作。<br>runlevel 3 是默认的multi-user + network enabled。<br>runlevel 5 是Desktop interface + runlevel 3的组合。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show current runlevel</span></span><br><span class="line">who -r</span><br><span class="line">runlevel</span><br><span class="line"></span><br><span class="line"><span class="comment"># default runlevel</span></span><br><span class="line">systemctl get-default</span><br><span class="line"><span class="comment"># set defaiult runlevel</span></span><br><span class="line">systemctl <span class="built_in">set</span>-default multi-user.target</span><br></pre></td></tr></table></figure></p>
<p>More about systemd, see my systemd blog.</p>
<h2 id="Manage-processes"><a href="#Manage-processes" class="headerlink" title="Manage processes"></a>Manage processes</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show process on current shell</span></span><br><span class="line"><span class="comment"># use dash is UNIX options</span></span><br><span class="line">ps -f</span><br><span class="line"><span class="comment"># -e means all processes</span></span><br><span class="line">ps -ef --forest</span><br><span class="line"><span class="comment"># -F show full format column</span></span><br><span class="line">ps -F -p $(pgrep sshd)</span><br><span class="line"><span class="comment"># kill all sleep processes</span></span><br><span class="line">pkill sleep</span><br><span class="line"><span class="comment"># BSD options</span></span><br><span class="line">ps aux</span><br></pre></td></tr></table></figure>
<p><code>$$</code> the PID of current running process<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /proc/$$</span><br><span class="line"><span class="comment"># we can interrogate this directory</span></span><br><span class="line"><span class="comment"># current dir</span></span><br><span class="line">ls -l cwd</span><br><span class="line"><span class="comment"># current exe</span></span><br><span class="line">ls -l exe</span><br></pre></td></tr></table></figure></p>
<p><code>top</code> 命令的options还记得吗? 比如切换memory显示单位，选择排序的依据CPU/MEM occupied..</p>
<h2 id="Process-priority"><a href="#Process-priority" class="headerlink" title="Process priority"></a>Process priority</h2><p>if something runs in foreground and prevent you from doing anything, use <code>ctrl + z</code> to suspend it (still in memory, not takeing CPU time), then put it in background.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sleep 10000</span><br><span class="line">^Z</span><br><span class="line">[1]+  Stopped                 sleep 10000</span><br><span class="line"></span><br><span class="line"><span class="comment"># use job command, `+` means current focus</span></span><br><span class="line"><span class="built_in">jobs</span></span><br><span class="line">[1]+  Stopped                 sleep 10000</span><br><span class="line"></span><br><span class="line"><span class="comment"># use bg command to put current focus in background</span></span><br><span class="line"><span class="built_in">bg</span></span><br><span class="line">[1]+ sleep 10000 &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># check is running in background</span></span><br><span class="line"><span class="built_in">jobs</span></span><br><span class="line">[1]+  Running                 sleep 10000 &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># use fg will bring current focus to foreground again</span></span><br></pre></td></tr></table></figure></p>
<p>如果你在一个bash shell中sleep 1000&amp; 然后exit bash shell，则这个sleep process will hand over to init process. can check via <code>ps -F -p $(pgrep sleep)</code>, 会发现PPID是<code>1</code>了。进入另一个bash shell <code>jobs</code> 并不会显示之前bash shell的background process.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show PRI(priority) and NI(nice) number</span></span><br><span class="line">ps -l</span><br><span class="line"></span><br><span class="line">F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD</span><br><span class="line">4 S     0 23785 23781  0  80   0 - 28891 do_wai pts/1    00:00:00 bash</span><br><span class="line">0 S     0 24859 23785  0  80   0 - 26987 hrtime pts/1    00:00:00 sleep</span><br><span class="line">0 S     0 24861 23785  0  80   0 - 26987 hrtime pts/1    00:00:00 sleep</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>NI value is from [-20,19], higher the nicer so less CPU time to take.<br>PRI value is from [60,99], 60 is the highest.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># set nice value to 19</span></span><br><span class="line">nice -n 19 sleep 1000 &amp;</span><br><span class="line"><span class="comment"># reset nice value</span></span><br><span class="line">renice -n 10 -p &lt;pid&gt;</span><br></pre></td></tr></table></figure></p>
<p>要注意的是只有root可以设置负数nice value和降低nice value. root可以去<code>vim /etc/security/limits.conf</code>设置对不同user/group的nice value。</p>
<h2 id="Monitor-linux-performance"><a href="#Monitor-linux-performance" class="headerlink" title="Monitor linux performance"></a>Monitor linux performance</h2><p>这个很重要，一般关注网络，硬盘，CPU</p>
<p>List content of the package <code>procps-ng</code>, <code>procps</code> is the package that has a bunch of small useful utilities that give information about processes using the <code>/proc</code> filesystem. The package includes the programs ps, top, vmstat, w, kill, free, slabtop, and skill.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># see executable files under procps package via rpm</span></span><br><span class="line">rpm -ql procps-ng | grep <span class="string">"^/usr/bin/"</span></span><br><span class="line"></span><br><span class="line">/usr/bin/free</span><br><span class="line">/usr/bin/pgrep</span><br><span class="line">/usr/bin/pkill</span><br><span class="line">/usr/bin/pmap</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># check the source package of top command</span></span><br><span class="line">rpm -qf $(<span class="built_in">which</span> top)</span><br><span class="line"></span><br><span class="line">procps-ng-3.3.10-17.el7_5.2.x86_64</span><br></pre></td></tr></table></figure></p>
<p>Introduce 2 new commands: <code>pmap</code> and <code>pwdx</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># pmap, show memory map of a process</span></span><br><span class="line"><span class="comment"># for example, current running process</span></span><br><span class="line">pmap $$</span><br><span class="line"><span class="comment"># you can also see shared libary been used by the process</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># show current working directory of process</span></span><br><span class="line">pwdx $$</span><br><span class="line">pwdx $(pgrep sshd)</span><br><span class="line"><span class="comment"># actually the output is from /proc/&lt;pid&gt;/cwd, it is a softlink</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check how long the system has been running</span></span><br><span class="line"><span class="comment"># load average is not normalized for cpu number 如果你知道CPU有多少个</span></span><br><span class="line"><span class="comment"># 根据load average就能看出是不是很忙, 如果load average的值超出了CPU个数</span></span><br><span class="line"><span class="comment"># 则说明需要queue or wait</span></span><br><span class="line"><span class="comment"># 这个命令其实是从/proc/uptime, /proc/loadavg 来的数据 </span></span><br><span class="line">uptime</span><br><span class="line">18:53:14 up 39 days,  3:50,  1 user,  load average: 0.00, 0.01, 0.05</span><br><span class="line"></span><br><span class="line"><span class="comment"># check how many cpu</span></span><br><span class="line">lscpu</span><br><span class="line"></span><br><span class="line"><span class="comment"># the same as w</span></span><br><span class="line">w</span><br><span class="line"> 18:59:29 up 12 days, 23:40,  3 users,  load average: 0.04, 0.26, 0.26</span><br><span class="line">USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT</span><br><span class="line">root     pts/0    9.160.1.111      08:47    6:46m  0.03s  0.03s -bash</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>监控load or output<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># execute a program periodically, showing output fullscreen</span></span><br><span class="line"><span class="comment"># 这里的例子是每隔4秒 运行 uptime</span></span><br><span class="line">watch -n 4 uptime</span><br><span class="line"></span><br><span class="line"><span class="comment"># graphic representation of system load average</span></span><br><span class="line"><span class="comment"># 如果此时运行一个tar，会看到loadavg显著变化</span></span><br><span class="line">tload</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -b 使用batch mode 输出所有process情况</span></span><br><span class="line"><span class="comment"># -n2 运行2回合</span></span><br><span class="line">top -b -n2 &gt; file.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># run 3 time, gap 5 seconds</span></span><br><span class="line"><span class="comment"># reports information about processes, memory, paging, block IO, traps, disks and cpu activity</span></span><br><span class="line">vmstat 5 3</span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   <span class="keyword">in</span>   cs us sy id wa st</span><br><span class="line"> 1  0    520  90576   4176 1601932    0    0     4   188   18   19  0  1 93  4  2</span><br><span class="line"> 0  0    520  90460   4176 1601956    0    0     0    46  514  348  0  0 98  2  1</span><br><span class="line"> 0  0    520  88972   4176 1603692    0    0     0   542  707  589  0  1 97  2  1</span><br></pre></td></tr></table></figure>
<h2 id="sysstat-toolkit"><a href="#sysstat-toolkit" class="headerlink" title="sysstat toolkit"></a>sysstat toolkit</h2><p>Install <code>sysstat</code> (this is a series of command: <code>iostat</code>, <code>netstat</code>, etc).<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y sysstat</span><br><span class="line"></span><br><span class="line"><span class="comment"># then check executable</span></span><br><span class="line">rpm -ql | grep <span class="string">"^/usr/bin"</span></span><br><span class="line"></span><br><span class="line">/usr/bin/cifsiostat</span><br><span class="line">/usr/bin/iostat</span><br><span class="line">/usr/bin/mpstat</span><br><span class="line">/usr/bin/nfsiostat-sysstat</span><br><span class="line">/usr/bin/pidstat</span><br><span class="line">/usr/bin/sadf</span><br><span class="line">/usr/bin/sar</span><br><span class="line">/usr/bin/tapestat</span><br></pre></td></tr></table></figure></p>
<p>在安装后，其实用的cron在背后操作收集数据, configuration is in file <code>cat /etc/sysconfig/sysstat</code>，这里面可以设置记录的周期，默认是28天。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cron config for sysstat</span></span><br><span class="line">cat /etc/cron.d/sysstat </span><br><span class="line"></span><br><span class="line"><span class="comment"># Run system activity accounting tool every 10 minutes</span></span><br><span class="line">*/10 * * * * root /usr/lib64/sa/sa1 1 1</span><br><span class="line"><span class="comment"># 0 * * * * root /usr/lib64/sa/sa1 600 6 &amp;</span></span><br><span class="line"><span class="comment"># Generate a daily summary of process accounting at 23:53</span></span><br><span class="line">53 23 * * * root /usr/lib64/sa/sa2 -A</span><br></pre></td></tr></table></figure></p>
<p>start and enable:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start sysstat</span><br><span class="line">systemctl <span class="built_in">enable</span> sysstat</span><br></pre></td></tr></table></figure></p>
<p>来看看sysstat下的工具命令:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show in mega byte</span></span><br><span class="line"><span class="comment"># run 3 times 5 seconds in between</span></span><br><span class="line">iostat -m 5 3</span><br><span class="line"><span class="comment"># others</span></span><br><span class="line">pidstat</span><br><span class="line">mpstat</span><br></pre></td></tr></table></figure></p>
<p>Let’s see <code>sar</code> report, 通过分析一天的bottleneck(cpu/memory/disk/network/loadavg)可以更好的schedule任务。这里并没有深入讲解怎么解读这些数据，并且你需要了解各个部分数据的含义，以及什么样的数据可能是异常。<br><code>sar</code>的数据在<code>/var/log/sa</code>里面，每天一个文件，周期性覆盖。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># default show CPU utilization</span></span><br><span class="line">sar -u</span><br><span class="line"><span class="comment"># show memory utilization</span></span><br><span class="line">sar -r</span><br><span class="line"><span class="comment"># show disk utilization</span></span><br><span class="line">sar -b</span><br><span class="line"><span class="comment"># network activity</span></span><br><span class="line">sar -n DEV</span><br><span class="line"><span class="comment"># load average</span></span><br><span class="line">sar -q</span><br><span class="line"><span class="comment"># 显示sa23这天的文件，从18:00:00到19:00:00 </span></span><br><span class="line">sar -n DEV -s 18:00:00 -e 19:00:00 -f /var/<span class="built_in">log</span>/sa/sa23</span><br></pre></td></tr></table></figure></p>
<p>图形化sar数据，可以用ksar:<a href="https://www.cyberciti.biz/tips/identifying-linux-bottlenecks-sar-graphs-with-ksar.html" target="_blank" rel="noopener">https://www.cyberciti.biz/tips/identifying-linux-bottlenecks-sar-graphs-with-ksar.html</a></p>
<h2 id="Log-and-logrotate"><a href="#Log-and-logrotate" class="headerlink" title="Log and logrotate"></a>Log and logrotate</h2><p>Auditing login events，这个还挺有用的，看哪个user什么时候login了, <code>w</code>是查看当前哪些user正在使用中。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># see user login info</span></span><br><span class="line">lastlog | grep -v <span class="string">"Never"</span></span><br><span class="line"></span><br><span class="line">Username         Port     From             Latest</span><br><span class="line">root             pts/0    9.65.239.28      Fri Apr 24 17:51:48 -0700 2020</span><br><span class="line">fyre             pts/0                     Fri Apr 24 17:52:00 -0700 2020</span><br><span class="line"></span><br><span class="line"><span class="comment"># check system reboot info</span></span><br><span class="line"><span class="comment"># The last command reads data from the wtmp log and displays it in a terminal window.</span></span><br><span class="line">last reboot</span><br><span class="line"><span class="comment"># check still login user</span></span><br><span class="line">last | grep still</span><br></pre></td></tr></table></figure></p>
<p>Auditing root access，看su/sudo的使用情况，在<code>/var/log/secure</code>文件中，这里其实有多个secure文件，有日期区分。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># there are some secure and auditing files</span></span><br><span class="line"><span class="built_in">cd</span> /var/<span class="built_in">log</span></span><br><span class="line"><span class="comment"># secure file</span></span><br><span class="line"><span class="comment"># 当然有grep也行，把用sudo的事件找出来</span></span><br><span class="line">awk <span class="string">'/sudo/ &#123; print $5, $6, $14&#125;'</span> secure</span><br></pre></td></tr></table></figure></p>
<p>我会专门总结一下awk的笔记，这个挺有用的。</p>
<p><code>journalctl</code>是一个常用的system log查询工具。当时查看一些docker的log在里面也能看到。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show last 10 lines</span></span><br><span class="line">journalctl -n 10</span><br><span class="line"><span class="comment"># ses real time appending</span></span><br><span class="line">journalctl -f</span><br><span class="line"><span class="comment"># -u: systemd unit</span></span><br><span class="line">journalctl -u sshd</span><br><span class="line"><span class="comment"># timestamp</span></span><br><span class="line">journalctl --since <span class="string">"10 minutes ago"</span></span><br><span class="line">journalctl --since <span class="string">"2020-04-26 13:00:00"</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Selinux"><a href="#Selinux" class="headerlink" title="Selinux"></a>Selinux</h2><p>O’Reilly有过相关的课程，在我工作邮件中连接还在。目前只需要知道什么是selinux，如何打开，关闭它即可。<br>SELINUX= can take one of these three values:<br><code>enforcing</code> - SELinux security policy is enforced.<br><code>permissive</code> - SELinux prints warnings instead of enforcing.<br><code>disabled</code> - No SELinux policy is loaded.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># see if selinux is permissive, enforcing or disabled</span></span><br><span class="line">getenforce</span><br><span class="line"><span class="comment"># more clear</span></span><br><span class="line">sestatus</span><br></pre></td></tr></table></figure></p>
<p>如果最开始是disabled的，则要去config file <code>/etc/selinux/config</code> 设置permissive，然后重启。<br>不能setenforce 去disable，也只能在config文件中disable然后重启机器。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># setenforce [ Enforcing | Permissive | 1 | 0 ]</span></span><br><span class="line"><span class="comment"># 成为permissive后就可以用setenforce切换了，但都不是永久的</span></span><br><span class="line">setenforce 0</span><br><span class="line">setenforce 1</span><br></pre></td></tr></table></figure></p>
<p>显示selinux的labels, <code>Z</code>对于其他命令也有用。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps -Zp $(pgrep sshd)</span><br><span class="line"></span><br><span class="line">LABEL                             PID TTY      STAT   TIME COMMAND</span><br><span class="line">system_u:system_r:kernel_t:s0     968 ?        Ss     0:00 /usr/sbin/sshd -D</span><br><span class="line">unconfined_u:unconfined_r:unconfined_t:s0 1196 ? Ss   0:00 sshd: root@pts/0</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>LPIC-1</tag>
      </tags>
  </entry>
  <entry>
    <title>Awk Command Daily Work Summary</title>
    <url>/2019/02/28/linux-awk-summary/</url>
    <content><![CDATA[<p>Designed for data extraction and reporting.</p>
<p><code>awk</code> is its own programming language itself and contains a lot of really good tools, enables a programmer to write tiny but effective programs in the form of statements that define <strong>text patterns</strong> that are to be searched for in <strong>each line</strong> of a document and the action that is to be taken when a <strong>match</strong> is found within a line. </p>
<p><a href="https://www.geeksforgeeks.org/awk-command-unixlinux-examples/" target="_blank" rel="noopener">Reference from GeeksforGeeks</a><br><a href="https://ferd.ca/awk-in-20-minutes.html" target="_blank" rel="noopener">awk in 20 mins</a><br>WHAT CAN WE DO WITH AWK ?</p>
<ol>
<li><p>AWK Operations:<br>(a) Scans a file line by line<br>(b) Splits each input line into fields<br>(c) Compares input line/fields to pattern<br>(d) Performs action(s) on matched lines</p>
</li>
<li><p>Useful For:<br>(a) Transform data files<br>(b) Produce formatted reports</p>
</li>
<li><p>Programming Constructs:<br>(a) Format output lines<br>(b) Arithmetic and string operations<br>(c) Conditionals and loops</p>
</li>
</ol>
<p>日期记录的部分主要平时遇到的零散总结:<br>################################################################<br>#  &emsp; Date &emsp; &emsp; &emsp; &emsp; &emsp; Description<br>#  &emsp; 09/11/2019 &emsp; &emsp; skip first line<br>#  &emsp; 02/28/2019 &emsp; &emsp; print last column<br>#  &emsp; 02/26/2019 &emsp; &emsp; awk remote execution<br>#<br>################################################################</p>
<h3 id="02-26-2019"><a href="#02-26-2019" class="headerlink" title="02/26/2019"></a>02/26/2019</h3><p>When use <code>awk</code> in script, may suffer shell unexpected expanding:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -o StrictHostKeyChecking=no sshrm1 <span class="string">"ifconfig eth0 | grep \"inet\" | awk '&#123;print <span class="variable">$2</span>&#125;'"</span></span><br></pre></td></tr></table></figure></p>
<p>Above will not get right data, instead preceding <code>\</code> before <code>$</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -o StrictHostKeyChecking=no sshrm1 <span class="string">"ifconfig eth0 | grep \"inet\" | awk '&#123;print \$2&#125;'"</span></span><br></pre></td></tr></table></figure></p>
<p>Another method is <code>awk</code> the return value from <code>ssh</code> rather than wrap it in <code>ssh</code> command.</p>
<h3 id="02-28-2019"><a href="#02-28-2019" class="headerlink" title="02/28/2019"></a>02/28/2019</h3><p>Print last column separated by space:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## NF: count of fields of a line</span></span><br><span class="line">awk <span class="string">'&#123;print $NF&#125;'</span> &lt;file&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="09-11-2019"><a href="#09-11-2019" class="headerlink" title="09/11/2019"></a>09/11/2019</h3><p>Skip the first line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## NR: current count of lines</span></span><br><span class="line">awk <span class="string">'NR&gt;1 &#123;print $1&#125;'</span> &lt;file&gt;</span><br></pre></td></tr></table></figure></p>
<p>You can use <code>NR&gt;=2</code>, <code>NR&lt;5</code>, <code>NR==3</code>, etc to limit the range.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## check version</span></span><br><span class="line">awk -W version</span><br><span class="line"><span class="comment">## looks also works</span></span><br><span class="line">awk --version</span><br></pre></td></tr></table></figure>
<p><code>awk</code> has BEGIN and END block, between is the body:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## BEGIN and END run only once</span></span><br><span class="line"><span class="comment">## body run as line number times</span></span><br><span class="line">awk <span class="string">'BEGIN &#123;print "start..."&#125; &#123;print NR, $0&#125; END &#123;print NR&#125;'</span> /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="comment">## BEGIN</span></span><br><span class="line">start...</span><br><span class="line"><span class="comment">## body</span></span><br><span class="line">1 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">2 ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">3 172.16.163.83 myk8s1.fyre.ibm.com myk8s1</span><br><span class="line">4 172.16.182.156 myk8s2.fyre.ibm.com myk8s2</span><br><span class="line">5 172.16.182.187 myk8s3.fyre.ibm.com myk8s3</span><br><span class="line"><span class="comment">## END</span></span><br><span class="line">5</span><br></pre></td></tr></table></figure></p>
<p>We can also put the awk option into awk script:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk -f file.awk /etc/passwd</span><br></pre></td></tr></table></figure></p>
<p><code>file.awk</code> content:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## FS is used to specify delimiter to parse line, by default awk use space</span></span><br><span class="line">BEGIN &#123; FS=<span class="string">":"</span> ; <span class="built_in">print</span> <span class="string">"User Name:"</span>&#125; </span><br><span class="line"><span class="comment">## $3 &gt; 999 is the condition match</span></span><br><span class="line"><span class="comment">## NR is internal variable of awk</span></span><br><span class="line"><span class="variable">$3</span> &gt; 999 &#123;<span class="built_in">print</span> NR, <span class="variable">$0</span>; count++ &#125; </span><br><span class="line">END &#123;<span class="built_in">print</span> <span class="string">"Total Lines: "</span> NR <span class="string">" Count Lines: "</span> count&#125;</span><br></pre></td></tr></table></figure></p>
<p>Let’s see more examples, actually sed may perform the same task but awk is more readable.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## set "," as delimiter, $1 to uppercase, $2 to lowercase</span></span><br><span class="line"><span class="comment">## toupper and tolower is awk internal functions</span></span><br><span class="line">awk -F<span class="string">","</span> <span class="string">'&#123;print toupper($1), tolower($2), $3&#125;'</span> &lt;file&gt;</span><br></pre></td></tr></table></figure></p>
<p>lastlog.awk file to show non-root user login statistics<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## exclude if match these:</span></span><br><span class="line">!(/Never logged <span class="keyword">in</span>/ || /^Username/ || /^root/) &#123;</span><br><span class="line">cnt++</span><br><span class="line"><span class="comment">## line fields == 8</span></span><br><span class="line"><span class="keyword">if</span> (NF == 8)</span><br><span class="line">    <span class="built_in">printf</span> <span class="string">"%8s %2s %3s %4s\n"</span>, <span class="variable">$1</span>, <span class="variable">$5</span>, <span class="variable">$4</span>, <span class="variable">$8</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">"%8s %2s %3s %4s\n"</span>, <span class="variable">$1</span>, <span class="variable">$6</span>, <span class="variable">$5</span>, <span class="variable">$9</span></span><br><span class="line">&#125;</span><br><span class="line">END &#123;</span><br><span class="line"><span class="built_in">print</span> <span class="string">"==============================="</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">"Total # of user processed: "</span> cnt</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode Python Summary</title>
    <url>/2020/08/09/leetcode-python-recall/</url>
    <content><![CDATA[<p>未来可见的一段时期要switch 到 Python了。<br>这里主要记录一下用Python 刷题的总结，特别是一些不知道的module, funtions等等，还有就是知道了但没有熟练应用。</p>
<p>对于while, if 等，None, 0 等都视作False，不用再去显示比较了。<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">divmod(x, y)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">returns a pair of numbers consisting of their quotient and remainder.</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">x <span class="keyword">and</span> y : x <span class="keyword">is</span> numerator <span class="keyword">and</span> y <span class="keyword">is</span> denominator</span><br><span class="line">x <span class="keyword">and</span> y must be non complex</span><br></pre></td></tr></table></figure></p>
<p>L1480: 这题学到个新的function accumulate 依次叠加<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> accumulate</span><br><span class="line">itr = accumulate([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">list(itr)</span><br><span class="line"><span class="comment">## [1, 3, 6, 10, 15]</span></span><br></pre></td></tr></table></figure></p>
<p>L617: 如果是BFS, 则要使用queue:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## init</span></span><br><span class="line">queue = collections.deque([])</span><br><span class="line"><span class="comment">## same as len(queue)</span></span><br><span class="line"><span class="comment">## canonical way for all collections (tuples, strings, lists, dicts and all their many subtypes) to check empty or not</span></span><br><span class="line"><span class="keyword">while</span> queue:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<p>L1512: collecions.Counter()<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## return a dict subclass object</span></span><br><span class="line"><span class="comment">## &#123;object: count, ...&#125;</span></span><br><span class="line">collections.Counter(<span class="string">"sbadbfasdbfab"</span>)</span><br></pre></td></tr></table></figure></p>
<p>LC236: 注意这里的这里表达方式<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lowestCommonAncestor</span><span class="params">(self, root, p, q)</span>:</span></span><br><span class="line">    <span class="comment">## 这个表达很省事</span></span><br><span class="line">    <span class="keyword">if</span> root <span class="keyword">in</span> (<span class="keyword">None</span>, p, q): <span class="keyword">return</span> root</span><br><span class="line">    <span class="comment">## generator </span></span><br><span class="line">    left, right = (self.lowestCommonAncestor(kid, p, q)</span><br><span class="line">                   <span class="keyword">for</span> kid <span class="keyword">in</span> (root.left, root.right))</span><br><span class="line">    <span class="keyword">return</span> root <span class="keyword">if</span> left <span class="keyword">and</span> right <span class="keyword">else</span> left <span class="keyword">or</span> right</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Capability</title>
    <url>/2019/05/13/linux-capability/</url>
    <content><![CDATA[<p>In my post <a href="https://chengdol.github.io/2019/05/01/linux-ipcs/" target="_blank" rel="noopener"><code>&lt;&lt;Linux IPC&gt;&gt;</code></a>, I mentioned <code>Linux Capability</code>, so what is it? Why we use it? How and when to use this feature?</p>
<p>For the purpose of performing permission checks, traditional UNIX implementations distinguish two categories of processes: <code>privileged</code> processes (whose effective user ID is 0, referred to as superuser or root), and <code>unprivileged</code> processes (whose effective UID is nonzero).</p>
<p>Privileged processes bypass all kernel permission checks, while unprivileged processes are subject to full permission checking based on the process’s credentials (usually: effective UID, effective GID, and supplementary group list).</p>
<blockquote>
<p>Note again, privilege process (root user) bypass all kernel permission checks, but in K8s or docker container, it depends on the configuration you made.</p>
</blockquote>
<p>Starting with kernel 2.2, Linux divides the privileges traditionally associated with superuser into distinct units, known as <code>capabilities</code>, which can be independently enabled and disabled. This way the full set of privileges is reduced and decreasing the risks of exploitation.</p>
<h2 id="Basic-Capability-Thing"><a href="#Basic-Capability-Thing" class="headerlink" title="Basic Capability Thing"></a>Basic Capability Thing</h2><h3 id="Header-File"><a href="#Header-File" class="headerlink" title="Header File"></a>Header File</h3><p>Linux capabilities are defined in a header file with the non-surprising name <code>capability.h</code>, in <code>/usr/include/linux/capability.h</code>. They’re pretty self-explanatory and well commented</p>
<h3 id="Capability-Number"><a href="#Capability-Number" class="headerlink" title="Capability Number"></a>Capability Number</h3><p>To see the highest capability number for your kernel, use the data from the <code>/proc</code> file system.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat /proc/sys/kernel/cap_last_cap</span><br><span class="line"></span><br><span class="line">36</span><br></pre></td></tr></table></figure></p>
<h3 id="Current-Capabilities"><a href="#Current-Capabilities" class="headerlink" title="Current Capabilities"></a>Current Capabilities</h3><p>To see the current capabilities list, run <code>capsh --print</code>, for example, normal user <code>dsadm</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ capsh --print</span><br><span class="line"></span><br><span class="line">Current: =</span><br><span class="line">Bounding set =cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,</span><br><span class="line">cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,</span><br><span class="line">cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,</span><br><span class="line">cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,</span><br><span class="line">cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,</span><br><span class="line">cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,</span><br><span class="line">35,36</span><br><span class="line">Securebits: 00/0x0/1&apos;b0</span><br><span class="line"> secure-noroot: no (unlocked)</span><br><span class="line"> secure-no-suid-fixup: no (unlocked)</span><br><span class="line"> secure-keep-caps: no (unlocked)</span><br><span class="line">uid=1002(dsadm)</span><br><span class="line">gid=1002(dsadm)</span><br><span class="line">groups=1002(dsadm)</span><br></pre></td></tr></table></figure></p>
<p>you see the <code>Current: =</code> is empty, but if you run as root user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ capsh --print</span><br><span class="line"></span><br><span class="line">Current: = cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,</span><br><span class="line">cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,</span><br><span class="line">cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,</span><br><span class="line">cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,</span><br><span class="line">cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,</span><br><span class="line">cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,</span><br><span class="line">35,36+ep</span><br><span class="line">Bounding set =cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,</span><br><span class="line">cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,</span><br><span class="line">cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,</span><br><span class="line">cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,</span><br><span class="line">cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,</span><br><span class="line">cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,</span><br><span class="line">35,36</span><br><span class="line">Securebits: 00/0x0/1&apos;b0</span><br><span class="line"> secure-noroot: no (unlocked)</span><br><span class="line"> secure-no-suid-fixup: no (unlocked)</span><br><span class="line"> secure-keep-caps: no (unlocked)</span><br><span class="line">uid=0(root)</span><br><span class="line">gid=0(root)</span><br><span class="line">groups=0(root)</span><br></pre></td></tr></table></figure></p>
<p>To see the capabilities for a particular process, run <code>cat /proc/&lt;PID&gt;/status | grep -i cap</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat /proc/1/status | grep -i cap</span><br><span class="line"></span><br><span class="line">CapInh: 00000000a884a5fb</span><br><span class="line">CapPrm: 00000000a884a5fb</span><br><span class="line">CapEff: 00000000a884a5fb</span><br><span class="line">CapBnd: 00000000a884a5fb</span><br><span class="line">CapAmb: 0000000000000000</span><br></pre></td></tr></table></figure></p>
<p>This is the bit map for capabilities, the meaning for each is:</p>
<ul>
<li>CapInh = Inherited capabilities</li>
<li>CapPrm – Permitted capabilities</li>
<li>CapEff = Effective capabilities</li>
<li>CapBnd = Bounding set</li>
<li>CapAmb = Ambient capabilities set</li>
</ul>
<blockquote>
<p>The <code>CapBnd</code> defines the upper level of available capabilities. During the time a process runs, no capabilities can be added to this list. Only the capabilities in the bounding set can be added to the inheritable set, which uses the capset() system call. If a capability is dropped from the boundary set, that process or its children can no longer have access to it.</p>
</blockquote>
<p>Using the <code>capsh</code> utility we can decode them into the capabilities name:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># capsh --decode=00000000a884a5fb</span><br><span class="line"></span><br><span class="line">0x00000000a884a5fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,</span><br><span class="line">cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,cap_sys_chroot,</span><br><span class="line">cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap</span><br></pre></td></tr></table></figure></p>
<p>The another easy way is use <code>getpcaps</code> utility:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># getpcaps 1965</span><br><span class="line"></span><br><span class="line">Capabilities for `1965&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+eip</span><br></pre></td></tr></table></figure></p>
<p>It is also interesting to see the capabilities of a set of processes that have a relationship.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># getpcaps $(pgrep db2)</span><br><span class="line"></span><br><span class="line">Capabilities for `1965&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+eip</span><br><span class="line">Capabilities for `2151&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+i</span><br><span class="line">Capabilities for `2245&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+eip</span><br><span class="line">Capabilities for `2246&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+eip</span><br><span class="line">Capabilities for `2247&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+eip</span><br><span class="line">Capabilities for `2249&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+i</span><br><span class="line">Capabilities for `2614&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+i</span><br><span class="line">Capabilities for `4213&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+i</span><br><span class="line">Capabilities for `4238&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+i</span><br></pre></td></tr></table></figure></p>
<h3 id="Limit-Capability"><a href="#Limit-Capability" class="headerlink" title="Limit Capability"></a>Limit Capability</h3><p>You can test what happens when a particular capability is dropped by using the <code>capsh</code> utility. This is a way to see what capabilities a particular program may need to function correctly. The <code>capsh</code> command can run a particular process and restrict the set of available capabilities.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">capsh --print -- -c &quot;/bin/ping -c 1 localhost&quot;</span><br></pre></td></tr></table></figure></p>
<p>After dropping <code>cap_net_raw</code>, <code>ping</code> not permitted.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">capsh --drop=cap_net_raw --print -- -c &quot;/bin/ping -c 1 localhost&quot;</span><br></pre></td></tr></table></figure></p>
<h3 id="Capability-Meet"><a href="#Capability-Meet" class="headerlink" title="Capability Meet"></a>Capability Meet</h3><p>List the capabilities I have seen so far:</p>
<ul>
<li><p>CAP_SYS_ADMIN<br>Without it, I cannot perform <code>hostname</code> command for docker container in K8s.</p>
</li>
<li><p>CAP_SYS_RESOURCE<br>This is for adjust <a href="https://www.ibm.com/support/knowledgecenter/en/SSEPGG_11.1.0/com.ibm.db2.luw.qb.server.doc/doc/c0057140.html" target="_blank" rel="noopener">Db2 kernel parameters</a></p>
</li>
</ul>
<p>These 3 are for Db2:</p>
<ul>
<li><p>CAP_SETFCAP<br>Set arbitrary capabilities on a file. (actually this is default in unprivileged docker container)</p>
</li>
<li><p>CAP_SYS_NICE</p>
</li>
<li><p>CAP_IPC_OWNER<br>Bypass permission checks for operations on System V IPC objects.</p>
</li>
</ul>
<h3 id="My-Questions"><a href="#My-Questions" class="headerlink" title="My Questions"></a>My Questions</h3><ol>
<li><p>Privileges grant to user or process?<br>I think for the process run by normal user.</p>
</li>
<li><p>Privilege process bypass all kernel permission check? Does that mean linux capabilities are only for non-privilege user or process?<br>I think there is a global or default capability set in system to determine what ever processes on system is allowed to do. Then you can fine-tune for unprivileged process.</p>
</li>
<li><p>If we have root and normal user both in docker container, so capabilities are applied on root or normal user or both?<br>After testing and comparing by <code>capsh --print</code> with different user in xmeta container, I think capabilities are applied on all users in K8s environment.</p>
</li>
</ol>
<p>Later I post blogs to talk about <code>&lt;&lt;Capability in Docker&gt;&gt;</code> and <code>&lt;&lt;Capability in K8s&gt;&gt;</code>.</p>
<h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h2><p><a href="http://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">Linux Programmer’s Manual</a><br><a href="https://linux-audit.com/linux-capabilities-101/" target="_blank" rel="noopener">Linux capabilities 101</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>capability</tag>
      </tags>
  </entry>
  <entry>
    <title>What&#39;s New in CentOS 8</title>
    <url>/2020/07/05/linux-centos8-new/</url>
    <content><![CDATA[<p>New features:</p>
<ul>
<li>Using cockpit web interface</li>
<li>Using enhanced firewall: nftables</li>
<li>Managing NFSv4 with nfsconf</li>
<li>Layered storage management with stratis</li>
<li>Data de-duplication and compression with VDO (virtual data optimizer)</li>
</ul>
<p>感觉资源挺分散的，不知道就是不知道😢<br>RedHat provides lab interactive learning exercise:</p>
<ul>
<li><a href="https://lab.redhat.com/" target="_blank" rel="noopener">https://lab.redhat.com/</a></li>
</ul>
<p>Openshift lab interactive exercise:</p>
<ul>
<li><a href="https://learn.openshift.com/" target="_blank" rel="noopener">https://learn.openshift.com/</a></li>
</ul>
<h1 id="Fast-Ping-Test"><a href="#Fast-Ping-Test" class="headerlink" title="Fast Ping Test"></a>Fast Ping Test</h1><p>This is the new shorthand format.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## last decimal represents 24 bits</span></span><br><span class="line"><span class="comment">## the same as 127.0.0.1</span></span><br><span class="line">ping 127.1</span><br><span class="line"><span class="comment">## 1.0.0.1</span></span><br><span class="line">ping 1.1</span><br></pre></td></tr></table></figure></p>
<h1 id="Cocopit-Web-Console"><a href="#Cocopit-Web-Console" class="headerlink" title="Cocopit Web Console"></a>Cocopit Web Console</h1><p>Available since CentOS 7.5. 相当于一个简化版的桌面. You can check logs, create account, monitor network, start services, and so on.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install</span></span><br><span class="line">sudo yum install -y cockpit-211.3-1.el8.x86_64</span><br><span class="line"></span><br><span class="line"><span class="comment">## start socket only not cockpit.service</span></span><br><span class="line">sudo systemctl <span class="built_in">enable</span> --now cockpit.socket</span><br><span class="line">systemctl status cockpit.socket</span><br><span class="line"><span class="comment">## see port opened: 9090</span></span><br><span class="line">sudo ss -tnlp</span><br><span class="line"></span><br><span class="line"><span class="comment">## still inactive</span></span><br><span class="line">systemctl status cockpit.service</span><br></pre></td></tr></table></figure>
<p>Set root password, user <code>vagrant</code> is privileged, run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo passwd root</span><br></pre></td></tr></table></figure></p>
<p>I have the port forwarding for <code>9090</code>, view cockpit UI by <code>localhost:9090</code>, login as root user with the password you set. After login the <code>cockpit.service</code> is now active:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl status cockpit.service</span><br></pre></td></tr></table></figure></p>
<p>There is a <code>terminal</code> in web UI, you can work with it just like working on a normal ssh terminal.</p>
<p>The <code>dashboard</code> plugin:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## see plugins</span></span><br><span class="line"><span class="comment">## you can see yum packages installed and available</span></span><br><span class="line">yum list cockpit*</span><br><span class="line"></span><br><span class="line">yum info cockpit-dashboard</span><br><span class="line">yum install -y cockpit-dashboard</span><br></pre></td></tr></table></figure></p>
<p>With cockpit dashboard plugin installed, you can connect to remote machine (with cockpit installed and cockpit.socket running), dashboard is just like a control plane.</p>
<p>Other plugins like <code>cockpit-machines</code> is used to manage virtual guests.</p>
<h1 id="Enhancing-Firewall"><a href="#Enhancing-Firewall" class="headerlink" title="Enhancing Firewall"></a>Enhancing Firewall</h1><p><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/configuring_and_managing_networking/getting-started-with-nftables_configuring-and-managing-networking" target="_blank" rel="noopener">RedHat 8 Getting start with nftables</a><br>It is the designated <strong>successor</strong> to the iptables, ip6tables, arptables, and ebtables tools. Stick to one command, not using mixed. <code>firewalld</code> command can be replaced by nftables.</p>
<p>NFTables <code>nft</code> is the default kernel firewall in CentOS 8. Single command for IPV4, IPV6 ARP, and Bridge filters. nftables does not have any predefined tables, tables are created by <code>firewalld</code> or rely on our scripts.</p>
<p>First yum install nftables, run as sudo or <strong>root</strong>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">disable</span> --now firewalld</span><br><span class="line">reboot</span><br><span class="line"><span class="comment">## list all tables, nothing is there.</span></span><br><span class="line">nft list tables</span><br></pre></td></tr></table></figure>
<p>Now start and enable firewalld, the tables will be created:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> --now firewalld</span><br><span class="line"><span class="comment">## list all tables</span></span><br><span class="line">nft list tables</span><br><span class="line"></span><br><span class="line">table ip filter</span><br><span class="line">table ip6 filter</span><br><span class="line">table bridge filter</span><br><span class="line">table ip security</span><br><span class="line">table ip raw</span><br><span class="line">table ip mangle</span><br><span class="line">table ip nat</span><br><span class="line">table ip6 security</span><br><span class="line">table ip6 raw</span><br><span class="line">table ip6 mangle</span><br><span class="line">table ip6 nat</span><br><span class="line">table bridge nat</span><br><span class="line">table inet firewalld</span><br><span class="line">table ip firewalld</span><br><span class="line">table ip6 firewalld</span><br></pre></td></tr></table></figure></p>
<p>Some common commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list all tables</span></span><br><span class="line">nft list tables</span><br><span class="line"></span><br><span class="line"><span class="comment">## list tables with specific protocol family</span></span><br><span class="line">nft list tables ip</span><br><span class="line"><span class="comment">## check detail of ip filter</span></span><br><span class="line">nft list table ip filter</span><br></pre></td></tr></table></figure></p>
<p>Let’s see the demo code to build nftables: </p>
<ul>
<li>create chains</li>
<li>create rules</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## disable firewalld</span></span><br><span class="line">systemctl <span class="built_in">disable</span> --now firewalld ; reboot</span><br><span class="line">nft list tables</span><br><span class="line"><span class="comment">## inet will work both for ipv4 and ipv6</span></span><br><span class="line"><span class="comment">## create a new table `filter`</span></span><br><span class="line">nft add table inet filter </span><br><span class="line"></span><br><span class="line"><span class="comment">## INPUT is the chain name, not necessarily call it INPUT</span></span><br><span class="line"><span class="comment">## here we add INPUT chain to inet filter table</span></span><br><span class="line">nft add chain inet filter INPUT \</span><br><span class="line">  <span class="comment">## basic chain type: filter, route, nat</span></span><br><span class="line">  <span class="comment">## basic hook types: prerouting, input, forward, output, postrouting, ingress</span></span><br><span class="line">  <span class="comment">## priority 0 ~ 100, 0 is hightest</span></span><br><span class="line">  &#123; <span class="built_in">type</span> filter hook input priority 0 \; policy accept \;&#125;</span><br></pre></td></tr></table></figure>
<p>Add SSH inbound to our system, set rules:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## add rule to inet filter table INPUT chain</span></span><br><span class="line">nft add rule inet filter INPUT iif lo accept </span><br><span class="line"><span class="comment">## allow traffic back to system with specified state</span></span><br><span class="line">nft add rule inet filter INPUT ct state \</span><br><span class="line">      established,related accept </span><br><span class="line">nft add rule inet filter INPUT tcp dport 22 accept</span><br><span class="line"><span class="comment">## drop everthing that is not explicitly defined</span></span><br><span class="line">nft add rule inet filter INPUT counter drop</span><br></pre></td></tr></table></figure></p>
<p>Persisting nftables rules<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## store rules</span></span><br><span class="line">nft list ruleset &gt; /root/myrules</span><br><span class="line"><span class="comment">## clear table</span></span><br><span class="line">nft flush table inet filter</span><br><span class="line"><span class="comment">## delete table</span></span><br><span class="line">nft delete table inet filter</span><br><span class="line"><span class="comment">## restore rules</span></span><br><span class="line">nft -f /root/myrules</span><br></pre></td></tr></table></figure></p>
<p>Using systemd service unit:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## the systemd service unit for nftables use /etc/sysconfig/nftables.conf</span></span><br><span class="line">nft list ruleset &gt; /etc/sysconfig/nftables.conf</span><br><span class="line">nft flush table inet filter</span><br><span class="line">nft delete table inet filter</span><br><span class="line">systemctl <span class="built_in">enable</span> --now nftables</span><br></pre></td></tr></table></figure></p>
<h1 id="NFSv4"><a href="#NFSv4" class="headerlink" title="NFSv4"></a>NFSv4</h1><p>CentOS 8 uses <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/exporting-nfs-shares_managing-file-systems" target="_blank" rel="noopener">NFSv4.2</a> as NFS server.<br>The new tool <code>nfsconf</code> writes to the <code>/etc/nfs.conf</code>.<br>Enable and use NFSv4 only and managing inbound TCP connections using firewall.<br>SELinux NFS configuration.</p>
<p>Install nfs package for both server and clients:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y nfs-utils</span><br></pre></td></tr></table></figure></p>
<p>The default will have NFSv2 disable and NFSv3 and above enabled, we will disable NFSv3 and <strong>have NFSv4 only with TCP port 2049 to be opened</strong>. 这样看来之前项目中的NFS 用的默认设置，并且不是secure的.</p>
<p>we can edit <code>/etc/nfs.conf</code> or using <code>nfsconf</code> commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">nfsconf --<span class="built_in">set</span> nfsd vers4 y</span><br><span class="line">nfsconf --<span class="built_in">set</span> nfsd tcp y</span><br><span class="line"><span class="comment">## close udp and nfsv3</span></span><br><span class="line">nfsconf --<span class="built_in">set</span> nfsd vers3 n</span><br><span class="line">nfsconf --<span class="built_in">set</span> nfsd udp n</span><br></pre></td></tr></table></figure></p>
<p>Start nfs server daemon:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> --now nfs-server.service</span><br></pre></td></tr></table></figure></p>
<p>Check port opened:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ss -tlp -4</span><br><span class="line"></span><br><span class="line">State  Recv-Q   Send-Q      Local Address:Port       Peer Address:Port                                                              </span><br><span class="line">LISTEN 0        128               0.0.0.0:sunrpc          0.0.0.0:*      users:((<span class="string">"rpcbind"</span>,pid=8920,fd=4),(<span class="string">"systemd"</span>,pid=1,fd=76))  </span><br><span class="line">LISTEN 0        128               0.0.0.0:mountd          0.0.0.0:*      users:((<span class="string">"rpc.mountd"</span>,pid=8936,fd=8))                       </span><br><span class="line">LISTEN 0        128               0.0.0.0:ssh             0.0.0.0:*      users:((<span class="string">"sshd"</span>,pid=917,fd=5))                              </span><br><span class="line">LISTEN 0        128               0.0.0.0:54425           0.0.0.0:*      users:((<span class="string">"rpc.statd"</span>,pid=8925,fd=9))                        </span><br><span class="line">LISTEN 0        64                0.0.0.0:nfs             0.0.0.0:*</span><br></pre></td></tr></table></figure></p>
<p>We don’t need <code>sunrpc</code> with NFSv4, mask them both service and socket:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl mask --now rpc-statd rpcbind.service rpcbind.socket</span><br></pre></td></tr></table></figure></p>
<p>Then we have nfs and mounted port only, only nfs port needs firewalld setting:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ss -tl -4</span><br><span class="line"></span><br><span class="line">State           Recv-Q           Send-Q                      Local Address:Port                         Peer Address:Port           </span><br><span class="line">LISTEN          0                128                               0.0.0.0:mountd                            0.0.0.0:*              </span><br><span class="line">LISTEN          0                128                               0.0.0.0:ssh                               0.0.0.0:*              </span><br><span class="line">LISTEN          0                64                                0.0.0.0:nfs                               0.0.0.0:*</span><br></pre></td></tr></table></figure></p>
<p>Let’s create some shared files:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir /share</span><br><span class="line"><span class="comment">## copy *.txt under /usr/share/doc to /share</span></span><br><span class="line"><span class="comment">## &#123;&#125; represents the content find finds</span></span><br><span class="line"><span class="comment">## \; is used for find command, escape in bash</span></span><br><span class="line">find /usr/share/doc -name <span class="string">'*.txt'</span> -<span class="built_in">exec</span> cp &#123;&#125; /share \;</span><br></pre></td></tr></table></figure></p>
<p>Go to edit <code>/etc/exports</code> file<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Here only rw, in my previous work, we use (rw,insecure,async,no_root_squash)</span></span><br><span class="line"><span class="comment">## 这里其他默认设置够用了</span></span><br><span class="line">/share *(rw)</span><br><span class="line"></span><br><span class="line"><span class="comment">## launch</span></span><br><span class="line">exportfs -rav</span><br><span class="line"><span class="comment">## check options applied</span></span><br><span class="line">exportfs -v</span><br><span class="line"></span><br><span class="line">/share          &lt;world&gt;(sync,wdelay,hide,no_subtree_check,sec=sys,rw,secure,root_squash,no_all_squash)</span><br></pre></td></tr></table></figure></p>
<p>Configure firewall:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">firewall-cmd --add-service=nfs --permanent</span><br></pre></td></tr></table></figure></p>
<p>Then go to the client and mount <code>/share</code> folder.<br>后面讲了SElinux对NFS的支持，目前用不到, 也没明白.</p>
<h1 id="Storage-Management-Stratis"><a href="#Storage-Management-Stratis" class="headerlink" title="Storage Management Stratis"></a>Storage Management Stratis</h1><p>Stratis resources:</p>
<ul>
<li><a href="https://stratis-storage.github.io/" target="_blank" rel="noopener">https://stratis-storage.github.io/</a></li>
<li><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/managing-layered-local-storage-with-stratis_managing-file-systems" target="_blank" rel="noopener">MANAGING LAYERED LOCAL STORAGE WITH STRATIS</a></li>
</ul>
<p>视频中的讲解比RedHat的练习更好一些，在mount的时候，用的是<code>/etc/fstab</code> persistent configuration.</p>
<p>In creating filesystem, the author chooses <code>xfs</code>, so what is the difference comparing to <code>ext4</code>?</p>
<ul>
<li><a href="https://computingforgeeks.com/ext4-vs-xfs-complete-comparison/" target="_blank" rel="noopener">https://computingforgeeks.com/ext4-vs-xfs-complete-comparison/</a></li>
</ul>
<p>New commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list block device</span></span><br><span class="line">lsblk</span><br><span class="line"><span class="comment">## wipe disks</span></span><br><span class="line">wipefs --all /dev/sdb</span><br><span class="line"><span class="comment">## shrink or extend file to specific size</span></span><br><span class="line">truncate -s 10g /tmp/blk.tmp1</span><br><span class="line"><span class="comment">## create loopback device from a file</span></span><br><span class="line">losetup /dev/loop1 /tmp/blk.tmp1</span><br></pre></td></tr></table></figure></p>
<h1 id="Virtual-Data-Optimizer"><a href="#Virtual-Data-Optimizer" class="headerlink" title="Virtual Data Optimizer"></a>Virtual Data Optimizer</h1><p>To make use of block level deduplication, compression, thin-provisioning to save space.</p>
<ul>
<li><a href="https://lab.redhat.com/vdo-configure" target="_blank" rel="noopener">https://lab.redhat.com/vdo-configure</a></li>
</ul>
<p>Example Use Case:<br>To reduce the amount of operational and storage costs in data centers, we use the deduplication and compression features in VDO to decrease the footprint of data.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title>linux-change-homedir</title>
    <url>/2019/07/15/linux-change-homedir/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Linux Commands Collect</title>
    <url>/2020/03/19/linux-cmd-collect/</url>
    <content><![CDATA[<p>Frequently used Linux commands collected and sorted by first letter:</p>
<h3 id="a"><a href="#a" class="headerlink" title="a"></a>a</h3><p><code>awk</code> (data processing and extracting), <code>alias</code>, <code>at</code> (schedule job one time), <code>arp</code> (check layer2 to layer3 mapping), <code>ab</code> (apach HTTP server benchmark tool)</p>
<h3 id="b"><a href="#b" class="headerlink" title="b"></a>b</h3><p><code>base64</code> (encode/decode), <code>bg</code>, <code>basename</code> (last name), <code>blkid</code></p>
<h3 id="c"><a href="#c" class="headerlink" title="c"></a>c</h3><p><code>cat</code>, <code>cd</code>, <code>cp</code>, <code>cut</code> ,<code>curl</code> ,<code>chown</code> ,<code>chmod</code> ,<code>chgrp</code> ,<code>cron</code> ,<code>clear</code></p>
<h3 id="d"><a href="#d" class="headerlink" title="d"></a>d</h3><p><code>df</code> (disk space check), <code>dirname</code> (path prefix), <code>du</code> (occupied space check), <code>diff</code>, <code>date</code>, <code>dd</code> (convert and copy), <code>dnsdomainname</code>, <code>dig</code> (dns lookup utility)</p>
<h3 id="e"><a href="#e" class="headerlink" title="e"></a>e</h3><p><code>echo</code>, <code>exit</code>, <code>export</code>, <code>env</code>, <code>exportfs</code>, <code>ethtool</code> (physical card), <code>eval</code></p>
<h3 id="f"><a href="#f" class="headerlink" title="f"></a>f</h3><p><code>file</code>, <code>free</code>, <code>find</code>, <code>fg</code>, <code>firewall-cmd</code>, <code>fallocate</code> (fast allocate space), <code>fuser</code></p>
<h3 id="g"><a href="#g" class="headerlink" title="g"></a>g</h3><p><code>gzip</code>, <code>grep</code>, <code>git</code>, <code>gitk</code>, <code>getfacl</code>, <code>getent</code>(look up /etc/hosts)</p>
<h3 id="h"><a href="#h" class="headerlink" title="h"></a>h</h3><p><code>hostname</code>, <code>host</code>, <code>htpasswd</code>, <code>history</code>, <code>hostnamectl</code> (permenant hostname)</p>
<h3 id="i"><a href="#i" class="headerlink" title="i"></a>i</h3><p><code>ip</code> (so powerful), <code>ifconfig</code> (obsolete), <code>id</code>, <code>iperf3</code>, <code>iptables</code>, <code>iostat</code>, <code>ifdown</code>, <code>ifup</code></p>
<h3 id="j"><a href="#j" class="headerlink" title="j"></a>j</h3><p><code>jq</code>, <code>jobs</code>, <code>journalctl</code></p>
<h3 id="k"><a href="#k" class="headerlink" title="k"></a>k</h3><p><code>kill</code></p>
<h3 id="l"><a href="#l" class="headerlink" title="l"></a>l</h3><p><code>ls</code>, <code>less</code>, <code>ln</code>, <code>lsblk</code>, <code>lvdisplay</code>, <code>lscpu</code>, <code>lastlog</code>, <code>last</code> (reboot), <code>losetup</code>, <code>lsof</code> (list open files), <code>loginctl</code></p>
<h3 id="m"><a href="#m" class="headerlink" title="m"></a>m</h3><p><code>mv</code>, <code>mount</code>, <code>more</code>, <code>man</code>, <code>mkdir</code>, <code>mktemp</code></p>
<h3 id="n"><a href="#n" class="headerlink" title="n"></a>n</h3><p><code>nc</code>, <code>netstat</code>, <code>nslookup</code>, <code>nmap</code>, <code>nice</code> (process priority)</p>
<h3 id="o"><a href="#o" class="headerlink" title="o"></a>o</h3><p><code>openssl</code></p>
<h3 id="p"><a href="#p" class="headerlink" title="p"></a>p</h3><p><code>pwd</code>, <code>ping</code>, <code>ps</code>, <code>perf</code>, <code>pvdisplay</code>, <code>pmap</code>, <code>pwdx</code>, <code>pv</code>(monitor the progress of data through a pipe)</p>
<h3 id="q"><a href="#q" class="headerlink" title="q"></a>q</h3><p>so far no!</p>
<h3 id="r"><a href="#r" class="headerlink" title="r"></a>r</h3><p><code>rm</code>, <code>rmdir</code>, <code>route</code>, <code>rsync</code>, <code>readlink</code>, <code>runlevel</code>, <code>renice</code>, <code>rpm</code>, <code>rev</code> (reverse seq)</p>
<h3 id="s"><a href="#s" class="headerlink" title="s"></a>s</h3><p><code>ssh</code>, <code>scp</code>, <code>sftp</code>, <code>strace</code>, <code>sudo</code>, <code>su</code>, <code>sed</code> (stream editor), <code>setfacl</code>,<br><code>sleep</code>, <code>stat</code>, <code>systemctl</code>, <code>shutdown</code>, <code>sar</code> (system activity report), <code>ss</code>(similar to netstat), <code>stress</code>, <code>sort</code>, <code>seq</code>, <code>sync</code></p>
<h3 id="t"><a href="#t" class="headerlink" title="t"></a>t</h3><p><code>tar</code>, <code>tcpdump</code> (wireshark), <code>top</code> (keep update), <code>trap</code>, <code>touch</code>, <code>tee</code>, <code>tail</code>, <code>tree</code>, <code>tracepath</code>, <code>traceroute</code>, <code>tload</code>, <code>tc</code> (traffic control), <code>tac</code> (reversion of <code>cat</code>), <code>truncate</code>, <code>tr</code> (translate), <code>timeout</code></p>
<h3 id="u"><a href="#u" class="headerlink" title="u"></a>u</h3><p><code>uniq</code>, <code>uname</code>, <code>umount</code>, <code>unlink</code>, <code>uuidgen</code>, <code>uptime</code>, <code>udevadm</code></p>
<h3 id="v"><a href="#v" class="headerlink" title="v"></a>v</h3><p><code>vim</code>, <code>vmstat</code></p>
<h3 id="w"><a href="#w" class="headerlink" title="w"></a>w</h3><p><code>w</code>, <code>who</code>, <code>wget</code>, <code>wc</code>, <code>wall</code>, <code>write</code>, <code>watch</code>, <code>wipefs</code></p>
<h3 id="x"><a href="#x" class="headerlink" title="x"></a>x</h3><p><code>xargs</code></p>
<h3 id="y"><a href="#y" class="headerlink" title="y"></a>y</h3><p><code>yum</code>, <code>yes</code></p>
<h3 id="z"><a href="#z" class="headerlink" title="z"></a>z</h3><p><code>zip</code></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Clean Memory Cache</title>
    <url>/2019/03/30/linux-clean-memory/</url>
    <content><![CDATA[<p>When deploying DS, I find the compute pod that assigned to the second node is always in <code>CreateContainer</code> status and hangs there. I ssh into that node and find its memory is occupied heavily by some other processes so the command response is so slow, and the cpu% is also busy with the swap daemon.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">free</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:        8168772      105152      295732     7491216     7767888      273448</span><br><span class="line">Swap:             0           0           0</span><br></pre></td></tr></table></figure></p>
<p>Compare the normal node:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">free</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">  Mem:        8168772      123504     7041388      270836     1003880     7424612</span><br><span class="line">  Swap:             0           0           0</span><br></pre></td></tr></table></figure></p>
<p>You see the shared and buff/cache parts are huge, I need to flush and clean it.</p>
<blockquote>
<p>Note: <code>free -h</code> is more readable</p>
</blockquote>
<p>If you have to clear the disk cache, this command is safest in enterprise and production, will clear the <code>PageCache</code> only:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sync; echo 1 &gt; /proc/sys/vm/drop_caches</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>What is <code>sync</code> command?<br>writes any data buffered in memory out to disk.</p>
</blockquote>
<p>More aggressively, Clear <code>dentries</code> and <code>inodes</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sync; echo 2 &gt; /proc/sys/vm/drop_caches</span><br></pre></td></tr></table></figure></p>
<p>Clear <code>PageCache</code>, <code>dentries</code> and <code>inodes</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sync; echo 3 &gt; /proc/sys/vm/drop_caches</span><br></pre></td></tr></table></figure></p>
<p>It is not recommended to use this in production until you know what you are doing, as it will clear <code>PageCache</code>, <code>dentries</code> and <code>inodes</code>. Because just after your run drop_caches, your server will get busy re-populating memory with <code>inodes</code> and <code>dentries</code>, original Kernel documentation recommends not to run this command outside of a testing or debugging environment. But what if you are a home user or your server is getting too busy and almost filling up it’s memory. You need to be able trade the benefits with the risk.</p>
<blockquote>
<p>what is <code>dirty cache</code>?<br>Dirty Cache refers to data which has not yet been committed to the database (or disk), and is currently held in computer memory. In short, the new/old data is available in Memory and it is different to what you have in database/disk.</p>
</blockquote>
<blockquote>
<p>what is <code>clean cache</code>?<br>Clean cache refers to data which has been committed to database (or disk) and is currently held in computer memory. This is what we desire where everything is in sync.</p>
</blockquote>
<blockquote>
<p>what is <code>dentries</code> and <code>inodes</code>?<br>A filesystem is represented in memory using dentries and inodes.  Inodes are<br>  the objects that represent the underlying files (and also directories). A dentry is an object with a string name (d_name), a pointer to an inode (d_inode), and a pointer to the parent dentry (d_parent)</p>
</blockquote>
<blockquote>
<p>what is <code>drop_caches</code>?<br>Writing to this will cause the kernel to drop <code>clean caches</code>, as well as reclaimable slab objects like dentries and inodes.  Once dropped, their memory becomes free. It will not kill any process.</p>
</blockquote>
<p>This <a href="https://www.blackmoreops.com/2014/10/28/delete-clean-cache-to-free-up-memory-on-your-slow-linux-server-vps/" target="_blank" rel="noopener">post</a> is good to reference.</p>
<p>If you want to clean swap space:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">swapoff -a &amp;&amp; swapon -a</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux CPU Info</title>
    <url>/2019/11/14/linux-cpuinfo/</url>
    <content><![CDATA[<p>Check CPU information on Linux, just like check memory by watching <code>/proc/meminfo</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo</span><br><span class="line"></span><br><span class="line"><span class="comment">## each processor has a dedicated description</span></span><br><span class="line">processor       : 0</span><br><span class="line">vendor_id       : GenuineIntel</span><br><span class="line">cpu family      : 6</span><br><span class="line">model           : 61</span><br><span class="line">model name      : Intel Core Processor (Broadwell, IBRS)</span><br><span class="line">stepping        : 2</span><br><span class="line">microcode       : 0x1</span><br><span class="line">cpu MHz         : 2199.996</span><br><span class="line">cache size      : 4096 KB</span><br><span class="line">physical id     : 0</span><br><span class="line">siblings        : 1</span><br><span class="line">core id         : 0</span><br><span class="line">cpu cores       : 1</span><br><span class="line">apicid          : 0</span><br><span class="line">initial apicid  : 0</span><br><span class="line">fpu             : yes</span><br><span class="line">fpu_exception   : yes</span><br><span class="line">cpuid level     : 13</span><br><span class="line">wp              : yes</span><br><span class="line">flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb tpr_shadow vnmi flexpriority ept vpid fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt spec_ctrl</span><br><span class="line">bogomips        : 4399.99</span><br><span class="line">clflush size    : 64</span><br><span class="line">cache_alignment : 64</span><br><span class="line">address sizes   : 40 bits physical, 48 bits virtual</span><br></pre></td></tr></table></figure></p>
<p>Count number of processing units<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo | grep processor | wc -l</span><br></pre></td></tr></table></figure></p>
<p>To get actualy number of cores<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo | grep <span class="string">'core id'</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: The number of processors shown by <code>/proc/cpuinfo</code> might not be the actual number of cores on the processor. For example a processor with 2 cores and hyperthreading would be reported as a processor with 4 cores.</p>
</blockquote>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Scheduling Recurring Tasks with cron</title>
    <url>/2019/05/28/linux-cronjob/</url>
    <content><![CDATA[<p>Let’s first see what does <code>cron</code> represent from <a href="https://en.wikipedia.org/wiki/Cron" target="_blank" rel="noopener">wiki</a>:</p>
<blockquote>
<p>The software utility <code>cron</code> is a time-based job scheduler in Unix-like computer operating systems. People who set up and maintain software environments use <code>cron</code> to schedule jobs (commands or shell scripts) to run periodically at fixed times, dates, or intervals. </p>
</blockquote>
<p><code>cron</code> is most suitable for scheduling repetitive tasks. For example, it runs log file rotation utilities to ensure that your hard drive doesn’t fill up with old log files. You should know how to use cron because it’s just plain useful.</p>
<blockquote>
<p>Also see <a href="https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/" target="_blank" rel="noopener">cronjob</a> in K8s.</p>
</blockquote>
<h2 id="Install-crontab"><a href="#Install-crontab" class="headerlink" title="Install crontab"></a>Install crontab</h2><p>In CentOS or RedHat, you can run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install cronie</span><br></pre></td></tr></table></figure></p>
<p>If you are not sure, try <code>yum provides crontab</code> to see which package will provide this service.</p>
<p>To check if <code>cron</code> service is running or not:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl status crond</span><br></pre></td></tr></table></figure></p>
<p>If inactive, enable and restart it. </p>
<h2 id="crontab-File"><a href="#crontab-File" class="headerlink" title="crontab File"></a>crontab File</h2><p>Cron is driven by a <code>crontab(cron table)</code> file, a configuration file that specifies shell commands to run periodically on a given schedule. </p>
<p>The program running through cron is called a <code>cron job</code>. To install a <code>cron job</code>, you’ll create an entry line in your <code>crontab</code> file, usually by running the <code>crontab</code> command.</p>
<p>Each user can have his or her own crontab file, which means that every system may have multiple crontabs, usually found in <code>/var/spool/cron/</code> folder. the crontab command installs, lists, edits, and removes a user’s crontab.</p>
<h2 id="crontab-Commands"><a href="#crontab-Commands" class="headerlink" title="crontab Commands"></a>crontab Commands</h2><p>For example, run as <code>root</code>, I want to set a recurring task for user <code>dsadm</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -u dsadm -e</span><br></pre></td></tr></table></figure></p>
<p>Then edit like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">00 21 * * * /home/dsadm/test.sh &gt; /tmp/cron-log 2&gt;&amp;1</span><br></pre></td></tr></table></figure></p>
<p>This means on everyday at 9:00PM, user <code>dsadm</code> will run <code>test.sh</code> and redirect output to <code>/tmp/cron-log</code> file. You can also put the entries into a file and run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -u dsadm &lt;entry file&gt;</span><br></pre></td></tr></table></figure></p>
<p>The meaning of the entry is:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ┌───────────── minute (0 - 59)</span><br><span class="line"># │ ┌───────────── hour (0 - 23)</span><br><span class="line"># │ │ ┌───────────── day of the month (1 - 31)</span><br><span class="line"># │ │ │ ┌───────────── month (1 - 12)</span><br><span class="line"># │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday;</span><br><span class="line"># │ │ │ │ │                                   7 is also Sunday on some systems)</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># * * * * * command to execute</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>A <code>*</code> in any field means to match every value.</p>
</blockquote>
<p>Now, if you check <code>/var/spool/cron</code> directory, the <code>dsadm</code> crontab file is created there.</p>
<p>To list the <code>dsadm</code> cron job:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -u dsadm -l</span><br></pre></td></tr></table></figure></p>
<p>To remove <code>dsadm</code> cron job:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -u dsadm -r</span><br></pre></td></tr></table></figure></p>
<h2 id="Run-as-Non-Root"><a href="#Run-as-Non-Root" class="headerlink" title="Run as Non-Root"></a>Run as Non-Root</h2><p>If you want to run <code>crontab</code> as <code>dsadm</code>, you must set the cron permission:</p>
<ul>
<li><code>/etc/cron.allow</code> - If this file exists, it must contain your username for you to use cron jobs.</li>
<li><code>/etc/cron.deny</code> - If the cron.allow file does not exist but the <code>/etc/cron.deny</code> file does exist then, to use cron jobs, you must not be listed in the <code>/etc/cron.deny</code> file. </li>
</ul>
<p>So, if you put <code>dsadm</code> in <code>/etc/cron.allow</code> file, then you can use <code>crontab</code> directly.</p>
<h2 id="System-crontab-File"><a href="#System-crontab-File" class="headerlink" title="System crontab File"></a>System crontab File</h2><p>Linux distributions normally have an <code>/etc/crontab</code> file. You can also edit here, but the format is a little bit difference:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Example of job definition:</span><br><span class="line"># .---------------- minute (0 - 59)</span><br><span class="line"># |  .------------- hour (0 - 23)</span><br><span class="line"># |  |  .---------- day of month (1 - 31)</span><br><span class="line"># |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...</span><br><span class="line"># |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat</span><br><span class="line"># |  |  |  |  |</span><br><span class="line"># *  *  *  *  * user-name  command to be executed</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cronjob</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Check Disk Space</title>
    <url>/2019/08/11/linux-disk-check/</url>
    <content><![CDATA[<p>这里补充一下，常用的关于disk排查的命令就是<code>df</code>, <code>du</code>, <code>dd</code>, <code>lsof</code>, <code>lsblk</code>, <code>blkid</code>, <code>mount</code>, <code>fdisk</code>, <code>mkfs</code>, <code>sync</code>. More about Linux Storage, see my blog <code>&lt;&lt;Linux Storage System&gt;&gt;</code>.</p>
<p>I get error messages when run <code>docker load</code> command, this is caused by disk space run out. How do I know the disk utilization?</p>
<p>Shows the amount of disk space used and available on Linux file systems.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># disk space report tool</span></span><br><span class="line"><span class="comment"># -h: readable</span></span><br><span class="line">$ df [-h]</span><br><span class="line"></span><br><span class="line">Filesystem             Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/rhel-root  241G  219G   23G  91% /</span><br><span class="line">devtmpfs               3.9G     0  3.9G   0% /dev</span><br><span class="line">tmpfs                  3.9G     0  3.9G   0% /dev/shm</span><br><span class="line">tmpfs                  3.9G  8.6M  3.9G   1% /run</span><br><span class="line">tmpfs                  3.9G     0  3.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/vda1             1014M  208M  807M  21% /boot</span><br><span class="line">tmpfs                  783M     0  783M   0% /run/user/0</span><br><span class="line"></span><br><span class="line"><span class="comment"># check mounted filesystem of directory</span></span><br><span class="line">df -h &lt;directory&gt;</span><br></pre></td></tr></table></figure></p>
<p>Shows total size of the directory and it’s subdirectories<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># du: estimate file space usage</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计当前目录下文件大小，并按照大小排序</span></span><br><span class="line"><span class="comment"># -s: display only a total</span></span><br><span class="line"><span class="comment"># -m: --block-size=1M</span></span><br><span class="line"><span class="comment"># *: shell globs</span></span><br><span class="line">du -sm * | sort -nr</span><br><span class="line"></span><br><span class="line"><span class="comment"># current directory total size</span></span><br><span class="line">du -sm .</span><br></pre></td></tr></table></figure></p>
<p><code>lsof</code> 在这方面主要就是检查哪些文件正在被什么user, process使用:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># see what is interacting with this file</span></span><br><span class="line"><span class="comment"># -l: show user id instead of user name</span></span><br><span class="line">lsof -l /path/to/file/or/directory</span><br><span class="line"></span><br><span class="line"><span class="comment"># see files have been opened from a directory</span></span><br><span class="line"><span class="comment"># +D: directory option</span></span><br><span class="line">lsof +D /var/<span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># files opened by process name, wild match by beginning characters</span></span><br><span class="line">lsof -c ssh</span><br><span class="line">lsof -c init</span><br><span class="line"></span><br><span class="line"><span class="comment"># files opened by process id</span></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line"><span class="comment"># files opened by user</span></span><br><span class="line">lsof -u root</span><br><span class="line">lsof -u 1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># ^: excluding root</span></span><br><span class="line">lsof +D /home -u ^root</span><br><span class="line"></span><br><span class="line"><span class="comment"># -a: and operation</span></span><br><span class="line"><span class="comment"># default is or operation</span></span><br><span class="line">lsof -u mary -c ssh -a</span><br></pre></td></tr></table></figure></p>
<p>当然在network上<code>lsof</code>也很强大:<br><a href="https://danielmiessler.com/study/lsof/" target="_blank" rel="noopener">An lsof primer</a><br><a href="https://www.howtogeek.com/426031/how-to-use-the-linux-lsof-command/" target="_blank" rel="noopener">How to se lsof command</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Kill Defunct Process</title>
    <url>/2019/06/05/linux-defunct-process/</url>
    <content><![CDATA[<p>Today after killing a running process, it didn’t disappear but was marked as <code>&lt;defunct&gt;</code> (run <code>ps</code> can see it). What’s this?</p>
<p>Processes marked <code>&lt;defunct&gt;</code> are dead processes (so-called <code>zombies</code>) that remain because their parent has not destroyed them properly. These processes will be destroyed by <code>init(8)</code> if the parent process exits.</p>
<p>On Unix and Unix-like computer operating systems, a <code>zombie process</code> or <code>defunct process</code> is a process that has completed execution but still has an entry in the process table. This entry is still needed to allow the parent process to read its child’s exit status.</p>
<p>There is no harm in letting such processes be unless there are many of them. <code>Zombie</code> is eventually reaped by its parent (by calling wait(2)). If original parent hasn’t reaped it before its own exit then init process (PID == <code>1</code>) does it at some later time.</p>
<p>I checked the PPID of that <code>defunct</code> process, it’s not PID 1 but other shell process. By killing its parent process, the zombie is gone. Determine which is the parent process of this defunct process and kill it. To know this run the command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -ef | grep defunct</span><br></pre></td></tr></table></figure></p>
<p>You can also use this command to verify defunct process is gone.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># To see every process on the system using standard syntax:</span></span><br><span class="line">ps -ef</span><br><span class="line"></span><br><span class="line"><span class="comment"># To see every process on the system using BSD syntax:</span></span><br><span class="line">ps aux</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>process</tag>
      </tags>
  </entry>
  <entry>
    <title>cURL Use Case Summary</title>
    <url>/2019/05/23/linux-curl-summary/</url>
    <content><![CDATA[<p><code>cURL</code> stands for ‘Client URL’, it is a command-line tool for getting or sending data including files using URL syntax. Since <code>cURL</code> uses <code>libcurl</code>, it supports a range of common network protocols, currently including HTTP, HTTPS, FTP, FTPS, SCP, SFTP, TFTP, LDAP, DAP, DICT, TELNET, FILE, IMAP, POP3, SMTP and RTSP.</p>
<p>Here is a open-source book: <a href="https://ec.haxx.se/" target="_blank" rel="noopener">Everything curl</a></p>
<p>About proxy environment variables:<br><a href="https://ec.haxx.se/usingcurl/usingcurl-proxies#proxy-environment-variables" target="_blank" rel="noopener">https://ec.haxx.se/usingcurl/usingcurl-proxies#proxy-environment-variables</a><br>env variables can only be on lower case:<br><code>http_proxy</code> for http proxy<br><code>https_proxy</code> for https proxy (这里指的是CONNECT method)</p>
<p><code>NO_PROXY</code> or <code>--noproxy</code> to skip proxy use.</p>
<p>################################################################<br>#  &emsp; Date &emsp; &emsp; &emsp; &emsp; &emsp; Description<br>#  &emsp; 05/23/2019 &emsp; &emsp; download file<br>#  &emsp; 06/16/2019 &emsp; &emsp; http request verbose<br>#  &emsp; 06/22/2020 &emsp; &emsp; redirect, PUT/GET/DELETE<br>#  &emsp; 09/02/2020 &emsp; &emsp; check headers only<br>#  &emsp; 09/03/2020 &emsp; &emsp; use specific forward proxy<br>#  &emsp; 09/06/2020 &emsp; &emsp; resume download<br>#  &emsp; 09/07/2020 &emsp; &emsp; limit rate<br>#  &emsp; 09/08/2020 &emsp; &emsp; fetch headers only<br>#  &emsp; 09/09/2020 &emsp; &emsp; proxy tunnel<br>#<br>################################################################</p>
<h2 id="05-23-2019"><a href="#05-23-2019" class="headerlink" title="05/23/2019"></a>05/23/2019</h2><p>If the file server needs user name/password (usually will prompt when you open in browser).<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">USER=<span class="string">"username"</span></span><br><span class="line">PASSWD=<span class="string">"passwd"</span></span><br><span class="line">USER_PWD=<span class="string">"<span class="variable">$USER</span>:<span class="variable">$PASSWD</span>"</span></span><br><span class="line">STREAMURL=<span class="string">"https://ips-file.xx.com/Builds/InformationServer/10.5.1/release/target.tar.gz"</span></span><br><span class="line"><span class="comment">## downlaod file with user/password to server</span></span><br><span class="line">curl -k -u <span class="variable">$&#123;USER_PWD&#125;</span> -LO <span class="variable">$&#123;STREAMURL&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## download file with custom name and slient</span></span><br><span class="line">curl -sS &lt;url&gt; -o /tmp/archive.tgz</span><br></pre></td></tr></table></figure></p>
<p><code>-O</code>: downloads the file and saves it with the same name as in the URL.<br><code>-u</code>: specify “user:password”<br><code>-k</code>: explicitly allows curl to perform ‘insecure’ SSL connections and transfers.<br><code>-L</code>: allow redirect<br><code>-o</code>: custom file name<br><code>-s</code>: slient all output<br><code>-S</code>: used with slient, output error message</p>
<p>If you don’t turn off the certificate check, you will get error message and fail:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">curl:</span> <span class="string">(60)</span> <span class="string">Peer's</span> <span class="string">Certificate</span> <span class="string">has</span> <span class="string">expired.</span></span><br><span class="line"><span class="string">More</span> <span class="string">details</span> <span class="attr">here:</span> <span class="attr">http://curl.haxx.se/docs/sslcerts.html</span></span><br><span class="line"></span><br><span class="line"><span class="string">curl</span> <span class="string">performs</span> <span class="string">SSL</span> <span class="string">certificate</span> <span class="string">verification</span> <span class="string">by</span> <span class="string">default,</span> <span class="string">using</span> <span class="string">a</span> <span class="string">"bundle"</span></span><br><span class="line"> <span class="string">of</span> <span class="string">Certificate</span> <span class="string">Authority</span> <span class="string">(CA)</span> <span class="string">public</span> <span class="string">keys</span> <span class="string">(CA</span> <span class="string">certs).</span> <span class="string">If</span> <span class="string">the</span> <span class="string">default</span></span><br><span class="line"> <span class="string">bundle</span> <span class="string">file</span> <span class="string">isn't</span> <span class="string">adequate,</span> <span class="string">you</span> <span class="string">can</span> <span class="string">specify</span> <span class="string">an</span> <span class="string">alternate</span> <span class="string">file</span></span><br><span class="line"> <span class="string">using</span> <span class="string">the</span> <span class="bullet">--cacert</span> <span class="string">option.</span></span><br><span class="line"><span class="string">If</span> <span class="string">this</span> <span class="string">HTTPS</span> <span class="string">server</span> <span class="string">uses</span> <span class="string">a</span> <span class="string">certificate</span> <span class="string">signed</span> <span class="string">by</span> <span class="string">a</span> <span class="string">CA</span> <span class="string">represented</span> <span class="string">in</span></span><br><span class="line"> <span class="string">the</span> <span class="string">bundle,</span> <span class="string">the</span> <span class="string">certificate</span> <span class="string">verification</span> <span class="string">probably</span> <span class="string">failed</span> <span class="string">due</span> <span class="string">to</span> <span class="string">a</span></span><br><span class="line"> <span class="string">problem</span> <span class="string">with</span> <span class="string">the</span> <span class="string">certificate</span> <span class="string">(it</span> <span class="string">might</span> <span class="string">be</span> <span class="string">expired,</span> <span class="string">or</span> <span class="string">the</span> <span class="string">name</span> <span class="string">might</span></span><br><span class="line"> <span class="string">not</span> <span class="string">match</span> <span class="string">the</span> <span class="string">domain</span> <span class="string">name</span> <span class="string">in</span> <span class="string">the</span> <span class="string">URL).</span></span><br><span class="line"><span class="string">If</span> <span class="string">you'd</span> <span class="string">like</span> <span class="string">to</span> <span class="string">turn</span> <span class="string">off</span> <span class="string">curl's</span> <span class="string">verification</span> <span class="string">of</span> <span class="string">the</span> <span class="string">certificate,</span> <span class="string">use</span></span><br><span class="line"> <span class="string">the</span> <span class="bullet">-k</span> <span class="string">(or</span> <span class="bullet">--insecure)</span> <span class="string">option.</span></span><br></pre></td></tr></table></figure></p>
<h2 id="06-16-2019"><a href="#06-16-2019" class="headerlink" title="06/16/2019"></a>06/16/2019</h2><p>When I was working on <a href="https://chengdol.github.io/2019/06/10/docker-registry-api/" target="_blank" rel="noopener">Docker Registry API</a>, I primarily use <code>curl</code> to do the job.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -v -k -X GET http://localhost:5000/v2/_catalog</span><br></pre></td></tr></table></figure></p>
<p><code>-v</code>: Makes the fetching more verbose/talkative. Mostly useful for debugging. A line starting with <code>&gt;</code> means <code>header data</code> sent by curl, <code>&lt;</code> means <code>header data</code> received by curl that is hidden in normal cases, and a line starting with <code>*</code> means additional info provided by curl.<br><code>-X</code>: (HTTP) Specifies a custom request method to use when communicating with the HTTP server.</p>
<h2 id="06-22-2020"><a href="#06-22-2020" class="headerlink" title="06/22/2020"></a>06/22/2020</h2><p>在学习Consul 和 Vault的时候，它们有HTTP API接口，会用到curl:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -L: redirect</span></span><br><span class="line"><span class="comment">## -i: include response header info to output</span></span><br><span class="line">curl -iL http://...</span><br><span class="line"></span><br><span class="line"><span class="comment">## -v: verbose, to see better error message</span></span><br><span class="line"><span class="comment">## 比如开了防火墙，网页打不开，可以用-v 检查一下输出</span></span><br><span class="line">curl -v http://...</span><br><span class="line"></span><br><span class="line"><span class="comment">## -d|--data: value to be put</span></span><br><span class="line"><span class="comment">##  -X, --request</span></span><br><span class="line">curl -X PUT -d <span class="string">'50s'</span> http://localhost:8500/v1/kv/prod/portal/haproxy/timeout-server</span><br><span class="line">curl -X DELETE http://localhost:8500/v1/kv/prod/portal/haproxy/timeout-server</span><br><span class="line">curl -X GET http://localhost:8500/v1/kv/prod/portal/haproxy/timeout-server?pretty</span><br></pre></td></tr></table></figure></p>
<h2 id="09-02-2020"><a href="#09-02-2020" class="headerlink" title="09/02/2020"></a>09/02/2020</h2><p>添加header，仅仅显示headers，以及隐藏output:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -H,--header: add header</span></span><br><span class="line"><span class="comment">## -L: redirect</span></span><br><span class="line"><span class="comment">## -I: fetch headers only</span></span><br><span class="line"><span class="comment">## -v: show request headers</span></span><br><span class="line"><span class="comment">## -s: hide progress bar, slient</span></span><br><span class="line"><span class="comment">## &gt; /dev/null: hide output, show only the -v output</span></span><br><span class="line">curl --header <span class="string">"Host: chengdol.github.io"</span> --header <span class="string">"..."</span> -L -Ivs http://185.199.110.153 &gt; /dev/null</span><br></pre></td></tr></table></figure></p>
<h2 id="09-03-2020"><a href="#09-03-2020" class="headerlink" title="09/03/2020"></a>09/03/2020</h2><p>Using HTTP proxy (forward) with proxy authentication, learned from Envoy migration.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -x, --proxy: use the specific forward proxy</span></span><br><span class="line">curl -v -x &lt;proxy:port&gt; http://www.example.com</span><br><span class="line"><span class="comment">## the same as</span></span><br><span class="line">http_proxy=&lt;proxy:port&gt; curl -v -x http://www.example.com</span><br><span class="line"></span><br><span class="line"><span class="comment">## -U, --proxy-user: user/password for proxy authentication</span></span><br><span class="line"><span class="comment">## this option override the existing proxy environment variable </span></span><br><span class="line">curl -v -x &lt;proxy:port&gt; -U &lt;user:password&gt; http://www.example.com</span><br></pre></td></tr></table></figure></p>
<p>Default to use basic authentication scheme, Some proxies will require another authentication scheme (and the headers that are returned when you get a 407 response will tell you which).<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## --proxy-anyauth: ask curl to use any method the proxy wants</span></span><br><span class="line">curl -U &lt;user:password&gt; -x myproxy:80 http://example.com --proxy-anyauth</span><br></pre></td></tr></table></figure></p>
<p>When using HTTPS proxy (tunnel), just an example with no authz here:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -v -x &lt;proxy:port&gt; https://www.example.com</span><br><span class="line"><span class="comment">## the same as</span></span><br><span class="line">https_proxy=&lt;proxy:port&gt; curl -v -x http://www.example.com</span><br></pre></td></tr></table></figure></p>
<h2 id="09-06-2020"><a href="#09-06-2020" class="headerlink" title="09/06/2020"></a>09/06/2020</h2><p><code>wget</code> can do the same thing.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl &lt;url&gt; -o archive</span><br><span class="line"><span class="comment">## then break and resume</span></span><br><span class="line"><span class="comment">## -C -: automatrically resume from the break point</span></span><br><span class="line">curl &lt;url&gt; -C - -o archive</span><br></pre></td></tr></table></figure></p>
<h2 id="09-07-2020"><a href="#09-07-2020" class="headerlink" title="09/07/2020"></a>09/07/2020</h2><p>Download/upload speed limit if you have a limit bandwidth.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## limit rate as 1m/second</span></span><br><span class="line"><span class="comment">## for example: 10k, 1g</span></span><br><span class="line">curl &lt;url&gt; -O --<span class="built_in">limit</span>-rate 1m</span><br></pre></td></tr></table></figure></p>
<h2 id="09-08-2020"><a href="#09-08-2020" class="headerlink" title="09/08/2020"></a>09/08/2020</h2><p>Only fetch header information, no body:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -I,--head: (HTTP FTP FILE) Fetch the headers only!</span></span><br><span class="line"><span class="comment">## notice that -i is to have response header to output, they are different</span></span><br><span class="line">curl -I &lt;url&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="09-09-2020"><a href="#09-09-2020" class="headerlink" title="09/09/2020"></a>09/09/2020</h2><p>Non-HTTP protocols over HTTP proxy<br>Most HTTP proxies allow clients to “tunnel through” it to a server on the other side. That’s exactly what’s done every time you use HTTPS through the HTTP proxy. CONNECT tunnel不仅仅针对HTTPS的，其他协议也可以借助于这个通道进行通信.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -p, --proxytunnel: make curl tunnel through the proxy</span></span><br><span class="line"><span class="comment">## used with -x, --proxy options</span></span><br><span class="line"><span class="comment">## here tunnel ftp protocol</span></span><br><span class="line">curl -p -x http://proxy.example.com:80 ftp://ftp.example.com/file.txt</span><br></pre></td></tr></table></figure></p>
<h2 id="10-25-2020"><a href="#10-25-2020" class="headerlink" title="10/25/2020"></a>10/25/2020</h2><p><a href="https://daniel.haxx.se/blog/2018/04/05/curl-another-host/" target="_blank" rel="noopener">https://daniel.haxx.se/blog/2018/04/05/curl-another-host/</a><br>curl <code>--connect-to</code> option, 有的curl版本没有这个功能，要注意。用法是你不想curl去解析你给的URL中的hostname, 你告诉curl去其他地方，也就是这个URL真正的地址:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 这个example.com实际上是在localhost:8843 (自己搭建的)</span></span><br><span class="line"><span class="comment">## 如果不用--connect-to，那么curl会解析这个example.com然后到其他地方去了</span></span><br><span class="line">curl --connect-to example.com:443:localhost:8843 https://example.com/</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title>Check Linux Distributions</title>
    <url>/2019/03/27/linux-distros/</url>
    <content><![CDATA[<p>I encounter a problem that check which OS is running in my docker container, or extend it as how to check which OS am I using?<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /etc/os-release</span><br><span class="line"></span><br><span class="line">NAME=&quot;Red Hat Enterprise Linux Server&quot;</span><br><span class="line">VERSION=&quot;7.5 (Maipo)&quot;</span><br><span class="line">ID=&quot;rhel&quot;</span><br><span class="line">ID_LIKE=&quot;fedora&quot;</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hostnamectl</span><br><span class="line"></span><br><span class="line">Static hostname: example.com</span><br><span class="line">        Icon name: computer-vm</span><br><span class="line">          Chassis: vm</span><br><span class="line">       Machine ID: e57cfe9136e9430587366e04f14195e1</span><br><span class="line">          Boot ID: 6ebe05de8b7f43c0bfa36d2c62b702de</span><br><span class="line">   Virtualization: kvm</span><br><span class="line"> Operating System: Red Hat Enterprise Linux Server 7.5 (Maipo)</span><br><span class="line">      CPE OS Name: cpe:/o:redhat:enterprise_linux:7.5:GA:server</span><br><span class="line">           Kernel: Linux 3.10.0-862.14.4.el7.x86_64</span><br><span class="line">     Architecture: x86-64</span><br></pre></td></tr></table></figure>
<p>For docker image, you can use <code>docker image inspect</code> command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker image inspect &lt;image name&gt;:&lt;tag&gt; | grep -i &quot;base image&quot;</span><br><span class="line"></span><br><span class="line">&quot;org.label-schema.schema-version&quot;: &quot;= 1.0  </span><br><span class="line">org.label-schema.name=CentOS Base Image  </span><br><span class="line">org.label-schema.vendor=CentOS</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux DNS Explore</title>
    <url>/2019/11/04/linux-dns/</url>
    <content><![CDATA[<p>这个问题很有意思，最开始我并没有意识到这其实是个DNS问题，后来随着逐步深入排查，解决了一些有干扰的边边角角的错误，才发现。</p>
<p>问题的开始是当集群中docker registry 已经正常运行的时候，docker push 以及 docker pull不能正常工作，retry 超时。当时的push 路径是以hostname为主的，比如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dal12-3m-3w-testcluster-03master-00.demo.ibmcloud.com:5000/is-realtime-busybox         latest              db8ee88ad75f        3 months ago        1.22MB</span><br></pre></td></tr></table></figure></p>
<p>很奇怪的是docker push操作就在docker registry pod的宿主机上进行，居然还是不行，如果把地址改成<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">localhost:5000/is-realtime-busybox         latest              db8ee88ad75f        3 months ago        1.22MB</span><br></pre></td></tr></table></figure></p>
<p>就可以，这让我首先意识到是域名解析的问题，我的第一反应是查看各个节点上的<code>/etc/hosts</code>文件，完全没问题, <code>ping</code>命令也OK，奇了怪了。</p>
<p>让我们来再仔细的检查一下域名配置：<br>参考这篇文章：<br><a href="https://www.tecmint.com/setup-local-dns-using-etc-hosts-file-in-linux/" target="_blank" rel="noopener">https://www.tecmint.com/setup-local-dns-using-etc-hosts-file-in-linux/</a><br>查看<code>/etc/nsswitch.conf</code>可知域名查询时的顺序:<br>值得注意的是，有的malicious scripting或病毒可能会更改你的nsswitch.conf文件。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#hosts:     db files nisplus nis dns</span></span><br><span class="line">hosts:      files dns</span><br></pre></td></tr></table></figure></p>
<p>files就是指<code>/etc/hosts</code>, dns指DNS server，说明确实是先看local file <code>/etc/hosts</code>的。</p>
<p>查看<code>/etc/resolv.conf</code>，这个就是DNS server的地址了，貌似也没啥问题。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nameserver 10.0.80.11</span><br><span class="line">nameserver 10.0.80.12</span><br></pre></td></tr></table></figure></p>
<p>我大胆猜测了一下有的命令可能不会使用local dns file <code>/etc/hosts</code>，我试了试<code>host</code> command，果然如此：<br><a href="https://serverfault.com/questions/498500/why-does-the-host-command-not-resolve-entries-in-etc-hosts" target="_blank" rel="noopener">Why does the host command not resolve entries in /etc/hosts?</a><br>这个答案还告诉了我另一个命令<code>getent</code>，对于查询<code>/etc/hosts</code>挺方便的。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">getent hosts halos1</span><br></pre></td></tr></table></figure></p>
<p>You will find that <code>dig</code> and <code>nslookup</code> behave the same way as <code>host</code>, the purpose of all of these commands is to do DNS lookups, not to look in files.</p>
<p>后来我让别人把master node的域名和IP加入到集群访问的DNS Server中，问题就解决了！</p>
<p>所以，下次遇到类似问题，除了检查本地DNS配置和文件，还要用<code>host</code> command试一下，看看外部DNS Server是否工作正常，最重要的是，有的命令不会使用<code>/etc/hosts</code>去查询。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Double Level Softlink</title>
    <url>/2019/09/27/linux-double-softlink/</url>
    <content><![CDATA[<p>This blog shows how double level softlink can be a good workaround for some situations.</p>
<p>We need to link persistent data to a directory under <code>/</code> in a container or pod, for example: <code>/data</code>, this folder is owned by <code>demo</code>, <code>demo</code> is also the start user of the container.</p>
<p>在pod中有个<code>/data</code> folder, owned by <code>demo</code>，我们想persist这个folder的内容. 在这个pod中有个mount point <code>/mnt</code>. 于是想把<code>/data</code> map到 <code>/mnt/data</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ln -s &lt;target&gt; &lt;link name&gt;</span></span><br><span class="line"><span class="comment"># 这样相当于/mnt/data 是个link</span></span><br><span class="line">ln -s /data /mnt/data</span><br></pre></td></tr></table></figure></p>
<p>这样是不对的，从pod外部的storage provisioner看 <code>/min/data</code>仅仅是个borken link.</p>
<p>The correct way is first remove <code>/data</code> then <code>ln -s /mnt/data /data</code> (<code>/data</code>变成了快捷方式，所以写入<code>/data</code>的内容实际上被写入了<code>/mnt/data</code>), but <code>demo</code> is a non-root user without super privilege, it cannot remove <code>/data</code> (<code>/</code> is owned by root).</p>
<p>Let’s see how double level softlink can help:</p>
<ol>
<li>first in docker build time remove <code>/data</code>: <code>rm -rf /data</code></li>
<li>create a intermediary: <code>mkdir -p /home/demo/data &amp;&amp; chown demo:demo /home/demo/data</code></li>
<li>link: <code>ln -s /home/demo/data /data</code></li>
</ol>
<p>then commit the changes into image.</p>
<p>when container start, in the entrypoint:</p>
<ol>
<li>first remove <code>/home/demo/data</code>: <code>rm -rf /home/demo/data</code>, this will make link to <code>/data</code> break.</li>
<li>create another link: <code>ln -s /mnt/data /home/demo/data</code>, now link connected and fixed.</li>
</ol>
<p>So finally the link structure is:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/mnt/data -&gt; /home/demo/data -&gt; /data</span><br></pre></td></tr></table></figure></p>
<p><code>/home/demo/data</code> is a agent between persistent mount<code>/mnt/data</code> and <code>/data</code>.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux getfacl and setfacl Commands</title>
    <url>/2019/09/25/linux-getfacl-setfacl/</url>
    <content><![CDATA[<p>Today I learn a new method to operate on permission of files and directories, usually I use <code>chmod</code> and <code>chown</code>.</p>
<p>One thing you need to be clear is if for example <code>/etc</code> is owned by root, and <code>/etc/xxx</code> is owned by <code>demo</code> (non-root) user, <code>demo</code> cannot remove <code>/etc/xxx</code> because of permission deny, but <code>demo</code> can create soft link from <code>/etc/xxx</code> and do all other operations inside <code>/etc/xxx</code>.</p>
<p>What if <code>demo</code> want to remove <code>/etc/xxx</code> without changing permissiond of <code>/etc</code> by <code>chmod</code> or <code>chown</code> and without <code>sudo</code>? <code>setfacl</code> is a good choice.</p>
<blockquote>
<p>Note that docker will not allow commit the change of any permission of <code>/</code> directory into image.</p>
</blockquote>
<p>Each file and directory in a Linux filesystem is created with <code>Access Control Lists (ACLs)</code>. The permissions can be set using the <code>setfacl</code> utility. In order to know the access permissions of a file or directory we use <code>getfacl</code>.</p>
<p>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># getfacl /etc</span><br><span class="line"></span><br><span class="line">getfacl: Removing leading &apos;/&apos; from absolute path names</span><br><span class="line"># file: etc/</span><br><span class="line"># owner: root</span><br><span class="line"># group: root</span><br><span class="line">user::rwx</span><br><span class="line">group::r-x</span><br><span class="line">other::r-x</span><br></pre></td></tr></table></figure></p>
<p>then we add <code>demo</code> full permission to <code>/etc</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## run as root</span></span><br><span class="line">setfacl -m u:demo:rwx /etc</span><br></pre></td></tr></table></figure></p>
<p>check again:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># getfacl /etc</span><br><span class="line"></span><br><span class="line">getfacl: Removing leading &apos;/&apos; from absolute path names</span><br><span class="line"># file: etc</span><br><span class="line"># owner: root</span><br><span class="line"># group: root</span><br><span class="line">user::rwx</span><br><span class="line">user:demo:rwx</span><br><span class="line">group::r-x</span><br><span class="line">mask::rwx</span><br><span class="line">other::r-x</span><br></pre></td></tr></table></figure></p>
<p>I have this question:<br><a href="https://unix.stackexchange.com/questions/364517/difference-between-chmod-vs-acl" target="_blank" rel="noopener">Difference between chmod vs ACL</a></p>
<p>Under Linux, <code>ls -l</code> puts a <code>+</code> at the end of the permissions characters to indicate that <code>ACL</code> are present. If <code>ACL</code> are presenting then the basic permissions do not tell the full story: ACL override POSIX permissions:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ls -l /etc</span><br><span class="line"></span><br><span class="line">drwxrwxr-x+ 89 root root 8192 Sep 25 16:24</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>ip Command</title>
    <url>/2020/02/04/linux-ip-command/</url>
    <content><![CDATA[<p>//TODO<br>[ ] <code>ip</code> vs <code>iptables</code> 各自用在什么地方?</p>
<p><code>ip</code> command in Linux is present in the <code>iproute</code> package which is used for performing several network administration tasks. IP stands for Internet Protocol.</p>
<p><code>ifconfig</code> is obsolete.</p>
<p>It can perform several tasks like configuring and modifying the default and static routing, setting up tunnel over IP, listing IP addresses and property information, modifying the status of the interface, assigning, deleting and setting up IP addresses and routes.</p>
<p>Explanations:<br><a href="https://linuxize.com/post/linux-ip-command/" target="_blank" rel="noopener">Linux ip Command with Examples</a><br><a href="http://man7.org/linux/man-pages/man8/ip.8.html" target="_blank" rel="noopener">Linux manual page: ip</a></p>
<p>Most frequently used subcommands:</p>
<ul>
<li>link (l) - Display and modify network interfaces.</li>
<li>address (a) - Display and modify IP Addresses.</li>
<li>route (r) - Display and alter the routing table.</li>
<li>neigh (n) - Display and manipulate neighbor objects (ARP table).</li>
<li>netns - deal with network namespace</li>
</ul>
<p>The configurations set with the ip command are <strong>not</strong> persistent. After a system restart, all changes are lost. For permanent settings, you need to edit the distro-specific configuration files or add the commands to a startup script.</p>
<h2 id="address"><a href="#address" class="headerlink" title="address"></a>address</h2><p>Show all IP address associated with all interfaces that are available<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip addr</span><br><span class="line"><span class="comment">## abbr</span></span><br><span class="line">ip a</span><br><span class="line"><span class="comment">## only show ipv4</span></span><br><span class="line">ip -4 a</span><br><span class="line"><span class="comment">## show specified device</span></span><br><span class="line">ip addr show eth0</span><br><span class="line"><span class="comment">## abbr</span></span><br><span class="line">ip a s eth0</span><br><span class="line"><span class="comment">## assign an IP address to an interface. (need append netmask)</span></span><br><span class="line"><span class="comment">## can assign multiple ip address to an interface</span></span><br><span class="line"><span class="comment">## not persistent</span></span><br><span class="line">ip addr add 192.168.1.50/24 dev eth0</span><br><span class="line"><span class="comment">## delete an assigned IP address to an interface. (need append netmask)</span></span><br><span class="line">ip addr del 192.168.1.50/24 dev eth0</span><br></pre></td></tr></table></figure></p>
<h2 id="link"><a href="#link" class="headerlink" title="link"></a>link</h2><p>It is used to display <code>link layer</code> information, like MAC address, it will fetch characteristics of the link layer devices currently available. Any networking device which has a driver loaded can be classified as an available device.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip link</span><br><span class="line"><span class="comment">## show statistic of device with human readable format</span></span><br><span class="line"><span class="comment">## 显示有多少error, drop packets来看是不是网络由问题</span></span><br><span class="line">ip -s -h link</span><br><span class="line">ip -s -h link show eth0</span><br><span class="line"><span class="comment">## bring up</span></span><br><span class="line">ip link <span class="built_in">set</span> eth0 up</span><br><span class="line"><span class="comment">## bring down</span></span><br><span class="line">ip link <span class="built_in">set</span> eth0 down</span><br></pre></td></tr></table></figure></p>
<h2 id="route"><a href="#route" class="headerlink" title="route"></a>route</h2><p>This command helps you to see the route packets your network will take as set in your <strong>kernel routing table</strong>. The first entry is the default route.<br>Other commands perform the same: <code>route</code>, <code>netstat -r</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip route</span><br><span class="line"><span class="comment">## route for a specific network</span></span><br><span class="line">ip route list 9.30.204.0/22</span><br><span class="line"><span class="comment">## add a route to 192.168.121.0/24 via the gateway at 192.168.121.1</span></span><br><span class="line">ip route add 192.168.121.0/24 via 192.168.121.1</span><br><span class="line"><span class="comment">## add a route to 192.168.121.0/24 that can be reached on device eth0.</span></span><br><span class="line">ip route add 192.168.121.0/24 dev eth0</span><br></pre></td></tr></table></figure></p>
<h2 id="neigh"><a href="#neigh" class="headerlink" title="neigh"></a>neigh</h2><h2 id="netns"><a href="#netns" class="headerlink" title="netns"></a>netns</h2>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux IPC</title>
    <url>/2019/05/01/linux-ipc/</url>
    <content><![CDATA[<h2 id="Prequel"><a href="#Prequel" class="headerlink" title="Prequel"></a>Prequel</h2><p>Recently I was dealing with Linux kernel parameters, which are new to me and in my case they are the key to performance of the Database (DB2). This story is about removing <code>SYS_ADMIN</code> and <code>SYS_RESOURCE</code> Linux capabilities for K8s container </p>
<blockquote>
<p>Forget what is Linux capability? See my blog <a href="https://chengdol.github.io/2019/05/13/linux-capability/" target="_blank" rel="noopener"><code>&lt;&lt;Linux Capability</code>&gt;&gt;</a></p>
</blockquote>
<p>In <a href="https://www.ibm.com/support/knowledgecenter/en/SSEPGG_11.1.0/com.ibm.db2.luw.qb.server.doc/doc/c0057140.html" target="_blank" rel="noopener">Db2 IPC kernel parameters doc</a>, the database manager uses a formula to automatically adjust kernel parameter settings and eliminate the need for manual updates to these settings.</p>
<p>When instances are started, if an <code>interprocess communication (IPC)</code> kernel parameter is below the enforced minimum value, the database manager updates it to the enforced minimum value. The IPC kernel parameter values change when a Db2 instance is started.</p>
<p>There are severl Linux interprocess communication kernel parameters need to be adjusted for Db2:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kernel.shmmni (SHMMNI)</span><br><span class="line">kernel.shmmax (SHMMAX)</span><br><span class="line">kernel.shmall (SHMALL)</span><br><span class="line">kernel.sem (SEMMNI)</span><br><span class="line">kernel.sem (SEMMSL)</span><br><span class="line">kernel.sem (SEMMNS)</span><br><span class="line">kernel.sem (SEMOPM)</span><br><span class="line">kernel.msgmni (MSGMNI)</span><br><span class="line">kernel.msgmax (MSGMAX)</span><br><span class="line">kernel.msgmnb (MSGMNB)</span><br></pre></td></tr></table></figure></p>
<p>If you check <code>SYS_RESOURCE</code> <a href="http://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">manual</a>, you can see:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CAP_SYS_RESOURCE</span><br><span class="line">...</span><br><span class="line">  * raise msg_qbytes limit for a System V message queue above</span><br><span class="line">    the limit in /proc/sys/kernel/msgmnb (see msgop(2) and</span><br><span class="line">    msgctl(2));</span><br><span class="line">  * use F_SETPIPE_SZ to increase the capacity of a pipe above</span><br><span class="line">    the limit specified by /proc/sys/fs/pipe-max-size;</span><br><span class="line">  * override /proc/sys/fs/mqueue/queues_max limit when creating</span><br><span class="line">    POSIX message queues (see mq_overview(7));</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>Without granting <code>SYS_RESOURCE</code>, <code>msgmnb</code> (maybe also other kernel parameters) cannot be changed properly (actually I doubt this after checking having and not having <code>SYS_RESOURCE</code> result).</p>
<p>If there is no <code>SYS_RESOURCE</code>, one workaround is to use <code>sysctl</code> in K8s (I will talk this later…), but in my case I cannot modify kubelet configuration thus this method doesn’t work.</p>
<p>Now what we did was just removing the Linux capabilities and ran test suite to expose failures and errors with xmeta pods.</p>
<h2 id="IPC-thing"><a href="#IPC-thing" class="headerlink" title="IPC thing"></a>IPC thing</h2><p>Let’s first understand what is IPC? </p>
<p><a href="http://en.tldp.org/LDP/tlk/ipc/ipc.html" target="_blank" rel="noopener">IPC Mechanisms</a><br><a href="http://www.chandrashekar.info/articles/linux-system-programming/introduction-to-linux-ipc-mechanims.html" target="_blank" rel="noopener">IPC Mechanisms on Linux - Introduction</a></p>
<p>This post website seems going to die, just forward it here (after I go through it, I can still remember some tech words from 402 Operating System, but I forget the detail):</p>
<p><code>Inter-Process-Communication</code> (or IPC for short) are mechanisms provided by the kernel to allow processes to communicate with each other. On modern systems, IPCs form the web that bind together each process within a large scale software architecture.</p>
<p>The Linux kernel provides the following IPC mechanisms:</p>
<ol>
<li>Signals</li>
<li>Anonymous Pipes</li>
<li>Named Pipes or FIFOs</li>
<li>SysV Message Queues</li>
<li>POSIX Message Queues</li>
<li>SysV Shared memory</li>
<li>POSIX Shared memory</li>
<li>SysV semaphores</li>
<li>POSIX semaphores</li>
<li>FUTEX locks</li>
<li>File-backed and anonymous shared memory using mmap</li>
<li>UNIX Domain Sockets</li>
<li>Netlink Sockets</li>
<li>Network Sockets</li>
<li>Inotify mechanisms</li>
<li>FUSE subsystem</li>
<li>D-Bus subsystem</li>
</ol>
<p>While the above list seems quite a lot, each IPC mechanism from the list describe above , is tailored to work better for a particular use-case scenario.</p>
<ul>
<li><p>SIGNALS<br>Signals are the cheapest forms of IPC provided by Linux. Their primary use is to notify processes of change in states or events that occur within the kernel or other processes. We use signals in real world to convey messages with least overhead - think of hand and body gestures. For example, in a crowded gathering, we raise a hand to gain attention, wave hand at a friend to greet and so on.</p>
<p>On Linux, the kernel notifies a process when an event or state change occurs by interrupting the process’s normal flow of execution and invoking one of the signal handler functinos registered by the process or by the invoking one of the default signal dispositions supplied by the kernel, for the said event.</p>
</li>
<li><p>ANONYMOUS PIPES<br>Anonymous pipes (or simply pipes, for short) provide a mechanism for one process to stream data to another. A pipe has two ends associated with a pair of file descriptors - making it a one-to-one messaging or communication mechanism. One end of the pipe is the read-end which is associated with a file-descriptor that can only be read, and the other end is the write-end which is associated with a file descriptor that can only be written. This design means that pipes are essentially half-duplex.</p>
<p>Anonymous pipes can be setup and used only between processes that share parent-child relationship. Generally the parent process creates a pipe and then forks child processes. Each child process gets access to the pipe created by the parent process via the file descriptors that get duplicated into their address space. This allows the parent to communicate with its children, or the children to communicate with each other using the shared pipe.</p>
<p>Pipes are generally used to implement Producer-Consumer design amongst processes - where one or more processes would produce data and stream them on one end of the pipe, while other processes would consume the data stream from the other end of the pipe.</p>
</li>
<li><p>NAMED PIPES OR FIFO<br>Named pipes (or FIFO) are variants of pipe that allow communication between processes that are not related to each other. The processes communicate using named pipes by opening a special file known as a FIFO file. One process opens the FIFO file from writing while the other process opens the same file for reading. Thus any data written by the former process gets streamed through a pipe to the latter process. The FIFO file on disk acts as the contract between the two processes that wish to communicate.</p>
</li>
<li><p>MESSAGE QUEUES<br>Message Queues are synonymous to mailboxes. One process writes a message packet on the message queue and exits. Another process can access the message packet from the same message queue at a latter point in time. The advantage of message queues over pipes/FIFOs are that the sender (or writer) processes do not have to wait for the receiver (or reader) processes to connect. Think of communication using pipes as similar to two people communicating over phone, while message queues are similar to two people communicating using mail or other messaging services.</p>
<p>There are two standard specifications for message queues.</p>
<ul>
<li><p>SysV message queues.<br>The AT&amp;T SysV message queues support message channeling. Each message packet sent by senders carry a message number. The receivers can either choose to receive message that match a particular message number, or receive all other messages excluding a particular message number or all messages.</p>
</li>
<li><p>POSIX message queues.<br>The POSIX message queues support message priorities. Each message packet sent by the senders carry a priority number along with the message payload. The messages get ordered based on the priority number in the message queue. When the receiver tries to read a message at a later point in time, the messages with higher priority numbers get delivered first. POSIX message queues also support asynchronous message delivery using threads or signal based notification.</p>
</li>
</ul>
<p>Linux support both of the above standards for message queues.</p>
</li>
<li><p>SHARED MEMORY<br>As the name implies, this IPC mechanism allows one process to share a region of memory in its address space with another. This allows two or more processes to communicate data more efficiently amongst themselves with minimal kernel intervention.</p>
<p>There are two standard specifications for Shared memory.</p>
<ul>
<li><p>SysV Shared memory. Many applications even today use this mechanism for historical reasons. It follows some of the artifacts of SysV IPC semantics.</p>
</li>
<li><p>POSIX Shared memory. The POSIX specifications provide a more elegant approach towards implementing shared memory interface. On Linux, POSIX Shared memory is actually implemented by using files backed by RAM-based filesystem. I recommend using this mechanism over the SysV semantics due to a more elegant file based semantics.</p>
</li>
</ul>
</li>
<li><p>SEMAPHORES<br>Semaphores are locking and synchronization mechanism used most widely when processes share resources. Linux supports both SysV semaphores and POSIX semaphores. POSIX semaphores provide a more simpler and elegant implementation and thus is most widely used when compared to SysV semaphores on Linux.</p>
</li>
<li><p>FUTEXES<br>Futexes are high-performance low-overhead locking mechanisms provided by the kernel. Direct use of futexes is highly discouraged in system programs. Futexes are used internally by POSIX threading API for condition variables and its mutex implementations.</p>
</li>
<li><p>UNIX DOMAIN SOCKETS<br>UNIX Domain Sockets provide a mechanism for implementing applications that communicate using the Client-Server architecture. They support both stream and datagram oriented communication, are full-duplex and support a variety of options. They are very widely used for developing many large-scale frameworks.</p>
</li>
<li><p>NETLINK SOCKETS<br>Netlink sockets are similar to UNIX Domain Sockets in its API semantics - but used mainly for two purposes:</p>
<p>For communication between a process in user-space to a thread in kernel-space<br>For communication amongst processes in user-space using broadcast mode.</p>
</li>
<li><p>NETWORK SOCKETS<br>Based on the same API semantics like UNIX Domain Sockets, Network Sockets API provide mechanisms for communication between processes that run on different hosts on a network. Linux has rich support for features and various protocol stacks for using network sockets API. For all kinds of network programming and distributed programming - network socket APIs form the core interface.</p>
</li>
</ul>
<ul>
<li><p>INOTIFY MECHANISMS<br>The Inotify API on Linux provides a method for processes to know of any changes on a monitored file or a directory asynchronously. By adding a file to inotify watch-list, a process will be notified by the kernel on any changes to the file like open, read, write, changes to file stat, deleting a file and so on.</p>
</li>
<li><p>FUSE SUBSYSTEM<br>FUSE provides a method to implement a fully functional filesystem in user-space. Various operations on the mounted FUSE filesystem would trigger functions registered by the user-space filesystem handler process. This technique can also be used as an IPC mechanism to implement Client-Server architecture without using socket API semantics.</p>
</li>
<li><p>D-BUS SUBSYSTEM<br>D-Bus is a high-level IPC mechanism built generally on top of socket API that provides a mechanism for multiple processes to communicate with each other using various messaging patterns. D-Bus is a standards specification for processes communicating with each other and very widely used today by GUI implementations on Linux following Freedesktop.org specifications.</p>
</li>
</ul>
<h2 id="IPC-Related-Commands"><a href="#IPC-Related-Commands" class="headerlink" title="IPC Related Commands"></a>IPC Related Commands</h2><p>you can use <code>ipcs</code> command to show IPC facilities information: shared memory segments, message queues, and semaphore arrays.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ipcs -l</span><br><span class="line"></span><br><span class="line">------ Shared Memory Limits --------</span><br><span class="line">max number of segments = 4096               // SHMMNI	</span><br><span class="line">max seg size (kbytes) = 32768               // SHMMAX</span><br><span class="line">max total shared memory (kbytes) = 8388608  // SHMALL</span><br><span class="line">min seg size (bytes) = 1</span><br><span class="line"></span><br><span class="line">------ Semaphore Limits --------</span><br><span class="line">max number of arrays = 1024                 // SEMMNI</span><br><span class="line">max semaphores per array = 250              // SEMMSL</span><br><span class="line">max semaphores system wide = 256000         // SEMMNS</span><br><span class="line">max ops per semop call = 32                 // SEMOPM</span><br><span class="line">semaphore max value = 32767</span><br><span class="line"></span><br><span class="line">------ Messages: Limits --------</span><br><span class="line">max queues system wide = 1024               // MSGMNI</span><br><span class="line">max size of message (bytes) = 65536         // MSGMAX</span><br><span class="line">default max size of queue (bytes) = 65536   // MSGMNB</span><br></pre></td></tr></table></figure>
<p>Also, you can use <code>sysctl</code> command to view kernel parameters:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#sysctl -a | grep -i shmmni</span></span><br><span class="line"><span class="string">kernel.shmmni</span> <span class="string">=</span> <span class="number">4096</span></span><br></pre></td></tr></table></figure></p>
<p>or<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#sysctl kernel.shmmni</span></span><br><span class="line"><span class="string">kernel.shmmni</span> <span class="string">=</span> <span class="number">4096</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Modify-Kernel-Parameters"><a href="#Modify-Kernel-Parameters" class="headerlink" title="Modify Kernel Parameters"></a>Modify Kernel Parameters</h2><p>From this post <a href="https://www.ibm.com/support/knowledgecenter/en/SSEPGG_11.1.0/com.ibm.db2.luw.qb.server.doc/doc/t0008238.html" target="_blank" rel="noopener">Db2 Modify Kernel Parameters</a>.</p>
<p>Modify the kernel parameters that you have to adjust by editing the <code>/etc/sysctl.conf</code> file. If this file does not exist, create it. The following lines are examples of what must be placed into the file:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kernel.shmmni=4096</span></span><br><span class="line"><span class="string">kernel.shmmax=17179869184</span></span><br><span class="line"><span class="string">kernel.shmall=8388608</span></span><br><span class="line"><span class="comment">#kernel.sem=&lt;SEMMSL&gt; &lt;SEMMNS&gt; &lt;SEMOPM&gt; &lt;SEMMNI&gt;</span></span><br><span class="line"><span class="string">kernel.sem=4096</span> <span class="number">1024000</span> <span class="number">250</span> <span class="number">4096</span></span><br><span class="line"><span class="string">kernel.msgmni=16384</span></span><br><span class="line"><span class="string">kernel.msgmax=65536</span></span><br><span class="line"><span class="string">kernel.msgmnb=65536</span></span><br></pre></td></tr></table></figure></p>
<p>Reload settings from the default file <code>/etc/sysctl.conf</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl -p</span><br></pre></td></tr></table></figure></p>
<p>For RedHat The rc.sysinit initialization script reads the <code>/etc/sysctl.conf</code> file automatically after every reboot.</p>
<p>You can also make the change not persistently, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl -w kernel.shmmni=4096</span><br><span class="line">sysctl -w kernel.sem=&quot;4096 1024000 250 4096&quot;</span><br></pre></td></tr></table></figure></p>
<p>or directly wirte into <code>procfs</code> files:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;4096 1024000 250 4096&quot; &gt; /proc/sys/kernel/sem</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ipc</tag>
      </tags>
  </entry>
  <entry>
    <title>nc/netcat Command</title>
    <url>/2020/10/25/linux-netcat-nc-summary/</url>
    <content><![CDATA[<p>I almost forget this command, but recently I used it as a TCP client to test Envoy TCP proxy. <code>nc</code> can also be a TCP server that listening on port and waiting for connection.<br><a href="https://www.tecmint.com/netcat-nc-command-examples/" target="_blank" rel="noopener">https://www.tecmint.com/netcat-nc-command-examples/</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install nc (netcat)</span></span><br><span class="line"><span class="comment"># on centos</span></span><br><span class="line">yum install -y nc</span><br><span class="line"><span class="comment"># on ubuntu</span></span><br><span class="line">apt install -y netcat</span><br></pre></td></tr></table></figure>
<p>Port scanning<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -v: verbose</span></span><br><span class="line"><span class="comment"># -z: just scan for listening daemons, without sending any data to them</span></span><br><span class="line"><span class="comment"># -w: timeout second</span></span><br><span class="line"><span class="comment"># scan port 22 and 8080</span></span><br><span class="line">nc -v -w 2 -z 127.0.0.1 22 8080</span><br><span class="line"><span class="comment"># range scan</span></span><br><span class="line">nc -v -w 2 -z 127.0.0.1 1-10004</span><br></pre></td></tr></table></figure></p>
<p>Connection check:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check if port is open, no need to go to server and run ps aux or netstat -tunlp</span></span><br><span class="line">nc -vvv baidu.com 443</span><br><span class="line">nc -vvv baidu.com 80</span><br></pre></td></tr></table></figure></p>
<p>Data transfer, also see <code>man nc</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># file will write to out</span></span><br><span class="line">nc -l 1234 &gt; filename.out</span><br><span class="line"></span><br><span class="line"><span class="comment"># file input</span></span><br><span class="line"><span class="comment"># -N: disconnet when finish</span></span><br><span class="line">nc -N host.example.com 1234 &lt; filename.in</span><br></pre></td></tr></table></figure></p>
<p>For folder transfer:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># - in tar </span></span><br><span class="line"><span class="comment"># destination</span></span><br><span class="line"><span class="comment"># after done you will see the folder</span></span><br><span class="line">nc -v -l 1234 | tar zxf -</span><br><span class="line"><span class="comment"># source</span></span><br><span class="line">tar czf - file | nc -N -v &lt;ip&gt; 1234</span><br></pre></td></tr></table></figure></p>
<p>Other ways to transfer files: scp, sftp, python http server.</p>
<p>Client/Server model, a chat server, can talk either way:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server </span></span><br><span class="line"><span class="comment"># -l: listening</span></span><br><span class="line"><span class="comment"># -vv: verbose</span></span><br><span class="line">nc -l -vv -p 3000</span><br><span class="line"><span class="comment"># client</span></span><br><span class="line"><span class="comment"># -p: source port to establish connection</span></span><br><span class="line">nc localhost -p 6666 3000</span><br></pre></td></tr></table></figure></p>
<p>Execute command on remote via backdoor opened by <code>nc</code>, see nc’s manual<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server side</span></span><br><span class="line">rm -f /tmp/f; mkfifo /tmp/f</span><br><span class="line"><span class="comment"># -i: interactive shell</span></span><br><span class="line">cat /tmp/f | /bin/sh -i 2&gt;&amp;1 | nc -l 0.0.0.0 1234 &gt; /tmp/f</span><br><span class="line"><span class="comment"># remove after done</span></span><br><span class="line">rm -f /tmp/f</span><br><span class="line"></span><br><span class="line"><span class="comment"># client side</span></span><br><span class="line">nc &lt;server ip&gt; 1234</span><br><span class="line"><span class="comment"># prompt a interactive shell </span></span><br><span class="line"><span class="comment"># then run command on remote server</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nc</tag>
        <tag>netcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Network Port Watching</title>
    <url>/2019/11/04/linux-network-port-watching/</url>
    <content><![CDATA[<p>This issue is from a machine without <code>net-tools.x86_64 : Basic networking tools</code> pre-installed, so <code>netstat</code> command does not exist. When watching docker registry pod setup, ansible runs <code>netstat -tunlp | grep 5000</code> to check 5000 port, failed.</p>
<p>Is there other way around to check if the 5000 port is up or not? Yes.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Wait</span> <span class="string">for</span> <span class="string">docker</span> <span class="string">registry</span> <span class="string">to</span> <span class="string">come</span> <span class="string">up</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  shell:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    declare -a array=($(cat /proc/net/tcp6 | cut -d":" -f"3"|cut -d" " -f"1"))</span></span><br><span class="line"><span class="string">    for port in $&#123;array[@]&#125;;</span></span><br><span class="line"><span class="string">    do</span></span><br><span class="line"><span class="string">      val=$(echo $((0x$port)) | grep 5000)</span></span><br><span class="line"><span class="string">      if ! [[ "X$&#123;val&#125;" == "X" ]]; then</span></span><br><span class="line"><span class="string">        break</span></span><br><span class="line"><span class="string">      fi</span></span><br><span class="line"><span class="string">    done</span></span><br><span class="line"><span class="string">    echo $&#123;val&#125; | grep 5000</span></span><br><span class="line"><span class="string"></span><span class="attr">  register:</span> <span class="string">docker_registry</span></span><br><span class="line"><span class="attr">  until:</span> <span class="string">docker_registry.rc</span> <span class="string">==</span> <span class="number">0</span></span><br><span class="line"><span class="attr">  retries:</span> <span class="string">"<span class="template-variable">&#123;&#123; 10 &#125;&#125;</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>Here I watch <code>/proc/net/tcp6</code> kernel file to see what ipv6 port is running (docker registry port is in ipv6 scope here). for ipv4, use <code>/proc/net/tcp</code>. </p>
<p>This file is not plain text, after use <code>cut</code> to extra the port field, then convert the number to decimal. see <a href="https://www.kernel.org/doc/Documentation/networking/proc_net_tcp.txt" target="_blank" rel="noopener">https://www.kernel.org/doc/Documentation/networking/proc_net_tcp.txt</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Network Interface</title>
    <url>/2019/11/04/linux-network-interface/</url>
    <content><![CDATA[<p>Sometimes I need to fetch IP from specified network interface, for example <code>eth0</code>.</p>
<p>There are several ways to do it:</p>
<p><code>ifconfig</code> command, but you need to first yum install <code>net-tools.x86_64 : Basic networking tools</code> if it is not present.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ifconfig eth0 | grep &quot;inet&quot; | awk &apos;&#123;print $2&#125;&apos;</span><br></pre></td></tr></table></figure></p>
<p><code>ip</code> command, this command is pre-installed in most linux machine and powerful.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip addr show eth0 | grep &quot;inet\b&quot; | awk &apos;&#123;print $2&#125;&apos; | cut -d/ -f1</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Networking Summary</title>
    <url>/2019/11/29/linux-networking-summary/</url>
    <content><![CDATA[<p>//TODO<br>[ ] <a href="https://www.youtube.com/watch?v=kQYQ_3ayz8w&amp;list=PLvadQtO-ihXt5k8XME2iv0cKpKhcYqe7i&amp;index=5" target="_blank" rel="noopener">https://www.youtube.com/watch?v=kQYQ_3ayz8w&amp;list=PLvadQtO-ihXt5k8XME2iv0cKpKhcYqe7i&amp;index=5</a></p>
<p>常用的关于networking 检查的commands: <code>ss</code>, <code>lsof</code>, <code>netstat</code>, <code>ifconfig</code>, <code>hostname</code>, <code>ip</code>, <code>route</code>, <code>iptables</code>, <code>nc</code>, <code>ping</code>, <code>arp</code>, <code>curl</code>, <code>wget</code>, <code>host</code>, <code>nslookup</code>, <code>dig</code>.</p>
<p>这篇总结主要是来自PluralSight上的<code>LPIC-1</code>课程的Network chapter，以及<code>LFCE</code> Advanced Networking training. 后来加入了一些iptables的内容, from Youtube.<br>Environment: <code>CentOS 7 Enterprise Linux</code> or <code>RedHat</code>.</p>
<p><strong>Frequently Asked Question:</strong><br>What is going on when you hit URL in browser?</p>
<ul>
<li><a href="https://medium.com/@maneesha.wijesinghe1/what-happens-when-you-type-an-url-in-the-browser-and-press-enter-bb0aa2449c1a" target="_blank" rel="noopener">from medium</a></li>
<li><a href="https://www.quora.com/What-are-the-series-of-steps-that-happen-when-a-URL-is-requested-from-the-address-field-of-a-browser" target="_blank" rel="noopener">from Quora</a></li>
</ul>
<p>About domain name: <code>www.microsfot.com</code>:</p>
<ul>
<li>root domain: <code>.</code></li>
<li>top-level domain: <code>com</code></li>
<li>second-level domain: <code>microsoft</code></li>
<li>third-level domain: <code>www</code></li>
</ul>
<p>以上是最基本的流程，如果使用了HTTPS，还可以描述一下TLS handshakes的过程, 再比如中间有proxy则会Tunnel，有load balancer则可能有TLS termination等等。</p>
<h2 id="Ip-vs-Ifconfig"><a href="#Ip-vs-Ifconfig" class="headerlink" title="Ip vs Ifconfig"></a>Ip vs Ifconfig</h2><p><code>ifconfig</code> is obsolete, use <code>ip</code> instead.<br>我专门有一篇写的ip command.</p>
<p><code>ipv4</code>: <code>32</code>  bits long, dotted decimal<br><code>ipv6</code>: <code>128</code> bits long, quad hex</p>
<h2 id="Hostname"><a href="#Hostname" class="headerlink" title="Hostname"></a>Hostname</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show full hostname</span></span><br><span class="line">hostname -f</span><br><span class="line"></span><br><span class="line"><span class="comment"># node hostname</span></span><br><span class="line">uname -n</span><br><span class="line"></span><br><span class="line"><span class="comment"># query and change the system hostname and related settings</span></span><br><span class="line">hostnamectl</span><br><span class="line"></span><br><span class="line">   Static hostname: halos1.fyre.xxx.com</span><br><span class="line">         Icon name: computer-vm</span><br><span class="line">           Chassis: vm</span><br><span class="line">        Machine ID: f7bbe4af93974cbfa5c55b68c011d41c</span><br><span class="line">           Boot ID: 4e30e7107fa441a9b3ad70d0b784782d</span><br><span class="line">    Virtualization: kvm</span><br><span class="line">  Operating System: Red Hat Enterprise Linux Server 7.6 (Maipo)</span><br><span class="line">       CPE OS Name: cpe:/o:redhat:enterprise_linux:7.6:GA:server</span><br><span class="line">            Kernel: Linux 3.10.0-957.10.1.el7.x86_64</span><br><span class="line">      Architecture: x86-64</span><br><span class="line"></span><br><span class="line"><span class="comment"># show domain name</span></span><br><span class="line"><span class="comment"># The chances are unless we have a web server running on our computer, we will not have any dns domain</span></span><br><span class="line"><span class="comment"># name. By default, there is no web server running on a system and hence there is no result when we</span></span><br><span class="line"><span class="comment"># type “dnsdomainname” on the terminal and hit enter.</span></span><br><span class="line">dnsdomainname</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># this will not be persistent</span></span><br><span class="line"><span class="comment"># the static hostname is still unchanged but transient hostname is xxx.example.com</span></span><br><span class="line"><span class="comment"># you can see transient name by hostnamectl</span></span><br><span class="line">hostname xxx.examplel.com</span><br><span class="line"></span><br><span class="line"><span class="comment"># this will be persistent in</span></span><br><span class="line"><span class="comment"># /etc/hostname</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname xxx.example.com</span><br><span class="line"></span><br><span class="line"><span class="comment"># set pretty hostname which includes '</span></span><br><span class="line"><span class="comment"># /etc/machine-info</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname <span class="string">"xxx'ok.example.com"</span></span><br></pre></td></tr></table></figure>
<p>Notice that the order we add in <code>/etc/hosts</code> file is important!<br>把fully qualified hostname放第一个，然后aliases，否则在一些场景会出问题！<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># /etc/hosts</span></span><br><span class="line">&lt;ip&gt; &lt;fully qualified domain name: FQDN&gt; &lt;aliases&gt;</span><br></pre></td></tr></table></figure></p>
<p>除了local hosts file, 来看看DNS设置, 我有一篇blog讲到了这个。<br><code>dig</code> command (DNS lookup utility)，用来check response and checking hostname from DNS server.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># use default dns server</span></span><br><span class="line">dig www.pluralsight.com </span><br><span class="line"><span class="comment"># use specified dns server, for example, google dns server 8.8.8.8</span></span><br><span class="line">dig www.pluralsight.com @8.8.8.8</span><br></pre></td></tr></table></figure></p>
<p>Output:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&lt;&lt;&gt;&gt;</span> <span class="string">DiG</span> <span class="number">9.9</span><span class="number">.4</span><span class="bullet">-RedHat-9.9.4-61.el7_5.1</span> <span class="string">&lt;&lt;&gt;&gt;</span> <span class="string">www.pluralsight.com</span> <span class="string">@8.8.8.8</span></span><br><span class="line"><span class="string">;;</span> <span class="string">global</span> <span class="attr">options:</span> <span class="string">+cmd</span></span><br><span class="line"><span class="string">;;</span> <span class="string">Got</span> <span class="attr">answer:</span></span><br><span class="line"><span class="string">;;</span> <span class="bullet">-&gt;&gt;HEADER&lt;&lt;-</span> <span class="attr">opcode:</span> <span class="string">QUERY,</span> <span class="attr">status:</span> <span class="string">NOERROR,</span> <span class="attr">id:</span> <span class="number">14726</span></span><br><span class="line"><span class="string">;;</span> <span class="attr">flags:</span> <span class="string">qr</span> <span class="string">rd</span> <span class="string">ra;</span> <span class="attr">QUERY:</span> <span class="number">1</span><span class="string">,</span> <span class="attr">ANSWER:</span> <span class="number">3</span><span class="string">,</span> <span class="attr">AUTHORITY:</span> <span class="number">0</span><span class="string">,</span> <span class="attr">ADDITIONAL:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="string">;;</span> <span class="string">OPT</span> <span class="attr">PSEUDOSECTION:</span></span><br><span class="line"><span class="string">;</span> <span class="attr">EDNS:</span> <span class="attr">version:</span> <span class="number">0</span><span class="string">,</span> <span class="attr">flags:;</span> <span class="attr">udp:</span> <span class="number">512</span></span><br><span class="line"><span class="string">;;</span> <span class="string">QUESTION</span> <span class="attr">SECTION:</span></span><br><span class="line"><span class="string">;www.pluralsight.com.</span>           <span class="string">IN</span>      <span class="string">A</span></span><br><span class="line"></span><br><span class="line"><span class="string">;;</span> <span class="string">ANSWER</span> <span class="attr">SECTION:</span></span><br><span class="line"><span class="string">www.pluralsight.com.</span>    <span class="number">59</span>      <span class="string">IN</span>      <span class="string">CNAME</span>   <span class="string">www.pluralsight.com.cdn.cloudflare.net.</span></span><br><span class="line"><span class="string">www.pluralsight.com.cdn.cloudflare.net.</span> <span class="number">186</span> <span class="string">IN</span> <span class="string">A</span> <span class="number">104.19</span><span class="number">.162</span><span class="number">.127</span></span><br><span class="line"><span class="string">www.pluralsight.com.cdn.cloudflare.net.</span> <span class="number">186</span> <span class="string">IN</span> <span class="string">A</span> <span class="number">104.19</span><span class="number">.161</span><span class="number">.127</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># server now is 8.8.8.8</span></span><br><span class="line"><span class="string">;;</span> <span class="string">Query</span> <span class="attr">time:</span> <span class="number">60</span> <span class="string">msec</span></span><br><span class="line"><span class="string">;;</span> <span class="attr">SERVER:</span> <span class="number">8.8</span><span class="number">.8</span><span class="number">.8</span><span class="comment">#53(8.8.8.8)</span></span><br><span class="line"><span class="string">;;</span> <span class="attr">WHEN:</span> <span class="string">Sun</span> <span class="string">Apr</span> <span class="number">12</span> <span class="number">13</span><span class="string">:03:48</span> <span class="string">PDT</span> <span class="number">2020</span></span><br><span class="line"><span class="string">;;</span> <span class="string">MSG</span> <span class="string">SIZE</span>  <span class="attr">rcvd:</span> <span class="number">132</span></span><br></pre></td></tr></table></figure></p>
<p>Add short format <code>+short</code> to return the IP address only:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dig +short www.pluralsight.com @8.8.8.8</span><br><span class="line"></span><br><span class="line">www.pluralsight.com.cdn.cloudflare.net.</span><br><span class="line">104.19.161.127</span><br><span class="line">104.19.162.127</span><br></pre></td></tr></table></figure></p>
<h2 id="Network-services"><a href="#Network-services" class="headerlink" title="Network services"></a>Network services</h2><p>04/12/2020 目前我只是查看配置，没有去设置过。</p>
<p>Display and set IP address<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip -4 addr</span><br><span class="line">ip addr show eth0</span><br><span class="line"><span class="comment"># not persist</span></span><br><span class="line">ip addr add 192.168.1.50/24 dev eth0</span><br></pre></td></tr></table></figure></p>
<p>没太明白这些配置的具体用法。<br>Network Manager tool, 这个tool也不是万能的，有的地方不适用, can be used to set persistent change so we will not lost it.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check status</span></span><br><span class="line">systemctl status NetworkManager</span><br><span class="line"><span class="comment"># if not active, start it</span></span><br><span class="line">systemctl start NetworkManager</span><br><span class="line"></span><br><span class="line"><span class="comment"># nmcli command</span></span><br><span class="line"><span class="comment"># command-line tool for controlling NetworkManager</span></span><br><span class="line"><span class="comment"># show all connections</span></span><br><span class="line">nmcli connection show</span><br><span class="line"><span class="comment"># pretty format</span></span><br><span class="line">nmcli -p connection show eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># terminal graph interface</span></span><br><span class="line">nmtui</span><br><span class="line"><span class="comment"># then edit a connection, select network interface</span></span><br><span class="line"><span class="comment"># config ipv4 ip address/gateway.</span></span><br><span class="line">systemctl restart network</span><br></pre></td></tr></table></figure></p>
<p>Traditional network service, more flexible and common.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl status network</span><br></pre></td></tr></table></figure></p>
<p>The network configuration is read from scripts under <code>/etc/sysconfig/network-scripts/</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ifcfg-eth0  ifcfg-eth1  ifcfg-lo ...</span><br></pre></td></tr></table></figure></p>
<p>这些文件里面都写好了配置，more details see this link:<br><a href="https://www.computernetworkingnotes.com/rhce-study-guide/network-configuration-files-in-linux-explained.html" target="_blank" rel="noopener">https://www.computernetworkingnotes.com/rhce-study-guide/network-configuration-files-in-linux-explained.html</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TYPE=Ethernet</span><br><span class="line">BOOTPROTO=dhcp</span><br><span class="line">NAME=eth0</span><br><span class="line">DEVICE=eth0</span><br><span class="line">ONBOOT=yes</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>After editing the ifcfg-xx file, bring down and up that interface:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ifdown eth0</span><br><span class="line">ifup eth0</span><br></pre></td></tr></table></figure></p>
<h2 id="Routing"><a href="#Routing" class="headerlink" title="Routing"></a>Routing</h2><p>[ ] IP tables vs routing tables 有啥区别，使用场景? see this <a href="https://superuser.com/questions/419659/iptables-vs-route" target="_blank" rel="noopener">question</a> and diagram in comment.</p>
<p>Display routing tables 路由表<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># see below</span></span><br><span class="line">ip r</span><br><span class="line"><span class="comment"># route and netstat 每个column的意思更清楚一些</span></span><br><span class="line"><span class="comment"># -n: displays the results as IP addresses only and does not attempt to perform a DNS lookup</span></span><br><span class="line">netstat -rn</span><br><span class="line"><span class="comment"># -e: display as netstat format</span></span><br><span class="line">route -n [-ee]</span><br></pre></td></tr></table></figure></p>
<p>Explain host routing table (因为这不是一个router), the column name explaination can see <code>man route</code>，比如Flags字母的含义。<br>The order in the routing table does not matter, the longer prefix always takes priority.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 简而言之，路由表就是找,到哪里,出口在哪以及下一跳是谁</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Destination 表示destination `network name` or `host name`</span></span><br><span class="line"><span class="comment"># 是用来和要出去的packet destination IP 和 (Genmask)mask 作用之后得到的结果对比的</span></span><br><span class="line"><span class="comment"># 如果match了，则通过Iface(interface)送出去</span></span><br><span class="line"><span class="comment"># 如果和mask作用后有多个match, 则去match最长的那个destination</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0.0.0.0在Destination中表示默认网关，network mask也是0.0.0.0, 任何一个IP和0.0.0.0 与操作，最后</span></span><br><span class="line"><span class="comment"># 就是0.0.0.0了，所以去了default gateway了</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Gateway: gateway address, 比如192.168.0.1，如果是0.0.0.0，表示unspecified 或者`没有`</span></span><br><span class="line"><span class="comment"># this assumes that the network is locally connected, as there is no intermediate hop.</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         192.168.0.1     0.0.0.0         UG    100    0        0 ens4</span><br><span class="line"><span class="comment"># 注意这里是个host IP了，不是network name</span></span><br><span class="line">192.168.0.1     0.0.0.0         255.255.255.255 UH    100    0        0 ens4</span><br><span class="line">192.168.9.0     0.0.0.0         255.255.255.0   U     0      0        0 docker0</span><br></pre></td></tr></table></figure></p>
<p>对比一下<code>ip r</code> command, 显示不太一样:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># proto [type]: routing protocol identifier of this route</span></span><br><span class="line"><span class="comment"># scope link: 表示在设备的网段内通过此链接允许通信</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># default gateway</span></span><br><span class="line">default via 192.168.0.1 dev ens4 proto dhcp metric 100</span><br><span class="line"><span class="comment"># </span></span><br><span class="line">192.168.0.1 dev ens4 proto dhcp scope link metric 100</span><br><span class="line"><span class="comment"># docker0</span></span><br><span class="line">192.168.9.0/24 dev docker0 proto kernel scope link src 192.168.9.1</span><br></pre></td></tr></table></figure></p>
<p>Adding routes, 把所有的找不到routing的traffic全部转到192.168.56.104上去，通过eth0, 比如当前的machine无法访问外网，而192.168.56.104却可以, 但之后192.168.56.104也需要配置成router。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># this command is not persistent</span></span><br><span class="line"><span class="comment"># default can be formatted as 192.168.1.0/24</span></span><br><span class="line">ip route add default via 192.168.56.104 dev eth0</span><br></pre></td></tr></table></figure></p>
<p>如果需要make it persist, need to edit <code>/etc/sysconfig/network-scripts/</code> corresponding file eth0, 或者自己添加script，然后重启network <code>systemctl restart network</code>.</p>
<p>Configuring a linux system as router:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># now let's configure machine 192.168.56.104 as a router</span></span><br><span class="line">vim /etc/sysctl.conf</span><br><span class="line"><span class="comment"># add this line to enable ipv4 forward</span></span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line"><span class="comment"># reload</span></span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure></p>
<p>当时在做项目的时候需要去DataStage Ops Console查看performance, 但Openshift worker node外界无法直接访问，只能通过infra node的routing才行，于是先用nodePort expose service, 再设置infra node到对应worker node port的映射，最后对外用MASQUERADE。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># this is operating on nat iptables</span></span><br><span class="line"><span class="comment"># run in infra node</span></span><br><span class="line"><span class="comment"># DNAT: destination nat</span></span><br><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 32160 -j DNAT --to-destination &lt;worker private IP&gt;:32160</span><br><span class="line">iptables -t nat -A POSTROUTING -j MASQUERADE</span><br><span class="line">iptables -t nat -nvL</span><br></pre></td></tr></table></figure></p>
<p>Allowing access to the internet via NAT, so traffic can get back to private network.</p>
<blockquote>
<p>注意routing这部分还没有涉及到firewall, firewall is inactive</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -t nat: working on nat table</span></span><br><span class="line"><span class="comment"># -A POSTROUTING: appending to post routing chain</span></span><br><span class="line"><span class="comment"># -o eth0: outbound via eth0, eth0 connects to internet</span></span><br><span class="line"><span class="comment"># -j MASQUERADE: jump to MASQUERADE rule</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># not persistent, see iptables section below</span></span><br><span class="line">iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</span><br></pre></td></tr></table></figure>
<p>then if you check <code>iptables -t nat -nvL</code> will see the postrouting rule with new line added.</p>
<h2 id="Firewall"><a href="#Firewall" class="headerlink" title="Firewall"></a>Firewall</h2><p>其实很多linux是靠iptables去实现firewall的功能的，见下一节，firewalld service背后改动的也是iptables.</p>
<p>Implement packet filtering (iptables and firewalld both can do this)<br>firewall <code>zone</code>: represent a concept to manage incoming traffic more transparently. The zones are connected to networking interfaces or assigned a range of source addresses. You manage firewall rules for each zone independently.</p>
<p>配置命令类似于kubectl/oc的形式。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment"># show default zone</span></span><br><span class="line">firewall-cmd --get-default-zone</span><br><span class="line"><span class="comment"># show active zones, will see interfaces apply to it</span></span><br><span class="line">firewall-cmd --get-active-zones</span><br><span class="line"><span class="comment"># show available zones</span></span><br><span class="line">firewall-cmd --get-zones</span><br><span class="line"></span><br><span class="line"><span class="comment"># permanently remove interface eth0 from public zone</span></span><br><span class="line">firewall-cmd --permanent --zone=public --remove-interface=eth0</span><br><span class="line"><span class="comment"># permanently add eth0 to external zone</span></span><br><span class="line">firewall-cmd --permanent --zone=external --add-interface=eth0</span><br><span class="line"><span class="comment"># permanently add eth1 to internal zone</span></span><br><span class="line">firewall-cmd --permanent --zone=internal --add-interface=eth1</span><br><span class="line"></span><br><span class="line"><span class="comment"># change default zone</span></span><br><span class="line">firewall-cmd --<span class="built_in">set</span>-default-zone=external</span><br><span class="line"><span class="comment"># after updating, restart to take effect</span></span><br><span class="line">systemctl restart firewalld</span><br></pre></td></tr></table></figure></p>
<p>后面主要讲了firewall的配置，可以对不同的zone添加或删除services, ports等，service的默认配置文件在<code>/usr/lib/firewalld/services</code>目录，但是自己创建的service文件在<code>/etc/firewalld/services/</code>。</p>
<h2 id="Iptables"><a href="#Iptables" class="headerlink" title="Iptables"></a>Iptables</h2><p>用iptables也可以实现firewall的功能via filter table.</p>
<p>There are currently five independent tables:</p>
<ul>
<li><code>filter</code>: This is the default table (if no <code>-t</code> option is passed),It contains the built-in chains <code>INPUT</code> (for packets destined to local sockets),<code>FORWARD</code> (for packets being routed through the box), and <code>OUTPUT</code> (for locally-generated packets).</li>
<li><code>nat</code>: This table is consulted when a packet that creates a new connection is encountered.  It consists of three built-ins: <code>PREROUTING</code> (forltering  packets  as  soon  as  they  come in), <code>OUTPUT</code> (for altering locally-generated packets before routing), and <code>POSTROUTING</code> (foraltering packets as they are about to go out). IPv6 NAT support is available since kernel 3.7.</li>
<li><code>mangle</code>: This table is used for specialized packet alteration.</li>
<li><code>raw</code>: This  table  is used mainly for configuring exemptions from connection tracking in combination with the NOTRACK target.</li>
<li><code>security</code>: This table is used for Mandatory Access Control (MAC) networking rules</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># list 3 basic chain in filter table: INPUT, FORWARD, OUTPUT</span></span><br><span class="line"><span class="comment"># INPUT: traffic comes in firewall</span></span><br><span class="line"><span class="comment"># FORWARD: traffic pass through firewall</span></span><br><span class="line"><span class="comment"># OUTPUT: traffic leaving firewall</span></span><br><span class="line">iptables [-t filter] -L</span><br><span class="line"></span><br><span class="line"><span class="comment"># policy ACCEPT: default policy is ACCEPT if no specific rules</span></span><br><span class="line"><span class="comment"># other policies: DROP, REJECT(will send ICMP rejecter to sender)</span></span><br><span class="line"><span class="comment"># by default, most system won't have any rules</span></span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"></span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"></span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br></pre></td></tr></table></figure>
<p>Change default policies。<br>注意， 可以自己添加rules去加功能，但不要轻易去更改default policy ACCEPT。否则出了意外都不能连接上了。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># set default policy to DROP</span></span><br><span class="line"><span class="comment"># accept any traffic for INPUT and OUTPUT</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># rules 类似于switch中的case，从上到下match，顺序很重要！</span></span><br><span class="line"><span class="comment"># -A: append</span></span><br><span class="line">iptables -A INPUT -j ACCEPT</span><br><span class="line">iptables -A OUTPUT -j ACCEPT</span><br><span class="line"><span class="comment"># 这里设置为DROP是因为上面新加了ACCEPT</span></span><br><span class="line">iptables -P INPUT DROP</span><br><span class="line">iptables -P OUTPUT DROP</span><br><span class="line">iptables -P FORWARD DROP</span><br><span class="line"></span><br><span class="line"><span class="comment"># accept any loopback traffic</span></span><br><span class="line"><span class="comment"># loopback traffic never leaves machine</span></span><br><span class="line"><span class="comment"># -i: in-interface</span></span><br><span class="line"><span class="comment"># -o: out-interface</span></span><br><span class="line">iptables -A INPUT -i lo -j ACCEPT</span><br><span class="line">iptables -A OUTPUT -o lo -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># -v: verbose, </span></span><br><span class="line"><span class="comment"># -n: numberic data</span></span><br><span class="line"><span class="comment"># --line-numbers: show rules index</span></span><br><span class="line">iptables -nvL --line-numbers</span><br><span class="line"></span><br><span class="line"><span class="comment"># keep current traffic, for example, current ssh connection</span></span><br><span class="line">iptables -A INPUT -j ACCEPT -m conntrack  --ctstate ESTABLISHED,RELATED</span><br><span class="line">iptables -A OUTPUT -j ACCEPT -m conntrack  --ctstate ESTABLISHED,RELATED</span><br><span class="line"></span><br><span class="line"><span class="comment"># remove rule by index from --line-numbers</span></span><br><span class="line"><span class="comment"># -D: delete rule</span></span><br><span class="line"><span class="comment"># 这里就把之前ACCEPT去掉了，但链接并不会断开，因为有conntrack with established</span></span><br><span class="line">iptables -D INPUT 1</span><br><span class="line">iptables -D OUTPUT 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 目前为止，没有新的流量可以进来或出去</span></span><br><span class="line"><span class="comment"># add filter rules to iptables firewall for inbound and outbound traffic</span></span><br><span class="line"><span class="comment"># others can ping me</span></span><br><span class="line">iptables -A INPUT -j ACCEPT -p icmp --icmp-type 8</span><br><span class="line"><span class="comment"># I can ping others</span></span><br><span class="line">iptables -A OUTPUT -j ACCEPT -p icmp --icmp-type 8</span><br><span class="line"><span class="comment"># others can ssh in</span></span><br><span class="line"><span class="comment"># add comment</span></span><br><span class="line">iptables -A INPUT -j ACCEPT -p tcp --dport 22 -m comment --comment <span class="string">"allow ssh from all"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># I can access others</span></span><br><span class="line"><span class="comment"># 当时这里理解有点问题，为什么不需要INPUT 80 port呢？</span></span><br><span class="line">iptables -A OUTPUT -j ACCEPT -p tcp --dport 80</span><br><span class="line">iptables -A OUTPUT -j ACCEPT -p tcp --dport 443</span><br><span class="line"><span class="comment"># DNS</span></span><br><span class="line">iptables -A OUTPUT -j ACCEPT -p tcp --dport 53</span><br><span class="line">iptables -A OUTPUT -j ACCEPT -p udp --dport 53</span><br><span class="line"><span class="comment"># NTP</span></span><br><span class="line">iptables -A OUTPUT -j ACCEPT -p tcp --dport 123</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># save current config</span></span><br><span class="line"><span class="comment"># can edit in this output file</span></span><br><span class="line">iptables-save &gt; orgset</span><br><span class="line">iptables-restore &lt; orgset</span><br><span class="line"></span><br><span class="line"><span class="comment"># drop if not match </span></span><br><span class="line"><span class="comment"># 这个放最后，否则一来就drop了，但如果设置了default DROP则不需要了</span></span><br><span class="line">iptables -A INPUT -j DROP</span><br><span class="line"><span class="comment"># not acting as a router</span></span><br><span class="line">iptables -A FORWARD -j DROP</span><br><span class="line"></span><br><span class="line"><span class="comment"># -I: insert</span></span><br><span class="line"><span class="comment"># 把这个rule加到INPUT chain的第一行</span></span><br><span class="line">iptables -I INPUT 1 -p tcp --dport 80 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># clear rules in all chains</span></span><br><span class="line">iptables -F [chain name]</span><br></pre></td></tr></table></figure>
<p>来看看iptables service的使用，变成systemctl service的形式了，使用上更正规一些。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y iptables-services</span><br></pre></td></tr></table></figure></p>
<p>在<code>/etc/sysconfig</code>目录下，有<code>iptables</code> and <code>iptables-config</code> files, If set these two values as <code>yes</code>, then iptables will save the config automatically in <code>iptables</code> file, easy to maintain.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Save current firewall rules on stop.</span></span><br><span class="line"><span class="comment">#   Value: yes|no,  default: no</span></span><br><span class="line"><span class="comment"># Saves all firewall rules to /etc/sysconfig/iptables if firewall gets stopped</span></span><br><span class="line"><span class="comment"># (e.g. on system shutdown).</span></span><br><span class="line">IPTABLES_SAVE_ON_STOP=<span class="string">"yes"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save current firewall rules on restart.</span></span><br><span class="line"><span class="comment">#   Value: yes|no,  default: no</span></span><br><span class="line"><span class="comment"># Saves all firewall rules to /etc/sysconfig/iptables if firewall gets</span></span><br><span class="line"><span class="comment"># restarted.</span></span><br><span class="line">IPTABLES_SAVE_ON_RESTART=<span class="string">"yes"</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Monitoring-Network"><a href="#Monitoring-Network" class="headerlink" title="Monitoring Network"></a>Monitoring Network</h2><p>Measure network performance, bottleneck<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 可以查看途径的IP，比如VPN看路径是不是正确的</span></span><br><span class="line">tracepath www.google.com</span><br></pre></td></tr></table></figure></p>
<p><code>traceroute</code> vs <code>tracepath</code>:<br><a href="https://askubuntu.com/questions/114264/what-are-the-significant-differences-between-tracepath-and-traceroute" target="_blank" rel="noopener">https://askubuntu.com/questions/114264/what-are-the-significant-differences-between-tracepath-and-traceroute</a><br>some option of <code>traceroute</code> need root privilege, and has more features then <code>tracepath</code>.</p>
<p>Display network status<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 显示有多少error, drop packets来看是不是网络有问题</span></span><br><span class="line">ip -s -h link</span><br><span class="line">ip -s -h link show eth0</span><br></pre></td></tr></table></figure></p>
<p><code>netstat</code> command can also do the same thing.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -i</span><br><span class="line"></span><br><span class="line">Kernel Interface table</span><br><span class="line">Iface             MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg</span><br><span class="line">eth0             1500 16008695      0      5 0       8446165      0      0      0 BMRU</span><br><span class="line">eth1             1500   461914      0     12 0         35082      0      0      0 BMRU</span><br><span class="line">lo              65536   277761      0      0 0        277761      0      0      0 LRU</span><br></pre></td></tr></table></figure></p>
<p>还介绍了一下<code>sysstat</code> command，需要yum安装，安装之后它会收集每日的系统历史数据供查看。这也是一个很重要的系统监控工具。<br>还有一个command <code>nmap</code>, 用来scan ports:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y nmap</span><br><span class="line"><span class="comment"># check what ports in your system is opening</span></span><br><span class="line">nmap scanme.nmap.org</span><br><span class="line"><span class="comment"># list interface and routes information</span></span><br><span class="line">nmap -iflist</span><br></pre></td></tr></table></figure></p>
<p>Can use <code>ss</code> command (similar to <code>netstat</code>) to show listening tcp ports:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show listening ipv4 tcp sockets in numeric format</span></span><br><span class="line">ss -ltn -4</span><br><span class="line"></span><br><span class="line"><span class="comment"># *:* means listening from any address and any port</span></span><br><span class="line">State      Recv-Q Send-Q                  Local Address:Port                                 Peer Address:Port              </span><br><span class="line">LISTEN     0      64                                  *:2049                                            *:*                  </span><br><span class="line">LISTEN     0      128                                 *:36168                                           *:*                  </span><br><span class="line">LISTEN     0      128                                 *:111                                             *:* </span><br><span class="line"></span><br><span class="line"><span class="comment"># list current active connections</span></span><br><span class="line">ss -t</span><br><span class="line"></span><br><span class="line"><span class="comment"># 9.30.166.179:ssh is my Mac IP, it ssh to current host</span></span><br><span class="line"><span class="comment"># 这里State is ESTAB, 如果握手没回应，则会显示SYN-SENT</span></span><br><span class="line">State      Recv-Q Send-Q                Local Address:Port                                 Peer Address:Port                </span><br><span class="line">ESTAB      0      128                    9.30.166.179:ssh                                  9.160.91.147:62991                </span><br><span class="line">ESTAB      0      0                      9.30.166.179:54556                               54.183.140.32:https</span><br></pre></td></tr></table></figure></p>
<h1 id="Network-Basic"><a href="#Network-Basic" class="headerlink" title="Network Basic"></a>Network Basic</h1><p>这里主要是通过做实验，把基本概念过了一遍。用Vitual Box 设置实验环境，在虚拟机中安装使用wireshark, tcpdump很清晰，没有其他干扰信息。设置实验环境时，可以有1主2从，主机可以访问外界(Adapter1 设置NAT, Adapter2/3 设置Internal Network)，从机可以访问主机，间接实现外部访问(各自的Adapter1 设置Internal Network连接主机的Internal Network). 然后可以进行各种ip, route, iptables的实验了。</p>
<p><code>Network topology</code>: LAN, WAN (bus, star, ring, full mesh)<br><code>Network devices</code>: adapter, switch, router, firewall<br><code>OSI</code> model</p>
<p>subnetting: a logically grouped collection of devices on the same network<br>subnet mask: network portion / host portion<br>special address:<br>  network address (all 0 in host portion)<br>  broadcast (all 1 in host portion)<br>  loopback 127.0.0.1<br>classful subnet: class A/B/C, they are inefficient</p>
<p><code>VLSM</code>: variable length subet mask, for example x.x.x/25<br><code>NAT</code>: one to one, many to one map<br><code>ARP</code>: address resolution protocol (IP -&gt; MAC), broadcast on bus to see who has MAC for a particular IP<br><code>DNS</code>: map hostname to IP, UDP protocol</p>
<p><code>IP packet</code>: can be fragmented and reassembled by router and host. fragments其实很影响throughput，因为每个IP packet都有header。还要注意有的IP加密 (VPN)会额外增加IP packet的长度，造成fragments.<br><code>TTL</code>: time to live in IP header, this is how <code>traceroute</code> works</p>
<p><code>Routing Table</code>:<br>static: path defined by admin<br>dynamic: path programmatically defined, routing protocol <a href="https://en.wikipedia.org/wiki/Quagga_(software" target="_blank" rel="noopener">software Quagga on Linux</a>)</p>
<p><code>TCP</code>:<br>  connection oriented: three way handshake<br>  connection establishment/termination<br>  data transfer<br>  ports: system can have more than one IP, ports are only unique per IP<br>         well know port: 0-1024<br>  flow control: maintained by receiver<br>  congestion control: the sender slow down<br>  error detection and retransmission</p>
<p><code>UDP</code>:<br>  send it and forget it<br>  DNS (dig, host commands)<br>  VoIP</p>
<ol>
<li><p>setup http service on server host</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y httpd</span><br><span class="line"><span class="comment"># if firewall is on</span></span><br><span class="line">firewall-cmd --permanent --add-port=80/tcp</span><br><span class="line">firewall-cmd --reload</span><br><span class="line"><span class="comment"># set page content</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"hello world"</span> &gt; /var/www/html/index.html</span><br><span class="line">systemctl <span class="built_in">enable</span> httpd</span><br><span class="line">systemctl start httpd</span><br></pre></td></tr></table></figure>
</li>
<li><p>get the web page from other host</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget http://&lt;ip or hostname&gt;/index.html</span><br></pre></td></tr></table></figure>
</li>
<li><p>install <a href="https://danielmiessler.com/study/tcpdump/" target="_blank" rel="noopener">tcpdump</a> wireshark on other host</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y tcpdump wireshark wireshark-gnome</span><br><span class="line"><span class="comment"># if you have desktop in linux, start wireshark</span></span><br><span class="line">wireshark &amp;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>Check the arp cache<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># '?' means stale</span></span><br><span class="line">arp -a</span><br><span class="line">ip neighbor</span><br><span class="line"><span class="comment"># delete arp cache</span></span><br><span class="line">arp -d 192.168.1.1</span><br></pre></td></tr></table></figure></p>
<p>specify size of the data and ping total number:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -c 1: ping once</span></span><br><span class="line"><span class="comment"># -s 1472: 1472 bytes long (this is not total length of IP, it will append header)</span></span><br><span class="line"><span class="comment"># so maybe exceed 1500 MTU and then packet will be fragmented</span></span><br><span class="line">ping -c 1 -s 1472 192.168.1.1</span><br><span class="line"><span class="comment"># -t set TTL</span></span><br><span class="line">ping -c 2 -t 5 192.168.0.1</span><br></pre></td></tr></table></figure></p>
<p>Create a large file to transfer:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fast allocate file</span></span><br><span class="line"><span class="comment"># -l5G: length of file is 5G</span></span><br><span class="line">fallocate -l5G test.bin</span><br><span class="line"><span class="comment"># then using scp to copy from network</span></span><br><span class="line">scp ...</span><br><span class="line"><span class="comment"># you can check wireshark to see the tcp window scaling graph</span></span><br><span class="line"><span class="comment"># will see slow start and speed up</span></span><br></pre></td></tr></table></figure></p>
<p>Traffic control setting<br>用来模拟网络不好的情况, 如用scp在传输文件，设置tc bad performance，然后恢复，会发现transmission rate提高了。可以查看wireshark window scaling graph 和 IO graph.<br><a href="https://blog.csdn.net/pansaky/article/details/88801249" target="_blank" rel="noopener">Linux 下 TC 命令原理及详解</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tc qdisc add dev eth1 root netem delay 3000m loss 5%</span><br><span class="line"><span class="comment"># remove the above policy</span></span><br><span class="line">tc qdisc del dev eth1 root</span><br></pre></td></tr></table></figure></p>
<p>let’s see the statistic:<br>After performance recover, TCP congestion window size enlarge quickly:<br><img src="https://drive.google.com/uc?id=1DqpLc4_K5ZSjSSSBKIqUEYuSOrXWdra_" alt=""></p>
<p>This is IO graph, shows TCP window size and update points:<br><img src="https://drive.google.com/uc?id=1soVs4XwDeH6A6D9CG6ZK4WS_jSAnVxPI" alt=""><br><img src="https://drive.google.com/uc?id=1QRlirLbMDaA2p_XgEPnvA1fZn98qLJ_M" alt=""></p>
<h1 id="Network-Troubleshooting"><a href="#Network-Troubleshooting" class="headerlink" title="Network Troubleshooting"></a>Network Troubleshooting</h1><p><code>Network is not reachable</code>. For example, cannot ping through.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check subnet and gateway, then</span></span><br><span class="line">ip route</span><br><span class="line"><span class="comment"># check interface, state DOWN? NO-CARRIER? then</span></span><br><span class="line">ip addr</span><br><span class="line"><span class="comment"># check MAC mapping in layer 2, then</span></span><br><span class="line">arp -a</span><br><span class="line"><span class="comment"># layer1 is ok? link detected no?</span></span><br><span class="line"><span class="comment"># 注意虚拟机是没有这个统计的！真实网卡才有，之前遇到过这个情景了</span></span><br><span class="line"><span class="comment"># port speed 也可以查看</span></span><br><span class="line">ethtool eth0</span><br></pre></td></tr></table></figure></p>
<p><code>No route to host</code>，比如在scp的时候，这时去host server上看一下port是不是打开的<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ss -lnt4</span><br></pre></td></tr></table></figure></p>
<p>wireshark看一下client端的情况，发现可能是firewall issue! 端口被屏蔽了。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>network</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Networking 千峰</title>
    <url>/2020/12/13/linux-networking-qianfeng/</url>
    <content><![CDATA[<p>Youtube 上的一个免费培训频道,linux <a href="https://www.youtube.com/watch?v=YyDtpke3zmE&amp;list=PLwDQt7s1o9J5DTcjzYo5O0z_UqXQPxMoD" target="_blank" rel="noopener">网络</a>，看完了发现一般。不过倒是提醒我看看Cisco CCNA 相关的培训视频。</p>
<p>OSI<br>传输层使用 segment<br>网络层使用 packet<br>数据链路层使用 frame 帧<br>物理层使用: bit stream</p>
<p>之前有blog总结了 在浏览器中输入网址并hit后发生的事情，但并没有详细说网路上的包是如果传输的。data-link layer frame中的MAC地址是点对点的，但IP packet中的IP地址是源和最终目的地。</p>
<p>IP 头格式<br>IP 地址分类: A,B,C,D,E class<br>特殊的IP地址, for example: 0.0.0.0, 255.255.255.255(全网广播), 127.x.x.x, etc.</p>
<p>TCP 3次握手, 4次挥手</p>
<p>Switch: 一般是2层设备, 交换机组成的网络属于同一广播域(广播风暴)。但交换机也可以使用VLAN(虚拟局域网)隔离广播，3层交换机还可以划分不同VLAN的广播域范围, 灵活构建虚拟组。VLAN的划分可以基于端口，协议，子网 或MAC地址。</p>
<p>Router: 一般是3层设备, 能隔离广播域。<br>[ ] <a href="https://youtu.be/yYnrgxhXaDE?t=1667" target="_blank" rel="noopener">video</a>为什么route tables 查了2次？</p>
<p>ARP 协议，地址解析, only run first time if next hop MAC is unknown, use broadcast. ARP cache.<br>DHCP 协议</p>
<p><code>arp</code> command<br><code>ip</code>, <code>route</code> commands<br><code>tcpdump</code> command</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>Offline Package Installation II</title>
    <url>/2019/02/26/linux-offline-package-install-2/</url>
    <content><![CDATA[<p>Now, let’s practice what we have learned from <code>Offline package Installation I</code>. For example, I want to install <code>docker</code> and <code>kubeadm</code> etc offline in the target machine.</p>
<h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><blockquote>
<p>Note: here we only download actual dependencies need for installation, not all rpms if we use <code>--installroot</code> option</p>
</blockquote>
<p>I want to install <code>Docker 18.06.3</code> (currently kubeadm now properly recognizes <code>Docker 18.09.0</code> and newer, but still treats <code>18.06</code> as the default supported version). You should perform below steps on a machine that hasn’t installed docker yet.</p>
<blockquote>
<p>Note: <a href="https://docs.docker.com/install/linux/docker-ce/centos/#install-from-a-package" target="_blank" rel="noopener">install from a package</a>, rpms list in this link are not complete, they are in top level but can be used to upgrade version.</p>
</blockquote>
<h4 id="Uninstall-old-version"><a href="#Uninstall-old-version" class="headerlink" title="Uninstall old version"></a>Uninstall old version</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum remove docker \</span><br><span class="line">           docker-client \</span><br><span class="line">           docker-client-latest \</span><br><span class="line">           docker-common \</span><br><span class="line">           docker-latest \</span><br><span class="line">           docker-latest-logrotate \</span><br><span class="line">           docker-logrotate \</span><br><span class="line">           docker-engine</span><br></pre></td></tr></table></figure>
<p>The contents of <code>/var/lib/docker/</code>, including images, containers, volumes, and networks, are preserved. The Docker CE package is now called <code>docker-ce</code>.</p>
<h4 id="Set-up-docker-repository"><a href="#Set-up-docker-repository" class="headerlink" title="Set up docker repository"></a>Set up docker repository</h4><p>Before you install Docker CE for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-data \</span><br><span class="line">  lvm2</span><br></pre></td></tr></table></figure></p>
<p>Use the following command to set up the stable repository, <code>yum-utils</code> contains <code>yum-config-manager</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure></p>
<h4 id="List-docker-version"><a href="#List-docker-version" class="headerlink" title="List docker version"></a>List docker version</h4><p>List and sort the versions available in your repo. This example sorts results by version number, highest to lowest, and is truncated:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum list docker-ce --showduplicates | sort -r</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">docker-ce.x86_64            3:18.09.2-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64            3:18.09.1-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64            3:18.09.0-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.06.3.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.06.2.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.06.1.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.06.0.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.03.1.ce-1.el7.centos             docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.03.0.ce-1.el7.centos             docker-ce-stable</span><br><span class="line">docker-ce.x86_64            17.12.1.ce-1.el7.centos             docker-ce-stable</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h4 id="Download-docker-rpms"><a href="#Download-docker-rpms" class="headerlink" title="Download docker rpms"></a>Download docker rpms</h4><p>Install a specific version by its fully qualified package name, which is the package name (<code>docker-ce</code>) plus the version string (2nd column) starting at the first colon (:), up to the first hyphen, separated by a hyphen (-). For example, <code>docker-ce-18.06.3.ce</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/docker-18.06.3-rpms</span><br><span class="line">yum install --downloadonly --downloaddir=/root/docker-18.06.3-rpms docker-ce-18.06.3.ce</span><br></pre></td></tr></table></figure></p>
<p>list the rpms in the target folder:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">audit-2.8.4-4.el7.x86_64.rpm               libselinux-utils-2.5-14.1.el7.x86_64.rpm</span><br><span class="line">audit-libs-2.8.4-4.el7.x86_64.rpm          libsemanage-2.5-14.el7.x86_64.rpm</span><br><span class="line">audit-libs-python-2.8.4-4.el7.x86_64.rpm   libsemanage-python-2.5-14.el7.x86_64.rpm</span><br><span class="line">checkpolicy-2.5-8.el7.x86_64.rpm           libsepol-2.5-10.el7.x86_64.rpm</span><br><span class="line">container-selinux-2.68-1.el7.noarch.rpm    libtool-ltdl-2.4.2-22.el7_3.x86_64.rpm</span><br><span class="line">docker-ce-18.06.3.ce-3.el7.x86_64.rpm      policycoreutils-2.5-29.el7_6.1.x86_64.rpm</span><br><span class="line">libcgroup-0.41-20.el7.x86_64.rpm           policycoreutils-python-2.5-29.el7_6.1.x86_64.rpm</span><br><span class="line">libseccomp-2.3.1-3.el7.x86_64.rpm          python-IPy-0.75-6.el7.noarch.rpm</span><br><span class="line">libselinux-2.5-14.1.el7.x86_64.rpm         setools-libs-3.3.8-4.el7.x86_64.rpm</span><br><span class="line">libselinux-python-2.5-14.1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure></p>
<p>Note that the required components may be changed in later version, such as <code>18.09.2</code>, there are 2 more packages <code>docker-ce-cli-18.09.2</code> and <code>containerd.io</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/docker-18.09.2-rpms</span><br><span class="line">yum install --downloadonly --downloaddir=/root/docker-18.09.2-rpms docker-ce-18.09.2 docker-ce-cli-18.09.2 containerd.io</span><br></pre></td></tr></table></figure></p>
<h4 id="Install-docker-rpms"><a href="#Install-docker-rpms" class="headerlink" title="Install docker rpms"></a>Install docker rpms</h4><p>now install docker <code>18.06.3</code> offline by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum --disablerepo=* -y install /root/docker-18.06.3-rpms/*.rpm</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: please refer my blog <code>Set up and Use Local Yum Repository</code> if you want to create and use local yum repository</p>
</blockquote>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux</tag>
        <tag>yum</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>Offline Package Installation I</title>
    <url>/2019/02/25/linux-offline-package-install-1/</url>
    <content><![CDATA[<p>When I was working on the upgrade DS k8s installer issue, I ran into the problem that I need to install <code>ansible</code>, <code>docker</code> and <code>kubeadm</code> offline. In the production environment, we may not have internet access, that means we need to prepare the rpms and dependencies needed and create a self-contained installer.</p>
<h3 id="Download-missing-rpms-without-installing"><a href="#Download-missing-rpms-without-installing" class="headerlink" title="Download missing rpms without installing"></a>Download missing rpms without installing</h3><blockquote>
<p>Note: This method is (by-design) sensitive to the existence of already-installed packages. It will <strong>only</strong> download missing dependencies you need for that particular box, not all rpms.</p>
</blockquote>
<p>First let’s install the <code>yum-plugin-downloadonly</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y yum-plugin-downloadonly</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install --downloadonly --downloaddir=&lt;directory&gt; &lt;package:version&gt;</span><br></pre></td></tr></table></figure>
<p>For example, I want to get missing rpms for <em>vim</em> editor, reside them in <code>/root/vim</code> folder<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/vim</span><br><span class="line">yum install --downloadonly --downloaddir=/root/vim vim</span><br></pre></td></tr></table></figure></p>
<p><img src="https://drive.google.com/uc?id=1l5sohiuz020QXowIfKddAtIlUyjJWmFl" alt=""></p>
<p>List the target folder:</p>
<p><img src="https://drive.google.com/uc?id=1o9fPX-boaTBYl7r6y2uzDFePAsLa9G9B" alt=""></p>
<p>Another way is using <code>yumdownloader</code> that is from <code>yum-utils</code>. The difference is if the package is already installed completely, <code>yumdownloader</code> will download the outermost level rpm but <code>--downloadonly</code> will do nothing.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yumdownloader --resolve --destdir=/root/vim vim</span><br></pre></td></tr></table></figure>
<p><img src="https://drive.google.com/uc?id=1I_QfnLAWpj-CNKnfZAvF4yKjZ6U8xHET" alt=""></p>
<h3 id="Download-all-rpms-without-installing"><a href="#Download-all-rpms-without-installing" class="headerlink" title="Download all rpms without installing"></a>Download all rpms without installing</h3><h4 id="yum-amp-yumdownloader"><a href="#yum-amp-yumdownloader" class="headerlink" title="yum &amp; yumdownloader"></a>yum &amp; yumdownloader</h4><p>Usually what we really want is to resolve all dependencies and download them, even though some required rpms have already installed in box, <code>yumdownloader</code> or <code>yum --downloadonly</code> with <code>--installroot</code> option is the solution.</p>
<p>Keep in mind that <code>yumdownloader</code> will use your yum database when resolving dependencies.</p>
<p>For example if you download bash, which needs glibc, it will resolve glibc and skip it, since it is installed. <strong>If you want to download all dependencies</strong>, use a different <code>installroot</code> instead.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/vim</span><br><span class="line">mkdir -p /root/new_root</span><br><span class="line">yumdownloader --installroot=/root/new_root --destdir=/root/vim/ --resolve vim</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>This is what I need for a self-contained offline installer.</p>
</blockquote>
<p>Let’s check how many <code>vim</code> related rpms are here, way too many then what we get from the first section.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls -ltr /root/vim | wc -l</span><br><span class="line">57</span><br></pre></td></tr></table></figure></p>
<h4 id="repotrack"><a href="#repotrack" class="headerlink" title="repotrack"></a>repotrack</h4><p>This method can also resolve and download all dependencies, <code>repotrack</code> is from <code>yum-utils</code>, it will down all the dependencies for any architecture by default.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/vim</span><br><span class="line">repotrack -p /root/vim vim-enhanced</span><br></pre></td></tr></table></figure></p>
<p>if you check <code>/root/vim</code>, there are some <code>i686</code> rpms, once you delete them and count again, <code>57</code> the same as we use <code>yumdownloader</code> above.</p>
<blockquote>
<p>Note: actually <code>repotrack</code> has <code>-a</code> option to specify arch, but I am not able to use it, when I specify <code>x86_64</code>, it still downloads <code>i686</code>.</p>
</blockquote>
<h3 id="Install-local-rpms"><a href="#Install-local-rpms" class="headerlink" title="Install local rpms"></a>Install local rpms</h3><p>Now the problem is how to install these rpms in correct order, install them one by one is obviously infeasible, the method that can resolve their dependencies and install automatically is welcome, both command like:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum --disablerepo=* --skip-broken install -y /root/vim/*.rpm</span><br></pre></td></tr></table></figure></p>
<p>and<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm --force -ivh /root/vim/*.rpm</span><br></pre></td></tr></table></figure></p>
<p>may work but it’s not a good way, you may encounter rpm version upgrade issue and duplicate problem. Now from my knowledge create a local yum repository is clean and elegant, please refer my blog <code>Set up and Use Local Yum Repository</code>.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode Java Summary</title>
    <url>/2019/07/10/leetcode-java-recall/</url>
    <content><![CDATA[<h2 id="TO-DO"><a href="#TO-DO" class="headerlink" title="TO-DO"></a>TO-DO</h2><ol start="0">
<li>hiring season, internal reference</li>
<li>position: backend developer, DevOps, Infra</li>
<li>system design from x code in my laptop? baidu cloud?</li>
<li>company series, buy x code or leetcode?</li>
<li>resume project chat</li>
<li>blog review</li>
</ol>
<h1 id="Data-Structure"><a href="#Data-Structure" class="headerlink" title="Data Structure"></a>Data Structure</h1><p>java Integer notation, see this <a href="https://stackoverflow.com/questions/17636749/java-why-cant-i-declare-integer-types-using-scientific-notation" target="_blank" rel="noopener">post</a>:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 10^9</span></span><br><span class="line"><span class="keyword">int</span> a = (<span class="keyword">int</span>)<span class="number">1e9</span>;</span><br><span class="line"><span class="keyword">int</span> a = (<span class="keyword">int</span>)Math.pow(<span class="number">10</span>, <span class="number">9</span>);</span><br><span class="line"><span class="keyword">int</span> b = <span class="number">2_000_000_000</span>;</span><br></pre></td></tr></table></figure></p>
<h2 id="Class-features"><a href="#Class-features" class="headerlink" title="Class features"></a>Class features</h2><p>basic structure and syntax<br>nested class, inner class<br>static class<br>private<br>public<br>protected</p>
<h2 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h2><p>LRU除了可以使用自定义的double linked list去实现，也可以用Java API <code>LinkedHashMap</code>，在constructor中指定参数:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 设置capacity</span></span><br><span class="line"><span class="keyword">int</span> CAPACITY = <span class="number">10</span>;</span><br><span class="line"><span class="comment">// true表示自动实现LRU功能</span></span><br><span class="line">LinkedHashMap&lt;String, Integer&gt; lru = <span class="keyword">new</span> LinkedHashMap&lt;&gt;(CAPACITY, <span class="number">0.75f</span>, <span class="keyword">true</span>)&#123;</span><br><span class="line">  <span class="comment">// override</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">boolean</span> removeEldestEntry​(Map.Entry&lt;String, Integer&gt; eldest)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">return</span> size() &gt; CAPACITY;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如此一来，可以直接使用put(), get()即可，其他不用操心，当达新增的量超过capacity时会自动删除least recently used item.</p>
<p>此外，如果不使用这个special constructor <code>new LinkedHashMap&lt;&gt;(CAPACITY, 0.75f, true)</code>，则linked list中的顺序是insertion order，即最先insert的在前面，最近的在后面，如果用keySet() iterator是按照linked list的顺序出来的，即最先insert的先出来。</p>
<p>经过试验发现，LRU声称的access order，都是insertion order的顺序，只不过LRU实现每次会自动把最新活动的元素重新放到linked list最后， 然后超出capacity时，把least recently used one删除了.</p>
<h2 id="Pair-class"><a href="#Pair-class" class="headerlink" title="Pair class"></a>Pair class</h2><p><a href="https://docs.oracle.com/javase/8/javafx/api/javafx/util/Pair.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/javafx/api/javafx/util/Pair.html</a><br><a href="https://www.baeldung.com/java-pairs" target="_blank" rel="noopener">https://www.baeldung.com/java-pairs</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> javafx.util.Pair;</span><br></pre></td></tr></table></figure></p>
<p><a href="https://www.geeksforgeeks.org/pair-class-in-java/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/pair-class-in-java/</a></p>
<h2 id="input-method"><a href="#input-method" class="headerlink" title="input method"></a>input method</h2><h2 id="Deque"><a href="#Deque" class="headerlink" title="Deque"></a>Deque</h2><p>如果把Deque既当stack又当queue, 不要使用他们的native method，用能明确指出操作位置的method:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">addLast(x)</span><br><span class="line">removeLast()</span><br><span class="line">peekLast()</span><br><span class="line"></span><br><span class="line">addFirst()</span><br><span class="line">removeFirst()</span><br><span class="line">peekFirst()</span><br></pre></td></tr></table></figure></p>
<p>如果只充当stack or queue之一，则可以用native method:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">stack: push, pop</span><br><span class="line">queue: add, poll</span><br></pre></td></tr></table></figure></p>
<h2 id="Segment-Tree"><a href="#Segment-Tree" class="headerlink" title="Segment Tree"></a>Segment Tree</h2><p><a href="https://www.geeksforgeeks.org/segment-tree-set-1-sum-of-given-range/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/segment-tree-set-1-sum-of-given-range/</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// get min value &gt;= x</span></span><br><span class="line"><span class="comment">// 返回的都是整数，但是是double type</span></span><br><span class="line">Math.ceil(<span class="keyword">double</span> x)</span><br><span class="line"><span class="comment">// get max value &lt;= x</span></span><br><span class="line"><span class="comment">// 返回的都是整数，但是是double type</span></span><br><span class="line">Math.floor(<span class="keyword">double</span> x)</span><br><span class="line"><span class="comment">// log e of x</span></span><br><span class="line">Math.log(<span class="keyword">double</span> x)</span><br><span class="line"><span class="comment">// calculate log2</span></span><br><span class="line">Math.log(x) / Math.log(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>Complete binary tree number of nodes: <code>2^height - 1</code> (height start from <code>1</code>)<br>For segment tree, number of nodes:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// n is the length of array</span></span><br><span class="line"><span class="keyword">int</span> h = (<span class="keyword">int</span>)Math.ceil(Math.log(n) / Math.log(<span class="number">2</span>));</span><br><span class="line"><span class="keyword">int</span> maxSTSize = <span class="number">2</span> * (<span class="keyword">int</span>)Math.pow(<span class="number">2</span>, h) - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span>[] st</span><br></pre></td></tr></table></figure></p>
<p>Or you can define <code>class Node</code> to build segment tree.</p>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><ul>
<li>LinkedList is doubly-linked!</li>
<li>change array to list<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; list = Arrays.&lt;Integer&gt;asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, ...);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>but this is fixed size list backed by array, you can create a new one:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; list = <span class="keyword">new</span> ArrayList&lt;Integer&gt;(Arrays.&lt;Integer&gt;asList(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>, ...));</span><br></pre></td></tr></table></figure></p>
<p>use slow-fast pointer to find middle of linkedlist or find cycle<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ListNode slow = head, fast = head;</span><br><span class="line"><span class="keyword">while</span> (fast.next != <span class="keyword">null</span> &amp;&amp; fast.next.next != <span class="keyword">null</span>) &#123;</span><br><span class="line">    slow = slow.next;</span><br><span class="line">    fast = fast.next.next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// when loop break, slow is in middle</span></span><br></pre></td></tr></table></figure></p>
<p>reverse the linked list:<br><a href="https://leetcode.com/problems/reorder-list/submissions/" target="_blank" rel="noopener">https://leetcode.com/problems/reorder-list/submissions/</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1-&gt;2-&gt;3-&gt;4</span></span><br><span class="line"><span class="comment">// 1&lt;-2&lt;-3&lt;-4</span></span><br><span class="line">ListNode pre = <span class="keyword">null</span>;</span><br><span class="line">ListNode cur = &lt;node <span class="number">1</span>&gt;;</span><br><span class="line"><span class="keyword">while</span> (cur != <span class="keyword">null</span>)</span><br><span class="line">&#123;</span><br><span class="line">    ListNode next = cur.next;</span><br><span class="line">    cur.next = pre;</span><br><span class="line">    pre = cur;</span><br><span class="line">    cur = next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 注意这里不要弄错了</span></span><br><span class="line">ListNode newHead = pre;</span><br></pre></td></tr></table></figure></p>
<h2 id="PriorityQueue"><a href="#PriorityQueue" class="headerlink" title="PriorityQueue"></a>PriorityQueue</h2><p>Priority queue has <code>contains(object)</code> and <code>remove(object)</code> method, but that will take <code>O(n)</code> time.</p>
<p>如果要构造比较整数大小的priority queue<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// if use (a, b) -&gt; a - b, this may overflow when encounter MAX MIN</span></span><br><span class="line">Queue&lt;Integer&gt; pq = <span class="keyword">new</span> PriorityQueue&lt;&gt;((a, b) -&gt; Integer.compare(a, b));</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意priorityQueue iterator返回的是random order!</p>
</blockquote>
<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p>String: immutable<br>StringBuilder: mutable, not thread safe<br>StringBuffer: mutable, thread safe</p>
<p>注意<code>&quot;\t&quot;, &quot;\n&quot;</code>在string中只相当于一个长度！！！</p>
<p>“abcdefg”<br>substring 是连续的: “cdef”<br>subsequence可以不连续，但顺序要一致: “abdf”</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str = <span class="keyword">new</span> String(<span class="string">"123"</span>);</span><br><span class="line">String str = <span class="string">"123"</span>;</span><br><span class="line"><span class="comment">// convert number 123456 to string "123"</span></span><br><span class="line">String str = String.valueOf(<span class="number">123456</span>);</span><br><span class="line">str.length();</span><br><span class="line"><span class="comment">// use + to concatenate</span></span><br><span class="line">str1 + str2</span><br><span class="line"><span class="comment">// string compare</span></span><br><span class="line">str1.compareTo(str2);</span><br></pre></td></tr></table></figure>
<p>when do replace<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str = <span class="string">"a.b.c.d"</span>;</span><br><span class="line">str.replace(<span class="string">"."</span>, <span class="string">""</span>); <span class="comment">// get "abcd"</span></span><br><span class="line"><span class="comment">// don't use str.replace('.',''), cannot be empty char</span></span><br><span class="line"><span class="comment">// there is no regex, just CharSequence type</span></span><br></pre></td></tr></table></figure></p>
<p>if just want to create a string using other type:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="string">""</span> + other type</span><br></pre></td></tr></table></figure></p>
<p>caution:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String a = <span class="string">"1.2.3."</span>;</span><br><span class="line"><span class="comment">// a.split("\\.") will get length of 3, it will ignore last '.'</span></span><br><span class="line">String a = <span class="string">".1.2.3"</span>;</span><br><span class="line"><span class="comment">// a.split("\\.") will get length of 4, it will not ignore first '.'</span></span><br><span class="line">String b = <span class="string">"1..2.3"</span>;</span><br><span class="line"><span class="comment">// b.split("\\.") will get length of 4, it will not ignore consecutive '.'</span></span><br></pre></td></tr></table></figure></p>
<p>Notice the parameters format<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">indexOf(<span class="keyword">int</span> ch, <span class="keyword">int</span> startIndex)</span><br><span class="line">split(String reg)</span><br><span class="line"></span><br><span class="line"><span class="comment">// returns the index within this string of</span></span><br><span class="line"><span class="comment">// the last occurrence of the specified character.</span></span><br><span class="line"><span class="keyword">int</span> lastIndexOf​(<span class="keyword">int</span> ch)</span><br></pre></td></tr></table></figure></p>
<h2 id="StringBuilder"><a href="#StringBuilder" class="headerlink" title="StringBuilder"></a>StringBuilder</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StringBuilder sb = <span class="keyword">new</span> StringBuilder(String);</span><br><span class="line">sb.append(x);</span><br><span class="line"><span class="comment">// insert in head</span></span><br><span class="line">sb.insert(<span class="number">0</span>, x);</span><br><span class="line">sb.toString();</span><br><span class="line"><span class="comment">// return stringbuilder</span></span><br><span class="line">sb.reverse();</span><br><span class="line"><span class="comment">// stringbuilder does not implement equals method!!</span></span><br><span class="line">sb.equals(another stringbuilder object); <span class="comment">// wrong!!</span></span><br></pre></td></tr></table></figure>
<p>more methods:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// return String</span></span><br><span class="line"><span class="comment">// 这里只有一个参数的时候是start index!</span></span><br><span class="line">substring(<span class="keyword">int</span> startidx)</span><br><span class="line"><span class="comment">// [start end)</span></span><br><span class="line">substring(<span class="keyword">int</span> startidx, <span class="keyword">int</span> endidx) </span><br><span class="line">append(lot of types)</span><br><span class="line">setLength(<span class="keyword">int</span> len)</span><br></pre></td></tr></table></figure></p>
<h2 id="Character"><a href="#Character" class="headerlink" title="Character"></a>Character</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// return Character</span></span><br><span class="line">Character.valueOf(<span class="keyword">char</span>)</span><br><span class="line"><span class="comment">//return char</span></span><br><span class="line">c.charValue()</span><br><span class="line"></span><br><span class="line"><span class="comment">// actually the convert is auto like int and Integer!</span></span><br><span class="line"><span class="keyword">char</span> c1 = <span class="keyword">new</span> Character(<span class="string">'a'</span>);</span><br><span class="line">Character c1 = <span class="string">'b'</span>;</span><br></pre></td></tr></table></figure>
<p>char compare in <code>if</code> use <code>==</code><br>if use +- with char, such as <code>ch - &#39;a&#39;</code>, don’t forget <code>(char)(ch)</code></p>
<p>check letter:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Character.isDigit(ch);</span><br><span class="line">Character.toLowerCase(ch);</span><br><span class="line">Character.isLetterOrDigit(ch);</span><br></pre></td></tr></table></figure></p>
<p>Non-ASCII character (&gt; 256):<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Character.toString((<span class="keyword">char</span>)<span class="number">342</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="3-items-if-expression"><a href="#3-items-if-expression" class="headerlink" title="3 items if expression"></a>3 items if expression</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// I forget the precedence</span></span><br><span class="line"><span class="comment">// this will first 1 + 2 + 3 then compare with 3!</span></span><br><span class="line"><span class="number">1</span> + <span class="number">2</span> + <span class="number">3</span> == <span class="number">3</span>? <span class="keyword">true</span>: <span class="keyword">false</span></span><br></pre></td></tr></table></figure>
<h2 id="Enhenced-for-Loop"><a href="#Enhenced-for-Loop" class="headerlink" title="Enhenced for Loop"></a>Enhenced for Loop</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// enhanced for loop</span></span><br><span class="line"><span class="keyword">for</span> (Character ch : str.toCharArray())</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Collection"><a href="#Collection" class="headerlink" title="Collection"></a>Collection</h2><p>convert list to array<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// result is List&lt;int[]&gt; type</span></span><br><span class="line"><span class="comment">// think about it</span></span><br><span class="line">result.toArray(<span class="keyword">new</span> <span class="keyword">int</span>[result.size()][]);</span><br></pre></td></tr></table></figure></p>
<p>convert Integer list to int array (from Java8):<br><a href="https://stackoverflow.com/questions/718554/how-to-convert-an-arraylist-containing-integers-to-primitive-int-array" target="_blank" rel="noopener">https://stackoverflow.com/questions/718554/how-to-convert-an-arraylist-containing-integers-to-primitive-int-array</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] arr = list.stream().mapToInt(i -&gt; i).toArray();</span><br></pre></td></tr></table></figure></p>
<p>also from int array to Integer list<br><a href="https://stackoverflow.com/questions/1073919/how-to-convert-int-into-listinteger-in-java" target="_blank" rel="noopener">https://stackoverflow.com/questions/1073919/how-to-convert-int-into-listinteger-in-java</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; list = Arrays.stream(ints).boxed().collect(Collectors.toList());</span><br></pre></td></tr></table></figure></p>
<p>这个是Java stream的知识点</p>
<h2 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// one dimension</span></span><br><span class="line"><span class="keyword">int</span>[] arr = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line"><span class="keyword">int</span>[] arr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">4</span>]; <span class="comment">// default value is 0</span></span><br><span class="line"><span class="comment">// two dimensions</span></span><br><span class="line"><span class="keyword">int</span>[][] arr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">3</span>][<span class="number">4</span>]; <span class="comment">// 3 rows 4 columns</span></span><br><span class="line"><span class="keyword">int</span>[][] arr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">3</span>][]; <span class="comment">// still ok, you can init one dimension array later</span></span><br><span class="line"><span class="keyword">int</span>[][] arr = <span class="keyword">new</span> <span class="keyword">int</span>[][]&#123;&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;, &#123;<span class="number">4</span>,<span class="number">5</span>&#125;, &#123;<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>&#125;&#125;; <span class="comment">// each one dimension array can have different length!</span></span><br></pre></td></tr></table></figure>
<p>Let’s see char array<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span>[] arr = str.toCharArray();</span><br></pre></td></tr></table></figure></p>
<p>Use sort static method, if you want to use comparator, see my <strong>lambda</strong> section<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Arrays.sort(E[] e);</span><br><span class="line"><span class="comment">// also for collections</span></span><br><span class="line">Collections.sort(List&lt;xx&gt; l);</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Arrays.sort(int[]) primitive type是不能自己写comparator的！</p>
</blockquote>
<p>数组内容字符串化用:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] a = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line"><span class="comment">// correct!</span></span><br><span class="line">Arrays.toString(a);</span><br><span class="line"><span class="comment">// wrong! 这个返回id string</span></span><br><span class="line">a.toString()</span><br></pre></td></tr></table></figure></p>
<p>Shuffle arrays:<br>Every permutation of array element should equally likely:<br><a href="https://www.geeksforgeeks.org/shuffle-a-given-array-using-fisher-yates-shuffle-algorithm/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/shuffle-a-given-array-using-fisher-yates-shuffle-algorithm/</a><br><a href="https://introcs.cs.princeton.edu/java/stdlib/StdRandom.java.html" target="_blank" rel="noopener">https://introcs.cs.princeton.edu/java/stdlib/StdRandom.java.html</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// nums[0] swap with element in range [0, n)</span></span><br><span class="line"><span class="comment">// nums[1] swap with element in range [1, n)</span></span><br><span class="line"><span class="comment">// nums[2] swap with element in range [2, n)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] shuffle(<span class="keyword">int</span>[] nums)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">int</span> j = i + rand.nextInt(nums.length - i);</span><br><span class="line">    <span class="comment">// swap</span></span><br><span class="line">    <span class="keyword">int</span> tmp = nums[i];</span><br><span class="line">    nums[i] = nums[j];</span><br><span class="line">    nums[j] = tmp;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> nums;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>TreeSet operation time complexity, from java TreeSet doc:<br><strong>This implementation provides guaranteed log(n) time cost for the basic operations (add, remove and contains).</strong></p>
<h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br></pre></td></tr></table></figure>
<p>HashMap&lt;&gt;() not thread safe<br>HashTable&lt;&gt;(), thread safe but ConcurrentHash…</p>
<p>有时用char[26]（<code>c - &#39;a&#39;</code>） 或者 int[256] (直接用c即可) 可以用来代替hashmap</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">map.containsKey()</span><br><span class="line"><span class="comment">// also has contains value method!</span></span><br><span class="line">map.containsValue()</span><br><span class="line"><span class="comment">// return set</span></span><br><span class="line">map.keySet()</span><br><span class="line">map.entrySet()</span><br><span class="line"><span class="comment">// return collection</span></span><br><span class="line">map.values()</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// provide value for new key which is absent </span></span><br><span class="line">map.put(key, map.getOrDefault(key, <span class="number">0</span>) + <span class="number">1</span>);</span><br><span class="line"><span class="comment">// if value is a collection object can use:</span></span><br><span class="line">map.computeIfAbsent(key, k -&gt; <span class="keyword">new</span> ArrayList&lt;Stone&gt;()).add(<span class="keyword">new</span> Stone(x,y));</span><br><span class="line"><span class="comment">// remove current key if it's value is val</span></span><br><span class="line">map.remove(key, val)</span><br></pre></td></tr></table></figure>
<p>Treemap/TreeSet (sorted map) perform <strong>all operation</strong> based on it’s default/custom comparator! if two key are equal in comparator, should be treated as equal in equals() method! 但如果没有一致，还是按照comparator去做. treemap/treeset.remove(object) 用的是comparator去比较相等！！</p>
<p>range query API:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// treemap</span></span><br><span class="line">tm.ceilingKey(K key)</span><br><span class="line">tm.ceilingEntry(K key)</span><br><span class="line">tm.floorEntry(K key)</span><br><span class="line">tm.floorKey(K key)</span><br><span class="line"></span><br><span class="line">tm.firstKey()</span><br><span class="line">tm.firstEntry()</span><br><span class="line">tm.lastKey()</span><br><span class="line">tm.lastEntry()</span><br><span class="line"></span><br><span class="line">tm.pollFirstEntry()</span><br><span class="line">tm.pollLastEntry()</span><br><span class="line"><span class="comment">// treeset</span></span><br><span class="line">ts.ceiling(K key)</span><br><span class="line">ts.floor(K key)</span><br><span class="line"></span><br><span class="line">ts.first()</span><br><span class="line">ts.last()</span><br><span class="line"><span class="comment">// 可以用来模拟pq</span></span><br><span class="line">ts.pollFirst()</span><br><span class="line">ts.pollLast()</span><br></pre></td></tr></table></figure></p>
<p>如果要返回map中的任意一个key，比如key是string类型<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> (String)map.keySet().iterator().next();</span><br></pre></td></tr></table></figure></p>
<p>this is java <strong>syntax</strong>, I see it in leetcode<br><a href="https://stackoverflow.com/questions/1958636/what-is-double-brace-initialization-in-java" target="_blank" rel="noopener">https://stackoverflow.com/questions/1958636/what-is-double-brace-initialization-in-java</a></p>
<h2 id="Exception-Handling"><a href="#Exception-Handling" class="headerlink" title="Exception Handling"></a>Exception Handling</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"xxx"</span>);</span><br></pre></td></tr></table></figure>
<h2 id="Random-Number-Generation"><a href="#Random-Number-Generation" class="headerlink" title="Random Number Generation"></a>Random Number Generation</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line">Random rand = <span class="keyword">new</span> Random();</span><br><span class="line"><span class="keyword">int</span> randomNum = rand.nextInt((max - min) + <span class="number">1</span>) + min;</span><br><span class="line"><span class="comment">// simply can use this:</span></span><br><span class="line"><span class="comment">// return double, need to force convert to int maybe</span></span><br><span class="line">Math.random(): [<span class="number">0.00</span>,<span class="number">1.00</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Lambda-Expression"><a href="#Lambda-Expression" class="headerlink" title="Lambda Expression"></a>Lambda Expression</h2><p>for comparator and comparable, let’s see how to wirte it, <a href="https://www.mkyong.com/java8/java-8-lambda-comparator-example/" target="_blank" rel="noopener">this post</a></p>
<p>原来的方法，在constructor中定义comparator:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Queue&lt;Integer&gt; que = <span class="keyword">new</span> PriorityQueue&lt;&gt;(<span class="keyword">new</span> Comparator&lt;Integer&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Integer n1, Integer n2)</span> </span>&#123;</span><br><span class="line">				<span class="keyword">return</span> Integer.compare(n1, n2);</span><br><span class="line">			&#125; </span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span>[] arr = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">5</span>, <span class="number">3</span>, <span class="number">56</span>, <span class="number">78</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">5</span>&#125;;</span><br><span class="line"><span class="comment">// anonymous class to implement comparator</span></span><br><span class="line">Arrays.sort(arr, <span class="keyword">new</span> Comparator&lt;Integer&gt;()&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Integer n1, Integer n2)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Integer.compare(n1, n2);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[][] arr = &#123;&#123;<span class="number">5</span>,<span class="number">1</span>&#125;, &#123;<span class="number">2</span>,<span class="number">3</span>&#125;&#125;;</span><br><span class="line"><span class="comment">// sort by the first element of one dimenstional array</span></span><br><span class="line">Arrays.sort(arr, (<span class="keyword">int</span>[] a, <span class="keyword">int</span>[]b) -&gt; a[<span class="number">0</span>] - b[<span class="number">0</span>]);</span><br><span class="line">System.out.println(<span class="string">"result= "</span> + Arrays.deepToString(arr));</span><br></pre></td></tr></table></figure>
<p>用lambda构造comparator 时可以用到外部的数据结构？<br><a href="https://leetcode.com/problems/top-k-frequent-elements/solution/" target="_blank" rel="noopener">https://leetcode.com/problems/top-k-frequent-elements/solution/</a><br>比如这个的官方solution<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// init heap 'the less frequent element first'</span></span><br><span class="line">    PriorityQueue&lt;Integer&gt; heap =</span><br><span class="line">            <span class="keyword">new</span> PriorityQueue&lt;Integer&gt;((n1, n2) -&gt; count.get(n1) - count.get(n2))</span><br></pre></td></tr></table></figure></p>
<p>其实这里可以使用Map.Entry&lt;&gt; 放入pq中。<br>count是一个外部定义的hashmap. 这个到底是怎么回事？</p>
<h2 id="Java-Memory-Management"><a href="#Java-Memory-Management" class="headerlink" title="Java Memory Management"></a>Java Memory Management</h2><p>java heap space, java stack memory<br><a href="https://www.journaldev.com/4098/java-heap-space-vs-stack-memory" target="_blank" rel="noopener">Memory Allocation in Java</a><br><a href="https://www.baeldung.com/java-stack-heap" target="_blank" rel="noopener">Stack Memory and Heap Space in Java</a></p>
<h2 id="Java-Garbage-Collection"><a href="#Java-Garbage-Collection" class="headerlink" title="Java Garbage Collection"></a>Java Garbage Collection</h2><p>you can watch the operting system course video<br>implemented by DFS with marked bit in each object, scan from stack</p>
<h3 id="Why-use-Deque-instead-of-stack"><a href="#Why-use-Deque-instead-of-stack" class="headerlink" title="Why use Deque instead of stack"></a>Why use Deque instead of stack</h3><p>check this post <a href="https://leetcode.com/problems/flatten-nested-list-iterator/discuss/80147/Simple-Java-solution-using-a-stack-with-explanation/165585" target="_blank" rel="noopener">https://leetcode.com/problems/flatten-nested-list-iterator/discuss/80147/Simple-Java-solution-using-a-stack-with-explanation/165585</a></p>
<p>I just recently interviewed with 16 different companies in the silicon valley (including FAANG except Netflix) for senior software engineering positions. Here’s my opinion, based on my experience:</p>
<p>Some interviewers will expect you to know why Deque is better than Stack.</p>
<p>Showing mastery of at least one programming language (in this case, Java) can, at worst, score you extra points in the interview, and at best get you the job and even help you get higher compensation or leveling. Getting the optimal solution is the basic requirement to pass an interview. Additionally, you are being benchmarked against other candidates being asked exactly the same question. Lastly, for those targeting senior level positions, the interviewer will also evaluate your seniority. This is one case where I think most interviewers will expect to see that you’ve mastered the Java programming language (if you chose to use it in your interview).</p>
<p>Here are a few reasons why Deque is better than Stack:</p>
<p>Object oriented design - Inheritance, abstraction, classes and interfaces: Stack is a class, Deque is an interface. Only one class can be extended, whereas any number of interfaces can be implemented by a single class in Java (multiple inheritance of type). Using the Deque interface removes the dependency on the concrete Stack class and its ancestors and gives you more flexibility, e.g. the freedom to extend a different class or swap out different implementations of Deque (like LinkedList, ArrayDeque).</p>
<p>Inconsistency: Stack extends the Vector class, which allows you to access element by index. This is inconsistent with what a Stack should actually do, which is why the Deque interface is preferred (it does not allow such operations)–its allowed operations are consistent with what a FIFO or LIFO data structure should allow.</p>
<p>Performance: The Vector class that Stack extends is basically the “thread-safe” version of an ArrayList. The synchronizations can potentially cause a significant performance hit to your application. Also, extending other classes with unneeded functionality (as mentioned in #2) bloat your objects, potentially costing a lot of extra memory and performance overhead.</p>
<h2 id="Tries"><a href="#Tries" class="headerlink" title="Tries"></a>Tries</h2><p><code>string symbol table</code>: specialized to string key. Faster than hashing, flexible then BST<br>recall the structure of tries, very simple! put value in last node (character).<br>put and search method for tries can be recursion implementations.<br>一般都用的这个。</p>
<p><code>3-way tries</code>: 这里注意，当前char的值和node char比较，less then go left, larger then go right, then compare, if not match, miss hit. Using recursion to do put and search operation. <code>TST</code> is as fast as hashing (for string key) and space efficient. support in-order traverse (obey BST rule)</p>
<p>Implementation: prefix matching, wildcard match, longest prefix.</p>
<h1 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h1><p><a href="https://www.youtube.com/user/tusharroy2525/playlists" target="_blank" rel="noopener">Tushar Roy youtube channel</a><br>princeton algorithms，在youtube or coursera上都有</p>
<p>Time complexity:<br><a href="https://en.wikipedia.org/wiki/Time_complexity" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Time_complexity</a><br>usually:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">constant O(1)</span><br><span class="line">logarithmic O(logn)</span><br><span class="line">linear O(n)</span><br><span class="line">quasilinear O(nlogn)</span><br><span class="line">quadratic O(n^2), n to the power of 2</span><br><span class="line">cubic O(n^3), n to the power of 3</span><br><span class="line">polynomial O(n^x + n^y + ..)</span><br><span class="line">exponential O(2^n)</span><br><span class="line">factorial O(n!)</span><br></pre></td></tr></table></figure></p>
<p><code>Tilde notation</code>: ignore lower order terms, negligible<br>best case, lower bound<br>worst case, upper bound, <code>Big O</code> does this<br>average case, cost for random input, expected cost<br>when upper bound equals lower bound, we get optimal algorithms</p>
<p><a href="https://cs.stackexchange.com/questions/52776/difference-between-the-tilde-and-big-o-notations" target="_blank" rel="noopener">tilde notation vs big-O</a></p>
<h2 id="Prime"><a href="#Prime" class="headerlink" title="Prime"></a>Prime</h2><p>LC 886 <a href="https://leetcode.com/problems/prime-palindrome/" target="_blank" rel="noopener">https://leetcode.com/problems/prime-palindrome/</a><br>isPrime是如何检查的，函数记住, 并不是检查每个递增+1的除数是否整除！<br>检查特殊的值就可以了<br><a href="https://en.wikipedia.org/wiki/Primality_test" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Primality_test</a></p>
<h2 id="Monotonic-Stack"><a href="#Monotonic-Stack" class="headerlink" title="Monotonic Stack"></a>Monotonic Stack</h2><p>LC 496 Next Greater Element I<br>LC 503 Next Greater Element II<br>还有LC 31 next permutation 也是属于monotonic problem, 见这题我的note</p>
<p>Monotonic stack practice:<br><a href="https://medium.com/@vishnuvardhan623/monotonic-stack-e9dcc4fa8c3e" target="_blank" rel="noopener">https://medium.com/@vishnuvardhan623/monotonic-stack-e9dcc4fa8c3e</a></p>
<p>increasing monotonic stack: from stack top to stack bottom is increasing<br>decreasing monotonoc stack: reverse order</p>
<h2 id="General"><a href="#General" class="headerlink" title="General"></a>General</h2><p>bit and boolean can use XOR ^ operator!</p>
<h2 id="Sliding-Window"><a href="#Sliding-Window" class="headerlink" title="Sliding Window"></a>Sliding Window</h2><p>相关window问题的<a href="https://leetcode.com/problems/minimum-window-substring/discuss/26808" target="_blank" rel="noopener">template</a> and <a href="https://leetcode.com/problems/find-all-anagrams-in-a-string/discuss/92007" target="_blank" rel="noopener">summary</a>, good sliding window <a href="https://www.geeksforgeeks.org/window-sliding-technique/" target="_blank" rel="noopener">demo</a></p>
<p><a href="https://www.geeksforgeeks.org/window-sliding-technique/" target="_blank" rel="noopener">basic sliding window problem</a><br>leetcode 904<br>find the longest sequence with at most 2 integers</p>
<h2 id="Quick-select"><a href="#Quick-select" class="headerlink" title="Quick select"></a>Quick select</h2><p>Average <code>O(n)</code>, worst case <code>O(n^2)</code>, need to shuffle.<br>if quick select Kth element, then in the range [0, K] is guarantee the K smallest elemets in unsorted array.</p>
<p>Summary of top k problem:<br><a href="https://leetcode.com/problems/k-closest-points-to-origin/discuss/220235/" target="_blank" rel="noopener">https://leetcode.com/problems/k-closest-points-to-origin/discuss/220235/</a></p>
<h2 id="Binary-search"><a href="#Binary-search" class="headerlink" title="Binary search"></a>Binary search</h2><p>how to decide the condition?<br>lo &lt; hi or lo &lt;= hi?<br>hi = mid - 1 or hi = mid?<br>lo = mid + 1 or lo = mid?</p>
<p>when target exists, use<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (lo &lt;= hi)</span><br></pre></td></tr></table></figure></p>
<p>because it will finally concentrate. lo == hi will be the result:<br>hi = mid - 1 or hi = mid?<br>or<br>lo = mid + 1 or lo = mid?<br>does not matter.<br>对于可能不存在的也用lo &lt;= hi，但要保证hi = mid - 1 和 lo = mid + 1</p>
<p>You use while (start &lt;= end) if you are returning the match from inside the loop.<br>You use while (start &lt; end) if you want to exit out of the loop first, and then use the result of start or end to return the match.</p>
<h2 id="Backtracking"><a href="#Backtracking" class="headerlink" title="Backtracking"></a>Backtracking</h2><p><a href="https://www.geeksforgeeks.org/backtracking-algorithms/#standard" target="_blank" rel="noopener"><code>Backtracking</code></a> is an algorithmic-technique for solving problems <code>recursively</code> by trying to build a solution <code>incrementally</code>, one piece at a time, abandons those solutions that fail to satisfy the constraints of the problem at any point of time.</p>
<p>for example:<br>SudoKo<br><a href="https://www.youtube.com/watch?v=xouin83ebxE" target="_blank" rel="noopener">N Queens problem</a>, smart at process diagonal row-col and row + col. think recursion as a tree, back and forth.</p>
<p>leetcode <a href="https://leetcode.com/problems/permutations/discuss/18239" target="_blank" rel="noopener">summary</a> backtracking about <code>Subsets</code>, <code>Permutations</code>, and <code>Combination Sum</code></p>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>x^y how to describe: x to the power of y<br>x^2: x squard<br>x^3: x cubed</p>
<h2 id="Find-rectangle"><a href="#Find-rectangle" class="headerlink" title="Find rectangle"></a>Find rectangle</h2><p>p1[x,y], p2[x,y]<br>if p1 and p2 are diagonal, check if other 2 points exist, can use hashmap or hashset</p>
<h2 id="Toggle-1-and-0"><a href="#Toggle-1-and-0" class="headerlink" title="Toggle 1 and 0"></a>Toggle 1 and 0</h2><p>use xor 1 to toggle 1 and 0<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span></span><br><span class="line">a ^= <span class="number">1</span>; <span class="comment">// a is 0</span></span><br><span class="line">a ^= <span class="number">1</span>; <span class="comment">// a is 1</span></span><br></pre></td></tr></table></figure></p>
<p>calculate power of 2:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.pow(<span class="number">2</span>, n); <span class="comment">// slow</span></span><br><span class="line"><span class="comment">// or can use shift</span></span><br><span class="line"><span class="number">1</span> &lt;&lt; n <span class="comment">// fast</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Union-Find"><a href="#Union-Find" class="headerlink" title="Union Find"></a>Union Find</h2><p>for quick find, all sites in a component must have the same value in id[], directly check <code>id[p] == id[q]</code><br>for quick union, set the root of pool p to the root of q<br>then improve quick union, compress the path when seach the root:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span>[] uf, <span class="keyword">int</span> i)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (uf[i] != i)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// path compression</span></span><br><span class="line">    uf[i] = uf[uf[i]];</span><br><span class="line">    i = uf[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h2><p>in-place:<br>  bobble sort     stable<br>  selection sort  not stable<br>  insertion sort  stable<br>  quick sort      not stable<br>  heap sort       not stable<br>need space:<br>  merge sort      stable</p>
<p>insertion sort对于partial sorted的数组排序很快。<br>merge sort O(nlogn) 很稳定，可以用merge sort的思路去divide and conquer解决其他问题<br>quick sort 最坏O(n^2)，比如排好序的数组，所以需要shuffle: <code>Collections.shuffle(list)</code></p>
<p>radix sort不是通过comparison机制实现的, leetcode 164</p>
<p>sort one array based on another array<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// sort a based on b</span></span><br><span class="line"><span class="keyword">int</span>[] a = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">78</span>,<span class="number">4</span>,<span class="number">2</span>&#125;;</span><br><span class="line"><span class="keyword">int</span>[] b = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">7</span>,<span class="number">45</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">78</span>,<span class="number">2</span>,<span class="number">4</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// pair[i][0] = a[i];</span></span><br><span class="line"><span class="comment">// pair[i][1] = b[i];</span></span><br><span class="line"><span class="keyword">int</span>[][] pair = <span class="keyword">new</span> <span class="keyword">int</span>[a.length][a.length];</span><br><span class="line">Arrays.sort(pair, (a, b) -&gt; a[<span class="number">1</span>] - b[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line"><span class="comment">// or use map &lt;b value: b index&gt;</span></span><br><span class="line"><span class="comment">// the sort b, recreate a using the map mapping</span></span><br></pre></td></tr></table></figure></p>
<h2 id="0-1-knapsack"><a href="#0-1-knapsack" class="headerlink" title="0/1 knapsack"></a>0/1 knapsack</h2><h2 id="Binary-Search-Tree"><a href="#Binary-Search-Tree" class="headerlink" title="Binary Search Tree"></a>Binary Search Tree</h2><p>need to know different traverse orders:</p>
<ul>
<li><em>pre-order</em>: current -&gt; display -&gt; left -&gt; right</li>
<li><em>post-order</em>: current -&gt; left -&gt; right -&gt; display</li>
<li><em>in-order</em>: current -&gt; left -&gt; display -&gt; right, this will get ascending order if traverse a BST.</li>
<li><em>out-order</em>: current -&gt; right -&gt; display -&gt; left, this will get descending order if traverse a BST</li>
</ul>
<p>pre order list can build BST uniquely.<br>(post)pre order + in order can build BT uniquely</p>
<h3 id="threaded-binary-search-tree"><a href="#threaded-binary-search-tree" class="headerlink" title="threaded binary search tree"></a>threaded binary search tree</h3><p>LC 99:<br><a href="https://leetcode.com/problems/recover-binary-search-tree/submissions/" target="_blank" rel="noopener">https://leetcode.com/problems/recover-binary-search-tree/submissions/</a><br>video:<br>morris traversal inorder to binary tree: 不用递归的方式，实现constant space的一种traverse<br><a href="https://www.youtube.com/watch?v=wGXB9OWhPTg" target="_blank" rel="noopener">https://www.youtube.com/watch?v=wGXB9OWhPTg</a><br><a href="https://www.geeksforgeeks.org/inorder-tree-traversal-without-recursion-and-without-stack/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/inorder-tree-traversal-without-recursion-and-without-stack/</a></p>
<h2 id="Undirected-graph"><a href="#Undirected-graph" class="headerlink" title="Undirected graph"></a>Undirected graph</h2><p>vertex and edge matters<br>degree: num of edge connect to a vertex<br>graph API design:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">addEdge()</span><br><span class="line">Iterable adjacent nodes</span><br><span class="line">numEdge()</span><br><span class="line">numVertex()</span><br></pre></td></tr></table></figure></p>
<p>How to repesent vertex and it’s edge, here use <code>adjacency list</code><br>如果发现graph的node是连续的，比如<code>0 ~ n-1</code>则用adjacency list比较好，否则用<code>Map&lt;Integer, List&lt;Integer&gt;&gt;</code><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// generic array</span></span><br><span class="line">List&lt;Integer&gt;[] adj = (List&lt;Integer&gt;[]) <span class="keyword">new</span> List[n];</span><br><span class="line"><span class="comment">// it seems we can do now:</span></span><br><span class="line">List&lt;Integer&gt;[] adj =  <span class="keyword">new</span> List[n];</span><br><span class="line">TreeMap&lt;Integer, Integer&gt;[] tmap = <span class="keyword">new</span> TreeMap[n];</span><br><span class="line"><span class="comment">// init</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">&#123;</span><br><span class="line">  adj[i] = <span class="keyword">new</span> ArrayList&lt;Integer&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>actually we can use list of list instead of this format, but array is faster.<br><a href="https://stackoverflow.com/questions/8559092/create-an-array-of-arraylists" target="_blank" rel="noopener">how to create an array of list</a></p>
<p>may contains:<br>self-loop<br>parallel edges</p>
<h3 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS</h3><p>use <code>queue</code> to hold the vertices<br>add all unmarked vertices to queue adjacent to v and mark them<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">boolean</span>[] marked;</span><br><span class="line"><span class="keyword">int</span>[] edgeTo;</span><br><span class="line"><span class="keyword">int</span>[] distTo;</span><br></pre></td></tr></table></figure></p>
<p>time complexity: O(E + V)</p>
<h3 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h3><p>for example, find exit for maze graph<br>mark vertex has visited<br>recursive (or use <code>stack</code> )visit all unmarked vertices w adjancent to v<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">boolean</span>[] marked;</span><br><span class="line"><span class="keyword">int</span>[] edgeTo;</span><br></pre></td></tr></table></figure></p>
<p>time complexity: O(E + V)</p>
<h3 id="Bridge"><a href="#Bridge" class="headerlink" title="Bridge"></a>Bridge</h3><p>leetcode: <a href="https://leetcode.com/problems/critical-connections-in-a-network/" target="_blank" rel="noopener">1192</a><br>这是一种找bridge的算法: Tarjan algorithm<br>可以看看这个频道的graph theory playlist:<br><a href="https://www.youtube.com/watch?v=aZXi1unBdJA" target="_blank" rel="noopener">https://www.youtube.com/watch?v=aZXi1unBdJA</a><br><a href="https://www.youtube.com/watch?v=TyWtx7q2D7Y" target="_blank" rel="noopener">https://www.youtube.com/watch?v=TyWtx7q2D7Y</a></p>
<h3 id="Connected-components"><a href="#Connected-components" class="headerlink" title="Connected components"></a>Connected components</h3><p>a connected component is a max pool of connected vertices<br>answer the question: is v and w connected in contact time.</p>
<p>DFS? yes, run DFS for each unvisited vertex, verteice in same connected component has the same id (this can represent component number!), so, check vertex id will get result.</p>
<h2 id="Directed-graph"><a href="#Directed-graph" class="headerlink" title="Directed graph"></a>Directed graph</h2><p>also called <code>digraph</code><br>outdegree, indegree<br>directed cycle</p>
<p><code>DAG</code>: directed acyclic graph</p>
<h3 id="Unweighted"><a href="#Unweighted" class="headerlink" title="Unweighted"></a>Unweighted</h3><p><strong>without</strong> weight on edge, the same for DFS and BFS<br>we use <code>adjacency list</code> the same as undirected graph<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt;[] adj;</span><br></pre></td></tr></table></figure></p>
<h4 id="topological-sorting"><a href="#topological-sorting" class="headerlink" title="topological sorting"></a>topological sorting</h4><p>for example, <code>precedence scheduling</code><br>at least one vertex has 0 indegree and should be <code>directed acyclic graph (DAG)</code></p>
<p><code>BFS</code>: 从indegree为0的node开始，压入队列中，每次下一个node的indegree减1，再把下一批indegree为0的node压入队列中，最后如果没有cycle，所有node都应该被explored.</p>
<p><code>DFS</code>也可以，但要注意visited用2种记号表示, 0:没有访问，1:当前访问, 2:完全访问。如果在一次DFS中再次遇到了1，则说明有cycle.当完全访问后，再设置成2.</p>
<h4 id="strongly-connected-component"><a href="#strongly-connected-component" class="headerlink" title="strongly connected component"></a>strongly connected component</h4><p>Strongly connected: there is a path from v to w and w to v as well.<br>skip this topic</p>
<h3 id="Weighted"><a href="#Weighted" class="headerlink" title="Weighted"></a>Weighted</h3><p>API design:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">class DirectedEdge: weight, from, to</span><br><span class="line">class EdgeWeightedDigraph: addEdge(new DirectedEdge(from, to, weight));</span><br><span class="line">distTo(<span class="keyword">int</span> w);</span><br><span class="line">pathTo(<span class="keyword">int</span> w);</span><br></pre></td></tr></table></figure></p>
<p>we still use adjacency list representation:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;DirectedEdge&gt;[] adj = (List&lt;DirectedEdge&gt;[]) <span class="keyword">new</span> List[n];</span><br><span class="line"><span class="comment">// new init array</span></span><br><span class="line">List&lt;DirectedEdge&gt;[] adj = <span class="keyword">new</span> List[n];</span><br></pre></td></tr></table></figure></p>
<h4 id="Dijkstra"><a href="#Dijkstra" class="headerlink" title="Dijkstra"></a>Dijkstra</h4><p><code>non-negative weight</code><br><code>SPT</code>: shortest path tree exist in graph from the source vertex</p>
<p><strong>remember</strong>:<br>Use minium priority queue, to choose the next vertex cloest to the source vertex!<br>Then update the path accordingly if it’s shorter than before (如何实现这个degrade呢?)<br><a href="https://www.geeksforgeeks.org/dijkstras-shortest-path-algorithm-in-java-using-priorityqueue/" target="_blank" rel="noopener">implementation</a></p>
<p>有几点需要注意：</p>
<ol>
<li>它没有实现degrade操作，只是又加入了新的元素在pq中，这样旧的就沉到底部了</li>
<li>有一个visited set去控制结束</li>
<li>注意comparator interface是怎么实现的，override了compare method，其实也用不着，在pq初始化的时候可以用lambda去实现。</li>
</ol>
<p>time complexity of the construct computation: O(ElogV)</p>
<h4 id="Bellman-Ford"><a href="#Bellman-Ford" class="headerlink" title="Bellman-Ford"></a>Bellman-Ford</h4><p><code>no negative cycle</code></p>
<h3 id="A"><a href="#A" class="headerlink" title="A*"></a>A*</h3><p>A graph traversal and path search algorithm<br>leetcode 1263</p>
<h3 id="regular-expression"><a href="#regular-expression" class="headerlink" title="regular expression"></a>regular expression</h3><p>leetcode 819<br>去掉所有非字典字母，然后split每个word组成数组:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[] words = p.replaceAll(<span class="string">"\\W+"</span> , <span class="string">" "</span>).toLowerCase().split(<span class="string">"\\s+"</span>);</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>nologin User</title>
    <url>/2020/09/22/linux-nologin/</url>
    <content><![CDATA[<p>Previously I had a post talked about the <code>login and non-login shell</code>, please note that is a different concept with <code>nologin</code> user here.</p>
<p>Take <code>envoy</code> image as an example, pull it and launch the container:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull envoyproxy/envoy-dev:latest</span><br><span class="line">docker run -d \</span><br><span class="line">       --name <span class="built_in">test</span> \</span><br><span class="line">       --entrypoint=/bin/bash \</span><br><span class="line">       envoyproxy/envoy-dev:latest \</span><br><span class="line">       -c <span class="string">"tail -f /dev/null"</span></span><br></pre></td></tr></table></figure></p>
<p>Get into the container by (note this is not a <code>login</code> operation! see below my question):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -it <span class="built_in">test</span> bash</span><br></pre></td></tr></table></figure></p>
<p>Check <code>/etc/passwd</code> file, the <code>envoy</code> is a nologin user:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">envoy:x:101:101::/home/envoy:/usr/sbin/nologin</span><br></pre></td></tr></table></figure></p>
<p>If you run <code>su - envoy</code> from any other users (even you enter the login password), you get error:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># su - envoy</span></span><br><span class="line">This account is currently not available</span><br></pre></td></tr></table></figure></p>
<p>From nologin man page, the description is clear: nologin displays a message that an account is not available and exits<br>non-zero. It is intended as a replacement shell field to <strong>deny login access</strong> to an account. If the file <code>/etc/nologin.txt</code> exists, nologin displays its contents to the user instead of the default message. The exit status returned by nologin is always <code>1</code>.</p>
<p>Sometimes you will also see <code>/bin/false</code> is used:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">syslog:x:101:104::/home/syslog:/bin/false</span><br></pre></td></tr></table></figure></p>
<p>They both have the same purpose, but <code>nologin</code> is preferred since it give you a friendly message. <code>ssh</code>, <code>scp</code> and other login services will not work if the user is <code>nologin</code> type.</p>
<p>BTY, You still can execute command as a nologin user:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo -u &lt;nologin user name&gt; bash -c <span class="string">"ls -ltr /tmp"</span></span><br><span class="line"><span class="comment">## or launch a shell</span></span><br><span class="line">sudo -u &lt;nologin user name&gt; bash</span><br></pre></td></tr></table></figure></p>
<p>Then I have a question here: <a href="https://unix.stackexchange.com/questions/610851/why-docker-exec-command-can-launch-shell-with-nologin-user" target="_blank" rel="noopener">Why docker exec command can launch shell with nologin user?</a>. It turns out <code>docker exec</code> is not <code>login</code> action!</p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p><a href="https://unix.stackexchange.com/questions/155139/does-usr-sbin-nologin-as-a-login-shell-serve-a-security-purpose" target="_blank" rel="noopener">Does /usr/sbin/nologin as a login shell serve a security purpose?</a><br><a href="https://serverfault.com/questions/519215/what-is-the-difference-between-sbin-nologin-and-bin-false" target="_blank" rel="noopener">https://serverfault.com/questions/519215/what-is-the-difference-between-sbin-nologin-and-bin-false</a><br><a href="https://serverfault.com/questions/333321/executing-a-command-as-a-nologin-user" target="_blank" rel="noopener">https://serverfault.com/questions/333321/executing-a-command-as-a-nologin-user</a><br><a href="https://jpetazzo.github.io/2014/06/23/docker-ssh-considered-evil/" target="_blank" rel="noopener">Don’t sshd your container</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux</tag>
        <tag>nologin</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux PAM Module Configuration</title>
    <url>/2019/04/01/linux-pam/</url>
    <content><![CDATA[<p>When I was working on non-root set up worker containers or pods, in order to grant the non-root user su password-less privilege, I got into PAM module in RHEL. Let’s spend time to understand it.</p>
<p><strong>Pluggable authentication modules (PAMs)</strong> are a common framework for <strong>authentication</strong> and <strong>authorization</strong>. </p>
<p>There are many programs on your system that use PAM modules like su, passwd, ssh and login and other services. PAM main focus is to authenticate your users.</p>
<p>PAM or Pluggable Authentication Modules are the management layer that sits between Linux applications and the Linux native authentication system.</p>
<blockquote>
<p>For full details, please refer:<br><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system-level_authentication_guide/pluggable_authentication_modules" target="_blank" rel="noopener">USING PLUGGABLE AUTHENTICATION MODULES (PAM)</a><br><a href="https://www.cnblogs.com/kevingrace/p/8671964.html" target="_blank" rel="noopener">CHINESE VERSION</a></p>
</blockquote>
<p>Each PAM-aware application or service has a file in the <code>/etc/pam.d/</code> directory. Each file in this directory has the same name as the service to which it controls access. For example, the <code>login</code> program defines its service name as login and installs the <code>/etc/pam.d/login</code> PAM configuration file.</p>
<p>What I have done is add a non-root user, for example <code>demo</code>, to <code>wheel</code> group (usually <code>wheel</code> group is pre-existing), operate this as root user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usermod -a -G wheel demo</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Why <code>wheel</code> group? What is <code>wheel</code> stand for in computing?</p>
<p>In computing, the term <code>wheel</code> refers to a user account with a wheel bit, a system setting that provides additional special system privileges that empower a user to execute restricted commands that ordinary user accounts cannot access.</p>
<p>Modern Unix systems generally use user groups as a security protocol to control access privileges. The <code>wheel</code> group is a special user group used on some Unix systems to control access to the su or sudo command, which allows a user to masquerade as another user (usually the super user).</p>
<p>By default it permits root access to the system if the applicant user is a member of the <code>wheel</code> group.</p>
</blockquote>
<p>check <code>demo</code> group information:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">id demo</span><br><span class="line"></span><br><span class="line">uid=1010(demo) gid=1010(demo) groups=1010(demo),10(wheel)</span><br></pre></td></tr></table></figure></p>
<p>you can also go to <code>/etc/group</code> file to check group members of <code>wheel</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wheel:x:10:demo</span><br></pre></td></tr></table></figure></p>
<p>Then go to edit <code>/etc/pam.d/su</code> file to uncomment this directive:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Uncomment the following line to implicitly trust users in the &quot;wheel&quot; group.</span><br><span class="line">auth           sufficient      pam_wheel.so trust use_uid</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>What is <code>pam_wheel.so</code>?</p>
<p>The <code>pam_wheel</code> PAM module is used to enforce the so-called <code>wheel</code> group. By default it permits root access(su - ) to the system if the applicant user is a member of the wheel group. If no group with this name exist, the module is using the group with the group-ID 0.</p>
</blockquote>
<p>Now the user <code>demo</code> can su to other users (include root) without password. You can run command as another user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">su - &lt;another&gt; -c &quot;&lt;command&gt;&quot;</span><br></pre></td></tr></table></figure></p>
<p>If you also want to have <code>sudo</code> password-less privilege for <code>wheel</code> group user, you need to edit <code>/etc/sudoers</code> file by <code>visudo</code> as root like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## Allows people in group wheel to run all commands</span><br><span class="line">#%wheel  ALL=(ALL)       ALL</span><br><span class="line"></span><br><span class="line">## Same thing without a password</span><br><span class="line">%wheel        ALL=(ALL)       NOPASSWD: ALL</span><br></pre></td></tr></table></figure></p>
<h3 id="PAM-file-format"><a href="#PAM-file-format" class="headerlink" title="PAM file format"></a>PAM file format</h3><p>Each PAM configuration file, such as <code>/etc/pam.d/su</code> contains a group of directives that define the module (the authentication configuration area) and any controls or arguments with it.</p>
<p>The directives all have a simple syntax that identifies the module purpose (interface) and the configuration settings for the module.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">module_interface	control_flag	module_name module_arguments</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>module_name</strong> — such as <code>pam_wheel.so</code></li>
<li><strong>auth</strong> — This module interface authenticates users. For example, it requests and verifies the validity of a password. Modules with this interface can also set credentials, such as group memberships.</li>
</ul>
<p>All PAM modules generate a success or failure result when called. <code>Control flags</code> tell PAM what to do with the result. Modules can be listed (stacked) in a particular order, and the control flags determine how important the success or failure of a particular module is to the overall goal of authenticating the user to the service.</p>
<ul>
<li><strong>sufficient</strong> — The module result is ignored if it fails. However, if the result of a module flagged sufficient is successful and no previous modules flagged required have failed, then no other results are required and the user is authenticated to the service.</li>
</ul>
<p>Let’s see an example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@MyServer ~]# cat /etc/pam.d/setup</span><br><span class="line"></span><br><span class="line">auth       sufficient	pam_rootok.so</span><br><span class="line">auth       include	system-auth</span><br><span class="line">account    required	pam_permit.so</span><br><span class="line">session	   required	pam_permit.so</span><br></pre></td></tr></table></figure></p>
<p>Here the modules are stacking, from up to bottom, verify each directive one by one,</p>
<ul>
<li><p><em>auth sufficient pam_rootok.so</em> — This line uses the <code>pam_rootok.so</code> module to check whether the current user is root, by verifying that their UID is 0. If this test succeeds, no other modules are consulted and the command is executed. If this test fails, the next module is consulted.</p>
</li>
<li><p><em>auth include system-auth</em> — This line includes the content of the /etc/pam.d/system-auth module and processes this content for authentication.</p>
</li>
</ul>
<p>PAM uses <code>arguments</code> to pass information to a pluggable module during authentication for some modules.</p>
<ul>
<li><p><strong>trust</strong>: The <code>pam_wheel</code> module will return PAM_SUCCESS instead of PAM_IGNORE if the user is a member of the wheel group</p>
</li>
<li><p><strong>use_uid</strong>: The check for wheel membership will be done against the current uid instead of the original one</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>pam</tag>
      </tags>
  </entry>
  <entry>
    <title>/proc/$$ and /proc/self</title>
    <url>/2020/02/03/linux-proc-$$-self/</url>
    <content><![CDATA[<p><code>$$</code> is a special bash variable (special parameter <code>$</code> with a preceding expansion mark <code>$</code>) that gets expanded to the <code>pid of the shell</code>.</p>
<p><code>/proc/self</code> is a real symbolic link to the /proc/ subdirectory of the process that is <code>currently making the call</code>.</p>
<p>When you do <code>ls /proc/$$</code> the shell expands it to <code>ls /proc/pid-of-bash</code> and that is what you see, the contents of the shell process.</p>
<p>But when you do <code>ls /proc/self</code> you see the contents of the short lived <code>ls</code> process. If you write code which uses <code>/proc/self</code> that code will see its own pid, namely the process making the system call with <code>/proc/self</code> as part of the pathname in one of its arguments. </p>
<p>The <code>$$</code> is not limited to this usage, you can write echo $$ to see the bash pid; you can use it to kill yourself, etc.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Sync Up Files with rsync</title>
    <url>/2019/05/28/linux-rsync/</url>
    <content><![CDATA[<p>This command is awesome! I said I should do backup periodically and it suits the demands. It’s more elegant and smart than using portable storage or <code>scp</code> to transfer the files.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Let’s see what is <code>rsync</code> from <a href="https://en.wikipedia.org/wiki/Rsync" target="_blank" rel="noopener">wiki</a>:<br><code>rsync</code> is a utility for efficiently transferring and synchronizing files between a computer and an external hard drive and across networked computers by comparing the modification times and sizes of files.</p>
<p><code>rsync</code> will use <strong>SSH</strong> to connect. Once connected, it will invoke the remote host’s <code>rsync</code> and then the two programs will determine what parts of the local file need to be transferred so that the remote file matches the local one.</p>
<p><code>rsync</code> can also operate in a daemon mode, serving and receiving files in the native rsync protocol (using the <code>rsync://</code> syntax). Here I only talks SSH way.</p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>To get <code>rsync</code> working between two hosts, the <code>rsync</code> program must be installed on both the source and destination, and you’ll need a way to access one machine from the other.</p>
<p>Copy files to remote home or from remote to local<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync files remote:</span><br><span class="line">rsync files user@remote:</span><br><span class="line">rsync user@remote:source dest</span><br></pre></td></tr></table></figure></p>
<p>If <code>rsync</code> isn’t in the remote path but is on the system, use <code>--rsync-path=path</code> to manually specify its location.</p>
<p>Unless you supply extra options, <code>rsync</code> copies <strong>only</strong> files. You will see:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skipping directory xxx</span><br></pre></td></tr></table></figure></p>
<p>To transfer entire directory hierarchies, complete with symbolic links, permissions, modes, and devices, use the <code>-a</code> option.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -nv files -a dir user@remote:</span><br></pre></td></tr></table></figure></p>
<p><code>-n</code>: dry-run, this is vital when you are not sure.<br><code>-vv</code>: verbose mode</p>
<p>To make an exact replica of the source directory, you must delete files in the destination directory that do not exist in the source directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -vv --delete -a dir user@remote:</span><br></pre></td></tr></table></figure></p>
<p>Please use <code>-n</code> dry-run to see what will be deleted before performing command.</p>
<p>Be particular careful with tailing slash after dir:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -a dir/ user@remote:dest</span><br></pre></td></tr></table></figure></p>
<p>This will copy all files under dir to dest folder in remote instead of copy dir into dest.</p>
<p>You can also <code>--exclude=</code>, <code>--exclude-from=</code> and <code>--include=</code> in command.</p>
<p>To speed operation, <code>rsync</code> uses a quick check to determine whether any files on the transfer source are already on the destination. The quick check uses a combination of the file size and its last-modified date.</p>
<p>When the files on the source side are not identical to the files on the destination side, <code>rsync</code> transfers the source files and overwrites any files that exist on the remote side. The default behavior may be inadequate, though, because you may need additional reassurance that files are indeed the same before skipping over them in transfers, or you may want to put in some extra safeguards:</p>
<ul>
<li><p><code>--checksum</code>(abbreviation: <code>-c</code>) Compute checksums (mostly unique signatures) of the files to see if they’re the same. This consumes additional I/O and CPU resources during transfers, but if you’re dealing with sensitive data or files that often have uniform sizes, this option is a must. (This will focus on file content, not date stamp)</p>
</li>
<li><p><code>--ignore-existing</code> Doesn’t clobber files already on the target side.</p>
</li>
<li><p><code>--backup</code> (abbreviation: <code>-b</code>) Doesn’t clobber files already on the target but rather renames these existing files by adding a ~ suffix to their names before transferring the new files.</p>
</li>
<li><p><code>--suffix=s</code> Changes the suffix used with –backup from <code>~</code> to <code>s</code>.</p>
</li>
<li><p><code>--update</code> (abbreviation: <code>-u</code>) Doesn’t clobber any file on the target that has a later date than the corresponding file on the source.</p>
</li>
</ul>
<p>You can also compress the dir when transfer:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -az dir user@remote:</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>rsync</tag>
      </tags>
  </entry>
  <entry>
    <title>SELinux</title>
    <url>/2019/06/23/linux-selinux/</url>
    <content><![CDATA[<p>I have got chance to learn something about <code>SELinux</code> (Security-Enhanced Linux). This is a online training from O’REILLY.</p>
<p>The Linux operating system was never designed with overall security in mind, and that’s exactly where <code>SELinux</code> comes in. Using SELinux adds 21st century security to the Linux operating system. It is key to providing access control and is also an important topic in the Red Hat RHCSA, CompTIA Linux+ and Linux Foundation LFCS exams.</p>
<p><a href="https://en.wikipedia.org/wiki/Security-Enhanced_Linux" target="_blank" rel="noopener">Security-Enhanced Linux</a><br>I am using a <code>CentOS</code> machine in this training.</p>
<p>SELinux implements Mandatory Security. All syscalls are <strong>denied</strong> by default,<br>unless specifically enabled</p>
<ul>
<li>All objects (files, ports, processes) are provided with a security label (the<br>context)</li>
<li>User, role and type part in the context</li>
<li>Type part is the most important</li>
<li>The SELinux policy contains rules where you can see which source context<br>has access to which target context</li>
</ul>
<p>To check if SELinux status, dsiabled or enforcing<br><a href="https://howto.lintel.in/enable-disable-selinux-centos/" target="_blank" rel="noopener">Enable SELinux</a></p>
<p><code>Z</code> flag is the magic to show SELinux information<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -Z /boot</span><br><span class="line">netstat -Ztunlp</span><br><span class="line">ps auxZ</span><br></pre></td></tr></table></figure></p>
<p>看到22:00，没来得及看完😂，唉。。。这个topic对于目前的我，有点用不上，晦涩。不过这个配置有时会被特别提起，disable or permissive.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Special Permission Bits</title>
    <url>/2019/05/11/linux-setuid-sticky-bit/</url>
    <content><![CDATA[<p>I haven’t seen something like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-r-sr-sr-x 1 root     db2iadm1   115555 Mar 21 03:19 db2start</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drwxrwsr-t 1 db2inst1 db2iadm1 212 May 10 17:16 sqllib</span><br><span class="line">drwxr-x--T 1 wasadmin dstage    21 Mar 21 03:56 usr</span><br></pre></td></tr></table></figure>
<p>What are these <code>s</code> (sometimes <code>S</code>) and <code>t/T</code> for? I only know <code>rwx</code> before (too young too simple T_T), these should be some basic things…</p>
<h3 id="Basic-Permissions"><a href="#Basic-Permissions" class="headerlink" title="Basic Permissions"></a>Basic Permissions</h3><ul>
<li><p><code>Read</code> - a readable permission allows the contents of the file to be viewed. A read permission on a directory allows you to list the contents of a directory.</p>
</li>
<li><p><code>Write</code> - a write permission on a file allows you to modify the contents of that file. For a directory, the write permission allows you to edit the contents of a directory (e.g. add/delete files).</p>
</li>
<li><p><code>Execute</code> - for a file, the executable permission allows you to run the file and execute a program or script. For a directory, the execute permission allows you to change to a different directory and make it your current working directory.</p>
</li>
</ul>
<h3 id="Setuid-and-Setgid-Bit"><a href="#Setuid-and-Setgid-Bit" class="headerlink" title="Setuid and Setgid Bit"></a>Setuid and Setgid Bit</h3><p>Assigning the <code>setuid</code> bit to binaries is a common way to give programs root permissions. <code>Linux capabilities</code> is a great alternative to reduce the usage of setuid.</p>
<blockquote>
<p>Capabilities break up root privileges in smaller units, so root access is no longer needed. Most of the binaries that have a setuid flag, can be changed to use capabilities instead.</p>
</blockquote>
<p><a href="https://linux-audit.com/linux-capabilities-hardening-linux-binaries-by-removing-setuid/" target="_blank" rel="noopener">Harden Linux Binaries by Removing setuid</a></p>
<h4 id="Apply-on-File"><a href="#Apply-on-File" class="headerlink" title="Apply on File"></a>Apply on File</h4><p>When the <code>setuid</code> or <code>setgid</code> attributes are set on an executable file, then any users able to execute the file will automatically execute the file with the privileges of the file’s owner (commonly root) and/or the file’s group, depending upon the flags set</p>
<p>This may pose potential security risks in some cases and executables should be properly evaluated before set.</p>
<p>For example the <code>passwd</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rwsr-xr-x. 1 root root 27832 Jan 29  2014 /usr/bin/passwd</span><br></pre></td></tr></table></figure></p>
<p>set setuid on file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod u+s script.sh</span><br></pre></td></tr></table></figure></p>
<p>remove setuid on file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod u-s script.sh</span><br></pre></td></tr></table></figure></p>
<h4 id="Apply-on-Directory"><a href="#Apply-on-Directory" class="headerlink" title="Apply on Directory"></a>Apply on Directory</h4><p>Setting the <code>setgid</code> permission on a directory causes new files and subdirectories created within it to inherit its <code>group ID</code>, rather than the primary group ID of the user who created the file (the owner ID is <strong>never</strong> affected, only the group ID).</p>
<p>set setgid on directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod g+s dir</span><br></pre></td></tr></table></figure></p>
<p>remove setgid on directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod g-s dir</span><br></pre></td></tr></table></figure></p>
<p>The <code>setuid</code> permission set on a directory is ignored on most UNIX and Linux systems.However FreeBSD can be configured to interpret <code>setuid</code> in a manner similar to setgid, in which case it forces all files and sub-directories created in a directory to be owned by that directory’s owner - a simple form of inheritance.</p>
<p>Note that both the <code>setuid</code> and <code>setgit</code> bits have <strong>no effect</strong> if the executable bit is not set. if executable bit is not set, <code>s</code> changes to <code>S</code>.</p>
<h4 id="Chown-Removes-Setuid"><a href="#Chown-Removes-Setuid" class="headerlink" title="Chown Removes Setuid"></a>Chown Removes Setuid</h4><p>If you run <code>chown</code> on a <code>setuid</code> script, you will find that the <code>s</code> is gone. This is a reasonable design, otherwise the <code>s</code> will apply to the new owner, a big security hole.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The `chown&apos; command sometimes clears the set-user-ID or set-group-ID</span><br><span class="line">permission bits.  This behavior depends on the policy and functionality</span><br><span class="line">of the underlying `chown&apos; system call, which may make system-dependent</span><br><span class="line">file mode modifications outside the control of the `chown&apos; command.</span><br><span class="line">For example, the `chown&apos; command might not affect those bits when</span><br><span class="line">invoked by a user with appropriate privileges, or when the bits signify</span><br><span class="line">some function other than executable permission (e.g., mandatory</span><br><span class="line">locking).  When in doubt, check the underlying system behavior.</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note that is you want to keep setuid and owner no change, for example last time deal with <code>sqllib</code>, please perserve when you do copy like: <code>/bin/cp -rfp /home/dfdcdc/sqllib /tmp</code></p>
</blockquote>
<h3 id="Sticky-Bit"><a href="#Sticky-Bit" class="headerlink" title="Sticky Bit"></a>Sticky Bit</h3><p>When set on a file or directory, the <code>sticky bit</code>, or <code>+t</code> mode, means that only the <code>owner</code> (or <code>root</code>) can delete the file (or files under the directory), <strong>regardless of</strong> which users have write access to this file or directory by way of group membership or ownership! </p>
<p>This is useful when a file or directory is owned by a group through which a number of users share write access to a given set of files.</p>
<p>set sticky bit:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +t script.sh</span><br></pre></td></tr></table></figure></p>
<p>remove sticky bit, note that to change the sticky bit, you need to be either root or the file owner. The root user will be able to delete files regardless of the status of the sticky bit.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod -t script.sh</span><br></pre></td></tr></table></figure></p>
<p>Sometimes you see <code>T</code> instead of <code>t</code>, usually <code>t</code> sits with execute <code>x</code>, but if the execute bit is not set then the <code>t</code> is flagged up as a capital, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">touch file</span><br><span class="line">chmod u=rwx,go=rx file    # &quot;-rwxr-xr-x 1 roaima 0 Sep 10 23:13 file&quot;</span><br><span class="line">chmod +t file             # &quot;-rwxr-xr-t 1 roaima 0 Sep 10 23:13 file&quot;</span><br><span class="line">chmod o-x file            # &quot;-rwxr-xr-T 1 roaima 0 Sep 10 23:13 file&quot;</span><br><span class="line">chmod u=rwx,go=,+t file   # &quot;-rwx-----T 1 roaima 0 Sep 10 23:13 file&quot;</span><br></pre></td></tr></table></figure></p>
<p>Now if a user is not in that group, it cannot even enter the directory.</p>
<h3 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h3><p><a href="https://en.wikipedia.org/wiki/Setuid#SGID" target="_blank" rel="noopener">wiki setuid and setgid</a><br><a href="https://unix.stackexchange.com/questions/228925/how-do-you-set-the-t-bit" target="_blank" rel="noopener">how to set <code>T</code> bit</a><br><a href="https://unix.stackexchange.com/questions/53665/chown-removes-setuid-bit-bug-or-feature" target="_blank" rel="noopener">chown remove setuid</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>setuid</tag>
        <tag>setgid</tag>
        <tag>sticky</tag>
      </tags>
  </entry>
  <entry>
    <title>sed Command Daily Work Summary</title>
    <url>/2019/05/30/linux-sed-summary/</url>
    <content><![CDATA[<p>Normally we use a interactive text editor, like <code>vim</code>. The command <code>sed</code> is one of the most commonly used <code>command line editor</code> in Linux world. <code>sed</code> stands for the <code>stream editor</code>, it uses the roles supplied to edit a stream of data on the fly.</p>
<p><strong>Note</strong>: Be careful that <code>sed</code> will break the softlink and create a file with the same name! for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ln -s /tmp/source.txt /tmp/link.txt</span><br><span class="line">sed -i -e <span class="string">"s#aaa#bbb#"</span> /tmp/link.txt</span><br></pre></td></tr></table></figure></p>
<p>then the softlink is gone, a new file named link.txt is created instead.<br>so use <code>readlink</code> first to get resolved symbolic links, then use <code>sed</code> on it.</p>
<p>First you need to understand how <code>sed</code> works with text:</p>
<ol>
<li>Reads <strong>one</strong> data line at a time from the input</li>
<li>Matches that data with the supplied editor commands</li>
<li>Changes data in the stream as specified in the commands</li>
<li>Outputs the new data to STDOUT</li>
</ol>
<p>2个对于输出很有帮助的flags, 可以加在其他功能后面:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -n: quiet</span></span><br><span class="line"><span class="comment"># /p: print the edited line</span></span><br><span class="line"><span class="comment"># 这样组合就只会输出改动的部分</span></span><br><span class="line">sed -n -e <span class="string">'s/root/toor/p'</span> file</span><br></pre></td></tr></table></figure></p>
<h2 id="Substitution"><a href="#Substitution" class="headerlink" title="Substitution"></a>Substitution</h2><p>I have a text file <code>sedtxt</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hello world and hello tree.</span><br><span class="line">Using Java print hello world and hello tree.</span><br><span class="line">Using Java print hello world and hello tree.</span><br><span class="line">Using Java print hello world and hello tree.</span><br></pre></td></tr></table></figure></p>
<p>If I want to substite all <code>hello</code> with <code>hi</code> in-place:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i -e <span class="string">'s/hello/hi/g'</span> sedtxt</span><br></pre></td></tr></table></figure></p>
<p><code>-i</code>: does in-place substitution in file <code>sedtxt</code>, create backup file automatically by using <code>-i.bak</code><br><code>-e</code>: followed by commands<br><code>s/x/y/flags</code>: substitute option, <code>/</code> is the delimiter, can be other chars; <code>g</code> represents that replace in all occurrences (global).</p>
<blockquote>
<p>Note that if not set <code>g</code>, it will only replace first occurrence in <strong>each</strong> line!</p>
</blockquote>
<blockquote>
<p>Note that <code>sed</code> can get input from STDIN or from pipe</p>
</blockquote>
<p>If I want to substitute the <strong>second</strong> <code>hello</code> with <code>goodbye</code> in each line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'s/hello/goodbye/2'</span> sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hello world and goodbye tree.</span><br><span class="line">Using Java print hello world and goodbye tree.</span><br><span class="line">Using Java print hello world and goodbye tree.</span><br><span class="line">Using Java print hello world and goodbye tree.</span><br></pre></td></tr></table></figure>
<p>If I want to substitute <code>hello</code> with <code>hi</code> and <code>Java</code> with <code>Python</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'s/hello/hi/g'</span> -e <span class="string">'s/Java/Pyhton/g'</span> sedtxt</span><br><span class="line">sed -e <span class="string">'s/hello/hi/g; s/Java/Python/g'</span> sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Pyhton print hi world and hi tree.</span><br><span class="line">Using Pyhton print hi world and hi tree.</span><br><span class="line">Using Pyhton print hi world and hi tree.</span><br><span class="line">Using Pyhton print hi world and hi tree.</span><br></pre></td></tr></table></figure>
<p>If I want to print only the matching lines, convenient for debugging:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -n -e <span class="string">'s/hello/hi/gp'</span> sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br></pre></td></tr></table></figure>
<p><code>-n</code>: quiet output<br><code>p</code>: substitute flag to print matching line</p>
<blockquote>
<p>Note, combine with <code>grep</code> to debug is good</p>
</blockquote>
<h3 id="Using-Address"><a href="#Using-Address" class="headerlink" title="Using Address"></a>Using Address</h3><p>The <code>sed</code> editor assigns the first line in the text stream as line number 1 and continues sequentially for each new line.</p>
<p>only replace 2rd line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'2s/hello/hi/g'</span> sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Using Java <span class="built_in">print</span> hello world and hello tree.</span><br><span class="line">Using Java <span class="built_in">print</span> hi world and hi tree.</span><br><span class="line">Using Java <span class="built_in">print</span> hello world and hello tree.</span><br><span class="line">Using Java <span class="built_in">print</span> hello world and hello tree.</span><br></pre></td></tr></table></figure>
<p>range substitution, <code>&#39;1,$s/hello/hi/g&#39;</code> means from top to bottom.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'2,3s/hello/hi/g'</span> sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hello world and hello tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hello world and hello tree.</span><br></pre></td></tr></table></figure>
<p>can also use text pattern to filter lines, this will apply one line contains <code>print</code> word.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'/print/s#and#or#'</span> sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hello world or hello tree.</span><br><span class="line">Using Java print hello world or hello tree.</span><br><span class="line">Using Java print hello world or hello tree.</span><br><span class="line">Using Java print hello world or hello tree.</span><br></pre></td></tr></table></figure>
<h2 id="Deletion"><a href="#Deletion" class="headerlink" title="Deletion"></a>Deletion</h2><p>I have a text file <code>seddel</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure></p>
<p>Delete line 2 to end:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'2,$d'</span> seddel</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br></pre></td></tr></table></figure>
<p>can also use pattern matching, delete <code>3rd</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'/3rd/d'</span> seddel</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure>
<p>You can combine 2 address syntax, this will start from first line and until match <code>3rd</code>, replace <code>3rd</code> in the range with <code>NAN</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'1,/3rd/&#123;s/3rd/NAN/g&#125;'</span> seddel</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The NAN line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure>
<p>Delete commented and empty line<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'/^#/d; /^$/d'</span> &lt;file&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Insertion-and-Appending"><a href="#Insertion-and-Appending" class="headerlink" title="Insertion and Appending"></a>Insertion and Appending</h2><p>The insert command (<code>i</code>) adds a new line <strong>before</strong> the specified line.<br>The append command (<code>a</code>) adds a new line <strong>after</strong> the specified line.</p>
<p>I have a text file <code>sedins</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure></p>
<p>Insert at first line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'1iNew line coming!'</span> sedins</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">New line coming!</span><br><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure>
<p>Append at 3rd line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'2aNew line coming!'</span> sedins</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">New line coming!</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure>
<h3 id="Insert-with-white-spaces"><a href="#Insert-with-white-spaces" class="headerlink" title="Insert with white spaces"></a>Insert with white spaces</h3><p>For example, When developing non-root, I want to add <code>runAsUser: 1000</code> right after <code>securityContext:</code> with correct alignment:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i -e <span class="string">'/securityContext/a\         runAsUser: 1000'</span> xxx.yml</span><br></pre></td></tr></table></figure></p>
<p>Only to escape the first space. <code>sed</code> can automatically recognize the rest of the spaces.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">       securityContext:</span><br><span class="line">         runAsUser: 1000</span><br><span class="line">         privileged: false</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h2 id="Changing"><a href="#Changing" class="headerlink" title="Changing"></a>Changing</h2><p>The change command allows you to change the contents of an entire line of text in the data stream.</p>
<p>I have a text file <code>sedch</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure></p>
<p>change the second line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'2cNONE'</span> sedch</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">sed -e <span class="string">'/2rd/cNONE'</span> sedch</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">NONE</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure>
<h2 id="Transforming-chars"><a href="#Transforming-chars" class="headerlink" title="Transforming chars"></a>Transforming chars</h2><p>The transform command (<code>y</code>) is the only sed editor command that operates on a single character. </p>
<p>I have a text file <code>sedtrans</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure></p>
<p>The transform command performs a one-to-one mapping of the inchars and the outchars values.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'y/1234/5678/'</span> sedtrans</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 5st line is 5</span><br><span class="line">The 6rd line is 6</span><br><span class="line">The 7rd line is 7</span><br><span class="line">The 8th line is 8</span><br></pre></td></tr></table></figure>
<p>The transform command is a <strong>global</strong> command; that is, it performs the transformation on any character found in the text line automatically, without regard to the occurrence.<br>You can’t limit the transformation to a specific occurrence of the character.</p>
<h2 id="sed-files-in-directory-and-subdirectories-recursively"><a href="#sed-files-in-directory-and-subdirectories-recursively" class="headerlink" title="sed files in directory and subdirectories recursively"></a>sed files in directory and subdirectories recursively</h2><p>Actually we can find all files by <code>find</code> then exec <code>sed</code>, see this <a href="https://stackoverflow.com/questions/6758963/find-and-replace-with-sed-in-directory-and-sub-directories" target="_blank" rel="noopener">post</a>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find &lt;dir&gt; -<span class="built_in">type</span> f -name <span class="string">"*sh"</span> -<span class="built_in">exec</span> sed -i -e <span class="string">"s|<span class="variable">$&#123;old&#125;</span>|<span class="variable">$&#123;new&#125;</span>|g"</span> &#123;&#125; \;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>-type f</code> is necessary, otherwise will pass directory name to <code>sed</code>.</p>
</blockquote>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Signals and Trap</title>
    <url>/2019/08/13/linux-signal-trap/</url>
    <content><![CDATA[<p>Signals are software interrupts sent to a program to indicate that an important event has occurred. The events can vary from user requests to illegal memory access errors.</p>
<p>To list the signal supported on Linux system:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list all signal and corresponding number</span></span><br><span class="line"><span class="built_in">kill</span> -l</span><br><span class="line"></span><br><span class="line"> 1) SIGHUP	 2) SIGINT	 3) SIGQUIT	 4) SIGILL	 5) SIGTRAP</span><br><span class="line"> 6) SIGABRT	 7) SIGBUS	 8) SIGFPE	 9) SIGKILL	10) SIGUSR1</span><br><span class="line">11) SIGSEGV	12) SIGUSR2	13) SIGPIPE	14) SIGALRM	15) SIGTERM</span><br><span class="line">16) SIGSTKFLT	17) SIGCHLD	18) SIGCONT	19) SIGSTOP	20) SIGTSTP</span><br><span class="line">21) SIGTTIN	22) SIGTTOU	23) SIGURG	24) SIGXCPU	25) SIGXFSZ</span><br><span class="line">26) SIGVTALRM	27) SIGPROF	28) SIGWINCH	29) SIGIO	30) SIGPWR</span><br><span class="line">31) SIGSYS	34) SIGRTMIN	35) SIGRTMIN+1	36) SIGRTMIN+2	37) SIGRTMIN+3</span><br><span class="line">38) SIGRTMIN+4	39) SIGRTMIN+5	40) SIGRTMIN+6	41) SIGRTMIN+7	42) SIGRTMIN+8</span><br><span class="line">43) SIGRTMIN+9	44) SIGRTMIN+10	45) SIGRTMIN+11	46) SIGRTMIN+12	47) SIGRTMIN+13</span><br><span class="line">48) SIGRTMIN+14	49) SIGRTMIN+15	50) SIGRTMAX-14	51) SIGRTMAX-13	52) SIGRTMAX-12</span><br><span class="line">53) SIGRTMAX-11	54) SIGRTMAX-10	55) SIGRTMAX-9	56) SIGRTMAX-8	57) SIGRTMAX-7</span><br><span class="line">58) SIGRTMAX-6	59) SIGRTMAX-5	60) SIGRTMAX-4	61) SIGRTMAX-3	62) SIGRTMAX-2</span><br><span class="line">63) SIGRTMAX-1	64) SIGRTMAX</span><br><span class="line"></span><br><span class="line"><span class="comment">## output signal name or number</span></span><br><span class="line"><span class="built_in">kill</span> -l 9</span><br><span class="line"><span class="built_in">kill</span> -l usr1</span><br></pre></td></tr></table></figure></p>
<p>Kill process in command line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">kill</span> -9 &lt;pid&gt;</span><br><span class="line"><span class="built_in">kill</span> -s 9 &lt;pid&gt;</span><br><span class="line"><span class="built_in">kill</span> -SIGKILL &lt;pid&gt;</span><br></pre></td></tr></table></figure></p>
<p>Some commonly use signals:</p>
<ul>
<li><strong>SIGHUP</strong>: Hang up detected on controlling terminal or death of controlling process. Many daemons will <code>reload</code> their configuration files and reopen their logfiles instead of exiting when receiving this signal.</li>
<li><strong>SIGINT</strong>: Issued if the user sends an interrupt signal (Ctrl + C)</li>
<li><strong>SIGQUIT</strong>: Issued if the user sends a quit signal (Ctrl + D)</li>
<li><strong>SIGKILL</strong>: If a process gets this signal it must quit immediately and will not perform any clean-up operations, this one cannot be ignored or trapped! (这里提一下，force kill会导致程序，比如Python中finally clauses 和 exit handler 无法工作)</li>
<li><strong>SIGTERM</strong>: Software termination signal (sent by kill by default)</li>
<li><strong>SIGSTOP</strong>: Stop process</li>
<li><strong>SIGSTP</strong>: Stop typed at terminal</li>
<li><strong>SIGCONT</strong>: Continue if stopped</li>
</ul>
<p>About trap the signals in script, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Set a Trap for Signals for graceful shutdown</span></span><br><span class="line"><span class="built_in">declare</span> -a SIGNALS_TRAPPED=(INT HUP QUIT TERM STOP)</span><br><span class="line"><span class="function"><span class="title">shudown_hook</span></span>() &#123;</span><br><span class="line">  ...</span><br><span class="line">  (/opt/servers/stop.sh)</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"Shutdown and Cleanup Successful..."</span></span><br><span class="line">  <span class="built_in">exit</span> 0</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">trap</span> <span class="string">'shudown_hook'</span> <span class="string">"<span class="variable">$&#123;SIGNALS_TRAPPED[@]&#125;</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>The general format is <code>trap command signals</code>, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">trap</span> <span class="string">"rm -rf /tmp/peek.txt; exit 0"</span> 1 2</span><br></pre></td></tr></table></figure></p>
<p>To ignore signals, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">trap</span> <span class="string">""</span> 2 3 15</span><br></pre></td></tr></table></figure></p>
<p>If you ignore a signal, all subshells also ignore that signal. However, if you specify an action to be taken on the receipt of a signal, all subshells will still take the default action on receipt of that signal.</p>
<p>Reset the traps to default:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">trap</span> 2 3 15</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>signal</tag>
      </tags>
  </entry>
  <entry>
    <title>Symbolic Link Operations</title>
    <url>/2019/04/13/linux-soft-link/</url>
    <content><![CDATA[<blockquote>
<p>Must use <code>absolute path</code> to do softlink!</p>
</blockquote>
<p>A symbolic link, also known as a <strong>symlink</strong> or a <strong>soft link</strong>, is a special kind of file (entry) that points to the actual file or directory on a disk (like a shortcut in Windows).</p>
<p>Symbolic links are used all the time to link libraries and often used to link files and folders on mounted NFS (Network File System) shares.</p>
<p>Generally, the <code>ln</code> syntax is similar to the <code>cp</code> or <code>mv</code> syntax, e.g. <source> <destination>.</destination></p>
<p>But if the path to the <link name=""> is an directory, link will be created inside that directory.</p>
<h2 id="Create-Softlink"><a href="#Create-Softlink" class="headerlink" title="Create Softlink"></a>Create Softlink</h2><p>For example, create a symbolic link to a file and directory<br><code>-f</code>: remove existing destination file, otherwise if the link is exist, get error like this:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## you need to remove the link first</span></span><br><span class="line"><span class="comment">## but with -f, no need</span></span><br><span class="line">ln: failed to create symbolic link ‘xxxx’: File exists</span><br></pre></td></tr></table></figure></p>
<p><code>-n</code>: treat LINK_NAME as a normal file if it is a symbolic link to a directory</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## link a file</span></span><br><span class="line">ln -nfs &lt;path to file&gt; &lt;path to link&gt;</span><br><span class="line"><span class="comment">## link a directory</span></span><br><span class="line">ln -nfs &lt;path to dir&gt; &lt;path to link&gt;</span><br></pre></td></tr></table></figure>
<h2 id="Delete-Softlink"><a href="#Delete-Softlink" class="headerlink" title="Delete Softlink"></a>Delete Softlink</h2><p>There are 2 ways to undo or delete the soft link:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">unlink &lt;link name&gt;</span><br><span class="line">rm [-rf] &lt;link name&gt;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that, the <code>rm</code> command just removes the link. It will not delete the target directory.</p>
</blockquote>
<h2 id="Broken-Softlink"><a href="#Broken-Softlink" class="headerlink" title="Broken Softlink"></a>Broken Softlink</h2><p>Find broken symbolic link:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -xtype l</span><br></pre></td></tr></table></figure></p>
<p>If you want to delete in one go:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -xtype l -delete</span><br></pre></td></tr></table></figure></p>
<p>A bit of explanation:<br><code>-xtype l</code> tests for links that are broken (it is the opposite of <code>-type</code>)<br><code>-delete</code> deletes the files directly, no need for further bothering with <code>xargs</code> or <code>-exec</code></p>
<h2 id="Ownership-of-Softlink"><a href="#Ownership-of-Softlink" class="headerlink" title="Ownership of Softlink"></a>Ownership of Softlink</h2><p><a href="https://unix.stackexchange.com/questions/218557/how-to-change-ownership-from-symbolic-links" target="_blank" rel="noopener">How to change ownership from symbolic links?</a><br><a href="https://unix.stackexchange.com/questions/87200/change-permissions-for-a-symbolic-link" target="_blank" rel="noopener">Change permissions for a symbolic link</a></p>
<p>On most system, softlink ownership does not matter, usually the link permission is <code>777</code>, for example: <code>lrwxrwxrwx</code>, when using, the softlink target’s permission will be checked.</p>
<p>How to check the ownership or permission of softlink, <code>chown -h &lt;link&gt;</code>, if no <code>-h</code>, the chown will change the ownership of the link target. the same as <code>chmod</code>, etc.</p>
<h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources:"></a>Resources:</h2><p><a href="https://www.shellhacks.com/symlink-create-symbolic-link-linux/" target="_blank" rel="noopener">SymLink – HowTo: Create a Symbolic Link – Linux</a><br><a href="https://unix.stackexchange.com/questions/34248/how-can-i-find-broken-symlinks" target="_blank" rel="noopener">How can I find broken symlinks</a><br><a href="https://unix.stackexchange.com/questions/314974/how-to-delete-broken-symlinks-in-one-go" target="_blank" rel="noopener">How to delete broken symlinks in one go?</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>soft link</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Storage System</title>
    <url>/2020/12/25/linux-storage/</url>
    <content><![CDATA[<p>[x] terraform mount disk <code>/dev/sdb</code>, why this name?<br>[x] do experiment, using vagrant mount extra disk<br>[x] blkid, lsblk 使用场景<br>[x] fstab mount 设置</p>
<p>Vagrant demo please see <a href="https://github.com/chengdol/InfraTree/tree/master/vagrant-storage" target="_blank" rel="noopener">vagrant-storage</a>. This is for VirtualBox provider, at the time of writting this is a experimental <a href="https://www.vagrantup.com/docs/disks/usage" target="_blank" rel="noopener">feature</a>.</p>
<p>After launch the machine:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># up</span></span><br><span class="line">VAGRANT_EXPERIMENTAL=<span class="string">"disks"</span> vagrant up</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check block device, their name, type, size and mount point</span></span><br><span class="line">lsblk</span><br><span class="line">NAME                    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda                       8:0    0  40G  0 disk</span><br><span class="line">├─sda1                    8:1    0   1G  0 part /boot</span><br><span class="line">└─sda2                    8:2    0  31G  0 part</span><br><span class="line">  ├─centos_centos7-root 253:0    0  29G  0 lvm  /</span><br><span class="line">  └─centos_centos7-swap 253:1    0   2G  0 lvm  [SWAP]</span><br><span class="line">sdb                       8:16   0   2G  0 disk</span><br><span class="line">sdc                       8:32   0   2G  0 disk</span><br><span class="line"></span><br><span class="line"><span class="comment"># /dev/sda is not used up, let's add one more partition of 3GB</span></span><br><span class="line">fdisk /dev/sda</span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n</span><br><span class="line">Partition <span class="built_in">type</span>:</span><br><span class="line">   p   primary (2 primary, 0 extended, 2 free)</span><br><span class="line">   e   extended</span><br><span class="line">Select (default p):</span><br><span class="line">Using default response p</span><br><span class="line">Partition number (3,4, default 3):</span><br><span class="line">First sector (67108864-83886079, default 67108864):</span><br><span class="line">Using default value 67108864</span><br><span class="line">Last sector, +sectors or +size&#123;K,M,G&#125; (67108864-83886079, default 83886079): +3GB</span><br><span class="line">Partition 3 of <span class="built_in">type</span> Linux and of size 2.8 GiB is <span class="built_in">set</span></span><br><span class="line"></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): w</span><br><span class="line">The partition table has been altered!</span><br><span class="line"></span><br><span class="line">Calling ioctl() to re-read partition table.</span><br><span class="line"></span><br><span class="line">WARNING: Re-reading the partition table failed with error 16: Device or resource busy.</span><br><span class="line">The kernel still uses the old table. The new table will be used at</span><br><span class="line">the next reboot or after you run partprobe(8) or kpartx(8)</span><br><span class="line">Syncing disks.</span><br><span class="line"></span><br><span class="line"><span class="comment"># re-read partition for /dev/sda</span></span><br><span class="line">partprobe -s /dev/sda</span><br><span class="line"></span><br><span class="line"><span class="comment"># now see lsblk</span></span><br><span class="line">NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda                       8:0    0   40G  0 disk</span><br><span class="line">├─sda1                    8:1    0    1G  0 part /boot</span><br><span class="line">├─sda2                    8:2    0   31G  0 part</span><br><span class="line">│ ├─centos_centos7-root 253:0    0   29G  0 lvm  /</span><br><span class="line">│ └─centos_centos7-swap 253:1    0    2G  0 lvm  [SWAP]</span><br><span class="line">└─sda3                    8:3    0  2.8G  0 part</span><br><span class="line">sdb                       8:16   0    2G  0 disk</span><br><span class="line">sdc                       8:32   0    2G  0 disk</span><br><span class="line"></span><br><span class="line"><span class="comment"># format sda3</span></span><br><span class="line">mkfs -t ext4 /dev/sda3s</span><br><span class="line"></span><br><span class="line"><span class="comment"># see type</span></span><br><span class="line">blkid | grep sda3</span><br><span class="line">/dev/sda3: UUID=<span class="string">"7d4a365c-1639-41de-a7c7-ebe79ea2830c"</span> TYPE=<span class="string">"ext4"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># mount to /data3 folder</span></span><br><span class="line">mkdir /data3</span><br><span class="line">mount /dev/sda3 /data3</span><br><span class="line"><span class="comment"># check lsblk</span></span><br><span class="line"><span class="comment"># now see lsblk</span></span><br><span class="line">NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda                       8:0    0   40G  0 disk</span><br><span class="line">├─sda1                    8:1    0    1G  0 part /boot</span><br><span class="line">├─sda2                    8:2    0   31G  0 part</span><br><span class="line">│ ├─centos_centos7-root 253:0    0   29G  0 lvm  /</span><br><span class="line">│ └─centos_centos7-swap 253:1    0    2G  0 lvm  [SWAP]</span><br><span class="line">└─sda3                    8:3    0  2.8G  0 part /data3</span><br><span class="line">sdb                       8:16   0    2G  0 disk</span><br><span class="line">sdc                       8:32   0    2G  0 disk</span><br><span class="line"></span><br><span class="line"><span class="comment"># check space and inode usage</span></span><br><span class="line"><span class="built_in">cd</span> /data3</span><br><span class="line">df -k .</span><br><span class="line">df -i .</span><br></pre></td></tr></table></figure>
<p>If you copy a big file to /data3, its use% may not change because flush does not happen, run <code>sync</code> to flush file system buffer.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># format whole disk sdb without partition</span></span><br><span class="line"><span class="comment"># use btrfs and mount with compress</span></span><br><span class="line">mkfs -t btrfs /dev/sdb</span><br><span class="line"></span><br><span class="line">mkdir /datab</span><br><span class="line">mount /dev/sdb -o compress /datab</span><br><span class="line"></span><br><span class="line">mount | grep sdb</span><br><span class="line">/dev/sdb on /datab <span class="built_in">type</span> btrfs (rw,relatime,seclabel,compress=zlib,space_cache,subvolid=5,subvol=/)</span><br><span class="line"></span><br><span class="line"><span class="comment"># check lsblk</span></span><br><span class="line">NAME                    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda                       8:0    0   40G  0 disk</span><br><span class="line">├─sda1                    8:1    0    1G  0 part /boot</span><br><span class="line">├─sda2                    8:2    0   31G  0 part</span><br><span class="line">│ ├─centos_centos7-root 253:0    0   29G  0 lvm  /</span><br><span class="line">│ └─centos_centos7-swap 253:1    0    2G  0 lvm  [SWAP]</span><br><span class="line">└─sda3                    8:3    0  2.8G  0 part /data3</span><br><span class="line">sdb                       8:16   0    2G  0 disk /datab</span><br><span class="line">sdc                       8:32   0    2G  0 disk</span><br></pre></td></tr></table></figure>
<p>From Linkedin Learn <a href="https://www.linkedin.com/learning/linux-storage-systems?trk=course_title&amp;upsellOrderOrigin=default_guest_learning" target="_blank" rel="noopener">Linux: Storage Systems</a>.</p>
<p>首先需要理解加入一个新的disk到系统之后，发生了什么，以及需要做什么工作才能使用这个新加入的disk。可以参考一下<a href="https://www.techotopia.com/index.php/Adding_a_New_Disk_Drive_to_an_Ubuntu_Linux_System" target="_blank" rel="noopener">这篇文章</a>. 主要用到了<code>fdisk</code>(partition), <code>mkfs</code>(make filesystem), <code>mount or fstab</code>(make accessable)</p>
<p>新加入的disk 的device file 如何命名的, Name conventions of device file, see <a href="https://en.wikipedia.org/wiki/Device_file#Naming_conventions" target="_blank" rel="noopener">here</a>, 比如<code>/dev/sda</code>, <code>/dev/sdb</code>, etc.</p>
<p>总的来看，可以用这样的顺序去观察storage system:</p>
<ul>
<li>lsblk, blkid 查看block device的大致状态，fs, disk, part, mount point等</li>
<li>/etc/fstab 查看是否persistent 以及 mount option 是否合适</li>
<li>mount 查看一下defaults mount option 具体内容是什么</li>
<li>df -k/-i 查看mount point space使用情况</li>
<li>dd 测试I/O performance (或者结合iperf3如果是NFS 之类的分布式存储)</li>
</ul>
<h1 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h1><p><code>lsblk</code> and <code>blkid</code> are used to identify block storages (linux also has character device).<br>有一点要注意，使用<code>lsblk</code>的时候，比如:<br><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">NAME                    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda                       <span class="number">8</span>:<span class="number">0</span>    <span class="number">0</span>  <span class="number">32</span>G  <span class="number">0</span> disk</span><br><span class="line">├─sda1                    <span class="number">8</span>:<span class="number">1</span>    <span class="number">0</span>   <span class="number">1</span>G  <span class="number">0</span> part /boot</span><br><span class="line">└─sda2                    <span class="number">8</span>:<span class="number">2</span>    <span class="number">0</span>  <span class="number">31</span>G  <span class="number">0</span> part</span><br><span class="line">  ├─centos_centos7-root <span class="number">253</span>:<span class="number">0</span>    <span class="number">0</span>  <span class="number">29</span>G  <span class="number">0</span> lvm  /</span><br><span class="line">  └─centos_centos7-swap <span class="number">253</span>:<span class="number">1</span>    <span class="number">0</span>   <span class="number">2</span>G  <span class="number">0</span> lvm  [SWAP]</span><br></pre></td></tr></table></figure></p>
<p>区分<code>TYPE</code>的不同类型(也可以从缩进结构看出), <code>MOUNTPOINT</code>中有值得部分才会在<code>mount</code> command中显示。在<code>/etc/fstab</code>中也会看到对应的records.</p>
<p>Check storage partition:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># list partitions and see type of a disk</span></span><br><span class="line"><span class="comment"># type `p` to see part </span></span><br><span class="line"><span class="comment"># `n` to add new part</span></span><br><span class="line"><span class="comment"># `d` to delete part</span></span><br><span class="line"><span class="comment"># `w` to confirm</span></span><br><span class="line"><span class="comment"># `q` to quit</span></span><br><span class="line"><span class="comment"># /dev/sda is disk type</span></span><br><span class="line">fdisk /dev/sda</span><br><span class="line"></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">ls /dev/sda*</span><br></pre></td></tr></table></figure></p>
<h1 id="Formating"><a href="#Formating" class="headerlink" title="Formating"></a>Formating</h1><p>Formatting partition or disk is to make a filesystem on it.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># format as ext4 type to /dev/sdb1 partition</span></span><br><span class="line">mkfs -t ext4 /dev/sdb1</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"><span class="comment"># Mounting</span></span><br><span class="line">Mounting is associating a filesystem(a partition) with a directory, mornally we would mount an empty directory, otherwise the content will be hidden.</span><br><span class="line">```bash</span><br><span class="line">mount /dev/sdb1 /data</span><br><span class="line"></span><br><span class="line"><span class="comment"># non-disk filesystem, system will mount for you</span></span><br><span class="line"><span class="comment"># -t: type</span></span><br><span class="line">mount -t proc proc /proc</span><br><span class="line">mount -t sysfs sysfs /sys</span><br><span class="line">mount -t debugfs debugfs /sys/kernel/debug</span><br><span class="line"><span class="comment"># NFS</span></span><br><span class="line">mount server:dir /nfs-data</span><br></pre></td></tr></table></figure></p>
<p>[ ] Ordinary file can also be formatted and mounted.</p>
<p>The persistent mounts are in <code>/etc/fstab</code> file on boot, If you type <code>mount</code> command on shell, you will see several mount points, like above <code>proc</code>, <code>sysfs</code>, <code>debugfs</code>. These are not in <code>/etc/fstab</code>, <code>systemd</code> mounts them on boot automatically.</p>
<p>For the mount options specific to file system type, see <code>man</code> fstab and mount.</p>
<p>You can unmount by <code>umount</code> command, filesystem cannot be unmounted while in use: files are open, process has dir in it. Can check by <code>lsof</code> command.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">umount /data</span><br></pre></td></tr></table></figure></p>
<h1 id="Filesystem-Types"><a href="#Filesystem-Types" class="headerlink" title="Filesystem Types"></a>Filesystem Types</h1><p>Commonly used ones: <code>ext2/3/4</code>, <code>xfs</code>, <code>Btrfs</code>. they have different properties.</p>
<p>Note that sometime you cannot create file because of no space left on device, but when you check <code>df -k .</code>, it is not full, check <code>df -i .</code> may help, you may use up the inode capacity even if there are lots of space still.</p>
]]></content>
      <categories>
        <category>Storage</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>storage</tag>
      </tags>
  </entry>
  <entry>
    <title>Solve Conflicts in RPM installation</title>
    <url>/2019/03/02/linux-solve-rpm-conflicts/</url>
    <content><![CDATA[<h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>I want to offline install some rpms for an application, I put all dependencies for that application in a dedicated directory. The problem is it will cause conflicts with the old installed ones, I also want to <strong>keep old existing</strong> rpms because they may needed by other packages. For example, I offline install <code>bind-utils</code> use command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum --disablerepo=* install -y ./<span class="built_in">bind</span>-utils/*.rpm</span><br></pre></td></tr></table></figure></p>
<p>Error output:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">Error: Package: 1:openssl-1.0.2k-12.el7.x86_64 (@anaconda/7.5)</span><br><span class="line">           Requires: openssl-libs(x86-64) = 1:1.0.2k-12.el7</span><br><span class="line">           Removing: 1:openssl-libs-1.0.2k-12.el7.x86_64 (@anaconda/7.5)</span><br><span class="line">               openssl-libs(x86-64) = 1:1.0.2k-12.el7</span><br><span class="line">           Updated By: 1:openssl-libs-1.0.2k-16.el7.x86_64 (/openssl-libs-1.0.2k-16.el7.x86_64)</span><br><span class="line">               openssl-libs(x86-64) = 1:1.0.2k-16.el7</span><br><span class="line">...</span><br><span class="line">You could try using --skip-broken to work around the problem</span><br><span class="line">** Found 1 pre-existing rpmdb problem(s), <span class="string">'yum check'</span> output follows:</span><br><span class="line">mokutil-15-1.el7.x86_64 is a duplicate with mokutil-12-1.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<p>This error shows that <code>yum</code> try to update old rpm with new one but this breaks the dependency chain. Option <code>--skip-broken</code> won’t work here, it will skip the dependency-problem rpm which include exactly what I need:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># skipped</span><br><span class="line">bind-utils.x86_64 32:9.9.4-73.el7_6</span><br></pre></td></tr></table></figure></p>
<p>Then I try to use:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ivh ./<span class="built_in">bind</span>-utils/*.rpm</span><br></pre></td></tr></table></figure></p>
<p>still bad with conflicts:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">file /usr/lib64/openssl/engines/libcapi.so from install of openssl-libs-1:1.0.2k-16.el7.x86_64 conflicts with file from package openssl-libs-1:1.0.2k-12.el7.x86_64</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>After doing research I find some <code>rpm</code> options may help:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm &#123;-i|--install&#125; [install-options] PACKAGE_FILE ...</span><br><span class="line"></span><br><span class="line">       This installs a new package.</span><br><span class="line"></span><br><span class="line">       The general form of an rpm upgrade command is</span><br><span class="line"></span><br><span class="line">rpm &#123;-U|--upgrade&#125; [install-options] PACKAGE_FILE ...</span><br><span class="line"></span><br><span class="line">       This upgrades or installs the package currently installed to a newer version.  This is the same as  install,</span><br><span class="line">       except all other version(s) of the package are removed after the new package is installed.</span><br><span class="line"></span><br><span class="line">rpm &#123;-F|--freshen&#125; [install-options] PACKAGE_FILE ...</span><br><span class="line"></span><br><span class="line">       This will upgrade packages, but only ones for which an earlier version is installed.</span><br><span class="line">...</span><br><span class="line">--force</span><br><span class="line">              Same as using --replacepkgs, --replacefiles, and --oldpackage.</span><br><span class="line">--replacepkgs</span><br><span class="line">              Install the packages even if some of them are already installed on this system.</span><br><span class="line">--replacefiles</span><br><span class="line">              Install the packages even if they replace files from other, already installed, packages.</span><br><span class="line">--oldpackage</span><br><span class="line">              Allow an upgrade to replace a newer package with an older one.</span><br></pre></td></tr></table></figure></p>
<p>Let’s add <code>--force</code> flag and try again, this works and the old rpms are still there:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm --force -ivh ./<span class="built_in">bind</span>-utils/*.rpm</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qa | grep openssl-libs</span><br><span class="line">openssl-libs-1.0.2k-12.el7.x86_64</span><br><span class="line">openssl-libs-1.0.2k-16.el7.x86_64</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>Setup SSH Passwordless</title>
    <url>/2019/10/30/linux-ssh-passwordless-setup/</url>
    <content><![CDATA[<p>We need to setup ssh passwordless in softlayer cluster, otherwise our Datastage installer wouldn’t work. Now the master node in cluster uses <code>/ibm/unicorn_rsa</code> as the key to ssh, we can generate a new key and utilize it to communicate.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## "yes" will overwrite existing rsa key</span></span><br><span class="line"><span class="comment">## -t specify the type of key to create</span></span><br><span class="line"><span class="comment">## -N provides the new passphrase</span></span><br><span class="line"><span class="comment">## -f specifies the filename of the key file</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"yes"</span> | ssh-keygen -t rsa -N <span class="string">""</span> -f ~/.ssh/id_rsa</span><br><span class="line"></span><br><span class="line"><span class="comment">## then append the id_rsa.pub content to authorized_keys in each node</span></span><br><span class="line"><span class="built_in">declare</span> -a nodes=($(cat /etc/hosts | grep -i ibmcloud | awk &#123;<span class="string">'print $2'</span>&#125;))</span><br><span class="line">key=$(cat ~/.ssh/id_rsa.pub)</span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;nodes[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"[INFO] copy ssh public to <span class="variable">$&#123;node&#125;</span>"</span></span><br><span class="line">  ssh -i /ibm/unicorn_rsa -o StrictHostKeyChecking=no <span class="variable">$&#123;node&#125;</span> <span class="string">"echo <span class="variable">$&#123;key&#125;</span> &gt;&gt; ~/.ssh/authorized_keys"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>More information about ssh and scp can refer this <a href="https://chengdol.github.io/2019/02/21/linux-ssh-scp-summary/" target="_blank" rel="noopener">post</a>.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>Grant User sudo Privilege</title>
    <url>/2019/07/15/linux-sudo-privilege/</url>
    <content><![CDATA[<p>Let’s see how to grant a regular user <code>sudo</code> privilege, this is summaried from non-root upgrade.</p>
<p>Say, there is a regular user named <code>guest</code>, the simplest way is to edit sudoers file solely, run as root user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">visudo</span><br></pre></td></tr></table></figure></p>
<p>Append this line at end of file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">guest ALL=(ALL) NOPASSWD:ALL</span><br></pre></td></tr></table></figure></p>
<p>Then when <code>su - guest</code>, you can run <code>sudo</code> free.</p>
<p>Another way is add this user to <code>wheel</code> group then give this special group password-less <code>sudo</code> privilege, why does this? because sometimes I also need grant <code>su</code> password-less to the user, <code>wheel</code> group is easy for both to operate on. See my blog <a href="https://chengdol.github.io/2019/04/01/linux-pam/" target="_blank" rel="noopener"><code>&lt;&lt;Linux PAM Module Configuration&gt;&gt;</code></a></p>
<p>Run as root user, add <code>guest</code> to <code>wheel</code> group:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usermod -a -G wheel guest</span><br></pre></td></tr></table></figure></p>
<p>then edit sudoers file<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">visudo</span><br></pre></td></tr></table></figure></p>
<p>Comment and uncomment like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## Allows people in group wheel to run all commands</span><br><span class="line">#%wheel ALL=(ALL)       ALL</span><br><span class="line"></span><br><span class="line">## Same thing without a password</span><br><span class="line">%wheel  ALL=(ALL)       NOPASSWD: ALL</span><br></pre></td></tr></table></figure></p>
<p>That’s it.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>SSH SCP SFTP Daily Work Summary</title>
    <url>/2019/02/21/linux-ssh-scp-sftp-summary/</url>
    <content><![CDATA[<p>This blog used to walk through some <code>ssh</code>(secure shell), <code>scp</code> and <code>sftp</code> use cases.</p>
<p><strong>Aside:</strong><br><a href="https://security.stackexchange.com/questions/29876/what-are-the-differences-between-ssh-generated-keysssh-keygen-and-openssl-keys" target="_blank" rel="noopener">difference between OpenSSH vs OpenSSL</a><br>The file format is different but they both encode the same kind of keys. Moreover, they are both generated with the same code.</p>
<h1 id="Install-SSH-SCP-SFTP"><a href="#Install-SSH-SCP-SFTP" class="headerlink" title="Install SSH (SCP SFTP)"></a>Install SSH (SCP SFTP)</h1><p>Notice that <code>ssh</code>, <code>scp</code> and <code>sftp</code> are all installed from <code>openssh-clients</code> package. 操作的目标机器的用户以及密码就是目标机器上在<code>/etc/passwd</code>中对应的用户及其密码。</p>
<p>First, understand that there are openssh client and openssh server: <a href="https://phoenixnap.com/kb/how-to-enable-ssh-centos-7" target="_blank" rel="noopener">Installing and Enabling OpenSSH on CentOS 7</a>, this article briefly introduce openssh configuration and firewall setting for it.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum –y install openssh-server openssh-clients</span><br></pre></td></tr></table></figure>
<p>If only install <code>openssh-clients</code>, you can ssh to others but others cannot ssh to you, since you don’t have ssh server listening at port 22.</p>
<p>After installing openssh-server, enable and start the sshd daemon<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> sshd</span><br><span class="line">systemctl start sshd</span><br><span class="line"><span class="comment">## check status</span></span><br><span class="line">systemctl status sshd</span><br></pre></td></tr></table></figure></p>
<p>The system OpenSSH server configuration file is <code>/etc/ssh/sshd_config</code>, the custom configuration file is <code>~/.ssh/config</code>. The <code>/etc/ssh/ssh_config</code> is for system-wide client behavior.</p>
<p>Restricted configuration you may need on server side:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Port 22</span><br><span class="line">PermitRootLogin prohibit-password</span><br><span class="line">PubkeyAuthentication yes</span><br><span class="line"><span class="comment">## after copy the public key in</span></span><br><span class="line">PasswordAuthentication no</span><br></pre></td></tr></table></figure></p>
<p>After making changes, restart sshd daemon.</p>
<p>Firewall setting for ssh is file <code>/etc/sysconfig/iptables</code>.</p>
<h1 id="SSH-Tunnel"><a href="#SSH-Tunnel" class="headerlink" title="SSH Tunnel"></a>SSH Tunnel</h1><p>Forward a local port to remote port, one on one mapping.<br>用在比如database or web servers 没有对外开放端口，我们可以通过SSH穿过防火墙(SSH的端口是开放的)去远程映射它们的端口到本地，然后通过localhost访问。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -L: port forward</span></span><br><span class="line"><span class="comment">## 3232: local port</span></span><br><span class="line"><span class="comment">## 80: remote port</span></span><br><span class="line">ssh -L 3232:remotehost:80 user@remotehost</span><br><span class="line"><span class="comment">## then you get login to remotehost, also the mapping is established</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## -N: Do not execute a remote command.  This is useful for just forwarding ports.</span></span><br><span class="line"><span class="comment">## the 80 port is blocked by firewall remotely, but after mapping, we can see it locally</span></span><br><span class="line">ssh -L 1234:remotehost:80 user@remotehost -N</span><br></pre></td></tr></table></figure>
<p>Then go to <code>localhost:1234</code> on browser to see the web page.</p>
<h1 id="SSH-SOCKS-Proxy-Tunnel"><a href="#SSH-SOCKS-Proxy-Tunnel" class="headerlink" title="SSH SOCKS Proxy Tunnel"></a>SSH SOCKS Proxy Tunnel</h1><p>Aside: <a href="http://www.firewall.cx/vpn/vpn-guides-articles/1191-best-socks5-proxy-guide-torrenting-free-proxy-list.html" target="_blank" rel="noopener">Introduction to SOCKS proxy</a></p>
<p>The transport protocol and by itself it is not encrypted.<br>类似于VPN的部分功能，但是通过SSH实现, allow web access from restricted network.<br><a href="https://www.pandasecurity.com/mediacenter/technology/difference-vpn-vs-proxy" target="_blank" rel="noopener">What is the difference between a VPN and a proxy</a></p>
<p><a href="https://www.digitalocean.com/community/tutorials/how-to-route-web-traffic-securely-without-a-vpn-using-a-socks-tunnel" target="_blank" rel="noopener">How To Route Web Traffic Securely Without a VPN Using a SOCKS Tunnel</a>:<br>A SOCKS proxy is basically an SSH tunnel in which specific applications forward their traffic down the tunnel to the server, and then on the server end, the proxy forwards the traffic out to the general Internet. Unlike a VPN, a SOCKS proxy has to be configured on an app by app basis on the client machine, but can be set up without any specialty client agents.</p>
<p>The remote host must has ssh server running.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -D: dynamic application-level port forwarding</span></span><br><span class="line"><span class="comment">## -C: Compresses the data before sending it</span></span><br><span class="line"><span class="comment">## -q: quiet</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## -f: Forks the process in the background</span></span><br><span class="line"><span class="comment">## don't like tunnel, on the remote host it is dynamic forwarding</span></span><br><span class="line">ssh -D 1234 -f -C -N -q user@remotehost</span><br></pre></td></tr></table></figure></p>
<p>Then configure the web browser to use this socket proxy: <code>localhost:1234</code>, in firefox, check <code>Proxy DNS when using SOCKS v5</code>. 其实就类似于一个forward proxy了。<br>可以对比使用前后<code>ip4.me</code>，不一样了。</p>
<p>Manually kill the tunnel process if you use <code>-f</code>.</p>
<p>当时用SSH SOCKS tunnel 解决了内网中Vault 的访问问题，本地机器建立tunnel to Jenkins slave, which forward the request to Vault server.</p>
<h1 id="SSH-X11-Forwarding"><a href="#SSH-X11-Forwarding" class="headerlink" title="SSH X11 Forwarding"></a>SSH X11 Forwarding</h1><p>Similar to VNC, but VNC transmits whole desktop which is more expensive.<br>Linux has good support to X11, on Mac, need to install XQuartz(still not work on Mac).<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -X: X11 forwarding</span></span><br><span class="line">ssh -X user@remotehost</span><br><span class="line"></span><br><span class="line"><span class="comment">## gedit is running on remotehost but reflect GUI locally</span></span><br><span class="line">&gt; gedit</span><br></pre></td></tr></table></figure></p>
<h1 id="SSH-Agent"><a href="#SSH-Agent" class="headerlink" title="SSH Agent"></a>SSH Agent</h1><p>很久之前看书的时候没明白这个概念. 一个常见的用处就是保护originating host的private key.<br>A handy program called <code>ssh-agent</code> simplifies working with SSH private keys.</p>
<p>In Mac, ssh-agent is running by default, but in Linux, start by yourself (ensure only one instance of ssh-agent is running)<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## don't need do this if you are Mac, or your company laptop has agent running by default</span></span><br><span class="line"><span class="comment">## you can check by:</span></span><br><span class="line">ssh-add -l</span><br><span class="line"></span><br><span class="line"><span class="comment">## first check if only one instance is running</span></span><br><span class="line">ps aux | grep ssh-agent$</span><br><span class="line"><span class="comment">## if it is there but cannot work, kill it.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">eval</span> $(ssh-agent)</span><br></pre></td></tr></table></figure></p>
<p>If you run <code>ssh-agent</code>, it will output environment vars you need to set, for example, you can also manually export these instead of using <code>eval</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-agent</span><br><span class="line"></span><br><span class="line"><span class="comment">## export these manually is OK</span></span><br><span class="line">SSH_AUTH_SOCK=/tmp/ssh-YI7PBGlkOteo/agent.2547; <span class="built_in">export</span> SSH_AUTH_SOCK;</span><br><span class="line">SSH_AGENT_PID=2548; <span class="built_in">export</span> SSH_AGENT_PID;</span><br><span class="line"><span class="built_in">echo</span> Agent pid 2548;</span><br></pre></td></tr></table></figure></p>
<p>Add your private key to ssh-agent, sometimes git ssh clone failed, you may need to add private key to agent:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## default path ~/.ssh/id-rsa</span></span><br><span class="line">ssh-add</span><br><span class="line">ssh-add &lt;other private key path&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## list all identities </span></span><br><span class="line">ssh-add -l</span><br><span class="line"></span><br><span class="line"><span class="comment">## delete all identities</span></span><br><span class="line">ssh-add -D</span><br><span class="line"><span class="comment">## delete specified identity</span></span><br><span class="line">ssh-add -d &lt;private key path&gt;</span><br></pre></td></tr></table></figure></p>
<p>How to start ssh-agent on login:<br><a href="https://stackoverflow.com/questions/18880024/start-ssh-agent-on-login" target="_blank" rel="noopener">https://stackoverflow.com/questions/18880024/start-ssh-agent-on-login</a><br>Add below to your <code>.bash_profile</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SSH_ENV=<span class="string">"<span class="variable">$HOME</span>/.ssh/env"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> start_agent &#123;</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"Initialising new SSH agent..."</span></span><br><span class="line">    /usr/bin/ssh-agent | sed <span class="string">'s/^echo/#echo/'</span> &gt; <span class="string">"<span class="variable">$&#123;SSH_ENV&#125;</span>"</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">'succeeded'</span></span><br><span class="line">    chmod 600 <span class="string">"<span class="variable">$&#123;SSH_ENV&#125;</span>"</span></span><br><span class="line">    . <span class="string">"<span class="variable">$&#123;SSH_ENV&#125;</span>"</span> &gt; /dev/null</span><br><span class="line">    <span class="comment">## add private key ~/.ssh/id_rsa.pub</span></span><br><span class="line">    /usr/bin/ssh-add;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## Source SSH settings, if applicable</span></span><br><span class="line"><span class="keyword">if</span> [ -f <span class="string">"<span class="variable">$&#123;SSH_ENV&#125;</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="comment">## need resource, but ssh-agent is there</span></span><br><span class="line">    . <span class="string">"<span class="variable">$&#123;SSH_ENV&#125;</span>"</span> &gt; /dev/null</span><br><span class="line">    <span class="comment">## ps $&#123;SSH_AGENT_PID&#125; doesn't work under cywgin</span></span><br><span class="line">    ps -ef | grep <span class="variable">$&#123;SSH_AGENT_PID&#125;</span> | grep ssh-agent$ &gt; /dev/null || &#123;</span><br><span class="line">        <span class="comment">## statement block</span></span><br><span class="line">        start_agent;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    start_agent;</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<p>When you try to make a connection to a remote host, and you have ssh-agent running, the SSH client will automatically use the keys stored in ssh-agent to authenticate with the host.</p>
<p>Advantages:</p>
<ol>
<li><p>For encrypted SSH private keys，只有第一次加入ssh-agent的时候要求输入password。如果不使用ssh-agent，每次SSH都会要求输入password</p>
</li>
<li><p>If you are using Ansible to manage hosts that use different SSH keys, using an SSH agent simplifies your Ansible configuration files.</p>
</li>
<li><p>ssh-agent forwarding, see below</p>
</li>
</ol>
<p>ssh-agent 还解决了一个问题，比如你有personal and work git account各一个，但各自是不同的ssh key pairs，在git clone的时候如何指定用哪个private key呢? see this <a href="https://stackoverflow.com/questions/4565700/how-to-specify-the-private-ssh-key-to-use-when-executing-shell-command-on-git" target="_blank" rel="noopener">link</a>.</p>
<h1 id="SSh-Agent-Forwarding"><a href="#SSh-Agent-Forwarding" class="headerlink" title="SSh Agent Forwarding"></a>SSh Agent Forwarding</h1><p>If you are cloning a Git repository over SSH, you’ll need to use an SSH private key recognized by your Git server. I like to avoid copying private SSH keys to my remote host (for example, a EC2 instance), in order to limit the damage in case a host ever gets compromised.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## example.xx.com does not have the private key to access git repo</span></span><br><span class="line"><span class="comment">## but the local host who issue ssh has</span></span><br><span class="line">ssh -A root@example.xxx.com</span><br><span class="line"><span class="comment">## git clone via ssh</span></span><br><span class="line">git <span class="built_in">clone</span> git@github.com:lorin/mezzanine-example.git</span><br></pre></td></tr></table></figure></p>
<p>Here <code>-A</code> limit the agent forwarding in this session only, you can have ssh config to set agent forwarding on a broad view.</p>
<h1 id="ProxyJump"><a href="#ProxyJump" class="headerlink" title="ProxyJump"></a>ProxyJump</h1><p>现在想想，当时登录openshift or softlayer 的master时，也需要经过跳板机，所以应该可以配置proxyjump.<br>这个和ssh-agent没有必然联系，如果没用ssh-agent, 则应该可以在配置config file中指定key的位置.</p>
<p><a href="https://www.youtube.com/watch?v=QKZP9FbP3mo" target="_blank" rel="noopener">Using OpenSSH ProxyJump</a><br>It uses vagrant VMs to demonstrate. 但是我觉得不需要再指定port, user, identifykey对target server了，这些应该在bastion上已经配置好了。</p>
<p><a href="https://smallstep.com/blog/ssh-agent-explained/" target="_blank" rel="noopener">SSH agent and ProxyJump explained</a><br>Talking risk of SSH agent forwarding, access internal hosts through a bastion, ProxyJump is much safer.<br>也谈到了SSH是怎么handshake, 传输中用的是新的对称钥匙.</p>
<p><strong>JumpBox or Bastion Host:</strong><br>Baston hosts are usually public-facing, hardened systems that serve as an entrypoint to systems behind a firewall or other restricted location, and they are especially popular with the rise of cloud computing.</p>
<p>Notice that you need to generate key and copy the public key to bastion host first.<br><a href="https://linuxize.com/post/using-the-ssh-config-file/" target="_blank" rel="noopener">Using the SSH Config File</a><br><a href="https://www.redhat.com/sysadmin/ssh-proxy-bastion-proxyjump" target="_blank" rel="noopener">SSH to remote hosts though a proxy or bastion with ProxyJump</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -J specify the jumphost</span></span><br><span class="line">ssh -J &lt;bastion-host&gt; &lt;remote-host&gt; -l &lt;remote login user&gt; -i &lt;pem file&gt;</span><br><span class="line">ssh -J user@&lt;bastion:port&gt; &lt;user@remote:port&gt;</span><br><span class="line">ssh -J &lt;bastion1&gt;,&lt;bastion2&gt; &lt;remote&gt;</span><br></pre></td></tr></table></figure></p>
<p>最主要的还是配置<code>~/.ssh/config</code> 文件, basic settings:<br>注意，之前遇到过奇怪的问题，用同样的config file，别人一切正常，但我就连不上，简化了一下config file后就好了，当时的解决办法是把Match host模块移到匹配的Host 下面，其实Match host不要也行，很多可以合并的。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## May have more options, for example, User, Port, AgentForward, etc.</span></span><br><span class="line"><span class="comment">## refer `man ssh_config`</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## The `Host` sections are read in order and the options matched will get accumulated</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## The Bastion Host</span></span><br><span class="line">Host &lt;jump-host-nickname&gt;</span><br><span class="line">  User &lt;user name&gt;</span><br><span class="line">  <span class="comment">## default is no</span></span><br><span class="line">  ProxyUseFdpass no</span><br><span class="line">  <span class="comment">## jumpbox port</span></span><br><span class="line">  Port 22</span><br><span class="line">  <span class="comment">## jumpbox IP</span></span><br><span class="line">  HostName &lt;hostname or IP&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## The Remote Host</span></span><br><span class="line">Host &lt;remote-host-nickname&gt;</span><br><span class="line">  Hostname &lt;remote-hostname or ip address <span class="keyword">for</span> example: 172.12.234.12&gt;</span><br><span class="line">  User &lt;user name&gt;</span><br><span class="line">  AddKeysToAgent yes</span><br><span class="line">  IdentitiesOnly yes</span><br><span class="line">  <span class="comment">## may need pem file, the private key</span></span><br><span class="line">  IdentityFile ~/.ssh/file.pem</span><br><span class="line">  StrictHostKeyChecking no</span><br><span class="line">  ServerAliveInterval 60</span><br><span class="line"></span><br><span class="line"><span class="comment">## the remote host match this IP will use jumpbox</span></span><br><span class="line"><span class="comment">## 这个可以不要，就是用来match Host的</span></span><br><span class="line">Match host 172.??.*</span><br><span class="line">  ProxyJump &lt;jump-host-nickname&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## or can specify jumpbox directly</span></span><br><span class="line">Host &lt;remote-host-nickname&gt;</span><br><span class="line">  HostName &lt; remote-hostname or ip address&gt;</span><br><span class="line">  ProxyJump bastion-host-nickname</span><br></pre></td></tr></table></figure></p>
<p>Then you can ssh directly: <code>ssh remote-host-nickname</code></p>
<p><code>ProxyCommand</code> is an alternative of ProxyJump, but it is old.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -o ProxyCommand=<span class="string">"ssh -W %h:%p bastion-host"</span> remote-host</span><br></pre></td></tr></table></figure></p>
<h1 id="Debug"><a href="#Debug" class="headerlink" title="Debug"></a>Debug</h1><ol>
<li>Use <code>-v</code>, <code>-vv</code>, <code>-vvv</code> flag in ssh command (比如之前pem file 权限和格式没设置对，都有提示)</li>
<li>Wireshark capture ssh traffic on that interface, you should see <code>SSHv2</code> protocol and more details</li>
<li>Check system log, <code>journalctl | grep sshd</code>.</li>
<li>Launch sshd on another port in debug mode: <code>sudo /usr/bin/sshd -d -p 2020</code>, then ssh to this port <code>2020</code> from client <code>ssh -p 2020 user@remote_server</code>.</li>
<li>May restriced by firewall</li>
</ol>
<h1 id="Usage-Summary"><a href="#Usage-Summary" class="headerlink" title="Usage Summary"></a>Usage Summary</h1><p>################################################################<br># &emsp; Insert latest update at the top of the logs<br>#<br># &emsp; Date &emsp; &emsp; &emsp; &emsp; &emsp; Description<br># &emsp; 10/01/2018 &emsp; &emsp; ssh send command<br># &emsp; 11/14/2018 &emsp; &emsp; ssh run shell script<br># &emsp; 12/19/2018 &emsp; &emsp; ssh-copy-id<br># &emsp; 01/06/2019 &emsp; &emsp; ssh-kenscan<br># &emsp; 01/08/2019 &emsp; &emsp; ECDSA host key changed<br># &emsp; 01/22/2019 &emsp; &emsp; no prompt first time<br># &emsp; 01/23/2019 &emsp; &emsp; sshpass<br># &emsp; 02/21/2019 &emsp; &emsp; scp folder or files<br># &emsp; 03/11/2019 &emsp; &emsp; ssh -i option<br># &emsp; 03/12/2019 &emsp; &emsp; recover public key<br># &emsp; 09/05/2020 &emsp; &emsp; sftp<br>#<br>################################################################</p>
<h2 id="10-01-2018"><a href="#10-01-2018" class="headerlink" title="10/01/2018"></a>10/01/2018</h2><p>use <code>ssh</code> send commands to execute on remote machine:<br><img src="https://drive.google.com/uc?id=1OgNJ5NJpx6Kkr46oCxScylGhu1ShYaCV" alt=""><br><code>-t</code> flag allow you to interact with remote machine:<br><img src="https://drive.google.com/uc?id=1rgH7Eu7Qzw2icZQzroTT1_J7LH0G3EBP" alt=""></p>
<h2 id="11-14-2018"><a href="#11-14-2018" class="headerlink" title="11/14/2018"></a>11/14/2018</h2><p>use ssh run shell script in remote machine<br><img src="https://drive.google.com/uc?id=1FvvQTq-ujz1ETmharmWt9JsMBC1ipuUJ" alt=""></p>
<h2 id="12-19-2018"><a href="#12-19-2018" class="headerlink" title="12/19/2018"></a>12/19/2018</h2><p>use <code>ssh-copy-id</code> to copy local machine public key to remote machine’s <code>~/.ssh/authorized_keys</code> file, so next time when you <code>ssh</code>, <code>scp</code> or <code>sftp</code> again, no prompt to require password:</p>
<p><img src="https://drive.google.com/uc?id=1HdAmGdDB1HxPtwFSzrTQcS-g7hw5r3o4" alt=""></p>
<p>Sometimes I see people use <code>~/.ssh/id_rsa</code> with <code>ssh-copy-id</code>, that confused me because that is private key, OK, <code>man</code> tell me why:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-i identity_file</span><br><span class="line">        ...If the filename does not end in .pub this is added.  If the filename is omitted, the default_ID_file is used.</span><br></pre></td></tr></table></figure></p>
<h2 id="01-06-2019"><a href="#01-06-2019" class="headerlink" title="01/06/2019"></a>01/06/2019</h2><p>use <code>ssh-keyscan</code> to get remote machine ecdsa identity, you can put this item into local known_hosts file, so when first time <code>ssh</code> login, there is no prompt to input <code>yes</code>:<br><img src="https://drive.google.com/uc?id=1C_IHZxToXYRN4iLabvmcW21x_5wbGcQp" alt=""><br>actually better to use <code>-o StrictHostKeyChecking=no</code> flag.</p>
<h2 id="01-08-2019"><a href="#01-08-2019" class="headerlink" title="01/08/2019"></a>01/08/2019</h2><p>I create a new cluster with the same master hostname as the deleted one, so when I try to ssh to it, interesting thing happens:<br><img src="https://drive.google.com/uc?id=1Fkc0M9_e0hufGmI2Es_qvFOBRaHLwPKd" alt=""><br>go to <code>~/.ssh/known_hosts</code> file and delete the corresponding <code>ECDSA</code> line<br><img src="https://drive.google.com/uc?id=159d02J98eKyz2jJMUpTgJ6kCuZtqVe10" alt=""></p>
<h2 id="01-22-2019"><a href="#01-22-2019" class="headerlink" title="01/22/2019"></a>01/22/2019</h2><p>when you first time ssh or scp, sftp to remote machine, it will prompt to add remote machine to <code>~/.ssh/known_hosts</code> file, this may interrupt <code>ansible</code> or shell script running, so I want to skip it. For example:<br><img src="https://drive.google.com/uc?id=1WfbdXCFeyg5k7tr9wS5JjMRIifJcdPaq" alt=""><br>use <code>-o StrictHostKeyChecking=no</code> option, it will silently add remote host name to <code>~/.ssh/known_host</code> file.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-copy-id -i .ssh/id_dsa.pub -o StrictHostKeyChecking=no root@example.com</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -o StrictHostKeyChecking=no -r ./<span class="built_in">source</span> root@example.com:~</span><br></pre></td></tr></table></figure>
<p>if you don’t want to add the host name, <code>-o UserKnownHostsFile=/dev/null</code> option can save you.</p>
<h2 id="01-23-2019"><a href="#01-23-2019" class="headerlink" title="01/23/2019"></a>01/23/2019</h2><p>scp or ssh without prompt input password<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y sshpass</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sshpass -p &lt;password&gt; scp/ssh ...</span><br></pre></td></tr></table></figure>
<p>It’s useful to set password-less at first time, combine all of these, no prompt will show up:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sshpass -p &lt;password&gt; ssh-copy-id -i ~/.ssh/id_rsa.pub -o StrictHostKeyChecking=no ...</span><br></pre></td></tr></table></figure></p>
<h2 id="02-21-2019"><a href="#02-21-2019" class="headerlink" title="02/21/2019"></a>02/21/2019</h2><p>scp <code>source</code> directory and it’s content recursively to <code>root</code> user home directory in <code>example.com</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -o StrictHostKeyChecking=no -r ~/<span class="built_in">source</span> root@example.com:~</span><br></pre></td></tr></table></figure></p>
<p>scp all files in <code>source</code> directory to <code>target</code> directory in <code>example.com</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -o StrictHostKeyChecking=no ./<span class="built_in">source</span>/* root@example.com:~/target</span><br></pre></td></tr></table></figure></p>
<h2 id="03-11-2019"><a href="#03-11-2019" class="headerlink" title="03/11/2019"></a>03/11/2019</h2><p>The <code>ssh</code> command has <code>-i</code> option, you associate private key with this flags:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -i ~/.ssh/id_rsa xxx</span><br></pre></td></tr></table></figure></p>
<p>Note that SSH never send private key over the network, <code>-i</code> merely used to answer challenge that is generated using the corresponding public key from target machine, you don’t need to explicitly use <code>-i</code> if you use default private key in right location.</p>
<h2 id="03-12-2019"><a href="#03-12-2019" class="headerlink" title="03/12/2019"></a>03/12/2019</h2><p>If public key is lost, you can use existing private key to generate one:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keygen -y -f ~/.ssh/id_rsa &gt; ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure></p>
<p>Or just create new key pair<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"yes"</span> | ssh-keygen -t rsa -N <span class="string">""</span> -f ~/.ssh/id_rsa</span><br></pre></td></tr></table></figure></p>
<h2 id="09-05-2020"><a href="#09-05-2020" class="headerlink" title="09/05/2020"></a>09/05/2020</h2><p><code>sftp</code> server is up when install <code>openssh-server</code> package, and can be configured in <code>/etc/ssh/sshd_config</code> file:<br><a href="https://www.techrepublic.com/article/how-to-set-up-an-sftp-server-on-linux/" target="_blank" rel="noopener">https://www.techrepublic.com/article/how-to-set-up-an-sftp-server-on-linux/</a></p>
<p>For the interactive commands, see <code>man sftp</code>, there are logs of regular commands can be used in sftp, for example: cd, chmod, ln, rm, etc.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Use password or ssh-public key to login to sftp server</span></span><br><span class="line">sftp -o StrictHostKeyChecking=no user@hostname[:path]</span><br><span class="line"></span><br><span class="line"><span class="comment">## print local working directory, the default place to hold download file</span></span><br><span class="line">sftp&gt; lpwd</span><br><span class="line"><span class="comment">## change local working directory</span></span><br><span class="line">sftp&gt; lcd [path]</span><br><span class="line"><span class="comment">## escape to local shell, type `exit` to back</span></span><br><span class="line">sftp&gt; !</span><br><span class="line"><span class="comment">## secape to local command</span></span><br><span class="line">sftp&gt; ![<span class="built_in">command</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## enable/disable progress meter</span></span><br><span class="line">sftp&gt; progress</span><br><span class="line"><span class="comment">## download file to local working directory</span></span><br><span class="line">sftp&gt; get &lt;filename&gt;</span><br><span class="line"><span class="comment">## download file to specified directory</span></span><br><span class="line">sftp&gt; get &lt;filename&gt; &lt;<span class="built_in">local</span> file path&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## upload file</span></span><br><span class="line"><span class="comment">## default file is in local working directory and upload to sftp current folder</span></span><br><span class="line"><span class="comment">## if no path is specified</span></span><br><span class="line">sftp&gt; put [<span class="built_in">local</span> file path] [remote file path]</span><br><span class="line"></span><br><span class="line"><span class="comment">## quit sftp</span></span><br><span class="line">sftp&gt; <span class="built_in">bye</span></span><br></pre></td></tr></table></figure></p>
<p>For non-interactive download/upload file:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## download</span></span><br><span class="line">sftp user@hostname[:path] &lt;<span class="built_in">local</span> file path&gt;</span><br><span class="line"><span class="comment">## upload, tricky</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"put &lt;local file path&gt;"</span> | sftp user@hostname[:path]</span><br><span class="line">sftp user@hostname[:path] &lt;&lt;&lt; $<span class="string">'put &lt;local file path&gt;'</span></span><br></pre></td></tr></table></figure></p>
<p>Used in shell script:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sftp user@hostname &lt;&lt;EOF</span><br><span class="line">lcd /xxx/yyy/zzz</span><br><span class="line"><span class="built_in">cd</span> /aaa/bbb/ccc</span><br><span class="line">put file.tgz</span><br><span class="line"><span class="built_in">bye</span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
        <tag>scp</tag>
        <tag>sftp</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux System Admin</title>
    <url>/2020/12/25/linux-system-admin/</url>
    <content><![CDATA[<p>这个课程的收获就是boot stages, kernel的升级以及linux logging的种类，使用。特别是journald，来自systemd。我从其他文章中补充了一些内容，包括loginctl.</p>
<h1 id="Boot"><a href="#Boot" class="headerlink" title="Boot"></a>Boot</h1><p>Linux booting process:</p>
<ul>
<li>firmware stage (BIOS or UEFI)</li>
<li>boot loader stage (grub2)</li>
<li>kernel stage (ramdisk -&gt; root filesystem)</li>
<li>initialization stage (systemd)</li>
</ul>
<p><code>/boot</code> directory is about kernel.<br>grub configuration file:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># providing boot menu and exxcuting kernel</span></span><br><span class="line">sudo less -N /boot/grub2/grub.cfg</span><br></pre></td></tr></table></figure></p>
<p>讲了一下如何定制grub 的kernel 菜单选项 to add custom boot entry，grub 的菜单会在开机时的图形界面显示。可以在开机时更改kernel line加入systemd rescue or emergency target, refer here:</p>
<ul>
<li><a href="https://www.thegeekdiary.com/centos-rhel-7-how-to-boot-into-rescue-mode-or-emergency-mode/" target="_blank" rel="noopener">CentOs boot into rescur or emernency mode</a></li>
<li><a href="https://ostechnix.com/how-to-boot-into-rescue-mode-or-emergency-mode-in-ubuntu-18-04/" target="_blank" rel="noopener">Ubuntu boot into rescur or emernency mode</a></li>
</ul>
<h1 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h1><p>Update kernel version:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># uname -r</span></span><br><span class="line">sudo yum list installed kernel-*</span><br><span class="line"><span class="comment"># see new kernel available</span></span><br><span class="line">sudo yum list available kernel</span><br><span class="line"></span><br><span class="line"><span class="comment"># update</span></span><br><span class="line">sudo yum update -y kernel</span><br><span class="line"><span class="comment"># then reboot and check kernel version</span></span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure></p>
<p>Boot to old kernel version<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check kernel index list, index starts from 0</span></span><br><span class="line">sudo awk -F\<span class="string">' '</span><span class="variable">$1</span>==<span class="string">"menuentry "</span> &#123;<span class="built_in">print</span> <span class="variable">$2</span>&#125;<span class="string">' /etc/grub2.cfg</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">CentOS Linux 7 Rescue d722048b30f64edcbc49c3f935bcd36e (3.10.0-1160.11.1.el7.x86_64)</span></span><br><span class="line"><span class="string">CentOS Linux (3.10.0-1160.11.1.el7.x86_64) 7 (Core)</span></span><br><span class="line"><span class="string">CentOS Linux (3.10.0-1127.10.1.el7.x86_64) 7 (Core)</span></span><br><span class="line"><span class="string">CentOS Linux (0-rescue-02cb98fcb3934f7aba01583a19853647) 7 (Core</span></span><br></pre></td></tr></table></figure></p>
<p>Switch to <code>3.10.0-1127.10.1</code> version:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># set kernel index 2</span></span><br><span class="line">sudo grub2-set-default 2</span><br><span class="line"><span class="comment"># reconfig boot loader code</span></span><br><span class="line">sudo grub2-mkconfig -o /boot/grub2/grub.cfg</span><br><span class="line">sudo reboot</span><br><span class="line"><span class="comment"># uname -r</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Linux-Logging"><a href="#Linux-Logging" class="headerlink" title="Linux Logging"></a>Linux Logging</h1><p>Linux 2 logging systems，这2个logging systems can run parallelly, or you can use journal alone.</p>
<ul>
<li>rsyslog (persistent logs, can log remotely)</li>
<li>journald (nonpersistent default)</li>
</ul>
<p>Differet logs for differnet purpose, some for failed jobs, some for cron jobs, etc.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl status rsyslog</span><br></pre></td></tr></table></figure></p>
<p><code>/etc/rsyslog.conf</code> is the configuration file, see section in <code>#### RULES ####</code>. For example, anything beyond mail, authpriv and cron is logged in <code>/var/log/messages</code>.</p>
<p>Log rotate config is in <code>/etc/logrotate.conf</code>, and there is a cron job for rotate <code>/etc/cron.daily/logrotate</code>.</p>
<p>If you want to log message to system log file, use <code>logger</code> command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># you will see it in /var/log/messages</span></span><br><span class="line">logger <span class="string">"hello"</span></span><br></pre></td></tr></table></figure></p>
<p><code>journalctl</code> have the same logs as in <code>rsyslogd</code>, from <a href="https://serverfault.com/questions/959982/is-rsyslog-redundant-on-when-using-journald" target="_blank" rel="noopener">here</a>, persistent journal can replace rsyslogd.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># persist journald</span></span><br><span class="line">sudo mkdir -p /var/<span class="built_in">log</span>/journal</span><br><span class="line">sudo systemctl restart systemd-journald</span><br><span class="line"><span class="comment"># you will see journal records here</span></span><br><span class="line">ls -l /var/<span class="built_in">log</span>/journal</span><br></pre></td></tr></table></figure></p>
<p>Or enable in <code>/etc/systemd/journald.conf</code>, set <code>Storage=persistent</code>.</p>
<p>You can specify date ranges:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">journalctl --since <span class="string">"2020-12-11 15:44:32"</span></span><br><span class="line"><span class="comment"># time left off is 00:00:00 midight</span></span><br><span class="line">journalctl --since <span class="string">"2020-10-01"</span> --until <span class="string">"2020-10-03 03:00"</span></span><br><span class="line">journalctl --since yesterday</span><br><span class="line">journalctl --since 09:00 --until <span class="string">"1 hour ago"</span></span><br></pre></td></tr></table></figure></p>
<p>Some useful commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># list boots</span></span><br><span class="line">journalctl --list-boots</span><br><span class="line"><span class="comment"># check last boot journal</span></span><br><span class="line">sudo reboot</span><br><span class="line">sudo journalctl -b -1</span><br><span class="line"></span><br><span class="line"><span class="comment"># combine</span></span><br><span class="line">journalctl -u nginx.service -u php-fpm.service --since today</span><br><span class="line"></span><br><span class="line"><span class="comment"># pid, uid, gid</span></span><br><span class="line">journalctl _PID=8088</span><br><span class="line">journalctl _UID=33 --since today</span><br><span class="line"></span><br><span class="line"><span class="comment"># -F: show available values</span></span><br><span class="line">journalctl -F _GID</span><br><span class="line">journalctl -F _UID</span><br><span class="line"></span><br><span class="line"><span class="comment"># check executable</span></span><br><span class="line">journalctl /usr/bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># display only kernel message</span></span><br><span class="line">journalctl -k</span><br><span class="line"></span><br><span class="line"><span class="comment"># by priority, can use number or name</span></span><br><span class="line"><span class="comment">#0: emerg</span></span><br><span class="line"><span class="comment">#1: alert</span></span><br><span class="line"><span class="comment">#2: crit</span></span><br><span class="line"><span class="comment">#3: err</span></span><br><span class="line"><span class="comment">#4: warning</span></span><br><span class="line"><span class="comment">#5: notice</span></span><br><span class="line"><span class="comment">#6: info</span></span><br><span class="line"><span class="comment">#7: debug</span></span><br><span class="line">journalctl -p err -b</span><br><span class="line"></span><br><span class="line"><span class="comment"># the same as tail -n</span></span><br><span class="line">journalctl -n 10</span><br><span class="line">journalctl -f</span><br><span class="line"></span><br><span class="line"><span class="comment"># disk usage</span></span><br><span class="line">journalctl --disk-usage</span><br><span class="line"><span class="comment"># shrink</span></span><br><span class="line">sudo journalctl --vacuum-size=1G</span><br><span class="line">sudo journalctl --vacuum-time=1years</span><br></pre></td></tr></table></figure></p>
<p>You can use <code>right arrow key</code> to see full entry if it is too long.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># print all on stdout, no pager with less</span></span><br><span class="line">journalctl --no-pager</span><br><span class="line"></span><br><span class="line"><span class="comment"># -o output format</span></span><br><span class="line"><span class="comment">#cat: Displays only the message field itself.</span></span><br><span class="line"><span class="comment">#export: A binary format suitable for transferring or backing up.</span></span><br><span class="line"><span class="comment">#json: Standard JSON with one entry per line.</span></span><br><span class="line"><span class="comment">#json-pretty: JSON formatted for better human-readability</span></span><br><span class="line"><span class="comment">#json-sse: JSON formatted output wrapped to make add server-sent event compatible</span></span><br><span class="line"><span class="comment">#short: The default syslog style output</span></span><br><span class="line"><span class="comment">#short-iso: The default format augmented to show ISO 8601 wallclock timestamps.</span></span><br><span class="line"><span class="comment">#short-monotonic: The default format with monotonic timestamps.</span></span><br><span class="line"><span class="comment">#short-precise: The default format with microsecond precision</span></span><br><span class="line"><span class="comment">#verbose: Shows every journal field available for the entry, including those usually hidde </span></span><br><span class="line"><span class="comment">#internally.</span></span><br><span class="line">journalctl -b -u nginx -o json</span><br><span class="line">journalctl -b -u nginx -o json-pretty</span><br></pre></td></tr></table></figure>
<h1 id="Linux-Session"><a href="#Linux-Session" class="headerlink" title="Linux Session"></a>Linux Session</h1><p>Other capabilities, like log management and user sessions are handled by separate daemons and management utilities (<code>journald/journalctl</code> and <code>logind/loginctl</code> respectively).</p>
<p>Get info about user and the processes he is running before:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># list sessions</span></span><br><span class="line">loginctl list-sessions</span><br><span class="line"></span><br><span class="line"><span class="comment"># session status </span></span><br><span class="line"><span class="comment"># you can see the user action history</span></span><br><span class="line">loginctl session-status [session id]</span><br><span class="line">loginctl show-session [session id]</span><br><span class="line">loginctl <span class="built_in">kill</span>-session [session id]</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>system admin</tag>
      </tags>
  </entry>
  <entry>
    <title>Tar Path Format Issue</title>
    <url>/2019/07/03/linux-tar-path/</url>
    <content><![CDATA[<p>I haven’t noticed the path format when I created tarball, this time the format issue plays as a major blocker.</p>
<p>We use a module tar file to deploy <code>Zen</code> in ICP4D cluster, when I use my customized tar file, I get:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Loading images</span><br><span class="line">/xxx/InstallPackage/modules/./xxx-iisee-zen:1.0.0//images</span><br><span class="line">Loaded Images [==============================================================================] 7m29s (35/35) done</span><br><span class="line">Pushed Images [==============================================================================] 15m17s (35/35) done</span><br><span class="line">Deploying the chart as name xxx-iisee-zen100</span><br><span class="line">Running command: /xxx/InstallPackage/components/dpctl --config /xxx/InstallPackage/components/install.yaml helm rewriteChart -i /xxx/InstallPackage/modules/./xxx-iisee-zen:1.0.0//charts/*.tgz -o /xxx/InstallPackage/modules/./xxx-iisee-zen:1.0.0//charts/updated_xxx-iisee-zen100.tgz</span><br><span class="line">Running command: /xxx/InstallPackage/components/dpctl --config /xxx/InstallPackage/components/install.yaml helm installChart -f /xxx/InstallPackage/components/global.yaml   -r zen-xxx-iisee-zen100 -n zen -c /xxx/InstallPackage/modules/./xxx-iisee-zen:1.0.0//charts/updated_xxx-iisee-zen100.tgz</span><br><span class="line">Starting the installation ...</span><br><span class="line">There was a problem installing /xxx/InstallPackage/modules/xxx-iisee-zen:1.0.0/charts/updated_xxx-iisee-zen100.tgz chart. Reason: chart metadata (Chart.yaml) missing</span><br></pre></td></tr></table></figure></p>
<p>Let’s highlight the command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Running command: /xxx/InstallPackage/components/dpctl --config /xxx/InstallPackage/components/install.yaml helm rewriteChart -i /xxx/InstallPackage/modules/./xxx-iisee-zen:1.0.0//charts/*.tgz -o /xxx/InstallPackage/modules/./xxx-iisee-zen:1.0.0//charts/updated_xxx-iisee-zen100.tgz</span><br></pre></td></tr></table></figure></p>
<p>Look carefully there is a <code>./</code> in path <code>/xxx/InstallPackage/modules/./xxx-iisee-zen:1.0.0/....</code>, this is because I create tarball use:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar cf xxx-iisee-zen-1.0.0.tar ./xxx-iisee-zen:1.0.0</span><br></pre></td></tr></table></figure></p>
<p>the <code>./</code> will be put in the extract path! which is the trouble maker.</p>
<p>Correct way:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> &lt;xxx-iisee-zen:1.0.0 parent folder&gt;</span><br><span class="line">tar cf xxx-iisee-zen-1.0.0.tar xxx-iisee-zen:1.0.0</span><br></pre></td></tr></table></figure></p>
<p>If we list the tarball contents, no prefix in the file structure:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar tvf xxx-iisee-zen-1.0.0.tar</span><br><span class="line"></span><br><span class="line">drwxr-xr-x 1001/docker       0 1969-12-31 16:00 xxx-iisee-zen:1.0.0/</span><br><span class="line">drwxr-xr-x 1001/docker       0 2019-07-02 15:13 xxx-iisee-zen:1.0.0/charts/</span><br><span class="line">-rw-r--r-- root/root    245868 2019-07-02 15:12 xxx-iisee-zen:1.0.0/charts/xxx-iisee-zen-1.0.1.tgz</span><br><span class="line">-rw------- 1001/docker    4758 1969-12-31 16:00 xxx-iisee-zen:1.0.0/manifest.yaml</span><br><span class="line">drwxr-xr-x 1001/docker       0 1969-12-31 16:00 xxx-iisee-zen:1.0.0/LICENSES/</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>For more information about tar commands, I have a blob about it already <a href="https://chengdol.github.io/2019/02/21/linux-tar-summary/" target="_blank" rel="noopener"><code>&lt;&lt;Tar Command Daily Work Summary&gt;&gt;</code></a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tar</tag>
      </tags>
  </entry>
  <entry>
    <title>Systemd Essential</title>
    <url>/2020/12/23/linux-systemd/</url>
    <content><![CDATA[<p>//TODO<br>[ ] loginctl usage</p>
<h1 id="Systemd"><a href="#Systemd" class="headerlink" title="Systemd"></a>Systemd</h1><p><a href="https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units" target="_blank" rel="noopener">How To Use Systemctl to Manage Systemd Services and Units</a></p>
<p>History:<br>SysV Init -&gt; Upstart -&gt; Systemd</p>
<p>The <code>systemd</code>, system and service manager, is an init system used to bootstrap the user space and to manage system processes after boot. Use <code>systemctl</code> command to manage the service on a systemd enabled system.</p>
<p>The fundamental purpose of an init system is to initialize the components that must be started after the Linux kernel is booted (traditionally known as “userland” components). The init system is also used to manage services and daemons for the server at any point while the system is running.</p>
<p>main commands, for example using nginx, some commands have to use <code>sudo</code> if you are non-root user, since it will affect te state of the operating system, you can leave off the <code>.service</code> suffix.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># start on boot</span></span><br><span class="line"><span class="comment"># This hooks it up to a certain boot “target”</span></span><br><span class="line"><span class="comment"># causing it to be triggered when that target is started.</span></span><br><span class="line">sudo systemctl <span class="built_in">enable</span> nginx.service</span><br><span class="line">sudo systemctl <span class="built_in">disable</span> nginx.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># start and stop</span></span><br><span class="line">sudo systemctl start nginx.service</span><br><span class="line">sudo systemctl stop nginx.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># To attempt to reload the service without </span></span><br><span class="line"><span class="comment"># interrupting normal functionalit</span></span><br><span class="line">sudo systemctl reload nginx.service</span><br><span class="line">sudo systemctl reload-or-restart nginx.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># status overview</span></span><br><span class="line"><span class="comment"># you can see:</span></span><br><span class="line"><span class="comment"># unit file path</span></span><br><span class="line"><span class="comment"># enabled or disabled at vendor and custom</span></span><br><span class="line"><span class="comment"># up time</span></span><br><span class="line"><span class="comment"># Cgroup</span></span><br><span class="line">systemctl status nginx.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># find overriden config files for all units</span></span><br><span class="line"><span class="comment"># 查看哪unit有drop in config snippets</span></span><br><span class="line">sudo systemd-delta</span><br></pre></td></tr></table></figure></p>
<p><code>enable</code> will create a soft link into the location on disk where systemd looks for autostart files (usually <code>/etc/systemd/system/some_target.target.wants</code>).</p>
<p>Some command exit code result for shell script:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># may need sudo</span></span><br><span class="line">systemctl is-active nginx.service</span><br><span class="line">systemctl is-enabled nginx.service</span><br><span class="line">systemctl is-failed nginx.service</span><br></pre></td></tr></table></figure></p>
<p>Check system states managed by systemd:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># list enabled units only</span></span><br><span class="line">systemctl [list-units]</span><br><span class="line"></span><br><span class="line"><span class="comment"># list all of the units that systemd has loaded or attempted to load into memory</span></span><br><span class="line"><span class="comment"># include not currently active</span></span><br><span class="line">systemctl list-units --all [--state=active|inactive] [--<span class="built_in">type</span>=service|target]</span><br><span class="line"></span><br><span class="line"><span class="comment"># show every available units installed on the system</span></span><br><span class="line">systemctl list-unit-files</span><br></pre></td></tr></table></figure></p>
<p><code>list-unit-files</code> state meaning: The state will usually be <code>enabled</code>, <code>disabled</code>, <code>static</code>, or <code>masked</code>. In this context, <code>static</code> means that the unit file does not contain an <code>[Install]</code> section, which is used to enable a unit. As such, these units cannot be enabled. Usually, this means that the unit performs a one-off action or is used only as a dependency of another unit and should not be run by itself.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># after mask, cannot enable or start service</span></span><br><span class="line">sudo systemctl mask nginx.service</span><br><span class="line">sudo systemctl unmask nginx.service</span><br></pre></td></tr></table></figure></p>
<p>To see full content and path of a unit file, vanilla unit files(don’t touch them, override them if needed in other places, for example <code>/etc/systemd/system</code>) are in <code>/usr/lib/systemd/system</code> and customized are in <code>/etc/systemd/system</code> folder:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show unit file content and path</span></span><br><span class="line"><span class="comment"># it is currently running settings!</span></span><br><span class="line">systemctl cat nginx.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># list dependencies </span></span><br><span class="line">systemctl list-dependencies nginx.service [--all] [--reverse] [--before] [--after]</span><br><span class="line"></span><br><span class="line"><span class="comment"># low-level detail of unit</span></span><br><span class="line"><span class="comment"># all key=values</span></span><br><span class="line"><span class="comment"># -p: display a single property</span></span><br><span class="line">systemctl show nginx.service [-p ExecStart]</span><br><span class="line"></span><br><span class="line"><span class="comment"># edit unit file</span></span><br><span class="line">sudo systemctl edit --full nginx.service</span><br><span class="line"><span class="comment"># append unit file snippet</span></span><br><span class="line">sudo systemctl edit nginx.service</span><br><span class="line"><span class="comment"># then reload to pick up changes</span></span><br><span class="line">sodu systemctl daemon-reload</span><br></pre></td></tr></table></figure></p>
<p>In systemd, service and other unit files can be tied to a <code>target</code>.</p>
<p>Targets are special unit files that describe a system state or synchronization point. Like other units, the files that define targets can be identified by their suffix, which in this case is <code>.target</code>. Targets do not do much themselves, but are instead used to group other units together.</p>
<p>This can be used in order to bring the system to certain states, much like other init systems use <code>runlevels</code>. (仍然可以显示系统的runlevel的)</p>
<p>For instance, there is a swap.target that is used to indicate that swap is ready for use. Units that are part of this process can sync with this target by indicating in their configuration that they are WantedBy= or RequiredBy= the swap.target. Units that require swap to be available can specify this condition using the Wants=, Requires=, and After= specifications to indicate the nature of their relationship.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># all available targets</span></span><br><span class="line">systemctl list-unit-files --<span class="built_in">type</span>=target</span><br><span class="line"></span><br><span class="line"><span class="comment"># current default target</span></span><br><span class="line">systemctl get-default</span><br><span class="line"></span><br><span class="line"><span class="comment"># set default target</span></span><br><span class="line">sudo systemctl <span class="built_in">set</span>-default multi-user.target</span><br><span class="line">sudo systemctl <span class="built_in">set</span>-default runlevel3.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># see what units are tied to a target</span></span><br><span class="line">systemctl list-dependencies multi-user.target</span><br></pre></td></tr></table></figure>
<p>Unlike runlevels, multiple targets can be active at one time. An active target indicates that systemd has attempted to start all of the units tied to the target and has not tried to tear them down again.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># show all active targets</span></span><br><span class="line">systemctl list-units --<span class="built_in">type</span>=target</span><br></pre></td></tr></table></figure></p>
<p>This is similar to changing the runlevel in other init systems. For instance, if you are operating in a graphical environment with <code>graphical.target</code> active, you can shut down the graphical system and put the system into a multi-user command line state by isolating the <code>multi-user.target</code>. Since graphical.target depends on multi-user.target but not the other way around, all of the graphical units will be stopped.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check units that will be kept alive</span></span><br><span class="line">systemctl list-dependencies multi-user.target</span><br><span class="line"><span class="comment"># transition</span></span><br><span class="line">sudo systemctl isolate multi-user.target</span><br></pre></td></tr></table></figure></p>
<p>Stopping and rebooting system, note <code>shutdown</code>, <code>reboot</code>, <code>poweroff</code> are actually softlink to systemd!<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo systemctl poweroff</span><br><span class="line">sudo systemctl reboot</span><br><span class="line"><span class="comment">#  boot into rescue mode (single-user)</span></span><br><span class="line">sudo systemctl rescue</span><br></pre></td></tr></table></figure></p>
<p>These all alert logged in users that the event is occurring.</p>
<p>有意思的是，这些都是同一个softlink，但是调用却有不同的效果呢? 利用了<code>$0</code> 作为判断, see <a href="https://unix.stackexchange.com/questions/77029/why-are-reboot-shutdown-and-poweroff-symlinks-to-systemctl" target="_blank" rel="noopener">here</a>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lrwxrwxrwx. 1 root root          16 Jun  6  2020 halt -&gt; ../bin/systemctl</span><br><span class="line">lrwxrwxrwx. 1 root root          16 Jun  6  2020 poweroff -&gt; ../bin/systemctl</span><br><span class="line">lrwxrwxrwx. 1 root root          16 Jun  6  2020 reboot -&gt; ../bin/systemctl</span><br><span class="line">lrwxrwxrwx. 1 root root          16 Jun  6  2020 runlevel -&gt; ../bin/systemctl</span><br><span class="line">lrwxrwxrwx. 1 root root          16 Jun  6  2020 shutdown -&gt; ../bin/systemctl</span><br><span class="line">lrwxrwxrwx. 1 root root          16 Jun  6  2020 telinit -&gt; ../bin/systemctl</span><br></pre></td></tr></table></figure></p>
<h1 id="Systemd-Journal"><a href="#Systemd-Journal" class="headerlink" title="Systemd Journal"></a>Systemd Journal</h1><p><a href="https://www.digitalocean.com/community/tutorials/how-to-use-journalctl-to-view-and-manipulate-systemd-logs" target="_blank" rel="noopener">How To Use Journalctl to View and Manipulate Systemd Logs</a></p>
<p>The journal is implemented with the <code>journald</code> daemon, which handles all of the messages produced by the kernel, initrd, services, etc.</p>
<p>这里介绍了关于systemd service journal的使用，更详细的介绍Journal 可以参考我的blog <code>&lt;&lt;Linux System Admin&gt;&gt;</code>.</p>
<p>Set time of the prompt:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># available time zone</span></span><br><span class="line">timedatectl list-timezones</span><br><span class="line"><span class="comment"># set time zone</span></span><br><span class="line">sudo timedatectl <span class="built_in">set</span>-timezone America/Los_Angeles</span><br><span class="line"><span class="comment"># check</span></span><br><span class="line">timedatectl status</span><br><span class="line"></span><br><span class="line"><span class="comment"># or using UTC</span></span><br><span class="line"><span class="comment"># --utc: time zone</span></span><br><span class="line">journalctl --utc</span><br></pre></td></tr></table></figure></p>
<p>To see full log of a specific service:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -b: limit to current boot</span></span><br><span class="line"><span class="comment"># -u: unit</span></span><br><span class="line"><span class="comment"># -e: show ending logs</span></span><br><span class="line"><span class="comment"># -r: show in reverse order</span></span><br><span class="line"><span class="comment"># -f: tail log</span></span><br><span class="line">journalctl -u nginx.service [--since] [--until]</span><br><span class="line"></span><br><span class="line"><span class="comment"># combine related units</span></span><br><span class="line"><span class="comment"># good for debug</span></span><br><span class="line">journalctl -u nginx.service -u php-fpm.service --since today</span><br></pre></td></tr></table></figure></p>
<h1 id="Service-Unit-File"><a href="#Service-Unit-File" class="headerlink" title="Service Unit File"></a>Service Unit File</h1><p><a href="https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files" target="_blank" rel="noopener">Understanding Systemd Units and Unit Files</a></p>
<p>Here only focusing on <code>.service</code> unit. Systemd manages a broad range of resources, such as <code>.target</code>. <code>.socket</code>, <code>.device</code>, <code>.mount</code>, <code>.swap</code>, etc. They may or may not have specified section block.</p>
<p>Section block names are case-sensitive. Non-standard section name <code>[X-name]</code> has a <code>X-</code> prefix.<br><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="comment">#This is generally used for defining metadata for the unit </span></span><br><span class="line"><span class="comment"># and configuring the relationship of the unit to other units</span></span><br><span class="line"><span class="attr">Description</span>=</span><br><span class="line"><span class="attr">Documentation</span>=</span><br><span class="line"></span><br><span class="line"><span class="attr">Requires</span>=</span><br><span class="line"><span class="attr">BindsTo</span>=</span><br><span class="line"></span><br><span class="line"><span class="attr">Wants</span>=</span><br><span class="line"><span class="attr">Before</span>=</span><br><span class="line"><span class="attr">After</span>=</span><br><span class="line"></span><br><span class="line"><span class="attr">Conflicts</span>=</span><br><span class="line"><span class="attr">Conditionxxx</span>=</span><br><span class="line"><span class="attr">Assertxxx</span>=</span><br><span class="line"></span><br><span class="line"><span class="section">[Service]</span></span><br><span class="line"><span class="comment"># provide configuration that is only applicable for services</span></span><br><span class="line"><span class="attr">Environment</span>=</span><br><span class="line"><span class="attr">Type</span>=simple(default)|forking|<span class="literal">on</span>eshot|dbus|notify|idle</span><br><span class="line"></span><br><span class="line"><span class="attr">PIDFile</span>=</span><br><span class="line"></span><br><span class="line"><span class="attr">ExecStart</span>=</span><br><span class="line"><span class="attr">ExecStartPre</span>=</span><br><span class="line"><span class="attr">ExecStartPost</span>=</span><br><span class="line"><span class="attr">ExecReload</span>=</span><br><span class="line"><span class="attr">ExecStop</span>=</span><br><span class="line"><span class="attr">ExecStopPost</span>=</span><br><span class="line"></span><br><span class="line"><span class="attr">RestartSec</span>=</span><br><span class="line"><span class="attr">Restart</span>=always|<span class="literal">on</span>-success|<span class="literal">on</span>-failure|<span class="literal">on</span>-abnormal|<span class="literal">on</span>-abort|<span class="literal">on</span>-watchdog</span><br><span class="line"><span class="attr">TimeoutSec</span>=</span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="comment"># only units that can be enabled will have this section</span></span><br><span class="line"><span class="attr">WantedBy</span>=</span><br><span class="line"><span class="attr">RequiredBy</span>=</span><br><span class="line"></span><br><span class="line"><span class="attr">Alias</span>=</span><br><span class="line"><span class="attr">Also</span>=</span><br><span class="line"><span class="attr">DefaultInstance</span>=</span><br></pre></td></tr></table></figure></p>
<p>key=value pairs 不止这些，遇到新的可以补充。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>systemd</tag>
      </tags>
  </entry>
  <entry>
    <title>VNC Set up</title>
    <url>/2019/05/29/linux-vnc/</url>
    <content><![CDATA[<p><code>Virtual Network Computing (VNC)</code> is a graphical desktop-sharing system that uses the Remote Frame Buffer protocol (RFB) to remotely control another computer. It transmits the keyboard and mouse events from one computer to another, relaying the graphical-screen updates back in the other direction, over a network.</p>
<p>Popular uses for this technology include remote technical support and accessing files on one’s work computer from one’s home computer, or vice versa.</p>
<p>I usually use it to do remote development in Fyre, I have a central control machine with VNC set, after vnc to that machine then use it to SSH to others within the same internal network, you can also install IDE in VNC to do general programming work rather than developing locally.</p>
<blockquote>
<p>Note, there are other remote terminal tools like <code>Termius</code>. </p>
</blockquote>
<h2 id="Install-VNC-Server"><a href="#Install-VNC-Server" class="headerlink" title="Install VNC Server"></a>Install VNC Server</h2><p>Not sure if the configurations are the same, actually the settings are varies.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum update -y</span><br><span class="line"></span><br><span class="line">## seems no need this:</span><br><span class="line">yum install open-vm-tools</span><br><span class="line"></span><br><span class="line">## if you don’t have desktop installed, note linux has many different desktop system themes, only install core packages of KDE or GNOME, KDE is better</span><br><span class="line">yum groupinstall &apos;X Window System&apos; &apos;KDE&apos;</span><br><span class="line">yum groupinstall &apos;X Window System&apos; &apos;GNOME&apos;</span><br><span class="line"></span><br><span class="line">yum list |grep tiger</span><br><span class="line">yum -y install tigervnc-server </span><br><span class="line"></span><br><span class="line">## Fyre firewalld default is inactive, no need to deal with firewall here</span><br><span class="line">## if it’s enable, may need to config</span><br><span class="line">systemctl status firewalld</span><br><span class="line">firewall-cmd --permanent --zone=public --add-service vnc-server </span><br><span class="line">firewall-cmd --reload</span><br><span class="line"></span><br><span class="line">## start vnc</span><br><span class="line">## select yes then create password: 123456</span><br><span class="line">## first time it will open port 1</span><br><span class="line">## then you will get the address and port to login:</span><br><span class="line">## centctl1.fyre.ibm.com:1</span><br><span class="line">vncserver</span><br></pre></td></tr></table></figure></p>
<p>Note if you will get new vnc session everytime you run <code>vncserver</code>, check with<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep vnc</span><br><span class="line"></span><br><span class="line">root      2682  0.0  3.0 284860 116840 ?       Sl   May27   1:38 /usr/bin/Xvnc :1 -auth /root/.Xauthority -desktop mycentctl1.fyre.ibm.com:1 (root) -fp catalogue:/etc/X11/fontpath.d -geometry 1024x768 -pn -rfbauth /root/.vnc/passwd -rfbport 5901 -rfbwait 30000</span><br><span class="line">root      9199  1.4  1.6 231660 62388 pts/3    Sl   08:59   0:00 /usr/bin/Xvnc :2 -auth /root/.Xauthority -desktop mycentctl1.fyre.ibm.com:2 (root) -fp catalogue:/etc/X11/fontpath.d -geometry 1024x768 -pn -rfbauth /root/.vnc/passwd -rfbport 5902 -rfbwait 30000</span><br></pre></td></tr></table></figure></p>
<p>you can kill it by running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vncserver -kill :2</span><br></pre></td></tr></table></figure></p>
<p>If the VNC is broken due to maintenance, open a new session again by <code>vncserver</code>.</p>
<h2 id="Install-VNC-viewer"><a href="#Install-VNC-viewer" class="headerlink" title="Install VNC viewer"></a>Install VNC viewer</h2><p>Install VNC viewer on your local laptop, then connect by<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">centctl1.fyre.ibm.com:1</span><br></pre></td></tr></table></figure></p>
<h2 id="Copy-and-Paste"><a href="#Copy-and-Paste" class="headerlink" title="Copy and Paste"></a>Copy and Paste</h2><p>If you want to copy from local to viewer, sometimes it’s malfunction, kill the <code>klipper</code> process:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep klipper</span><br><span class="line">kill -9 &lt;PID of klipper&gt;</span><br></pre></td></tr></table></figure></p>
<p>You can adjust shortcuts in VNC viewer for copy and paste:<br>Settings -&gt; Configure Shortcuts -&gt; copy / paste</p>
<h2 id="Other-Settings"><a href="#Other-Settings" class="headerlink" title="Other Settings"></a>Other Settings</h2><p>Other settings useful:<br>Settings -&gt; Edit Current Profile -&gt; Mouse -&gt; copy on select / Trim trailing space</p>
<p>Adjust font size the themes:<br>Settings -&gt; Manage Profiles -&gt; Edit Profile -&gt; Appearabce -&gt; Black on Random Light<br>-&gt; check Vary the background color for each tab</p>
<p>Also change the text size under Appearance.</p>
<h2 id="Screen-resolution"><a href="#Screen-resolution" class="headerlink" title="Screen resolution"></a>Screen resolution</h2><p>If the screen open by VNC viewer is small, you can change the resolution, run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xrandr -s 1920x1080</span><br></pre></td></tr></table></figure></p>
<p>on the terminal in your remote machine.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vnc</tag>
      </tags>
  </entry>
  <entry>
    <title>User ID Valid Range</title>
    <url>/2019/07/26/linux-uid-range/</url>
    <content><![CDATA[<p>From the CloudPak certification requirments, the <code>uid</code> for non-root user in container should be set in a higher range. We change it from <code>1000</code> to <code>100321000</code> but the image build got stuck and failed.</p>
<p>The reason is there is a range for <code>uid</code> number, it’s described in <code>/etc/login.defs</code> file (you can edit this file).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /etc/login.defs | grep -i UID</span><br><span class="line"></span><br><span class="line">UID_MIN                  1000</span><br><span class="line">UID_MAX                 60000</span><br></pre></td></tr></table></figure></p>
<p>So if you create a user by <code>useradd</code> without specify user id explicitly, its <code>uid</code> will start from <code>1000</code>. Also when change the <code>uid</code> by <code>usermod -u &lt;new uid&gt; &lt;user name&gt;</code>, you need to follow the limitation.</p>
<p>The <code>gid</code> has the same restriction:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /etc/login.defs | grep -i GID</span><br><span class="line"></span><br><span class="line">GID_MIN                  1000</span><br><span class="line">GID_MAX                 60000</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Wget Use Case Summary</title>
    <url>/2020/09/04/linux-wget-summary/</url>
    <content><![CDATA[<p><code>Wget</code> is a free utility for non-interactive download of files from the Web.  It supports HTTP, HTTPS, and FTP protocols, as well as retrieval through HTTP proxies. It is fault-tolerance, has big overlap with curl, both heavily using.</p>
<p><code>wget -h</code> and man page are informative.</p>
<blockquote>
<p>值得注意的是，不同Linux版本wget支持的选项可能不完整。</p>
</blockquote>
<h2 id="Continue-download"><a href="#Continue-download" class="headerlink" title="Continue download"></a>Continue download</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## assume the url is disrupted and leave a incomplete file in current folder</span></span><br><span class="line"><span class="comment">## -c,--continue: continue</span></span><br><span class="line">wget &lt;url&gt; -c</span><br></pre></td></tr></table></figure>
<h2 id="Authz"><a href="#Authz" class="headerlink" title="Authz"></a>Authz</h2><p>If you proxy, http_proxy for http connection, https_proxy for https connection.<br><a href="https://askubuntu.com/questions/1070838/why-wget-does-not-use-username-and-password-in-url-first-time" target="_blank" rel="noopener">Wget basic authentication challenge</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## http use http_proxy flag</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## other options:</span></span><br><span class="line"><span class="comment">## --no-check-certificate: Don't check the server certificate against the available certificate authorities</span></span><br><span class="line"><span class="comment">## --connect-timeout: seconds, TCP connections that take longer to establish will be aborted</span></span><br><span class="line"><span class="comment">## -e, --execute: commands, env varaible</span></span><br><span class="line"><span class="comment">## --auth-no-challenge: for server never sends HTTP authentication challenges, not recommended</span></span><br><span class="line">wget --no-check-certificate --connect-timeout 10 -e http_proxy=<span class="string">"envoy:10000"</span> http://www.httpbin.org/ip --auth-no-challenge --user xxx --password xxx</span><br><span class="line"></span><br><span class="line"><span class="comment">## https use https_proxy flag</span></span><br><span class="line">wget --no-check-certificate --connect-timeout 10 -e https_proxy=<span class="string">"envoy:10000"</span> https://www.httpbin.org/ip --auth-no-challenge --user xxx --password xxx</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>wget</tag>
      </tags>
  </entry>
  <entry>
    <title>Tar Command Daily Work Summary</title>
    <url>/2019/02/21/linux-tar-summary/</url>
    <content><![CDATA[<p>This article used to walk you through some commonly <code>tar</code> usages , based on a real life scenario.</p>
<p>################################################################<br>#  &emsp; Date &emsp; &emsp; &emsp; &emsp; &emsp; Description<br>#  &emsp; 05/29/2019 &emsp; &emsp; vim tar files<br>#  &emsp; 05/29/2019 &emsp; &emsp; extract single file to another directory<br>#  &emsp; 05/28/2019 &emsp; &emsp; extract file to another directory<br>#  &emsp; 05/23/2019 &emsp; &emsp; extract single file from archive<br>#  &emsp; 04/21/2019 &emsp; &emsp; untar keep owner and permission<br>#  &emsp; 02/27/2019 &emsp; &emsp; untar to specified folder<br>#  &emsp; 02/22/2019 &emsp; &emsp; list tar content<br>#  &emsp; 02/21/2019 &emsp; &emsp; tar exclude<br>#  &emsp; 02/20/2019 &emsp; &emsp; untar multiple files<br>#  &emsp; 02/19/2019 &emsp; &emsp; tar multiple files<br>#<br>################################################################</p>
<p>Sometimes I see people use <code>-czf</code> but sometimes <code>czf</code>, dash or not to pass flags?<br>Historical and compatible reason, <strong>no</strong> dash version is probably more portable.</p>
<p><code>tar</code> is one of those ancient commands from the days when option syntax hadn’t been standardized. Because all useful invocations of <code>tar</code> require specifying an operation before providing any file name, most <code>tar</code> implementations interpret their first argument as an option even if it doesn’t begin with a <code>-</code>. Most current implementations accept a <code>-</code>.</p>
<p>注意, 这里的例子大多是用的old option style for compatibility. For example <code>czf</code> this set of letters must be the first to appear on the command line, after the tar program name and some white space; old options cannot appear anywhere else.</p>
<p>还要注意，当前pwd是<code>/tmp</code>然后运行<code>tar</code>，则<code>tar</code>的结果就在<code>/tmp</code>, 和<code>-C</code>无关, <code>-C</code>option只是在执行中暂时去指定的位置。</p>
<h3 id="02-19-2019"><a href="#02-19-2019" class="headerlink" title="02/19/2019"></a>02/19/2019</h3><p>Basic operation: tar multiple files into <code>example.tar.gz</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## use -C to go to target directory</span></span><br><span class="line"><span class="comment">## target directory: the directory which contains file1/2/3</span></span><br><span class="line">tar czf example.tar.gz -C &lt;target directory&gt; file1 file2 file3</span><br><span class="line"></span><br><span class="line"><span class="comment">## tar a directory as whole</span></span><br><span class="line"><span class="comment">## target directory: &lt;folder name&gt;'s parent folder</span></span><br><span class="line"><span class="comment">## untar 结果是&lt;folder name&gt;这个文件夹</span></span><br><span class="line">tar czf example.tar.gz -C &lt;target directory&gt; &lt;folder name&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果只想打包某一文件夹内的内容, 则用-C 进入那个文件夹</span></span><br><span class="line"><span class="comment">## 但这样用tar tvf 查看，会有./ 前缀, 因为最后那个`.` 会展开显示所有hidden file，包括当前文件夹那个`.`</span></span><br><span class="line">tar czf example.tar.gz -C &lt;target directory&gt; .</span><br><span class="line"></span><br><span class="line"><span class="comment">## 用`*`就没有./ 前缀，但是不会包含hidden file, 必须自己列出来</span></span><br><span class="line"><span class="comment">## 但这样用tar tvf 查看就没有前缀了</span></span><br><span class="line">tar czf example.tar.gz -C &lt;target directory&gt; * .hidden1 .hidden2</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>The file path matters! see my <a href="https://chengdol.github.io/2019/07/03/linux-tar-path/" target="_blank" rel="noopener">blog</a>.</p>
</blockquote>
<h3 id="02-20-2019"><a href="#02-20-2019" class="headerlink" title="02/20/2019"></a>02/20/2019</h3><p>When untar multiple files, you cannot do this, it will fail<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar zxf file1.tar.gz file2.tar.gz file3.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>The reason please see this <a href="https://stackoverflow.com/questions/583889/how-can-you-untar-more-than-one-file-at-a-time" target="_blank" rel="noopener">link</a>, the solution is to use <code>xargs</code> instead:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls *.tar.gz | xargs -i tar xzf &#123;&#125;</span><br></pre></td></tr></table></figure></p>
<p>Or you can use <code>find</code> with <code>-exec</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find . -maxdepth 1 -name <span class="string">"*.tar.gz"</span> -<span class="built_in">exec</span> tar zxf <span class="string">'&#123;&#125;'</span> \;</span><br></pre></td></tr></table></figure></p>
<h3 id="02-21-2019"><a href="#02-21-2019" class="headerlink" title="02/21/2019"></a>02/21/2019</h3><p>For example, if you want to tar things inside a folder <code>foler1</code> but excluding some files:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 注意最后的`.` 目标必须放最后</span></span><br><span class="line"><span class="comment">## target directory: 进入</span></span><br><span class="line"><span class="built_in">cd</span> folder1</span><br><span class="line">tar czf folder1.tar.gz --exclude=<span class="string">"folder1.tar.gz"</span> --exclude=<span class="string">'file1'</span> --exclude=<span class="string">'file2'</span> *</span><br><span class="line"><span class="comment">## if you want to have hidden files</span></span><br><span class="line">tar czf folder1.tar.gz --exclude=<span class="string">"folder1.tar.gz"</span> --exclude=<span class="string">'file1'</span> --exclude=<span class="string">'file2'</span> * .file3 .file4</span><br></pre></td></tr></table></figure></p>
<p>If you don’t exclude <code>folder1.tar.gz</code>, it will tar itself again.</p>
<h3 id="02-22-2019"><a href="#02-22-2019" class="headerlink" title="02/22/2019"></a>02/22/2019</h3><p>List tar.gz file content, flag <code>z</code> is used to distinguish tar and tar.gz<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar tvf target.tar</span><br><span class="line">tar ztvf target.tar.gz</span><br></pre></td></tr></table></figure></p>
<h3 id="02-27-2019"><a href="#02-27-2019" class="headerlink" title="02/27/2019"></a>02/27/2019</h3><p>If you don’t specify target folder, untar will put things in current directory, use <code>-C</code> option to specify it. For example, I want to untar <code>source.tar.gz</code> to <code>/etc/yum.repos.d/</code> folder:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar zxf /tmp/source.tar.gz -C /etc/yum.repos.d/</span><br></pre></td></tr></table></figure></p>
<p>For <code>-C</code> option, in <code>c</code> and <code>r</code> mode, this changes the directory before adding the following files.  In <code>x</code> mode, change directories after opening the archive but before extracting entries from the archive.</p>
<h3 id="04-21-2019"><a href="#04-21-2019" class="headerlink" title="04/21/2019"></a>04/21/2019</h3><p>When unpacking, consider using <code>p</code> option to perserve file permissions. Use this in extract mode to override your <code>umask</code> and get the exact permissions specified in the archive.. The <code>p</code> option is the default when working as the <strong>superuser</strong>, it will get what it has. If you are a <strong>regular user</strong>, add <code>p</code> to keep permissions.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar zxpf target.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>It seems umask ignores execute bit? When I untar the file with <code>rwxrwxrwx</code> permission inside by regular user with umask <code>0002</code>, the final permission is <code>rwxrwxr-x</code>.</p>
<p>if you want to keep owner as well:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar --same-owner -zxpf target.tar.gz</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that there is a <code>-</code> before <code>zxpf</code>.</p>
</blockquote>
<h3 id="05-23-2019"><a href="#05-23-2019" class="headerlink" title="05/23/2019"></a>05/23/2019</h3><p>Extract specific files from tarball to current directory:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar xzf target.tar.gz file1 file2</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that no leading <code>/</code> in the path (it uses relative path in tar file!), you can use <code>tar xtvf target.tar.gz</code> to check the path.</p>
</blockquote>
<h3 id="05-28-2019"><a href="#05-28-2019" class="headerlink" title="05/28/2019"></a>05/28/2019</h3><p><code>tar</code> by default extracts file to current directory, if you want to place the untar files to another directory, run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxf target.tar.gz -C /target/directory</span><br></pre></td></tr></table></figure></p>
<p>Note that the target directory has to <strong>exist</strong> before running that command.</p>
<h3 id="05-29-2019"><a href="#05-29-2019" class="headerlink" title="05/29/2019"></a>05/29/2019</h3><p>If you want to extact files to another directory:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## file1 and file2 put at end</span></span><br><span class="line">tar xzf target.tar.gz -C /target/directory file1 file2</span><br></pre></td></tr></table></figure></p>
<h3 id="11-12-2020"><a href="#11-12-2020" class="headerlink" title="11/12/2020"></a>11/12/2020</h3><p>Latest VIM support edit on tar file:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## then select file in dashboard, edit and save normally</span></span><br><span class="line">vim source.tar.gz</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tar</tag>
      </tags>
  </entry>
  <entry>
    <title>Set up and Use Local Yum Repository</title>
    <url>/2019/03/05/linux-yum-local-repo/</url>
    <content><![CDATA[<p>Just like the blogs I wrote before: <code>Offline Package Installation I</code> and <code>Solve Conflicts in RPM installation</code>, Use <code>rpm</code> or bare <code>yum</code> command to install downloaded rpm file works but I find somehow this will cause some maintenance problems, for example<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Warning: RPMDB altered outside of yum.</span><br><span class="line">** Found 51 pre-existing rpmdb problem(s), &apos;yum check&apos; output follows:</span><br><span class="line">bash-4.2.46-31.el7.x86_64 is a duplicate with bash-4.2.46-30.el7.x86_64</span><br><span class="line">binutils-2.27-34.base.el7.x86_64 is a duplicate with binutils-2.27-28.base.el7_5.1.x86_64</span><br><span class="line">coreutils-8.22-23.el7.x86_64 is a duplicate with coreutils-8.22-21.el7.x86_64</span><br><span class="line">cryptsetup-libs-2.0.3-3.el7.x86_64 is a duplicate with cryptsetup-libs-1.7.4-4.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<p>I need to find a way that can automatically figure out the dependency chain, install the rpm required from download pool.</p>
<h3 id="Create-a-yum-repository"><a href="#Create-a-yum-repository" class="headerlink" title="Create a yum repository"></a>Create a yum repository</h3><p>Install <code>createrepo</code> package:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y createrepo</span><br></pre></td></tr></table></figure></p>
<p>Next, creates the necessary metadata for your Yum repository, as well as the sqlite database for speeding up yum operations. For example, <code>/root/docker</code> directory contains all rpms that install docker needs:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">createrepo --database /root/docker</span><br></pre></td></tr></table></figure></p>
<p>you will find it generates a folder called <code>repodata</code> that contains:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">304457af78cd250275222993fa0da09256f64cc627c1e31fb3ec0848b28b28d8-primary.xml.gz</span><br><span class="line">3d5ab2f5b706e5750e0ebe5802a278525da9cac4b9700634c51c2bfdf04a0d0e-primary.sqlite.bz2</span><br><span class="line">421810a6b2d93e49bfe417404f937e17929f0d8c55953dbe8e96cbb19f40708d-filelists.sqlite.bz2</span><br><span class="line">62c33f23a9485d74076d3db77064a9bdf606ce68d6702cd84fc5c6f1bcb48f01-other.sqlite.bz2</span><br><span class="line">649e08cdba02219eb660f579b89e7a86cf805e4f989222cb1be556a8e0b82b5c-other.xml.gz</span><br><span class="line">6cd1c3a2d6f385b1cbb878a88f86b8ef7e32d6e5c2c32c41a81f51464c3785c7-filelists.xml.gz</span><br><span class="line">repomd.xml</span><br></pre></td></tr></table></figure></p>
<h3 id="Create-yum-repo-file"><a href="#Create-yum-repo-file" class="headerlink" title="Create yum repo file"></a>Create yum repo file</h3><p>To define a new repository, you can either add a <code>[repository]</code> section to the <code>/etc/yum.conf</code> file, or to a <code>.repo</code> file in the <code>/etc/yum.repos.d/</code> directory. All files with the <code>.repo</code> file extension in this directory are read by yum, and it is recommended to define your repositories here instead of in <code>/etc/yum.conf</code>.</p>
<p>For example, create a <code>docker-local.repo</code> file in <code>/etc/yum.repos.d/</code> directory, <code>baseurl</code> points to the folder that holds downloaded rpms:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[docker-local.repo]</span><br><span class="line">name=docker-local</span><br><span class="line">baseurl=file:///root/docker</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br></pre></td></tr></table></figure></p>
<p>Then if you run <code>yum repolist all</code>, you will see this new added yum repository:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum repolist all</span><br><span class="line"></span><br><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">repo id                 repo name                          status</span><br><span class="line">...</span><br><span class="line">docker-local.repo       docker-local                       enabled:    134</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>You can also list enabled and disabled repository:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum repolist enabled</span><br><span class="line">yum repolist disabled</span><br></pre></td></tr></table></figure></p>
<h3 id="Install-using-yum"><a href="#Install-using-yum" class="headerlink" title="Install using yum"></a>Install using yum</h3><p>Now you can install docker by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y docker-ce</span><br></pre></td></tr></table></figure></p>
<p>yum will check local repository and launch dependencies for you.</p>
<p>Sometimes it’s better to set <code>enabled=0</code> in <code>.repo</code> file to disable it by default, so you can run:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum --enablerepo=docker-local.repo install -y docker-ce</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title>Yum Pending Transaction</title>
    <url>/2019/02/28/linux-yum-pending/</url>
    <content><![CDATA[<p>I need to clean yum pending or unfinished transactions before our installer start to work, otherwise the <code>yum update</code> or <code>yum install</code> may fail. But where are these pending transactions from? Sometimes the machine is down or unexpected thing happens, the yum installation process failed.</p>
<h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>you may see error like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">There are unfinished transactions remaining. You might consider running yum-complete-transaction first to finish them.</span><br><span class="line">The program yum-complete-transaction is found in the yum-utils package.</span><br></pre></td></tr></table></figure></p>
<h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>According to the prompt, we need first install <code>yum-utils</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils</span><br></pre></td></tr></table></figure></p>
<p><code>yum-complete-transaction</code> is a program which finds incomplete or aborted yum transactions on a system and attempts to complete them. It looks at the transaction-all<em> and transaction-done</em> files which can normally be found in /var/lib/yum if a yum transaction aborted in the middle of execution.</p>
<p>If it finds more than one unfinished transaction it will attempt to complete the most recent one first. You can run it more than once to clean up all unfinished transactions.</p>
<p>Then just issue the following command to do a cleanup:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum-complete-transaction --cleanup-only</span><br></pre></td></tr></table></figure></p>
<p>You can also check how many pending transactions exist:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find /var/lib/yum -maxdepth 1 -<span class="built_in">type</span> f -name <span class="string">'transaction-all*'</span> -not -name <span class="string">'*disabled'</span> -<span class="built_in">printf</span> . | wc -c</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title>Yum and Rpm Daily Work Summary</title>
    <url>/2019/03/02/linux-yum-rpm-summary/</url>
    <content><![CDATA[<p>This article used to walk you through some commonly <code>yum</code> and <code>rpm</code> usages , based on a real life scenario.</p>
<p>################################################################<br>#  &emsp; Date &emsp; &emsp; &emsp; &emsp; &emsp; Description<br>#  &emsp; 03/05/2019 &emsp; &emsp; yum autoremove<br>#  &emsp; 03/02/2019 &emsp; &emsp; upgrade rpm<br>#  &emsp; 03/01/2019 &emsp; &emsp; list rpm dependencies<br>#  &emsp; 02/27/2019 &emsp; &emsp; yum provides<br>#  &emsp; 02/25/2019 &emsp; &emsp; search rpm installed<br>#  &emsp; 02/24/2019 &emsp; &emsp; install rpm<br>#  &emsp; 01/19/2019 &emsp; &emsp; remove package<br>#<br>################################################################</p>
<p>Yum command <a href="https://access.redhat.com/sites/default/files/attachments/rh_yum_cheatsheet_1214_jcs_print-1.pdf" target="_blank" rel="noopener">cheat sheet</a><br><code>rpm</code> command is one of the package management command.</p>
<h3 id="01-19-2019"><a href="#01-19-2019" class="headerlink" title="01/19/2019"></a>01/19/2019</h3><p>Remove or erase a installed package with its dependencies:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ev &lt;package name&gt;</span><br><span class="line">yum erase &lt;package name&gt;</span><br></pre></td></tr></table></figure></p>
<p>if the rpm is part of other dependencies, <code>rpm -ev</code> will fail, or you can use <code>yum erase</code> to delete them all:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ev containerd.io</span><br><span class="line"></span><br><span class="line">error: Failed dependencies:</span><br><span class="line">        containerd.io &gt;= 1.2.2-3 is needed by (installed) docker-ce-3:18.09.2-3.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<p>Remove or erase a installed package <strong>without</strong> checking for dependencies<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ev --nodeps &lt;package name&gt;</span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ev --nodpes containerd.io</span><br><span class="line"></span><br><span class="line">Preparing packages...</span><br><span class="line">containerd.io-1.2.2-3.3.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<h3 id="02-24-2019"><a href="#02-24-2019" class="headerlink" title="02/24/2019"></a>02/24/2019</h3><p>This command will install a single rpm file if it meets all dependencies, otherwise install will fail and the output will show you the missig rpms.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ivh &lt;rpm name&gt;</span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ivh 416b2856f8dbb6f07a50a46018fee8596479ebc0eaeec069c26bedfa29033315-kubeadm-1.13.2-0.x86_64.rpm</span><br><span class="line"></span><br><span class="line">warning: 416b2856f8dbb6f07a50a46018fee8596479ebc0eaeec069c26bedfa29033315-kubeadm-1.13.2-0.x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID 3e1ba8d5: NOKEY</span><br><span class="line">error: Failed dependencies:</span><br><span class="line">        cri-tools &gt;= 1.11.0 is needed by kubeadm-1.13.2-0.x86_64</span><br><span class="line">        kubectl &gt;= 1.6.0 is needed by kubeadm-1.13.2-0.x86_64</span><br><span class="line">        kubelet &gt;= 1.6.0 is needed by kubeadm-1.13.2-0.x86_64</span><br><span class="line">        kubernetes-cni &gt;= 0.6.0 is needed by kubeadm-1.13.2-0.x86_64</span><br></pre></td></tr></table></figure></p>
<h3 id="02-25-2019"><a href="#02-25-2019" class="headerlink" title="02/25/2019"></a>02/25/2019</h3><p>These two both work:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## query package installed</span></span><br><span class="line">rpm -qa | grep &lt;package name&gt;</span><br><span class="line">yum list installed | grep &lt;package name&gt;</span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qa | grep docker</span><br><span class="line">docker-ce-18.06.1.ce-3.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum list installed | grep docker</span><br><span class="line">docker-ce.x86_64                18.06.1.ce-3.el7           installed</span><br></pre></td></tr></table></figure>
<h3 id="02-27-2019"><a href="#02-27-2019" class="headerlink" title="02/27/2019"></a>02/27/2019</h3><p>Find packages that provide the queried file, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum provides host</span><br><span class="line"></span><br><span class="line">32:<span class="built_in">bind</span>-utils-9.9.4-14.el7.x86_64 : Utilities <span class="keyword">for</span> querying DNS name servers</span><br><span class="line">Repo        : Local-Base</span><br><span class="line">Matched from:</span><br><span class="line">Filename    : /usr/bin/host</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>Next you can install it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y bind-utils</span><br></pre></td></tr></table></figure></p>
<h3 id="03-01-2019"><a href="#03-01-2019" class="headerlink" title="03/01/2019"></a>03/01/2019</h3><p>If you have a local rpm file, you can list its dependencies by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qpR &lt;rpm name&gt;</span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qpR 416b2856f8dbb6f07a50a46018fee8596479ebc0eaeec069c26bedfa29033315-kubeadm-1.13.2-0.x86_64.rpm</span><br><span class="line"></span><br><span class="line">warning: 416b2856f8dbb6f07a50a46018fee8596479ebc0eaeec069c26bedfa29033315-kubeadm-1.13.2-0.x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID 3e1ba8d5: NOKEY</span><br><span class="line">cri-tools &gt;= 1.11.0</span><br><span class="line">kubectl &gt;= 1.6.0</span><br><span class="line">kubelet &gt;= 1.6.0</span><br><span class="line">kubernetes-cni &gt;= 0.6.0</span><br><span class="line">rpmlib(CompressedFileNames) &lt;= 3.0.4-1</span><br><span class="line">rpmlib(FileDigests) &lt;= 4.6.0-1</span><br><span class="line">rpmlib(PayloadFilesHavePrefix) &lt;= 4.0-1</span><br><span class="line">rpmlib(PayloadIsXz) &lt;= 5.2-1</span><br></pre></td></tr></table></figure></p>
<h3 id="03-02-2019"><a href="#03-02-2019" class="headerlink" title="03/02/2019"></a>03/02/2019</h3><p>If you run <code>man rpm</code>, there are two similar statements:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The general form of an rpm upgrade command is</span><br><span class="line"></span><br><span class="line">rpm &#123;-U|--upgrade&#125; [install-options] PACKAGE_FILE ...</span><br><span class="line"></span><br><span class="line">       This upgrades or installs the package currently installed to a newer version.  This is the same as  install,</span><br><span class="line">       except all other version(s) of the package are removed after the new package is installed.</span><br><span class="line"></span><br><span class="line">rpm &#123;-F|--freshen&#125; [install-options] PACKAGE_FILE ...</span><br><span class="line"></span><br><span class="line">       This will upgrade packages, but only ones for which an earlier version is installed.</span><br></pre></td></tr></table></figure></p>
<p>Both <code>rpm -Fvh</code> and <code>rpm -Uvh</code> will perform the same task but the diff is <code>rpm -Uvh</code> is also same as <code>rpm -ivh</code>, you can use any of them I mean <code>rpm -ivh</code> or <code>rpm -Uvh</code> for installing the package.</p>
<p>But for upgrading installed package you can use any of <code>rpm -Fvh</code> or <code>rpm -Uvh</code>.</p>
<p><code>rpm -Fvh</code> is used for upgrading the existing package (installed package).<br><code>rpm -Uvh</code> is used for installing the package and upgrading the package both.</p>
<p>For example, upgrade <code>ansible</code> from <code>2.4.6.0</code> to <code>2.7.8</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -Fvh ansible-2.7.8-1.el7.ans.noarch.rpm</span><br><span class="line"></span><br><span class="line">warning: ansible-2.7.8-1.el7.ans.noarch.rpm: Header V4 RSA/SHA1 Signature, key ID 442667a9: NOKEY</span><br><span class="line">Preparing...                          ################################# [100%]</span><br><span class="line">Updating / installing...</span><br><span class="line">   1:ansible-2.7.8-1.el7.ans          ################################# [ 50%]</span><br><span class="line">Cleaning up / removing...</span><br><span class="line">   2:ansible-2.4.6.0-1.el7.ans        ################################# [100%]</span><br></pre></td></tr></table></figure></p>
<h3 id="03-05-2019"><a href="#03-05-2019" class="headerlink" title="03/05/2019"></a>03/05/2019</h3><p>Remove dependencies which are not in use, any unneeded dependencies from your system, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum autoremove docker-ce</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">=========================================================================================================================</span><br><span class="line"> Package                            Arch               Version                      Repository                      Size</span><br><span class="line">=========================================================================================================================</span><br><span class="line">Removing:</span><br><span class="line"> docker-ce                          x86_64             18.06.1.ce-3.el7             @docker-local.repo             168 M</span><br><span class="line">Removing for dependencies:</span><br><span class="line"> container-selinux                  noarch             2:2.68-1.el7                 @Local-Extras                   36 k</span><br><span class="line"> libcgroup                          x86_64             0.41-20.el7                  @Local-Base                    134 k</span><br><span class="line"> libseccomp                         x86_64             2.3.1-3.el7                  @Local-Base                    297 k</span><br><span class="line"> libtool-ltdl                       x86_64             2.4.2-22.el7_3               @Local-Base                     66 k</span><br><span class="line"> policycoreutils-python             x86_64             2.5-29.el7_6.1               @Local-Base                    1.2 M</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">=========================================================================================================================</span><br><span class="line">Remove  1 Package (+5 Dependent packages)</span><br></pre></td></tr></table></figure>
<p>You also can add <code>clean_requirements_on_remove=1</code> in <code>/etc/yum.conf</code> file, then run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum remove docker-ce</span><br></pre></td></tr></table></figure></p>
<p>the same effect as using <code>autoremove</code>.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>iTerm2 and Oh-My-Zsh Setup</title>
    <url>/2020/07/26/mac-iterm2-zsh/</url>
    <content><![CDATA[<p>This post primarily talks about how to setup efficient, beautiful theme emulator with oh-my-zsh.</p>
<p>Reference:<br><a href="https://gist.github.com/kevin-smets/8568070" target="_blank" rel="noopener">https://gist.github.com/kevin-smets/8568070</a></p>
<h1 id="Install-iTerm"><a href="#Install-iTerm" class="headerlink" title="Install iTerm"></a>Install iTerm</h1><p>Install iTerm2 on Mac<br><a href="https://www.iterm2.com/" target="_blank" rel="noopener">https://www.iterm2.com/</a></p>
<h2 id="Configure-iTerm2"><a href="#Configure-iTerm2" class="headerlink" title="Configure iTerm2"></a>Configure iTerm2</h2><p>Solarized Dark is bad for some syntax highlighting, to import other themes, download from there, zip file, you can put the downloaded folder to your home directory.<br><a href="https://iterm2colorschemes.com/" target="_blank" rel="noopener">https://iterm2colorschemes.com/</a></p>
<p>The theme I select is <code>Chalk</code>, import itermcolors file(s) in the scheme(s) directory:<br><img src="https://drive.google.com/uc?id=1YBwdxAjAG_V8IztiBAz0ePf01m0N6eS2" alt=""></p>
<p><img src="https://drive.google.com/uc?id=1Q6qoOp8xFw6wa-XxCLEUp0jG9NebV_7W" alt=""></p>
<p>此外，需要设置 Preference -&gt; Advanced -&gt; mouse -&gt;<br>Scroll wheel sends arrow keys when in alternate screen mode -&gt; yes<br>否则滑动光标vim的界面会 和 terminal 混合。</p>
<h2 id="iTerm2-Tips"><a href="#iTerm2-Tips" class="headerlink" title="iTerm2 Tips"></a>iTerm2 Tips</h2><ol>
<li><p><code>imgcat</code> script, presenting image in terminal:<br><a href="https://iterm2.com/documentation-images.html" target="_blank" rel="noopener">https://iterm2.com/documentation-images.html</a></p>
</li>
<li><p>Hotkeys, the floating half-transparent terminal window:<br>Preferences -&gt; Keys -&gt; Hotkey -&gt; Create a Dedicated Hotkey Window.<br>My custom hotkey is <code>ctrl + shift + t</code></p>
</li>
<li><p>locate the cursor: <code>command + /</code></p>
</li>
<li><p>send commands to all tabs and all sessions <code>shift + command + i</code>, abort use the same command.</p>
</li>
</ol>
<h1 id="Configure-Oh-My-Zsh"><a href="#Configure-Oh-My-Zsh" class="headerlink" title="Configure Oh My Zsh"></a>Configure Oh My Zsh</h1><p>Install <code>ohmyz</code> on Mac:<br>Mac zsh is pre-installed, you can check by:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zsh --version</span><br></pre></td></tr></table></figure></p>
<p>If not, <a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Installing-ZSH" target="_blank" rel="noopener">install zsh</a> first.<br>Then <a href="https://ohmyz.sh/#install" target="_blank" rel="noopener">install ohmyzsh</a>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sh -c <span class="string">"<span class="variable">$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>Then install <code>Powerlevel10k</code> theme, this theme is what exactly I need:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/romkatv/powerlevel10k.git <span class="variable">$ZSH_CUSTOM</span>/themes/powerlevel10k</span><br></pre></td></tr></table></figure></p>
<p>By default it uses <code>robbyrussell</code> theme, you can see it from <code>~/.zshrc</code> file, the theme files are located in <code>~/.oh-my-zsh/themes</code> folder<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Set name of the theme to load --- if set to "random", it will</span></span><br><span class="line"><span class="comment"># load a random theme each time oh-my-zsh is loaded, in which case,</span></span><br><span class="line"><span class="comment"># to know which specific one was loaded, run: echo $RANDOM_THEME</span></span><br><span class="line"><span class="comment"># See https://github.com/ohmyzsh/ohmyzsh/wiki/Themes</span></span><br><span class="line">ZSH_THEME=<span class="string">"powerlevel10k/powerlevel10k"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Which plugins would you like to load?</span></span><br><span class="line"><span class="comment"># Standard plugins can be found in $ZSH/plugins/</span></span><br><span class="line"><span class="comment"># Custom plugins may be added to $ZSH_CUSTOM/plugins/</span></span><br><span class="line"><span class="comment"># Example format: plugins=(rails git textmate ruby lighthouse)</span></span><br><span class="line"><span class="comment"># Add wisely, as too many plugins slow down shell startup.</span></span><br><span class="line">plugins=(git kubectl docker docker-compose gcloud)</span><br></pre></td></tr></table></figure></p>
<p>Others you may like <code>agnoster</code>:<br><a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Themes" target="_blank" rel="noopener">https://github.com/ohmyzsh/ohmyzsh/wiki/Themes</a></p>
<p>Next when you start a new terminal session, the <code>Powerlevel10</code> configure wizard will be launched to set your prompt, is will automatically check and install the font for you. When select encoding, choose <code>Unicode</code>, otherwise no icon will show.</p>
<p>If you want to reset the configuration, simply run:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">p10k configure</span><br></pre></td></tr></table></figure></p>
<p><code>Powerlevel10</code> project web page:<br><a href="https://github.com/romkatv/powerlevel10k#extremely-customizable" target="_blank" rel="noopener">https://github.com/romkatv/powerlevel10k#extremely-customizable</a></p>
<p>Then set <code>zsh</code> as the default shell` on Mac:<br><a href="https://askubuntu.com/questions/131823/how-to-make-zsh-the-default-shell" target="_blank" rel="noopener">https://askubuntu.com/questions/131823/how-to-make-zsh-the-default-shell</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chsh -s $(<span class="built_in">which</span> zsh)</span><br><span class="line"><span class="comment">## verify default shell setting</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$SHELL</span></span><br><span class="line"><span class="comment">## show current running shell</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$0</span></span><br></pre></td></tr></table></figure></p>
<p>After changing the theme, relaunch iTerm2.</p>
<p><code>~./zshrc</code> works the same as <code>~/.bashrc</code> for bash, append other alias here, append following snippet in <code>~/.zshrc</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">alias</span> cdd=<span class="string">'cd ~/Desktop'</span></span><br><span class="line"><span class="built_in">alias</span> kbc=<span class="string">'kubectl'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## docker</span></span><br><span class="line"><span class="comment">## docker</span></span><br><span class="line"><span class="built_in">alias</span> di=<span class="string">'docker images'</span></span><br><span class="line"><span class="built_in">alias</span> dp=<span class="string">'docker ps'</span></span><br><span class="line"><span class="built_in">alias</span> drp=<span class="string">'docker rm -f'</span></span><br><span class="line"><span class="built_in">alias</span> dri=<span class="string">'docker rmi -f'</span></span><br><span class="line"><span class="built_in">alias</span> dl=<span class="string">'docker logs -f'</span></span><br><span class="line"><span class="built_in">alias</span> drun=<span class="string">'docker run -d --name=test --restart=always'</span></span><br><span class="line"><span class="built_in">alias</span> db=<span class="string">'docker build'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> dexec()</span><br><span class="line">&#123;</span><br><span class="line">  sudo docker <span class="built_in">exec</span> -it <span class="variable">$1</span> bash</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> OC_EDITOR=vim</span><br><span class="line"><span class="built_in">export</span> KUBE_EDITOR=vim</span><br><span class="line"></span><br><span class="line"><span class="comment">## Keybind in Zsh</span></span><br><span class="line"><span class="comment">## Move forward/backward one word is not convenient here, need to be reconfigured</span></span><br><span class="line"><span class="built_in">bindkey</span> <span class="string">"^[^[[C"</span> forward-word</span><br><span class="line"><span class="built_in">bindkey</span> <span class="string">"^[^[[D"</span> backward-word</span><br><span class="line"><span class="built_in">bindkey</span> <span class="string">"^U"</span> backward-kill-line</span><br></pre></td></tr></table></figure></p>
<p>To list all shortcut in Zsh, run<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">bindkey</span></span><br></pre></td></tr></table></figure></p>
<p>Reference:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/3483604/which-shortcut-in-zsh-does-the-same-as-ctrl-u-in-bash" target="_blank" rel="noopener">Ctrl-u in Bash</a></li>
<li><a href="https://stackoverflow.com/questions/12382499/looking-for-altleftarrowkey-solution-in-zsh" target="_blank" rel="noopener">Zsh key codes</a></li>
</ul>
<p>Use <code>cat</code> command to see what exactly the key will present is a good idea.</p>
<h2 id="Other-Alternatives"><a href="#Other-Alternatives" class="headerlink" title="Other Alternatives"></a>Other Alternatives</h2><p>Understanding and Configuring Zsh:<br><a href="https://thevaluable.dev/zsh-install-configure/" target="_blank" rel="noopener">https://thevaluable.dev/zsh-install-configure/</a></p>
<p>Hyper.js + ZSH + starship:<br><a href="https://tjay.dev/howto-my-terminal-shell-setup-hyper-js-zsh-starship/" target="_blank" rel="noopener">https://tjay.dev/howto-my-terminal-shell-setup-hyper-js-zsh-starship/</a></p>
<h1 id="Bash-with-Starship"><a href="#Bash-with-Starship" class="headerlink" title="Bash with Starship"></a>Bash with Starship</h1><p>Still using iTerm2, if you want to stick to <code>Bash</code> shell, try this:</p>
<p>Starship: cross shell prompt.<br><a href="https://starship.rs/" target="_blank" rel="noopener">https://starship.rs/</a></p>
<p>Install by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -fsSL https://starship.rs/install.sh | bash</span><br></pre></td></tr></table></figure></p>
<p>After install, append this line in <code>~/.bashrc</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">eval</span> <span class="string">"<span class="variable">$(starship init bash)</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>My config file:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p ~/.config &amp;&amp; touch ~/.config/starship.toml</span><br></pre></td></tr></table></figure></p>
<p>My current <code>~/.config/starship.toml</code> file:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Disable the newline at the start of the prompt</span></span><br><span class="line">add_newline = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[line_break]</span><br><span class="line">disabled = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">[character]</span><br><span class="line">symbol = <span class="string">"➜"</span></span><br><span class="line">error_symbol = <span class="string">"✗"</span></span><br><span class="line">use_symbol_for_status = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[battery]</span><br><span class="line">full_symbol = <span class="string">"🔋"</span></span><br><span class="line">charging_symbol = <span class="string">"⚡️"</span></span><br><span class="line">discharging_symbol = <span class="string">"💀"</span></span><br><span class="line"></span><br><span class="line">[time]</span><br><span class="line">disabled = <span class="literal">false</span></span><br><span class="line">format = <span class="string">"🕙[ %T ]"</span></span><br><span class="line">utc_time_offset = <span class="string">"-5"</span></span><br><span class="line">time_range = <span class="string">"10:00:00-14:00:00"</span></span><br><span class="line"></span><br><span class="line">[directory]</span><br><span class="line">truncation_length = 8</span><br><span class="line"></span><br><span class="line"><span class="comment">## show virtual environments</span></span><br><span class="line">[python]</span><br><span class="line">disabled = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">[docker_context]</span><br><span class="line">disabled = <span class="literal">false</span></span><br><span class="line">symbol = <span class="string">"🐋 "</span></span><br><span class="line">only_with_files = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[kubernetes]</span><br><span class="line">symbol = <span class="string">"⛵ "</span></span><br><span class="line">style = <span class="string">"dimmed green"</span></span><br><span class="line">disabled = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">[terraform]</span><br><span class="line">symbol = <span class="string">"🏎💨 "</span></span><br><span class="line">disabled = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">[package]</span><br><span class="line">disabled = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[ruby]</span><br><span class="line">disabled = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[rust]</span><br><span class="line">disabled = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[nodejs]</span><br><span class="line">disabled = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[java]</span><br><span class="line">disabled = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line">[golang]</span><br><span class="line">disabled = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">[aws]</span><br><span class="line">disabled = <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## add more</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>iterm2</tag>
      </tags>
  </entry>
  <entry>
    <title>Yum and Rpm Management 101</title>
    <url>/2019/03/26/linux-yum-rpm-management/</url>
    <content><![CDATA[<p>OK, This article is a summary from IBM developer <a href="https://developer.ibm.com/tutorials/l-lpic1-102-5/" target="_blank" rel="noopener">Linux series</a> that contains something I haven’t realized and history information about YUM and RPM.</p>
<h3 id="Introducing-package-management"><a href="#Introducing-package-management" class="headerlink" title="Introducing package management"></a>Introducing package management</h3><p>In the past, many Linux programs were distributed as source code, which a user would build into the required program or set of programs, along with the required man pages, configuration files, and so on. Nowadays, most Linux distributors use prebuilt programs or sets of programs called <em>packages</em>, which ship ready for installation on that distribution. In this tutorial, you will learn about <em>package management tools</em> that help you install, update, and remove packages. This tutorial focuses on the <strong>Red Hat Package Manager (RPM)</strong>, which was developed by Red Hat, as well as the <strong>Yellowdog Updater Modified (YUM)</strong>, which was originally developed to manage Red Hat Linux systems at Duke University’s Physics department. Another tutorial in this series, “<a href="https://developer.ibm.com/tutorials/l-lpic1-102-4/" target="_blank" rel="noopener">Learn Linux 101: Debian package management</a>,” covers the package management tools used on Debian systems.</p>
<h3 id="Package-managers"><a href="#Package-managers" class="headerlink" title="Package managers"></a>Package managers</h3><p>RPM, YUM, and APT (for Debian systems) have many similarities. All can install and remove packages. Information about installed packages is kept in a database. All have basic command-line functionality, while additional tools can provide more user-friendly interfaces. All can retrieve packages from the Internet.</p>
<p>When you install a Linux system, you typically install a large selection of packages. The set may be customized to the intended use of the system, such as a server, desktop, or developer workstation. And at some time you will probably need to install new packages for added functionality, update the packages you have, or even remove packages that you no longer need or that have been made obsolete by newer packages. Let’s look at how you do these tasks, and at some of the related challenges such as finding which package might contain a particular command.</p>
<h4 id="RPM"><a href="#RPM" class="headerlink" title="RPM"></a>RPM</h4><p>Red Hat introduced RPM in 1995. RPM is now the package management system used for packaging in the Linux Standard Base (LSB). The rpm command options are grouped into three subgroups for:</p>
<ul>
<li>Querying and verifying packages</li>
<li>Installing, upgrading, and removing packages</li>
<li>Performing miscellaneous functions</li>
</ul>
<h4 id="YUM"><a href="#YUM" class="headerlink" title="YUM"></a>YUM</h4><p>YUM adds automatic updates and package management, including dependency management, to RPM systems. In addition to understanding the installed packages on a system, YUM is like the Debian Advanced Packaging Tool (APT) in that it works with repositories, which are collections of packages and are typically accessible over a network connection.</p>
<h3 id="Install-RPM-packages"><a href="#Install-RPM-packages" class="headerlink" title="Install RPM packages"></a>Install RPM packages</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@attic‑f21 ~rpm ‑i  gcc‑gfortran‑4.9.2‑6.fc21.x86_64.rpm </span><br><span class="line">error: Failed dependencies:</span><br><span class="line">    libquadmath‑devel = 4.9.2‑6.fc21 is needed by gcc‑gfortran‑4.9.2‑6.fc21.x86_64</span><br></pre></td></tr></table></figure>
<p>One good thing is that you can give the rpm command a list of packages to install and it will install them all in the right order if all dependencies are satisfied. So you at least don’t have to manually install each piece in the right order.</p>
<p><a href="https://unix.stackexchange.com/questions/158244/what-is-the-difference-between-i686-and-x86-64-packages" target="_blank" rel="noopener">What is the difference between i686 and x86_64 packages?</a><br>Technically, i686 is actually a 32-bit instruction set (part of the x86 family line), while x86_64 is a 64-bit instruction set (also referred to as amd64).</p>
<p>let’s see the yum install output in my machine:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">Local-Base                                                                                | 2.0 kB  00:00:00     </span><br><span class="line">Local-Extras                                                                              | 2.9 kB  00:00:00     </span><br><span class="line">Local-Optional                                                                            | 2.0 kB  00:00:00     </span><br><span class="line">Local-Supplementary                                                                       | 2.0 kB  00:00:00     </span><br><span class="line">(1/6): Local-Base/updateinfo                                                              | 3.2 MB  00:00:00     </span><br><span class="line">(2/6): Local-Supplementary/primary                                                        |  99 kB  00:00:00     </span><br><span class="line">(3/6): Local-Optional/updateinfo                                                          | 2.3 MB  00:00:00     </span><br><span class="line">(4/6): Local-Optional/primary                                                             | 5.0 MB  00:00:00     </span><br><span class="line">(5/6): Local-Supplementary/updateinfo                                                     |  69 kB  00:00:00     </span><br><span class="line">(6/6): Local-Base/primary                                                                 |  34 MB  00:00:00     </span><br><span class="line">Local-Base                                                                                           23907/23907</span><br><span class="line">Local-Optional                                                                                       17526/17526</span><br><span class="line">Local-Supplementary                                                                                      310/310</span><br><span class="line">Resolving Dependencies</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package vim-enhanced.x86_64 2:7.4.160-5.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: vim-common = 2:7.4.160-5.el7 for package: 2:vim-enhanced-7.4.160-5.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: libgpm.so.2()(64bit) for package: 2:vim-enhanced-7.4.160-5.el7.x86_64</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package gpm-libs.x86_64 0:1.20.7-5.el7 will be installed</span><br><span class="line">---&gt; Package vim-common.x86_64 2:7.4.160-5.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: vim-filesystem for package: 2:vim-common-7.4.160-5.el7.x86_64</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package vim-filesystem.x86_64 2:7.4.160-5.el7 will be installed</span><br><span class="line">--&gt; Finished Dependency Resolution</span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">=================================================================================================================</span><br><span class="line"> Package                      Arch                 Version                        Repository                Size</span><br><span class="line">=================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> vim-enhanced                 x86_64               2:7.4.160-5.el7                Local-Base               1.0 M</span><br><span class="line">Installing for dependencies:</span><br><span class="line"> gpm-libs                     x86_64               1.20.7-5.el7                   Local-Base                32 k</span><br><span class="line"> vim-common                   x86_64               2:7.4.160-5.el7                Local-Base               5.9 M</span><br><span class="line"> vim-filesystem               x86_64               2:7.4.160-5.el7                Local-Base                10 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">=================================================================================================================</span><br><span class="line">Install  1 Package (+3 Dependent packages)</span><br><span class="line"></span><br><span class="line">Total download size: 7.0 M</span><br><span class="line">Installed size: 23 M</span><br><span class="line"></span><br><span class="line">Is this ok [y/d/N]: y</span><br><span class="line">Downloading packages:</span><br><span class="line">(1/4): gpm-libs-1.20.7-5.el7.x86_64.rpm                                                   |  32 kB  00:00:00     </span><br><span class="line">(2/4): vim-enhanced-7.4.160-5.el7.x86_64.rpm                                              | 1.0 MB  00:00:00</span><br><span class="line">(3/4): vim-filesystem-7.4.160-5.el7.x86_64.rpm                                            |  10 kB  00:00:00</span><br><span class="line">(4/4): vim-common-7.4.160-5.el7.x86_64.rpm                                                | 5.9 MB  00:00:00</span><br><span class="line">-----------------------------------------------------------------------------------------------------------------</span><br><span class="line">Total                                                                             55 MB/s | 7.0 MB  00:00:00</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">Warning: RPMDB altered outside of yum.</span><br><span class="line">** Found 1 pre-existing rpmdb problem(s), &apos;yum check&apos; output follows:</span><br><span class="line">mokutil-15-1.el7.x86_64 is a duplicate with mokutil-12-1.el7.x86_64</span><br><span class="line">  Installing : gpm-libs-1.20.7-5.el7.x86_64                                                                  1/4</span><br><span class="line">  Installing : 2:vim-filesystem-7.4.160-5.el7.x86_64                                                         2/4</span><br><span class="line">  Installing : 2:vim-common-7.4.160-5.el7.x86_64                                                             3/4</span><br><span class="line">  Installing : 2:vim-enhanced-7.4.160-5.el7.x86_64                                                           4/4</span><br><span class="line">Local-Base/productid                                                                      | 2.1 kB  00:00:00</span><br><span class="line">Local-Supplementary/productid                                                             | 2.1 kB  00:00:00</span><br><span class="line">  Verifying  : 2:vim-enhanced-7.4.160-5.el7.x86_64                                                           1/4</span><br><span class="line">  Verifying  : 2:vim-common-7.4.160-5.el7.x86_64                                                             2/4</span><br><span class="line">  Verifying  : 2:vim-filesystem-7.4.160-5.el7.x86_64                                                         3/4</span><br><span class="line">  Verifying  : gpm-libs-1.20.7-5.el7.x86_64                                                                  4/4</span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  vim-enhanced.x86_64 2:7.4.160-5.el7</span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  gpm-libs.x86_64 0:1.20.7-5.el7    vim-common.x86_64 2:7.4.160-5.el7    vim-filesystem.x86_64 2:7.4.160-5.el7</span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure></p>
<p>Here we see yum find <code>x86_64</code> version of vim in <code>Local-Base</code> repository. Sometimes you will usually want the latest version of a package, but you can provide additional qualifications if you need an earlier version, or the <code>i686</code> version instead of the <code>x86_64</code> version. See the section on specifying package names in the man pages for the yum command.</p>
<h3 id="Package-locations"><a href="#Package-locations" class="headerlink" title="Package locations"></a>Package locations</h3><p>Where do the packages come from? How does yum know where to download packages from? The starting point is the <code>/etc/yum.repos.d/</code> directory, which usually contains several repo files. This is the default location for repository information, but other locations may be specified in the YUM configuration file, normally <code>/etc/yum.conf</code>. </p>
<p>In the Fyre machine, there is a <code>devit-rh7-x86_64.repo</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Base OS packages</span><br><span class="line">[Local-Base]</span><br><span class="line">name=Fyre Local OS repository</span><br><span class="line">baseurl=http://fyreyum1.fyre.ibm.com/redhat/yum/server/7/7Server/x86_64/os</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line"></span><br><span class="line">[Local-Supplementary]</span><br><span class="line">name=Fyre Local Supplementary repository</span><br><span class="line">baseurl=http://fyreyum1.fyre.ibm.com/redhat/yum/server/7/7Server/x86_64/supplementary/os</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line"></span><br><span class="line">[Local-Optional]</span><br><span class="line">name=Fyre Local Optional repository</span><br><span class="line">baseurl=http://fyreyum1.fyre.ibm.com/redhat/yum/server/7/7Server/x86_64/optional/os</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line"></span><br><span class="line">[Local-Extras]</span><br><span class="line">name=Fyre Local Extras repository</span><br><span class="line">baseurl=http://fyreyum1.fyre.ibm.com/redhat/yum/server/7/7Server/x86_64/extras/os</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br></pre></td></tr></table></figure></p>
<p>YUM and RPM use a local database to determine what packages are installed. The metadata about packages that is stored in the local database is retrieved from the enabled repositories. Although you will seldom need to worry about the local database, you use the command <code>yum clean all</code> to clean out various parts of the locally stored information and <code>yum makecache</code> to create the information in your local database for the enabled repos. You might do this if you change your repo configuration, for example.</p>
<h3 id="Removing-RPM-packages"><a href="#Removing-RPM-packages" class="headerlink" title="Removing RPM packages"></a>Removing RPM packages</h3><p>The RPM system does not maintain information on packages that were automatically added, so there is no trivial way to find out which dependencies might also be removed. </p>
<p>If you use YUM and if the package you are trying to remove is a <em>dependent package</em> for some other installed packages, then YUM will offer to remove those as well as the dependent package. (This is different from <code>yum autoremove</code>)</p>
<h3 id="Upgrading-RPM-packages"><a href="#Upgrading-RPM-packages" class="headerlink" title="Upgrading RPM packages"></a>Upgrading RPM packages</h3><p>You can use <code>yum update</code> to update your entire system, or you can specify a single package or a wildcard specification. Listing 8 shows how to update all the packages whose names start with “pop”. Note the use of apostrophes to prevent shell expansion of the “*”.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum update &apos;pop*&apos;</span><br></pre></td></tr></table></figure></p>
<p><a href="[https://unix.stackexchange.com/questions/55777/in-centos-what-is-the-difference-between-yum-update-and-yum-upgrade](https://unix.stackexchange.com/questions/55777/in-centos-what-is-the-difference-between-yum-update-and-yum-upgrade">what is the difference between yum update and yum upgrade?</a><br>)<br><code>yum upgrade</code> forces the removal of obsolete packages, while <code>yum update</code> may or may not also do this. The removal of obsolete packages can be risky, as it may remove packages that you use.<br>This makes <code>yum update</code> the safer option.</p>
<h3 id="Querying-RPM-packages"><a href="#Querying-RPM-packages" class="headerlink" title="Querying RPM packages"></a>Querying RPM packages</h3><p>In our examples you saw that installing an rpm with the <code>rpm</code> command requires the full name of the package file (or URL), such as <code>gcc-gfortran-4.9.2-6.fc21.x8664.rpm</code>. On the other hand, installing with <code>yum</code>, or removing an rpm with either command requires only the package name, such as <code>gcc-gfortran</code>. As with APT, YUM maintains an internal database of your installed packages, allowing you to manipulate installed packages using the package name.</p>
<p>Note that you need to have root authority to install, upgrade, or remove packages, but non-root users can perform queries against the rpm database.</p>
<p>Basic query asks if package is installed, if so, show version number:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mycentctl1 ~]# rpm -q bind-utils</span><br><span class="line">bind-utils-9.9.4-73.el7_6.x86_64</span><br><span class="line"></span><br><span class="line">[root@mycentctl1 ~]# rpm -q ansible</span><br><span class="line">package ansible is not installed</span><br><span class="line"></span><br><span class="line">[root@mycentctl1 ~]# yum list bind-utils</span><br><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">Installed Packages</span><br><span class="line">bind-utils.x86_64                                    32:9.9.4-73.el7_6                                    @Local-Base</span><br><span class="line"></span><br><span class="line">[root@mycentctl1 ~]# yum list ansible</span><br><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">Available Packages</span><br><span class="line">ansible.noarch                                       2.4.2.0-2.el7                                       Local-Extras</span><br></pre></td></tr></table></figure></p>
<p>Display info about a package:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mycentctl1 ~]# yum info bind-utils</span><br><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">Installed Packages</span><br><span class="line">Name        : bind-utils</span><br><span class="line">Arch        : x86_64</span><br><span class="line">Epoch       : 32</span><br><span class="line">Version     : 9.9.4</span><br><span class="line">Release     : 73.el7_6</span><br><span class="line">Size        : 431 k</span><br><span class="line">Repo        : installed</span><br><span class="line">From repo   : Local-Base</span><br><span class="line">Summary     : Utilities for querying DNS name servers</span><br><span class="line">URL         : http://www.isc.org/products/BIND/</span><br><span class="line">License     : ISC</span><br><span class="line">Description : Bind-utils contains a collection of utilities for querying DNS (Domain</span><br><span class="line">            : Name System) name servers to find out information about Internet</span><br><span class="line">            : hosts. These tools will provide you with the IP addresses for given</span><br><span class="line">            : host names, as well as other information about registered domains and</span><br><span class="line">            : network addresses.</span><br><span class="line">            :</span><br><span class="line">            : You should install bind-utils if you need to get information from DNS name</span><br><span class="line">            : servers.</span><br></pre></td></tr></table></figure></p>
<p>Search package names and descriptions for a term<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mycentctl1 ~]# yum search vim</span><br><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">================================================= N/S matched: vim ==================================================</span><br><span class="line">golang-vim.noarch : Vim plugins for Go</span><br><span class="line">protobuf-vim.x86_64 : Vim syntax highlighting for Google Protocol Buffers descriptions</span><br><span class="line">vim-X11.x86_64 : The VIM version of the vi editor for the X Window System</span><br><span class="line">vim-common.x86_64 : The common files needed by any version of the VIM editor</span><br><span class="line">vim-enhanced.x86_64 : A version of the VIM editor which includes recent enhancements</span><br><span class="line">vim-filesystem.x86_64 : VIM filesystem layout</span><br><span class="line">vim-minimal.x86_64 : A minimal version of the VIM editor</span><br><span class="line"></span><br><span class="line">  Name and summary matches only, use &quot;search all&quot; for everything.</span><br></pre></td></tr></table></figure></p>
<h3 id="RPM-packages-and-files-in-them"><a href="#RPM-packages-and-files-in-them" class="headerlink" title="RPM packages and files in them"></a>RPM packages and files in them</h3><p>List the files inside the package, you will see <code>host</code> command is here:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mycentctl1 ~]# rpm -ql bind-utils</span><br><span class="line">/etc/trusted-key.key</span><br><span class="line">/usr/bin/dig</span><br><span class="line">/usr/bin/host</span><br><span class="line">/usr/bin/nslookup</span><br><span class="line">/usr/bin/nsupdate</span><br><span class="line">/usr/share/man/man1/dig.1.gz</span><br><span class="line">/usr/share/man/man1/host.1.gz</span><br><span class="line">/usr/share/man/man1/nslookup.1.gz</span><br><span class="line">/usr/share/man/man1/nsupdate.1.gz</span><br></pre></td></tr></table></figure></p>
<p>if you have a download package and want to know the files in it, <code>-p</code> means package:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mycentctl1 ~]# rpm -qlp jq-1.5-1.el7.x86_64.rpm</span><br><span class="line">warning: jq-1.5-1.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 352c64e5: NOKEY</span><br><span class="line">/usr/bin/jq</span><br><span class="line">/usr/lib64/libjq.so.1</span><br><span class="line">/usr/lib64/libjq.so.1.0.4</span><br><span class="line">/usr/share/doc/jq/AUTHORS</span><br><span class="line">/usr/share/doc/jq/COPYING</span><br><span class="line">/usr/share/doc/jq/README</span><br><span class="line">/usr/share/doc/jq/README.md</span><br><span class="line">/usr/share/man/man1/jq.1.gz</span><br></pre></td></tr></table></figure></p>
<h3 id="Which-package-owns-a-file"><a href="#Which-package-owns-a-file" class="headerlink" title="Which package owns a file?"></a>Which package owns a file?</h3><p>For YUM:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum provides vim</span><br></pre></td></tr></table></figure></p>
<p>For RPM:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -qf `which vim`</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka Quick Start</title>
    <url>/2020/11/27/message-kafka-learn/</url>
    <content><![CDATA[<p>[x] Kafka cluster communicate, how does the client know who is the leader? Ask zk, leader is partition based.<br>[x] producer send message to which topic partition? depends on event key (hash).<br>[x] topic has its own set of partitions, each partiton is assigned subset of coming events.<br>[x] how to ensure the message order that treats entire topic as a whole? cannot, but order is guarantee in partition.<br>[x] run as daemon</p>
<p>The Vagrant demo file please see my git repo <a href="https://github.com/chengdol/InfraTree/tree/master/vagrant-zk-kafka" target="_blank" rel="noopener">Infratree</a>, reading with <a href="https://chengdol.github.io/2020/11/27/message-zookeeper-learn/" target="_blank" rel="noopener"><code>Zookeeper Quick Start</code></a></p>
<p>I took the course from PluralSight and Udemy, both are good, Udemy course is some what out-of-date.<br>Pluralsight deploy Kafka cluster course uses java with gradle to run demos, the kafka and zookeeper are deployed as docker containers in <code>docker-compose</code>, Here I use Vagrant.</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><a href="https://zhuanlan.zhihu.com/p/37405836" target="_blank" rel="noopener">Kafka简明教程</a><br><a href="https://sookocheff.com/post/kafka/kafka-in-a-nutshell/" target="_blank" rel="noopener">Kafka in a Nutshell</a><br><a href="http://kafka.apache.org/" target="_blank" rel="noopener">Apach Kafka Official Doc</a><br><a href="https://www.ibm.com/cloud/learn/apache-kafka" target="_blank" rel="noopener">Learn Kafka Guide</a></p>
<p>Youtube Kafka talks:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=aj9CDZm0Glc" target="_blank" rel="noopener">https://www.youtube.com/watch?v=aj9CDZm0Glc</a></li>
<li><a href="https://www.youtube.com/watch?v=06iRM1Ghr1k" target="_blank" rel="noopener">https://www.youtube.com/watch?v=06iRM1Ghr1k</a></li>
</ul>
<p>Note that message ordering for the entire topic is not guaranteed.<br>Producers and consumers are both kafka clients.</p>
<p>Terms:</p>
<ul>
<li>topic (data send to or read from)</li>
<li>producer (generate data)</li>
<li>consumer (read data)</li>
<li>broker (node in cluster)</li>
<li>partition (divided from a topic)</li>
</ul>
<p>A topic is similar to a folder in a filesystem, and the events are the files in that folder. An example topic name could be “payments”. Topics in Kafka are always multi-producer and multi-subscriber: a topic can have zero, one, or many producers that write events to it, as well as zero, one, or many consumers that subscribe to these events.</p>
<p>Topics are partitioned, meaning a topic is spread over a number of “buckets” located on different Kafka brokers. This distributed placement of your data is very important for scalability because it allows client applications to both read and write the data from/to many brokers at the same time. When a new event is published to a topic, it is actually appended to <code>one</code> of the topic’s partitions. Events with the same event key (e.g., a customer or vehicle ID) are written to the same partition, Kafka guarantees that any consumer of a given <code>topic-partition</code> will always read that partition’s events in exactly the same order as they were written.</p>
<p>Kafka clents have 3 different levels of consistency, see <code>Consistency as a Kafka Client</code> in <a href="https://sookocheff.com/post/kafka/kafka-in-a-nutshell/" target="_blank" rel="noopener">Kafka in a Nutshell</a>.</p>
<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><p>Producer sends event to broker and broker places the event in one of the partitions.<br>比如这里有3个partitions, 2个consumers 在一个consumer group中，则consumer2 会对应到p2, p3读取事件，如果后来增加一个consumer3在这个consumer group中，则kafka 会partition rebalance p2 或 p3 到新增的消费者中，于是就变成了每个consumer 对应一个partiton。这样处理就不会因为consumer 数量的变化而导致event被重复读取或者没有被处理，也增加了throughput. </p>
<p>如果# of consumer &gt; # of partition 则多余的consumer 被闲置了，因此partition 的数量几乎决定了consumer 可有的最大数量。<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">                              <span class="string">broker</span>              <span class="string">consumer</span> <span class="string">group</span></span><br><span class="line">                        <span class="string">+---------------+</span>        <span class="string">+------------+</span></span><br><span class="line">                        <span class="string">|  partition1---|--------|-&gt;consumer1 |</span></span><br><span class="line"><span class="string">           (batch send) |/              |        |            |</span></span><br><span class="line"><span class="string">producer --------------&gt;|- partition2---|--------|-&gt;consumer2 |</span></span><br><span class="line"><span class="string">                        |\              |        |/           |</span></span><br><span class="line"><span class="string">                        |  partition3---|--------|            |</span></span><br><span class="line"><span class="string">                        +---------------+        +------------+</span></span><br></pre></td></tr></table></figure></p>
<p>关于event送到哪个partition是producer中key 决定的，所以如何选择key 很重要，它决定了送到partition 中的event 数量是否平衡，还要注意，kafka event order matters only within a single partition. 所以如果要保证某一类event 的顺序，则需要把它们划分到同一个partition中。Custom partitioning is possible and is reserved for special cases.</p>
<h2 id="Producer"><a href="#Producer" class="headerlink" title="Producer"></a>Producer</h2><p>Producer 中的message 在send前其实是到了一个buffer，然后满足一定条件再batch send, 可以设置batch size，compression等。This is a tradeoff between latency and throughput.</p>
<p>In kafka host data folder, partitions are stored here. 可以通过设置batch size大小去观察固定数量的event增加的空间大小，一般batch size越大，越节约broker的disk space.</p>
<h2 id="Consumer"><a href="#Consumer" class="headerlink" title="Consumer"></a>Consumer</h2><p>Offset<br>Heart beat for health checking</p>
<h2 id="High-Availability"><a href="#High-Availability" class="headerlink" title="High Availability"></a>High Availability</h2><p>New Kafka node will register itself via zookeeper and learn about other broker in the cluster. In production zookeeper usually has 3 ~ 5 nodes to form a cluster. Kafka broker will discover each other through zookeeper.</p>
<p>Producer should set acks to receive ack from broker for message comitted.</p>
<h2 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h2><p>It is related to disk I/O, network, RAM, CPU, OS, etc.</p>
<p><code>export KAFKA_HEAP_OPTS=&quot;-Xmx4g&quot;</code>, to set the Java heap size for Kafka (max amount), then start the Kafka. You can monitor the heap size overtime, increase it if needed.</p>
<p>Make sure swapping is disabled for Kafka entirely.</p>
<p>Increase the file descriptor limits on your linux, at least 100,000 as a starting point.</p>
<p>Run Kafka only on your macine, anything else will slow down the machine.</p>
<h1 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h1><h2 id="Single-node"><a href="#Single-node" class="headerlink" title="Single node"></a>Single node</h2><p>Use one Vanguard VM with Java pre-installed to do the expirement:<br><a href="http://kafka.apache.org/quickstart" target="_blank" rel="noopener">http://kafka.apache.org/quickstart</a><br>not using the self-contained zookeeper:<br><a href="https://dzone.com/articles/kafka-setup" target="_blank" rel="noopener">https://dzone.com/articles/kafka-setup</a></p>
<h2 id="Cluster-Setup"><a href="#Cluster-Setup" class="headerlink" title="Cluster Setup"></a>Cluster Setup</h2><p>Follow up the zk cluster setup, I use the same cluster nodes, kafka version is <code>2.6.0</code>.<br>3 node IPs, sudo su to use root user.<br><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// zk leader or follower not reflect real scenario</span></span><br><span class="line"></span><br><span class="line">  <span class="number">192.168</span><span class="number">.20</span><span class="number">.20</span>        <span class="number">192.168</span><span class="number">.20</span><span class="number">.21</span>         <span class="number">192.168</span><span class="number">.20</span><span class="number">.22</span></span><br><span class="line">|--------------|    |-----------------|    |----------------|</span><br><span class="line">| zk server1&lt;--|----|--&gt; zk server2&lt;--|----|--&gt;zk server3   | </span><br><span class="line">|  follower    |    |     leader      |    |    follower    |</span><br><span class="line">|              |    |     <span class="regexp">/  |  \     |    |                |</span></span><br><span class="line"><span class="regexp">|              |    |    /</span>   |   \    |    |                |</span><br><span class="line">|           <span class="regexp">/--|----|---/</span>    |    \---|----|--\             |</span><br><span class="line">|  kafka   /   |    |    kafka        |    |   \kafka       |</span><br><span class="line">|  broker1     |    |    broker2      |    |    broker3     |</span><br><span class="line">|--------------|    |-----------------|    |----------------|</span><br></pre></td></tr></table></figure></p>
<p>Kafka archive download <a href="https://archive.apache.org/dist/kafka" target="_blank" rel="noopener">link</a>.</p>
<p>Download kafka binary and untar:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget -q https://mirrors.sonic.net/apache/kafka/2.6.0/kafka_2.12-2.6.0.tgz</span><br><span class="line">tar -zxf kafka_2.12-2.6.0.tgz</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /root/kafka_2.12-2.6.0/config</span><br></pre></td></tr></table></figure></p>
<p>Create custom <code>log.dir</code> folder, update in configuration file:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/kafka/<span class="built_in">log</span></span><br></pre></td></tr></table></figure></p>
<p>Updates <code>zookeeper.connect</code>, <code>num.partitions</code> and <code>log.dir</code>. they are the same for all brokers.<br><code>broker.id</code> and <code>advertised.listeners</code>, these two need to be unique for each broker, this is not a exhausted list, more info see <a href="https://kafka.apache.org/documentation/#configuration" target="_blank" rel="noopener">here</a>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">############################# Server Basics #############################</span></span><br><span class="line"><span class="comment"># The id of the broker. This must be set to a unique integer for each broker.</span></span><br><span class="line">broker.id=1</span><br><span class="line"></span><br><span class="line"><span class="comment"># delete topic enable, default is true</span></span><br><span class="line">delete.topic.enable=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">############################# Socket Server Settings #############################</span></span><br><span class="line"><span class="comment"># Hostname and port the broker will advertise to producers and consumers. If not set,</span></span><br><span class="line"><span class="comment"># it uses the value for "listeners" if configured.  Otherwise, it will use the value</span></span><br><span class="line"><span class="comment"># returned from java.net.InetAddress.getCanonicalHostName().</span></span><br><span class="line">advertised.listeners=PLAINTEXT://192.168.20.20:9092</span><br><span class="line"></span><br><span class="line"><span class="comment">############################# Zookeeper #############################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Zookeeper connection string (see zookeeper docs for details).</span></span><br><span class="line"><span class="comment"># This is a comma separated host:port pairs, each corresponding to a zk</span></span><br><span class="line"><span class="comment"># server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".</span></span><br><span class="line"><span class="comment"># You can also append an optional chroot string to the urls to specify the</span></span><br><span class="line"><span class="comment"># root directory for all kafka znodes.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># /kafka的作用就是把所有kafka相关的folder都放在zk的kafka目录下, 从zk CLI中可以看到</span></span><br><span class="line"><span class="comment"># zookeeper.connect=192.168.20.20:2181,192.168.20.21:2181,192.168.20.22:2181/kafka</span></span><br><span class="line">zookeeper.connect=192.168.20.20:2181,192.168.20.21:2181,192.168.20.22:2181</span><br><span class="line"></span><br><span class="line"><span class="comment">############################# Log Basics #############################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># A comma separated list of directories under which to store log files</span></span><br><span class="line">log.dirs=/root/kafka/<span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The default number of log partitions per topic. More partitions allow greater</span></span><br><span class="line"><span class="comment"># parallelism for consumption, but this will also result in more files across</span></span><br><span class="line"><span class="comment"># the brokers.</span></span><br><span class="line"><span class="comment"># 指的是每个topic 分成多少份partition</span></span><br><span class="line">num.partitions=5</span><br><span class="line"></span><br><span class="line"><span class="comment"># default replication factors for automatically created topics</span></span><br><span class="line"><span class="comment"># 3 brokers, can be 2 or 3</span></span><br><span class="line"><span class="comment"># 指的是每个partition 都多少备份, 小于或等于 broker的个数</span></span><br><span class="line">default.replication.factor=3</span><br><span class="line"></span><br><span class="line"><span class="comment"># specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.</span></span><br><span class="line">min.insync.replicas=2</span><br><span class="line"><span class="comment"># The number of acknowledgments the producer requires the leader to have received before considering a request complete.</span></span><br><span class="line"><span class="comment"># 0, 1, all, -1, default is 1</span></span><br><span class="line">acks=1</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/kafka_2.12-2.6.0</span><br><span class="line"><span class="comment"># create a log file</span></span><br><span class="line">touch /root/kafka/run.log</span><br><span class="line"><span class="comment"># start kafka</span></span><br><span class="line">bin/kafka-server-start.sh config/server.properties &gt; /root/kafka/run.log 2&gt;1 &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment"># or run as daemon</span></span><br><span class="line">bin/kafka-server-start.sh -daemon config/server.properties</span><br><span class="line"><span class="comment"># stop kafka</span></span><br><span class="line">bin/kafka-server-stop.sh</span><br></pre></td></tr></table></figure>
<p>Kafka log is configured by <code>conf/log4j.properties</code>, by default is under <code>&lt;kafka package&gt;/logs/server.log</code> file.</p>
<p>Create and output topic description, can run in anyone of the nodes, <code>localhost</code> can be one of the broker IPs or list of IPs combination, separate by comma. In old version you use the <code>--zookeeper</code> option to list all zk <a href="ip:port" target="_blank" rel="noopener">ip:port</a> or <a href="ip:port" target="_blank" rel="noopener">ip:port</a>/kafka(if you use chroot).</p>
<p>如果想从外部connect kafka broker, <code>advertised.listeners</code> 必须使用public IP or DNS hostname, 如果用集群内部的private IP 或者 localhost 则外部不能访问了。</p>
<p>partition number and replic factor在command都可以override default的。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create topic</span></span><br><span class="line"><span class="comment"># --bootstrap-server: Kafka server to connect to</span></span><br><span class="line">bin/kafka-topics.sh --create --topic <span class="built_in">test</span> --bootstrap-server localhost:9092</span><br><span class="line"><span class="comment"># verify</span></span><br><span class="line">bin/kafka-topics.sh --list --bootstrap-server localhost:9092</span><br><span class="line"><span class="comment"># topic verbose</span></span><br><span class="line">bin/kafka-topics.sh --describe --topic <span class="built_in">test</span> --bootstrap-server localhost:9092</span><br><span class="line"></span><br><span class="line"><span class="comment"># delete topic</span></span><br><span class="line"><span class="comment"># delete.topic.enable=true by default</span></span><br><span class="line"><span class="comment"># deletion is not reversible</span></span><br><span class="line">bin/kafka-topics.sh --delete --topic <span class="built_in">test</span> --bootstrap-server localhost:9092</span><br></pre></td></tr></table></figure></p>
<p>Producer and consumer, can run on anyone of the nodes:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># produce message </span></span><br><span class="line">bin/kafka-console-producer.sh --topic <span class="built_in">test</span> --bootstrap-server localhost:9092</span><br><span class="line"><span class="comment"># consume message</span></span><br><span class="line"><span class="comment"># --from-beginning: read from beginning</span></span><br><span class="line">bin/kafka-console-consumer.sh --topic <span class="built_in">test</span> --from-beginning --bootstrap-server localhost:9092</span><br></pre></td></tr></table></figure></p>
<p>Update topic settings:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># partition number can only be increase</span></span><br><span class="line">bin/kafka-topics.sh --bootstrap-server localhost:9092 --alter --topic <span class="built_in">test</span> --partitions 4</span><br></pre></td></tr></table></figure></p>
<p>How to know all Kafka brokers are ready and running? Can check with zk ephemeral node, see <a href="https://stackoverflow.com/questions/37920923/how-to-check-whether-kafka-server-is-running" target="_blank" rel="noopener">here</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> dump | nc localhost 2181 | grep brokers</span><br></pre></td></tr></table></figure></p>
<h2 id="Perf-Test"><a href="#Perf-Test" class="headerlink" title="Perf Test"></a>Perf Test</h2><p>To see the kafka resiliency, we can have a perf test:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># generate 10KB of random data</span></span><br><span class="line">base64 /dev/urandom | head -c 10000 | egrep -ao <span class="string">"\w"</span> | tr -d <span class="string">'\n'</span> &gt; file10KB.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># in a new shell: start a continuous random producer</span></span><br><span class="line">./kafka-producer-perf-test.sh --topic perf \</span><br><span class="line">    --num-records 10000 \</span><br><span class="line">    --throughput 10 \</span><br><span class="line">    --payload-file file10KB.txt \</span><br><span class="line">    --producer-props acks=1 bootstrap.servers=localhost:9092 \</span><br><span class="line">    --payload-delimiter A</span><br><span class="line"></span><br><span class="line"><span class="comment"># in a new shell: start a consumer</span></span><br><span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic perf</span><br><span class="line"></span><br><span class="line"><span class="comment"># then do:</span></span><br><span class="line"><span class="comment"># kill one kafka server</span></span><br><span class="line"><span class="comment"># kill another kafka server</span></span><br><span class="line"><span class="comment"># kill the last server</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># start back the servers one by one</span></span><br></pre></td></tr></table></figure></p>
<p>Then open another terminal to consume the data, meanwhile go to kill the kafka broker one by one to see the result.</p>
<h2 id="Kafka-Manager"><a href="#Kafka-Manager" class="headerlink" title="Kafka Manager"></a>Kafka Manager</h2><p>There is a open source Web UI tool for managing Kafka cluster, <a href="https://github.com/yahoo/CMAK" target="_blank" rel="noopener">CMAK</a>.<br>You can build a docker image of it.</p>
<p>From README, it does not support recent Kafka version.</p>
<h1 id="Run-as-Daemon"><a href="#Run-as-Daemon" class="headerlink" title="Run as Daemon"></a>Run as Daemon</h1><p>Similar to Zookeeper daemon set. Set Kafka as system daemon so that it will be launched every time system boots.</p>
<p>For example, generate service file <code>kafka.service</code> in <code>/etc/systemd/system</code> folder.<br>Double curly brackets is placeholder in jinja2 template.<br><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=Apache Kafka server (broker)</span><br><span class="line"><span class="attr">Documentation</span>=http://kafka.apache.org/documentation.html</span><br><span class="line"><span class="comment"># after zookeeper is up</span></span><br><span class="line"><span class="attr">After</span>=network-<span class="literal">on</span>line.target consul.service zookeeper-server.service dnsmasq.service</span><br><span class="line"><span class="attr">StartLimitInterval</span>=<span class="number">200</span></span><br><span class="line"><span class="attr">StartLimitBurst</span>=<span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="section">[Service]</span></span><br><span class="line"><span class="comment"># long-runing without forking</span></span><br><span class="line"><span class="attr">Type</span>=simple</span><br><span class="line"><span class="attr">User</span>=&#123;&#123; kafka_user &#125;&#125;</span><br><span class="line"><span class="attr">Group</span>=&#123;&#123; kafka_group &#125;&#125;</span><br><span class="line"><span class="comment"># start, stop</span></span><br><span class="line"><span class="attr">ExecStart</span>=/opt/kafka/bin/kafka-server-start.sh &#123;&#123; kafka_conf_dir &#125;&#125;/server.properties</span><br><span class="line"><span class="attr">ExecStop</span>=/opt/kafka/bin/kafka-server-stop.sh</span><br><span class="line"></span><br><span class="line"><span class="attr">OOMScoreAdjust</span>=-<span class="number">500</span></span><br><span class="line"><span class="attr">Restart</span>=<span class="literal">on</span>-failure</span><br><span class="line"><span class="attr">RestartSec</span>=<span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="attr">WantedBy</span>=multi-user.target</span><br></pre></td></tr></table></figure></p>
<p>More detail about <code>systemd</code> please search and see my systemd blog.</p>
<p>Then you must enable kafka starts on boot:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line"><span class="comment"># enable start on boot</span></span><br><span class="line">systemctl <span class="built_in">enable</span> kafka</span><br></pre></td></tr></table></figure></p>
<p>Other systemd commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start kafka</span><br><span class="line">systemctl stop kafka</span><br><span class="line">systemctl restart kafka</span><br><span class="line"></span><br><span class="line"><span class="comment"># reload config without restart</span></span><br><span class="line">systemctl reload kafka</span><br><span class="line"><span class="comment"># first try relaod, if not supports then restart</span></span><br><span class="line">systemctl reload-or-restart kafka</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Copy &amp; Paste in Terminal</title>
    <url>/2019/01/27/mac-copy-paste/</url>
    <content><![CDATA[<p>Mac provides the command line for copy and paste, useful for some tasks.</p>
<blockquote>
<p>refer link：<a href="http://osxdaily.com/2007/03/05/manipulating-the-clipboard-from-the-command-line/" target="_blank" rel="noopener">http://osxdaily.com/2007/03/05/manipulating-the-clipboard-from-the-command-line/</a></p>
</blockquote>
<h2 id="Copy"><a href="#Copy" class="headerlink" title="Copy"></a>Copy</h2><p>copy the content of the file<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pbcopy &lt; file.txt</span><br></pre></td></tr></table></figure></p>
<p>now the content is in clipboard, ready to be pasted</p>
<blockquote>
<p>you can use pipe to combine command such as <code>find</code>,<code>grep</code>, <code>awk</code> and <code>cut</code> to filter and aggregate data.</p>
</blockquote>
<p>for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker images | grep <span class="string">"iis-"</span> | pbcopy</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"this is a demo"</span> | pbcopy</span><br></pre></td></tr></table></figure>
<h2 id="Paste"><a href="#Paste" class="headerlink" title="Paste"></a>Paste</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pbpaste</span><br></pre></td></tr></table></figure>
<p>redirect content to a file<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pbpaste &gt; file.txt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pbpaste | grep <span class="string">"xxx"</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Record Sounds in Mac</title>
    <url>/2019/12/28/mac-record-sounds/</url>
    <content><![CDATA[<p>How to capture the sounds coming from your Mac (with or without mixing the sounds from microphone):<br><a href="https://www.youtube.com/watch?v=dNYZOaf3Gvs" target="_blank" rel="noopener">https://www.youtube.com/watch?v=dNYZOaf3Gvs</a></p>
<p>Basically we need to install a plug-in <strong>Soundflower</strong>, download from <a href="https://www.youtube.com/redirect?q=http%3A%2F%2Fwww.fluxforge.com%2Fvector%2Fsoundflower_2.0b2.zip&amp;redir_token=FiOR4FxaoCa04ud_rckRAjoXlSd8MTU3NzY4OTE1N0AxNTc3NjAyNzU3&amp;v=dNYZOaf3Gvs&amp;event=video_description" target="_blank" rel="noopener">here</a>.</p>
<p>After downloading the zip folder, double click to install <code>Soundflower.pkg</code>(you may need to grant the privilege from system perference).</p>
<p>Open <strong>Audio MIDI Setup</strong>:</p>
<ol>
<li><p>Create a <code>Aggregate Device</code>, name it <code>Quicktime Player Input</code><br>Check <code>soundflower 2ch</code> and <code>Built-in Microphone</code>, clock source uses <code>Built-in Microphone</code>.</p>
</li>
<li><p>Create <code>Multi-Output Device</code>, name it <code>Screen Record w/ Audio</code><br>Check <code>soundflower 2ch</code> and <code>Built-in Output</code>, clock source uses <code>Built-in Output</code>.</p>
</li>
</ol>
<p>Before recording, go to system preference <code>Sound</code>, in <code>Output</code> section, select <code>Screen Record w/ Audio</code>. Then open <strong>Quicktime Player</strong> new audio or screen recording:</p>
<ol>
<li>If only wants to capture internal audio, in the drop-down menu select <code>soundflow (2ch)</code></li>
<li>If wants to capture internal/outside audio, select <code>Quicktime Player Input</code></li>
</ol>
<p>After recording is done, set back to <code>Headphones</code> in system preference <code>Sound</code>.</p>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper Quick Start</title>
    <url>/2020/11/27/message-zookeeper-learn/</url>
    <content><![CDATA[<p>The Vagrant demo file please see my git repo <a href="https://github.com/chengdol/InfraTree/tree/master/vagrant-zk-kafka" target="_blank" rel="noopener">Infratree</a> </p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Zookeeper quorum architecture, at least 3 nodes cluster setup via Vagrant for Kafka use.<br>Hght level information about zk:</p>
<ul>
<li>distributed key value store</li>
<li>has voting mechanism</li>
<li>used by many big data tools</li>
</ul>
<p><a href="https://www.quora.com/What-is-the-actual-role-of-Zookeeper-in-Kafka-What-benefits-will-I-miss-out-on-if-I-don%E2%80%99t-use-Zookeeper-and-Kafka-together" target="_blank" rel="noopener">Zookeeper role in Kafka</a>: </p>
<ul>
<li>broker registration, heart-beating check</li>
<li>maintaining a list of topics alongside</li>
<li>leader election</li>
<li>store kafka cluster id</li>
<li>store ACLs if security is enabled</li>
<li>quotas config if enabled</li>
</ul>
<p>使用kafka自带的zookeeper 还是 独立的zookeeper呢？见这个<a href="https://segmentfault.com/q/1010000021110446/a-1020000021113974" target="_blank" rel="noopener">回答</a>参考. 工作项目中还是用的独立的zk. Zookeeper is going to be removed from kafka, see this <a href="https://www.confluent.io/blog/removing-zookeeper-dependency-in-kafka/" target="_blank" rel="noopener">article</a>.</p>
<p>More references please see <a href="https://zookeeper.apache.org/" target="_blank" rel="noopener">Zookeeper main page</a>.<br><a href="https://zookeeper.apache.org/doc/r3.6.2/zookeeperAdmin.html#sc_systemReq" target="_blank" rel="noopener">System Requirements</a> for version <code>3.6.2</code>: ZooKeeper (also Kafka) runs in <code>Java</code>, release 1.8 or greater (JDK 8 LTS, JDK 11 LTS, JDK 12 - Java 9 and 10 are not supported).</p>
<p>Archive download <a href="https://archive.apache.org/dist/zookeeper/" target="_blank" rel="noopener">link</a>. For example, here uses Zookeeper version <code>3.6.2</code>.</p>
<h1 id="Performance-Factors"><a href="#Performance-Factors" class="headerlink" title="Performance Factors"></a>Performance Factors</h1><p>Latency is key for zookeeper:</p>
<ul>
<li>fast disk</li>
<li>no RAM swap</li>
<li>separate disk for snapshots and logs</li>
<li>high performance network</li>
<li>resonable number of zk servers</li>
<li>isolation zk process from others</li>
</ul>
<h1 id="Cluster-Setup"><a href="#Cluster-Setup" class="headerlink" title="Cluster Setup"></a>Cluster Setup</h1><h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p><a href="https://zookeeper.apache.org/doc/r3.6.2/zookeeperAdmin.html" target="_blank" rel="noopener">Clustered (Multi-Server) Setup</a>.<br>这里面说了很多注意事项, 比如Java heap size to avoid swapping or disable swapping.</p>
<p>The architecture diagram of this experiment, co-locate zk and kafka in the same node, this is not recommended on production.<br><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// zk leader can be anyone of them</span></span><br><span class="line"></span><br><span class="line">  <span class="number">192.168</span><span class="number">.20</span><span class="number">.20</span>        <span class="number">192.168</span><span class="number">.20</span><span class="number">.21</span>         <span class="number">192.168</span><span class="number">.20</span><span class="number">.22</span></span><br><span class="line">|--------------|    |-----------------|    |----------------|</span><br><span class="line">| zk server1&lt;--|----|--&gt; zk server2&lt;--|----|--&gt;zk server3   | </span><br><span class="line">|  follower    |    |     leader      |    |    follower    |</span><br><span class="line">|              |    |     <span class="regexp">/  |  \     |    |                |</span></span><br><span class="line"><span class="regexp">|              |    |    /</span>   |   \    |    |                |</span><br><span class="line">|           <span class="regexp">/--|----|---/</span>    |    \---|----|--\             |</span><br><span class="line">|  kafka   /   |    |    kafka        |    |   \kafka       |</span><br><span class="line">|  broker1     |    |    broker2      |    |    broker3     |</span><br><span class="line">|--------------|    |-----------------|    |----------------|</span><br></pre></td></tr></table></figure></p>
<h2 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h2><p>Generate <code>zoo.cfg</code> file in each node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># download release binary version 3.6.2</span></span><br><span class="line"><span class="built_in">cd</span> /root</span><br><span class="line">wget https://archive.apache.org/dist/zookeeper/zookeeper-3.6.2/apache-zookeeper-3.6.2-bin.tar.gz</span><br><span class="line">tar -zxf apache-zookeeper-3.6.2-bin.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /root/apache-zookeeper-3.6.2-bin/conf</span><br><span class="line">cp zoo_sample.cfg zoo.cfg</span><br></pre></td></tr></table></figure></p>
<p>Create zk data, log and conf directories in each zookeeper node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/zk/data</span><br><span class="line">mkdir -p /root/zk/<span class="built_in">log</span></span><br><span class="line">mkdir -p /root/zk/conf</span><br></pre></td></tr></table></figure></p>
<p>Edit <code>zoo.cfg</code> file for each zookeeper instance, use the same configuration for them:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># the basic time unit in milliseonds used by zk</span></span><br><span class="line">tickTime=2000</span><br><span class="line"><span class="comment">#Leader-Follower初始通信时限 tickTime * 10 = 20 seconds</span></span><br><span class="line">initLimit=10</span><br><span class="line"><span class="comment">#Leader-Follower同步通信时限 tickTime * 5 = 10 seconds</span></span><br><span class="line">syncLimit=5</span><br><span class="line"></span><br><span class="line"><span class="comment"># data dir</span></span><br><span class="line">dataDir=/root/zk/data</span><br><span class="line"><span class="comment"># log dir</span></span><br><span class="line">dataLogDir=/root/zk/<span class="built_in">log</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># client port, 3 nodes use the same port number</span></span><br><span class="line">clientPort=2181</span><br><span class="line"><span class="comment">#maxClientCnxns=60</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># broker id and IP address, or using hostname from /etc/hosts</span></span><br><span class="line"><span class="comment"># for cluster, borker id must start from 1, not 0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2888: connect the individual follower nodes to the leader node</span></span><br><span class="line"><span class="comment"># 3888: used for leader election in the ensemble</span></span><br><span class="line"><span class="comment"># can by any port number</span></span><br><span class="line">server.1=192.168.20.20:2888:3888</span><br><span class="line">server.2=192.168.20.21:2888:3888</span><br><span class="line">server.3=192.168.20.22:2888:3888</span><br></pre></td></tr></table></figure></p>
<p>In zk data directory, create <code>myid</code> for each zk instance, much be unqiue:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># current in 192.168.20.20</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /root/zk/data/myid</span><br><span class="line"><span class="comment"># run on 192.168.20.21</span></span><br><span class="line"><span class="built_in">echo</span> 2 &gt; /root/zk/data/myid</span><br><span class="line"><span class="comment"># run on 192.168.20.22</span></span><br><span class="line"><span class="built_in">echo</span> 3 &gt; /root/zk/data/myid</span><br></pre></td></tr></table></figure></p>
<h2 id="Commands"><a href="#Commands" class="headerlink" title="Commands"></a>Commands</h2><p>Run zk service commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/apache-zookeeper-3.6.2-bin/bin</span><br><span class="line"><span class="comment"># start</span></span><br><span class="line"><span class="comment"># default uses zoo.cfg config file</span></span><br><span class="line"><span class="comment"># run in background by default, has flag to run in foreground</span></span><br><span class="line">./zkServer.sh start [path/to/zoo.cfg]</span><br><span class="line"><span class="comment"># stop</span></span><br><span class="line">./zkServer.sh stop [path/to/zoo.cfg]</span><br><span class="line"></span><br><span class="line"><span class="comment"># status check</span></span><br><span class="line"><span class="comment"># Mode: standalone, follower, leader</span></span><br><span class="line">./zkServer.sh status [path/to/zoo.cfg]</span><br><span class="line"></span><br><span class="line"><span class="comment"># test zk is good</span></span><br><span class="line"><span class="comment"># ipv6 + port</span></span><br><span class="line">./zkCli.sh -server :2181</span><br><span class="line"><span class="comment"># then run</span></span><br><span class="line"><span class="comment"># you will see some output like [zookeeper], etc</span></span><br><span class="line">ls /</span><br></pre></td></tr></table></figure></p>
<p>[x] why port 2181 is bound on ipv6? 其他环境上也是如此。</p>
<p>After start zookeeper, check <code>./zkServer.sh status</code> to see if current node is leader or follower.<br>Run <code>./zkCli.sh</code>, you can execute zk CLI, see this <a href="https://zookeeper.apache.org/doc/r3.6.2/zookeeperCLI.html" target="_blank" rel="noopener">reference</a>.</p>
<p><code>./zkCli.sh</code> 也可用于从外部连接一个zk server, 只要指定accessable IP 和 port即可，demo中由于就在本机，所以其实是localhost.</p>
<p>If start failed, see <code>&lt;zk package&gt;/logs/zookeeper_audit.log</code>, If you don’t start another 2 zk instance, you will see periodically exception errors in <code>&lt;zk package&gt;/logs/zookeeper-root-server-kafka1.out</code>, it will be resolved after you start all of them. The log setting is by log4j configuration from <code>&lt;zk package&gt;/conf/log4j.properties</code>.</p>
<p>After the cluster is up and running, you can check the ports:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># see 2181, 2888, 3888</span></span><br><span class="line"><span class="comment"># -i: network socket</span></span><br><span class="line"><span class="comment"># -P: show port number</span></span><br><span class="line"><span class="comment"># -n: shpw ip address</span></span><br><span class="line">lsof -i -P -n</span><br><span class="line"></span><br><span class="line"><span class="comment"># scan 2181</span></span><br><span class="line"><span class="comment"># -z: scan only</span></span><br><span class="line"><span class="comment"># -v: verbose</span></span><br><span class="line">nc -zv &lt;zk instance ip&gt; 2181</span><br></pre></td></tr></table></figure></p>
<p>在旧版本中，可以使用<a href="https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_4lw" target="_blank" rel="noopener">four letter words</a>去检查一些状态，比如:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># are you ok</span></span><br><span class="line"><span class="built_in">echo</span> ruok | nc locahost 2181</span><br></pre></td></tr></table></figure></p>
<p>新版本已经切换到<a href="https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_adminserver" target="_blank" rel="noopener">AdminServer</a>. The AdminServer is enabled by default, access by http 8080 port:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># list all commands</span></span><br><span class="line">http://192.168.20.20:8080/commands</span><br><span class="line"></span><br><span class="line"><span class="comment"># for example:</span></span><br><span class="line"><span class="comment"># state</span></span><br><span class="line">http://192.168.20.20:8080/commands/<span class="built_in">stat</span></span><br><span class="line"><span class="comment"># config</span></span><br><span class="line">http://192.168.20.20:8080/commands/configuration</span><br></pre></td></tr></table></figure></p>
<p><a href="https://github.com/elkozmon/zoonavigator" target="_blank" rel="noopener">ZooNavigator</a> is a web based ZooKeeper UI and editor/browser with many features. You can launched it by docker container.</p>
<h1 id="Run-as-Daemon"><a href="#Run-as-Daemon" class="headerlink" title="Run as Daemon"></a>Run as Daemon</h1><p>Set zookeeper as system daemon so that it will be launched every time on system boots.</p>
<p><code>systemd</code> zookeeper cluster setup on ubuntu, see <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-an-apache-zookeeper-cluster-on-ubuntu-18-04" target="_blank" rel="noopener">here</a>.</p>
<p>Basically speaking, first generate a zookeeper service file, for example <code>zookeeper.service</code>, the prefix <code>zookeeper</code> is the service name used in systemctl command. Place this file in <code>/etc/systemd/system</code> folder and owned by <code>root</code>.</p>
<p>Double curly brackets is placeholder in jinja2 template.<br><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[Unit]</span></span><br><span class="line"><span class="attr">Description</span>=Zookeeper Daemon</span><br><span class="line"><span class="attr">Documentation</span>=http://zookeeper.apache.org</span><br><span class="line"><span class="comment"># boot after these services</span></span><br><span class="line"><span class="comment"># for example, here we rely consul and dnsmasq services</span></span><br><span class="line"><span class="attr">After</span>=network-<span class="literal">on</span>line.target consul.service dnsmasq.service</span><br><span class="line"><span class="attr">StartLimitInterval</span>=<span class="number">200</span></span><br><span class="line"><span class="attr">StartLimitBurst</span>=<span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="section">[Service]</span></span><br><span class="line"><span class="comment"># in zkServer.sh, it uses `&amp;` to fork and exec</span></span><br><span class="line"><span class="attr">Type</span>=forking</span><br><span class="line"><span class="comment"># systemd can identify the main process of the daemon</span></span><br><span class="line"><span class="comment"># in zkServer.sh it will echo pid to this file</span></span><br><span class="line"><span class="attr">PIDFile</span>=&#123;&#123; zookeeper_data_dir &#125;&#125;/zookeeper-server.pid</span><br><span class="line"></span><br><span class="line"><span class="attr">User</span>=&#123;&#123; zookeeper_user &#125;&#125;</span><br><span class="line"><span class="attr">Group</span>=&#123;&#123; zookeeper_group &#125;&#125;</span><br><span class="line"><span class="attr">WorkingDirectory</span>=/opt/zookeeper</span><br><span class="line"></span><br><span class="line"><span class="comment"># environment variables may be needed</span></span><br><span class="line"><span class="comment"># or configure in zoo.cfg file</span></span><br><span class="line"><span class="attr">Environment</span>=ZOOPIDFILE=&#123;&#123; zookeeper_data_dir &#125;&#125;/zookeeper-server.pid</span><br><span class="line"><span class="attr">Environment</span>=ZOOKEEPER_HOME=/opt/zookeeper</span><br><span class="line"><span class="attr">Environment</span>=ZOOKEEPER_CONF=&#123;&#123; zookeeper_conf_dir &#125;&#125;</span><br><span class="line"><span class="attr">Environment</span>=ZOOCFGDIR=&#123;&#123; zookeeper_conf_dir &#125;&#125;</span><br><span class="line"><span class="attr">Environment</span>=CLASSPATH=<span class="variable">$CLASSPATH</span>:<span class="variable">$ZOOKEEPER_CONF</span>:<span class="variable">$ZOOKEEPER_HOME</span>/*:<span class="variable">$ZOOKEEPER_HOME</span>/lib/*</span><br><span class="line"><span class="attr">Environment</span>=ZOO_LOG_DIR=&#123;&#123; zookeeper_log_dir &#125;&#125;</span><br><span class="line"><span class="attr">Environment</span>=ZOO_LOG4J_PROP=INFO,ROLLINGFILE</span><br><span class="line"><span class="attr">Environment</span>=JVMFLAGS=-Dzookeeper.log.threshold=INFO</span><br><span class="line"><span class="attr">Environment</span>=ZOO_DATADIR_AUTOCREATE_DISABLE=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># start, stop and reload commands</span></span><br><span class="line"><span class="attr">ExecStart</span>=/opt/zookeeper/bin/zkServer.sh start &#123;&#123; zookeeper_conf_dir &#125;&#125;/zoo.cfg</span><br><span class="line"><span class="attr">ExecStop</span>=/opt/zookeeper/bin/zkServer.sh stop &#123;&#123; zookeeper_conf_dir &#125;&#125;/zoo.cfg</span><br><span class="line"><span class="attr">ExecReload</span>=/opt/zookeeper/bin/zkServer.sh restart &#123;&#123; zookeeper_conf_dir &#125;&#125;/zoo.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># OOM killer: -1000 disable ~ 1000 very likely</span></span><br><span class="line"><span class="attr">OOMScoreAdjust</span>=-<span class="number">500</span></span><br><span class="line"><span class="attr">Restart</span>=<span class="literal">on</span>-failure</span><br><span class="line"><span class="attr">RestartSec</span>=<span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="section">[Install]</span></span><br><span class="line"><span class="comment"># usually this is your system default target</span></span><br><span class="line"><span class="attr">WantedBy</span>=multi-user.target</span><br></pre></td></tr></table></figure></p>
<p>More detail about <code>systemd</code> please search and see my systemd blog.</p>
<p>Then you must enable zookeeper starts on boot:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line"><span class="comment"># enable start on boot</span></span><br><span class="line">systemctl <span class="built_in">enable</span> zookeeper</span><br></pre></td></tr></table></figure></p>
<p>Other systemd commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start zookeeper</span><br><span class="line">systemctl stop zookeeper</span><br><span class="line">systemctl restart zookeeper</span><br><span class="line"></span><br><span class="line"><span class="comment"># reload config without restart</span></span><br><span class="line">systemctl reload zookeeper</span><br><span class="line"><span class="comment"># first try relaod, if not supports then restart</span></span><br><span class="line">systemctl reload-or-restart zookeeper</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Useful Chrome Extensions</title>
    <url>/2020/09/20/mac-chrome-plugins/</url>
    <content><![CDATA[<p>Some useful Chrome extensions:</p>
<ul>
<li><code>OneTab</code>: 把多个tabs整理成列表在一个网页中，可分享。</li>
<li><code>Grammarly for Chrome</code>: 英语语法检查。</li>
<li><code>SimpleUndoClose</code>: 重新打开关闭的网页。</li>
<li><code>Screen Shader</code>: 护眼模式，可调。</li>
<li><code>Dark Reader</code>: 夜晚模式。</li>
<li><code>清理大师Clean Master</code>: 一键清理浏览器的缓存记录，可配置。</li>
<li><code>Octotree</code>: 可以在侧边栏显示github 仓库代码的结构，点击跳转。</li>
<li><code>Tab Rsize</code>: 拆分浏览器页面，方便对比查看内容。</li>
<li><code>JSON Formatter</code>: 自动格式化JSON文件在浏览器中。</li>
<li><code>Awesome Autocomplete for GitHub</code>: 搜索github项目时可自动补全，方便查找。</li>
<li><code>Wappalyzer</code>: 识别当前网站所用的技术栈。</li>
<li><code>扩展管理器Extension Manager</code>: 插件统一管理工具。</li>
<li><code>ZenHub for GitHub</code>: zenhub 的管理插件，需要登录。</li>
</ul>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>chrome</tag>
      </tags>
  </entry>
  <entry>
    <title>Gain from People</title>
    <url>/2019/04/30/mis-gain-from-people/</url>
    <content><![CDATA[<p>入职IBM接近一年了，除了记录在博客中的东西，还有很多所学所得。目前觉得很实用的几个过来人的建议，一直贯彻落实在平时工作中。</p>
<ol>
<li><p>Document everything，能多详细多详细：时间，链接，上下文，切换原因，做了什么，目前得到了什么，接下来做什么, 能上图片上图片，能上语音上与语音, etc. 千万不要觉得记性好，那是幻觉。</p>
</li>
<li><p>Automate tedious work，如果你发现某一件事会重复发生至少3次以上，请立马想想能不能自动化一下，至少来点alias简化一下敲击键盘的数量。</p>
</li>
<li><p>At least half day. 以前太老实了，每次manager 问我how much time do you think you can finish it，我都给自己的buffer很少。有次我居然说20分钟可以解决，结果被大佬教育千万别这么说，万一半路去拉个屎20分钟就没了。</p>
</li>
<li><p>Back up daily work. 始于一次internal cloud maintenance后，自己的中控机文件系统受到损害无法修复壮烈牺牲（我总觉得可以修复，可能那人觉得没必要），后来又遇到laptop无故反复重启的险情，遂领悟高级备份技能。</p>
</li>
<li><p>Learning is an endless process. 以前还在想是不是经过一个陡峭的learning curve，工作将手到擒来（或者游刃有余），后来发现想多了T_T。我几乎每天都能遇到以前不会的新东西，honestly，我还是很高兴的，否则博客该写啥呢。也不是说领域完全没有尽头，只是它太大了，由点到面，融会贯通还需要时间。keep learning, all of these will pay off in the end.</p>
</li>
<li><p>Try, do try. 别太相信查找到解答，但其中很多内容已经失效，过时，并不是最佳方案（虽然能用），有的还是错的。一定要上手试一下，验证一下是否自己已经正确理解。几次遇到和2位组里大佬探讨时发现实际运行结果和期待的东西完全不一样。知其然，更知其所以然，否则心里不踏实。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Miscellanea</category>
      </categories>
  </entry>
  <entry>
    <title>Miscellanea 2019</title>
    <url>/2019/03/03/mis-2019/</url>
    <content><![CDATA[<p>This series contains something that is too short to be a blog, so put them all here, chronologically.</p>
<h3 id="02-25-2019"><a href="#02-25-2019" class="headerlink" title="02/25/2019"></a>02/25/2019</h3><ul>
<li><code>hostPath</code> in <code>PersistentVolume</code> is the mount path in host machine. <code>mountPath</code> in <code>containers</code> field is the mount path inside the container.</li>
</ul>
<h3 id="02-27-2019"><a href="#02-27-2019" class="headerlink" title="02/27/2019"></a>02/27/2019</h3><ul>
<li><p>Docker uses <code>/var/lib/docker</code> to store your images, containers, and local named volumes. Deleting this can result in data loss and possibly stop the engine from running. The <code>overlay2</code> subdirectory specifically contains the various <a href="https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers" target="_blank" rel="noopener">filesystem layers</a> for images and containers.</p>
</li>
<li><p><strong>Vim</strong> readonly mode, can open the same file in multiple windows:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim -R file</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="02-28-2019"><a href="#02-28-2019" class="headerlink" title="02/28/2019"></a>02/28/2019</h3><ul>
<li><p>reboot machine rightnow, <code>-r</code> means reboot, for example:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">shutdown -r now</span><br></pre></td></tr></table></figure>
<p>If you execute remotely, use <code>ssh example.com</code> to test if it bring up.</p>
</li>
<li><p><strong>Jenkins</strong>: the exit code of last command of the Jenkin’s Execute Shell build step is what determines the success/failure, now it’s better to wrap the code snippet as a script and execute it. Need to do more search on it.</p>
</li>
</ul>
<h3 id="03-02-2019"><a href="#03-02-2019" class="headerlink" title="03/02/2019"></a>03/02/2019</h3><ul>
<li><p>For <code>ls</code> command: If no operands are given, the contents of the current directory are displayed.  If more than one operand is given, non-directory operands are displayed first; directory and non-directory operands are sorted separately and in <strong>lexicographical order</strong>.</p>
<p> I use this feature with <code>tail</code> command to pick latest package, for example:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls | grep ansible-* | tail -1</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>ansible</code> has <code>log_path</code> setting in <code>~/.ansible.cfg</code> file, for example:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">log_path = /ibm-test/DS-Kube-Installer/logs/ds_installer_20190301_1645.log</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="03-04-2019"><a href="#03-04-2019" class="headerlink" title="03/04/2019"></a>03/04/2019</h3><ul>
<li><p><a href="https://www.gluster.org/" target="_blank" rel="noopener">Gluster file system</a> with RedHat?</p>
</li>
<li><p>when run <code>systemctl start docker</code>, these directories are created: <code>/var/lib/docker</code>, <code>/run/docker</code>, <code>etc/docker</code>.</p>
</li>
</ul>
<h3 id="03-05-2019"><a href="#03-05-2019" class="headerlink" title="03/05/2019"></a>03/05/2019</h3><ul>
<li>Find Red Hat or CentOS version:<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /etc/os-release</span><br><span class="line"></span><br><span class="line">Red Hat Enterprise Linux Server release 7.6 (Maipo)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="03-13-2019"><a href="#03-13-2019" class="headerlink" title="03/13/2019"></a>03/13/2019</h3><ul>
<li><p>I see people sometimes use <code>/bin/cp</code>, <code>/bin/rm</code> in script, why they don’t use <code>cp</code> or <code>rm</code> directly? The answer is <code>cp</code> or <code>rm</code> may be an alias in target machine! For example:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alias cp=&apos;cp -i&apos;</span><br><span class="line">alias mv=&apos;mv -i&apos;</span><br><span class="line">alias rm=&apos;rm -i&apos;</span><br></pre></td></tr></table></figure>
<p>So when use <code>cp -f source target</code> it will still prompt you the overwrite confirm if target and source are the same. <code>/bin/cp -f source target</code> is correct way to go.</p>
</li>
</ul>
<h3 id="03-16-2019"><a href="#03-16-2019" class="headerlink" title="03/16/2019"></a>03/16/2019</h3><p>These are from <code>Ansible: Up and Running, 2nd Edition</code> book:</p>
<ul>
<li><p><a href="https://gunicorn.org/" target="_blank" rel="noopener">Gunicorn</a>: a Python WSGI HTTP Server for UNIX.</p>
</li>
<li><p><a href="https://www.tablesgenerator.com/markdown_tables" target="_blank" rel="noopener">Markdown table generator</a></p>
</li>
<li><p><a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s Encrypt</a>: a free, automated, and open Certificate Authority.</p>
</li>
<li><p><a href="http://www.celeryproject.org/" target="_blank" rel="noopener">Celery</a>: a distributed task queue.</p>
</li>
<li><p><a href="https://www.rabbitmq.com/" target="_blank" rel="noopener">RabbitMQ</a>: open source message broker</p>
</li>
<li><p>A <strong>staging environment</strong> (stage) is a nearly exact replica of a production environment for software testing. Staging environments are made to test codes, builds, and updates to ensure quality under a production-like environment before application deployment.</p>
</li>
</ul>
<h3 id="03-17-2019"><a href="#03-17-2019" class="headerlink" title="03/17/2019"></a>03/17/2019</h3><p>These are from <code>Ansible: Up and Running, 2nd Edition</code> book:</p>
<ul>
<li><p><a href="http://mezzanine.jupo.org/" target="_blank" rel="noopener">Mezzanine</a>: similar in spirit to WordPress. Mezzanine is built on top of Django, the free Python-based framework for writing web applications.</p>
</li>
<li><p><a href="http://www.fabfile.org/" target="_blank" rel="noopener">Fabric</a>: a Python-based tool that helps automate running tasks via SSH.</p>
</li>
<li><p><a href="https://www.sqlite.org/serverless.html" target="_blank" rel="noopener">SQLite is serveless database</a>: Most SQL database engines are implemented as a separate server process. Programs that want to access the database communicate with the server using some kind of interprocess communication (typically TCP/IP) to send requests to the server and to receive back results. SQLite does not work this way. With SQLite, the process that wants to access the database reads and writes directly from the database files on disk. There is no intermediary server process.</p>
</li>
</ul>
<h3 id="03-18-2019"><a href="#03-18-2019" class="headerlink" title="03/18/2019"></a>03/18/2019</h3><ul>
<li><p>Today after Fyre maintenance, one of my VM cannot resolve hostname, when I run</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ping google.com</span><br></pre></td></tr></table></figure>
<p>it hangs, also <code>nslookup</code> doesn’t work as well.<br>Let’s check <code>/etc/resolv.conf</code> file, it is good:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">; generated by /usr/sbin/dhclient-script</span><br><span class="line">search fyre.ibm.com. svl.ibm.com.</span><br><span class="line">nameserver 172.16.200.52</span><br><span class="line">nameserver 172.16.200.50</span><br></pre></td></tr></table></figure>
<p>Then reboot VM again it works, sometimes Fyre generates weird problem.</p>
</li>
</ul>
<h3 id="03-22-2019"><a href="#03-22-2019" class="headerlink" title="03/22/2019"></a>03/22/2019</h3><ul>
<li><a href="https://kb.iu.edu/d/afiz" target="_blank" rel="noopener">Corn job</a></li>
</ul>
<h3 id="03-23-2019"><a href="#03-23-2019" class="headerlink" title="03/23/2019"></a>03/23/2019</h3><ul>
<li>From IBM developer website, <a href="https://developer.ibm.com/tutorials/l-lpic1-102-5/" target="_blank" rel="noopener">RPM and YUM package management</a></li>
</ul>
<h3 id="03-25-2019"><a href="#03-25-2019" class="headerlink" title="03/25/2019"></a>03/25/2019</h3><ul>
<li><a href="https://electronjs.org/" target="_blank" rel="noopener">ELECTRON</a>: Build cross platform desktop apps with JavaScript, HTML, and CSS</li>
</ul>
<h3 id="03-27-2019"><a href="#03-27-2019" class="headerlink" title="03/27/2019"></a>03/27/2019</h3><ul>
<li><p>This is from a issue I encountered: when we setup a NFS server as storage in K8s cluster with the <code>/etc/exports</code> file, we need to  restrict the clients who is able to access the NFS mount instead of something like:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/data *(rw,insecure,async,no_root_squash)</span><br></pre></td></tr></table></figure>
<p>Correct way is to specify which NFS client can access:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/data example1.com(rw,insecure,async,no_root_squash)</span><br><span class="line">/data example1.com(rw,insecure,async,no_root_squash)</span><br><span class="line">/data example1.com(rw,insecure,async,no_root_squash)</span><br></pre></td></tr></table></figure>
<p>Here in ansible template, it uses <code>lookup</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for host in &#123;&#123; lookup(&apos;env&apos;,&apos;nfsclienthosts&apos;) &#125;&#125;; do</span><br><span class="line">  echo &quot;&#123;&#123; dfsDataDir &#125;&#125; &quot;$host&quot;(rw,insecure,async,no_root_squash)&quot; &gt;&gt; /etc/exports</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>I want to say be careful with the space in exports file, from <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/nfs-serverconfig" target="_blank" rel="noopener">RHEL NFS exports</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Important</span><br><span class="line"></span><br><span class="line">The format of the /etc/exports file is very precise, particularly in </span><br><span class="line">regards to use of the space character. Remember to always separate exported</span><br><span class="line">file systems from hosts and hosts from one another with a space character. </span><br><span class="line">However, there should be no other space characters in the file except on </span><br><span class="line">comment lines.</span><br><span class="line"></span><br><span class="line">For example, the following two lines do not mean the same thing:</span><br><span class="line"></span><br><span class="line">/home bob.example.com(rw)</span><br><span class="line">/home bob.example.com (rw)</span><br><span class="line"></span><br><span class="line">The first line allows only users from bob.example.com read and write access </span><br><span class="line">to the /home directory. The second line allows users from bob.example.com </span><br><span class="line">to mount the directory as read-only (the default), while the rest of the </span><br><span class="line">world can mount it read/write.</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="03-28-2019"><a href="#03-28-2019" class="headerlink" title="03/28/2019"></a>03/28/2019</h3><ul>
<li><p><code>ps aux</code> command will not show full outputs and the lines are truncated, if you are in a lightweight Linux distributions like <code>BusyBox</code>, you can try:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | cat</span><br></pre></td></tr></table></figure>
<p>otherwise try:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps auxw</span><br><span class="line">ps auxww</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="03-29-2019"><a href="#03-29-2019" class="headerlink" title="03/29/2019"></a>03/29/2019</h3><ul>
<li>open terminal run <code>vimtutor</code>, haha.</li>
</ul>
<h3 id="03-30-2019"><a href="#03-30-2019" class="headerlink" title="03/30/2019"></a>03/30/2019</h3><ul>
<li><p>see memory usage</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">free -h</span><br></pre></td></tr></table></figure>
</li>
<li><p>clean swap space</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">swapoff -a &amp;&amp; swapon -a</span><br></pre></td></tr></table></figure>
</li>
<li><p><a href="https://www.nagios.org/about/overview/" target="_blank" rel="noopener">Nagios</a>: open source Industry Standard In IT Infrastructure Monitoring</p>
</li>
<li><p><a href="http://www.haproxy.org/" target="_blank" rel="noopener">HAProxy</a>:The Reliable, High Performance TCP/HTTP Load Balancer</p>
</li>
<li><p><code>/bin/false</code> is a system command that is used anytime you need to pass a command to a program that should do nothing more than exit with an error. It’s the companion to <code>/bin/true</code>. Both of these are very old and standard POSIX utilities and neither produce any output by definition. <code>true</code> is sometimes used for a shell script that should loop indefinitely, like:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">while true; do</span><br><span class="line">    ...</span><br><span class="line">    # Waste time</span><br><span class="line">    if [ $wasted_time -gt 100000 ]; then</span><br><span class="line">        exit 0</span><br><span class="line">    fi</span><br><span class="line">    ...</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p><code>/usr/sbin/nologin</code> is specifically designed to replace a shell and produces output complaining you can’t log-in. Before it existed, it was common to use <code>/bin/false</code> for dummy users, but could be confusing since the user doesn’t know why they’re kicked off.</p>
</li>
</ul>
<h3 id="04-01-2019"><a href="#04-01-2019" class="headerlink" title="04/01/2019"></a>04/01/2019</h3><ul>
<li><p>Sometimes when I login to a user home, the prompt is like:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bash-4.2$</span><br></pre></td></tr></table></figure>
<p>instead of </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[demo@myk8s1 ~]$</span><br></pre></td></tr></table></figure>
<p>the reason is <code>.bash_history  .bash_logout  .bash_profile  .bashrc</code> under <code>/home/demo</code> are missing!</p>
</li>
</ul>
<h3 id="04-02-2019"><a href="#04-02-2019" class="headerlink" title="04/02/2019"></a>04/02/2019</h3><ul>
<li><p>docker <a href="https://docs.docker.com/storage/bind-mounts/" target="_blank" rel="noopener">bind mounts</a> and <a href="https://docs.docker.com/storage/volumes/" target="_blank" rel="noopener">volume</a>, in our application, we use mount type in docker run command:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect &lt;container name&gt;</span><br><span class="line"></span><br><span class="line">&quot;Mounts&quot;: [</span><br><span class="line">          &#123;</span><br><span class="line">              &quot;Type&quot;: &quot;bind&quot;,</span><br><span class="line">              &quot;Source&quot;: &quot;/opt/builds&quot;,</span><br><span class="line">              &quot;Destination&quot;: &quot;/opt/builds&quot;,</span><br><span class="line">              &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">              &quot;RW&quot;: true,</span><br><span class="line">              &quot;Propagation&quot;: &quot;rprivate&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>I use <code>busybox</code> does a bind mount test, in the Dockerfile, I create a <code>/tmp/bb</code> folder and put <code>test.txt</code> file in it</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM busybox</span><br><span class="line">MAINTAINER chengdol@ibm.com</span><br><span class="line"></span><br><span class="line">COPY ./hello.txt /</span><br><span class="line">RUN sh -c &quot;mkdir /tmp/bb&quot; &amp;&amp; \</span><br><span class="line">  touch /tmp/bb/test.txt &amp;&amp; \</span><br><span class="line">  sh -c &quot;echo &apos;123&apos; &gt; /tmp/bb/test.txt&quot;</span><br><span class="line"></span><br><span class="line">CMD tail -f /hello.txt</span><br></pre></td></tr></table></figure>
<p>After build image and run as:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d --name mybb -v /tmp/bb:/tmp/bb mybb:v1</span><br></pre></td></tr></table></figure>
<p>Then I get into the container, the <code>test.txt</code> is missing. But if we first put something in the host <code>/tmp/bb</code> folder, it will show up inside container.</p>
</li>
<li><p>occasionally find a online drawing tool, <a href="https://www.draw.io/" target="_blank" rel="noopener">draw.io</a>, but this cloud service may not approved by company use.</p>
</li>
</ul>
<h3 id="04-03-2019"><a href="#04-03-2019" class="headerlink" title="04/03/2019"></a>04/03/2019</h3><ul>
<li><p><code>echo -n</code> will disable the newline, <code>echo -e</code> will enable the escape, so if you run</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo -e &quot;\n&quot;</span><br></pre></td></tr></table></figure>
<p>it will output a newline</p>
</li>
</ul>
<h3 id="04-04-2019"><a href="#04-04-2019" class="headerlink" title="04/04/2019"></a>04/04/2019</h3><ul>
<li><p>Linux capability, how to know what capabilities a process required to work properly?</p>
</li>
<li><p>Linux user and group with permission problem</p>
</li>
<li><p><code>docker commit</code>, commit what</p>
</li>
<li><p><code>docker save</code>, <code>docker export</code> difference</p>
</li>
<li><p>suid <code>rws</code> bit field for file and <code>t</code> sometimes, <a href="https://www.linode.com/docs/tools-reference/linux-users-and-groups/#additional-file-permissions" target="_blank" rel="noopener">link</a></p>
</li>
<li><p><code>usermod</code>, specify or change home directory</p>
</li>
<li><p><code>useradd</code>/<code>userdel</code>, <code>groupadd</code>/<code>groupdel</code> usage, <code>passwd</code> add password for user</p>
</li>
<li><p>sudo run process will be root USER</p>
</li>
<li><p><code>cp -p</code>, don’t change permission, owner and timestamps of the file</p>
</li>
</ul>
<h3 id="04-09-2019"><a href="#04-09-2019" class="headerlink" title="04/09/2019"></a>04/09/2019</h3><ul>
<li>find files owned by particular user<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -user &quot;xxx&quot;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>###04/10/2019</p>
<ul>
<li><p>check the parent of the process, show <code>PPID</code> (parent id) in ps command:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -efj</span><br></pre></td></tr></table></figure>
</li>
<li><p>setuid <strong>only</strong> set when owner is <strong>root</strong>, and other user with permission to run the file will be the owner of that process:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rwsr-xr-x 1 root  root  62 Apr 10 15:40 hang.sh</span><br></pre></td></tr></table></figure>
<p>if I’m <code>demo</code> user to run it, the process is owned by demo</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">demo     32403  0.0  0.0 113176  1388 pts/1    S+   10:13   0:00 /bin/bash ./hang.sh</span><br></pre></td></tr></table></figure>
<p>There is also <code>setgid</code> concept.</p>
</li>
</ul>
<h3 id="04-11-2019"><a href="#04-11-2019" class="headerlink" title="04/11/2019"></a>04/11/2019</h3><ul>
<li>copy with hidden files and directories</li>
</ul>
<h3 id="04-21-2019"><a href="#04-21-2019" class="headerlink" title="04/21/2019"></a>04/21/2019</h3><ul>
<li><p>global user start file: <code>/etc/bashrc</code>, the <code>umask</code> is inside it. </p>
<blockquote>
<p>Note that <code>umask</code> uses subtraction.</p>
</blockquote>
</li>
<li><p>tools which preserve permissions apply the appropriate mode and ignore umask: <code>cp -p</code>, <code>tar -p</code>.</p>
</li>
</ul>
<h3 id="04-24-2019"><a href="#04-24-2019" class="headerlink" title="04/24/2019"></a>04/24/2019</h3><ul>
<li><p>I find sometimes I use <code>grep -r XXX .</code> cannot find the pattern in files in current and subdirectories. The reason is <code>-r</code> flag will not process symbolic link except it’s on the command link. you can use:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep -Rn XXX .</span><br></pre></td></tr></table></figure>
<p><code>-R</code> will follow symbolic links<br><code>-n</code> will show line number for each matched result<br><code>-i</code> make it case-insensitive<br><code>-F</code> used looking for fixed string to save time</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep -Rn --include &quot;*.txt&quot; XXX .</span><br></pre></td></tr></table></figure>
<p>if you know the pattern of the file, you can specify that using <code>--include</code>, you can also mention using <code>--exclude</code> option.</p>
</li>
</ul>
<h3 id="05-10-2019"><a href="#05-10-2019" class="headerlink" title="05/10/2019"></a>05/10/2019</h3><ul>
<li><p>scp from linux to windows machine</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp ~/Downloads/PXSmokeTest_outputs.dsx Administrator@indraniwindows1.fyre.ibm.com:</span><br></pre></td></tr></table></figure>
<p>the file will be put in <code>C:\Users\Administrator&gt;</code> folder in windows.</p>
</li>
<li><p>How to scp files from remote host to container in k8s?<br>inside the container, install <code>openssh-clients</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install openssh-clients</span><br></pre></td></tr></table></figure>
<p>then just like normal:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo scp root@mycentctl1:/GitRepos/cognitive-designer-api/DSNexus_Build/Docker_Scripts/Kubernetes_11.7.DS/buildengine/opt/IBM/InformationServer/initScripts/* .</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="05-20-2019"><a href="#05-20-2019" class="headerlink" title="05/20/2019"></a>05/20/2019</h3><ul>
<li><code>Coordinated Universal Time (UTC)</code> is 7 hours ahead of <code>Pacific Time</code>.</li>
</ul>
<h3 id="06-12-2019"><a href="#06-12-2019" class="headerlink" title="06/12/2019"></a>06/12/2019</h3><ul>
<li><p>grep exclude pattern use <code>-v</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker images | grep -E <span class="string">"xmeta|services|engine|compute"</span> | grep -v <span class="string">"mycluster"</span> | awk <span class="string">'&#123;print $1&#125;'</span></span><br></pre></td></tr></table></figure>
<p>this will exclude results have <code>mycluster</code>.</p>
</li>
</ul>
<h3 id="06-19-2019"><a href="#06-19-2019" class="headerlink" title="06/19/2019"></a>06/19/2019</h3><ul>
<li>workaround when you cannot find rpm or package to install in linux, download the    binary and put it in working PATH, for example, to use <code>jq</code>, download binaries form<br><a href="https://stedolan.github.io/jq/download/" target="_blank" rel="noopener">here</a>.<br>add executable bit and move to <code>/usr/bin</code>.</li>
</ul>
<h3 id="07-01-2019"><a href="#07-01-2019" class="headerlink" title="07/01/2019"></a>07/01/2019</h3><ul>
<li><p>check directory current used size:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -s: total</span></span><br><span class="line"><span class="comment"># -h: human</span></span><br><span class="line">du -sh &lt;path to directory&gt;</span><br></pre></td></tr></table></figure>
<p>if you want to know the partition size associated with this directory, for example <code>/var/lib/docker</code>, use</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -h /var</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="07-02-2019"><a href="#07-02-2019" class="headerlink" title="07/02/2019"></a>07/02/2019</h3><ul>
<li><p>change file or directory time stamp to <code>1969-12-31 16:00</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">touch -a -m -t 196912311600 xx.txt</span><br></pre></td></tr></table></figure>
<p><code>-a</code>: change the access time of a file. By default it will take the current system time and update the atime field.<br><code>-m</code>: change the modification time of a file.<br><code>-t</code>: explicitly specify the time</p>
<p>Check status by <code>stat</code> command:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stat xx.txt</span><br><span class="line"></span><br><span class="line">File: `xx.txt&apos;</span><br><span class="line">Size: 3         	Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: 801h/2049d	Inode: 394283      Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: ( 1000/lakshmanan)   Gid: ( 1000/lakshmanan)</span><br><span class="line">Access: 2038-01-18 12:05:09.000000000 +0530</span><br><span class="line">Modify: 2038-01-18 12:05:09.000000000 +0530</span><br><span class="line">Change: 2012-10-19 00:40:58.763514502 +0530</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>  reference and update the time stamp of file a.txt from the time stamp of b.txt file<br>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">touch a.txt -r b.txt</span><br></pre></td></tr></table></figure></p>
<p>  Change time stamp recursively<br>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -type f -exec touch -a -m -t 196912311600 &#123;&#125; +</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>Convert format from <code>DOS</code> to <code>UNIX</code>:<br>If you open a file via <code>vim</code> and see there are many <code>^M</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NOTICE^M</span><br><span class="line">^M</span><br><span class="line">This document includes License Information documents below for multiple Programs. Each License Information document identifies the Program(s) to which it applies. Only those License Information documents for the Program(s) for which Licensee has acquired entitlements apply.^M</span><br><span class="line">^M</span><br><span class="line">^M</span><br></pre></td></tr></table></figure>
<p>This is because it’s <code>DOS</code> format:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">file LA_en.ORIG</span><br><span class="line"></span><br><span class="line">LA_en.ORIG: ASCII text, with very long lines, with CRLF, LF line terminators</span><br></pre></td></tr></table></figure>
<p>how to convert to <code>UNIX</code>?</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y dos2unix</span><br><span class="line">dos2unix &lt;file name&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="07-12-2019"><a href="#07-12-2019" class="headerlink" title="07/12/2019"></a>07/12/2019</h3><ul>
<li>Previously I use<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -ltr --block-size=M</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>to see the human readable size for each file, actually use<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -ltrh</span><br></pre></td></tr></table></figure></p>
<p>is enough!</p>
<h3 id="07-15-2019"><a href="#07-15-2019" class="headerlink" title="07/15/2019"></a>07/15/2019</h3><ul>
<li>new tech word <code>linting</code>: the process of running a program that will analyse code for potential errors. For example, <code>PHPLint</code>, <code>JSLint</code>.</li>
</ul>
<h3 id="07-24-2019"><a href="#07-24-2019" class="headerlink" title="07/24/2019"></a>07/24/2019</h3><ul>
<li><p>if run script using <code>sudo</code>, for example:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo script.sh</span><br></pre></td></tr></table></figure>
<p>then every command in scipt is executed with sudo.</p>
</li>
</ul>
<h3 id="08-05-2019"><a href="#08-05-2019" class="headerlink" title="08/05/2019"></a>08/05/2019</h3><ul>
<li><p>find file owned by a particular user or group</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find &lt;path&gt; -user &lt;dsadm&gt; -group &lt;dstage&gt;</span><br></pre></td></tr></table></figure>
<p>find file by case-insensitive name and use <code>-ls</code> format</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find &lt;path&gt; -iname &lt;name&gt; -type f -ls</span><br></pre></td></tr></table></figure>
</li>
<li><p>find particular files and change the chown or chmod</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find &lt;path&gt; -user &lt;dsadm&gt; -group &lt;dstage&gt; -exec chmod 755 &#123;&#125; /;</span><br></pre></td></tr></table></figure>
<p>explain:<br><code>chmod 755 {} \;</code> specifies the command that will be executed by find for each file. <code>{}</code> is replaced by the file path, and the <code>semicolon(;)</code> denotes the end of the command (escaped, otherwise it would be interpreted by the shell instead of find).</p>
</li>
</ul>
<h3 id="08-09-2019"><a href="#08-09-2019" class="headerlink" title="08/09/2019"></a>08/09/2019</h3><ul>
<li>if var is not set, use default value <code>123456</code>:<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var=$&#123;var:-&quot;123456&quot;&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="08-28-2019"><a href="#08-28-2019" class="headerlink" title="08/28/2019"></a>08/28/2019</h3><ul>
<li>docker commit will not apply <code>chmod 777 /</code> in new image, the permission mode of <code>/</code> directory is still original. Not sure why.</li>
</ul>
<h3 id="09-05-2019"><a href="#09-05-2019" class="headerlink" title="09/05/2019"></a>09/05/2019</h3><ul>
<li><code>curl</code> can be used to verbose request in detail, to check the RESTful API content.</li>
</ul>
<h3 id="11-13-2019"><a href="#11-13-2019" class="headerlink" title="11/13/2019"></a>11/13/2019</h3><ul>
<li><code>uniq</code> <a href="https://www.geeksforgeeks.org/uniq-command-in-linux-with-examples/" target="_blank" rel="noopener">command</a>, used to deduplicates </li>
</ul>
<h3 id="11-30-2019"><a href="#11-30-2019" class="headerlink" title="11/30/2019"></a>11/30/2019</h3><ul>
<li><code>https://distrowatch.com/</code> linux forum, contains lots of different linux distribtions and release informations.</li>
</ul>
]]></content>
      <categories>
        <category>Miscellanea</category>
      </categories>
      <tags>
        <tag>miscellanea</tag>
      </tags>
  </entry>
  <entry>
    <title>Miscellanea 2020</title>
    <url>/2020/01/22/mis-2020/</url>
    <content><![CDATA[<h3 id="01-22-2020"><a href="#01-22-2020" class="headerlink" title="01/22/2020"></a>01/22/2020</h3><ul>
<li><p>NFS network file system, list nfs port:<br><a href="https://serverfault.com/questions/377170/which-ports-do-i-need-to-open-in-the-firewall-to-use-nfs" target="_blank" rel="noopener">https://serverfault.com/questions/377170/which-ports-do-i-need-to-open-in-the-firewall-to-use-nfs</a></p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">rpcinfo -p | grep nfs</span><br></pre></td></tr></table></figure>
<p>It depends on the version of the protocol you intent to use. NFS 4 only require <code>2049</code> while older versions require more.</p>
</li>
<li><p>setup nfs cluster to prevent single point of failure<br><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/high_availability_add-on_administration/ch-nfsserver-haaa" target="_blank" rel="noopener">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/high_availability_add-on_administration/ch-nfsserver-haaa</a></p>
</li>
</ul>
<h3 id="02-26-2020"><a href="#02-26-2020" class="headerlink" title="02/26/2020"></a>02/26/2020</h3><ul>
<li><p>如果不想让一个executable 执行多次，可以在每次run的时候在当前或固定文件夹create一个hidden file, for example: <code>.commad.lock</code>，然后写入当前正在run的command 参数等。通过检查这个file是否存在去决定是不是正在执行。</p>
</li>
<li><p>redhat 一个很不错的网站: <a href="https://www.redhat.com/sysadmin/" target="_blank" rel="noopener">https://www.redhat.com/sysadmin/</a></p>
</li>
<li><p>command <code>uuidgen</code> 可以用来generate random unique number.</p>
</li>
</ul>
<h3 id="04-07-2020"><a href="#04-07-2020" class="headerlink" title="04/07/2020"></a>04/07/2020</h3><ul>
<li><code>find</code> softlink file, use type <code>l</code>:<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -type l -name dsenv</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>or use <code>-L</code>, then the <code>-type</code> predicate will always match against the type of the file that  a  symbolic  link  points  to  rather  than  the link itself (unless the symbolic link is broken).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find -L / type f -name dsenv</span><br></pre></td></tr></table></figure></p>
<p>类似于<code>readlink</code>, 会去softlink directory里面寻找original file.</p>
<h3 id="04-09-2020"><a href="#04-09-2020" class="headerlink" title="04/09/2020"></a>04/09/2020</h3><ul>
<li><p><code>&gt; /dev/null 2&gt;&amp;1</code> can be written as <code>&amp;&gt; /dev/null</code></p>
</li>
<li><p><code>su</code> vs <code>su -</code>. 都是login to another user, <code>-</code> 表示normal login，login后会完全变成当前user的初始环境，比如在当前user的home dir且$PATH也是当前user的。没有<code>-</code>, 则会继承上个user的环境，比如dir还是上次的。2个login都会执行~/.bashrc.</p>
</li>
<li><p><code>!$</code> the last word from last command in history list:<br><a href="https://unix.stackexchange.com/questions/88642/what-does-mean" target="_blank" rel="noopener">https://unix.stackexchange.com/questions/88642/what-does-mean</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep -i joe /some/long/directory/structure/user-lists/list-15</span><br><span class="line"><span class="comment">## expand as /some/long/directory/structure/user-lists/list-15</span></span><br><span class="line">vi !$</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="04-18-2020"><a href="#04-18-2020" class="headerlink" title="04/18/2020"></a>04/18/2020</h3><ul>
<li>在pod container中，如果script process不是init process (pid 1)，那么script中的trap 内容不会被执行。 还不太清楚为什么。</li>
</ul>
<h3 id="04-26-2020"><a href="#04-26-2020" class="headerlink" title="04/26/2020"></a>04/26/2020</h3><ul>
<li><code>declare -F</code> show function name in current shell</li>
<li><code>declare -f</code> show function definition in current shell, <code>declare -f &lt;f name&gt;</code> get just that definition</li>
</ul>
<h3 id="06-16-2020"><a href="#06-16-2020" class="headerlink" title="06/16/2020"></a>06/16/2020</h3><ul>
<li>很多build可以用Makiefile + make command去实现，应该是一个通用的工具。</li>
</ul>
<h3 id="06-21-2020"><a href="#06-21-2020" class="headerlink" title="06/21/2020"></a>06/21/2020</h3><ul>
<li><a href="https://stackoverflow.com/questions/16365130/what-is-the-difference-between-usr-bin-env-bash-and-usr-bin-bash#:~:text=Using%20%23!%2Fusr%2Fbin%2Fenv,want%20to%20search%20for%20it.&amp;text=If%20the%20shell%20scripts%20start,run%20with%20bash%20from%20%2Fbin%20." target="_blank" rel="noopener">What is the difference between “#!/usr/bin/env bash” and “#!/usr/bin/bash”?</a></li>
</ul>
<h3 id="06-24-2020"><a href="#06-24-2020" class="headerlink" title="06/24/2020"></a>06/24/2020</h3><ul>
<li><code>bash -x ./script</code>, no need <code>set -x</code></li>
</ul>
<h3 id="06-25-2020"><a href="#06-25-2020" class="headerlink" title="06/25/2020"></a>06/25/2020</h3><ul>
<li>script performance comparison <code>strace -c ./script</code>. 也就是说，多用bash internal command from <code>help</code>.</li>
</ul>
<h3 id="06-26-2020"><a href="#06-26-2020" class="headerlink" title="06/26/2020"></a>06/26/2020</h3><ul>
<li>Create custom systemd service: <a href="https://medium.com/@benmorel/creating-a-linux-service-with-systemd-611b5c8b91d6" target="_blank" rel="noopener">https://medium.com/@benmorel/creating-a-linux-service-with-systemd-611b5c8b91d6</a>. Interesting. 印象里面和当时设置K8s systemd 有点类似.</li>
</ul>
<h3 id="07-05-2020"><a href="#07-05-2020" class="headerlink" title="07/05/2020"></a>07/05/2020</h3><ul>
<li><code>shopt -s nocasematch</code>, set bash case-insensitive match in <code>case</code> or <code>[[ ]]</code> condition. 这个是从bash tutorial 中文版中学到的, <code>shopt</code> is bash built-in setting, unlike <code>set</code> is from POSIX.</li>
</ul>
<h3 id="07-09-2020"><a href="#07-09-2020" class="headerlink" title="07/09/2020"></a>07/09/2020</h3><ul>
<li>vim can directly operate on file in tarball: <code>vim xx.tgz</code> then save the changes</li>
</ul>
<h3 id="07-12-2020"><a href="#07-12-2020" class="headerlink" title="07/12/2020"></a>07/12/2020</h3><ul>
<li><a href="https://www.youtube.com/watch?v=D-k-h0GuFmE&amp;list=PLroEs25KGvwzmvIxYHRhoGTz9w8LeXek0" target="_blank" rel="noopener">Database SQL course</a> online from Stanford or Edx.com</li>
</ul>
<h3 id="07-29-2020"><a href="#07-29-2020" class="headerlink" title="07/29/2020"></a>07/29/2020</h3><ul>
<li><code>!!</code> re-execute last command.</li>
<li><code>!&lt;beginning token&gt;</code> re-execute last command start with this token.</li>
<li><code>$_</code> last token in last command line</li>
</ul>
<h3 id="08-22-2020"><a href="#08-22-2020" class="headerlink" title="08/22/2020"></a>08/22/2020</h3><ul>
<li>Interesting: top 10 most used CLI: <code>history | awk {&#39;print $2&#39;} | sort | uniq -c | sort -nr | head -n 10</code></li>
<li>same idea to check my blog theme: <code>ls -ltr | awk &#39;NR&gt;1 {print $NF}&#39; | cut -d&#39;-&#39; -f1 | sort | uniq -c | sort</code></li>
</ul>
<h3 id="09-09-2020"><a href="#09-09-2020" class="headerlink" title="09/09/2020"></a>09/09/2020</h3><ul>
<li>Mac netstat list listening port, the <code>netstat</code> on Mac is not that powerful as on Linux:<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -p: protocol</span></span><br><span class="line"><span class="comment">## -n: numerical address</span></span><br><span class="line"><span class="comment">## -a: show all connections</span></span><br><span class="line">netstat -an -ptcp | grep -i listen</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line"><span class="comment">## -i: lists IP sockets</span></span><br><span class="line"><span class="comment">## -P: do not resolve port names</span></span><br><span class="line"><span class="comment">## -n: do not resolve hostnames</span></span><br><span class="line">lsof -i -P -n | grep -i <span class="string">"listen"</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="09-18-2020"><a href="#09-18-2020" class="headerlink" title="09/18/2020"></a>09/18/2020</h3><ul>
<li>Interesting project <a href="https://github.com/hubotio/hubot" target="_blank" rel="noopener">https://github.com/hubotio/hubot</a></li>
<li><code>seq</code> commands, i.e. <code>seq 1 9</code> generate sequence 1 to 9, used in shell for loop as counter.</li>
</ul>
<h3 id="10-25-2020"><a href="#10-25-2020" class="headerlink" title="10/25/2020"></a>10/25/2020</h3><ul>
<li>Interesting, <code>ed</code> editor: <a href="https://sanctum.geek.nz/arabesque/actually-using-ed/" target="_blank" rel="noopener">https://sanctum.geek.nz/arabesque/actually-using-ed/</a></li>
<li><code>Dash</code> is a Mac app browser API</li>
<li><code>Typora</code> markdown editor</li>
</ul>
<h3 id="11-03-2020"><a href="#11-03-2020" class="headerlink" title="11/03/2020"></a>11/03/2020</h3><p>Known from IBM channel, docker security talk</p>
<ul>
<li><a href="https://github.com/docker/docker-bench-security" target="_blank" rel="noopener">docker security scan</a></li>
<li><a href="https://cilium.io/" target="_blank" rel="noopener">k8s cilium</a>: securing the network connectivity between application</li>
</ul>
<h3 id="11-20-2020"><a href="#11-20-2020" class="headerlink" title="11/20/2020"></a>11/20/2020</h3><ul>
<li><p>shell nop command: <code>:</code>, synopsis is <code>true</code>, do nothing, similar to <code>pass</code> in python</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## : as true</span></span><br><span class="line"><span class="keyword">while</span> :; <span class="keyword">do</span></span><br><span class="line">  sleep 1</span><br><span class="line">  <span class="built_in">echo</span> 1</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>shell mutliline comment, can use heredoc</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">: &lt;&lt;<span class="string">'COMMENT'</span></span><br><span class="line">...</span><br><span class="line">COMMENT</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="11-24-2020"><a href="#11-24-2020" class="headerlink" title="11/24/2020"></a>11/24/2020</h3><ul>
<li>python shebang:<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="11-27-2020"><a href="#11-27-2020" class="headerlink" title="11/27/2020"></a>11/27/2020</h3><ul>
<li><code>ls -1</code> 每行只输出一个文件名.</li>
<li><code>mv -v</code> verbose</li>
</ul>
<h3 id="12-06-2020"><a href="#12-06-2020" class="headerlink" title="12/06/2020"></a>12/06/2020</h3><ul>
<li>bash read file line by line<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat <span class="variable">$file</span> | <span class="keyword">while</span> <span class="built_in">read</span> line</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$line</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">input=<span class="string">"/path/to/txt/file"</span></span><br><span class="line"><span class="keyword">while</span> IFS= <span class="built_in">read</span> -r line</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"<span class="variable">$line</span>"</span></span><br><span class="line"><span class="keyword">done</span> &lt; <span class="string">"<span class="variable">$input</span>"</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="12-09-2020"><a href="#12-09-2020" class="headerlink" title="12/09/2020"></a>12/09/2020</h3><ul>
<li>sudo to edit restricted permission file:<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># executing as non-root user</span></span><br><span class="line"><span class="comment"># wrong, because redirection is done by the shell which doesn't has write permission.</span></span><br><span class="line">sudo <span class="built_in">echo</span> <span class="string">"sth"</span> &gt;&gt; /root/.bashrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># correct</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"sth"</span> | sudo tee -a /root/.bashrc</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">sudo sh -c <span class="string">'echo sth &gt;&gt; /root/.bashrc'</span></span><br><span class="line"><span class="comment"># or mutli-line</span></span><br><span class="line">sudo tee -a /root/.bashrc &lt;&lt; EOF</span><br><span class="line">dexec()</span><br><span class="line">&#123;</span><br><span class="line">  docker <span class="built_in">exec</span> -it \<span class="variable">$&#123;1&#125;</span> sh</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="12-10-2020"><a href="#12-10-2020" class="headerlink" title="12/10/2020"></a>12/10/2020</h3><ul>
<li><a href="https://app.pluralsight.com/guides/introduction-to-semantic-versioning" target="_blank" rel="noopener">semantic versioning</a><br>major.minor.patch</li>
</ul>
<h3 id="12-25-2020"><a href="#12-25-2020" class="headerlink" title="12/25/2020"></a>12/25/2020</h3><ul>
<li><code>cat jsonfile | python -m json.tool</code> 和<code>jq</code> 类似，一个json的format工具，但只能pretty print.</li>
<li><a href="https://askubuntu.com/questions/59458/error-message-sudo-unable-to-resolve-host-none" target="_blank" rel="noopener">sudo: unable to resolve host:</a> 我不太理解为什么sudo 会设计到hostname resolution?</li>
</ul>
]]></content>
      <categories>
        <category>Miscellanea</category>
      </categories>
      <tags>
        <tag>miscellanea</tag>
      </tags>
  </entry>
  <entry>
    <title>Music in My Life</title>
    <url>/2019/05/27/music/</url>
    <content><![CDATA[<p>把这十几年间喜欢的音乐收集列出来，做个纪念😃😑😯😡😣😭😢绝不是随机排列…</p>
<h2 id="我弹奏的钢琴曲😃"><a href="#我弹奏的钢琴曲😃" class="headerlink" title="我弹奏的钢琴曲😃"></a>我弹奏的钢琴曲😃</h2><p>2019年6月17号我拿到了我买的YAMAHA P-125，从此开始了我钢琴自学之旅，记录一下自己的进步与快乐。</p>
<ul>
<li><p>Youtube:<br>🎹<a href="https://youtu.be/xReoYTG_0-4" target="_blank" rel="noopener">Because of You</a><br>🎹<a href="https://youtu.be/zatnaCmdDm4" target="_blank" rel="noopener">The Sound of Silence</a><br>🎹[stay tuned]</p>
</li>
<li><p>Blibli:<br>🎹<a href="https://www.bilibili.com/video/av65980280" target="_blank" rel="noopener">Because of You</a><br>🎹<a href="https://www.bilibili.com/video/av73571372" target="_blank" rel="noopener">The Sound of Silence</a><br>🎹[stay tuned]</p>
</li>
</ul>
<h2 id="最喜欢的😍"><a href="#最喜欢的😍" class="headerlink" title="最喜欢的😍"></a>最喜欢的😍</h2><ul>
<li><p><code>With an Orchid (与兰同馨)</code>(夜深人静戴耳机😝)<br>🎹🎻<a href="https://www.youtube.com/watch?v=rsNrpw2vPrA" target="_blank" rel="noopener">现场版</a><br>🎹<a href="https://www.youtube.com/watch?v=xCUjBPS9WTw" target="_blank" rel="noopener">原版</a><br>🎤<a href="https://www.youtube.com/watch?v=FRWgAV8i65o" target="_blank" rel="noopener">演唱版</a></p>
</li>
<li><p><code>Because of You</code>(夜深人静戴耳机😝)<br>🎻<a href="https://www.youtube.com/watch?v=3oYee5CEHRI" target="_blank" rel="noopener">小提琴版</a><br>🎹<a href="https://www.youtube.com/watch?v=PZIH_btEqFc" target="_blank" rel="noopener">钢琴版</a><br>🎤<a href="https://www.youtube.com/watch?v=atz_aZA3rf0" target="_blank" rel="noopener">原版MV</a></p>
</li>
</ul>
<h2 id="喜欢的🌹"><a href="#喜欢的🌹" class="headerlink" title="喜欢的🌹"></a>喜欢的🌹</h2><p>🎤<a href="https://www.youtube.com/watch?v=QN-N8jrinOM" target="_blank" rel="noopener">奔跑</a><br>🎤<a href="https://www.youtube.com/watch?v=R1i2kMxELJM" target="_blank" rel="noopener">嘻唰唰</a><br>🎤<a href="https://www.youtube.com/watch?v=hzzqzfPGrOQ" target="_blank" rel="noopener">浪漫满屋</a><br>🎤<a href="https://www.youtube.com/watch?v=qWV4gJIRRPY" target="_blank" rel="noopener">快乐崇拜</a><br>🎤<a href="https://www.youtube.com/watch?v=kqgYyfuGAag" target="_blank" rel="noopener">数码宝贝Brave Heart</a><br>🎤<a href="https://www.youtube.com/watch?v=RMFVuCURZIs" target="_blank" rel="noopener">数码宝贝Butterfly</a><br>🎤<a href="https://www.youtube.com/watch?v=5-2ednIJsa8" target="_blank" rel="noopener">你的微笑</a><br>🎹<a href="https://www.youtube.com/watch?v=KWdhcOtGtcE" target="_blank" rel="noopener">梦中的婚礼</a><br>🎤<a href="https://www.youtube.com/watch?v=h03_hs_QbEE" target="_blank" rel="noopener">不死之身</a><br>🎤<a href="https://www.youtube.com/watch?v=G97_rOdHcnY" target="_blank" rel="noopener">江南</a><br>🎹<a href="https://www.youtube.com/watch?v=WkM2Tqy-_OY" target="_blank" rel="noopener">星空</a><br>🎤<a href="https://www.youtube.com/watch?v=ZOHsd6Zk7DM" target="_blank" rel="noopener">Lydia</a><br>🎤<a href="https://www.youtube.com/watch?v=FQaid7WMr4g" target="_blank" rel="noopener">Soledad</a><br>🎤<a href="https://www.youtube.com/watch?v=8B3q6upO-Vw" target="_blank" rel="noopener">Evergreen</a><br>🎤<a href="https://www.youtube.com/watch?v=hqpDebYpP6w" target="_blank" rel="noopener">Black Black Heart</a><br>🎤<a href="https://www.youtube.com/watch?v=VNSgKDRndpQ" target="_blank" rel="noopener">7 Days</a><br>🎹<a href="https://www.youtube.com/watch?v=J7or0noYfMA" target="_blank" rel="noopener">Summer</a><br>🎤<a href="https://www.youtube.com/watch?v=E9a1W9hNkVo" target="_blank" rel="noopener">紫藤花</a><br>🎤<a href="https://www.youtube.com/watch?v=25rL-ooWICU" target="_blank" rel="noopener">I swear</a><br>🎹<a href="https://www.youtube.com/watch?v=7maJOI3QMu0" target="_blank" rel="noopener">River Flows in You</a><br>🎤<a href="https://www.youtube.com/watch?v=oXvYw-kgFz8" target="_blank" rel="noopener">Brave</a><br>🎹<a href="https://www.youtube.com/watch?v=MyziqLYNoNM" target="_blank" rel="noopener">忧伤还是快乐</a><br>🎤<a href="https://www.youtube.com/watch?v=Xp_EAKEWA-g" target="_blank" rel="noopener">留在我身边</a><br>🎤<a href="https://www.youtube.com/watch?v=CS-oP-XAzmU" target="_blank" rel="noopener">情非得已</a><br>🎹<a href="https://www.youtube.com/watch?v=cisd1_nUGkE" target="_blank" rel="noopener">The Sound of Silence</a><br>🎤<a href="https://www.youtube.com/watch?v=o6wtDPVkKqI" target="_blank" rel="noopener">残酷な天使のテーゼ</a><br>🎤<a href="https://www.youtube.com/watch?v=-7aY4tomcEE" target="_blank" rel="noopener">分开旅行</a><br>🎤<a href="https://www.youtube.com/watch?v=HwXIImlUFmY" target="_blank" rel="noopener">老男孩</a><br>🎹<a href="https://www.youtube.com/watch?v=ZrFQ88l2lAQ" target="_blank" rel="noopener">幽灵公主</a><br>🎤<a href="https://www.youtube.com/watch?v=w41gqTFYh08" target="_blank" rel="noopener">心跳</a><br>🎹🎻<a href="https://www.youtube.com/watch?v=E9kcNFpOavk" target="_blank" rel="noopener">Santorini</a><br>🎤<a href="https://www.youtube.com/watch?v=jofNR_WkoCE" target="_blank" rel="noopener">The Fox</a><br>🎤<a href="https://www.youtube.com/watch?v=hT_nvWreIhg" target="_blank" rel="noopener">Counting Stars</a><br>🎤<a href="https://www.youtube.com/watch?v=Xn676-fLq7I" target="_blank" rel="noopener">Stronger</a><br>🎤<a href="https://www.youtube.com/watch?v=EX_YWo1h-kQ&amp;list=PLRndcoWkF2_4Gv2QWYmI0pdToTYROsfQq&amp;index=16" target="_blank" rel="noopener">转动命运之轮</a><br>🎤<a href="https://www.youtube.com/watch?v=wJ61ENvN9e4" target="_blank" rel="noopener">下个，路口，见</a><br>🎹<a href="https://www.youtube.com/watch?v=LsrEEAFH0O8" target="_blank" rel="noopener">Run Away With Me</a><br>🎻<a href="https://www.youtube.com/watch?v=VZRVou4cyic" target="_blank" rel="noopener">Love Me Like You Do</a><br>🎤<a href="https://www.youtube.com/watch?v=W52V9a4iSEQ" target="_blank" rel="noopener">生来倔强</a><br>🎤<a href="https://www.youtube.com/watch?v=1Op8xDcgpUY" target="_blank" rel="noopener">飞-致我们的星辰大海</a><br>🎤<a href="https://www.youtube.com/watch?v=6GHJhhmVgdE" target="_blank" rel="noopener">追梦赤子心</a><br>🎤<a href="https://www.youtube.com/watch?v=Hpnub-uM6eo" target="_blank" rel="noopener">小苹果</a><br>🎤<a href="https://www.youtube.com/watch?v=TRgum7sGAXw" target="_blank" rel="noopener">荷塘月色</a><br>🎤<a href="https://www.youtube.com/watch?v=nWb_X3ZJQjw" target="_blank" rel="noopener">温柔</a><br>🎤<a href="https://www.youtube.com/watch?v=AQ-cLkZ7Pqw" target="_blank" rel="noopener">远走高飞</a><br>🎤<a href="https://www.youtube.com/watch?v=jdf3gxFP0F8" target="_blank" rel="noopener">美人鱼</a><br>🎤<a href="https://www.youtube.com/watch?v=TmIk61_Msgg" target="_blank" rel="noopener">杀破狼</a><br>🎤<a href="https://www.youtube.com/watch?v=GggTls8KznY" target="_blank" rel="noopener">三国恋</a><br>🎤<a href="https://www.youtube.com/watch?v=WWSxxV0KBaI" target="_blank" rel="noopener">时间飞了</a><br>🎤<a href="https://www.youtube.com/watch?v=OU3kSSMLNvE" target="_blank" rel="noopener">曾经的你</a><br>🎤<a href="https://www.youtube.com/watch?v=sHD_z90ZKV0" target="_blank" rel="noopener">稻香</a><br>🎤<a href="https://www.youtube.com/watch?v=k8IiCim0iW4" target="_blank" rel="noopener">偏爱</a><br>🎤<a href="https://www.youtube.com/watch?v=QtXby3twMmI" target="_blank" rel="noopener">Adventure Of A Lifetime</a></p>
<h2 id="随便记记😆"><a href="#随便记记😆" class="headerlink" title="随便记记😆"></a>随便记记😆</h2><p>🎤<a href="https://www.youtube.com/watch?v=rmPHuvQoh0g" target="_blank" rel="noopener">没那么简单</a><br>🎤<a href="https://www.youtube.com/watch?v=qnDlH_S4Fak" target="_blank" rel="noopener">王妃</a><br>🎤<a href="https://www.youtube.com/watch?v=Ynypvs5s75Y" target="_blank" rel="noopener">最炫民族风</a><br>🎤<a href="https://www.youtube.com/watch?v=a_Dmq21YoIc" target="_blank" rel="noopener">猪之歌</a><br>🎤<a href="https://www.youtube.com/watch?v=4GWH8q8BTtU" target="_blank" rel="noopener">我相信</a><br>🎤<a href="https://www.youtube.com/watch?v=C_91v3amKDw" target="_blank" rel="noopener">燃烧你的卡路里</a><br>🎤<a href="https://www.youtube.com/watch?v=rYEDA3JcQqw" target="_blank" rel="noopener">Rolling in the Deep</a><br>🎤<a href="https://www.youtube.com/watch?v=Nn9HqibQYCc" target="_blank" rel="noopener">幸福糊涂虫</a><br>🎤<a href="https://www.youtube.com/watch?v=jn40gqhxoSY" target="_blank" rel="noopener">No Promises</a><br>🎤<a href="https://www.youtube.com/watch?v=X1Fqn9du7xo" target="_blank" rel="noopener">Whataya Want from Me</a><br>🎤<a href="https://www.youtube.com/watch?v=ABvAbpusRbc" target="_blank" rel="noopener">默</a><br>🎤<a href="https://www.youtube.com/watch?v=pUTqs4c1mSA" target="_blank" rel="noopener">羅曼蒂克的愛情</a><br>🎤<a href="https://www.youtube.com/watch?v=TMBe2ulmNIA" target="_blank" rel="noopener">江湖笑</a><br>🎤<a href="https://www.youtube.com/watch?v=MP241noyop8" target="_blank" rel="noopener">你不是真正的快乐</a><br>🎤<a href="https://www.youtube.com/watch?v=-5YFaTrZiAg" target="_blank" rel="noopener">新贵妃醉酒</a><br>🎤<a href="https://www.youtube.com/watch?v=nfs8NYg7yQM" target="_blank" rel="noopener">Attention</a><br>🎤<a href="https://www.youtube.com/watch?v=wGAmgmZg-48" target="_blank" rel="noopener">最初的梦想</a><br>🎤<a href="https://www.youtube.com/watch?v=meruGj7Gxdw" target="_blank" rel="noopener">给我你的爱</a><br>🎤<a href="https://www.youtube.com/watch?v=F901ls8TVnY" target="_blank" rel="noopener">咱们结婚吧</a><br>🎤<a href="https://www.youtube.com/watch?v=Q0qD-EGNncs" target="_blank" rel="noopener">最好的舞台</a><br>🎤<a href="https://www.youtube.com/watch?v=PvWAApWoYmc" target="_blank" rel="noopener">最美情侣</a><br>🎹<a href="https://www.youtube.com/watch?v=bMPM3o0NYAU" target="_blank" rel="noopener">Horizon</a><br>🎤<a href="https://www.youtube.com/watch?v=b_goBPeiD7w" target="_blank" rel="noopener">空空如也</a><br>🎤<a href="https://youtu.be/ayaGw9un1wE" target="_blank" rel="noopener">渴望光荣</a><br>🎤<a href="https://www.youtube.com/watch?v=E8NC_MH7dok" target="_blank" rel="noopener">那么骄傲</a><br>🎤<a href="https://www.youtube.com/watch?v=ru0K8uYEZWw" target="_blank" rel="noopener">CAN’T STOP THE FEELING</a><br>🎤<a href="https://www.youtube.com/watch?v=lEDZyIUbSd0" target="_blank" rel="noopener">明天会更好</a><br>🎤<a href="https://www.youtube.com/watch?v=CfihYWRWRTQ" target="_blank" rel="noopener">Love Me Again</a><br>🎤<a href="https://www.youtube.com/watch?v=NjTT5_RSkw4" target="_blank" rel="noopener">平凡之路</a><br>🎤<a href="https://www.youtube.com/watch?v=ft-D_5OmsRY" target="_blank" rel="noopener">怒放的生命</a><br>🎤<a href="https://www.youtube.com/watch?v=k-9Q--LbPXU" target="_blank" rel="noopener">新的心跳</a><br>🎤<a href="https://www.youtube.com/watch?v=0sXxhp9Zcow" target="_blank" rel="noopener">Be what You Wanna Be</a><br>🎤<a href="https://www.youtube.com/watch?v=qySMxzayRcM" target="_blank" rel="noopener">回到过去</a><br>🎤<a href="https://www.youtube.com/watch?v=CZ78y__MIzM" target="_blank" rel="noopener">青花瓷</a><br>🎤<a href="https://www.youtube.com/watch?v=AdkkF6MT0R0" target="_blank" rel="noopener">夜的第七章</a><br>🎤<a href="https://www.youtube.com/watch?v=6j0riQjd7Sc" target="_blank" rel="noopener">不仅仅是喜欢</a><br>🎤<a href="https://www.youtube.com/watch?v=6Q0Pd53mojY" target="_blank" rel="noopener">夜曲</a><br>🎤<a href="https://www.youtube.com/watch?v=QpmygPPuUQ4" target="_blank" rel="noopener">只要有你</a><br>🎤<a href="https://www.youtube.com/watch?v=OtEJ6LGCW-U" target="_blank" rel="noopener">有點甜</a><br>🎤<a href="https://www.youtube.com/watch?v=AnMhdn0wJ4I" target="_blank" rel="noopener">Nevada</a><br>🎤<a href="https://www.youtube.com/watch?v=T4SimnaiktU" target="_blank" rel="noopener">光年之外</a><br>🎤<a href="https://www.youtube.com/watch?v=OgjFJKUh34I" target="_blank" rel="noopener">戰火榮耀</a></p>
]]></content>
      <categories>
        <category>Music</category>
      </categories>
  </entry>
  <entry>
    <title>Prometheus Quick Start</title>
    <url>/2020/05/18/monitor-prometheus/</url>
    <content><![CDATA[<h1 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h1><p>A go project, basic introduction:<br><a href="https://github.com/yolossn/Prometheus-Basics" target="_blank" rel="noopener">https://github.com/yolossn/Prometheus-Basics</a></p>
<p>Architecture<br><img src="https://drive.google.com/uc?id=1WrobLras0BsfiVB_RphmprnA6-6Dm83U" alt=""></p>
<p>To recap:</p>
<ul>
<li>Know how to setup</li>
<li>Know how to configure</li>
<li>Know how to export different kind of metrics</li>
<li>Know how to PromQL</li>
<li>Know how to integrate Grafana</li>
</ul>
<p>Open-source monitoring and alerting toolkit: <a href="https://prometheus.io/" target="_blank" rel="noopener">https://prometheus.io/</a></p>
<ul>
<li>PromQL</li>
<li>Grafana integration</li>
<li>written in Go</li>
</ul>
<p>Type of metrics want to collect, get full view of the health of the system:<br>Runtime metrics</p>
<ul>
<li>memory usage</li>
<li>cpu load</li>
<li>other requests</li>
</ul>
<p>Application metrics, custom statistics<br>Docker metrics: 监控docker自身的状况也很重要</p>
<h2 id="Architecting"><a href="#Architecting" class="headerlink" title="Architecting"></a>Architecting</h2><ol>
<li>Metrics provider (spend more time analyzing app to see which states to be collected)<br>Docker container/server expose metrics API</li>
<li>Metrics server (polling server)<br>Prometheus container reads and store time-series data from metrics API</li>
<li>Metrics visualizer<br>Query and visualize data by Grafana running in another container to build the dashboard, we can add security access(https) of Grafana from outsdie the cluster.</li>
</ol>
<p>On prometheus side, using different configuration to different environment, for example: dev, test, prod have different polling interval seconds.</p>
<h2 id="Collecting-Metrics"><a href="#Collecting-Metrics" class="headerlink" title="Collecting Metrics"></a>Collecting Metrics</h2><p>Prometheus is driven by simple configuration file.</p>
<p>Prometheus image under <code>prom</code> org in Docker Hub:<br><a href="https://hub.docker.com/r/prom/prometheus" target="_blank" rel="noopener">https://hub.docker.com/r/prom/prometheus</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull prom/prometheus:v2.18.1</span><br><span class="line"><span class="comment">## --publish-all: publish all ports</span></span><br><span class="line"><span class="comment">## after run check which port is mapping to 9090</span></span><br><span class="line">docker run --detach --name=prom --publish-all prom/prometheus:v2.18.1</span><br></pre></td></tr></table></figure></p>
<p>Then access the interface via<code>&lt;public&gt;:&lt;port&gt;</code>. Per specified in prometheus Docker file, the configure file by default is <code>--config.file=/etc/prometheus/prometheus.yml</code> in container. You can customize as you need, for example, wrap the original image:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM prom/prometheus:v2.18.1</span><br><span class="line"><span class="comment">## copy your config file to default place</span></span><br><span class="line">COPY prometheus.yml /etc/prometheus/prometheus.yml</span><br></pre></td></tr></table></figure></p>
<p>Other userful image in <code>prom</code>:<br><a href="https://hub.docker.com/u/prom" target="_blank" rel="noopener">https://hub.docker.com/u/prom</a><br>Key components for monitoring:</p>
<ul>
<li>node-exporter</li>
<li>alertmanager</li>
<li>pushgateway </li>
</ul>
<h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><p><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/" target="_blank" rel="noopener">https://prometheus.io/docs/prometheus/latest/configuration/configuration/</a><br>Set other containers as scrape targets, in the prometheus UI, you can check the configuration file from <code>Status</code> -&gt; <code>Configuration</code>, for example:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line"><span class="attr">  scrape_interval:</span> <span class="number">10</span><span class="string">s</span></span><br><span class="line"></span><br><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'netfx-app'</span></span><br><span class="line">    <span class="comment">## metrics point http</span></span><br><span class="line"><span class="attr">    metrics_path:</span> <span class="string">/metrics/</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line">    <span class="comment">## netfx is the container name</span></span><br><span class="line">    <span class="comment">## 50506 is port number</span></span><br><span class="line"><span class="attr">      - targets:</span> <span class="string">['netfx:50506']</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'java-app'</span></span><br><span class="line"><span class="attr">    metrics_path:</span> <span class="string">/app-metrics/</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line"><span class="attr">      - targets:</span> <span class="string">['java:8080']</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'java-tomcat'</span></span><br><span class="line"><span class="attr">    metrics_path:</span> <span class="string">/metrics/</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line"><span class="attr">      - targets:</span> <span class="string">['java:8080']</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## monitor docker</span></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'docker-managers'</span></span><br><span class="line">    <span class="comment">## override global setting</span></span><br><span class="line"><span class="attr">    scrape_interval:</span> <span class="number">15</span><span class="string">s</span></span><br><span class="line"><span class="attr">    metrics_path:</span> <span class="string">/metrics</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line"><span class="attr">      - targets:</span> <span class="string">['host.docker.internal:50501']</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'docker-workers'</span></span><br><span class="line"><span class="attr">    scrape_interval:</span> <span class="number">15</span><span class="string">s</span></span><br><span class="line"><span class="attr">    metrics_path:</span> <span class="string">/metrics</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line"><span class="attr">      - targets:</span> <span class="string">['host.docker.internal:50501']</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Here the configuration is <code>static_configs</code>, Prometheus supports service discovery so is able to scrape all containers, good for dynamical and self-healing environment.</p>
</blockquote>
<h3 id="Metrics-data-type"><a href="#Metrics-data-type" class="headerlink" title="Metrics data type"></a>Metrics data type</h3><p><a href="https://prometheus.io/docs/concepts/metric_types/" target="_blank" rel="noopener">https://prometheus.io/docs/concepts/metric_types/</a></p>
<ul>
<li>counter (monotonic increasing)</li>
<li>gauge (up and down)</li>
<li>histogram</li>
<li>summary<br>目前就这几种类型的metrics type，prometheus server收集这些数据并且存在数据库中，可以使用promQL去查询。自带的graph UI比较简单，后面会有Grafana去帮忙显示。</li>
</ul>
<h2 id="Exposing-Metrics"><a href="#Exposing-Metrics" class="headerlink" title="Exposing Metrics"></a>Exposing Metrics</h2><p>Let’s see how to export metrics for prometheus to scrape.</p>
<h3 id="Runtime-metrics"><a href="#Runtime-metrics" class="headerlink" title="Runtime metrics"></a>Runtime metrics</h3><p>Runtime (operating system or application host data) has metrics by its own, for example, Tomcat has web server metrics, Java has JVM metrics, we just need to expose them from container as <code>/metrics</code>.</p>
<ul>
<li>Using exporting utility<br>For app which don’t have their own metrics API</li>
<li>Running in app container</li>
<li>Reading runtime metrics</li>
<li>Exporting in prometheus format</li>
</ul>
<p>Exporter的好处是显而易见的，比如legacy app没有metrics的接口，这时候可以使用exporter去处理。如此一来Container hosts both app and exportor，要注意exportor不要占用太多资源。</p>
<p>Exporter integration:<br><a href="https://prometheus.io/docs/instrumenting/exporters/" target="_blank" rel="noopener">https://prometheus.io/docs/instrumenting/exporters/</a></p>
<p>This Dockerfile has integrated Tomcat exporter:<br><a href="https://github.com/nlighten/tomcat_exporter" target="_blank" rel="noopener">https://github.com/nlighten/tomcat_exporter</a><br>Just several extra line added:<br><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment">## build source code</span></span><br><span class="line"><span class="keyword">FROM</span> maven:<span class="number">3.5</span>.<span class="number">4</span>-jdk-<span class="number">8</span>-slim AS builder</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /usr/src/jsfapp </span></span><br><span class="line"><span class="bash">COPY src/java/jsfapp/pom.xml .</span></span><br><span class="line"><span class="bash">RUN mvn -B -f pom.xml -s /usr/share/maven/ref/settings-docker.xml dependency:resolve</span></span><br><span class="line"><span class="bash">COPY src/java/jsfapp .</span></span><br><span class="line"><span class="bash">RUN mvn -B -s /usr/share/maven/ref/settings-docker.xml package -DskipTests</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment"># app image</span></span></span><br><span class="line"><span class="bash">FROM tomcat:8.5-jre8-alpine</span></span><br><span class="line"><span class="bash">ENV WEBAPP_HOME=<span class="variable">$&#123;CATALINA_HOME&#125;</span>/webapps</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">RUN rm -r -f <span class="variable">$&#123;WEBAPP_HOME&#125;</span></span></span><br><span class="line"><span class="bash"><span class="comment">#############################</span></span></span><br><span class="line"><span class="bash"><span class="comment">## add exporter utility</span></span></span><br><span class="line"><span class="bash">WORKDIR <span class="variable">$&#123;WEBAPP_HOME&#125;</span></span></span><br><span class="line"><span class="bash"><span class="comment">## copy exporter jar and war files</span></span></span><br><span class="line"><span class="bash">COPY --from=psmonitoring/tomcat-exporter:0.0.6 /exporter/*.jar <span class="variable">$&#123;CATALINA_HOME&#125;</span>/lib/</span></span><br><span class="line"><span class="bash">COPY --from=psmonitoring/tomcat-exporter:0.0.6 /exporter/tomcat_exporter_servlet-0.0.6.war ./metrics.war</span></span><br><span class="line"><span class="bash"><span class="comment">#############################</span></span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">WORKDIR <span class="variable">$&#123;WEBAPP_HOME&#125;</span>/ROOT </span></span><br><span class="line"><span class="bash"><span class="comment">## copy from builder (see first line)</span></span></span><br><span class="line"><span class="bash">COPY --from=builder /usr/src/jsfapp/target/jsfapp/ .</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Application-metrics"><a href="#Application-metrics" class="headerlink" title="Application metrics"></a>Application metrics</h3><p><a href="https://prometheus.io/docs/instrumenting/clientlibs/" target="_blank" rel="noopener">https://prometheus.io/docs/instrumenting/clientlibs/</a><br>Using prometheus client libraries, 选择匹配你开发语言的库，然后加入依赖调用即可。</p>
<p>Also see best practice:<br><a href="https://prometheus.io/docs/practices/naming/" target="_blank" rel="noopener">https://prometheus.io/docs/practices/naming/</a><br><code>Label</code> is useful, for example, you want to metrics the http response, there are several kinds: 200 OK, 500 Internal Server Error, 401 Unauthroized, 403 Forbidden. Don;t separate them to different metrics, too complicated, just put them as http_response_total with different label, easy to graph and filter. </p>
<p>Some guidelines:</p>
<ul>
<li>Any external interactions with other systems should be instrumented, so you know how often your app is communicating, whether the communication succeeds, and how long it takes. </li>
<li>Any workflows that involve multiple processes should be instrumented at each stage with a correlation ID label, so you can track progress through the system. </li>
<li>Any business facing metrics, which need reporting on, should be instrumented, so you can build a live dashboard rather than sending out historical reports. </li>
<li>Look at all the logging that you currently have in your app. Try to instrument total counts for each type of log entry, info, warn, error and so on. Then you can compare the numbers between environments or between releases.</li>
</ul>
<p>For example, use <code>/app-metrics</code> as endpoint to expose. For example, adding metrics to Java App:</p>
<ol>
<li>maven prometheus client library</li>
<li>create and register custom metrics</li>
<li>increment counters and gauges</li>
<li>servlet hosting metrics endpoint </li>
</ol>
<h3 id="Docker-metrics"><a href="#Docker-metrics" class="headerlink" title="Docker metrics"></a>Docker metrics</h3><p>Experimental mode in docker but safe to use, docker metrics includes:</p>
<ul>
<li>Engine details</li>
<li>Image builds</li>
<li>Containers<br>The metrics endpoint is in standard prometheus text format.</li>
</ul>
<h3 id="Grafana-Integration"><a href="#Grafana-Integration" class="headerlink" title="Grafana Integration"></a>Grafana Integration</h3><p>Grafana image in Docker Hub:<br><a href="https://hub.docker.com/r/grafana/grafana" target="_blank" rel="noopener">https://hub.docker.com/r/grafana/grafana</a></p>
<ul>
<li>Running in container</li>
<li>Connecting to Prometheus</li>
<li>Visualizing query results</li>
<li>Packaging the dashboard</li>
</ul>
<p>Grafana support querying time-series database like <strong>prometheus</strong> and influxdb, also support <strong>Elasticsearch</strong> logging &amp; analytics database.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## pull image</span></span><br><span class="line">docker pull grafana/grafana:7.0.0</span><br><span class="line">docker run --detach --name=grafana --publish-all grafana/grafana:7.0.0</span><br></pre></td></tr></table></figure>
<p>The default login is <code>admin/admin</code>. After login, go to set <code>Data Sources</code>, select prometheus and specify the url, then import data in dashboard.</p>
<p>You can also create new dashboard with different graph, import and query data from data sources.</p>
<p>更深入的话比如如何设置alerting等。</p>
<h1 id="Pair-with-Kubernetes"><a href="#Pair-with-Kubernetes" class="headerlink" title="Pair with Kubernetes"></a>Pair with Kubernetes</h1><p><a href="https://www.youtube.com/watch?v=bErGEHf6GCc&amp;list=PLpbcUe4chE7-HuslXKj1MB10ncorfzEGa" target="_blank" rel="noopener">https://www.youtube.com/watch?v=bErGEHf6GCc&amp;list=PLpbcUe4chE7-HuslXKj1MB10ncorfzEGa</a><br><a href="https://www.youtube.com/watch?v=CmPdyvgmw-A" target="_blank" rel="noopener">https://www.youtube.com/watch?v=CmPdyvgmw-A</a><br><a href="https://www.youtube.com/watch?v=h4Sl21AKiDg" target="_blank" rel="noopener">https://www.youtube.com/watch?v=h4Sl21AKiDg</a></p>
<p><a href="https://www.youtube.com/watch?v=5o37CGlNLr8" target="_blank" rel="noopener">https://www.youtube.com/watch?v=5o37CGlNLr8</a><br><a href="https://www.youtube.com/watch?v=LQpmeb7idt8" target="_blank" rel="noopener">https://www.youtube.com/watch?v=LQpmeb7idt8</a></p>
<p>articles:<br><a href="https://www.metricfire.com/blog/prometheus-vs-elk" target="_blank" rel="noopener">https://www.metricfire.com/blog/prometheus-vs-elk</a><br><a href="https://logz.io/blog/grafana-vs-kibana/" target="_blank" rel="noopener">https://logz.io/blog/grafana-vs-kibana/</a></p>
]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>monitor</tag>
        <tag>prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title>Elastic Stack Quick Start</title>
    <url>/2020/05/20/monitor-elasticsearch/</url>
    <content><![CDATA[<h1 id="Elastic-Stack"><a href="#Elastic-Stack" class="headerlink" title="Elastic Stack"></a>Elastic Stack</h1><p><a href="https://www.elastic.co/elastic-stack" target="_blank" rel="noopener">https://www.elastic.co/elastic-stack</a><br>The Elastic Stack is one of the most effective ways to leverage open source technology to build a central logging, monitoring, and alerting system for servers and applications.</p>
<p><code>Elasticsearch</code>: distributed, fast, highly scalable document database.<br><code>Logstash</code>: Aggregates, filters and supplyments log data, forwards them to Elasticsearch.<br><code>Kibana</code>: Web-based front-end to visualize data.<br><code>Beats</code>: lightweight utilities for reading logs from a varity of sources, sends data to Logstash or other backends.<br><code>Altering</code>: Send notifications to email, slack, pagerduty so on and so forth.</p>
<p><img src="https://drive.google.com/uc?id=1ch29tlydlCpFxh2RARV0EVxH_1AWSzRl" alt=""></p>
<p><a href="https://stackoverflow.com/questions/40793901/prometheus-vs-elasticsearch-which-is-better-for-container-and-server-monitoring" target="_blank" rel="noopener">Elastic stack vs Prometheus</a>:<br>ELK is general-purpose no-sql stack can be used for monitoring, aggregating all the logging and shipping to elastic search for ease of browsing all the logging and similar things.</p>
<p>Prometheus is dedicated monitoring system, alongside with service discovery consul and alert-manager, the right tool for the jobs.</p>
<h2 id="Install-Elasticsearch"><a href="#Install-Elasticsearch" class="headerlink" title="Install Elasticsearch"></a>Install Elasticsearch</h2><p>There are several ways to install: binary, rpm or on kubernetes<br><a href="https://www.elastic.co/downloads/elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/downloads/elasticsearch</a></p>
<blockquote>
<p>Java runtime is required.</p>
</blockquote>
<p>I am here installing by yum repo with latest Elasticsearch version, before launching it go to <code>/etc/elasticsearch/elasticsearch.yml</code>, set the cluster name and node name, for example:<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/rpm.html#rpm-configuring" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.7/rpm.html#rpm-configuring</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## cluster name</span></span><br><span class="line">cluster.name: chengdol-els</span><br><span class="line"><span class="comment">## node name</span></span><br><span class="line">node.name: master</span><br><span class="line"><span class="comment">## ip to access</span></span><br><span class="line">network.host: 9.30.94.85</span><br><span class="line"><span class="comment">## this is one of the must configuration</span></span><br><span class="line">discovery.seed_hosts: [<span class="string">"127.0.0.1"</span>, <span class="string">"[::1]"</span>]</span><br></pre></td></tr></table></figure></p>
<p>Then changing one system level setting (this is default, can skip):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## permenantly </span></span><br><span class="line">sysctl -w vm.max_map_count=262144</span><br></pre></td></tr></table></figure></p>
<p>The start by systemd<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start Elasticsearch</span><br></pre></td></tr></table></figure></p>
<p>Check the server is up and running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 9200 is the defaul port</span></span><br><span class="line"><span class="comment">## or using postman</span></span><br><span class="line">curl http://9.30.94.85:9200</span><br><span class="line"></span><br><span class="line"><span class="comment">## response from Elasticsearch server</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span> : <span class="string">"master"</span>,</span><br><span class="line">  <span class="string">"cluster_name"</span> : <span class="string">"chengdol-els"</span>,</span><br><span class="line">  <span class="string">"cluster_uuid"</span> : <span class="string">"1fDfNniwR-uX3mXHQGItVw"</span>,</span><br><span class="line">  <span class="string">"version"</span> : &#123;</span><br><span class="line">    <span class="string">"number"</span> : <span class="string">"7.7.0"</span>,</span><br><span class="line">    <span class="string">"build_flavor"</span> : <span class="string">"default"</span>,</span><br><span class="line">    <span class="string">"build_type"</span> : <span class="string">"rpm"</span>,</span><br><span class="line">    <span class="string">"build_hash"</span> : <span class="string">"81a1e9eda8e6183f5237786246f6dced26a10eaf"</span>,</span><br><span class="line">    <span class="string">"build_date"</span> : <span class="string">"2020-05-12T02:01:37.602180Z"</span>,</span><br><span class="line">    <span class="string">"build_snapshot"</span> : <span class="literal">false</span>,</span><br><span class="line">    <span class="string">"lucene_version"</span> : <span class="string">"8.5.1"</span>,</span><br><span class="line">    <span class="string">"minimum_wire_compatibility_version"</span> : <span class="string">"6.8.0"</span>,</span><br><span class="line">    <span class="string">"minimum_index_compatibility_version"</span> : <span class="string">"6.0.0-beta1"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"tagline"</span> : <span class="string">"You Know, for Search"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Install-Logstash"><a href="#Install-Logstash" class="headerlink" title="Install Logstash"></a>Install Logstash</h2><p><a href="https://www.elastic.co/downloads/logstash" target="_blank" rel="noopener">https://www.elastic.co/downloads/logstash</a></p>
<blockquote>
<p>Java runtime is required.</p>
</blockquote>
<p>Installing by yum repos, by default the app location is in <code>/usr/share/logstash</code>, enable and start by systemd. A simple test to verify the correction:</p>
<p>Using systemd to start Logstash will load the configuration specified in <code>/etc/logstash/logstash.yml</code>. Using command to start Logstash is not recommended, usually for testing.</p>
<p>In <code>/etc/logstash/logstash.yml</code> file, you can set the value of <code>path.config</code> field so Logstash know where to pick the pipeline configurations.<br><a href="https://www.elastic.co/guide/en/logstash/current/logstash-settings-file.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/logstash-settings-file.html</a></p>
<p>A brief deviation, If you run <code>systemctl status logstash</code>, will see<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Loaded: loaded (/etc/systemd/system/logstash.service; disabled; vendor preset: disabled)</span><br></pre></td></tr></table></figure></p>
<p>Open and check <code>/etc/systemd/system/logstash.service</code>, you will find where the configuration files reside: <code>/etc/logstash</code>, also where is the executable <code>/usr/share/logstash</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/share/logstash</span><br><span class="line"><span class="comment">## test running</span></span><br><span class="line">bin/logstash -e <span class="string">'input &#123; stdin &#123; &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; ["&lt;9.30.94.85&gt;:9200"] &#125; &#125;'</span></span><br><span class="line"><span class="comment">## then type something to send</span></span><br></pre></td></tr></table></figure>
<p>Then use curl or postman to fetch log from Elasticsearch:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## you will see what you typed in logstash</span></span><br><span class="line">curl http://9.30.94.85:9200/logstash-*/_search</span><br></pre></td></tr></table></figure></p>
<h3 id="Read-Beats-Data"><a href="#Read-Beats-Data" class="headerlink" title="Read Beats Data"></a>Read Beats Data</h3><p>To read data from Beats:</p>
<ol>
<li>Input: where is the data from? logs? beats?</li>
<li>Filter: how should we parse the data? grok filters, geoip filters, etc.</li>
<li>Output: where should we store the logs? backend? Elasticsearch?</li>
</ol>
<p>Go to <code>/etc/logstash/conf.d</code>, create new file for example, <code>beats.conf</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    <span class="comment">## in Beats side, listening on port 5043</span></span><br><span class="line">    beats &#123;</span><br><span class="line">        port =&gt; <span class="string">"5043"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">    <span class="keyword">if</span> [<span class="built_in">type</span>] == <span class="string">"syslog"</span> &#123;</span><br><span class="line">        <span class="comment">## grok filter</span></span><br><span class="line">        grok &#123;</span><br><span class="line">            match =&gt; &#123; <span class="string">"message"</span> =&gt; <span class="string">"%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\[%&#123;POSINT:syslog_pid&#125;\])?: %&#123;GREEDYDATA:syslog_message&#125;"</span> &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        date &#123;</span><br><span class="line">           match =&gt; [ <span class="string">"syslog_timestamp"</span>, <span class="string">"MMM  d HH:mm:ss"</span>, <span class="string">"MMM dd HH:mm:ss"</span> ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        <span class="comment">## Elasticsearch address</span></span><br><span class="line">        hosts =&gt; [ <span class="string">"9.30.94.85:9200"</span> ]</span><br><span class="line">        <span class="comment">## 这个对应Kibana中的Index Patterns</span></span><br><span class="line">        index =&gt; <span class="string">"%&#123;[@metadata][beat]&#125;-%&#123;+YYYY.MM.dd&#125;"</span></span><br><span class="line">        document_type =&gt; <span class="string">"%&#123;[@metadata][type]&#125;"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Then run command to testing file validity:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## --config.test_and_exit: parses configuration file and reports any errors.</span></span><br><span class="line">bin/logstash -f beats.conf --config.test_and_exit</span><br><span class="line"></span><br><span class="line"><span class="comment">## The --config.reload.automatic: enables automatic config reloading so that don’t have to stop and restart Logstash every time modify the configuration file.</span></span><br><span class="line">bin/logstash -f beats.conf --config.reload.automatic</span><br></pre></td></tr></table></figure></p>
<h2 id="Install-Kibana"><a href="#Install-Kibana" class="headerlink" title="Install Kibana"></a>Install Kibana</h2><p><a href="https://www.elastic.co/downloads/kibana" target="_blank" rel="noopener">https://www.elastic.co/downloads/kibana</a><br>written in Node.js, no other dependencies needed.</p>
<p>Do a quick configuration, then start by systemd:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/kibana/kibana.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># To allow connections from remote users, set this parameter to a non-loopback address.</span></span><br><span class="line">server.host: <span class="string">"9.30.94.85"</span></span><br><span class="line"><span class="comment"># The Kibana server's name.  This is used for display purposes.</span></span><br><span class="line">server.name: <span class="string">"chengdol-kibana"</span></span><br><span class="line"><span class="comment"># The URLs of the Elasticsearch instances to use for all your queries.</span></span><br><span class="line">elasticsearch.hosts: [<span class="string">"http://9.30.94.85:9200"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## start</span></span><br><span class="line">systemctl start kibana</span><br><span class="line"><span class="comment">## to view the web interface</span></span><br><span class="line"><span class="comment">## default is 5601</span></span><br><span class="line">http://9.30.94.85:5601</span><br></pre></td></tr></table></figure></p>
<h3 id="Create-Dashboard"><a href="#Create-Dashboard" class="headerlink" title="Create Dashboard"></a>Create Dashboard</h3><p>Go to <code>Management</code>, create <code>Index Patterns</code> set format to poll data from Elasticsearch, then <code>Visualize</code> create graphs, add the graph to <code>Dashboard</code>.</p>
<h2 id="Beats"><a href="#Beats" class="headerlink" title="Beats"></a>Beats</h2><p><a href="https://www.elastic.co/beats/" target="_blank" rel="noopener">https://www.elastic.co/beats/</a><br>Beats can output data to Elasticsearch, Logstash and Redis. But usually we send data to Logstash (pre-processing) then forward to Elasticsearch.</p>
<p>Each Beat has configure yaml file with detailed configuration guideline. For example, in the configure yaml file, comment out Elasticsearch output, use Logstash output.</p>
<ul>
<li>Filebeat: text log files</li>
<li>Metricbeat: OS and applications</li>
<li>Packetbeat: network monitoring</li>
<li>Winlogbeat: windows event log</li>
<li>Libbeat: write your own</li>
</ul>
<h2 id="Alerting"><a href="#Alerting" class="headerlink" title="Alerting"></a>Alerting</h2><p>Not free feature.</p>
<p>Workflow:</p>
<ul>
<li>Schedule/trigger</li>
<li>Input/Query</li>
<li>Condition</li>
<li>Action</li>
</ul>
]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>monitor</tag>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Open Sources</title>
    <url>/2019/03/09/open-source/</url>
    <content><![CDATA[<h1 id="Open-source-projects"><a href="#Open-source-projects" class="headerlink" title="Open source projects"></a>Open source projects</h1><ul>
<li><a href="https://github.com/sindresorhus/awesome" target="_blank" rel="noopener">awesome-list</a></li>
<li><a href="https://github.com/alebcay/awesome-shell" target="_blank" rel="noopener">awesome-shell</a></li>
<li><a href="https://github.com/veggiemonk/awesome-docker" target="_blank" rel="noopener">awwsome-docker</a></li>
<li><a href="https://github.com/ramitsurana/awesome-kubernetes" target="_blank" rel="noopener">awesome-kubernetes</a></li>
<li><a href="https://github.com/akullpp/awesome-java" target="_blank" rel="noopener">awesome-java</a></li>
</ul>
<h1 id="Books"><a href="#Books" class="headerlink" title="Books"></a>Books</h1><ul>
<li><a href="https://github.com/dylanaraps/pure-bash-bible" target="_blank" rel="noopener">pure bash bible</a><br>这个是中文版的简明教程，非常不错了</li>
<li><a href="https://wangdoc.com/bash/" target="_blank" rel="noopener">Bash tutorial</a></li>
<li><a href="https://www.usenix.org/sites/default/files/conference/protected-files/lisa19_maheshwari.pdf" target="_blank" rel="noopener">Linux Productivity Tools</a></li>
<li><a href="https://github.com/xjh22222228/git-manual" target="_blank" rel="noopener">git manual</a></li>
</ul>
<h1 id="Blogs"><a href="#Blogs" class="headerlink" title="Blogs"></a>Blogs</h1><ul>
<li><a href="https://www.liaoxuefeng.com/" target="_blank" rel="noopener">廖雪峰的官方网站</a></li>
</ul>
]]></content>
      <categories>
        <category>Open Source</category>
      </categories>
  </entry>
  <entry>
    <title>Openshift Vs Kubernetes</title>
    <url>/2019/07/09/openshift-intro/</url>
    <content><![CDATA[<p>OpenShift version: <code>3.10</code></p>
<p>I have worked on Kubernetes and OpenShift for several months, both are good container management and schedule tools, they have many overlaps and the kubectl commands are compitable in OpenShift, so what the exactly differences between them are?</p>
<p>我大概是从2018年下半年开始接触OpenShift的，当时要求将部署移植到OpenShift平台上。推荐一本书:<code>&lt;&lt;开源容器云OpenShift 构建基于Kubernetes的企业应用云平台&gt;&gt;</code>，这本书基本上介绍清楚了OpenShift的一些基本操作和概念，也提到了和K8s不同的地方。</p>
<blockquote>
<p>A brief Digression: Today IBM officially close the acquisistion of Red Hat!</p>
</blockquote>
<h3 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h3><p><a href="https://en.wikipedia.org/wiki/OpenShift" target="_blank" rel="noopener">OpenShift-wikipedia</a></p>
<ol>
<li>OpenShift is a family of containerization software developed by Red Hat. Its flagship product is the <code>OpenShift Container Platform</code>, an on-premises platform as a service built around <code>Docker containers</code> orchestrated and managed by <code>Kubernetes</code> on a foundation of <code>Red Hat Enterprise Linux</code>. </li>
</ol>
<p><a href="https://www.redhat.com/en/blog/openshift-and-kubernetes-whats-difference" target="_blank" rel="noopener">The Differences Between Kubernetes and Openshift</a></p>
<ol>
<li>Kubernetes is the kernel</li>
<li>Openshift is the distribution</li>
</ol>
<p><a href="https://cloudowski.com/articles/10-differences-between-openshift-and-kubernetes/" target="_blank" rel="noopener">10 most important differences between OpenShift and Kubernetes</a></p>
<ol>
<li>OKD can install on rhel and centos</li>
<li>Kubernetes is an integral part of OpenShift with more features built around it.</li>
<li>OpenShift has more strict security policies than default Kubernetes, most of container images available on Docker Hub or we have built before won’t run on OpenShift, because it forbids to run a container as root. we need to relax this strict to give the workspace higher privileges to run container as root, or update our image to</li>
</ol>
<p><a href="https://medium.com/levvel-consulting/the-differences-between-kubernetes-and-openshift-ae778059a90e" target="_blank" rel="noopener">The Differences Between Kubernetes and Openshift</a></p>
]]></content>
      <categories>
        <category>OpenShift</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>openshift</tag>
      </tags>
  </entry>
  <entry>
    <title>Cluster Image Registry in OpenShift</title>
    <url>/2020/02/26/openshift-image-registry/</url>
    <content><![CDATA[<p>OpenShift version: <code>4.3</code></p>
<h2 id="Create-Internal-Image-Registry-Route"><a href="#Create-Internal-Image-Registry-Route" class="headerlink" title="Create Internal Image Registry Route"></a>Create Internal Image Registry Route</h2><p>From the Infra Node, run the following commands.<br>This will create a accessable path for you to push image to internal image registry.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc project openshift-image-registry</span><br><span class="line">oc patch configs.imageregistry.operator.openshift.io/cluster --<span class="built_in">type</span> merge -p <span class="string">'&#123;"spec":&#123;"defaultRoute":true&#125;&#125;'</span></span><br><span class="line"><span class="comment">## we need this output when tag and push image</span></span><br><span class="line">CLUSTER_IMAGE_REGISTRY_ROUTE=$(oc get route)</span><br></pre></td></tr></table></figure></p>
<h2 id="Pull-Tag-and-Push-Image"><a href="#Pull-Tag-and-Push-Image" class="headerlink" title="Pull, Tag and Push Image"></a>Pull, Tag and Push Image</h2><p>Here we use podman:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## pull original from other registry</span></span><br><span class="line"><span class="comment">## or use podman to load image archive</span></span><br><span class="line">podman login -u &lt;user&gt; -p &lt;password&gt; docker.io</span><br><span class="line">podman load -i &lt;image&gt;.tar.gz</span><br><span class="line"></span><br><span class="line">podman pull &lt;path&gt;/&lt;image&gt;:&lt;tag&gt;</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PRIVATE_REGISTRY=<span class="variable">$&#123;CLUSTER_IMAGE_REGISTRY_ROUTE&#125;</span>/&lt;project&gt;</span><br><span class="line"><span class="comment">## kubeadmin is the default cluster admin</span></span><br><span class="line">podman login -u kubeadmin -p $(oc whoami -t)  <span class="variable">$PRIVATE_REGISTRY</span> --tls-verify=<span class="literal">false</span></span><br><span class="line"></span><br><span class="line">podman tag  &lt;path&gt;/&lt;image&gt;:&lt;tag&gt; <span class="variable">$PRIVATE_REGISTRY</span>/&lt;image&gt;:&lt;tag&gt;</span><br><span class="line">podman push <span class="variable">$PRIVATE_REGISTRY</span>/&lt;image&gt;:&lt;tag&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Create-Role-and-Binding"><a href="#Create-Role-and-Binding" class="headerlink" title="Create Role and Binding"></a>Create Role and Binding</h2><p>You need to get authenicated when pull image from cluster image registry, here we create a dedicated service account under the target project, then grant privileges to this service account and specify it to yaml file.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">oc</span> <span class="string">apply</span> <span class="bullet">-f</span> <span class="bullet">-</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">&lt;service</span> <span class="string">account</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">&lt;projetc&gt;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">&lt;cluster</span> <span class="string">role</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">["*"]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["*"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["*"]</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">&lt;couster</span> <span class="string">role</span> <span class="string">binding</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">  - kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">&lt;service</span> <span class="string">account</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">&lt;project&gt;</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">&lt;cluster</span> <span class="string">role</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>
<p>Example pod yaml file:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="comment">## specify the service accout</span></span><br><span class="line"><span class="attr">  serviceAccountName:</span> <span class="string">&lt;service</span> <span class="string">account</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">test-cotainer</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">image-registry.openshift-image-registry.svc:5000/&lt;project&gt;/&lt;image&gt;:&lt;tag&gt;</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'tail -f /dev/null'</span><span class="string">]</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that the default cluster registry path is <code>image-registry.openshift-image-registry.svc:5000</code>, consist of <code>&lt;svc name&gt;.&lt;project&gt;.svc:&lt;port&gt;</code>. don’t use that route path.</p>
</blockquote>
]]></content>
      <categories>
        <category>OpenShift</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>openshift</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenShift SCC Customized</title>
    <url>/2019/07/16/openshift-scc-customized/</url>
    <content><![CDATA[<p>OpenShift version: <code>3.10</code></p>
<p>There are by default 7 SCCs in OpenShift, but that may not satisfy the demands and it’s better to create a new dedicated one to use for non-root deployment.</p>
<blockquote>
<p>To get basic understand about <code>SCC</code>, see my blog <a href="https://chengdol.github.io/2019/06/21/openshift-scc/" target="_blank" rel="noopener"><code>&lt;&lt;OpenShift Security Context Constraint&gt;&gt;</code></a>.</p>
</blockquote>
<p>7 default existing SCCs are:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc get scc</span><br><span class="line"></span><br><span class="line">NAME               PRIV      CAPS      SELINUX     RUNASUSER          FSGROUP     SUPGROUP    PRIORITY   READONLYROOTFS   VOLUMES</span><br><span class="line">anyuid             <span class="literal">false</span>     []        MustRunAs   RunAsAny           RunAsAny    RunAsAny    10         <span class="literal">false</span>            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">hostaccess         <span class="literal">false</span>     []        MustRunAs   MustRunAsRange     MustRunAs   RunAsAny    &lt;none&gt;     <span class="literal">false</span>            [configMap downwardAPI emptyDir hostPath persistentVolumeClaim projected secret]</span><br><span class="line">hostmount-anyuid   <span class="literal">false</span>     []        MustRunAs   RunAsAny           RunAsAny    RunAsAny    &lt;none&gt;     <span class="literal">false</span>            [configMap downwardAPI emptyDir hostPath nfs persistentVolumeClaim projected secret]</span><br><span class="line">hostnetwork        <span class="literal">false</span>     []        MustRunAs   MustRunAsRange     MustRunAs   MustRunAs   &lt;none&gt;     <span class="literal">false</span>            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">nonroot            <span class="literal">false</span>     []        MustRunAs   MustRunAsNonRoot   RunAsAny    RunAsAny    &lt;none&gt;     <span class="literal">false</span>            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">privileged         <span class="literal">true</span>      [*]       RunAsAny    RunAsAny           RunAsAny    RunAsAny    &lt;none&gt;     <span class="literal">false</span>            [*]</span><br><span class="line">restricted         <span class="literal">false</span>     []        MustRunAs   MustRunAsRange     MustRunAs   RunAsAny    &lt;none&gt;     <span class="literal">false</span>            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br></pre></td></tr></table></figure></p>
<p>Don’t forget to examine SCC, such as <code>oc describe scc privileged</code>.</p>
<h2 id="SCC-Yaml-Demo"><a href="#SCC-Yaml-Demo" class="headerlink" title="SCC Yaml Demo"></a>SCC Yaml Demo</h2><blockquote>
<p>How to write SCC yaml and what does each field mean? <a href="https://docs.openshift.com/container-platform/3.9/architecture/additional_concepts/authorization.html#security-context-constraints" target="_blank" rel="noopener">OpenShift SCC official</a></p>
</blockquote>
<p>Create a file named as <code>scc-customized.yaml</code>, carefully fill the value to satisfy the demands<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">SecurityContextConstraints</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">scc-customized</span></span><br><span class="line"><span class="comment">## permission</span></span><br><span class="line"><span class="attr">allowPrivilegedContainer:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">allowHostIPC:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">allowHostNetwork:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">allowHostPID:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">allowHostPorts:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment">#allowedFlexVolumes: null</span></span><br><span class="line"><span class="comment">## linux capabilities, some pods require these</span></span><br><span class="line"><span class="attr">allowedCapabilities:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">SYS_NICE</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">IPC_OWNER</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">SYS_RESOURCE</span></span><br><span class="line"><span class="attr">requiredDropCapabilities:</span> <span class="string">[]</span></span><br><span class="line"><span class="attr">defaultAddCapabilities:</span> <span class="string">[]</span></span><br><span class="line"><span class="comment">## strategies</span></span><br><span class="line"><span class="attr">runAsUser:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">MustRunAsNonRoot</span></span><br><span class="line"><span class="attr">seLinuxContext:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">RunAsAny</span></span><br><span class="line"><span class="attr">fsGroup:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">RunAsAny</span></span><br><span class="line"><span class="attr">supplementalGroups:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">RunAsAny</span></span><br><span class="line"><span class="comment">## who can access this SCC</span></span><br><span class="line"><span class="attr">users:</span> <span class="string">[]</span></span><br><span class="line"><span class="attr">groups:</span></span><br><span class="line"><span class="attr">- system:</span><span class="string">authenticated</span></span><br><span class="line"><span class="comment">## may narrow down insteaf of `*`</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">'*'</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc create -f scc-customized.yaml</span><br></pre></td></tr></table></figure>
<p>Then, for example, you can bind <code>default</code> service account to this <code>SCC</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc adm policy add-scc-to-user scc-customized system:serviceaccount:&lt;project&gt;:default</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>A <code>default</code> service account is used by all other pods unless they specify a different service account.</p>
</blockquote>
]]></content>
      <categories>
        <category>OpenShift</category>
      </categories>
      <tags>
        <tag>openshift</tag>
        <tag>scc</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenShift RBAC</title>
    <url>/2020/02/20/openshift-rbac/</url>
    <content><![CDATA[<p>OpenShift version: <code>4.3</code></p>
<p>OpenShift current is evolved to version <code>4.3</code> (last time when I was working on it, it was version <code>3.11</code>), I am assigned to try non-root install for DS assembly (a plugin) in CP4D cluster. what non-root means<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">No cluster admin privileges</span><br><span class="line">No root processes in containers</span><br><span class="line">No host access or ssh requirements</span><br><span class="line">No elevated SCCs (other than the cpd defaults)</span><br></pre></td></tr></table></figure></p>
<p>We have met last 3 requirements, so focus on first one.</p>
<p>After doing research, the steps are clear but not that straightforward (相比3.11目前版本的配置变化还挺大的，支持的内容更丰富了)</p>
<ol>
<li>Create regular user</li>
<li>Specify identity provider for OAuth</li>
<li>Bind necessary cluster role or local role</li>
<li>Run installation</li>
</ol>
<p>4.3版本的一大变化是kubeadmin是默认的cluster-admin user，如同之前的systemadmin, kubeadmin is treated as the root user for the cluster. The password is dynamically generated and unique to your OpenShift Container Platform environment.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc login -u kubeadmin -p IVfPS-FvJZI-Vagzw-nIpVA --server=https://api.dsocp43.os.fyre.ibm.com:6443</span><br></pre></td></tr></table></figure></p>
<p>password is provided in output when install is done，记下来就行，之前3.11 systemadmin是不需要password login的。</p>
<h2 id="Create-user-and-specify-identity-provider"><a href="#Create-user-and-specify-identity-provider" class="headerlink" title="Create user and specify identity provider"></a>Create user and specify identity provider</h2><p><a href="https://docs.openshift.com/container-platform/4.3/authentication/understanding-identity-provider.html" target="_blank" rel="noopener">Understanding identity provider configuration</a>。<br>By default, only a kubeadmin user exists on your cluster. To specify an identity provider, you must create a Custom Resource (CR) that describes that identity provider and add it to the cluster.</p>
<p>这里我选择htpasswd当作identity provider, <a href="https://docs.openshift.com/container-platform/4.3/authentication/identity_providers/configuring-htpasswd-identity-provider.html" target="_blank" rel="noopener">Configuring an HTPasswd identity provider</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## htpasswd -c -B -b &lt;/path/to/users.htpasswd&gt; &lt;user_name&gt; &lt;password&gt;</span></span><br><span class="line">htpasswd -c -B -b ~/.htpasswd demo demo</span><br></pre></td></tr></table></figure></p>
<p>Then create htpasswd secret:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc create secret generic htpass-secret --from-file=htpasswd=~/.htpasswd -n openshift-config</span><br></pre></td></tr></table></figure></p>
<p>Create Custom Resource and add it to cluster<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">config.openshift.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">OAuth</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  identityProviders:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">my_htpasswd_provider</span> </span><br><span class="line"><span class="attr">    mappingMethod:</span> <span class="string">claim</span> </span><br><span class="line"><span class="attr">    type:</span> <span class="string">HTPasswd</span></span><br><span class="line"><span class="attr">    htpasswd:</span></span><br><span class="line"><span class="attr">      fileData:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">htpass-secret</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc apply -f &lt;yaml file&gt;</span><br></pre></td></tr></table></figure>
<p>Verify:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc login -u demo -p demo</span><br><span class="line">oc whoami</span><br></pre></td></tr></table></figure></p>
<h2 id="Bind-cluster-role-or-local-role"><a href="#Bind-cluster-role-or-local-role" class="headerlink" title="Bind cluster role or local role"></a>Bind cluster role or local role</h2><p><a href="https://docs.openshift.com/container-platform/4.3/authentication/using-rbac.html" target="_blank" rel="noopener">Using RBAC to define and apply permissions</a>. Cluster administrators can use the cluster roles and bindings to control who has various access levels to the OpenShift Container Platform platform itself and all projects.</p>
<p>Use <code>kubeadmin</code> to create custom cluster role or local role and bind<br>目前为止<code>demo</code> user只能对自己创建的project都基本的project admin权限，如果要想操作其他project的内容，可以local bind一个project admin:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc adm policy add-role-to-user admin demo -n &lt;target project&gt;</span><br></pre></td></tr></table></figure></p>
<p>如果需要access其他resource，比如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ERROR] [2020-02-19 15:19:21-0617] Error verifying current oauth token - Error from server (Forbidden): </span><br><span class="line">oauthaccesstokens.oauth.openshift.io &quot;XKRLOq8286U3YnRbf6lsv99Uk2rD1A6wanNVxgp5NNs&quot; is forbidden:</span><br><span class="line">User &quot;demo&quot; cannot get resource &quot;oauthaccesstokens&quot; in API group &quot;oauth.openshift.io&quot; at the cluster scope</span><br></pre></td></tr></table></figure></p>
<p>这里提示user <code>demo</code> cannot get resource <code>oauthaccesstokens</code> at the cluster scope, 我们可以先根据这个resource创建一个cluster role，然后bind it to user demo. 创建cluster role时可以指定操作，verb有get, list, create, delete, patch, watch, deletecollection。然后把创建好的cluster role 用cluster role binding 绑定到demo上:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## new custom custerrole oauthaccesstokens</span></span><br><span class="line">oc create clusterrole oauthaccesstoken_custom \</span><br><span class="line">  --verb=get,list,create,delete,patch,watch \</span><br><span class="line">  --resource=oauthaccesstokens</span><br><span class="line">oc adm policy add-cluster-role-to-user oauthaccesstoken_custom demo</span><br></pre></td></tr></table></figure></p>
<p>Check OpenShift Web can see what exactly bindings are there for user <code>demo</code>，这样就很方便了。</p>
]]></content>
      <categories>
        <category>OpenShift</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>openshift</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins CI/CD Concept</title>
    <url>/2019/07/22/pipeline-jenkins-concepts/</url>
    <content><![CDATA[<p><code>Jenkins</code> is a great tool for continuous integration and continuous delivery but what exactly does the <code>CI/CD</code> mean?</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">            +-----------------------+           +----------------------+           +------------------------+</span><br><span class="line">            |                       |           |                      |           |                        |</span><br><span class="line">            |   continuous          |           |   continuous         |           |   continuous           |</span><br><span class="line">            |         integration   +-----------&gt;         delivery     +-----------+       development      |</span><br><span class="line">            |                       |           |                      |           |                        |</span><br><span class="line">            +---------+-------------+           +--------------+-------+           +---------------------+--+</span><br><span class="line">                      ^                                        ^                                         ^</span><br><span class="line">                      |                                        |                                         |</span><br><span class="line">                      |                                        |                                         |</span><br><span class="line">+---------------------+----------+              +--------------+----------------------+      +-----------+--------------------+</span><br><span class="line">|  kick off depends on commits   |              |  platform specific testings:        |      | ready to be used by customers  |</span><br><span class="line">|  or schedule                   |              |  security, performance, API...      |      |                                |</span><br><span class="line">+-----------+--------------------+------+       |                                     |      +--------------------------------+</span><br><span class="line">            |   code version control    |       +-------------------------------------+</span><br><span class="line">            |   branching strategy      |</span><br><span class="line">+-----------+-------------+-------------+</span><br><span class="line">|  regression testings    |</span><br><span class="line">|                         |</span><br><span class="line">+-------------------------+</span><br></pre></td></tr></table></figure>
<p><code>Regression testing</code>: re-running functional and non-functional tests to ensure that previously developed and tested software still performs after a change. If not, that would be called a <code>regression</code>. Changes that may require regression testing include bug fixes, software enhancements, configuration changes, etc.</p>
<p>Git branching:<br><a href="https://nvie.com/posts/a-successful-git-branching-model/" target="_blank" rel="noopener">Branching strategy: feature branch and primary development branch</a></p>
<p>Devops practice:<br><a href="https://docs.cloudfoundry.org/devguide/deploy-apps/blue-green.html" target="_blank" rel="noopener">Blue-green deploy</a><br><a href="https://en.wikipedia.org/wiki/Smoke_testing_(software" target="_blank" rel="noopener">Smoke/Sanity test</a>)</p>
<h2 id="Resoucrs"><a href="#Resoucrs" class="headerlink" title="Resoucrs"></a>Resoucrs</h2><p><a href="https://www.infoworld.com/article/3271126/what-is-cicd-continuous-integration-and-continuous-delivery-explained.html" target="_blank" rel="noopener"><strong>What is CI/CD? Continuous integration and continuous delivery explained</strong></a><br><code>Continuous integration</code> is a coding philosophy and set of practices that drive development teams to implement small changes and check in code to version control repositories frequently. </p>
<p><code>Continuous delivery</code> automates the delivery of applications to selected infrastructure environments.</p>
<p>A mature <code>CI/CD</code> practice has the option of implementing <code>continuous deployment</code> where application changes run through the <code>CI/CD</code> pipeline and passing builds are deployed directly to production environments. </p>
<p>A best practice is to enable and require developers to run all or a subset of <code>regressions tests</code> in their local environments (or use <code>Travis</code>). This step ensures that developers only commit code to version control after regression tests pass on the code changes.</p>
<p>Test that require a full delivery environment such as performance and security testing are often integrated into CD and performed after builds are delivered to target environments.</p>
<p>To recap, <code>CI</code> packages and tests software builds and alerts developers if their changes failed any unit tests. <code>CD</code> is the automation that delivers changes to infrastructure and executes additional tests. </p>
<p><code>CI/CD</code> is a devops best practice because it addresses the misalignment between developers who want to push changes frequently, with operations that want stable applications.</p>
<p><a href="https://www.redhat.com/en/topics/devops/what-is-ci-cd" target="_blank" rel="noopener"><strong>What is CI/CD</strong></a><br>Continuous deployment (the other possible “CD”) can refer to automatically releasing a developer’s changes from the repository to production, where it is usable by customers. </p>
]]></content>
      <categories>
        <category>Pipeline</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins Git Check in</title>
    <url>/2020/06/02/pipeline-jenkins-git-checkin/</url>
    <content><![CDATA[<p>有时有这种需求: pipeline 结束后，有新生成或被改动的文件，需要把这些变化check in 到 remote github repository中，其实就是git add/commit/push 操作。这在Jenkins中如何实现呢?</p>
<p>注意这里的Github repository is secured, 比如Github Enterprise。一般我们设置SSH credentials access (SSH Username with private key), 这个credential 会提前写到 Jenkins Credential Management中，在配置pipeline的时候，最后一步设置SCM -&gt; Git, 除了输入Reporsity URL, 还要add SSH credential. 这样Jenkins才能正常地check out code. 当然，在pipeline steps 中 check out code也行，比如使用 <code>git</code>, <code>checkout</code> snippets.</p>
<p>对于check in code, 也可以使用snippet 比如:</p>
<ul>
<li><p><code>withCredentials</code><br>Bind credential to variables, 这个snippet 可以提供通过环境变量访问credential. 但在这里对于git SSH credential access, 需要设置让git去使用这个变量，this is unknown to me.</p>
</li>
<li><p><code>sshagent</code>:<br>需要install plugin: <a href="https://plugins.jenkins.io/ssh-agent/" target="_blank" rel="noopener">https://plugins.jenkins.io/ssh-agent/</a>, pass credential to it. 然后把git 操作放在这个snippet中即可. 比如:</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">steps &#123;</span><br><span class="line">  sshagent([<span class="string">'&lt;credential id&gt;'</span>]) &#123;</span><br><span class="line">    <span class="comment">// fetch a branch, edit and check in the code</span></span><br><span class="line">    sh <span class="string">'''</span></span><br><span class="line"><span class="string">      ## or git pull other repository</span></span><br><span class="line"><span class="string">      git fetch</span></span><br><span class="line"><span class="string">      git checkout $TARGET_BRANCH</span></span><br><span class="line"><span class="string">      git reset --hard origin/$TARGET_BRANCH</span></span><br><span class="line"><span class="string">      git pull</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      CHECKOUT_BRANCH="feature/$&#123;TARGET_BRANCH&#125;-$&#123;COMPONENT_NAME&#125;-$&#123;COMPONENT_VERSION&#125;"</span></span><br><span class="line"><span class="string">      echo "Creating feature branch: $CHECKOUT_BRANCH"</span></span><br><span class="line"><span class="string">      git checkout -b $CHECKOUT_BRANCH</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      sed -i "/.*version.*/c\  version: $COMPONENT_VERSION" files/$COMPONENT_NAME.yaml</span></span><br><span class="line"><span class="string">      git add files/$COMPONENT_NAME.yaml</span></span><br><span class="line"><span class="string">      ## list file changes</span></span><br><span class="line"><span class="string">      git status</span></span><br><span class="line"><span class="string">      git -c user.name="unibot" -c user.email="unibot@il.example.com" commit -m "Update $&#123;COMPONENT_NAME&#125; to $&#123;COMPONENT_VERSION&#125;"</span></span><br><span class="line"><span class="string">      git push --set-upstream origin $CHECKOUT_BRANCH</span></span><br><span class="line"><span class="string">      '''</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>参考这里的代码:<br><a href="https://github.com/jenkinsci/pipeline-examples/blob/master/pipeline-examples/push-git-repo/pushGitRepo.groovy" target="_blank" rel="noopener">https://github.com/jenkinsci/pipeline-examples/blob/master/pipeline-examples/push-git-repo/pushGitRepo.groovy</a></p>
</li>
</ul>
<p>在这里，如果我没有权限去安装<code>sshagent</code> plugin, 还有一个比较好的办法是，设置一个 dedicated node with pre-set SSH credential. 然后需要执行git check in任务的时候指定在这个node上进行即可。</p>
]]></content>
      <categories>
        <category>Pipeline</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenShift Security Context Constraint</title>
    <url>/2019/06/21/openshift-scc/</url>
    <content><![CDATA[<p>OpenShift version: <code>3.10</code></p>
<p>I have some doubts about <code>Security Context Constraint (SCC)</code> in OpenShift, for example, I give <code>privileged</code> SCC to service account, but some containers are still running as non-root user.</p>
<p>First what is <code>SCC</code> used for: control the actions that a pod can perform and what it has the ability to access, also very useful for managing access to persistent storage.</p>
<h2 id="Prerequisite"><a href="#Prerequisite" class="headerlink" title="Prerequisite"></a>Prerequisite</h2><p>Spin up a fresh OpenShift Enterprise cluster with version:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openshift v3.9.31</span><br><span class="line">kubernetes v1.9.1+a0ce1bc657</span><br></pre></td></tr></table></figure></p>
<p>Create regular user <code>demo1</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">htpasswd -b /etc/origin/master/htpasswd demo1 demo1</span><br></pre></td></tr></table></figure></p>
<p>After login as <code>demo1</code>, you have its records in cluster, if run as <code>system:admin</code> user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc get user</span><br><span class="line">oc get identity</span><br></pre></td></tr></table></figure></p>
<p>You will get demo1 information.</p>
<p>Fetch integrated docker registry address and port from <code>system:admin</code> user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc get svc -n default | grep -E &quot;^docker-registry&quot;</span><br><span class="line"></span><br><span class="line">docker-registry                     ClusterIP   172.30.159.11    &lt;none&gt;        5000/TCP                  1h</span><br></pre></td></tr></table></figure></p>
<h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p>This experiment will show you:</p>
<ol>
<li>How to enable pulling image from other project.</li>
<li>How to run container as root user.</li>
</ol>
<p>Start with <code>demo1</code>, login by <code>oc login -u demo1</code> and create 2 projects:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc new-project demo1-proj ## this one is for deploying app</span><br><span class="line">oc new-project demo1-ds   ## this one is for storing imagestream</span><br></pre></td></tr></table></figure></p>
<p>Pull <code>busybox</code> and update <code>entrypoint</code> to tail <code>/dev/null</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull busybox</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name mybb \</span><br><span class="line">  --entrypoint=/bin/sh \</span><br><span class="line">  busybox \</span><br><span class="line">  -c &apos;tail -f /dev/null&apos;</span><br></pre></td></tr></table></figure>
<p>Then commit:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker commit &lt;container id&gt; busybox</span><br></pre></td></tr></table></figure></p>
<p>Then docker tag to add docker registry address prefix:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker tag docker.io/busybox 172.30.159.11:5000/demo1-ds/busybox:v1</span><br></pre></td></tr></table></figure></p>
<p>Docker login to integrated docker registry and push:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker login -u openshift -p `oc whoami -t` 172.30.159.11:5000</span><br><span class="line">docker push 172.30.159.11:5000/demo1-ds/busybox:v1</span><br></pre></td></tr></table></figure></p>
<p>Go back to <code>demo1-proj</code> project by <code>oc project demo1-proj</code>, write a simple deployment yaml <code>bb-deploy.yml</code>:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">bb-deployment</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">        image:</span> <span class="number">172.30</span><span class="number">.159</span><span class="number">.11</span><span class="string">:5000/demo1-ds/busybox:v1</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Enable-Pull-from-Other-Projects"><a href="#Enable-Pull-from-Other-Projects" class="headerlink" title="Enable Pull from Other Projects"></a>Enable Pull from Other Projects</h3><p>If now run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc apply -f bb-deploy.yml</span><br></pre></td></tr></table></figure></p>
<p>It will fail to pull the image from <code>demo1-ds</code> (describe pod can see) because we deploy objects on project <code>demo1-proj</code>, it doesn’t have the permission to pull image from other project, let’s enable it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc policy add-role-to-user \</span><br><span class="line">    system:image-puller system:serviceaccount:demo1-proj:default \</span><br><span class="line">    --namespace=demo1-ds</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that if you run this several times, it will create severl duplicate <code>system:image-puller</code>.</p>
</blockquote>
<p>Then if you check <code>rolebindings</code> in <code>demo1-ds</code>, you see there is a new binding <code>system:image-puller</code> with service account <code>demo1-proj/default</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc get rolebindings -n demo1-ds</span><br><span class="line"></span><br><span class="line">NAME                    ROLE                    USERS     GROUPS                            SERVICE ACCOUNTS     SUBJECTS</span><br><span class="line">admin                   /admin                  demo1</span><br><span class="line">system:deployers        /system:deployer                                                    deployer</span><br><span class="line">system:image-builders   /system:image-builder                                               builder</span><br><span class="line">system:image-puller     /system:image-puller                                                demo1-proj/default</span><br><span class="line">system:image-pullers    /system:image-puller              system:serviceaccounts:demo1-ds</span><br></pre></td></tr></table></figure></p>
<p>Ok, then we can deploy the busubox in <code>demo1-proj</code> project:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAME                            READY     STATUS    RESTARTS   AGE</span><br><span class="line">bb-deployment-78bdb8c4f-lzqfj   1/1       Running   0          6s</span><br></pre></td></tr></table></figure></p>
<p>Let’s next see the container UID:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kbc exec -it bb-deployment-78bdb8c4f-lzqfj sh</span><br><span class="line"></span><br><span class="line">/ $ id</span><br><span class="line">uid=1000130000 gid=0(root) groups=1000130000</span><br></pre></td></tr></table></figure></p>
<h3 id="Set-Security-Context-Constraint"><a href="#Set-Security-Context-Constraint" class="headerlink" title="Set Security Context Constraint"></a>Set Security Context Constraint</h3><p>Correct, OpenShift by default doesn’t spin up container run as root user due to security issue. Acutally this is about <code>SCC</code>, let’s dig deeper:</p>
<p>These 2 articles cover lots of things for SCC and service account:<br><a href="https://docs.openshift.com/container-platform/3.9/admin_guide/manage_scc.html#enable-images-to-run-with-user-in-the-dockerfile" target="_blank" rel="noopener">Managing Security Context Constraints</a><br><a href="https://docs.openshift.com/container-platform/3.9/architecture/additional_concepts/authorization.html#security-context-constraints" target="_blank" rel="noopener">Security Context Constraints official</a><br><a href="https://docs.openshift.com/container-platform/3.9/admin_guide/service_accounts.html" target="_blank" rel="noopener">Configuring Service Accounts</a></p>
<p>you must have <code>cluster-admin</code> privilege to manage SCCs (you can grant <code>cluster-admin</code> privilege to regular user), there are 7 SCCs:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc get scc</span><br><span class="line"></span><br><span class="line">NAME               PRIV      CAPS      SELINUX     RUNASUSER          FSGROUP     SUPGROUP    PRIORITY   READONLYROOTFS   VOLUMES</span><br><span class="line">anyuid             false     []        MustRunAs   RunAsAny           RunAsAny    RunAsAny    10         false            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">hostaccess         false     []        MustRunAs   MustRunAsRange     MustRunAs   RunAsAny    &lt;none&gt;     false            [configMap downwardAPI emptyDir hostPath persistentVolumeClaim projected secret]</span><br><span class="line">hostmount-anyuid   false     []        MustRunAs   RunAsAny           RunAsAny    RunAsAny    &lt;none&gt;     false            [configMap downwardAPI emptyDir hostPath nfs persistentVolumeClaim projected secret]</span><br><span class="line">hostnetwork        false     []        MustRunAs   MustRunAsRange     MustRunAs   MustRunAs   &lt;none&gt;     false            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">nonroot            false     []        MustRunAs   MustRunAsNonRoot   RunAsAny    RunAsAny    &lt;none&gt;     false            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">privileged         true      [*]       RunAsAny    RunAsAny           RunAsAny    RunAsAny    &lt;none&gt;     false            [*]</span><br><span class="line">restricted         false     []        MustRunAs   MustRunAsRange     MustRunAs   RunAsAny    &lt;none&gt;     false            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br></pre></td></tr></table></figure></p>
<p>By default, when a container or pod does not request a user ID under which it should be run, the effective UID depends on the SCC that emits this pod. Because <code>restricted</code> SCC is granted to all authenticated users by default, it will be available to all users and service accounts and used in most cases.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">oc</span> <span class="string">describe</span> <span class="string">scc</span> <span class="string">restricted</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Name:</span>                                           <span class="string">restricted</span></span><br><span class="line"><span class="attr">Priority:</span>                                       <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Access:</span></span><br><span class="line"><span class="attr">  Users:</span>                                        <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">  Groups:</span>                                       <span class="attr">system:authenticated</span></span><br><span class="line"><span class="attr">Settings:</span></span><br><span class="line">  <span class="string">Allow</span> <span class="attr">Privileged:</span>                             <span class="literal">false</span></span><br><span class="line">  <span class="string">Default</span> <span class="string">Add</span> <span class="attr">Capabilities:</span>                     <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">Required</span> <span class="string">Drop</span> <span class="attr">Capabilities:</span>                   <span class="string">KILL,MKNOD,SETUID,SETGID</span></span><br><span class="line">  <span class="string">Allowed</span> <span class="attr">Capabilities:</span>                         <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">Allowed</span> <span class="string">Seccomp</span> <span class="attr">Profiles:</span>                     <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">Allowed</span> <span class="string">Volume</span> <span class="attr">Types:</span>                         <span class="string">configMap,downwardAPI,emptyDir,persistentVolumeClaim,projected,secret</span></span><br><span class="line">  <span class="string">Allowed</span> <span class="attr">Flexvolumes:</span>                          <span class="string">&lt;all&gt;</span></span><br><span class="line">  <span class="string">Allow</span> <span class="string">Host</span> <span class="attr">Network:</span>                           <span class="literal">false</span></span><br><span class="line">  <span class="string">Allow</span> <span class="string">Host</span> <span class="attr">Ports:</span>                             <span class="literal">false</span></span><br><span class="line">  <span class="string">Allow</span> <span class="string">Host</span> <span class="attr">PID:</span>                               <span class="literal">false</span></span><br><span class="line">  <span class="string">Allow</span> <span class="string">Host</span> <span class="attr">IPC:</span>                               <span class="literal">false</span></span><br><span class="line">  <span class="string">Read</span> <span class="string">Only</span> <span class="string">Root</span> <span class="attr">Filesystem:</span>                    <span class="literal">false</span></span><br><span class="line">  <span class="string">Run</span> <span class="string">As</span> <span class="string">User</span> <span class="attr">Strategy:</span> <span class="string">MustRunAsRange</span></span><br><span class="line"><span class="attr">    UID:</span>                                        <span class="string">&lt;none&gt;</span></span><br><span class="line">    <span class="string">UID</span> <span class="string">Range</span> <span class="attr">Min:</span>                              <span class="string">&lt;none&gt;</span></span><br><span class="line">    <span class="string">UID</span> <span class="string">Range</span> <span class="attr">Max:</span>                              <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">SELinux</span> <span class="string">Context</span> <span class="attr">Strategy:</span> <span class="string">MustRunAs</span></span><br><span class="line"><span class="attr">    User:</span>                                       <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">    Role:</span>                                       <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">    Type:</span>                                       <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">    Level:</span>                                      <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">FSGroup</span> <span class="attr">Strategy:</span> <span class="string">MustRunAs</span></span><br><span class="line"><span class="attr">    Ranges:</span>                                     <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">Supplemental</span> <span class="string">Groups</span> <span class="attr">Strategy:</span> <span class="string">RunAsAny</span></span><br><span class="line"><span class="attr">    Ranges:</span>                                     <span class="string">&lt;none&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>The <code>restricted</code> SCC uses <code>MustRunAsRange</code> strategy for constraining and defaulting the possible values of the securityContext.runAsUser field. The admission plug-in will look for the <code>openshift.io/sa.scc.uid-range</code> annotation on the current project to populate range fields, as it does not provide this range. In the end, a container will have runAsUser equal to the first value of the range that is hard to predict because every project has different ranges. </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">oc</span> <span class="string">describe</span> <span class="string">project</span> <span class="string">demo1-proj</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Name:</span>                   <span class="string">demo1-proj</span></span><br><span class="line"><span class="attr">Created:</span>                <span class="number">3</span> <span class="string">hours</span> <span class="string">ago</span></span><br><span class="line"><span class="attr">Labels:</span>                 <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Annotations:</span>            <span class="string">openshift.io/description=</span></span><br><span class="line">                        <span class="string">openshift.io/display-name=</span></span><br><span class="line">                        <span class="string">openshift.io/requester=demo1</span></span><br><span class="line">                        <span class="string">openshift.io/sa.scc.mcs=s0:c11,c10</span></span><br><span class="line">                        <span class="string">openshift.io/sa.scc.supplemental-groups=1000130000/10000</span></span><br><span class="line">                        <span class="string">openshift.io/sa.scc.uid-range=1000130000/10000</span></span><br><span class="line"><span class="string">Display</span> <span class="attr">Name:</span>           <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Description:</span>            <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Status:</span>                 <span class="string">Active</span></span><br><span class="line"><span class="string">Node</span> <span class="attr">Selector:</span>          <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Quota:</span>                  <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="string">Resource</span> <span class="attr">limits:</span>        <span class="string">&lt;none&gt;</span></span><br></pre></td></tr></table></figure>
<p>You see, here <code>openshift.io/sa.scc.uid-range</code> start from <code>1000130000</code>, is the UID of our <code>busybox</code> container.</p>
<p>SCCs are not granted directly to a project. Instead, you add a service account to an SCC and either specify the service account name on your pod or, when unspecified, run as the <code>default</code> service account.</p>
<h4 id="Add-and-Remove-SCC"><a href="#Add-and-Remove-SCC" class="headerlink" title="Add and Remove SCC"></a>Add and Remove SCC</h4><p>Add service account <code>default</code> in project <code>demo1-proj</code> to SCC <code>privileged</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc adm policy add-scc-to-user privileged system:serviceaccount:demo1-proj:default</span><br><span class="line"></span><br><span class="line">scc &quot;privileged&quot; added to: [&quot;system:serviceaccount:demo1-proj:default&quot;]</span><br></pre></td></tr></table></figure></p>
<p>Where to examine the result:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">oc</span> <span class="string">describe</span> <span class="string">scc</span> <span class="string">privileged</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Name:</span>                                           <span class="string">privileged</span></span><br><span class="line"><span class="attr">Priority:</span>                                       <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Access:</span></span><br><span class="line"><span class="attr">  Users:</span>                                        <span class="attr">system:admin,system:serviceaccount:openshift-infra:build-controller,system:serviceaccount:management-infra:management-admin,system:serviceaccount:management-infra:inspector-admin,system:serviceaccount:glusterfs:default,system:serviceaccount:glusterfs:router,system:serviceaccount:glusterfs:heketi-storage-service-account,system:serviceaccount:demo1-proj:default</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></p>
<p>In the <code>Users</code> field, we now have <code>system:serviceaccount:demo1-proj:default</code>.</p>
<p>How to remove the SCC from a service account?<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc adm policy remove-scc-from-user privileged system:serviceaccount:demo1-proj:default</span><br><span class="line"></span><br><span class="line">scc &quot;privileged&quot; removed from: [&quot;system:serviceaccount:demo1-proj:default&quot;]</span><br></pre></td></tr></table></figure></p>
<h3 id="Deploy-Again"><a href="#Deploy-Again" class="headerlink" title="Deploy Again"></a>Deploy Again</h3><p>Then login as <code>demo1</code>, go to <code>demo1-proj</code>, deploy again:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc apply -f bb-deploy.yml</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc exec -it bb-deployment-78bdb8c4f-rgj88 sh</span><br><span class="line"></span><br><span class="line">/ $ id</span><br><span class="line">uid=1000130000 gid=0(root) groups=1000130000</span><br></pre></td></tr></table></figure>
<p>Why the UID is still <code>1000130000</code>? We have applied <code>privileged</code> right?<br>Because <code>privileged</code> is just a constraint, you need to <strong>Ensure</strong> that at least one of the pod’s containers is requesting a privileged mode in the security context.</p>
<p>So update the yaml file, add <code>securityContext</code>, and deploy again:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">bb-deployment</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">        image:</span> <span class="number">172.30</span><span class="number">.159</span><span class="number">.11</span><span class="string">:5000/demo1-ds/busybox:v1</span></span><br><span class="line"><span class="attr">      securityContext:</span></span><br><span class="line"><span class="attr">        runAsUser:</span> <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>Now if you check the UID, it’s <code>0</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc rsh bb-deployment-58cb44b56b-zmdcw</span><br><span class="line"></span><br><span class="line">/ # id</span><br><span class="line">uid=0(root) gid=0(root) groups=10(wheel)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>oc rsh</code> is the same as <code>kubectl exec -it ... sh</code></p>
</blockquote>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Add <code>privileged</code> SCC to service account is not enough, need to specify <code>runAsUser: 0</code> in yaml file.</p>
]]></content>
      <categories>
        <category>OpenShift</category>
      </categories>
      <tags>
        <tag>openshift</tag>
        <tag>scc</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins Quick Start</title>
    <url>/2020/05/12/pipeline-jenkins-learn/</url>
    <content><![CDATA[<p>Vagrant Jenkins server git repo for testing purpose:<br><a href="https://github.com/chengdol/vagrant-jenkins" target="_blank" rel="noopener">https://github.com/chengdol/vagrant-jenkins</a></p>
<h1 id="Certified-Jenkins-Enginee"><a href="#Certified-Jenkins-Enginee" class="headerlink" title="Certified Jenkins Enginee"></a>Certified Jenkins Enginee</h1><p>Certified Jenkins Engineer (CJE):<br><a href="https://github.com/bmuschko/cje-crash-course" target="_blank" rel="noopener">https://github.com/bmuschko/cje-crash-course</a></p>
<h1 id="Jenkins"><a href="#Jenkins" class="headerlink" title="Jenkins"></a>Jenkins</h1><p>Jenkins is not a build system, it is a structured model.<br>Other interesting project: <code>Tekton</code>, <code>Jenkins X</code> (k8s involved)</p>
<p>Installing Jenkins, must have compatible <code>openjdk</code> installed.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## can use war file:</span></span><br><span class="line">java -jar jenkins.war</span><br></pre></td></tr></table></figure></p>
<p>or using rpm install for centos/redhat, then using systemctl to start/enable Jenkins<br><a href="https://www.jenkins.io/doc/book/installing/#red-hat-centos" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/installing/#red-hat-centos</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## you will see the default jenkins port is 8080</span></span><br><span class="line">ps aux | grep jenkinx</span><br></pre></td></tr></table></figure></p>
<p>then you can open the web interface by <code>&lt;node ip&gt;:8080</code>. 如果发现是中文版，可能是浏览器的语言设置出了问题，改一下chrome的语言设置为English即可.</p>
<p>If wizard install failed with some plugins, you can fix this later in <code>Manage Plugins</code>.</p>
<p>Jenkins use file system to store everything, if using systemd, the configuration is in <code>/var/lib/jenkins</code>. You can backup this folder, or if you want to wipe it out, then run <code>systemctl restart jenkins</code>, then jenkins goes back to init state.</p>
<p>Even Jenkins UI to create project is not needed, you can mkdir and files in the Jenkins working directory, then go to <code>Manage Jenkins</code> -&gt; <code>Reload Configuration from Disk</code>.</p>
<blockquote>
<p>遇到一件很神奇的事情，有次Jenkins的Credentials配置消失了。。。重启也不见恢复，后来我直接stop daemon, 清空workspace下所有文件，再次重启初始化，就恢复了。后来想想我应该是在配置Credentials时把配置改错了，可以通过<code>Manage Jenkins</code> -&gt; <code>Configure Credentials</code> 改回去。</p>
</blockquote>
<h2 id="Creating-app-build"><a href="#Creating-app-build" class="headerlink" title="Creating app build"></a>Creating app build</h2><p>freestyle project -&gt; pipeline (series of freestyle project), freestyle project is not recommended.</p>
<p>Jenkins <strong>Workspace</strong>, you can see it in console output or click <code>Workspace</code> icon in your project dashboard. Everything running is in project workspace. Every build will override the previous one. You can use tar command to backup and restore this workspace, or clean workspace.</p>
<blockquote>
<p>注意, 如果在Jenkins configuration中直接使用pipeline script 而不是 SCM, 是不会创建workspace的。</p>
</blockquote>
<p>To store the build artifact, use <code>Post-build Action</code> in configure. for example, you want to archive some jar or zip files. then after build is done, these archives will show in the build page.</p>
<h3 id="Build-trend"><a href="#Build-trend" class="headerlink" title="Build trend"></a>Build trend</h3><p>Right to <code>Build History</code> list, there is a <code>trend</code> button, click it will see the build time history statistics and distribution.</p>
<h2 id="Testing-and-Continuous-integration"><a href="#Testing-and-Continuous-integration" class="headerlink" title="Testing and Continuous integration"></a>Testing and Continuous integration</h2><p>Now start the <code>pipeline</code> job type. After creating a pipeline job, you will see <code>pipeline syntax</code> button in the page bottom, it contains necessary resources to start. You can also use <code>Copy from</code> to copy a pipeline configure from another, for quick start.</p>
<h3 id="Add-slave-nodes"><a href="#Add-slave-nodes" class="headerlink" title="Add slave nodes"></a>Add slave nodes</h3><p><code>Manage Jenkins</code> -&gt; <code>Manage Nodes and Clouds</code><br>To add slaves, usually use SSH to launch agent nodes. (如果node没有被发现，会显示错误，根据错误指示排查问题即可)</p>
<p>Before adding a slave node to the Jenkins master we need to prepare the node. We need to install <code>Java</code> on the slave node. Jenkins will install a client program on the slave node. </p>
<p>To run the client program we need to install the same Java version we used to install on Jenkins master. You need to install and configure the necessary tool in the slave node.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y java-1.8.0-openjdk</span><br></pre></td></tr></table></figure></p>
<p>When configure add node agent,    Host Key Verification Strategy:</p>
<ul>
<li><a href="https://support.cloudbees.com/hc/en-us/articles/115000073552-Host-Key-Verification-for-SSH-Agents" target="_blank" rel="noopener">Host Key Verification for SSH Agents</a></li>
</ul>
<h3 id="Pipeline-steps"><a href="#Pipeline-steps" class="headerlink" title="Pipeline steps"></a>Pipeline steps</h3><blockquote>
<p>This is scripted pipeline syntax, not recommended! Please use declarative pipeline directives! what are the differences between them: <a href="https://www.jenkins.io/doc/book/pipeline/#pipeline-syntax-overview" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/#pipeline-syntax-overview</a></p>
</blockquote>
<p>如果直接在Jenkins configure UI中设置Jenkins file，则常用的Steps (in snippet generator):</p>
<ul>
<li><p>node: Allocate node<br>Jenkins use <code>master &lt;-&gt; agent model</code>, you can configure tasks to be executed in agent node.</p>
</li>
<li><p>stage: stage</p>
</li>
<li>stash: stash some files to be used later in build</li>
<li>unstash: restore files previous stashed</li>
<li>parallel: execute in parallel (如果注册了多个slave nodes，则parallel会在上面执行并行的任务， 一般用在测试的时候，比如测试不同的环境和配置, see declarative pipeline demo code below)</li>
<li>git: Git</li>
<li>dir: Change Current Directory</li>
<li>sh: Shell Script</li>
<li>step: General Build Step</li>
<li>emailext: Extended Email</li>
</ul>
<h3 id="Triggering-auto-build"><a href="#Triggering-auto-build" class="headerlink" title="Triggering auto build"></a>Triggering auto build</h3><p>在pipeline configure中有<code>Builder Triggers</code>可以选择:</p>
<ul>
<li>Build after other projects are built</li>
<li>Build periodically</li>
<li>Poll SCM</li>
<li>Disable this project</li>
<li>Quiet period</li>
<li>Trigger builds remotely</li>
</ul>
<h3 id="Email-Notification"><a href="#Email-Notification" class="headerlink" title="Email Notification"></a>Email Notification</h3><p>Using <code>emailext: Extended Email</code>，可以用groovy函数包装，传入email的subject以及内容再调用。</p>
<h2 id="Managing-plugins"><a href="#Managing-plugins" class="headerlink" title="Managing plugins"></a>Managing plugins</h2><p><code>Manage Jenkins</code> -&gt; <code>Manage Plugins</code>, then you can select and install plugin in <code>Available</code> section. For example:</p>
<ul>
<li>Pipeline (如果这个没安装，则不会在UI中显示pipeline的动态流程图)</li>
<li><p>Html publisher (常用于发布unit test后的html report，这些html文件其实是被相关test生成好的, publisher then renders it)</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">publishHTML([<span class="string">allowMissing:</span> <span class="literal">true</span>,</span><br><span class="line"><span class="symbol">            alwaysLinkToLastBuild:</span> <span class="literal">true</span>,</span><br><span class="line"><span class="symbol">                keepAll:</span> <span class="literal">true</span>,</span><br><span class="line"><span class="symbol">                reportDir:</span> <span class="string">"$WORKSPACE/cognitive-designer-api/DSJsonApiServletJUnitTests/build/reports/tests/payloadtests"</span>,</span><br><span class="line"><span class="symbol">                reportFiles:</span> <span class="string">'index.html'</span>,</span><br><span class="line"><span class="symbol">                reportName:</span> <span class="string">'Payload Test'</span>,</span><br><span class="line"><span class="symbol">                reportTitles:</span> <span class="string">''</span>])</span><br></pre></td></tr></table></figure>
</li>
<li><p>Green Balls (show green color for success)</p>
</li>
<li>Blue Ocean (embedded site with new Jenkins UI)</li>
<li>Job DSL: Allowing jobs to be defined in a programmatic form in a human readable file.</li>
</ul>
<blockquote>
<p>Pipeline compatible plugins:<br>  <a href="https://github.com/jenkinsci/pipeline-plugin/blob/master/COMPATIBILITY.md" target="_blank" rel="noopener">https://github.com/jenkinsci/pipeline-plugin/blob/master/COMPATIBILITY.md</a></p>
</blockquote>
<p>在初始化设置Jenkins的时候，有可能有plugins安装失败，可以自己在<code>Manage plugin</code>中安装，然后restart Jenkins (关于restart Jenkins请在没有job运行的情况下进行，不同的安装方式restart的方法不同，或者在安装plugin的时候选择restart jenkins after install), for example: <code>systemctl restart jenkins</code>, 这可以消除控制面板上的plugin failure警告。。</p>
<h2 id="Continuous-delivery"><a href="#Continuous-delivery" class="headerlink" title="Continuous delivery"></a>Continuous delivery</h2><p>In <code>Blue Ocean</code>, you can run multiple builds in parallel. if more than one builds run in the same agent, the workplace path is distinguished by suffix (@count number). 但是能不能run multiple builds in one agent depends on how you design your pipeline and tasks.</p>
<p><code>Blue Ocean</code>中的UI对parallel的显示也很直观，方便查看。</p>
<h3 id="Trigger-builds-remotely"><a href="#Trigger-builds-remotely" class="headerlink" title="Trigger builds remotely"></a>Trigger builds remotely</h3><p>Set pipeline can be triggered remotely by URL, also optionally set pipeline trigger token in pipeline configure UI (can be empty).</p>
<p>You also need to know the user token, set from current user profile menu, you must keep the your user token to somewhere, for example, store it in credential secret text. So you can refer the token for example:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">TRIGGER_USER = <span class="string">"chengdol.example.com"</span></span><br><span class="line">TRIGGER_USER_TOEKN = credentials(<span class="string">'&lt;token id&gt;'</span>)</span><br></pre></td></tr></table></figure></p>
<p>Then in the upstream pipeline script, trigger other pipeline by running curl command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## can be http or https connection</span></span><br><span class="line"><span class="comment">## --user is the jenkin user and its token or password</span></span><br><span class="line"><span class="comment">## token=$&#123;PIPELINE_TRIGGER_TOKEN&#125; can be ignored if it's empty</span></span><br><span class="line">curl --user <span class="variable">$&#123;TRIGGER_USER&#125;</span>:<span class="variable">$&#123;TRIGGER_USER_TOEKN&#125;</span> --request POST http/https://&lt;url&gt;/job/<span class="variable">$&#123;PIPELINE_NAME&#125;</span>/buildWithParameters?token=<span class="variable">$&#123;PIPELINE_TRIGGER_TOKEN&#125;</span>\\&amp;para1=val1\\&amp;&amp;para2=val2</span><br></pre></td></tr></table></figure></p>
<p>You don’t need to specify all parameters in URL, the parameters default values will be used if they are not specified in the URL.</p>
<p>Notice that <code>para1</code> and <code>para2</code> must exist in parameters section of the triggered pipeline, otherwise you cannot use them. So far, based on testing, I can pass string, bool and file parameter types.</p>
<h3 id="Check-Status-of-Another-pipeline"><a href="#Check-Status-of-Another-pipeline" class="headerlink" title="Check Status of Another pipeline"></a>Check Status of Another pipeline</h3><p>reference: <a href="https://gist.github.com/paul-butcher/dc68adc1c05ca970158c18206756dab1" target="_blank" rel="noopener">https://gist.github.com/paul-butcher/dc68adc1c05ca970158c18206756dab1</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl --user <span class="variable">$&#123;LOGIN_USER&#125;</span>:<span class="variable">$&#123;LOGIN_USER_TOEKN&#125;</span> --request GET http/https://&lt;url&gt;/job/<span class="variable">$&#123;PIPELINE_NAME&#125;</span>/&lt;build number&gt;/api/json</span><br></pre></td></tr></table></figure></p>
<p>Then you can parse the json returned:<br>artifacts -&gt; result: SUCCESS, FAILURE, ABORTED</p>
<h3 id="Flyweight-executor"><a href="#Flyweight-executor" class="headerlink" title="Flyweight executor"></a>Flyweight executor</h3><p>Flyweight executor reside in Jenkins master, used to execute code outside of node allocation. Others are heavyweight executors. Flyweight executor will not be counted into executor capacity.</p>
<p>For example, we use flyweight executor for pause, in Jenkins script:<br><a href="https://stackoverflow.com/questions/44737036/jenkins-pipeline-with-code-pause-for-input" target="_blank" rel="noopener">https://stackoverflow.com/questions/44737036/jenkins-pipeline-with-code-pause-for-input</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## see below declarative pipeline demo code</span></span><br><span class="line">input <span class="string">"waiting for approval, move to staging stage..."</span></span><br></pre></td></tr></table></figure></p>
<p>The job will be paused, you can go to <code>Paused for Input</code> to decide what to do next: proceed or abort. (In <code>Blue Ocean</code>, the pause interface is more clear)</p>
<h1 id="Declarative-pipeline"><a href="#Declarative-pipeline" class="headerlink" title="Declarative pipeline"></a>Declarative pipeline</h1><p>Please use <code>Groovy</code> style to wirte declarative pipeline!</p>
<p>github demo:<br><a href="https://github.com/sixeyed/jenkins-pipeline-demos" target="_blank" rel="noopener">https://github.com/sixeyed/jenkins-pipeline-demos</a></p>
<p>Declarative Pipelines:<br><a href="https://www.jenkins.io/doc/book/pipeline/syntax/" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/syntax/</a></p>
<p>这里有关于declarative pipeline的介绍视频, Jenkins file lives in source control!<br><a href="https://www.jenkins.io/solutions/pipeline/" target="_blank" rel="noopener">https://www.jenkins.io/solutions/pipeline/</a>, </p>
<p>Using <code>Blue Ocean</code> to setup pipeline from github need personal access token (must check out repo and user options):<br><a href="https://www.youtube.com/watch?v=FhDomw6BaHU" target="_blank" rel="noopener">https://www.youtube.com/watch?v=FhDomw6BaHU</a></p>
<p>In Jenkins UI, go to pipeline syntax then <code>declarative directive generator</code>, it will help you generate pipeline code for declarative pipeline:<br><a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#directive-generator" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/getting-started/#directive-generator</a></p>
<p>This is just a basic structure demo:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">  <span class="comment">// default agent specify</span></span><br><span class="line">  agent any</span><br><span class="line">  <span class="comment">// pipeline level env var, global scope</span></span><br><span class="line">  environment &#123;</span><br><span class="line">    <span class="comment">// you can put release number here</span></span><br><span class="line">    <span class="comment">// referred by env.RELEASE</span></span><br><span class="line">    RELEASE = <span class="string">'1.1.3'</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// can have multiple stages</span></span><br><span class="line">  stages &#123;</span><br><span class="line">    <span class="comment">// list tool version</span></span><br><span class="line">    stage(<span class="string">'Audit tools'</span>) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">          sh <span class="string">'''</span></span><br><span class="line"><span class="string">            git version</span></span><br><span class="line"><span class="string">            docker version</span></span><br><span class="line"><span class="string">          '''</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(<span class="string">'Build'</span>) &#123;</span><br><span class="line">      <span class="comment">// agent specify</span></span><br><span class="line">      agent any</span><br><span class="line">      <span class="comment">// stage level env var, stage scope</span></span><br><span class="line">      environment &#123;</span><br><span class="line">        USER = <span class="string">'root'</span></span><br><span class="line">      &#125;</span><br><span class="line">      steps &#123;</span><br><span class="line">        echo <span class="string">"this is Build stage"</span></span><br><span class="line">        <span class="comment">// executable in your repo</span></span><br><span class="line">        sh <span class="string">'chmod +x ./build.sh'</span></span><br><span class="line">        <span class="comment">// 把jenkins中一个名为api-key的密匙的值 放入 API_KEY这个环境变量中</span></span><br><span class="line">        <span class="comment">// 且这个API_KEY仅在block中可见</span></span><br><span class="line">        withCredentials([string(<span class="string">credentialsId:</span> <span class="string">'api-key'</span>, <span class="string">variable:</span> <span class="string">'API_KEY'</span>)]) &#123;</span><br><span class="line">          sh <span class="string">'''</span></span><br><span class="line"><span class="string">              ./build.sh</span></span><br><span class="line"><span class="string">          '''</span></span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="comment">// can have different type</span></span><br><span class="line">    stage(<span class="string">'Test'</span>) &#123;</span><br><span class="line">      environment &#123;</span><br><span class="line">        LOG_LEVEL = <span class="string">"INFO"</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// parallel tasks</span></span><br><span class="line">      parallel &#123;</span><br><span class="line">        <span class="comment">// they can be running on different agent</span></span><br><span class="line">        <span class="comment">// depends on you agent setting</span></span><br><span class="line">        stage(<span class="string">'test1'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">          steps &#123;</span><br><span class="line">            <span class="comment">// show current stage name test1</span></span><br><span class="line">            echo <span class="string">"parallel $&#123;STAGE_NAME&#125;"</span></span><br><span class="line">            <span class="comment">// switch to ./src directory</span></span><br><span class="line">            dir(<span class="string">'./gradle'</span>) &#123;</span><br><span class="line">              sh <span class="string">'''</span></span><br><span class="line"><span class="string">              ./gradlew -p xxx test1</span></span><br><span class="line"><span class="string">              '''</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'test2'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">          steps &#123;</span><br><span class="line">            echo <span class="string">"parallel $&#123;STAGE_NAME&#125;"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'test3'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">          steps &#123;</span><br><span class="line">            echo <span class="string">"parallel $&#123;STAGE_NAME&#125;"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(<span class="string">'Deploy'</span>) &#123;</span><br><span class="line">      <span class="comment">// waiting for user input before deploying</span></span><br><span class="line">      input &#123;</span><br><span class="line">        message <span class="string">"Continue Deploy?"</span></span><br><span class="line">        ok <span class="string">"Do it!"</span></span><br><span class="line">        parameters &#123;</span><br><span class="line">          string(<span class="string">name:</span> <span class="string">'TARGET'</span>, <span class="string">defaultValue:</span> <span class="string">'PROD'</span>, <span class="string">description:</span> <span class="string">'target environment'</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      steps &#123;</span><br><span class="line">        echo <span class="string">"this is Deploy with $&#123;env.RELEASE&#125;"</span></span><br><span class="line">        <span class="comment">// groovy code block</span></span><br><span class="line">        <span class="comment">// potential security hole, jenkins will not make it easy for you</span></span><br><span class="line">        script &#123;</span><br><span class="line">          <span class="comment">// you need to approve use of these class/method</span></span><br><span class="line">          <span class="keyword">if</span> (Math.random() &gt; <span class="number">0.5</span>) &#123;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> Exception()</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// you can use try/catch block for security reason</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// if fail, this wouldn't get executed</span></span><br><span class="line">        <span class="comment">// write 'passed' into file test-results.txt</span></span><br><span class="line">        writeFile <span class="string">file:</span> <span class="string">'test-results.txt'</span>, <span class="string">text:</span> <span class="string">'passed'</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125; </span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  post &#123;</span><br><span class="line">    <span class="comment">// will always be executed</span></span><br><span class="line">    always &#123;</span><br><span class="line">      echo <span class="string">"prints whether deploy happened or not, success or failure."</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// others like: success, failure, cleanup, etc</span></span><br><span class="line">    success &#123;</span><br><span class="line">      <span class="comment">// archive files</span></span><br><span class="line">      archiveArtifacts <span class="string">'test-results.txt'</span></span><br><span class="line">      <span class="comment">// slack notifation</span></span><br><span class="line">      slackSend <span class="string">channel:</span> <span class="string">'#chengdol-private'</span>,</span><br><span class="line"><span class="symbol">                   message:</span> <span class="string">"Release $&#123;env.RELEASE&#125;, success: $&#123;currentBuild.fullDisplayName&#125;."</span></span><br><span class="line">    &#125;</span><br><span class="line">    failure &#123;</span><br><span class="line">         slackSend <span class="string">channel:</span> <span class="string">'#chengdol-private'</span>,</span><br><span class="line"><span class="symbol">                   color:</span> <span class="string">'danger'</span>,</span><br><span class="line"><span class="symbol">                   message:</span> <span class="string">"Release $&#123;env.RELEASE&#125;, FAILED: $&#123;currentBuild.fullDisplayName&#125;."</span></span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>if you don’t want to checkout SCM in stages that run in same agent, you can use this option:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">options &#123;</span><br><span class="line">  skipDefaultCheckout <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Configure-slack"><a href="#Configure-slack" class="headerlink" title="Configure slack"></a>Configure slack</h2><p>This is a slightly out-of-date video, 其实在各自pipeline中可以自己单独配置token以及选择channel。<br><a href="https://www.youtube.com/watch?v=TWwvxn2-J7E" target="_blank" rel="noopener">https://www.youtube.com/watch?v=TWwvxn2-J7E</a></p>
<p>First install <code>slack notifaction</code> plugin. Then go to <code>Manage Jenkins</code> -&gt; <code>Configure System</code>, scroll down to bottom you will see slack section, see question mark for explanation.</p>
<p>Then go to your target slack channel, select <code>Add an app</code>, search <code>Jenkins CI</code>, then add it to slack, follow the instructions to get the secret token, add this token to Jenkins credentials and use it in above slack configuration.</p>
<p>After all set, try <code>Test connection</code>, you will see message in your slack channel.</p>
<h2 id="Reusable"><a href="#Reusable" class="headerlink" title="Reusable"></a>Reusable</h2><p>Reusable functions and libraries are written in <code>Groovy</code>.<br><a href="https://www.eficode.com/blog/jenkins-groovy-tutorial" target="_blank" rel="noopener">https://www.eficode.com/blog/jenkins-groovy-tutorial</a></p>
<p>Let’s see some demos:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    <span class="comment">// options</span></span><br><span class="line">    parameters &#123;</span><br><span class="line">        booleanParam(<span class="string">name:</span> <span class="string">'RC'</span>, <span class="string">defaultValue:</span> <span class="literal">false</span>, <span class="string">description:</span> <span class="string">'Is this a Release Candidate?'</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">        VERSION = <span class="string">"0.1.0"</span>        </span><br><span class="line">        VERSION_RC = <span class="string">"rc.2"</span></span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(<span class="string">'Audit tools'</span>) &#123;                        </span><br><span class="line">            steps &#123;</span><br><span class="line">                <span class="comment">// call function</span></span><br><span class="line">                auditTools()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'Build'</span>) &#123;</span><br><span class="line">            environment &#123;</span><br><span class="line">                <span class="comment">// call function</span></span><br><span class="line">                VERSION_SUFFIX = getVersionSuffix()</span><br><span class="line">            &#125;</span><br><span class="line">            steps &#123;</span><br><span class="line">              echo <span class="string">"Building version: $&#123;VERSION&#125; with suffix: $&#123;VERSION_SUFFIX&#125;"</span></span><br><span class="line">              sh <span class="string">'dotnet build -p:VersionPrefix="$&#123;VERSION&#125;" --version-suffix "$&#123;VERSION_SUFFIX&#125;" ./m3/src/Pi.Web/Pi.Web.csproj'</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'Unit Test'</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">              <span class="comment">// switch directory</span></span><br><span class="line">              dir(<span class="string">'./m3/src'</span>) &#123;</span><br><span class="line">                sh <span class="string">'''</span></span><br><span class="line"><span class="string">                    dotnet test --logger "trx;LogFileName=Pi.Math.trx" Pi.Math.Tests/Pi.Math.Tests.csproj</span></span><br><span class="line"><span class="string">                    dotnet test --logger "trx;LogFileName=Pi.Runtime.trx" Pi.Runtime.Tests/Pi.Runtime.Tests.csproj</span></span><br><span class="line"><span class="string">                '''</span></span><br><span class="line">                mstest <span class="string">testResultsFile:</span><span class="string">"**/*.trx"</span>, <span class="string">keepLongStdio:</span> <span class="literal">true</span></span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'Smoke Test'</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">              sh <span class="string">'dotnet ./m3/src/Pi.Web/bin/Debug/netcoreapp3.1/Pi.Web.dll'</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'Publish'</span>) &#123;</span><br><span class="line">            <span class="comment">// condition</span></span><br><span class="line">            when &#123;</span><br><span class="line">                expression &#123; <span class="keyword">return</span> params.RC &#125;</span><br><span class="line">            &#125; </span><br><span class="line">            steps &#123;</span><br><span class="line">                sh <span class="string">'dotnet publish -p:VersionPrefix="$&#123;VERSION&#125;" --version-suffix "$&#123;VERSION_RC&#125;" ./m3/src/Pi.Web/Pi.Web.csproj -o ./out'</span></span><br><span class="line">                archiveArtifacts(<span class="string">'out/'</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// groovy methods, can run straight groovy code</span></span><br><span class="line"><span class="keyword">def</span> String getVersionSuffix() &#123;</span><br><span class="line">    <span class="keyword">if</span> (params.RC) &#123;</span><br><span class="line">        <span class="keyword">return</span> env.VERSION_RC</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> env.VERSION_RC + <span class="string">'+ci.'</span> + env.BUILD_NUMBER</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="keyword">void</span> auditTools() &#123;</span><br><span class="line">    sh <span class="string">'''</span></span><br><span class="line"><span class="string">        git version</span></span><br><span class="line"><span class="string">        docker version</span></span><br><span class="line"><span class="string">        dotnet --list-sdks</span></span><br><span class="line"><span class="string">        dotnet --list-runtimes</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Shared-library"><a href="#Shared-library" class="headerlink" title="Shared library"></a>Shared library</h2><p>Demo structure and code:<br><a href="https://github.com/sixeyed/jenkins-pipeline-demo-library" target="_blank" rel="noopener">https://github.com/sixeyed/jenkins-pipeline-demo-library</a><br>Invoking shared library at head of jenkins file:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="comment">// this is dynamic reference, explicitly specify the library in jenkins file</span></span><br><span class="line">library <span class="string">identifier:</span> <span class="string">'jenkins-pipeline-demo-library@master'</span>, <span class="string">retriever:</span> modernSCM(</span><br><span class="line">        [<span class="string">$class:</span> <span class="string">'GitSCMSource'</span>,</span><br><span class="line"><span class="symbol">        remote:</span> <span class="string">'https://github.com/sixeyed/jenkins-pipeline-demo-library.git'</span>,</span><br><span class="line">        <span class="comment">// if the repo is private, you can have credential here</span></span><br><span class="line"><span class="symbol">        credentialsId:</span> <span class="string">'&lt;credential id&gt;'</span>])</span><br><span class="line"></span><br><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(<span class="string">'Audit tools'</span>) &#123; </span><br><span class="line">            environment &#123;</span><br><span class="line">                <span class="comment">// pass parameters as map</span></span><br><span class="line">                VERSION_SUFFIX = getVersionSuffix <span class="string">rcNumber:</span> env.VERSION_RC, <span class="string">isReleaseCandidate:</span> params.RC</span><br><span class="line">            &#125;</span><br><span class="line">            steps &#123;</span><br><span class="line">                auditTools()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>You can add <code>Global Pipeline Libraries</code> in <code>Configure Jenkins</code> for any pipeline use.<br>这种情况下，可以设置默认的shared library，然后在jenkins file中直接调用相关函数。</p>
<h3 id="Shared-pipelines"><a href="#Shared-pipelines" class="headerlink" title="Shared pipelines"></a>Shared pipelines</h3><p>You can put the shared pipeline into a shared library, for example:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">library <span class="string">identifier:</span> <span class="string">'jenkins-pipeline-demo-library@master'</span>, </span><br><span class="line"><span class="symbol">        retriever:</span> modernSCM([<span class="string">$class:</span> <span class="string">'GitSCMSource'</span>, <span class="string">remote:</span> <span class="string">'https://github.com/sixeyed/jenkins-pipeline-demo-library.git'</span>])</span><br><span class="line"></span><br><span class="line">crossPlatformBuild <span class="string">repoName:</span> <span class="string">'sixeyed/pi-psod-pipelines'</span>,</span><br><span class="line"><span class="symbol">                   linuxContext:</span> <span class="string">'m4'</span>, </span><br><span class="line"><span class="symbol">                   windowsContext:</span> <span class="string">'m4'</span></span><br></pre></td></tr></table></figure></p>
<p>Shared library is under <code>vars</code> folder. In Groovy, we can add a method named call to a class and then invoke the method without using the name <code>call</code>, crossPlatformBuild is actually the file name, inside file there is a call method.</p>
<h2 id="Multi-branch-pipeline"><a href="#Multi-branch-pipeline" class="headerlink" title="Multi-branch pipeline"></a>Multi-branch pipeline</h2><p><a href="https://www.jenkins.io/doc/book/pipeline/multibranch/" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/multibranch/</a><br>Jenkins automatically discovers, manages and executes Pipelines for branches which contain a Jenkinsfile in source control.</p>
<p>Orphaned item strategy, for deleted branch, you can discard or reserve it.</p>
<h1 id="Pipeline-development-tools"><a href="#Pipeline-development-tools" class="headerlink" title="Pipeline development tools"></a>Pipeline development tools</h1><h2 id="Validating-pipeline-syntax"><a href="#Validating-pipeline-syntax" class="headerlink" title="Validating pipeline syntax"></a>Validating pipeline syntax</h2><p>First enable <code>anonymous read access</code> in <code>Configure Global Security</code>:<br><a href="https://www.jenkins.io/doc/book/pipeline/development/#linter" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/development/#linter</a></p>
<p>Issue curl command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## if not success, it will show you the overall problems with your jenkins file</span></span><br><span class="line">curl -X POST -F <span class="string">"jenkinsfile=&lt;[jenkins file path]"</span> http://&lt;IP&gt;:8080/pipeline-model-converter/validate</span><br></pre></td></tr></table></figure></p>
<p>Visual Studio code has Jenkins linter plugin, you need to configure it with linter url.</p>
<h2 id="Restart-or-replay"><a href="#Restart-or-replay" class="headerlink" title="Restart or replay"></a>Restart or replay</h2><p>In every build interface, <code>restart from stage</code>, you can select which stage to restart (sometimes stage may fail due to external reason), <code>replay</code>, you can edit your jenkins file and library then rerun, the changes only live in current build (after succeed, check in your updates to source control).</p>
<h2 id="Unit-test"><a href="#Unit-test" class="headerlink" title="Unit test"></a>Unit test</h2><blockquote>
<p><a href="https://github.com/jenkinsci/JenkinsPipelineUnit" target="_blank" rel="noopener">https://github.com/jenkinsci/JenkinsPipelineUnit</a></p>
</blockquote>
<ul>
<li>Supports running pipelines and library methods</li>
<li>Can mock steps and validate calls</li>
</ul>
<h1 id="Jenkins-with-Docker"><a href="#Jenkins-with-Docker" class="headerlink" title="Jenkins with Docker"></a>Jenkins with Docker</h1><p>学习步骤:<br>首先是agent 使用docker，然后master + agent 都使用docker, 最后交由K8s去管理。</p>
<p>这块很有意思，加入容器后就太灵活了，只要有build agent支持docker且已安装，则jenkins就可以把container运行在之上。<br><a href="https://www.jenkins.io/doc/book/pipeline/docker/" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/docker/</a></p>
<p><a href="https://hub.docker.com/r/jenkins/jenkins" target="_blank" rel="noopener">https://hub.docker.com/r/jenkins/jenkins</a><br>you can parallelly run several jenkins version in one machine, for purposes like testing new features, testing upgrade, so on and so forth. But you may need to customize the jenkins docker image and expose to different port.</p>
<ul>
<li>containers as build agents</li>
<li>customizing the build container</li>
<li>using the docker pipeline plugin</li>
</ul>
<p>Jenkins master and slave with docker:<br><a href="https://medium.com/@prashant.vats/jenkins-master-and-slave-with-docker-b993dd031cbd" target="_blank" rel="noopener">https://medium.com/@prashant.vats/jenkins-master-and-slave-with-docker-b993dd031cbd</a></p>
<p>From agent syntax:<br><a href="https://www.jenkins.io/doc/book/pipeline/syntax/#agent" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/syntax/#agent</a><br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">agent &#123;</span><br><span class="line">    docker &#123;</span><br><span class="line">        image <span class="string">'myregistry.com/node'</span></span><br><span class="line">        <span class="comment">// can pass argument to docker run</span></span><br><span class="line">        args  <span class="string">'-v /tmp:/tmp'</span></span><br><span class="line">        <span class="comment">// the node must pre-configured to have docker</span></span><br><span class="line">        label <span class="string">'my-defined-label'</span></span><br><span class="line">        <span class="comment">// optional set the registry to pull image</span></span><br><span class="line">        registryUrl <span class="string">'https://myregistry.com/'</span></span><br><span class="line">        registryCredentialsId <span class="string">'myPredefinedCredentialsInJenkins'</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>If there is no <code>label</code> option, Jenkins will dynamically provisioned on a node and it will fail if no docker installed, you can set docker label to filter:<br><a href="https://www.jenkins.io/doc/book/pipeline/docker/#specifying-a-docker-label" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/docker/#specifying-a-docker-label</a></p>
<p>I got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock:<br><a href="https://stackoverflow.com/questions/47854463/docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socke" target="_blank" rel="noopener">https://stackoverflow.com/questions/47854463/docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socke</a></p>
<p>还解决了一个权限的问题，在实验中container默认用户是<code>jenkins</code>，没有root权限无线运行container内部的程序，解决办法是 <code>args  &#39;-u root&#39;</code>在上面的配置中。</p>
<p>此外jenkins会把workspace注入到container中，通过环境变量查找:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sh <span class="string">'printenv'</span></span><br><span class="line">sh <span class="string">'ls -l "$WORKSPACE"</span></span><br></pre></td></tr></table></figure></p>
<p>Additionally, you can use agent with <code>Dockerfile</code> and install Docker Pipeline plugin.</p>
]]></content>
      <categories>
        <category>Pipeline</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins Pass Variables between Stages</title>
    <url>/2020/06/04/pipeline-jenkins-pass-vars/</url>
    <content><![CDATA[<p>今天遇到一个问题，如何将在一个stage中产生的变量，传递到另一个stage中。一种解决办法是使用global variable, for example, in declarative pipeline:<br><a href="https://serverfault.com/questions/884764/jenkins-pipeline-file-passing-jenkinsfile-variables-into-further-commands/884798" target="_blank" rel="noopener">https://serverfault.com/questions/884764/jenkins-pipeline-file-passing-jenkinsfile-variables-into-further-commands/884798</a><br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="comment">// variable to be used</span></span><br><span class="line"><span class="keyword">def</span> jobBaseName</span><br><span class="line"></span><br><span class="line">stage (<span class="string">'Construct Img name'</span>) &#123;</span><br><span class="line">  <span class="comment">// this is from scripted pipeline syntax</span></span><br><span class="line">  jobBaseName = sh(</span><br><span class="line"><span class="symbol">    script:</span> <span class="string">"echo $&#123;BUILD_TAG&#125; | awk '&#123;print tolower($0)&#125;' | sed 's/jenkins-//'"</span>,</span><br><span class="line"><span class="symbol">    returnStdout:</span> <span class="literal">true</span></span><br><span class="line">  )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stage (<span class="string">'Build Target Container'</span>) &#123;</span><br><span class="line">  sh <span class="string">"ssh -i ~/ssh_keys/key.key user@somehost 'cd /dockerdata/build/$&#123;BUILD_TAG&#125; &amp;&amp; docker build -t localrepo/$&#123;jobBaseName&#125;:$&#123;BUILD_NUMBER&#125; .'"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>还有人通过将变量写入文件中，再从另一个stage读取加载的方式，但这需要保证Stages are running on the same node agent.</p>
<p>此外，关于Jenkins中的<code>environment variable</code> 和 <code>build parameters</code>，有如下需要注意的地方:<br><a href="https://stackoverflow.com/questions/50398334/what-is-the-relationship-between-environment-and-parameters-in-jenkinsfile-param" target="_blank" rel="noopener">https://stackoverflow.com/questions/50398334/what-is-the-relationship-between-environment-and-parameters-in-jenkinsfile-param</a></p>
<p>Basically it works as follow</p>
<ul>
<li><code>env</code> contains all environment variables, for example: <code>env.BUILD_NUMBER</code></li>
<li>Jenkins pipeline automatically creates a global variable for each environment variable</li>
<li>params contains all build parameters, for example: <code>params.WKC_BUILD_NUMBER</code></li>
<li>Jenkins also automatically creates an environment variable for each build parameter (and as a consequence of second point a global variable).</li>
</ul>
<p>Environment variables can be overridden or unset (via Groovy script block) but params is an <strong>immutable</strong> Map and cannot be changed. Best practice is to always use params when you need to get a build parameter.</p>
<p>这些信息哪里来的呢？在配置pipeline时，查看pipeline syntax -&gt; Global Variables Reference.</p>
]]></content>
      <categories>
        <category>Pipeline</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins X Quick Start</title>
    <url>/2020/06/25/pipeline-jenkinsX-learn/</url>
    <content><![CDATA[<p>An opinionated CI/CD platform built on top of Kubernetes.</p>
<p>Introduction from Cloudbees:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=PqSfYuKEkVU" target="_blank" rel="noopener">https://www.youtube.com/watch?v=PqSfYuKEkVU</a></li>
<li><a href="https://www.youtube.com/watch?v=dO3ZHr0Rsvs" target="_blank" rel="noopener">https://www.youtube.com/watch?v=dO3ZHr0Rsvs</a></li>
</ul>
<p>Terraform is recommended going forward.<br>K8s cluster must be compatiable with <code>jx</code>.</p>
<p>Prerequisites:</p>
<ul>
<li>Know how classic Jenkins pipeline works</li>
<li>Know how to operate on Kubernetes</li>
<li>Know how to run Docker container</li>
<li>Know how to use Helm</li>
</ul>
<p>All JX projects are deployed to Kubernetes using Docker and Helm.</p>
<h1 id="Aerial-View"><a href="#Aerial-View" class="headerlink" title="Aerial View"></a>Aerial View</h1><p>Jenkin X: <a href="https://jenkins-x.io/" target="_blank" rel="noopener">https://jenkins-x.io/</a></p>
<p>Traditional CI/CD pipeline like classic Jenkins they require heavy customization, and not cloud-native.</p>
<p>Jenkins X is opinionated and cloud-native CI/CD pipeline built on top of Kubernetes. Jenkins X uses <code>Tekton</code> (a Kubernetes-native pipeline engine) to do the job.<br><img src="https://jenkins-x.io/images/jx-arch.png" alt=""></p>
<h1 id="Setup-Jenkins-X"><a href="#Setup-Jenkins-X" class="headerlink" title="Setup Jenkins X"></a>Setup Jenkins X</h1><p>Create a cluser with Terraform on GCP.</p>
<p>Steps please see my github repository:<br><a href="https://github.com/chengdol/jenkins-X-deployment" target="_blank" rel="noopener">https://github.com/chengdol/jenkins-X-deployment</a></p>
<p>First install gcloud SDK and Terraform at local.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## init the environment, configuration and link to the target gcloud project</span></span><br><span class="line">gcloud init</span><br><span class="line"><span class="comment">## we need kubectl to interact with K8s cluster</span></span><br><span class="line">gcloud components install kubectl</span><br></pre></td></tr></table></figure></p>
<p>Then create <code>main.tf</code> file to provision jenkins X cluster on GCP, go to <code>https://registry.terraform.io/</code> and search <code>jx</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<h1 id="Create-First-App-on-Jenkins-X-Pipeline"><a href="#Create-First-App-on-Jenkins-X-Pipeline" class="headerlink" title="Create First App on Jenkins X Pipeline"></a>Create First App on Jenkins X Pipeline</h1><p>Key components:</p>
<ul>
<li>Applciation code source</li>
<li>Docker file: All services store in docker image</li>
<li>Helm chart: All docker images wrapped in helm packages</li>
<li>Jenkins X file: Defines the build pipeline</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jx create quickstart</span><br></pre></td></tr></table></figure>
<p>JX commands recap:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## out of box workflow for many language projects</span></span><br><span class="line">jx create qucikstart</span><br><span class="line"><span class="comment">## import an existing project to jx</span></span><br><span class="line">jx import</span><br><span class="line"></span><br><span class="line"><span class="comment">## watch pipeline for a project</span></span><br><span class="line">jx get activity -f &lt;project name&gt; -w</span><br><span class="line"></span><br><span class="line"><span class="comment">## view logs for a build pipeline</span></span><br><span class="line">jx get build logs &lt;project name&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="Environment-with-GitOps"><a href="#Environment-with-GitOps" class="headerlink" title="Environment with GitOps"></a>Environment with GitOps</h1><p>Introduce <code>GitOps</code>:</p>
<ul>
<li><a href="https://www.cloudbees.com/gitops/what-is-gitops" target="_blank" rel="noopener">What is GitOps</a></li>
<li><a href="https://www.weave.works/technologies/gitops/#key-benefits-of-gitops" target="_blank" rel="noopener">Guide to GitOps</a></li>
</ul>
<p>Jenkins X adopts GitOps, where Git is the single-source-of-truth for our environment.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list all available environment</span></span><br><span class="line">jx get env</span><br><span class="line"><span class="comment">## create new env</span></span><br><span class="line">jx create env</span><br><span class="line"></span><br><span class="line">jx promote</span><br></pre></td></tr></table></figure>
<h1 id="Pull-Requests-and-ChatOps"><a href="#Pull-Requests-and-ChatOps" class="headerlink" title="Pull Requests and ChatOps"></a>Pull Requests and ChatOps</h1><p>Jenkins streamlines the pull request workflow.</p>
<p><code>Prow</code>: <a href="https://jenkins-x.io/docs/reference/components/prow/" target="_blank" rel="noopener">https://jenkins-x.io/docs/reference/components/prow/</a></p>
<ul>
<li>Kubernetes CI/CD system</li>
<li>Orchestrates Jenkins X pipelines via GitHub events</li>
<li>Automates interactions with pull requests Enables </li>
<li>ChatOps driven development </li>
<li>GitHub only, to be superseded by Lighthouse</li>
</ul>
<p>Github webhook will call <code>Prow</code>, the webhook is actuall a HTTP POST request that contains the event payload, then <code>Prow</code> will execute pipeline. Conversely, <code>Prow</code> can call Github API.</p>
<p>Introduce <code>ChatOps</code>:</p>
<ul>
<li><a href="https://victorops.com/blog/what-is-chatops" target="_blank" rel="noopener">What is ChatOps</a></li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">jx create pullrequest</span><br><span class="line">jx get previews</span><br><span class="line">jx delete previews</span><br></pre></td></tr></table></figure>
<h1 id="Creating-Custom-QucikStart-and-Build-Packs"><a href="#Creating-Custom-QucikStart-and-Build-Packs" class="headerlink" title="Creating Custom QucikStart and Build Packs"></a>Creating Custom QucikStart and Build Packs</h1><p><code>Build Packs</code>: <a href="https://buildpacks.io/" target="_blank" rel="noopener">https://buildpacks.io/</a>, the Jenkins X project template, powered by <a href="https://github.com/Azure/draft" target="_blank" rel="noopener">Draft</a>, contains:</p>
<ul>
<li>Dockerfile</li>
<li>Production and Preview Helm charts</li>
<li>Jenkins X pipeline</li>
</ul>
<p>Quick start workflow:<br>jx create quickstart -&gt; choose<br>quick start projects -&gt; generate<br>Vanilla project      -&gt; detects<br>Build packs          -&gt; modifies<br>Jenkins X project</p>
<p>So bascially, we use quickstart to create a vanilla project skeleton, then Jenkins X-ify this project by build packs (generate languange specific Jenkins X template files). So <code>jx import</code> existing project also use build packs to do the job.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list repositories containing quickstarts</span></span><br><span class="line">jx get quickstartlocation</span><br><span class="line"></span><br><span class="line"><span class="comment">## create new quickstart repository</span></span><br><span class="line">jx create quickstartlocation</span><br><span class="line"></span><br><span class="line"><span class="comment">## delete new quickstart repository</span></span><br><span class="line">jx delete quickstartlocation</span><br><span class="line"></span><br><span class="line"><span class="comment">## edit current buildpack location</span></span><br><span class="line">jx edit buildpack</span><br></pre></td></tr></table></figure>
<h1 id="Customize-Jenkins-X-Pipeline"><a href="#Customize-Jenkins-X-Pipeline" class="headerlink" title="Customize Jenkins X Pipeline"></a>Customize Jenkins X Pipeline</h1><p>Jenkins X file definition has YAML file structure, make use of inheritance to reduce repetition.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## validate pipeline syntax</span></span><br><span class="line">jx step syntax validate pipeline</span><br><span class="line"></span><br><span class="line"><span class="comment">## show full pipeline</span></span><br><span class="line">jx step syntax effective</span><br></pre></td></tr></table></figure>
<h1 id="Versioning-and-Releasing-App"><a href="#Versioning-and-Releasing-App" class="headerlink" title="Versioning and Releasing App"></a>Versioning and Releasing App</h1><p>Jenkins X adopts <code>Semantic versioning</code>, split into 3 components.</p>
<ul>
<li>Major: breaking changes</li>
<li>Minor: non-breaking changes</li>
<li>Patch: bug fixes</li>
</ul>
<p>Patch number is auto-incremented, Major/Minor versions are set manually.</p>
<h1 id="Custom-Domain-and-TLS"><a href="#Custom-Domain-and-TLS" class="headerlink" title="Custom Domain and TLS"></a>Custom Domain and TLS</h1><p><code>nip.io</code>, the IP with it is not human readable and prevents TLS, insecure. 比如外界访问部署后的应用。 Jenkins X allows custom domains and HTTPS</p>
<p>External DNS:</p>
<ul>
<li>Makes Kubernetes resources discoverable on public DNS servers</li>
<li>Automates creation of DNS records</li>
</ul>
<p>Certificate Manager:</p>
<ul>
<li>Issues SSL certificates for our applications</li>
<li>Leverages <code>Lets Encrypt</code> behind the scenes</li>
</ul>
<p>First buy domain from Google Domains web site then use it in Google Cloud settings.</p>
]]></content>
      <categories>
        <category>Pipeline</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins Quick Start II</title>
    <url>/2020/08/02/pipeline-jenkins-learn2/</url>
    <content><![CDATA[<p>This course is from PluralSight <code>Automating Jenkins with Groovy</code>.<br>这里不是讲如何编写declarative pipeline, 而是对Jenkins进行本地化配置, by Groovy script.</p>
<p>使用 Groovy 操控Jenkins API 去替代一些重复的UI 操作，就是从API 层面去使用jenkins，比如schedule job等等，甚至改变一些系统设置，毕竟Jenkins 也是Java 应用。</p>
<p>除了对Jenkinsfile 进行 version control, 对Jenkins本身的配置，也可以，这时候就需要Groovy script帮忙了. 在哪里去Run groovy script呢?<br><a href="https://foxutech.com/how-to-run-groovy-script-in-jenkins/" target="_blank" rel="noopener">https://foxutech.com/how-to-run-groovy-script-in-jenkins/</a></p>
<ul>
<li>Groovy Plugin</li>
<li>Jenkins Script Console</li>
<li>Scriptler Plugins</li>
</ul>
<p>第1, 2个接下来👇都提到了。</p>
<h1 id="Jenkins-Configure-Groovy"><a href="#Jenkins-Configure-Groovy" class="headerlink" title="Jenkins Configure Groovy"></a>Jenkins Configure Groovy</h1><p>Install Groovy plug-in from Jenkins Plugin Manager, search <code>Groovy</code> in Available section. </p>
<p>You can also run Groovy script in <code>Manage Jenkins</code> -&gt; <code>Script Console</code>, you can write <code>system script</code> here, for example:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="comment">// default packages are imported</span></span><br><span class="line"><span class="keyword">def</span> svr = Jenkins.instance;</span><br><span class="line"><span class="comment">// get existing TEST job</span></span><br><span class="line"><span class="keyword">def</span> job = svr.getJob(<span class="string">"TEST"</span>);</span><br><span class="line"><span class="keyword">def</span> sched= job.scheduleBuild2(<span class="number">0</span>);</span><br><span class="line">sched.get();</span><br></pre></td></tr></table></figure></p>
<p>还可以用groovy 调用API 去读取设置的Parameters, then use them in script. The jenkins API documention is in:<br><a href="https://javadoc.jenkins.io/" target="_blank" rel="noopener">https://javadoc.jenkins.io/</a><br>Hudson的名字由来是历史原因.</p>
<p>You can put this inline script in <code>freestyle project</code>, go to configure -&gt; <code>Build</code>, there are 2 options about Groovy:</p>
<ul>
<li>Execute Groovy Script: <code>non-system</code> script, has less security freight, do jobs that out of jenkins internals.</li>
<li>Execute System Groovy Script: To run <code>system script</code>, you need to be admin (unchecked use groovy sandbox) or be approved by admin.</li>
</ul>
<h1 id="Groovy-Startup-Script"><a href="#Groovy-Startup-Script" class="headerlink" title="Groovy Startup Script"></a>Groovy Startup Script</h1><p>Configuration as code, the startup script will be executed after Jenkins starts immediately to set userful properties.</p>
<p>Create <code>init.groovy.d</code> folder under <code>/var/lib/jenkins</code> and put the script <code>1_config.groovy</code> in it:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> jenkins.model.*;</span><br><span class="line"><span class="keyword">import</span> java.util.logging.Logger</span><br><span class="line"><span class="comment">// add change into logs</span></span><br><span class="line">Logger logger = Logger.getLogger(<span class="string">""</span>)</span><br><span class="line">logger.info <span class="string">"Executing init script"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// disable remember me checkbox</span></span><br><span class="line">Jenkins.instance.setDisableRememberMe(<span class="literal">true</span>)</span><br><span class="line">Jenkins.instance.setSystemMessage(<span class="string">'Jenkins Server - Automating Jenkins with Groovy'</span>)</span><br><span class="line">Jenkins.instance.save()</span><br><span class="line"></span><br><span class="line">logger.info <span class="string">"Init script complete"</span></span><br></pre></td></tr></table></figure></p>
<p>on the browser, type <code>http://localhost:8080/restart</code>, after restart Jenkins, you will see the difference, the checkbox is gone.</p>
<p><strong>Grape</strong> is the package manager for Groovy:<br><a href="http://docs.groovy-lang.org/latest/html/documentation/grape.html" target="_blank" rel="noopener">http://docs.groovy-lang.org/latest/html/documentation/grape.html</a></p>
<h1 id="Creating-Builds"><a href="#Creating-Builds" class="headerlink" title="Creating Builds"></a>Creating Builds</h1><p>这里主要说了declarative pipeline 的Jenkinsfile, 如同工作中用到的，大量的Groovy functions.</p>
<h1 id="Credentials-and-Users"><a href="#Credentials-and-Users" class="headerlink" title="Credentials and Users"></a>Credentials and Users</h1><p>You can do the same job on UI, here show you how to do it via script.</p>
<ul>
<li><code>Credentials</code>: used by Jenkins to access something outside</li>
<li><code>Users</code>: for users to login Jenkins</li>
</ul>
<p>This Groovy script will create, delete and list Jenkins user:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> hudson.model.User;</span><br><span class="line"><span class="keyword">import</span> hudson.security.*</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UserManager</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  Set allUsers()</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">return</span> User.getAll();</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">void</span> createUser(String userName, String password)&#123;</span><br><span class="line">    <span class="keyword">if</span> (!<span class="keyword">this</span>.userExists(userName))</span><br><span class="line">    &#123;</span><br><span class="line">      Jenkins instance = Jenkins.getInstance();</span><br><span class="line">      <span class="keyword">def</span> realm = <span class="keyword">new</span> HudsonPrivateSecurityRealm(<span class="literal">false</span>);</span><br><span class="line">        </span><br><span class="line">      realm.createAccount(userName, password);</span><br><span class="line">      instance.setSecurityRealm(realm);</span><br><span class="line">      instance.save();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  Boolean userExists(userName)</span><br><span class="line">  &#123;</span><br><span class="line">	  <span class="keyword">return</span> User.get(userName) != <span class="literal">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">void</span> deleteUser(String userId)</span><br><span class="line">  &#123;</span><br><span class="line">  	<span class="keyword">if</span> (<span class="keyword">this</span>.userExists(userId))</span><br><span class="line">    &#123;</span><br><span class="line">	    User u = User.get(userId);</span><br><span class="line">	    u.delete();</span><br><span class="line">	  &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> mgr = <span class="keyword">new</span> UserManager();</span><br><span class="line"></span><br><span class="line">mgr.createUser(<span class="string">"test"</span>, <span class="string">"user"</span>);</span><br><span class="line">mgr.deleteUser(<span class="string">"test"</span>);</span><br><span class="line"></span><br><span class="line">println(mgr.userExists(<span class="string">"cbehrens"</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (user <span class="keyword">in</span> mgr.allUsers())&#123;</span><br><span class="line">	println(user.id); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Create credentials in script:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> com.cloudbees.plugins.credentials.*;</span><br><span class="line"><span class="keyword">import</span> com.cloudbees.plugins.credentials.common.*;</span><br><span class="line"><span class="keyword">import</span> com.cloudbees.plugins.credentials.impl.UsernamePasswordCredentialsImpl;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CredentialManager</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  Set getAll()</span><br><span class="line">  &#123;</span><br><span class="line">	<span class="keyword">return</span> CredentialsProvider.lookupCredentials(StandardUsernameCredentials.<span class="keyword">class</span>, Jenkins.instance, <span class="literal">null</span>, <span class="literal">null</span>);</span><br><span class="line">  &#125;  </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">void</span> changePassword(String credentialId, String password)&#123;</span><br><span class="line">    println <span class="string">'change password'</span>;</span><br><span class="line">    <span class="keyword">def</span> creds = CredentialsProvider.lookupCredentials(StandardUsernameCredentials.<span class="keyword">class</span>, Jenkins.instance, <span class="literal">null</span>, <span class="literal">null</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> credential = creds.findResult &#123; it.id == credentialId ? it : <span class="literal">null</span> &#125;;</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">if</span> (credential != <span class="literal">null</span>)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">def</span> credentials_store = jenkins.model.Jenkins.instance.getExtensionList(</span><br><span class="line">            <span class="string">'com.cloudbees.plugins.credentials.SystemCredentialsProvider'</span></span><br><span class="line">            )[<span class="number">0</span>].getStore()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">def</span> success = credentials_store.updateCredentials(</span><br><span class="line">            com.cloudbees.plugins.credentials.domains.Domain.global(), </span><br><span class="line">            credential, </span><br><span class="line">            <span class="keyword">new</span> UsernamePasswordCredentialsImpl(credential.scope, credential.id, credential.description, credential.username, password)</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!success) </span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Changing password failed."</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      </span><br><span class="line">      	println(<span class="string">"password change complete"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> mgr = <span class="keyword">new</span> CredentialManager()</span><br><span class="line">mgr.changePassword(<span class="string">"githubcreds"</span>, <span class="string">"password"</span>);</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Pipeline</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title>Python3 Click</title>
    <url>/2020/10/30/pyhton-click/</url>
    <content><![CDATA[<p>//TODO<br>[ ] setuptools understand<br>[ ] advanced complex usage</p>
<p>First understand how to parse command line options and arguments with <code>optparse</code> or <code>argparse</code>.<br>Then you need to learn decorator in Python to understand <code>click</code>.</p>
<p><a href="https://click.palletsprojects.com/en/7.x/" target="_blank" rel="noopener"><code>Click</code></a> has very different pattern with <code>optparse</code>, for example, you get the arguments and process them in its function, you cannot return the parameters.</p>
<p>把basic and advenced usage都讲解了一下:<br>Introduction video: <a href="https://youtu.be/kNke39OZ2k0" target="_blank" rel="noopener">https://youtu.be/kNke39OZ2k0</a></p>
<p><code>Click</code> official examples:<br><a href="https://github.com/pallets/click/tree/master/examples" target="_blank" rel="noopener">https://github.com/pallets/click/tree/master/examples</a></p>
<h1 id="Setuptools"><a href="#Setuptools" class="headerlink" title="Setuptools"></a>Setuptools</h1><p>When writing command line utilities, it’s recommended to write them as modules that are distributed with <code>setuptools</code> instead of using Unix shebangs:<br><a href="https://click.palletsprojects.com/en/7.x/setuptools/#setuptools-integration" target="_blank" rel="noopener">https://click.palletsprojects.com/en/7.x/setuptools/#setuptools-integration</a></p>
<h1 id="Basic-Usage"><a href="#Basic-Usage" class="headerlink" title="Basic Usage"></a>Basic Usage</h1><p>This script is named <code>make.py</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> click</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same type order matters</span></span><br><span class="line"><span class="comment">## each decorator can have different parameters</span></span><br><span class="line"><span class="meta">@click.command()</span></span><br><span class="line"><span class="meta">@click.option('--count', '-c', default = 1, type=int, help = "repeat number")</span></span><br><span class="line"><span class="meta">@click.argument("name", type=click.STRING)</span></span><br><span class="line"><span class="comment">## `count` and `name` are from decorator above </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cli</span><span class="params">(count, name)</span>:</span></span><br><span class="line">    <span class="comment">## now you get argument values</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(count):</span><br><span class="line">        <span class="comment">## clicj.echo is for both python2 and python3</span></span><br><span class="line">        click.echo(<span class="string">f"<span class="subst">&#123;i + <span class="number">1</span>&#125;</span>  <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">## return will not work</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">  cli()</span><br></pre></td></tr></table></figure></p>
<p>Run and test in virtualenv:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## help</span></span><br><span class="line">python make.py --<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line">python make.py --count 3 apple</span><br></pre></td></tr></table></figure></p>
<p>When make it executable then add shabang <code>#!/usr/bin/env python</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./make.py --count 3 apple</span><br></pre></td></tr></table></figure></p>
<p>Constructing subcommands, use the same file name <code>make.py</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## this will never run when subcommand runs</span></span><br><span class="line"><span class="meta">@click.group()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cli</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## the same pattern like above example</span></span><br><span class="line"><span class="comment">## here is cli not click! means register to parent</span></span><br><span class="line"><span class="meta">@cli.command()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initdb</span><span class="params">()</span>:</span></span><br><span class="line">    click.echo(<span class="string">'Initialized the database'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@cli.command()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropdb</span><span class="params">()</span>:</span></span><br><span class="line">    click.echo(<span class="string">'Dropped the database'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">  cli()</span><br></pre></td></tr></table></figure></p>
<p>Now in this script you have 2 subcommands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## help</span></span><br><span class="line">python make.py --<span class="built_in">help</span></span><br><span class="line"></span><br><span class="line">python make.py initdb</span><br><span class="line">python make.py dropdb</span><br></pre></td></tr></table></figure></p>
<h1 id="Advanced-Usage"><a href="#Advanced-Usage" class="headerlink" title="Advanced Usage"></a>Advanced Usage</h1><p>为什么会把Click单独拿出来，是因为当时遇到了专门针对Click复杂命令的自定义的python package, 用来传递top-level command context的:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">@click.pass_context</span></span><br><span class="line"><span class="meta">@click.pass_obj</span></span><br></pre></td></tr></table></figure></p>
<p>具体可以参考，我遇到的应用要复杂得多, 有时间再来整理一下。<br><a href="https://click.palletsprojects.com/en/7.x/complex/" target="_blank" rel="noopener">https://click.palletsprojects.com/en/7.x/complex/</a></p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Concurrency</title>
    <url>/2020/09/27/python-concurrency/</url>
    <content><![CDATA[<p>这里把Python concurrency的内容单独拿出来整理一下, 主要是multithreading, multiprocessing and asyncio.</p>
<p>根据需要选择适合场景的concurrency pattern, typs of concurrency (here we talk running app on a single machine):<br><strong>Parallel programming</strong><br>Working with multi-process cores, suited for <code>CPUs intensive tasks (CPU-bound tasks)</code>: solving the problem rather than reading to or writing from a device. Better CPU gets better performance:</p>
<ul>
<li>String operations</li>
<li>Search algorithns</li>
<li>Graphics processing</li>
</ul>
<p><strong>Asynchronous programming</strong><br>Suited for <code>IO intensive tasks (IO-bound tasks)</code>: most of time reading to or writing from a device, Either to disk or to a network. 经常和callback function一起实现，或者使用future, promise or task, 主线程可以检查完成情况, use cases:</p>
<ul>
<li>Databse reads, writes</li>
<li>Web service calls</li>
<li>Copying, downloading, uploading data</li>
</ul>
<h1 id="Python-Concurrency"><a href="#Python-Concurrency" class="headerlink" title="Python Concurrency"></a>Python Concurrency</h1><p>Python has concurrency support as the diagram shows:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">+---------------------------------------------------+</span><br><span class="line">|                                                   |</span><br><span class="line">|            concurrent.futures (3.2+)              |          </span><br><span class="line">|                                                   |</span><br><span class="line">|  +-------------------+ +------------------------+ |</span><br><span class="line">|  | threading (1.5+)  | | multiprocessing (2.6+) | |</span><br><span class="line">|  +-------------------+ +------------------------+ |</span><br><span class="line">+---------------------------------------------------+</span><br><span class="line"></span><br><span class="line">            +------------+</span><br><span class="line">            |  asyncio   |</span><br><span class="line">            |  (3.4+)    |</span><br><span class="line">            +------------+</span><br></pre></td></tr></table></figure></p>
<p>这里要提一下<code>subprocess</code> 和 <code>multiprocessing</code> modules的区别:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/13606867/what-is-the-difference-between-multiprocessing-and-subprocess" target="_blank" rel="noopener">What is the difference between multiprocessing and subprocess?</a></li>
<li><a href="https://stackoverflow.com/questions/2629680/deciding-among-subprocess-multiprocessing-and-thread-in-python" target="_blank" rel="noopener">Deciding among subprocess, multiprocessing, and thread in Python?</a></li>
</ul>
<h2 id="Git-Repo"><a href="#Git-Repo" class="headerlink" title="Git Repo"></a>Git Repo</h2><p>Demo code without threads and mulitprocessing:<br><a href="https://github.com/tim-ojo/python-concurrency-getting-started" target="_blank" rel="noopener">https://github.com/tim-ojo/python-concurrency-getting-started</a></p>
<p>In newer version, Logging is disabled by pytest, need to explicitly enable it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pytest -p no:logging</span><br></pre></td></tr></table></figure></p>
<h1 id="Threading"><a href="#Threading" class="headerlink" title="Threading"></a>Threading</h1><p>这里的介绍已经说得很清楚了:<br><a href="https://docs.python.org/3/library/threading.html" target="_blank" rel="noopener">https://docs.python.org/3/library/threading.html</a></p>
<p>如果有多个cores, threads running in parallel, if only single core, threads share time on that core.</p>
<p>A process starts with a main thread (注意main thread并不是这个process, process就像一个container, 提供资源和环境，thread才是真正用来执行任务), the main thread spawns other worker threads. 不过仅仅使用thread的基本并发功能有很多缺陷，比如thread interference, race condition.</p>
<p>这里说一下Python threading 的局限, <code>GIL(Global Interpreter Lock)</code>, only <code>one</code> Python thread can run at a time, it is not true concurrency, it is a cooperative multithreading, so using Python threads in <code>IO-bound</code> tasks rather than <code>CPU-bound</code> tasks.</p>
<p>GIL workarounds:</p>
<ul>
<li>Jython (write python wrapped by Java)</li>
<li>IronPython</li>
<li>Python Multiprocessing</li>
<li>concurrent.futures.ProcessPoolExecutor</li>
</ul>
<p>如何构造threads呢? You can pass callable object (function) to constructor, the Thread class is defined as<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">threading</span>.<span class="title">Thread</span><span class="params">(group=None, target=None, name=None, args=<span class="params">()</span>, kwargs=&#123;&#125;, *, daemon=None)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_some_work</span><span class="params">(val)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"doing some work in thread"</span>)</span><br><span class="line">    <span class="keyword">print</span> (<span class="string">"echo: &#123;&#125;"</span>.format(val))</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">val = <span class="string">"text"</span></span><br><span class="line"><span class="comment">## pass callable to constructor</span></span><br><span class="line"><span class="comment">## args is tuple</span></span><br><span class="line">t=threading.Thread(target=do_some_work,args=(val,))</span><br><span class="line"><span class="comment">## start thread t</span></span><br><span class="line">t.start()</span><br><span class="line"><span class="comment">## main thread waits until called thread terminates</span></span><br><span class="line">t.join()</span><br></pre></td></tr></table></figure></p>
<p>Or by overriding the <code>run()</code> method in a subclass. No other methods (except for the constructor) should be overridden in a subclass. In other words, only override the <code>__init__()</code> and <code>run()</code> methods of this class.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FibonacciThread</span><span class="params">(threading.Thread)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num)</span>:</span></span><br><span class="line">        Thread.__init__(self)</span><br><span class="line">        self.num = num</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(self)</span>:</span> </span><br><span class="line">        fib=[<span class="number">0</span>]*(self.num + <span class="number">1</span>) </span><br><span class="line">        fib[<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        fib[<span class="number">1</span>] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>, self.num + <span class="number">1</span>): </span><br><span class="line">            fib[i] = fib[i - <span class="number">1</span>] + fib[i - <span class="number">2</span>] </span><br><span class="line">            <span class="keyword">print</span> fib[self.num]</span><br><span class="line"></span><br><span class="line">myFibTask1 = FibonacciThread(<span class="number">9</span>)</span><br><span class="line">myFibTask2 = FibonacciThread(<span class="number">12</span>)</span><br><span class="line">myFibTask1.start()</span><br><span class="line">myFibTask2.start()</span><br><span class="line"></span><br><span class="line">myFibTask1.join()</span><br><span class="line">myFibTask2.join()</span><br></pre></td></tr></table></figure></p>
<p><code>Thread interference</code>, a typical example is bank account deposit and withdraw, a <code>race condition</code> may occur. To <strong>synchronze</strong> threads, can use <code>lock</code> (<strong>primitive</strong> or <strong>reentrant</strong>)</p>
<ul>
<li>primitive lock, any thread can release it.</li>
<li>reentrant lock, only holder can release, can be acquired multiple times, by the same thread.</li>
</ul>
<p>Lock benefit: faster then other thread sync mechanisms.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="comment">## not owned by a particular thread</span></span><br><span class="line"><span class="comment">## create in main thread</span></span><br><span class="line">lock = threading.Lock()</span><br><span class="line"></span><br><span class="line"><span class="comment">## call in work threads</span></span><br><span class="line"><span class="comment">## automically acquire and release lock</span></span><br><span class="line"><span class="keyword">with</span> lock:</span><br><span class="line">    <span class="keyword">pass</span> <span class="comment">## do something</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## use try-finally block</span></span><br><span class="line">lock.acquire()</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">pass</span> <span class="comment">## do something</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    lock.release()</span><br><span class="line"></span><br><span class="line"><span class="comment">## check is the lock is acquired</span></span><br><span class="line">lock.locked()</span><br></pre></td></tr></table></figure></p>
<p><code>Semaphore</code>: maintains a set of permits. Semaphores are often used to guard resources with limited capacity, for example, a database server.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create in main thread, default permit is 1</span></span><br><span class="line"><span class="comment">## BoundedSemaphore can prevent release operation number exceeds acquire's</span></span><br><span class="line">maxconnections = <span class="number">5</span></span><br><span class="line">pool_sema = threading.BoundedSemaphore(maxconnections)</span><br><span class="line"></span><br><span class="line"><span class="comment">## call in worker threads</span></span><br><span class="line"><span class="comment">## automically acquire and release semaphore</span></span><br><span class="line"><span class="keyword">with</span> pool_sema:</span><br><span class="line">    <span class="comment">## connect to the database server</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<p><code>Events</code>: This is one of the simplest mechanisms for communication between threads: one thread signals an event and other threads wait for it.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="comment">## initially false</span></span><br><span class="line">event = threading.Event()</span><br><span class="line"></span><br><span class="line"><span class="comment">## work thread</span></span><br><span class="line"><span class="comment">## block until event is set to true</span></span><br><span class="line">event.wait()</span><br><span class="line"></span><br><span class="line"><span class="comment">## main thread</span></span><br><span class="line"><span class="comment">## set to true</span></span><br><span class="line">event.set()</span><br><span class="line"><span class="comment">## set to false</span></span><br><span class="line">event.clear()</span><br></pre></td></tr></table></figure></p>
<p><code>Conditions</code>: combine lock and event, used for producer-consumer pattern.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line">cond = threading.Condition()</span><br><span class="line"><span class="comment">## consumer</span></span><br><span class="line">cond.acquire()</span><br><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> an_item_is_available():</span><br><span class="line">    <span class="comment">## wait will release lock</span></span><br><span class="line">    <span class="comment">## Once awakened, it re-acquires the lock and returns.</span></span><br><span class="line">    cond.wait()</span><br><span class="line">get_an_available_item()</span><br><span class="line">cond.release()</span><br><span class="line"></span><br><span class="line"><span class="comment">## producer</span></span><br><span class="line">cond.acquire()</span><br><span class="line">make_an_item_available()</span><br><span class="line"><span class="comment">## Since notify() does not release the lock, its caller should.</span></span><br><span class="line">cond.notify()</span><br><span class="line">cond.release()</span><br></pre></td></tr></table></figure></p>
<p>感觉这个还比较有用:<br>Inter-thread communication using <code>queues</code>. Python的queue module实际上是一个synchronized queue class, 用来threaded programming. 4 common methids: <code>put()</code>, <code>get()</code>, <code>task_done()</code>, <code>join()</code>. The put and get calls are blocking call.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> queue <span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">from</span> threading <span class="keyword">import</span> Thread</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">img_down</span><span class="params">(producer)</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> producer:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            url = producer.get(block=<span class="keyword">False</span>)</span><br><span class="line">            <span class="comment">## do sth</span></span><br><span class="line">            producer.task_done()</span><br><span class="line">        <span class="keyword">except</span> producer.Empty:</span><br><span class="line">            <span class="comment">## write some logs</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## image download queue</span></span><br><span class="line">producer = Queue()</span><br><span class="line">urls = [<span class="string">"https://image1"</span>, <span class="string">"https://image2"</span>, <span class="string">"https://image3"</span>]</span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    producer.put(url)</span><br><span class="line"></span><br><span class="line"><span class="comment">## specify only 2 threads to download</span></span><br><span class="line">num_thread = <span class="number">2</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num_thread):</span><br><span class="line">    t = Thread(target=img_down, args=(producer,))</span><br><span class="line">    t.start()</span><br><span class="line"></span><br><span class="line">producer.join()</span><br></pre></td></tr></table></figure></p>
<h1 id="Multiprocessing"><a href="#Multiprocessing" class="headerlink" title="Multiprocessing"></a>Multiprocessing</h1><p>Process benefits:</p>
<ul>
<li>sidesteps GIL, one GIL for every python process.</li>
<li>less need for synchronization.</li>
<li>can be paused and terminated.</li>
<li>more resilient, one crash will not bring down other prcesses.</li>
</ul>
<p><code>multiprocessing</code> is a package that supports spawning processes using an API similar to the threading module.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> multiporcessing</span><br></pre></td></tr></table></figure></p>
<p><code>picklable</code> arguments: serializing and deserializing.</p>
<p><code>Pool</code>, <code>apply_async</code>, <code>apply</code><br>inter-process communication: <code>pipe</code> and <code>queue</code></p>
<h1 id="AsycnIO"><a href="#AsycnIO" class="headerlink" title="AsycnIO"></a>AsycnIO</h1>]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>concurrency</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Co-routine</title>
    <url>/2020/09/13/python-coroutine/</url>
    <content><![CDATA[<p>Seeing the demo in <a href="https://github.com/chengdol/websocket-demo" target="_blank" rel="noopener"><code>websocket</code></a>, Python websockets module is taking advantage of <code>asyncio</code> which provides an elegant coroutine-based API.</p>
<p>So what is co-routine (协程)? 这个建议多看几遍如果忘了, 把多进程，多线程和协程优缺点都讲到了, 然后从generator + yield 出发，升级到asyncio:<br><a href="https://www.youtube.com/watch?v=GSiZkP7cI80" target="_blank" rel="noopener">Python perspective of view on coroutine</a><br>Demo code github:<br><a href="https://github.com/jreese/pycon" target="_blank" rel="noopener">https://github.com/jreese/pycon</a></p>
<p>A variant of functions that enables concurrency via <code>cooperative multitasking</code> (task yields control when they are waiting for external resources 也就是在做完重要工作需要其他资源的时候，再转换到其他任务，所以协程很适合IO-bound tasks). We can run all tasks in one thread in one process (就是在一个线程中模拟多线程，本质还是单线程，注意Python threading module也是如此), better than multi-threading and multi-processing in some situations(因为切换内核态和用户态要消耗系统时间和资源, 协程由用户自己控制切换，不用陷入系统内核态).</p>
<blockquote>
<p>to analyze function bytecode, the Python <code>dis</code> module can help, for example:<br>  <figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> dis <span class="keyword">import</span> dis</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">dis(func)</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>视频中举了个naive python code实现的例子, 用到了<code>yield</code> key word, 它不仅可以输出数据，也可以通过generator的send() method接收外部的参数. 当<code>yield</code> 整个过程结束的时候，会有一个StopIteration exception 抛出。这实现了AsyncIO的基本思想。</p>
<p>For example, asyncio with aiohttp:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment">## 支持async io 的http 库</span></span><br><span class="line"><span class="keyword">from</span> aiohttp <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line">URLS = [</span><br><span class="line">    <span class="string">"https://2019.northbaypython.org"</span>,</span><br><span class="line">    <span class="string">"https://duckduckgo.com"</span>,</span><br><span class="line">    <span class="string">"https://jreese.sh"</span>,</span><br><span class="line">    <span class="string">"https://news.ycombinator.com"</span>,</span><br><span class="line">    <span class="string">"https://python.org"</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Coroutines with aiohttp</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">fetch</span><span class="params">(url: str)</span> -&gt; str:</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> request(<span class="string">"GET"</span>, url) <span class="keyword">as</span> r:</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">await</span> r.text(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    coros = [fetch(url) <span class="keyword">for</span> url <span class="keyword">in</span> URLS]</span><br><span class="line">    <span class="comment">## gather will run tasks concurrently</span></span><br><span class="line">    <span class="comment">## *coros: unpacking waitable objects</span></span><br><span class="line">    results = <span class="keyword">await</span> asyncio.gather(*coros)</span><br><span class="line">    <span class="keyword">for</span> result <span class="keyword">in</span> results:</span><br><span class="line">        print(<span class="string">f"<span class="subst">&#123;result[:<span class="number">20</span>]!r&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Proxy Squid</title>
    <url>/2020/08/30/proxy-squid/</url>
    <content><![CDATA[<p>//TODO<br>[ ] https tunnel setup<br>[ ] docker image build and test</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><a href="http://www.squid-cache.org/" target="_blank" rel="noopener">http://www.squid-cache.org/</a><br>Squid is a caching proxy for the Web supporting HTTP, HTTPS, FTP, and more. It reduces bandwidth and improves response times by caching and reusing frequently-requested web pages. Squid has extensive access controls and makes a great server accelerator.</p>
<p>Squid docker image github, includes Dockerfile and entrypoint.sh:<br><a href="https://github.com/sameersbn/docker-squid" target="_blank" rel="noopener">https://github.com/sameersbn/docker-squid</a><br>dockerhub:<br><a href="https://hub.docker.com/r/sameersbn/squid" target="_blank" rel="noopener">https://hub.docker.com/r/sameersbn/squid</a></p>
<p>Features useful:<br>[1] store cache on disk(persistent data) vs. in memory.<br>[2] fine tune cache size and age.<br>[3] user authz and authn<br>[4] filter traffic</p>
<h1 id="Github"><a href="#Github" class="headerlink" title="Github"></a>Github</h1><p>This repository contains squid demo as both HTTP(s) forward proxy and reverse proxy:<br><a href="https://github.com/chengdol/proxy/tree/main/squid" target="_blank" rel="noopener">https://github.com/chengdol/proxy/tree/main/squid</a></p>
]]></content>
      <categories>
        <category>Proxy</category>
      </categories>
      <tags>
        <tag>squid</tag>
        <tag>proxy</tag>
      </tags>
  </entry>
  <entry>
    <title>Proxy Envoy</title>
    <url>/2020/08/30/proxy-envoy/</url>
    <content><![CDATA[<p>//TODO<br>[ ] docker compose http reverse proxy with flask apps<br>[ ] envoy series: <a href="https://youtu.be/KsO4pw4tEGA" target="_blank" rel="noopener">https://youtu.be/KsO4pw4tEGA</a></p>
<h1 id="General-Proxy-and-Network-Concepts"><a href="#General-Proxy-and-Network-Concepts" class="headerlink" title="General Proxy and Network Concepts"></a>General Proxy and Network Concepts</h1><p>由于第一次实际使用Proxy是从Envoy入手的，所以把关于Proxy的基本概念记录在这一章下, 在解决问题时，首先要明白需要的是哪种Proxy 以及要实现什么样的功能?</p>
<p><a href="https://www.youtube.com/playlist?list=PLQnljOFTspQVMeBmWI2AhxULWEeo7AaMC" target="_blank" rel="noopener">Youtube Proxy Channel</a><br>这个channel讲了很多关于Proxy的知识点，总结如下：</p>
<ol>
<li><p>Understand what is <code>forward proxy (proxy)</code> and <code>reverse proxy</code> and their benefits.</p>
<ul>
<li>forward proxy: anonymity, caching, blocking unwanted sites, GeoFencing</li>
<li>reverse proxy: load balancing, ingress, caching, isolating internal traffic, logging, canary deployment</li>
</ul>
<p>A <code>forward</code> proxy is a proxy connecting from private to public IP space (which was the original idea for a proxy) while a <code>reverse</code> proxy connects from public to private IP (e.g. mapping different web servers to a single, public IP).</p>
<blockquote>
<p>Note: reverse proxy is not necessarily to be a load balancer. Load balancer is just an instance of reverse proxy.</p>
</blockquote>
<p><strong>FAQ:</strong><br><a href="https://stackoverflow.com/questions/45874515/what-is-https-proxy" target="_blank" rel="noopener">What is HTTPS Proxy</a><br>depends on the context:<br>[1] HTTP proxy that supports CONNECT method<br>[2] Connecting proxy over ssl/tls.<br>这里要注意区别curl 和 wget 对HTTPS proxy的定义，curl 新版本支持了connect proxy over ssl/tls, 比如用<code>-x https://&lt;proxy-url&gt;:&lt;port&gt;</code>, 否则默认<code>-x &lt;proxy-url&gt;:&lt;port&gt;</code> 是<code>http://</code>, 而wget 中指定proxy的环境变量<code>-e https_proxy=&lt;proxy-url&gt;:&lt;port&gt;</code> 指的是HTTP proxy that supports CONNECT method.</p>
</li>
</ol>
<p>  Can proxy &amp; reverse proxy used in the same time? Yes, for example, service mesh.<br>  Is Proxy just for HTTP traffic? No, many types, for example, HTTP proxy, HTTPS proxy, SOCKS proxy..</p>
<p>  How does forward proxy know the final destination? via the <code>HOST</code> header, start from HTTP/1.1.<br>  <code>ping</code> will not go through HTTP proxy, it is a lower protocol L3. 也就是说，不是所有traffic都走的proxy. 你也可以设置哪些访问用proxy, 哪些不用。</p>
<p>  Proxy can add its header to tell server where is the originating IP: <code>X-Forwarded-For</code> header.<br>  Proxy is dedicated: HTTP proxy(for HTTP but can upgarde to support tunnel), SOCKS proxy(only for L4).</p>
<p>  <code>Transparent proxy(gateway)</code> you don’t need to do configiration, you are not aware of.</p>
<ol start="2">
<li><p>VPN vs Forward proxy, pros and cons.<br>In VPN, the client becomes a part of network as VPN server, different from originating network. The VPN server acts as an intermediary of sorts as you connect to the internet, thereby hiding your IP address.</p>
<p>VPN Pros:<br>[1] Anonymity (but VPN knows you).<br>[2] Encrypts traffic.<br>[3] Redirect all traffic at the lowest level (layer 2).<br>[4] Access restricted content.<br>[5] Access Private networks (work).<br>VPN Cons:<br>[1] Slow because extra hops .<br>[2] Double Encryption (already have TLS/SSL).<br>[3] VPN can log your data (DNS).<br>[4] No caching.</p>
<p>Proxy Pros:<br>[1] Anonymity (proxy knows you).<br>[2] Caching L7.<br>[3] Work on Layer 7 &amp; Layer 3/4.<br>[4] Blocking Websites (transparent proxy).<br>[5] Control and many applications (varnish http accelerator, load balancing, service mesh, firewall proxy security).<br>Proxy Cons:<br>[1] Applications can bypass proxy.<br>[2] Not all traffic is routed via proxy, dedicated.<br>[3] No encryption by default.<br>[4] More dangerous than VPN, for example MITM, so check your certificate.</p>
</li>
<li><p>L4 and L7 Reverse proxy<br>L7 proxy works on layer 7, it will redirect the request after it completely received. Proxy check client request and reassemble new request to target server.</p>
<p>L4 proxy works on layer 4 (packet level), it will redirect the request packet immediately to target server (don’t wait all packets). 这个proxy并不知道request内容是什么，仅仅是转发packets.</p>
</li>
<li><p>TLS termination proxy and TLS forward proxy<br>TLS termination proxy:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">        (proxy cert)</span><br><span class="line">client &lt;=================&gt; proxy &lt;------------------&gt; servers</span><br><span class="line">            https                        http</span><br></pre></td></tr></table></figure>
<p>TLS forward proxy, it is not <code>tunneling</code> (对于TLS tunnel的类型或许叫做<code>HTTP proxy support CONNECT</code>, <code>Tunnel proxy</code>更合适):</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">        (proxy cert)                  (server cert)</span><br><span class="line">client &lt;=================&gt; proxy &lt;==================&gt; servers</span><br><span class="line">            https                        https</span><br></pre></td></tr></table></figure>
</li>
<li><p>SNI<br>SNI (Server Name Indication) is an <code>extension to TLS</code> that allows a client to specify which hostname it is attempting to connect to at the start of the TLS handshaking process. (Because one single virtual server may host several secure web sites, the HOST header is hidden in TLS.)</p>
<p>SNI sends host name in clear text, since it is in first <strong>hello message</strong> in handshake.<br>ESNI is new proposal to encrypt SNI hello message.  </p>
<p><a href="https://www.youtube.com/watch?v=t0zlO5-NWFU" target="_blank" rel="noopener">Demo</a>: launch 3 web sites in laptop: 127.0.0.1:8080, 127.0.0.1:8081, 127.0.0.1:8082 and a haproxy 0.0.0.0:80 (reverse proxy), configuring the router routes internet inbound traffic to haproxy to mimic situation in public cloud. </p>
<p>Then use <code>noip</code> create 3 different domain names, then assign route’s public IP to each domain name.</p>
<p>如果使用HTTP, 则虽然访问的domain 不一样，但背后的IP是一样的，根据haproxy内部的设置通过parse HOST header把流量转发到对应的web site上。</p>
<p>如果要使用HTTPS, 用certbot 生成3个certs, private keys 对应于3个web sites, 然后配置haproxy使用SSL/TLS 和这些certs. 这时因为haproxy无法看到HOST head了，SNI才开始起作用，从而client (browser)能获取正确的cert。这里haproxy 应该是做了TLS termination.</p>
<p>这里Demo解释了当时envoy demo没看懂的地方，实际上就是更改了router的配置，所以才能用noip domain去访问private网站!</p>
</li>
<li><p><a href="https://en.wikipedia.org/wiki/Network_address_translation" target="_blank" rel="noopener">NAT</a><br>Used on layer4 LB and <a href="https://en.wikipedia.org/wiki/Port_forwarding" target="_blank" rel="noopener">port forwarding</a>.</p>
<p>Network address translation (NAT) is a method of remapping an IP address space into another by modifying network address information in the IP header of packets while they are in transit across a traffic routing device. It has become a popular and essential tool in conserving global address space in the face of IPv4 address exhaustion. One Internet-routable IP address of a NAT gateway can be used for an entire private network.</p>
<p><code>IP masquerading</code> is a technique that hides an entire IP address space, usually consisting of private IP addresses, behind a single IP address in another, usually public address space. The hidden addresses are changed into a single (public) IP address as the source address of the outgoing IP packets so they appear as originating not from the hidden host but from the routing device itself. Because of the popularity of this technique to conserve IPv4 address space, the term NAT has become virtually synonymous with IP masquerading.</p>
</li>
</ol>
<h1 id="GitHub-repo"><a href="#GitHub-repo" class="headerlink" title="GitHub repo"></a>GitHub repo</h1><p>This github repo contains demos for some popular proxies:<br><a href="https://github.com/chengdol/proxy/tree/main/envoy" target="_blank" rel="noopener">https://github.com/chengdol/proxy/tree/main/envoy</a></p>
<h1 id="Envoy"><a href="#Envoy" class="headerlink" title="Envoy"></a>Envoy</h1><p>首先要理解proxy的各种概念，类型，否则在配置时会一头雾水，不知所以然。</p>
<p>Chinese web site: <a href="https://www.servicemesher.com/envoy/about_docs.html" target="_blank" rel="noopener">https://www.servicemesher.com/envoy/about_docs.html</a><br>Web site: <a href="https://www.envoyproxy.io/" target="_blank" rel="noopener">https://www.envoyproxy.io/</a></p>
<p>选定Envoy的版本，进入文档，了解Envoy的terminology, for example: host, downstream, upstream, listener, cluster, mesh, etc.<br>了解envoy architecture，这对于理解配置很有帮助，对于Inbound 流量，指定有Listener, 每个Listener 有filter chains, 其中包含各种类型的filters. 对于Outbound 流量，设置upstream clusters, 流量会根据配置送到对应的upstream中去。<br><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">downstream clients -----&gt; listeners -----&gt; filters -----&gt; upstream clusters</span><br><span class="line">     (app)                            (routing decision)</span><br></pre></td></tr></table></figure></p>
<p>由于重要性的原因, Envoy将HTTP 单独划分出来, 当使用<code>http_connection_manager</code> filter时，Envoy就成为了L7 的proxy, 这时可以作为一般的reverse proxy (load balancer), 当配置为HTTP forward proxy时，主要用到了HTTP dynamic forward proxy 功能和 HTTP upgrades (CONNECT support)功能. 此外，在配置<code>http_connection_manager</code> 内部的<code>http_filters</code>时，<code>envoy.filters.http.router</code> 放在最后，这是向upstream 发送流量的filter.</p>
<p>Envoy 的配置文件可以使yaml/json format, 配置的格式其实是和API 一一对应的, 查看API部分即可, 目前最近的是v3 xDS API, xDS 中<code>x</code> 是一系列的LDS, EDS, CDS的统称，他们是不同层面的发现机制。LDS, CDS means Listener discovery service and cluster discovery service. EDS, endpoint discovery service.</p>
<p>对于Envoy的二次开发，可以使用官方提供的镜像:<br><a href="https://www.envoyproxy.io/docs/envoy/latest/start/building#pre-built-binaries" target="_blank" rel="noopener">https://www.envoyproxy.io/docs/envoy/latest/start/building#pre-built-binaries</a></p>
<p>在测试配置文件时，可以使用docker compose的network将client, server各自隔离，proxy则可以访问2个网络，或者单独docker container进行测试。更改mounted 配置文件后docker restart即可生效。</p>
<h2 id="Envoy-Series-Training"><a href="#Envoy-Series-Training" class="headerlink" title="Envoy Series Training"></a>Envoy Series Training</h2><p>So far the best Envoy series:<br><a href="https://youtu.be/KsO4pw4tEGA" target="_blank" rel="noopener">https://youtu.be/KsO4pw4tEGA</a>, recap as below:</p>
<p>Envoy can be controlled via API (control/data plane). 这个其实也是生产环境中主要的调节方式。Envoy admin 面板有很多选项，也有项目专门为Envoy开发control plane.</p>
<p>Using golang write tcp, http server.<br>Using <code>nc</code>(netcat) command to test envoy tcp proxy:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## envoy listening on port 10000 and upstream is a TCP server</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"hello"</span> | nc localhost 10000</span><br></pre></td></tr></table></figure></p>
<p>Or you can write a tcp client and the client talks to envoy.<br><code>fuser -k</code> command to kill processes.</p>
<p>Access envoy admin API from a docker container, expose the port <code>9901</code> and in browser hits <code>http://localhost:9901</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">admin:</span><br><span class="line">  access_log_path: /dev/stdout</span><br><span class="line">  address:</span><br><span class="line">    socket_address:</span><br><span class="line">      protocol: TCP</span><br><span class="line">      <span class="comment">## 127.0.0.1 is more secure,  can only be accessed when you are from within the network</span></span><br><span class="line">      <span class="comment">## 0.0.0.0 then everyone can access</span></span><br><span class="line">      address: 0.0.0.0</span><br><span class="line">      port_value: 9901</span><br></pre></td></tr></table></figure></p>
<p>In the dashboard, there are lots of metrics sections, important ones are <code>logging</code>, <code>stats</code>, <code>clusters</code>, <code>config_dump</code>,etc. For example, set debug mode in Envoy through curl command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## get help</span></span><br><span class="line">curl http://localhost:9901/<span class="built_in">help</span></span><br><span class="line"><span class="comment">## operation</span></span><br><span class="line">curl -X POST <span class="string">"localhost:9901/logging?level=trace"</span></span><br><span class="line">curl -X POST <span class="string">"localhost:9901/logging?level=debug"</span></span><br><span class="line">curl -X POST <span class="string">"localhost:9901/logging?level=info"</span></span><br></pre></td></tr></table></figure></p>
<p>Envoy status has native format support to Prometheus, Jaeger.</p>
<p>Overload manager:<br><a href="https://www.envoyproxy.io/docs/envoy/v1.16.0/intro/arch_overview/operations/overload_manager#" target="_blank" rel="noopener">https://www.envoyproxy.io/docs/envoy/v1.16.0/intro/arch_overview/operations/overload_manager#</a><br>for example, limits envoy host system resource occupation. 资源使用限制。</p>
<p>When configure envoy as edge proxy, 有很多需要考虑的地方，比如资源使用和限制等.</p>
<p>Currenly we use <code>static_resources:</code>, there is also <code>dynamic_resouces:</code>，这个部分需要编写自己的配置，不太明白。</p>
<p><code>hey</code> command, for load testing，这里用来测试envoy的根据权重的分流功能.<br><a href="https://github.com/rakyll/hey" target="_blank" rel="noopener">https://github.com/rakyll/hey</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## now looks it is lack of maintaince and the release link is broken</span></span><br><span class="line">curl -Lk <span class="string">'https://gobinaries.com/binary/github.com/rakyll/hey?os=linux&amp;arch=amd64&amp;version=v0.1.4'</span> -o ./hey</span><br><span class="line">chmod +x ./hey</span><br><span class="line"></span><br><span class="line"><span class="comment">## it show you the request statics graph</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">./hey -n 100 http://localhost:10000</span><br><span class="line">sleep 1</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<h2 id="CNCF-Envoy-Talk"><a href="#CNCF-Envoy-Talk" class="headerlink" title="CNCF Envoy Talk"></a>CNCF Envoy Talk</h2><p><a href="https://youtu.be/P719qI2h2yY" target="_blank" rel="noopener">Intro: Envoy - Matt Klein &amp; Constance Caramanolis, Lyft</a>, <a href="https://speakerdeck.com/mattklein123/velocity-2017-lyfts-envoy-experiences-operating-a-large-service-mesh" target="_blank" rel="noopener">slides</a><br><a href="https://youtu.be/gQF23Vw0keg" target="_blank" rel="noopener">Envoy Internals Deep Dive</a>, <a href="https://speakerdeck.com/mattklein123/kubecon-eu-2018" target="_blank" rel="noopener">slides</a></p>
<p><a href="https://www.getambassador.io/resources/?topics=Envoy%20Proxy" target="_blank" rel="noopener">Ambassador Envoy blogs</a></p>
<p><a href="https://jvns.ca/blog/2018/10/27/envoy-basics/" target="_blank" rel="noopener">Some Envoy basics</a><br>Istio (as far as I understand it) is basically an Envoy discovery service that uses information from the Kubernetes API (eg the services in your cluster) to configure Envoy clusters/routes. It has its own configuration language.</p>
<p><a href="https://blog.getambassador.io/envoy-proxy-in-2019-security-caching-wasm-http-3-and-more-e5ba82da0197" target="_blank" rel="noopener">Envoy supports traffic shadowing</a><br>Traffic shadowing is a deployment pattern where production traffic is asynchronously copied to a non-production service for testing. Shadowing is a close cousin to two other commonly known deployment patterns, canary releases and blue/green deployments.</p>
<h2 id="HTTP-s-Reverse-Proxy"><a href="#HTTP-s-Reverse-Proxy" class="headerlink" title="HTTP(s) Reverse Proxy"></a>HTTP(s) Reverse Proxy</h2><p>Good video:<br><a href="https://youtu.be/D0cuv1AEftE" target="_blank" rel="noopener">Load balancing and HTTP Routing with Envoy Proxy</a><br><a href="https://youtu.be/40gKzHQWgP0" target="_blank" rel="noopener">Envoy Proxy Crash Course, Architecture, L7 &amp; L4 Proxying, HTTP/2, Enabling TLS 1.2/1.3 and more</a> </p>
<p><a href="https://www.katacoda.com/envoyproxy/scenarios/getting-started" target="_blank" rel="noopener">Envoy online codelab</a></p>
<p>对于reverse proxy, 直接访问即可, 比如如果envoy在本地运行:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl http(s)://localhost:80(443)</span><br></pre></td></tr></table></figure></p>
<h2 id="HTTP-s-Forward-Proxy"><a href="#HTTP-s-Forward-Proxy" class="headerlink" title="HTTP(s) Forward Proxy"></a>HTTP(s) Forward Proxy</h2><p>Forward proxy support on envoy is still baisc, 当时遇到的几个问题:<br>CONNECT with domain match:<br><a href="https://github.com/envoyproxy/envoy/pull/13630" target="_blank" rel="noopener">https://github.com/envoyproxy/envoy/pull/13630</a><br>Block or allow downstream source IPs:<br><a href="https://github.com/envoyproxy/envoy/issues/8388" target="_blank" rel="noopener">https://github.com/envoyproxy/envoy/issues/8388</a></p>
<p>对于forward proxy, 则需要在curl中指定使用:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -v -x localhost:10000 http(s)://www.httpbin.org</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">http(s)_proxy=localhost:10000 curl -v http(s)://www.httpbin.org</span><br></pre></td></tr></table></figure></p>
<p>I was thinking what if I use <code>-x</code> with a reverse proxy, what will happen? For example, using this envoy config:<br><a href="https://github.com/envoyproxy/envoy/blob/v1.16.0/configs/google_com_proxy.v2.yaml" target="_blank" rel="noopener">https://github.com/envoyproxy/envoy/blob/v1.16.0/configs/google_com_proxy.v2.yaml</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -v -x localhost:10000 http://&lt;some valid or invalid url&gt;</span><br></pre></td></tr></table></figure></p>
<p>From test, it will not show error but ignore the url I provide, still act as a reverse proxy and forward traffic to specified upstream cluster.</p>
<h2 id="TCP-Proxy"><a href="#TCP-Proxy" class="headerlink" title="TCP Proxy"></a>TCP Proxy</h2><p>See Github demo:<br><a href="https://github.com/chengdol/proxy/tree/main/envoy/tcp-proxy" target="_blank" rel="noopener">https://github.com/chengdol/proxy/tree/main/envoy/tcp-proxy</a></p>
]]></content>
      <categories>
        <category>Proxy</category>
      </categories>
      <tags>
        <tag>proxy</tag>
        <tag>envoy</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Logging</title>
    <url>/2020/10/03/python-logging/</url>
    <content><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>Official document:<br><a href="https://docs.python.org/3.8/howto/logging.html" target="_blank" rel="noopener">https://docs.python.org/3.8/howto/logging.html</a></p>
<p>Logging level: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>CRITIAL</code>, in increasing order of severity.<br>设置这个的好处是可以根据level输出对应的logging信息，在设定level之下的logging不会被记录, 比如当前level 设定为INFO, 则logging.debug()不会被输出。</p>
<p>The default level is <code>WARNING</code>, which means that only events of this level and above will be tracked, unless the logging package is configured to do otherwise.</p>
<p>Note that <code>logging.basicConfig()</code> should come at very first and it only take effect once.</p>
<h1 id="Basic-Usage"><a href="#Basic-Usage" class="headerlink" title="Basic Usage"></a>Basic Usage</h1><p><a href="https://docs.python.org/3.8/howto/logging.html" target="_blank" rel="noopener">https://docs.python.org/3.8/howto/logging.html</a><br>See Basic Logging Tutorial</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment">## see logging record attributes</span></span><br><span class="line"><span class="comment">## https://docs.python.org/3/library/logging.html#logrecord-attributes</span></span><br><span class="line">FORMAT = <span class="string">"[%(threadName)s, %(asctime)s, %(levelname)s] %(message)s"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## you can get level from command line options: --log=INFO</span></span><br><span class="line"><span class="comment">## write log to a file</span></span><br><span class="line">logging.basicConfig(filename=<span class="string">'/opt/logfile.log'</span>, level=logging.DEBUG, format=FORMAT)</span><br><span class="line"><span class="comment">## default the log will append to file, if you want to overwrite, set filemode='w'</span></span><br><span class="line">logging.basicConfig(filename=<span class="string">'/opt/logfile.log'</span>, filemode=<span class="string">'w'</span>, level=logging.DEBUG, format=FORMAT)</span><br><span class="line"></span><br><span class="line"><span class="comment">## write to system stdout</span></span><br><span class="line">logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, format=FORMAT)</span><br><span class="line"></span><br><span class="line"><span class="comment">## in other places</span></span><br><span class="line">logging.debug(<span class="string">f"message"</span>)</span><br><span class="line">logging.info(<span class="string">f"message"</span>)</span><br><span class="line">logging.error(<span class="string">f"message"</span>)</span><br><span class="line">logging.critical(<span class="string">f"message"</span>)</span><br></pre></td></tr></table></figure>
<h1 id="Advanced-Usage"><a href="#Advanced-Usage" class="headerlink" title="Advanced Usage"></a>Advanced Usage</h1><p><a href="https://docs.python.org/3.8/howto/logging.html#advanced-logging-tutorial" target="_blank" rel="noopener">https://docs.python.org/3.8/howto/logging.html#advanced-logging-tutorial</a></p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>logging</tag>
      </tags>
  </entry>
  <entry>
    <title>Python3 Quick Start</title>
    <url>/2019/08/05/python-learn/</url>
    <content><![CDATA[<p>Python3 Tutorial:<br><a href="https://www.tutorialspoint.com/python3/index.htm" target="_blank" rel="noopener">https://www.tutorialspoint.com/python3/index.htm</a><br><a href="https://www.w3schools.com/python/default.asp" target="_blank" rel="noopener">https://www.w3schools.com/python/default.asp</a></p>
<h1 id="Template"><a href="#Template" class="headerlink" title="Template"></a>Template</h1><p>With Docstring, you can use <code>help()</code> command to get module information, for example:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## "words" is the script name: words.py</span></span><br><span class="line"><span class="keyword">import</span> words</span><br><span class="line">help(words)</span><br><span class="line"><span class="comment">## fetch_words is a function inside words.py script</span></span><br><span class="line">help(words.fetch_words)</span><br></pre></td></tr></table></figure></p>
<p>Acutally <code>help()</code> works on every object.</p>
<p>This is a python script named <code>words.py</code> with demonstration for Docstring:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="string">"""Retrieve and print words from a URL.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Usage:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">   python3 words.py &lt;URL&gt;</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlopen</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fetch_words</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="string">"""Fetch a list of words from a URL.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        url: The URL of a UTF-8 text document.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        A list of strings containing the words from</span></span><br><span class="line"><span class="string">        the document.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment">## can use with-block here</span></span><br><span class="line">    story = urlopen(url)</span><br><span class="line">    story_words = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> story:</span><br><span class="line">        line_words = line.decode(<span class="string">'utf8'</span>).split()</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> line_words:</span><br><span class="line">            story_words.append(word)</span><br><span class="line">    <span class="comment">## file like object, still need to close</span></span><br><span class="line">    story.close()</span><br><span class="line">    <span class="keyword">return</span> story_words</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_items</span><span class="params">(items)</span>:</span></span><br><span class="line">    <span class="string">"""Print items one per line.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        An iterable series of printable items.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">        print(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="string">"""Print each word from a text document from at a URL.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        url: The URL of a UTF-8 text document.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    words = fetch_words(url)</span><br><span class="line">    print_items(words)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">## pass parameter from command line</span></span><br><span class="line">    <span class="comment">## argv[0] is the module name</span></span><br><span class="line">    main(sys.argv[<span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<p>On Linux, if you add shebang <code>#!/usr/bin/env python3</code> at the top of the script, then you can run it by:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod +x words.py</span><br><span class="line">./words.py http://sixty-north.com/c/t.txt</span><br></pre></td></tr></table></figure></p>
<p>后面会专门学习一下python script方面的知识, see my blog <code>&lt;&lt;Python3 Scripting&gt;&gt;</code>.</p>
<h2 id="Exception"><a href="#Exception" class="headerlink" title="Exception"></a>Exception</h2><p><code>try</code> statements do not create a new scope! the variables in try block can be seen from outside try block:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        number = <span class="string">''</span></span><br><span class="line">        <span class="keyword">for</span> token <span class="keyword">in</span> s:</span><br><span class="line">            number += DIGIT_MAP[token]</span><br><span class="line">        <span class="keyword">return</span> int(number)</span><br><span class="line">    <span class="keyword">except</span> (KeyError, TypeError) <span class="keyword">as</span> e:</span><br><span class="line">        <span class="comment">## !r is a shortcut to call the repr of the value supplied.</span></span><br><span class="line">        print(<span class="string">f"Conversion error: <span class="subst">&#123;e!r&#125;</span>"</span>, file=sys.stderr)</span><br><span class="line">        <span class="comment">## re-raising exception</span></span><br><span class="line">        <span class="keyword">raise</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print(<span class="string">"I will be called only if exception didn't occur!"</span>)</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="comment">## will execute no matter normal or not</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sqrt</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""Compute square roots using the method </span></span><br><span class="line"><span class="string">    of Heron of Alexandria.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: The number for which the square root </span></span><br><span class="line"><span class="string">            is to be computed.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        The square root of x.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      Raises:</span></span><br><span class="line"><span class="string">          ValueError: If x is negative.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">if</span> x &lt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment">## upper level can catch this exception</span></span><br><span class="line">        <span class="keyword">raise</span> ValueError(</span><br><span class="line">            <span class="string">"Cannot compute square root of "</span></span><br><span class="line">            <span class="string">f"negative number <span class="subst">&#123;x&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">    guess = x</span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> guess * guess != x <span class="keyword">and</span> i &lt; <span class="number">20</span>:</span><br><span class="line">        guess = (guess + x / guess) / <span class="number">2.0</span></span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> guess</span><br></pre></td></tr></table></figure></p>
<p>Common exception types:</p>
<ul>
<li><code>indexError</code>: index out of boundary</li>
<li><code>keyError</code>: mapping</li>
<li><code>TypeError</code>: usually avoiding check this, increase function usability.</li>
<li><code>valueError</code>: int(“hello”)</li>
<li><code>OSError</code>: os module open file</li>
</ul>
<h1 id="Modularity"><a href="#Modularity" class="headerlink" title="Modularity"></a>Modularity</h1><p>Import module and attribute, 掌握import的语法, module normally is a single python source file, e.g. <code>hello.py</code>. When import, it is represented by <code>module</code> objects.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## import custom module</span></span><br><span class="line"><span class="keyword">import</span> hello</span><br><span class="line"><span class="comment">## Hello is a class in hello.py</span></span><br><span class="line"><span class="keyword">from</span> hello <span class="keyword">import</span> Hello</span><br><span class="line"></span><br><span class="line"><span class="comment">## system modules</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line">math.factorial(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> factorial</span><br><span class="line">factorial(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> factorial <span class="keyword">as</span> fac</span><br><span class="line">fac(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># other import forms</span></span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> (factorial, exp)</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure></p>
<p>In the interactive python console, use <code>help</code> to explore modules:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># you can search for modules, keywords, symbols, topics</span></span><br><span class="line">help()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>math</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>urllib.request</span><br><span class="line"></span><br><span class="line"><span class="comment"># or check math module by first import it</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line">help(math)</span><br><span class="line"><span class="comment">## request is a nested module after urllib</span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request <span class="keyword">as</span> req</span><br><span class="line">help(urllib.request)</span><br></pre></td></tr></table></figure></p>
<p>You can check the attributes of an object:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show all methods</span></span><br><span class="line">dir(math)</span><br><span class="line">dir(time.ctime)</span><br><span class="line"><span class="comment">## show type</span></span><br><span class="line">type(math)</span><br><span class="line">type(time.ctime)</span><br></pre></td></tr></table></figure></p>
<p>Commonly used modules:</p>
<ul>
<li><code>urllib</code>: urllib is a package that collects several modules for working with URLs</li>
<li><code>sys</code>: access argv, stdin, stdout, etc.</li>
<li><code>time</code>: principally for working with unix time stamps</li>
<li><code>datetime</code>: UTC datetime, Unix timestamp, timedetla</li>
<li><code>pprint</code>: pretty print</li>
<li><code>os</code>: interface to system services</li>
<li><code>itertools</code>: iteration processing</li>
<li><code>contextlib</code>: use with <code>with</code> statement</li>
<li><code>typing</code>: type hints, built-in after python 3.5</li>
<li><code>functools</code>: functools.wraps() 用来 copy original function metadata</li>
</ul>
<p>最近在做project的时候遇到几个新的modules:</p>
<ul>
<li><code>threading</code>: threading operation</li>
<li><code>subprocess</code>: spawn new processes</li>
</ul>
<p><code>time</code> vs <code>datetime</code> modules:<br><a href="https://stackoverflow.com/questions/7479777/difference-between-python-datetime-vs-time-modules" target="_blank" rel="noopener">https://stackoverflow.com/questions/7479777/difference-between-python-datetime-vs-time-modules</a><br>the <code>time</code> module is principally for working with unix time stamps; expressed as a floating point number taken to be seconds since the unix epoch. the <code>datetime</code> module can support many of the same operations, but provides a more object oriented set of types, and also has some limited support for time zones.</p>
<h2 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h2><p>Function name in python uses lowercase and <code>-</code> as delimiter. <code>def</code> keywork bind a function to a name, function in Python is treated as object.</p>
<p><code>Extended arguments</code>, for example: <code>*args</code>(act as tuple), <code>**kwargs</code>(act as dict). This is called parameters packing, these applies to all types of callables, for example lambda.</p>
<p>The parameter type order must follow: regular positional -&gt; *args -&gt; keyword -&gt; **kwargs, for example:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_args</span><span class="params">(arg1, arg2, *args, kwarg1, kwarg2, **kwargs)</span>:</span></span><br><span class="line">    print(arg1)</span><br><span class="line">    print(arg2)</span><br><span class="line">    print(args)</span><br><span class="line">    print(kwarg1)</span><br><span class="line">    print(kwarg2)</span><br><span class="line">    print(kwargs)</span><br><span class="line"></span><br><span class="line">print_args(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, kwarg1 = <span class="number">6</span>, kwarg2 = <span class="number">7</span>, kwarg3 = <span class="number">8</span>, kwarg4 = <span class="number">9</span>)</span><br></pre></td></tr></table></figure></p>
<p>The parameters after <code>*</code> must be passed by key word:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function_name</span><span class="params">(para1, *, para2 = <span class="string">"hello"</span>, para3)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">function_name(<span class="number">1</span>, para2 = <span class="string">"world"</span>, para3 = <span class="number">567</span>)</span><br></pre></td></tr></table></figure></p>
<p>Correspondingly, we have <code>extended call syntax</code>, unpacking when pass the parameters to function call, <code>*</code> is for tuple or list, <code>**</code> is for dict. </p>
<p>Unpacking parameters:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(a, b, c, d)</span>:</span> </span><br><span class="line">    print(a, b, c, d) </span><br><span class="line"></span><br><span class="line">my_list = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>] </span><br><span class="line">  </span><br><span class="line"><span class="comment"># Unpacking list into four arguments </span></span><br><span class="line"><span class="comment"># 在变量前加单星号表示将元组（列表、集合）拆分为单个元素</span></span><br><span class="line"><span class="comment"># 双星号同上，区别是目标为字典，字典前加单星号的话可以得到“键”</span></span><br><span class="line">fun(*my_list)</span><br></pre></td></tr></table></figure></p>
<p>Positional-only arguments:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## no kwarg can be used here</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function_name</span><span class="params">(x, /)</span>:</span></span><br><span class="line">    print(x)</span><br></pre></td></tr></table></figure></p>
<p>If no <code>return</code>, then will implicitly return <code>None</code>.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function_name</span><span class="params">(para1 = <span class="string">"hello"</span>, para2 = <span class="number">34</span>)</span>:</span></span><br><span class="line">    <span class="comment">## rebind the global variable to local</span></span><br><span class="line">    <span class="keyword">global</span> count</span><br><span class="line">    <span class="comment">## return None</span></span><br><span class="line">    <span class="keyword">return</span></span><br></pre></td></tr></table></figure></p>
<p>Notice that always use immutable value for default value!! Default value的赋值会在最初执行函数的时候运行一次，之后调用不会再重新赋值，看样子是一直存在内存里了。<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_word</span><span class="params">(org=[])</span>:</span></span><br><span class="line">    org.append(<span class="string">"!"</span>)</span><br><span class="line">    <span class="keyword">return</span> org</span><br><span class="line"><span class="comment">## if you call multiple times with default value, the "!" get accumulated</span></span><br><span class="line">print(append_word()) <span class="comment"># ["!"]</span></span><br><span class="line">print(append_word()) <span class="comment"># ["!", "!"]</span></span><br><span class="line">print(append_word()) <span class="comment"># ["!", "!", "!"]</span></span><br></pre></td></tr></table></figure></p>
<p>Another example:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_time</span><span class="params">(t = time.ctime<span class="params">()</span>)</span>:</span></span><br><span class="line">    print(t)</span><br><span class="line"></span><br><span class="line"><span class="comment">## the print will not get updated</span></span><br><span class="line">show_time()</span><br><span class="line">show_time()</span><br></pre></td></tr></table></figure></p>
<p>Function is also an object, can be used as parameters:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_card</span><span class="params">(words)</span>:</span></span><br><span class="line">    banner = <span class="string">"+"</span> + <span class="string">"-"</span> * (len(words) + <span class="number">2</span>) + <span class="string">"+"</span></span><br><span class="line">    output = <span class="string">"| "</span> + words + <span class="string">" |"</span></span><br><span class="line">    lines = [banner, output, banner]</span><br><span class="line">    print(<span class="string">"\n"</span>.join(lines))</span><br><span class="line">    print()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">print_words</span><span class="params">(printer, words)</span>:</span></span><br><span class="line">    printer(words)</span><br><span class="line"></span><br><span class="line"><span class="comment">## print_card passed as parameter</span></span><br><span class="line">print_words(print_card, <span class="string">"hello, world!"</span>)</span><br></pre></td></tr></table></figure></p>
<p>*args and **kwargs 可以用来<code>argument forwarding</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trace</span><span class="params">(f, *args, **kwargs)</span>:</span></span><br><span class="line">    res = f(*args, **kwargs)</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p>
<h2 id="Special-Functions"><a href="#Special-Functions" class="headerlink" title="Special Functions"></a>Special Functions</h2><p>Detect whether a module is run as a script or imported as a module.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># only execute function when it is run as a script</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure></p>
<h2 id="Functional-Programming"><a href="#Functional-Programming" class="headerlink" title="Functional Programming"></a>Functional Programming</h2><p>The special function <code>__call__</code>, 使用后class object可以当做function来调用，<code>__call__</code>就相当于定义了一个调用接口，并且加上其他数据结构，可以实现caching的效果 stateful.</p>
<p>You can use <code>timeit</code> module <code>timeit</code> method to measure exection time.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## resolver.py file</span></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Resolver</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self._cache = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span><span class="params">(self, host)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> host <span class="keyword">not</span> <span class="keyword">in</span> self._cache:</span><br><span class="line">            self._cache[host] = socket.gethostbyname(host)</span><br><span class="line">        <span class="keyword">return</span> self._cache[host]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">clear</span><span class="params">(self)</span>:</span></span><br><span class="line">        self._cache.clear()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">has_host</span><span class="params">(self, host)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> host <span class="keyword">in</span> self._cache</span><br></pre></td></tr></table></figure></p>
<p>Run in REPL:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> resolver <span class="keyword">import</span> Resolver</span><br><span class="line">res = Resolver()</span><br><span class="line"><span class="comment">## just like call function</span></span><br><span class="line">res(<span class="string">"www.google.com"</span>)</span><br><span class="line"><span class="comment">## call second time, the execution time reduces a lot</span></span><br><span class="line">res(<span class="string">"www.google.com"</span>)</span><br></pre></td></tr></table></figure></p>
<p>How to know object is callable, use <code>callable()</code> function to test.</p>
<h3 id="Lambda"><a href="#Lambda" class="headerlink" title="Lambda"></a>Lambda</h3><p>Create anonymous callable objects, syntax: <code>lambda [args]: expr</code>, the args are separated by commas or empty, the body is a <strong>single</strong> expression.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## the key is assigned a callable function</span></span><br><span class="line"><span class="comment">## similar to Java</span></span><br><span class="line">sort(name_list, key=<span class="keyword">lambda</span> name: name.split()[<span class="number">-1</span>])</span><br></pre></td></tr></table></figure></p>
<h3 id="Functional-style-Tools"><a href="#Functional-style-Tools" class="headerlink" title="Functional-style Tools"></a>Functional-style Tools</h3><p><code>map()</code>: maps function to a sequence, lazy implementation, return iterator.<br><code>filter()</code>: remove elements from sequence which don’t meet some criteria, lazily.<br><code>functools.reduce()</code>: 2-arguments function with a sequence, reduce the sequence to one result.</p>
<h2 id="Local-Function"><a href="#Local-Function" class="headerlink" title="Local Function"></a>Local Function</h2><p>functions defined inside function.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 实现了和前面lambda类似的功能</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sort_by_last_letter</span><span class="params">(strings)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">last_letter</span><span class="params">(s)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> s[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> sorted(strings, key=last_letter)</span><br><span class="line">sort_by_last_letter([<span class="string">"hesd"</span>, <span class="string">"sddn"</span>, <span class="string">"pplea"</span>])</span><br></pre></td></tr></table></figure></p>
<p>Name resulation in the scope is checked by <code>LEGB</code> rule: Local -&gt; Enclosing (the containing function) -&gt; Global -&gt; Build-in:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">g = <span class="string">"global"</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">outer</span><span class="params">(p = <span class="string">"param"</span>)</span>:</span></span><br><span class="line">    l = <span class="string">"local"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inner</span><span class="params">()</span>:</span></span><br><span class="line">        print(g, p, l)</span><br><span class="line">    inner()</span><br><span class="line"></span><br><span class="line"><span class="comment">## global param local</span></span><br><span class="line">outer()</span><br><span class="line"><span class="comment">## this call is wrong!</span></span><br><span class="line">outer.inner()</span><br></pre></td></tr></table></figure></p>
<p>Local function usage cases:</p>
<ol>
<li>define one-off functions close to their use.</li>
<li>code organization and readability.</li>
<li>similar to lambda but more general, can have mutliple expressions.</li>
</ol>
<p>Local function can be returned, working with <code>Closure</code>(在返回local function时，对其需要的资源进行保留，防止被垃圾回收, keep enclosing-scope objects alive):<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">enclosing</span><span class="params">()</span>:</span></span><br><span class="line">    x = <span class="string">"closed over"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">local_func</span><span class="params">()</span>:</span></span><br><span class="line">        print(x)</span><br><span class="line">    <span class="keyword">return</span> local_func</span><br><span class="line">lf = enclosing()</span><br><span class="line"><span class="comment">## call it</span></span><br><span class="line">lf()</span><br><span class="line"></span><br><span class="line"><span class="comment">## check closure env</span></span><br><span class="line"><span class="comment">## (&lt;cell at 0x106739e88: str object at 0x1067b5ab0&gt;,)</span></span><br><span class="line">lf.__closure__</span><br></pre></td></tr></table></figure></p>
<p><code>Function factories</code>, return other functions, returned function use both their own arguments as well as arguments to the factory.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">raise_to</span><span class="params">(exp)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">raise_to_exp</span><span class="params">(x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> pow(x, exp)</span><br><span class="line">    <span class="keyword">return</span> raise_to_exp</span><br><span class="line"></span><br><span class="line">square = raise_to(<span class="number">2</span>)</span><br><span class="line">square(<span class="number">9</span>)</span><br></pre></td></tr></table></figure></p>
<p><code>nonlocal</code> is like <code>global</code> keyword, to name binding in enclosing scope. 有点类似于local function使用的全局变量，但只针对同一个local function.</p>
<h2 id="Function-Decorators"><a href="#Function-Decorators" class="headerlink" title="Function Decorators"></a>Function Decorators</h2><p>Allow you to modify existing functions or methods without changing their definition (在原函数中加入上下文). Decorators can be:</p>
<ol>
<li>Local function 以及 closure 结合使用.</li>
<li>class, the class must implement <code>__call__()</code>, all class define variables are gave to decorated function.</li>
<li>instance of a class, can control decorator behavior via instance variable.</li>
</ol>
<p>You can think decorator as a function accepting a function and returning a function (callable).</p>
<p>这里举一个local function作为decorator的例子，其他类型decorator暂时没用到:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## f: the target decorated function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">escape_unicode</span><span class="params">(f)</span>:</span></span><br><span class="line">    <span class="comment">## local function wrap</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">wrap</span><span class="params">(*args, **kwargs)</span>:</span></span><br><span class="line">        <span class="comment">## in below, f is `city_name`</span></span><br><span class="line">        res = f(*args, **kwargs)</span><br><span class="line">        <span class="keyword">return</span> ascii(res)</span><br><span class="line">    <span class="comment">## wrap uses a closure to access f after escape_unicode returns</span></span><br><span class="line">    <span class="keyword">return</span> wrap</span><br><span class="line"></span><br><span class="line"><span class="comment">## original function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">city_name</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"Tomの"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## the city_name pass to decorator</span></span><br><span class="line"><span class="meta">@escape_unicode</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">city_name</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">"Tomの"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## now unicode is translated to ascii</span></span><br><span class="line">print(city_name())</span><br></pre></td></tr></table></figure></p>
<p>You can have multiple decorators, act in order 3-&gt;2-&gt;1:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">@decorator1</span></span><br><span class="line"><span class="meta">@decorator2</span></span><br><span class="line"><span class="meta">@decorator3</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">function</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<p>Keep original function metadata, for example <code>__name__</code> and <code>__doc__</code>, using functooks.wraps():<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> functools</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">noop</span><span class="params">(f)</span>:</span></span><br><span class="line">    <span class="comment">## </span></span><br><span class="line"><span class="meta">    @functools.wraps(f)</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">noop_wrapper</span><span class="params">()</span>:</span></span><br><span class="line">        <span class="keyword">return</span> f()</span><br><span class="line">    <span class="keyword">return</span> noop_wrapper</span><br><span class="line"></span><br><span class="line"><span class="meta">@noop</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""Print a dummy message</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    print(<span class="string">"hello. world!"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## check metadata is there</span></span><br><span class="line">help(hello)</span><br><span class="line">hello.__name__</span><br><span class="line">hello.__doc__</span><br></pre></td></tr></table></figure></p>
<p>Parameterized decorator的一个用途是检查传入原函数的参数，比如这里检查第二个参数不能为负数:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check_non_negative</span><span class="params">(index)</span>:</span></span><br><span class="line">     <span class="comment">## real decorating part                                      </span></span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">validator</span><span class="params">(f)</span>:</span>                                                       </span><br><span class="line">         <span class="function"><span class="keyword">def</span> <span class="title">wrap</span><span class="params">(*args)</span>:</span>                                                    </span><br><span class="line">             <span class="keyword">if</span> args[index] &lt; <span class="number">0</span>:                                             </span><br><span class="line">                 <span class="keyword">raise</span> ValueError(                                           </span><br><span class="line">                     <span class="string">'Argument &#123;&#125; must be non-negative.'</span>.format(index))      </span><br><span class="line">             <span class="keyword">return</span> f(*args)                                                 </span><br><span class="line">         <span class="keyword">return</span> wrap                                                         </span><br><span class="line">     <span class="keyword">return</span> validator                                                        </span><br><span class="line"></span><br><span class="line"><span class="comment">## 这里实际上是调用了check_non_negative，返回的结果作为decorator </span></span><br><span class="line"><span class="comment">## 和上面的用法不一样了                                                     </span></span><br><span class="line"><span class="meta">@check_non_negative(1)                                                      </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_list</span><span class="params">(value, size)</span>:</span>                                               </span><br><span class="line">    <span class="keyword">return</span> [value] * size</span><br><span class="line"></span><br><span class="line"><span class="comment">## good</span></span><br><span class="line">create_list(<span class="string">'a'</span>, <span class="number">3</span>) </span><br><span class="line"><span class="comment">## bad</span></span><br><span class="line">create_list(<span class="string">'a'</span>, <span class="number">-4</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h1><p>Unlike other programming languages, Python has <strong>no</strong> command for declaring a variable, python is dynamic type.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># explicit conversion</span></span><br><span class="line">int(<span class="string">"234"</span>)</span><br><span class="line"><span class="comment"># toward 0 cutting</span></span><br><span class="line">int(<span class="string">"-342.134"</span>)</span><br><span class="line"><span class="comment"># 2 is the base</span></span><br><span class="line">int(<span class="string">"100"</span>, <span class="number">2</span>)</span><br><span class="line">float(<span class="string">"34.56"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># special</span></span><br><span class="line">float(<span class="string">"nan"</span>)</span><br><span class="line">float(<span class="string">"inf"</span>)</span><br><span class="line">float(<span class="string">"-inf"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">None</span> </span><br><span class="line"><span class="keyword">True</span>, <span class="keyword">False</span></span><br><span class="line"><span class="comment"># True</span></span><br><span class="line">bool(<span class="number">3.4</span>)</span><br><span class="line">bool(<span class="string">"False"</span>)</span><br><span class="line"><span class="comment"># False</span></span><br><span class="line">bool(<span class="number">0</span>)</span><br><span class="line">bool([])</span><br><span class="line">bool(())</span><br><span class="line">bool(<span class="string">""</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="Operators"><a href="#Operators" class="headerlink" title="Operators"></a>Operators</h2><p>Python will not perform implicit type conversion, for example <code>&quot;123&quot; + 56</code> is wrong. Exception is in <code>if</code> and <code>while</code> condition.</p>
<p>Notice that <code>==</code> vs <code>is</code> when compare strings, <code>==</code> compare the value but <code>is</code> compares the identity equality, you can check the unique number by <code>id()</code>. And comparsion by value can be controlled programatically.</p>
<p>The logic operators are <code>and</code>, <code>or</code> and <code>not</code>. 这里注意它们会返回最后eval的值，可以利用这个特点:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 999</span></span><br><span class="line"><span class="string">"hello"</span> <span class="keyword">and</span> <span class="number">999</span></span><br><span class="line"><span class="comment">### "world"</span></span><br><span class="line"><span class="number">0</span> <span class="keyword">or</span> <span class="string">'world'</span></span><br></pre></td></tr></table></figure></p>
<p>Check if an object is None using <code>is</code> operator.<br>Function parameters and <code>return</code> are transferred using <strong>pass-by-object-reference</strong>.</p>
<p>Notice that sequence of the same type also support comparison, just like string comparison, item by item from left to right<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">(<span class="number">3</span>, <span class="number">99</span>, <span class="number">5</span>, <span class="number">2</span>) &lt; (<span class="number">5</span>, <span class="number">7</span>, <span class="number">3</span>)</span><br><span class="line">[<span class="number">5</span>, <span class="number">3</span>, <span class="number">1</span>] &gt; [<span class="number">1</span>, <span class="number">9</span>, <span class="number">2</span>]</span><br></pre></td></tr></table></figure></p>
<h2 id="Control-Flows"><a href="#Control-Flows" class="headerlink" title="Control Flows"></a>Control Flows</h2><p>Python does not have switch statement, there are several ways to mimic it:<br><a href="https://stackoverflow.com/questions/60208/replacements-for-switch-statement-in-python" target="_blank" rel="noopener">Python switch replacements</a></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## condition</span></span><br><span class="line"><span class="keyword">if</span> x &gt; <span class="number">100</span> <span class="keyword">and</span> x &lt;= <span class="number">999</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">elif</span> x &gt;= <span class="number">34</span> <span class="keyword">or</span> x &lt; <span class="number">-23</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">elif</span> <span class="keyword">not</span> x:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## ternary</span></span><br><span class="line">res = <span class="string">"big"</span> <span class="keyword">if</span> x &gt;= <span class="number">100</span> <span class="keyword">else</span> <span class="string">"small"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## loop</span></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> iterable:</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">break</span>/<span class="keyword">continue</span></span><br></pre></td></tr></table></figure>
<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p>Unicode characters.</p>
<p>Python does not have a character data type, a single character is simply a string with a length of <code>1</code>. Square brackets can be used to access elements of the string or slice string.</p>
<p>Escape will work on both <code>&quot;</code> and <code>&#39;</code>.</p>
<p>The same as Java, string in Python is immutable.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## raw string, no escape</span></span><br><span class="line">x = <span class="string">r"\n\r\x 234\n\r"</span></span><br><span class="line">type(x[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">## list str methods</span></span><br><span class="line">help(str) <span class="comment">## have definition</span></span><br><span class="line">dir(str)</span><br><span class="line"></span><br><span class="line"><span class="comment">## string length</span></span><br><span class="line">len(str)</span><br><span class="line"><span class="comment">## more efficient than "+"</span></span><br><span class="line">items = <span class="string">"+"</span>.join([<span class="string">"hello"</span>, <span class="string">"world"</span>])</span><br><span class="line">items.split(<span class="string">"+"</span>)</span><br><span class="line"><span class="string">"   abc   "</span>.strip()</span><br><span class="line"></span><br><span class="line"><span class="comment">## _ is the dummy var that will not be used</span></span><br><span class="line">up, _, down = <span class="string">"good:bad"</span>.partition(<span class="string">":"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## operator</span></span><br><span class="line"><span class="string">"123"</span> + <span class="string">"456"</span></span><br><span class="line"><span class="string">"123"</span> * <span class="number">5</span></span><br></pre></td></tr></table></figure></p>
<p>Python <code>f-Strings</code> is better and concise then <code>format()</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">a = <span class="number">23</span></span><br><span class="line">b = <span class="string">"apple"</span></span><br><span class="line">print(<span class="string">f"I have <span class="subst">&#123;a&#125;</span> <span class="subst">&#123;b&#125;</span>s"</span>)</span><br><span class="line"><span class="comment">## others</span></span><br><span class="line">print(<span class="string">"&#123;1&#125; and &#123;0&#125;"</span>.format(a, b))</span><br><span class="line">print(<span class="string">"%d and %s"</span> % (a, b))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example of accessing the attributes of an object</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">file = <span class="string">"/etc"</span></span><br><span class="line">info = os.stat(file)</span><br><span class="line">print(<span class="string">"file &#123;0&#125; uid &#123;1.st_uid&#125;, size &#123;1.st_size&#125;"</span>.format(file, info))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Example of specifying field width and precision</span></span><br><span class="line"><span class="comment"># Print table of powers of two and their square roots</span></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line">x = <span class="number">1</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    x = x * <span class="number">2</span></span><br><span class="line">    y = math.sqrt(x)</span><br><span class="line">    print(<span class="string">"&#123;0:4&#125;&#123;1:10&#125;&#123;2:10.3f&#125;"</span>.format(i, x, y))</span><br><span class="line">    <span class="comment"># print("%4d%10d%10.3f" % (i, x, y))</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Bytes"><a href="#Bytes" class="headerlink" title="Bytes"></a>Bytes</h2><p>In python3, Strings are represented by sequences of unicodes, but textual data in Linux is a sequence of bytes, we need to use <code>encode()</code> and <code>decode()</code> to convert python string to/from bytes.</p>
<p>You get byte object from HTTP request, need to convert to str to use.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">x = <span class="string">"hello world"</span></span><br><span class="line">type(x)</span><br><span class="line"><span class="comment">##convert to byte stream</span></span><br><span class="line">data = x.encode(<span class="string">"utf-8"</span>)</span><br><span class="line"><span class="comment">## convert back</span></span><br><span class="line">x = data.decode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## byte string</span></span><br><span class="line">b = <span class="string">b"hello world"</span></span><br><span class="line">type(b)</span><br></pre></td></tr></table></figure></p>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## can have comma at end</span></span><br><span class="line">a = [<span class="number">1</span>, <span class="number">2</span>, <span class="string">"abc"</span>, <span class="number">34</span>, <span class="number">76.887</span>, <span class="string">"jark"</span>, <span class="number">-84.124</span>]</span><br><span class="line">a = []</span><br><span class="line"><span class="comment">## slice</span></span><br><span class="line">a[<span class="number">1</span>: <span class="number">-1</span>: <span class="number">3</span>]</span><br><span class="line">a[: <span class="number">5</span>: <span class="number">3</span>]</span><br><span class="line">a[<span class="number">2</span>:]</span><br><span class="line"><span class="comment">## reverse the sequence</span></span><br><span class="line">a[::<span class="number">-1</span>]</span><br><span class="line"><span class="comment">## remove element from list</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">a</span>[3]</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="title">a</span>.<span class="title">append</span><span class="params">(<span class="number">998</span>)</span></span></span><br><span class="line">## join list, not append, they are different!</span><br><span class="line">a += [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]</span><br><span class="line">a.append([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">a.pop()</span><br><span class="line">a.index(<span class="string">"abc"</span>)</span><br><span class="line">a.count(<span class="number">34</span>)</span><br><span class="line">a.remove(<span class="string">"abc"</span>)</span><br><span class="line">a.insert(<span class="number">3</span>, <span class="string">"apple"</span>)</span><br><span class="line">a.reverse()</span><br><span class="line"><span class="comment">## reverse sort</span></span><br><span class="line">a.sort(reverse = <span class="keyword">True</span>)</span><br><span class="line"><span class="comment">## sort by length of each object</span></span><br><span class="line">a.sort(key=len)</span><br><span class="line"></span><br><span class="line"><span class="comment">## copy the list, but they are all shallow copy!!</span></span><br><span class="line">a[:]</span><br><span class="line">a.copy()</span><br><span class="line">list(a)</span><br></pre></td></tr></table></figure>
<p>除了list自带的sort and reverse, out-of-place functions: sorted(), reversed() can also be used, they create a new list, reversed() will return a reversed iterator.</p>
<h2 id="Dict"><a href="#Dict" class="headerlink" title="Dict"></a>Dict</h2><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">d = dict()</span><br><span class="line">d = &#123;&#125;</span><br><span class="line"><span class="comment">## add or update</span></span><br><span class="line">d[<span class="string">"one"</span>] = <span class="number">34</span></span><br><span class="line"><span class="keyword">del</span> d[<span class="string">"one"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## key can be string, number and bool</span></span><br><span class="line">d = &#123;<span class="string">"k1"</span>: <span class="string">"v1"</span>, <span class="string">"k2"</span>, <span class="number">123</span>&#125;</span><br><span class="line">d = dict(a=<span class="string">"343"</span>, b=<span class="string">"uuys"</span>, c=<span class="number">123</span>)</span><br><span class="line"><span class="comment">## can even be generated by tuple</span></span><br><span class="line">a = [(<span class="string">"sure"</span>, <span class="number">643</span>), (<span class="number">98</span>, <span class="string">"341"</span>), (<span class="string">"name"</span>, <span class="string">"monkey"</span>)]</span><br><span class="line">d = dict(a)</span><br></pre></td></tr></table></figure>
<p>The copy of dict is shallow.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">d.copy()</span><br><span class="line">dict(d)</span><br></pre></td></tr></table></figure></p>
<p>merge dict:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## if keys are overlapped, the value will be updated by the merged one</span></span><br><span class="line">d.update(&#123;<span class="string">"away"</span>: <span class="number">998</span>&#125;)</span><br></pre></td></tr></table></figure></p>
<p>iterate dict via foreach loop:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> d.keys()</span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> d.values()</span><br><span class="line"><span class="keyword">for</span> k, v <span class="keyword">in</span> d.items()</span><br></pre></td></tr></table></figure></p>
<p>Use <code>in</code> and <code>not in</code> to check the existence.</p>
<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>Immutable collection with unique immutable objects.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## s = () is tuple!</span></span><br><span class="line">s = set()</span><br><span class="line">s = &#123;<span class="number">3</span>, <span class="number">676</span>, <span class="number">1</span>, <span class="number">34</span>, <span class="number">89</span>&#125;</span><br><span class="line">type(s)</span><br><span class="line"></span><br><span class="line">s.add(<span class="number">99</span>)</span><br><span class="line">s.update(&#123;<span class="number">5</span>, <span class="number">232</span>, <span class="number">89</span>, <span class="number">-45</span>&#125;)</span><br><span class="line">s.remove(<span class="number">3</span>)</span><br></pre></td></tr></table></figure></p>
<p>Use <code>in</code> and <code>not in</code> to check the existence.</p>
<p>The copy of dict is shallow.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">s.copy()</span><br><span class="line">set(d)</span><br></pre></td></tr></table></figure></p>
<p>Set 有很多代数运算法则可以使用:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">s.union(t)</span><br><span class="line">s.intersection(t)</span><br><span class="line">s.difference(t)</span><br><span class="line">s.symmetric_difference(t)</span><br><span class="line">s.issubset(t)</span><br><span class="line">s.issuperset(t)</span><br><span class="line">s.isdisjoint(t)</span><br></pre></td></tr></table></figure></p>
<h2 id="Tuple"><a href="#Tuple" class="headerlink" title="Tuple"></a>Tuple</h2><p>Tuples are unchangeable, or <strong>immutable</strong> as it also is called.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## useless, because immutable</span></span><br><span class="line">t1 = ()</span><br><span class="line"></span><br><span class="line">t1 = (<span class="string">"apple"</span>, <span class="string">"banana"</span>, <span class="string">"cherry"</span>)</span><br><span class="line"><span class="comment">## create one item tuple, must append comma!</span></span><br><span class="line">t2= (<span class="string">"apple"</span>,)</span><br><span class="line">type(t2)</span><br><span class="line"></span><br><span class="line"><span class="comment">## this is also tuple, used in function return</span></span><br><span class="line">t2 = <span class="number">1</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="string">"ok"</span></span><br><span class="line"><span class="comment">## for example</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">min_max</span><span class="params">(items)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> min(items), max(items)</span><br><span class="line"></span><br><span class="line"><span class="comment">## tuple unpacking</span></span><br><span class="line">lower, upper = min_max([<span class="number">2</span>, <span class="number">3</span>, <span class="number">7</span>, <span class="number">4</span>, <span class="number">34</span>])</span><br><span class="line"><span class="comment">## can be nested unpacking</span></span><br><span class="line">(a, (b, c)) = (<span class="number">1</span>, (<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"><span class="comment">## swap value</span></span><br><span class="line">a, b = b, a</span><br></pre></td></tr></table></figure></p>
<p>Other operations:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">t3 = (<span class="string">"hello"</span>, <span class="number">10.23</span>, <span class="number">99</span>)</span><br><span class="line">len(t3)</span><br><span class="line">t3 += (<span class="string">"world!"</span>)</span><br><span class="line">t3 * <span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Range"><a href="#Range" class="headerlink" title="Range"></a>Range</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">range(stop)</span><br><span class="line">range(start, stop)</span><br><span class="line">range(start, stop, step)</span><br></pre></td></tr></table></figure>
<p>Used usually for loop counter:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<p>Other usages, for example, generate a list:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">list(range(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure></p>
<h2 id="Enumerate"><a href="#Enumerate" class="headerlink" title="Enumerate"></a>Enumerate</h2><p>If you want to have index pair with the item, use <code>enumerate()</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">t = [<span class="number">3</span>, <span class="number">35</span>, <span class="number">546</span>, <span class="number">76</span>, <span class="number">123</span>]</span><br><span class="line"><span class="keyword">for</span> i, v <span class="keyword">in</span> enumerate(t):</span><br><span class="line">    print(<span class="string">f"i = <span class="subst">&#123;i&#125;</span>, v = <span class="subst">&#123;v&#125;</span>"</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="Iteration-and-Iterables"><a href="#Iteration-and-Iterables" class="headerlink" title="Iteration and Iterables"></a>Iteration and Iterables</h1><p>Comprehensions with filtering<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list comprehension</span></span><br><span class="line">[expr(item) <span class="keyword">for</span> item <span class="keyword">in</span> iterable <span class="keyword">if</span> filtering(item)]</span><br><span class="line"><span class="comment">## set comprehension, no meaningful order</span></span><br><span class="line">&#123;expr(item) <span class="keyword">for</span> item <span class="keyword">in</span> iterable <span class="keyword">if</span> filtering(item)&#125;</span><br><span class="line"><span class="comment">## dict</span></span><br><span class="line">&#123;key_expr(item): val_expr(item) <span class="keyword">for</span> item <span class="keyword">in</span> iterable <span class="keyword">if</span> filtering(item)&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## can also be mixed and nested</span></span><br><span class="line"><span class="comment">## this will create a list with 3 identical dict that value is None</span></span><br><span class="line"><span class="comment">## _ here is just for count</span></span><br><span class="line">[&#123;letter: <span class="keyword">None</span> <span class="keyword">for</span> letter <span class="keyword">in</span> <span class="string">"ABCDEFG"</span>&#125; <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="string">"123"</span> <span class="keyword">if</span> int(_) % <span class="number">2</span> != <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## y is nested</span></span><br><span class="line"><span class="comment">## x is outer loop</span></span><br><span class="line">[(x, y) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">3</span>) <span class="keyword">for</span> y <span class="keyword">in</span> range(<span class="number">5</span>)]</span><br></pre></td></tr></table></figure></p>
<p><code>Iterable</code> can be passed to <code>iter()</code> to produce a iterator.<br><code>Iterator</code> can be passed to <code>next()</code> to get the next value in the sequence.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">iterable = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line">iterator = iter(iterable)</span><br><span class="line">next(iterator)</span><br><span class="line">next(iterator)</span><br></pre></td></tr></table></figure></p>
<p>Generator function, stateful, laziness with <code>yield</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">yield</span> <span class="number">0</span></span><br><span class="line">    a = <span class="number">1</span></span><br><span class="line">    b = <span class="number">2</span></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        <span class="keyword">yield</span> a</span><br><span class="line">        a, b = b, a + b</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> gen():</span><br><span class="line">    print(i)</span><br><span class="line">    <span class="keyword">if</span> i &gt; <span class="number">1000</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br></pre></td></tr></table></figure></p>
<p>Generator expression, can save big memory than list comprehension:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">(expr(item) <span class="keyword">for</span> item <span class="keyword">in</span> iterable <span class="keyword">if</span> filtering(item))</span><br><span class="line"><span class="comment">## if used as function parameter, no parenthesis is needed</span></span><br><span class="line"><span class="comment">## 多余的()可以省掉</span></span><br><span class="line">sum(x * x <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">10000000</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>Generator is only single use object, 用完就没了，需要重新造一个。</p>
<p>There are several aggregation functions: bool: <code>any()</code>, <code>all()</code>; sync unlimited number of iterables <code>zip()</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i, j <span class="keyword">in</span> zip([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]):</span><br><span class="line">    print(<span class="string">f"output: <span class="subst">&#123;i&#125;</span>, <span class="subst">&#123;j&#125;</span>"</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="Class"><a href="#Class" class="headerlink" title="Class"></a>Class</h1><p>Python does not have public, private, protected key word, everything is public.</p>
<p>Polymorphism is implemented by late binding in Python, 并不是和Java 通过继承实现多态，Python中你可以对一个Object 调用任意method，只要它有这个method就行，用的时候才会检查。 并且继承在Python中主要用来分享共用的方法，当然也可以来多态, 但是继承在python中用得不多。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Parent</span>:</span></span><br><span class="line">    <span class="string">""" A Parent class """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## no number() in this class, but child class has</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_treble_number</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">""" description """</span></span><br><span class="line">        <span class="comment">## editor会报错，但构造parent()不会，除非你调用这个方法才会出错</span></span><br><span class="line">        <span class="keyword">return</span> self.get_number() * <span class="number">3</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## inheritance</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child</span><span class="params">(Parent)</span>:</span></span><br><span class="line">    <span class="string">""" A Child class """</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">## class variable, shared among all instances</span></span><br><span class="line">    class_variable = <span class="number">0</span></span><br><span class="line">    <span class="comment">## initializer not quite a constructor</span></span><br><span class="line">    <span class="comment">## self is similar to this in Java</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, number)</span>:</span></span><br><span class="line">        <span class="string">""" description """</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">## _ prefix variable is class property, treated as private, although you can access it</span></span><br><span class="line">        self._number = number</span><br><span class="line">        <span class="comment">## still needs self to call method</span></span><br><span class="line">        self._lst = self._gen_list()</span><br><span class="line">        Child.class_variable += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_gen_list</span><span class="params">(self)</span>:</span></span><br><span class="line">         <span class="string">""" description """</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="keyword">None</span>] + [item <span class="keyword">for</span> item <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_number</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">""" description """</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self._number</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_double_number</span><span class="params">(self)</span>:</span></span><br><span class="line">         <span class="string">""" description """</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">## method local variable</span></span><br><span class="line">        double = self._number * <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> double</span><br></pre></td></tr></table></figure>
<p><code>Parent.__doc__</code> can be used to access doc string.</p>
<p>注意，class method的第一个parameter <code>self</code> 可以是任意其他的名字，就是个标记而已，比如:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Test</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(other, number)</span>:</span></span><br><span class="line">        other._number = number</span><br></pre></td></tr></table></figure></p>
<h1 id="File-I-O-and-Resource-Management"><a href="#File-I-O-and-Resource-Management" class="headerlink" title="File I/O and Resource Management"></a>File I/O and Resource Management</h1><p>Check default encoding, if not specified in open(), will use this default encoding format.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.getdefaultencoding()</span><br></pre></td></tr></table></figure></p>
<p>Open file with options, for example:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## mode can be any combination of `crwa`|`tb`</span></span><br><span class="line"><span class="comment">## r+ read/write</span></span><br><span class="line">f = open(<span class="string">'words.txt'</span>, mode = <span class="string">'rwt'</span>, encoding = <span class="string">'utf-8'</span>)</span><br></pre></td></tr></table></figure></p>
<p>Some useful methods after open the file:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## read all return string</span></span><br><span class="line">f.read()</span><br><span class="line"><span class="comment">## read one line</span></span><br><span class="line">f.readline()</span><br><span class="line"><span class="comment">## read all lines return a list</span></span><br><span class="line">f.readlines()</span><br><span class="line"></span><br><span class="line"><span class="comment">## use print, f is the file descriptor</span></span><br><span class="line">print(<span class="string">"wirte this line"</span>, file = f)</span><br><span class="line"><span class="comment">## write lines into file</span></span><br><span class="line">f.writelines([<span class="string">"first\n"</span>, <span class="string">"second\n"</span>])</span><br><span class="line"><span class="comment">## rewind to beginning</span></span><br><span class="line">f.seek(<span class="number">0</span>)</span><br><span class="line"><span class="comment">## close file after use, to flush updates to disk</span></span><br><span class="line">f.close(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>For reading file, you can also use loop:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">    <span class="comment">## will not print \n, or you can use print(line.strip())</span></span><br><span class="line">    sys.stdout.wirte(line)</span><br></pre></td></tr></table></figure></p>
<p>Use <code>with-block</code> to auto close the resource (or you can use finally block)，不仅仅是用在file上，比如网络上的读写也可以，它们背后的实现都遵循了同样的规则，所以可以使用with-block:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">with</span> open(...) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<p>注意这个<code>as</code> 是可以省略的，在threading module的lock使用中，就没有<code>as</code>.</p>
<h1 id="Data-Structure"><a href="#Data-Structure" class="headerlink" title="Data Structure"></a>Data Structure</h1><p>这里主要是和Java 对比，一些常用的数据结构，比如Stack, Queue, Deque, priorityQueue, Map, etc.</p>
<h2 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h2><p><a href="https://www.geeksforgeeks.org/queue-in-python/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/queue-in-python/</a><br>There are 3 ways to implement queue in python:</p>
<ol>
<li><code>list</code>, quite slow by <code>append()</code> and <code>pop(0)</code>, need shift all elements.</li>
<li><code>collections</code> module import <code>deque</code>, can be used as queue.</li>
<li><code>queue</code> module import <code>Queue</code>, A maxsize of zero <code>0</code> means a infinite queue. (this can be a synchronzied queue for thread programming)</li>
</ol>
<h2 id="Deque"><a href="#Deque" class="headerlink" title="Deque"></a>Deque</h2><p>see Queue section:</p>
<ol>
<li><code>collections</code> module import <code>deque</code>, can be used as queue.</li>
</ol>
<h2 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h2><p><a href="https://www.geeksforgeeks.org/stack-in-python/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/stack-in-python/</a></p>
<p>There are 3 ways to implement stack in python:</p>
<ol>
<li><code>list</code>, but when growing it has speed issues.</li>
<li><code>collections</code> module import <code>deque</code>, can be used as stack (use this one).</li>
<li><code>queue</code> module import <code>LifoQueue</code>, A maxsize of zero <code>0</code> means a infinite stack.</li>
</ol>
<h2 id="Priority-Queue"><a href="#Priority-Queue" class="headerlink" title="Priority Queue"></a>Priority Queue</h2><p><a href="https://www.geeksforgeeks.org/priority-queue-in-python/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/priority-queue-in-python/</a></p>
<p>By using heap data structure to implement Priority Queues, Time complexity:<br>Insert Operation: O(log(n))<br>Delete Operation: O(log(n))</p>
<p>Min heap can be implemented by <code>heapq</code> module:<br><a href="https://www.geeksforgeeks.org/heap-queue-or-heapq-in-python/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/heap-queue-or-heapq-in-python/</a></p>
<p>Max heap is not implemented in <code>heapq</code>, the alternative way is invert the priority:<br><a href="https://stackoverflow.com/questions/2501457/what-do-i-use-for-a-max-heap-implementation-in-python" target="_blank" rel="noopener">https://stackoverflow.com/questions/2501457/what-do-i-use-for-a-max-heap-implementation-in-python</a></p>
<p>from <code>queue</code> import <code>PriorityQueue</code>, min heap too:<br><a href="https://www.geeksforgeeks.org/priority-queue-using-queue-and-heapdict-module-in-python" target="_blank" rel="noopener">https://www.geeksforgeeks.org/priority-queue-using-queue-and-heapdict-module-in-python</a></p>
<h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><p>use primitive type <code>dict</code>.</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>Python3 Scripting</title>
    <url>/2020/08/14/python-scripting/</url>
    <content><![CDATA[<p>Why Python scripting?<br>Easy to learn and write, interactively, powerful built-in data types and object oriented. Included packages to support huge range of tasks.</p>
<p>The demos of this blog:<br><a href="https://github.com/chengdol/python-scripting" target="_blank" rel="noopener">https://github.com/chengdol/python-scripting</a></p>
<h1 id="Common-Modules-for-Scripting"><a href="#Common-Modules-for-Scripting" class="headerlink" title="Common Modules for Scripting"></a>Common Modules for Scripting</h1><ul>
<li><code>math</code>: Trig functions, sqrt, logarithms, exponentials</li>
<li><code>pickle</code>: Serialise / de-serialize objects for persistent storage</li>
<li><code>random</code>: Generate random numbers with various distributions</li>
<li><code>re</code>: Regular expression pattern matching and substitution</li>
<li><code>string</code>: Comprehensive string formatting</li>
<li><code>configparser</code>: Configuration file parser</li>
<li><code>bz2</code>: gzip, read and write compressed files</li>
<li><code>tarfile</code>: Read and write tar archives</li>
<li><code>datetime</code>: Represent and manipulate dates and times</li>
<li><code>logging</code>: Log message generator with various backends</li>
<li><code>argparse</code>: Parser for command-line options</li>
<li><code>optparse</code>: Parse command-line arguments</li>
<li><code>click</code>: command-line argument toolkit, decorator</li>
<li><code>os</code>: Interface to operating system services</li>
<li><code>sys</code>: Access argv, stdin, stdout, etc.</li>
<li><code>socket</code>: Python binding for the traditional BSD socket API</li>
<li><code>http</code>: Modules for client and server side http, and cookies</li>
<li><code>shutil</code>: Copy / remove files and directory trees</li>
<li><code>glob</code>: Shell-style wildcard expansion</li>
<li><code>xml</code>: Processing of XML data</li>
<li><code>hashlib</code>: common interface to many hash functions</li>
<li><code>signal</code>: single handling</li>
<li><code>subprocess</code>: execute command by spawn new processes, connect to their input/output/error pipes, and obtain their return codes</li>
<li><code>shlex</code>: parsing unix shell commands, for example, split long arguments</li>
<li><code>smtplib</code>: email handling</li>
<li><code>threading</code>: threading operations</li>
<li><code>timeit</code>: measure executing time </li>
<li><code>pyyaml</code>: parse yaml file</li>
</ul>
<h1 id="Work-Environment"><a href="#Work-Environment" class="headerlink" title="Work Environment"></a>Work Environment</h1><h2 id="REPL"><a href="#REPL" class="headerlink" title="REPL"></a>REPL</h2><p><code>REPL</code>: the interactive console. 这是最基本的一个python interactive shell, can be used for testing purpose.</p>
<h2 id="IPython"><a href="#IPython" class="headerlink" title="IPython"></a>IPython</h2><p><code>ipython</code>: the enhanced python interpreter, can run shell commands + REPL, make alias for arbitrary shell commands and with TAB completion.</p>
<p>How to install: <code>yum install -y ipython3</code><br>Then in terminal, run <code>ipython3</code></p>
<p>可以直接在ipython中运行比如<code>ls -ltr</code>, <code>cd</code> 之类的命令，这些都属于magic function:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## off magic</span></span><br><span class="line">automagic</span><br><span class="line"><span class="comment">## then you need % prefix to run shell commands</span></span><br><span class="line">%ls -ltr</span><br><span class="line"></span><br><span class="line"><span class="comment">## open magic again</span></span><br><span class="line">%automagic</span><br><span class="line"><span class="comment">## no need % prefix</span></span><br><span class="line">ls -ltr</span><br><span class="line"></span><br><span class="line"><span class="comment">## helper</span></span><br><span class="line">ls?</span><br><span class="line"></span><br><span class="line"><span class="comment">## list env variables</span></span><br><span class="line">whos</span><br></pre></td></tr></table></figure></p>
<p>Create alias:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create alias 'findsymlinks'</span></span><br><span class="line">alias findsymlinks ls -l /etc/ | grep <span class="string">'^l'</span></span><br><span class="line">%findsymlinks</span><br></pre></td></tr></table></figure></p>
<p>Run and edit files in IPython:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">run script.py</span><br><span class="line"><span class="comment">## default using vi or vim, $EDITOR</span></span><br><span class="line">edit script.py</span><br></pre></td></tr></table></figure></p>
<p>对于不能直接运行的shell commads, use shell escape with prefix <code>!</code>, similar to vim feature:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## can store the output to a variable</span></span><br><span class="line">out = !df</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> out.grep(<span class="string">"tmpfs"</span>):</span><br><span class="line">    print(line)</span><br></pre></td></tr></table></figure></p>
<h2 id="IDLE"><a href="#IDLE" class="headerlink" title="IDLE"></a>IDLE</h2><p>How to install: <code>yum install -y idle3</code><br>To run idle3, you need desktop environment.</p>
<h1 id="Managing-File-System"><a href="#Managing-File-System" class="headerlink" title="Managing File System"></a>Managing File System</h1><p>找能实现Bash中功能的函数就行。<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## walk around file system, wrap around Linux system call</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">os.getcwd()</span><br><span class="line"><span class="comment">## cd /tmp</span></span><br><span class="line">os.chdir(<span class="string">"/tmp"</span>)</span><br><span class="line"><span class="comment">## current level dir list</span></span><br><span class="line">os.listdir(<span class="string">"/"</span>)</span><br><span class="line"><span class="comment">## recursively to subdir, will return a tuple</span></span><br><span class="line"><span class="comment">## (current dir name, child dirs, child files)</span></span><br><span class="line">os.walk(<span class="string">"/tmp"</span>)</span><br><span class="line">os.stat(<span class="string">"/etc/hosts"</span>)</span><br><span class="line"></span><br><span class="line">os.mkdir(path [, mode])</span><br><span class="line">os.rename(src, dst)</span><br><span class="line">os.remove(file)</span><br><span class="line"><span class="comment">## remove empty dir</span></span><br><span class="line">os.rmdir(dir)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 0o644, prefixed with '0o'</span></span><br><span class="line">os.chown(file, mode)</span><br><span class="line">os.chmod(file, uid, gid)</span><br><span class="line"><span class="comment">## hardlink</span></span><br><span class="line">os.link(src, dst)</span><br><span class="line"><span class="comment">## softlink</span></span><br><span class="line">os.symlink(src, dst)</span><br><span class="line"></span><br><span class="line"><span class="comment">## high-level file operations</span></span><br><span class="line"><span class="keyword">import</span> shutil <span class="keyword">as</span> st</span><br><span class="line">st.copy(src, dst)</span><br><span class="line"><span class="comment">## also copy attr</span></span><br><span class="line">st.copy2(src, dst)</span><br><span class="line"><span class="comment">## mv</span></span><br><span class="line">st.move(src, dst)</span><br><span class="line"><span class="comment">## rm -f</span></span><br><span class="line">st.rmtree(path)</span><br><span class="line">st.copytree(src, dst, ignore=<span class="keyword">None</span>)</span><br><span class="line"><span class="comment">## which</span></span><br><span class="line">st.which(<span class="string">"java"</span>)</span><br><span class="line"></span><br><span class="line">st.make_archive(basename, format)</span><br><span class="line">st.unpack_archive(filename, extrac_dir, format)</span><br></pre></td></tr></table></figure></p>
<h1 id="Interacting-with-Linux-System"><a href="#Interacting-with-Linux-System" class="headerlink" title="Interacting with Linux System"></a>Interacting with Linux System</h1><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment">## print command line parameters</span></span><br><span class="line"><span class="keyword">for</span> arg <span class="keyword">in</span> sys.argv[:]:</span><br><span class="line">    print(<span class="string">f"<span class="subst">&#123;arg&#125;</span>"</span>, end = <span class="string">' '</span>)</span><br><span class="line">print()</span><br></pre></td></tr></table></figure>
<p>To parse parameters, use <code>optparse</code> module, see example in git repo <code>1_optparse-demo.py</code>.<br>Besides optparse and argparse from the standard library, <code>click</code> module is a good alternative.</p>
<p>To get env varaible:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">## set default value when empty response</span></span><br><span class="line">os.getenv(<span class="string">"EDITOR"</span>, <span class="string">"/usr/bin/vim"</span>)</span><br><span class="line">os.getenv(<span class="string">"HOME"</span>)</span><br><span class="line">os.environ.get(<span class="string">"HOME"</span>)</span><br></pre></td></tr></table></figure></p>
<p>这节的git repo例子很有意思<code>5_signal-primes-v5.py</code>, <code>6_timeout.py</code>, 用signal handler 去改变条件变量的值，从而改变运行逻辑。之前一直在BASH中用trap去做终止前的处理。Linux has 2 signals set aside for user: <code>SIGUSR1</code>, <code>SIGUSR2</code>.</p>
<h1 id="Executing-Commands"><a href="#Executing-Commands" class="headerlink" title="Executing Commands"></a>Executing Commands</h1><p>Run external commands, for example, call other shell commands or executables by <code>subprocess</code>, similar to linux <code>()</code>.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">## 这是最简单的调用</span></span><br><span class="line"><span class="comment">## this will not disturb current env</span></span><br><span class="line">env = os.environ.copy()</span><br><span class="line"><span class="comment">## the run method will call Popen under the nood</span></span><br><span class="line">cmd = [<span class="string">"ls"</span>, <span class="string">"-ltr"</span>]</span><br><span class="line"><span class="comment">## if does not set stdout/stderr, then command print result to console</span></span><br><span class="line">process = subprocess.run(cmd, </span><br><span class="line">               env=env, </span><br><span class="line">               stdout=subprocess.PIPE, </span><br><span class="line">               stderr=subprocess.PIPE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">process.returncode</span><br><span class="line">process.stdout.decode(<span class="string">"utf-8"</span>)</span><br><span class="line">process.stderr.decode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 如果要运行和shell有关的命名且需要用到shell的特性 such as shell pipes, filename wildcards, environment variable expansion, and expansion of ~ to a user’s home directory.</span></span><br><span class="line"><span class="comment">## If shell is True, it is recommended to pass args as a string rather than as a sequence.</span></span><br><span class="line">env = os.environ.copy()</span><br><span class="line">cmd = <span class="string">"ls -ltr ~ | grep -i download"</span></span><br><span class="line">process = subprocess.run(cmd, </span><br><span class="line">               shell=<span class="keyword">True</span>,</span><br><span class="line">               env=env, </span><br><span class="line">               stdout=subprocess.PIPE, </span><br><span class="line">               stderr=subprocess.PIPE)</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same as</span></span><br><span class="line">cmd = [<span class="string">"/bin/sh"</span>, <span class="string">"-c"</span>, <span class="string">"--"</span>, <span class="string">"ls -ltr ~ | grep -i download"</span>]</span><br><span class="line">process = subprocess.run(cmd,</span><br><span class="line">               env=env, </span><br><span class="line">               stdout=subprocess.PIPE, </span><br><span class="line">               stderr=subprocess.PIPE)</span><br><span class="line"></span><br><span class="line">process.returncode</span><br><span class="line">process.stdout.decode(<span class="string">"utf-8"</span>)</span><br><span class="line">process.stderr.decode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 高级操作 Popen, run 在背后调用的它</span></span><br><span class="line">env = os.environ.copy()</span><br><span class="line"><span class="comment">## the same as export KUBECONFIG=clusters.yaml</span></span><br><span class="line">env[<span class="string">'KUBECONFIG'</span>] = <span class="string">"clusters.yaml"</span></span><br><span class="line"><span class="comment">## this kubectl will refer KUBECONFIG env variable above</span></span><br><span class="line">cmd = [<span class="string">"kubectl"</span>, <span class="string">"get"</span>, <span class="string">"sts"</span>]</span><br><span class="line">process = subprocess.Popen(cmd, </span><br><span class="line">                 env=env, </span><br><span class="line">                 stdout=subprocess.PIPE, </span><br><span class="line">                 stderr=subprocess.PIPE)</span><br><span class="line"></span><br><span class="line"><span class="comment">## out, err is byte type</span></span><br><span class="line">out, err = process.communicate()</span><br><span class="line"><span class="comment">## conver to string</span></span><br><span class="line">out = out.decode(<span class="string">"utf-8"</span>)</span><br><span class="line">err = err.decode(<span class="string">"utf-8"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> process.returncode != <span class="number">0</span>:</span><br><span class="line">  <span class="keyword">raise</span> subprocess.CalledProcessError(process.returncode, cmd)</span><br></pre></td></tr></table></figure>
<p>关于python concurrency专门的总结: <code>Python Concurrency</code></p>
<h1 id="String-Manipulation"><a href="#String-Manipulation" class="headerlink" title="String Manipulation"></a>String Manipulation</h1><p>Besides basic operation, it talks about datetime:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="comment">## depends on your local time zone</span></span><br><span class="line">rightnow = datetime.datetime.now()</span><br><span class="line">utc_rightnow = datetime.datetime.utcnow()</span><br><span class="line"></span><br><span class="line">rightnow.month</span><br><span class="line">rightnow.hour</span><br><span class="line"></span><br><span class="line"><span class="comment">## lots of % format</span></span><br><span class="line">rightnow.strftime(<span class="string">"Today is %A"</span>)</span><br><span class="line"><span class="comment">## datetime.timedelta, to add and decrease time slot</span></span><br></pre></td></tr></table></figure></p>
<p>然后讲了<code>re</code> module. 可以参考这节的git code.</p>
<h1 id="Processing-Text-Logging"><a href="#Processing-Text-Logging" class="headerlink" title="Processing Text, Logging"></a>Processing Text, Logging</h1><p>For long running background service, logging is a must, we can log events into: file, syslog or systemd journal.</p>
<p>Logger has different handlers, for example: StreamHandler(stdout, stderr), FileHanlder, watchFileHandler, SysLogHandler, SockerHandler, JournalHandler, etc.</p>
<p>Logging levels: NOTSET, DEBUG, INFO, WARNING, ERROR, CRITICAL.</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>Python3 Package</title>
    <url>/2020/11/08/python-package/</url>
    <content><![CDATA[<p>最近在做Project的时候发现一个package无法在jump box之外的机器上通过pip安装，后来发现这是一个内部开发的python package， 并且为jump box的pip做了设置，加入了内部的package repo。关于package 的创建和发布还不是很了解，这里专门总结一下。<br><a href="https://packaging.python.org/" target="_blank" rel="noopener">Python Packaging User Guide</a></p>
<h1 id="Package-and-Module"><a href="#Package-and-Module" class="headerlink" title="Package and Module"></a>Package and Module</h1><p>Packages contains modules (module is normally a single python source file) or other packages.<br>Modules also are objects with special attributes.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## urllib is package because it contains other modules or packages</span></span><br><span class="line"><span class="comment">## request is a nested module </span></span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"></span><br><span class="line"><span class="comment">## although both are marked as module type</span></span><br><span class="line">type(urllib)</span><br><span class="line">type(urllib.request)</span><br><span class="line"></span><br><span class="line"><span class="comment">## show you the package location</span></span><br><span class="line">urllib.__path__</span><br><span class="line"><span class="comment">## error, because only package has this attribute</span></span><br><span class="line">urllib.request.__path__</span><br></pre></td></tr></table></figure>
<p>How does python know where to import?<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="comment">## for system built-in modules</span></span><br><span class="line">sys.path</span><br><span class="line"><span class="comment">## you can manipulate on it </span></span><br><span class="line">sys.path.append(<span class="string">"&lt;path&gt;"</span>)</span><br></pre></td></tr></table></figure></p>
<p>Or specify in environment variable (see <code>python --help</code>):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## will append to sys.path</span></span><br><span class="line"><span class="built_in">export</span> PYTHONPATH=path1:path2:path3</span><br></pre></td></tr></table></figure></p>
<h1 id="Package-Structure"><a href="#Package-Structure" class="headerlink" title="Package Structure"></a>Package Structure</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">package/:</span><br><span class="line">  |     <span class="comment">## init usually is empty, &gt; 3.3 version, it is optional</span></span><br><span class="line">  |     <span class="comment">## but explicitly have it is good </span></span><br><span class="line">  |---  __init__.py</span><br><span class="line">  |---  module1.py</span><br><span class="line">  |---  module2.py</span><br><span class="line">  |</span><br><span class="line">  |--- subpackage1/</span><br><span class="line">  |      |</span><br><span class="line">  |      |--- __init__.py</span><br><span class="line">  |      |--- module3.py</span><br><span class="line">  |</span><br><span class="line">  |--- subpackage2/</span><br><span class="line">          |</span><br><span class="line">          |--- __init__.py</span><br><span class="line">          |--- module4.py</span><br></pre></td></tr></table></figure>
<p>When import package, <code>__init__.py</code> will be executed if it has contents, so you can have init code here.<br>module1.py and modul2.py are normal python source files, subpackage1 and subpackage2 are nested packages that has its own module. module1.py can import subpackage1 resources, and so on.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## absolute imports</span></span><br><span class="line"><span class="keyword">import</span> package</span><br><span class="line"><span class="keyword">import</span> package.module1</span><br><span class="line"><span class="keyword">from</span> package <span class="keyword">import</span> module2</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> package.subpackage1</span><br><span class="line"><span class="keyword">from</span> package.subpackage1 <span class="keyword">import</span> module3</span><br><span class="line"></span><br><span class="line"><span class="comment">## relative imports</span></span><br><span class="line"><span class="comment">## for example, in module3 it wants to use something in module4</span></span><br><span class="line"><span class="comment">## .. the same meaning in bash `cd` command</span></span><br><span class="line"><span class="keyword">from</span> ..subpackage2 <span class="keyword">import</span> module4</span><br><span class="line"></span><br><span class="line"><span class="comment">## other forms</span></span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> sth</span><br><span class="line"><span class="keyword">from</span> .. <span class="keyword">import</span> sth</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note that relative import can only be used to import modules within the current top-level package and can only in the form if <code>from ... import</code>.</p>
</blockquote>
<p>Sometimes you will see <code>__all__</code> in <code>__init__.py</code>, it control the public objects you can use when <code>from .. import *</code>. If you want to import other modules or packages manually, it is fine.</p>
<h1 id="Namespace-Package"><a href="#Namespace-Package" class="headerlink" title="Namespace Package"></a>Namespace Package</h1><p>For splitting a single python package across multiple directories on disk.<br>Namespace package may not have <code>__init__.py</code>.</p>
<p>For example, split package1 to different path: path1 and path2, 注意这里package1 top-level 没有<code>__init__.py</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">path1/</span><br><span class="line">  |</span><br><span class="line">  |--- package1/</span><br><span class="line">         |</span><br><span class="line">         |--- module1.py</span><br><span class="line">         |--- <span class="comment">## other packages</span></span><br><span class="line">       </span><br><span class="line">path2/</span><br><span class="line">  |</span><br><span class="line">  |--- package1/</span><br><span class="line">         |</span><br><span class="line">         |--- module2.py</span><br><span class="line">         |--- <span class="comment">## other packages</span></span><br></pre></td></tr></table></figure></p>
<p>When import:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="comment">## must include both paths</span></span><br><span class="line">sys.path.extend()[<span class="string">'path1'</span>, <span class="string">'path2'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> package</span><br><span class="line"><span class="comment">## you will see 2 paths</span></span><br><span class="line">package.__path__</span><br><span class="line"><span class="keyword">import</span> package.module1</span><br><span class="line"><span class="keyword">import</span> package.module2</span><br></pre></td></tr></table></figure></p>
<h1 id="Executable-Directory"><a href="#Executable-Directory" class="headerlink" title="Executable Directory"></a>Executable Directory</h1><p>You can execute a directory if it contains <code>__main__.py</code>, then you can zip the directory and run the zip file.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">directory/</span><br><span class="line">  |</span><br><span class="line">  |--- __main__.py</span><br><span class="line">  |--- <span class="comment">## other modules or packages</span></span><br></pre></td></tr></table></figure></p>
<p>注意directory 没有<code>__init__.py</code>，它不是一个package.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## it will run __main__.py</span></span><br><span class="line">python directory</span><br><span class="line"></span><br><span class="line"><span class="comment">## zip it</span></span><br><span class="line"><span class="built_in">cd</span> directory</span><br><span class="line">python -m zipfile -c ../directory.zip *</span><br><span class="line"><span class="comment">## run it</span></span><br><span class="line">python directory.zip</span><br></pre></td></tr></table></figure>
<p>这就相当于打包了一个executable，别人使用时就不需要安装其他依赖了。</p>
<h1 id="Executable-Package"><a href="#Executable-Package" class="headerlink" title="Executable Package"></a>Executable Package</h1><p>if you want to execute a package, also need to adds <code>__main__.py</code>, you cannot use <code>__init__.py</code> since it is only executed when import.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">package/</span><br><span class="line">  |    <span class="comment">## you can wrap the function here</span></span><br><span class="line">  |--- __main__.py</span><br><span class="line">  |--- __init__.py</span><br><span class="line">  |--- <span class="comment">## other modules or packages</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## run it, arguments will be read by __main__.py</span></span><br><span class="line">python -m package &lt;arguments&gt;</span><br></pre></td></tr></table></figure>
<h1 id="Package-Layout"><a href="#Package-Layout" class="headerlink" title="Package Layout"></a>Package Layout</h1><p>This is the recommended structure:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">project_name/</span><br><span class="line">  |</span><br><span class="line">  |--- REAMDME.rst</span><br><span class="line">  |--- doc/</span><br><span class="line">  |--- src/</span><br><span class="line">  |     |    <span class="comment">## package is here</span></span><br><span class="line">  |     |--- package/</span><br><span class="line">  |    <span class="comment">## unit test code</span></span><br><span class="line">  |--- tests/</span><br><span class="line">  |      |</span><br><span class="line">  |      |--- test_code.py</span><br><span class="line">  |    <span class="comment">## use setuptolls package</span></span><br><span class="line">  |--- setup.py</span><br><span class="line">  |    <span class="comment">## see later discussion</span></span><br><span class="line">  |--- tox.ini</span><br></pre></td></tr></table></figure></p>
<p>The <code>setup.py</code> for example:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> setuptools</span><br><span class="line"></span><br><span class="line">setuptools.setup(</span><br><span class="line">    name=<span class="string">"&lt;package name&gt;"</span>,</span><br><span class="line">    version=<span class="string">"&lt;version number&gt;"</span>,</span><br><span class="line">    author=<span class="string">"chengdol"</span>,</span><br><span class="line">    author_email=<span class="string">"chengdol@xxx.com"</span>,</span><br><span class="line">    description=<span class="string">"..."</span>,</span><br><span class="line">    url=<span class="string">"&lt;package access url&gt;"</span>,</span><br><span class="line">    packages=setuptools.find_packages(<span class="string">'src'</span>),</span><br><span class="line">    package_dir=&#123;<span class="string">''</span>: <span class="string">'src'</span>&#125;,</span><br><span class="line">    classifiers=[</span><br><span class="line">        <span class="string">"Programming Language :: Python :: 3"</span>,</span><br><span class="line">        <span class="string">"License :: OSI Approved :: MIT License"</span>,</span><br><span class="line">        <span class="string">"Operating System :: OS Independent"</span>,</span><br><span class="line">    ],</span><br><span class="line">    install_requires=[<span class="string">'Flask==3.0.0'</span>, <span class="string">'pysocks'</span>, <span class="string">'pyyaml'</span>],</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p>
<p>关于<code>tox</code>, 是一个方便自动化测试的工具:<br><a href="https://tox.readthedocs.io/en/latest/" target="_blank" rel="noopener">tox</a>: Automate and standardize testing in Python.</p>
<p>后面讲了plugins的实现 via setuptools or namespace packages. 目前没用到。</p>
<h1 id="Package-Distribution"><a href="#Package-Distribution" class="headerlink" title="Package Distribution"></a>Package Distribution</h1><p>When you create a virtualenv, there are pip, wheel and setuptools installed already.</p>
<p>There are <code>source</code> and <code>built</code> distrubutions, <code>built</code> package can place directly into installation directory and can be platform-specific, it is a <code>.whl</code> file. <code>source</code> package is tar.gz file, need to build before installing it. If you run <code>pip download</code>, you will see these distribution files.</p>
<p>For <code>source</code> package:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> package</span><br><span class="line">python setup.py sdist</span><br><span class="line"></span><br><span class="line"><span class="comment">## you will see a xxx.tar.gz file</span></span><br><span class="line"><span class="built_in">cd</span> dist</span><br><span class="line">pip install xxx.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>For <code>built</code> package:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> package</span><br><span class="line">python setup.py bdist_wheel</span><br><span class="line"></span><br><span class="line"><span class="comment">## you will see a xx-py3-none-any.whl file</span></span><br><span class="line"><span class="built_in">cd</span> dist</span><br><span class="line"><span class="comment">## py3: python 3</span></span><br><span class="line"><span class="comment">## none: ABI requiremens, work with other language</span></span><br><span class="line"><span class="comment">## any: platform specifc</span></span><br><span class="line">pip install xx-none-any.whl</span><br></pre></td></tr></table></figure></p>
<p>Reading about what is <code>wheel</code>:<br><a href="https://realpython.com/python-wheels/" target="_blank" rel="noopener">https://realpython.com/python-wheels/</a><br>A Python <code>.whl</code> file is essentially a ZIP (.zip) archive with a specially crafted filename that tells installers what Python versions and platforms the wheel will support.</p>
<p>A wheel is a type of <code>built</code> distribution. In this case, built means that the wheel comes in a ready-to-install format and allows you to skip the build stage required with source distributions.</p>
<p>Then you register account on PyPI and upload the package:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install twine</span></span><br><span class="line">python -m pip install --user --upgrade twine</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> package</span><br><span class="line">python setup.py sdist bdist_wheel &amp;&amp; \</span><br><span class="line">          twine upload dist/* -u <span class="variable">$&#123;USER_NAME&#125;</span> -p <span class="variable">$&#123;PASSWORD&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## or upload to your personal repo</span></span><br><span class="line">twine upload  --repository-url <span class="variable">$&#123;PACKAGES_REPO&#125;</span> dist/* -u <span class="variable">$&#123;USER_NAME&#125;</span> -p <span class="variable">$&#123;PASSWORD&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>Tools used:<br><a href="https://twine.readthedocs.io/en/latest/" target="_blank" rel="noopener">twine</a>: Twine is a utility for publishing Python packages on PyPI.</p>
<p>After uploading you can use pip install the paclage in your new virtual environment.</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python3</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Simple Http(s) Server</title>
    <url>/2020/09/02/python-simpleHttpServer/</url>
    <content><![CDATA[<p>最近为了在局域网中传输文件，用Python搭建了一个很简单的<a href="https://docs.python.org/3/library/http.server.html" target="_blank" rel="noopener">HTTP web server to serve files</a>, 其实有其他软件也可以完成类似功能，甚至scp command也行。不过这个简单的HTTP web server里面的文件结构一目了然，下载非常方便。</p>
<p>后续还可以添加basic auth service, 甚至SSL/TLS support, 作为其他服务的测试工具。</p>
<p>How to:</p>
<ol>
<li>用<code>virtualenvwrapper</code> 先搭建一个python3 项目和对应的环境。</li>
<li>激活环境后, 写一个shell script，输出运行时的网址和端口</li>
</ol>
<p>比如在Mac中，使用如下脚本:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## use 8000 as port number</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$(ifconfig | grep -A 10 ^en0 | grep inet | grep -v inet6 | cut -d" " -f2)</span>"</span>:8000</span><br><span class="line"><span class="comment">## http.server module</span></span><br><span class="line"><span class="comment">## port number: 8000</span></span><br><span class="line"><span class="comment">## --directory: old version python may not support this option</span></span><br><span class="line">python3 -m http.server 8000 --<span class="built_in">bind</span> 0.0.0.0 --directory &lt;absolute path to share folder&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Basic-Auth"><a href="#Basic-Auth" class="headerlink" title="Basic Auth"></a>Basic Auth</h2><p><a href="https://gist.github.com/fxsjy/5465353" target="_blank" rel="noopener">https://gist.github.com/fxsjy/5465353</a><br>You can package it in container or run on virtualenv.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## works on python2</span></span><br><span class="line"><span class="comment">## port: 8080</span></span><br><span class="line"><span class="comment">## auth: user:password</span></span><br><span class="line">python2 -m main.py 8080 chengdol:123456</span><br></pre></td></tr></table></figure></p>
<p>This script is modified and integrate to below pip module.</p>
<h2 id="HTTPS-Basic-Auth"><a href="#HTTPS-Basic-Auth" class="headerlink" title="HTTPS Basic Auth"></a>HTTPS Basic Auth</h2><p><a href="https://github.com/tianhuil/SimpleHTTPAuthServer" target="_blank" rel="noopener">https://github.com/tianhuil/SimpleHTTPAuthServer</a><br>You can run the pip in python2 virtualenv or build a docker container.</p>
<p>Modify to build a image with https auth server, for example:<br><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment">## works on python2</span></span><br><span class="line"><span class="keyword">FROM</span> python:<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /usr/src/app</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">USER root</span></span><br><span class="line"><span class="bash"><span class="comment">## pip install</span></span></span><br><span class="line"><span class="bash">RUN pip install SimpleHTTPAuthServer</span></span><br><span class="line"><span class="bash"><span class="comment">## to setup self-signed certificate, need to pre-generated key and cert</span></span></span><br><span class="line"><span class="bash">RUN mkdir -p /root/.ssh</span></span><br><span class="line"><span class="bash">RUN openssl req \</span></span><br><span class="line"><span class="bash">    -newkey rsa:2048 -new -nodes -x509 -days 3650 \</span></span><br><span class="line"><span class="bash">    -keyout /root/.ssh/key.pem -out /root/.ssh/cert.pem \</span></span><br><span class="line"><span class="bash">    -subj <span class="string">"/C=US/ST=CA/L=San Jose/O=GOOG/OU=Org/CN=localhost"</span></span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment">## copy other files to WORKDIR</span></span></span><br><span class="line"><span class="bash">COPY file.txt .</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">EXPOSE 8080</span></span><br><span class="line"><span class="bash"><span class="comment">## start with https</span></span></span><br><span class="line"><span class="bash">CMD [<span class="string">"python"</span>, <span class="string">"-m"</span>, <span class="string">"SimpleHTTPAuthServer"</span>, <span class="string">"8080"</span>, <span class="string">"chengdol:123456"</span>, <span class="string">"--https"</span>]</span></span><br></pre></td></tr></table></figure></p>
<p>Then go to firefox, type and hit <code>https://localhost:8080</code>.</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>server</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Unit Test</title>
    <url>/2020/10/03/python-unit-test/</url>
    <content><![CDATA[<p>Unit test when and why:</p>
<ul>
<li>help you understand what to develop from the test case.</li>
<li>help you better to design the code structure, API or functions.</li>
<li>help you to detect regression, pinpoint failures.</li>
</ul>
<p>The unit test should be put in CI pipeline for every new merge request, just like gitlab-ci does.</p>
<h1 id="Unittest"><a href="#Unittest" class="headerlink" title="Unittest"></a>Unittest</h1><p><a href="https://docs.python.org/3.8/library/unittest.html" target="_blank" rel="noopener">https://docs.python.org/3.8/library/unittest.html</a><br>The test file name should be <code>test_xxx.py</code>.</p>
<p>The test method name must be <code>def test_&lt;test case name&gt;(self)</code>. The test case name should be very specific and focus on a particular scenario. Don’t put everything together.</p>
<p>Parent methods <code>setUp</code>, <code>tearDown</code> run for every test method. <code>tearDown</code> will still be run even if the test case failed. 一般来说不需要<code>tearDown</code> 因为对于strict test case 没有使用外界的资源。</p>
<p>Decorator <a href="mailto:`@unittest.skip" target="_blank" rel="noopener">`@unittest.skip</a>(“WIP”)<code>, will skip the test case.</code>WIP` stands for working in progress, more<br>decorators see:<br><a href="https://docs.python.org/3.8/library/unittest.html#skipping-tests-and-expected-failures" target="_blank" rel="noopener">https://docs.python.org/3.8/library/unittest.html#skipping-tests-and-expected-failures</a></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> unittest</span><br><span class="line"><span class="comment">## from &lt;py file name&gt; import &lt;class or some functions&gt;</span></span><br><span class="line"><span class="keyword">from</span> phonebook <span class="keyword">import</span> PhoneBook</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PhoneBookTest</span><span class="params">(unittest.TestCase)</span>:</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">## up to you use or not</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">setUp</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.phonebook = PhoneBook()</span><br><span class="line"></span><br><span class="line">  <span class="comment">## test basic function</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">test_lookup_by_name</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.phonebook.add(<span class="string">"Bob"</span>, <span class="string">"123456"</span>)</span><br><span class="line">    number = self.phonebook.lookup(<span class="string">"Bob"</span>)</span><br><span class="line">    self.assertEqual(<span class="string">"123456"</span>, number)</span><br><span class="line"></span><br><span class="line">  <span class="comment">## check exception</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">test_missing_name</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> self.assertRaises(KeyError):</span><br><span class="line">      self.phonebook.lookup(<span class="string">"missing"</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">## skip this test</span></span><br><span class="line"><span class="meta">  @unittest.skip("WIP")</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">test_duplicate_name</span><span class="params">(self)</span>:</span></span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>For more assert methods, see:<br><a href="https://docs.python.org/3.8/library/unittest.html#assert-methods" target="_blank" rel="noopener">https://docs.python.org/3.8/library/unittest.html#assert-methods</a></p>
<p>To start test in command line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## help</span></span><br><span class="line">python -m unittest -h</span><br><span class="line"></span><br><span class="line"><span class="comment">## start unit test with specific python version</span></span><br><span class="line"><span class="comment">## run all tests</span></span><br><span class="line">python3 -m unittest</span><br><span class="line"></span><br><span class="line"><span class="comment">## can run tests from modules, classes or individual test method:</span></span><br><span class="line">python -m unittest test_module1 test_module2</span><br><span class="line">python -m unittest test_module.TestClass</span><br><span class="line">python -m unittest test_module.TestClass.test_method</span><br></pre></td></tr></table></figure></p>
<h1 id="Pyest"><a href="#Pyest" class="headerlink" title="Pyest"></a>Pyest</h1><p>More native to python, use pip to install pytest module.<br><a href="https://docs.pytest.org/en/stable/" target="_blank" rel="noopener">https://docs.pytest.org/en/stable/</a><br>Other pytest plugins:</p>
<ul>
<li>pytest-html</li>
</ul>
<p>The test file name should be <code>test_xxx.py</code> and the test case name is <code>def test_xxx()</code>, the same as unittest conventions. No wrapping class is needed.</p>
<p>pytest 有一些已经定义好的fixture 可以直接使用, 类似于依赖注入:<br><a href="https://docs.pytest.org/en/stable/fixture.html#fixture" target="_blank" rel="noopener">https://docs.pytest.org/en/stable/fixture.html#fixture</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># shows builtin and custom fixtures</span></span><br><span class="line">pytest --fixtures</span><br></pre></td></tr></table></figure></p>
<p>目前用到的是很基本的，还有很多很强大的功能，比如 <code>pytest.ini</code>的配置，marker的定义和使用等，比如，定义了marker <code>slow</code> 用在test case上 <a href="mailto:**@pytest.mark.slow" target="_blank" rel="noopener">**@pytest.mark.slow</a>** 则在运行的时候可以在命令行上根据option 跳过所有被标记为slow的test cases: <code>python3 -m pytest &quot;not slow&quot;</code>.<br>Built-in marks:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list built-in markers</span></span><br><span class="line">pytest --markers</span><br><span class="line"></span><br><span class="line"><span class="comment">## 类似@unittest.skip("WIP")</span></span><br><span class="line">@pytest.mark.skip(reason=None)</span><br><span class="line">@pytest.mark.skipif(condition, ..., *, reason=...)</span><br></pre></td></tr></table></figure></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pytest</span><br><span class="line"><span class="comment">## from &lt;py file name&gt; import &lt;class or some functions&gt;</span></span><br><span class="line"><span class="keyword">from</span> phonebook <span class="keyword">import</span> PhoneBook</span><br><span class="line"></span><br><span class="line"><span class="comment">## phonebook 这个名字必须和使用它的一样</span></span><br><span class="line"><span class="comment">## 类似于unittest setUp</span></span><br><span class="line"><span class="meta">@pytest.fixture</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">phonebook</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="keyword">return</span> PhoneBook()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## phonebook 这个名字必须和使用它的一样</span></span><br><span class="line"><span class="comment">## 这里把setUp 和 tearDown 合在一起了</span></span><br><span class="line"><span class="meta">@pytest.fixture</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">phonebook</span><span class="params">()</span>:</span></span><br><span class="line">  phonebook = PhoneBook()</span><br><span class="line">  <span class="keyword">yield</span>  PhoneBook()</span><br><span class="line">  phonebook.clear()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 这里phonebook参数就是来自上面定义的 pytest fixture</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_lookup_name</span><span class="params">(phonebook)</span>:</span></span><br><span class="line">  phonebook.add(<span class="string">"Bob"</span>, <span class="string">"123456"</span>)</span><br><span class="line">  <span class="comment">## use native python assertion</span></span><br><span class="line">  <span class="keyword">assert</span> <span class="string">"123456"</span> = phonebook.lookup(<span class="string">"Bob"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_missing_name_raises_error</span><span class="params">(phonebook)</span>:</span></span><br><span class="line">  <span class="comment">## need import pytest</span></span><br><span class="line">  <span class="keyword">with</span> pytest.raises(KeyError):</span><br><span class="line">      phonebook.lookup(<span class="string">"Missing"</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">@pytest.mark.skip("WIP")</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_duplicate_name</span><span class="params">()</span>:</span></span><br><span class="line">  <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>
<p>To start test in command line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## start unit test</span></span><br><span class="line">python3 -m pytest</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>unit test</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell Arguments Format</title>
    <url>/2019/09/17/shell-argument-format/</url>
    <content><![CDATA[<p>When I check the <code>cmd</code> and <code>entrypoint</code> of one image, I see something like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cmd: zkServer.sh start-foreground</span><br><span class="line">entrypoint: /docker-entrypoint.sh</span><br></pre></td></tr></table></figure></p>
<p>That means <code>cmd</code> part will be passed into entrypoint as argument, let’s see what is inside <code>/docker-entrypoint.sh</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Generate Zookeeper configuration</span></span><br><span class="line">[ <span class="string">"<span class="variable">$1</span>"</span> = <span class="string">'zkServer.sh'</span> ] &amp;&amp; (zkGenConfig.sh || <span class="built_in">exit</span> 1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">exec</span> <span class="string">"<span class="variable">$@</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>It just like a wrapper and executes the passed parameters as a new command. This pattern gives me some inspirations.</p>
<p>About <code>$@</code>, reference from <a href="https://stackoverflow.com/questions/9994295/what-does-mean-in-a-shell-script" target="_blank" rel="noopener">https://stackoverflow.com/questions/9994295/what-does-mean-in-a-shell-script</a>:<br><code>$@</code> is nearly the same as <code>$*</code>, both meaning “all command line arguments”. They are often used to simply pass all arguments to another program (thus forming a wrapper around that other program).</p>
<p>The difference between the two syntaxes shows up when you have an argument with spaces in it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wrappedProgram <span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line"><span class="comment"># ^^^ this is correct and will hand over all arguments in the way</span></span><br><span class="line"><span class="comment">#     we received them, i. e. as several arguments, each of them</span></span><br><span class="line"><span class="comment">#     containing all the spaces and other uglinesses they have.</span></span><br><span class="line">wrappedProgram <span class="string">"$*"</span></span><br><span class="line"><span class="comment"># ^^^ this will hand over exactly one argument, containing all</span></span><br><span class="line"><span class="comment">#     original arguments, separated by single spaces.</span></span><br><span class="line">wrappedProgram $*</span><br><span class="line"><span class="comment"># ^^^ this will join all arguments by single spaces as well and</span></span><br><span class="line"><span class="comment">#     will then split the string as the shell does on the command</span></span><br><span class="line"><span class="comment">#     line, thus it will split an argument containing spaces into</span></span><br><span class="line"><span class="comment">#     several arguments.</span></span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wrapper &quot;one two    three&quot; four five &quot;six seven&quot;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;$@&quot;: wrappedProgram &quot;one two    three&quot; four five &quot;six seven&quot;</span><br><span class="line">&quot;$*&quot;: wrappedProgram &quot;one two    three four five six seven&quot;</span><br><span class="line">                             ^^^^ These spaces are part of the first</span><br><span class="line">                                  argument and are not changed.</span><br><span class="line">$*:   wrappedProgram one two three four five six seven</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Python Packages and Virtual Environment</title>
    <url>/2020/08/22/python-virtual-environment/</url>
    <content><![CDATA[<p>//TODO<br>[ ] pip package name convention and import name convention, e.g PyYaml but import yaml, pip install [name]?<br>[x] pip internal config, repo</p>
<p>To use and manage third-party libraries without messing up python environment, organizing different project that has its own unique dependencies:</p>
<ul>
<li><code>pip</code>: package management</li>
<li><code>virtualenv</code>: project and dependencies</li>
<li><code>virtualenvwrapper</code>: making venv more convenient</li>
</ul>
<p>Does not talk the package that is the form of <code>__init__.py</code> under a folder, we are talking python distribution package.</p>
<h1 id="PIP"><a href="#PIP" class="headerlink" title="PIP"></a>PIP</h1><p><strong>Best practice:</strong></p>
<ol>
<li>always work inside a virtual environment, keep things nice and clean.</li>
<li>don’t use pip with <code>sudo</code>, otherwise the installation is system-wide.</li>
</ol>
<p>Mac’s pre-installed Python is not meant for development, you can use <code>Homebrew</code> to install or download Python from python.org, that will go along with <code>pip</code>. For Linux, adhere to system manager to install pip or python. In Mac, try check if <code>pip</code> is there and it’s version.</p>
<p>For example, on some Linux, python3 has pip3 already but python2 may not have corresponding pip2, please do this command in virtual environment, see below:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## search pip2 or pip3 package</span></span><br><span class="line">sudo yum search python* | grep pip</span><br><span class="line"><span class="comment">## install pip</span></span><br><span class="line">sudo yum install -y &lt;pip package&gt;</span><br><span class="line"></span><br><span class="line">pip3 -V</span><br><span class="line">pip 9.0.3 from /usr/lib/python3.6/site-packages (python 3.6)</span><br><span class="line"></span><br><span class="line">pip2 -V</span><br><span class="line">pip 9.0.3 from /usr/lib/python2.7/site-packages (python 2.7)</span><br></pre></td></tr></table></figure></p>
<p><code>pip</code> commonly use commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## local or global config info</span></span><br><span class="line"><span class="comment">## you will see the package repo</span></span><br><span class="line">pip3 config [debug, edit, get, list, <span class="built_in">set</span>, <span class="built_in">unset</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## search</span></span><br><span class="line">pip3 search &lt;package name&gt;</span><br><span class="line"><span class="comment">## download package in current dir</span></span><br><span class="line">pip3 download &lt;package name&gt;</span><br><span class="line"><span class="comment">## will auto install other dependencies</span></span><br><span class="line">pip3 install &lt;package name&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## list packages installed</span></span><br><span class="line">pip3 list</span><br><span class="line"><span class="comment">## show outdate packages</span></span><br><span class="line">pip3 list -o</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## uninstall</span></span><br><span class="line"><span class="comment">## will not uninstall its dependencies</span></span><br><span class="line">pip3 uninstall &lt;package name&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## show package info</span></span><br><span class="line"><span class="comment">## you will see the location where the package is installed</span></span><br><span class="line"><span class="comment">## and its source code url</span></span><br><span class="line">pip3 show &lt;package name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## seek help</span></span><br><span class="line">pip3 <span class="built_in">help</span></span><br></pre></td></tr></table></figure></p>
<p><code>pip</code> is actually fetching packages from Python package index (or your own package repo)<br><a href="https://pypi.org/" target="_blank" rel="noopener">https://pypi.org/</a></p>
<p>How to work:</p>
<ol>
<li>search key work directly.</li>
<li>go to Browse projects -&gt; Operating system -&gt; Linux, then select other classifier (but this is still hard to search what is exactly needed).</li>
<li>check <code>development status</code>, select package in production/stable version.</li>
</ol>
<p>Pip install from specified repo:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## use additional repo</span></span><br><span class="line">pip install --extra-index-url <span class="string">'&lt;repo url&gt;'</span> vault-client==0.0.4</span><br><span class="line"></span><br><span class="line"><span class="comment">## or set by</span></span><br><span class="line"><span class="comment">## pip config set &lt;ket&gt; &lt;value&gt;</span></span><br><span class="line">global.extra-index-url=<span class="string">'&lt;repo url&gt;'</span></span><br><span class="line">global.timeout=<span class="string">'10'</span></span><br><span class="line">global.trusted-host=<span class="string">'registry.corp.xxx.com'</span></span><br><span class="line"><span class="comment">## then run</span></span><br><span class="line">pip install vault-client==0.0.4</span><br><span class="line"></span><br><span class="line"><span class="comment">## 或者创建一个~/.pip/pip.conf 文件</span></span><br><span class="line">[global]</span><br><span class="line">timeout=10</span><br><span class="line">trusted-host = egistry.corp.xxx.com</span><br><span class="line">extra-index-url = &lt;repo url&gt;</span><br><span class="line"><span class="comment">## 然后</span></span><br><span class="line">pip install --no-cache-dir vault-client==0.0.4</span><br></pre></td></tr></table></figure></p>
<h1 id="Virtual-Environment"><a href="#Virtual-Environment" class="headerlink" title="Virtual Environment"></a>Virtual Environment</h1><p>Combining with <code>virtualenvwrapper</code> is good, recommended.</p>
<p>Install <code>virtualenv</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install system-widely</span></span><br><span class="line"><span class="comment">## preferred way</span></span><br><span class="line"><span class="comment">## -m: run module</span></span><br><span class="line">sudo python3 -m pip install virtualenv</span><br><span class="line">sudo pip3 install virtualenv</span><br></pre></td></tr></table></figure></p>
<p>Create virtualenv:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir ~/virtualenvs &amp;&amp; <span class="built_in">cd</span> ~/virtualenvs</span><br><span class="line"></span><br><span class="line"><span class="comment">## create a virtual env called rates in python3</span></span><br><span class="line">virtualenv -p python3 rates_py3</span><br><span class="line">virtualenv -p python3.8.4 rates_py3</span><br><span class="line"><span class="comment">## python2 based</span></span><br><span class="line">virtualenv -p python2 rates_py2</span><br><span class="line"></span><br><span class="line"><span class="comment">## activate</span></span><br><span class="line"><span class="built_in">cd</span> rates_py3</span><br><span class="line"><span class="comment">## after this you will see a prefix </span></span><br><span class="line"><span class="comment">## 一旦激活，不管在其他任何地方，都是这个环境！</span></span><br><span class="line">. ./bin/activate</span><br><span class="line"><span class="comment">## check</span></span><br><span class="line">python -V</span><br><span class="line">pip -V</span><br><span class="line"><span class="comment">## you will only see less packages installed</span></span><br><span class="line">pip list</span><br><span class="line"></span><br><span class="line"><span class="comment">## then start your work in your project folder...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## deactivate</span></span><br><span class="line">deactivate</span><br></pre></td></tr></table></figure></p>
<p>Other similar tool, this venv may pre-installed or need to pip install globally:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## python &gt;= 3.3, may popular in furture</span></span><br><span class="line">python3 -m venv &lt;virtual env name&gt;</span><br></pre></td></tr></table></figure></p>
<p>Syncing packages with colleagues, put this requirement file in version control to share and update:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## fist activate the virtual environment</span></span><br><span class="line"><span class="comment">## package list</span></span><br><span class="line">python -m pip freeze &gt; requirements.txt</span><br><span class="line"><span class="comment">## the condition can be ==, !=, &gt;=, &lt;=</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## create another virtual environment with the same python verion like yours</span></span><br><span class="line"><span class="comment">## activeate this new environment</span></span><br><span class="line"><span class="comment">## then run</span></span><br><span class="line">python -m pip install -r requirements.txt</span><br></pre></td></tr></table></figure></p>
<p>You can specify version in pip install:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">pip install flask==<span class="number">1.0</span><span class="number">.0</span></span><br><span class="line">pip install <span class="string">'Django&lt;2.0'</span></span><br><span class="line"><span class="comment">## upgrade to latest version</span></span><br><span class="line">pip install -U flask</span><br><span class="line"></span><br><span class="line"><span class="comment">## upgrade pip</span></span><br><span class="line"><span class="comment">## take care not to overwrite system pip using sudo</span></span><br><span class="line">pip install -U pip</span><br></pre></td></tr></table></figure></p>
<p><strong>How to manage the project and virtual environment?</strong><br>Separating project with virtual environment! 放在不同的文件夹中，使用时激活就行了，一般一个venv对应一个project, 但如果要测试多个不同的环境，也可以多个venvs map to one project.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--dev</span><br><span class="line">|  |-----my_game</span><br><span class="line">|  |-----my_website</span><br><span class="line">|</span><br><span class="line">--virtual environment</span><br><span class="line">   |-----my_game</span><br><span class="line">   |-----my_website</span><br></pre></td></tr></table></figure></p>
<p>Real-world example, when develop flask framework, use <code>setup.py</code> with <code>editable</code> pip to install packages in virtual environment, so you can edit the flask source code and it will reflect in real-time:<br><a href="https://stackoverflow.com/questions/35064426/when-would-the-e-editable-option-be-useful-with-pip-install" target="_blank" rel="noopener">When would the -e, –editable option be useful with pip install?</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/pallets/flask</span><br><span class="line"></span><br><span class="line"><span class="comment">## activate virtual environment</span></span><br><span class="line"><span class="comment">## go to root level of flask directory</span></span><br><span class="line">python -m pip install -e .</span><br></pre></td></tr></table></figure></p>
<p>Now have developing env for flask. </p>
<p>You can also see <code>tox.ini</code> file in flask git repo, it is used for testing against different python versions in different virtual environments.</p>
<h1 id="Virtualenvwrapper"><a href="#Virtualenvwrapper" class="headerlink" title="Virtualenvwrapper"></a>Virtualenvwrapper</h1><p>A user-friently wrapper around virtualenv， easy creation and activation, bind projects to virtualenvs.</p>
<p>Setup:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install system-widely</span></span><br><span class="line">sudo python3 -m pip install virtualenvwrapper</span><br><span class="line">sudo pip3 install virtualenvwrapper</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## get path</span></span><br><span class="line"><span class="built_in">which</span> virtualenvwrapper.sh</span><br><span class="line">/usr/<span class="built_in">local</span>/bin/virtualenvwrapper.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">## add below lines to ~/.bashrc</span></span><br><span class="line"><span class="comment">## point virtualenvwrapper to pyhton3 explicitly</span></span><br><span class="line"><span class="built_in">export</span> VIRTUALENVWRAPPER_PYTHON=/usr/bin/python3</span><br><span class="line"><span class="built_in">source</span> /usr/<span class="built_in">local</span>/bin/virtualenvwrapper.sh</span><br><span class="line"><span class="comment">## if you don't want to use default virtual env home</span></span><br><span class="line"><span class="comment">## use absolute path</span></span><br><span class="line"><span class="built_in">export</span> WORKON_HOME=<span class="string">"/home/&lt;user&gt;/virtualenvs"</span></span><br><span class="line"><span class="comment">## set the project homes, when use mkproject will create project folder here</span></span><br><span class="line"><span class="comment">## use absolute path</span></span><br><span class="line"><span class="built_in">export</span> PROJECT_HOME=<span class="string">"/home/&lt;user&gt;/dev"</span></span><br></pre></td></tr></table></figure></p>
<p>Operations:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show virtual environments list</span></span><br><span class="line">workon</span><br><span class="line"></span><br><span class="line"><span class="comment">## enter or switch virtual environment</span></span><br><span class="line">workon &lt;venv name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## will create both venv and project</span></span><br><span class="line"><span class="comment">## if the project is bound with venv, use workon will auto switch to project folder</span></span><br><span class="line">mkproject &lt;pro name&gt;</span><br><span class="line">mkproject -p python3 &lt;pro name&gt;</span><br><span class="line">mkproject -p python2 &lt;pro name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## create a venv only</span></span><br><span class="line">mkvirtualenv &lt;venv name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## for old project does not bind with venv</span></span><br><span class="line"><span class="comment">## activate venv and go to old project folder, run below to bind them</span></span><br><span class="line">setvirtualenvproject </span><br><span class="line"></span><br><span class="line"><span class="comment">## remove a venv</span></span><br><span class="line"><span class="comment">## you need to manually remove project folder is you want</span></span><br><span class="line">rmvirtualenv &lt;venv name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## deactivate venv</span></span><br><span class="line">deactivate</span><br></pre></td></tr></table></figure></p>
<h1 id="Other-Future-Tools"><a href="#Other-Future-Tools" class="headerlink" title="Other Future Tools"></a>Other Future Tools</h1><p>New projects:</p>
<ul>
<li>pipenv: <a href="https://pipenv-fork.readthedocs.io/en/latest/" target="_blank" rel="noopener">https://pipenv-fork.readthedocs.io/en/latest/</a></li>
<li>poetry: <a href="https://python-poetry.org/" target="_blank" rel="noopener">https://python-poetry.org/</a></li>
</ul>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Asynchronous Processes</title>
    <url>/2019/05/29/shell-async-process/</url>
    <content><![CDATA[<p>I feel terrible today since I find a bug in the script I wrote several months ago! </p>
<p>Sometimes when I run some time-consuming tasks I want to make them execute parallelly to improve the CPU utilization and reduce execution time (if the machine is multi-core or multi-processing unit)</p>
<p>Let’s talk about different patterns to do that in shell script, for example, I have scripts:<br><code>back.sh</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">tail -f /dev/null</span><br></pre></td></tr></table></figure></p>
<p><code>hello.sh</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"====== hello"</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure></p>
<h2 id="Wait-for-all-background-tasks"><a href="#Wait-for-all-background-tasks" class="headerlink" title="Wait for all background tasks"></a>Wait for all background tasks</h2><p>In <code>main.sh</code>, if:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">declare</span> -a nums=(1 2 3)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;nums[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  ./hello.sh &amp;</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"###### PID is $!"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">wait</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"done!"</span></span><br></pre></td></tr></table></figure></p>
<p>you will get the result like this, only get <code>done!</code> after all background processes finished:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">###### PID is 11649</span><br><span class="line">###### PID is 11650</span><br><span class="line">###### PID is 11651</span><br><span class="line">====== hello</span><br><span class="line">====== hello</span><br><span class="line">====== hello</span><br><span class="line">done!</span><br></pre></td></tr></table></figure></p>
<p>But if the <code>main.sh</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./back.sh &amp;</span><br><span class="line"><span class="built_in">declare</span> -a nums=(1 2 3)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;nums[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  ./hello.sh &amp;</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"###### PID is $!"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">wait</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"done!"</span></span><br></pre></td></tr></table></figure></p>
<p>The <code>wait</code> will hold on until all background tasks complete, you will never see <code>done!</code> because back.sh will never exit. Have to use <code>kill</code> command to kill it.</p>
<p>The improved way is to only pass related PIDs to wait, so scheduler will not care unrelated background task <code>back.sh</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">declare</span> -a nums=(1 2 3)</span><br><span class="line"><span class="built_in">declare</span> -a pids</span><br><span class="line">./back.sh &amp;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;nums[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  ./hello.sh &amp;</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"###### PID is $!"</span></span><br><span class="line">  pids+=($!)</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">wait</span> <span class="variable">$&#123;pids[@]&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"done!"</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Wait-background-task-in-arbitrary-order"><a href="#Wait-background-task-in-arbitrary-order" class="headerlink" title="Wait background task in arbitrary order"></a>Wait background task in arbitrary order</h2><p>This way is very similar to above example, but we wait individually.</p>
<p>In <code>main.sh</code>, write:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">declare</span> -a nums=(1 2 3)</span><br><span class="line"><span class="built_in">declare</span> -a pids</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;nums[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"> ./hello.sh &amp;</span><br><span class="line"> <span class="built_in">echo</span> <span class="string">"###### PID is $!"</span></span><br><span class="line"> pids[<span class="variable">$&#123;n&#125;</span>]=$! <span class="comment">## pids[n]=$! also works</span></span><br><span class="line"> <span class="built_in">let</span> n+=1</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pid <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;pids[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">wait</span> <span class="variable">$&#123;pid&#125;</span>; <span class="keyword">then</span></span><br><span class="line">    <span class="comment">## success</span></span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="comment">## fail</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"done!"</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that don’t forget the <code>let n+=1</code></p>
</blockquote>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>Acutally there is a <code>jobs</code> command can deal with the background processes:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ./back.sh  &amp;</span></span><br><span class="line">[1] 15405</span><br><span class="line"><span class="comment"># jobs</span></span><br><span class="line">[1]+  Running                 ./back.sh &amp;</span><br><span class="line"><span class="comment"># jobs -p</span></span><br><span class="line">15405</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Array in Script</title>
    <url>/2019/08/13/shell-array/</url>
    <content><![CDATA[<p>Reference:</p>
<ul>
<li><a href="https://wangdoc.com/bash/array.html" target="_blank" rel="noopener">https://wangdoc.com/bash/array.html</a></li>
</ul>
<p>The first thing to do is to distinguish between bash <code>indexed</code> array and bash <code>associative</code> array. The former are arrays in which the keys are ordered integers, while the latter are arrays in which the keys are represented by strings.</p>
<p>Although indexed arrays can be initialized in many ways, associative ones can <strong>only</strong> be created by using the <code>declare</code> command.</p>
<h1 id="Create-Indexed-Array"><a href="#Create-Indexed-Array" class="headerlink" title="Create Indexed Array"></a>Create Indexed Array</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create array</span></span><br><span class="line">array=(</span><br><span class="line">  x</span><br><span class="line">  y</span><br><span class="line">  z</span><br><span class="line">)</span><br><span class="line"><span class="comment">## create array via declare</span></span><br><span class="line"><span class="built_in">declare</span> -a array=(x y z) </span><br><span class="line"><span class="comment">## create separately</span></span><br><span class="line"><span class="built_in">declare</span> -a array</span><br><span class="line">array[0]=xx</span><br><span class="line">array[1]=yy</span><br><span class="line">array[2]=zz</span><br><span class="line"></span><br><span class="line"><span class="comment">## print</span></span><br><span class="line"><span class="built_in">declare</span> -p array</span><br><span class="line"><span class="comment">## delete item</span></span><br><span class="line"><span class="built_in">unset</span> array[2]</span><br><span class="line"></span><br><span class="line"><span class="comment">## empty the array</span></span><br><span class="line"><span class="built_in">unset</span> array</span><br></pre></td></tr></table></figure>
<p>Add new element into array:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">array+=(<span class="variable">$&#123;var&#125;</span>)</span><br><span class="line"><span class="comment"># or multi-item</span></span><br><span class="line">array+=(<span class="string">'foo'</span> <span class="string">'cat'</span>)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that in the context where an assignment statement is assigning a value to a <code>shell variable</code> or <code>array</code> index (see Arrays), the <code>+=</code> operator can be used to append to or add to the variable’s previous value.</p>
</blockquote>
<p>Using <code>&quot;${array[@]}&quot;</code>(have double quotes) in for loop to fetch array item.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;array[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$&#123;item&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<p>Or fetch item by index(key):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!array[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="comment"># $&#123;array[i]&#125; also OK</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$&#123;array[$i]&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Create-Associated-Array"><a href="#Create-Associated-Array" class="headerlink" title="Create Associated Array"></a>Create Associated Array</h1><p>Statement <code>declare</code> is the only way to go, see reference for more details. Actually this is <code>Map</code> in shell script.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create all at once</span></span><br><span class="line"><span class="built_in">declare</span> -A array=([a]=xx [b]=yy [c]=zz)</span><br><span class="line"><span class="comment">## create separately</span></span><br><span class="line"><span class="built_in">declare</span> -A array</span><br><span class="line">array[a]=xx</span><br><span class="line">array[b]=yy</span><br><span class="line">array[c]=zz</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">array=([a]=xx [b]=yy [c]=zz)</span><br><span class="line"></span><br><span class="line"><span class="comment">## print</span></span><br><span class="line"><span class="built_in">declare</span> -p array</span><br><span class="line"><span class="comment">## delete item</span></span><br><span class="line"><span class="built_in">unset</span> array[2]</span><br><span class="line"><span class="comment">## empty array</span></span><br><span class="line"><span class="built_in">unset</span> array</span><br></pre></td></tr></table></figure></p>
<p>Iterate over the associated array:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## The keys are accessed using an exclamation point</span></span><br><span class="line"><span class="comment"># can do this to index array as well!</span></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!array[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"key  : <span class="variable">$key</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"value: <span class="variable">$&#123;array[$key]&#125;</span>"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## assign all keys to other array</span></span><br><span class="line">array2=(<span class="string">"<span class="variable">$&#123;!array[@]&#125;</span>"</span>)</span><br><span class="line"><span class="comment">## copy whole array</span></span><br><span class="line">array3=(<span class="string">"<span class="variable">$&#123;array[@]&#125;</span>"</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="Array-Counterpart"><a href="#Array-Counterpart" class="headerlink" title="Array Counterpart"></a>Array Counterpart</h1><p>Loop through comma separated string, or other delimiter.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">var=<span class="string">"1,2,3,4,5"</span></span><br><span class="line"><span class="comment"># use sed</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> $(<span class="built_in">echo</span> <span class="variable">$var</span> | sed <span class="string">"s/,/ /g"</span>)</span><br><span class="line"><span class="comment"># use pattern match</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;var//,/ &#125;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$i</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<p>还可以使用<code>IFS</code>设置不同的separator, 也可以用<code>tr</code>去替换分隔符。</p>
<h1 id="Caveat"><a href="#Caveat" class="headerlink" title="Caveat"></a>Caveat</h1><p>If you use <code>declare -a</code> or <code>declare -A</code> to create array in shell function, it by default is <strong>local scope</strong> in that function. You can move the <code>declare</code> out to make the array globally access, or use <code>declare -ga</code> and `declare -gA (<strong>only bash 4.2 and later support this</strong>).</p>
<p>Notice that variable defined without <code>local</code> in function is global access.</p>
<p>Assign array to other variables:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">a=(<span class="string">'a'</span> <span class="string">'b'</span> <span class="string">'c'</span>)</span><br><span class="line"><span class="comment">## must have double qoutes to protect key that has whitespace</span></span><br><span class="line">b=(<span class="string">"<span class="variable">$&#123;a[@]&#125;</span>"</span>)</span><br></pre></td></tr></table></figure></p>
<p>Notice that you <strong>cannot</strong> <code>export</code> array directly. <code>Array variables may not (yet) be exported.</code> in some bash verions, but there are some workarounds.</p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p><a href="https://www.artificialworlds.net/blog/2012/10/17/bash-associative-array-examples/" target="_blank" rel="noopener">Bash associative array examples</a><br><a href="https://www.artificialworlds.net/blog/2013/09/18/bash-arrays/" target="_blank" rel="noopener">Bash indexed arrays</a><br><a href="https://linuxconfig.org/how-to-use-arrays-in-bash-script" target="_blank" rel="noopener">Indexed and associative array</a></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Background Sign Caution</title>
    <url>/2019/09/09/shell-background-sign-caution/</url>
    <content><![CDATA[<p>I want to wrap several commands into one line format to put in <code>command</code>/<code>args</code> field in yaml file for Kubernetes. But always get syntax error with bad <code>;</code>, for example: <code>-bash: syntax error near unexpected token ;&#39;</code>, finally understand the error is from <code>&amp;</code>.</p>
<p>Notice that here <code>&amp;</code> should not have <code>;</code> after it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(<span class="built_in">echo</span> 123)&amp;; sleep 5; <span class="built_in">echo</span> 456</span><br></pre></td></tr></table></figure></p>
<p>Instead the correct way is:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">(<span class="built_in">echo</span> 123)&amp; sleep 5; <span class="built_in">echo</span> 456</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Apache Server</title>
    <url>/2020/09/07/server-apache/</url>
    <content><![CDATA[<p>因为需要验证Envoy CONNECT feature的缘故，我打算自己设置一个server with SSL/TLS测试:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">client &lt;--------------&gt; envoy proxy &lt;--------------&gt; Apache server</span><br><span class="line">                     (docker container)                (certbot)</span><br></pre></td></tr></table></figure></p>
<p>目前遇到的问题:</p>
<ol>
<li>localhost conigure domain name: <a href="https://www.youtube.com/watch?v=gBfZdJFxjew" target="_blank" rel="noopener">https://www.youtube.com/watch?v=gBfZdJFxjew</a></li>
<li>localhost set https: certbot</li>
<li>apache set user/password authentication: <a href="https://www.youtube.com/watch?v=HVt2E_Ny4po" target="_blank" rel="noopener">https://www.youtube.com/watch?v=HVt2E_Ny4po</a></li>
</ol>
<p>Tool involved:</p>
<ol>
<li>httpd apache</li>
<li>certbot</li>
<li>vagrant</li>
<li>docker container</li>
<li>envoy</li>
</ol>
<p>other links:</p>
<ol>
<li><p>set virtualhost domain:<br><a href="https://httpd.apache.org/docs/2.4/vhosts/examples.html" target="_blank" rel="noopener">https://httpd.apache.org/docs/2.4/vhosts/examples.html</a></p>
</li>
<li><p>apache config file in centos:<br><a href="https://www.liquidweb.com/kb/apache-configuration-centos/" target="_blank" rel="noopener">https://www.liquidweb.com/kb/apache-configuration-centos/</a></p>
</li>
</ol>
]]></content>
      <categories>
        <category>Server</category>
      </categories>
      <tags>
        <tag>server</tag>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title>Login and Nonlogin Shell</title>
    <url>/2019/05/27/shell-login-nonlogin/</url>
    <content><![CDATA[<p>In the non-root development for DataStage, in order to launch applications as non-root user, I use <code>su - dsadm</code> with following commands. Later I occassionally notice that badal use <code>su dsadm</code>… So what are the differences?</p>
<p>There are two main shell instance types: <code>interactive</code> and <code>noninteractive</code>, but of those, only interactive shells are of interest because noninteractive shells (such as those that run shell scripts) usually don’t read any startup files. </p>
<p><code>Interactive shells</code> are the ones that you use to <strong>run commands from a terminal</strong>, they can be classified as <code>login</code> or <code>non-login</code>. I know there are lots of startup files under each user’s home directory, how do they be called and in what order?</p>
<h2 id="Login-Shell"><a href="#Login-Shell" class="headerlink" title="Login Shell"></a>Login Shell</h2><p>Logging in remotely with <code>SSH</code> will give you a login shell.</p>
<p>You can tell if a shell is a login shell by running <code>echo $0</code>; if the first character is a <code>-</code>, the shell’s a login shell.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## if not sure it's login or non-login, check it</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$0</span></span><br><span class="line">-bash</span><br></pre></td></tr></table></figure></p>
<p>When Bash is invoked as a <code>Login</code> shell:</p>
<ol>
<li>Login process calls <code>/etc/profile</code> (this is for all users)</li>
<li><code>/etc/profile</code> calls the scripts in <code>/etc/profile.d/</code></li>
<li>Login process calls <code>$HOME/.bash_profile</code>, <code>$HOME/.bash_login</code> and <code>$HOME/.profile</code> in order, the first found file is run and rest are ignored, most Linux distributions use only one or two of these four startup files. Notice that <code>$HOME/.bashrc</code> are not in the list, it typically run from one of these files.</li>
</ol>
<p>Login Shells created by explicitly telling to login, there is a <code>-</code> or <code>-l</code> flag:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su -</span><br><span class="line">su -l</span><br><span class="line">su --login</span><br><span class="line">su USERNAME - </span><br><span class="line">su -l USERNAME</span><br><span class="line">su --login USERNAME</span><br><span class="line">sudo -i</span><br></pre></td></tr></table></figure></p>
<h2 id="Non-login-Shell"><a href="#Non-login-Shell" class="headerlink" title="Non-login Shell"></a>Non-login Shell</h2><p>When bash is invoked as a <code>Non-login</code> shell (for example, you just run <code>bash</code> or <code>sh</code> without login):<br>如果先ssh进入系统，再运行<code>bash</code>，则就是non-login shell了。</p>
<ol>
<li>Non-login process(shell) calls <code>/etc/bashrc</code></li>
<li>then calls <code>$HOME/.bashrc</code> (remember!)</li>
</ol>
<p><code>Non-Login</code> shells created using the below commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su</span><br><span class="line">su USERNAME</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Of course you can source <code>$HOME/.bashrc</code> in <code>$HOME/.bash_profile</code> files to satisfy both login and non-login shell, for example: add <code>. $HOME/.bashrc</code> in <code>$HOME/.bash_profile</code> (it’s usually there by default setting).</p>
</blockquote>
<p>The reasoning behind the two different startup filesystems is that in the old days, users logged in through a traditional terminal with a <code>login shell</code>, then started <code>non-login</code> subshells with windowing systems or the screen program. For the <code>non-login</code> subshells, it was deemed a waste to repeatedly set the user environment and run a bunch of programs that had already been run. With login shells, you could run fancy startup commands in a file such as <code>.bash_profile</code>, leaving only aliases and other “lightweight” things to your <code>.bashrc</code>.</p>
<p>This can explain that if you use non-login like <code>su dsadm</code>, the parent exported environment variables are still there in <code>env</code> scope. But if you run <code>su - dsadm</code>, the parent exported environment variables are gone.</p>
<h2 id="Bash-Parameters"><a href="#Bash-Parameters" class="headerlink" title="Bash Parameters"></a>Bash Parameters</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Make bash act as if it had been invoked as a login shell</span></span><br><span class="line"><span class="comment">## 但实际上并不是真正的login shell, echo $0 可知</span></span><br><span class="line">bash --login</span><br><span class="line">bash -l</span><br><span class="line"></span><br><span class="line"><span class="comment">## -c: string If the -c option is present, then commands are read from string.</span></span><br><span class="line"><span class="comment">## If there are arguments after the string</span></span><br><span class="line"><span class="comment">## they are assigned to the positional parameters, starting with $0.</span></span><br><span class="line"><span class="comment">## 这就不是interactive shell了</span></span><br><span class="line">bash -c /tmp/test.sh hello world!</span><br><span class="line"></span><br><span class="line"><span class="comment">## do not run ~/.bashrc, by default same as `sh`</span></span><br><span class="line">bash --norc</span><br><span class="line"></span><br><span class="line"><span class="comment">## 这个只对login shell才有用，不进行任何初始化</span></span><br><span class="line">bash --noprofile</span><br><span class="line"></span><br><span class="line"><span class="comment">## specify other script to replace .bashrc</span></span><br><span class="line">bash --rcfile &lt;path to file&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## do syntax check only</span></span><br><span class="line">bash -n &lt;script&gt;</span><br></pre></td></tr></table></figure>
<p>Interesting question:<br><a href="https://stackoverflow.com/questions/9357464/how-to-start-a-shell-without-any-user-configuration" target="_blank" rel="noopener">How to start a shell in clean</a></p>
<p><code>~/.bash_logout</code> will be executed when exit login shell.</p>
<h2 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h2><p>Docker or K8s pod init process 会初始化 <code>~/.bashrc</code>吗？ 这个init process 是user login shell呢 还是 non-login shell?</p>
<p>From experiment, no source <code>~/.bashrc</code> for init process.</p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Common Code Snippets</title>
    <url>/2019/02/24/shell-common-code/</url>
    <content><![CDATA[<p>More information please see <code>man bash</code>, it has comprehensive information.</p>
<p>This blog collects the commonly used code snippets based on my daily work, also do summary from related <em>stackoverflow</em> topics.</p>
<h1 id="set-builtin"><a href="#set-builtin" class="headerlink" title="set builtin"></a>set builtin</h1><p>Usually I use <code>set -x</code> for debugging purpose, today I see a new statement <code>set -ex</code>. What is this and what is set in Bash? 后来又知道了很多，见awesome list中的bash tutoral.</p>
<p><a href="https://www.gnu.org/software/bash//manual/html_node/The-Set-Builtin.html" target="_blank" rel="noopener">The Set Builtin</a>, in short, <code>set</code> allows you to change the values of shell options and set the positional parameters, or to display the names and values of shell variables.</p>
<p><code>set -e</code>, causes the shell to exit if any subcommand or pipeline returns a non-zero status. This tells bash that it should exit the script if any statement returns a non-true return value. The benefit of using <code>-e</code> is that it prevents errors snowballing into serious issues when they could have been caught earlier. </p>
<p>But sometimes <code>set -e</code> may not be good, see these two posts:<br><a href="https://serverfault.com/questions/143445/what-does-set-e-do-and-why-might-it-be-considered-dangerous" target="_blank" rel="noopener">What does ‘set -e’ do, and why might it be considered dangerous?</a><br>这个回答很有启发，用哪种方法还得看具体场景。一定要考虑清楚。</p>
<p><a href="https://www.cnblogs.com/YatHo/p/7682344.html" target="_blank" rel="noopener">“set -e” usage</a></p>
<h1 id="get-path-of-running-script"><a href="#get-path-of-running-script" class="headerlink" title="get path of running script"></a>get path of running script</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curpath=$(dirname $(readlink -f $0))</span><br></pre></td></tr></table></figure>
<p><code>readlink -f $0</code> will follow every symlink in every component of the given name recursively and get the <code>canonical</code> path. A single file existing on a system can have <strong>many</strong> different paths that refer to it, but only one <code>canonical</code> path, <code>canonical</code> gives a unique <strong>absolute</strong> path for a given file. That means even though you call a script in it’s current directory, <code>readlink -f $0</code> will give you the absolute path!</p>
<p><code>dirname $0</code> cut the script name to get the calling path, the path is relative not absolute.</p>
<h1 id="run-script-in-it’s-driectory"><a href="#run-script-in-it’s-driectory" class="headerlink" title="run script in it’s driectory"></a>run script in it’s driectory</h1><p>Sometimes we want to run script in it’s folder by <code>./xxx.sh</code>. we can check that:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SCRIPT_PATH=$(dirname <span class="variable">$0</span>)</span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">"X"</span><span class="string">"<span class="variable">$&#123;SCRIPT_PATH&#125;</span>"</span> != <span class="string">"X."</span> ]]; <span class="keyword">then</span></span><br><span class="line">  LogMsg <span class="string">"###### ERROR: Please run this script in it's directory!"</span></span><br><span class="line">  <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<h1 id="create-tmp-file-to-store-log"><a href="#create-tmp-file-to-store-log" class="headerlink" title="create tmp file to store log"></a>create tmp file to store log</h1><p>create a temporary file or directory, this temp file is owned and grouped by the current user.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">OUT_FILE=$(mktemp /tmp/log.XXXXXX)</span><br></pre></td></tr></table></figure></p>
<p>it will randomly generate 6 characters to replace <code>XXXXXX</code>. You may need to delete the tmp file when script exits, for example, use <code>trap</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> exitHook &#123;</span><br><span class="line">  rm -f <span class="variable">$OUT_FILE</span></span><br><span class="line">  rm -f <span class="variable">$&#123;OUT_FILE&#125;</span>.yml</span><br><span class="line">  rm -f <span class="variable">$&#123;OUT_FILE&#125;</span>.out</span><br><span class="line">  rm -f <span class="variable">$&#123;OUT_FILE&#125;</span>.err</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">## must put at beginning of script</span></span><br><span class="line"><span class="built_in">trap</span> exitHook EXIT</span><br></pre></td></tr></table></figure></p>
<p>Actually, you can get random number from<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$RANDOM</span></span><br></pre></td></tr></table></figure></p>
<p>you can also seed it to generate reproducible sequence:<br><a href="https://stackoverflow.com/questions/42004870/seed-for-random-environment-variable-in-bash" target="_blank" rel="noopener">https://stackoverflow.com/questions/42004870/seed-for-random-environment-variable-in-bash</a></p>
<h1 id="if-condition"><a href="#if-condition" class="headerlink" title="if condition"></a>if condition</h1><p>List of <a href="http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html" target="_blank" rel="noopener">test command condition statements</a> Or check manual <code>man test</code>.</p>
<p>when uses AND/OR, adopt form like: <code>[[ ]] &amp;&amp; [[ ]] || [[ ]]</code>.<br>if compare number, can use:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">declare</span> -i day=30</span><br><span class="line"><span class="keyword">if</span> (( day &gt; 0 || day &lt; 31 )); <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"day is good"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<p><code>==</code> or <code>=</code>, <code>!=</code> and <code>=~</code> are used for string comparision:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sth does not exist?</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">"<span class="variable">$&#123;sth&#125;</span>"</span><span class="string">"X"</span> == <span class="string">"X"</span> ]]; <span class="keyword">then</span></span><br><span class="line">  LogMsg <span class="string">"###### INFO: ..."</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<p>or<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># True if the length of "STRING" is non-zero.</span></span><br><span class="line"><span class="keyword">if</span> [[ -z <span class="string">"<span class="variable">$&#123;sth&#125;</span>"</span> ]]; <span class="keyword">then</span></span><br><span class="line">  LogMsg <span class="string">"###### INFO: ..."</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># directory does not exist?</span></span><br><span class="line"><span class="keyword">if</span> [[ ! -d <span class="string">"<span class="variable">$&#123;folder_path&#125;</span>"</span> ]]; <span class="keyword">then</span></span><br><span class="line">   LogMsg <span class="string">"###### ERROR: <span class="variable">$&#123;folder_path&#125;</span> directory doesn't exist!"</span></span><br><span class="line">   <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>Acutally the key is the test command, it has 3 forms: <code>[]</code> or <code>[[ ]]</code> or <code>test expression</code>, <code>[[ ]]</code> supports regular expression:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## don't double quote regexp</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$name</span> =~ colou?r ]]; <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"..."</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<h1 id="select-loop"><a href="#select-loop" class="headerlink" title="select loop"></a>select loop</h1><p>The select loop provides an easy way to create a numbered menu from which users can select options. It is useful when you need to ask the user to choose one or more items from a list of choices.</p>
<blockquote>
<p>Note that this loop was introduced in ksh and has been adapted into bash. It is not available in sh.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PS3=<span class="string">"Enter your choice (must be a number): "</span></span><br><span class="line">select DRINK <span class="keyword">in</span> tea cofee water juice appe all none</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">   <span class="keyword">case</span> <span class="variable">$DRINK</span> <span class="keyword">in</span></span><br><span class="line">      tea | cofee | water | all) </span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Go to canteen"</span></span><br><span class="line">        <span class="built_in">break</span></span><br><span class="line">        ;;</span><br><span class="line">      juice|appe)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Available at home"</span></span><br><span class="line">        <span class="built_in">break</span></span><br><span class="line">        ;;</span><br><span class="line">      none) </span><br><span class="line">        <span class="built_in">break</span> </span><br><span class="line">        ;;</span><br><span class="line">      *) </span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"ERROR: Invalid selection"</span> </span><br><span class="line">      ;;</span><br><span class="line">   <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>When select you can use index number or literal, if no <code>break</code>, it will loop forever.<br><code>PS3</code> is used to show the prompt for input.</p>
<h1 id="input-password-and-confirm"><a href="#input-password-and-confirm" class="headerlink" title="input password and confirm"></a>input password and confirm</h1><p>Must not show password user input:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"****************************************************************"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Please input the password:"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"****************************************************************"</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span></span><br><span class="line">  <span class="built_in">read</span> -s -p <span class="string">"PASSWORD: "</span> PASSWORD</span><br><span class="line">  <span class="built_in">echo</span></span><br><span class="line">  <span class="built_in">read</span> -s -p <span class="string">"CONFIRM:  "</span> PASSWORD_CONFIRM</span><br><span class="line">  <span class="built_in">echo</span></span><br><span class="line">  [ <span class="variable">$&#123;#PASSWORD&#125;</span> -lt 6 ] &amp;&amp; <span class="built_in">echo</span> <span class="string">"The length of password at least 6, please try again"</span> &amp;&amp; <span class="built_in">continue</span></span><br><span class="line">  [ <span class="string">"<span class="variable">$&#123;PASSWORD&#125;</span>"</span> = <span class="string">"<span class="variable">$&#123;PASSWORD_CONFIRM&#125;</span>"</span> ] &amp;&amp; <span class="built_in">break</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"Passwords do not match please try again..."</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<h1 id="script-input-parameters"><a href="#script-input-parameters" class="headerlink" title="script input parameters"></a>script input parameters</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -eq 0 ]; <span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"No command-line arguments were specified..."</span></span><br><span class="line">  <span class="comment"># call Usage function here</span></span><br><span class="line">  <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## case和C语言中有一样的性质，如果没有break，会继续对比接下来的选项</span></span><br><span class="line"><span class="comment">## 这里并不需要，因为shift 且没有相同的flags</span></span><br><span class="line"><span class="keyword">while</span> [ <span class="variable">$#</span> -gt 0 ]</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">    -p1)</span><br><span class="line">       <span class="built_in">shift</span></span><br><span class="line">       P1=<span class="variable">$&#123;1&#125;</span></span><br><span class="line">       <span class="built_in">shift</span>;;</span><br><span class="line"></span><br><span class="line">    -p2)</span><br><span class="line">       <span class="built_in">shift</span></span><br><span class="line">       P2=<span class="variable">$&#123;1&#125;</span></span><br><span class="line">       <span class="built_in">shift</span>;;</span><br><span class="line"></span><br><span class="line">    -h|--<span class="built_in">help</span>)</span><br><span class="line">       <span class="comment"># Usage</span></span><br><span class="line">       <span class="built_in">exit</span> 0;;</span><br><span class="line">       </span><br><span class="line">    *) <span class="comment"># Usage</span></span><br><span class="line">       <span class="built_in">exit</span> 1;;</span><br><span class="line">  <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">[[ <span class="string">"X<span class="variable">$P1</span>"</span> = <span class="string">"X"</span> ]] &amp;&amp;  <span class="built_in">exit</span> 1</span><br><span class="line">[[ <span class="string">"X<span class="variable">$P2</span>"</span> = <span class="string">"X"</span> ]] &amp;&amp;  <span class="built_in">exit</span> 1</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note there are 2 shift in one case, after each <code>shift</code>, <code>$#</code> minus 1.</p>
</blockquote>
<h1 id="function"><a href="#function" class="headerlink" title="function"></a>function</h1><p>The function refers to passed arguments by their position (not by name), that is <code>$1</code>, <code>$2</code>, and so forth. <code>$0</code> is the name of the script itself.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> example()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">## local var prevent var leaking to shell</span></span><br><span class="line">  <span class="built_in">local</span> first=<span class="variable">$1</span></span><br><span class="line">  <span class="built_in">local</span> second=<span class="variable">$2</span></span><br><span class="line">  <span class="comment">## return code is similar to exit code but this is return</span></span><br><span class="line">  <span class="comment">## will break the rest execution</span></span><br><span class="line">  <span class="built_in">return</span> &lt;<span class="built_in">return</span> code&gt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Need to call your function after it is declared.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">example <span class="string">"p1"</span> <span class="string">"p2"</span></span><br><span class="line"></span><br><span class="line">args <span class="comment">#0 is &lt;absolute path to script itself&gt;</span></span><br><span class="line">args <span class="comment">#1 is p1</span></span><br><span class="line">args <span class="comment">#2 is p2</span></span><br></pre></td></tr></table></figure></p>
<p>Show functions:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list all function names</span></span><br><span class="line"><span class="built_in">declare</span> -F</span><br><span class="line"><span class="comment">## show definition</span></span><br><span class="line"><span class="built_in">declare</span> -f [<span class="keyword">function</span> name]</span><br><span class="line"><span class="comment">## clear a function</span></span><br><span class="line"><span class="built_in">unset</span> -f &lt;<span class="keyword">function</span> name&gt;</span><br></pre></td></tr></table></figure></p>
<p>Export functions, to make it available to subshells, similarly to export variables:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -xf: export a function</span></span><br><span class="line"><span class="built_in">declare</span> -xf &lt;<span class="keyword">function</span> name&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="log-message"><a href="#log-message" class="headerlink" title="log message"></a>log message</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">LogMsg()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment"># parse input and reformat</span></span><br><span class="line">  logMsg=<span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"["</span>`date +<span class="string">"%Y/%m/%d %r"</span>`<span class="string">"] "</span> <span class="variable">$&#123;logMsg&#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">LogMsg <span class="string">"[INFO] ..."</span></span><br><span class="line">LogMsg <span class="string">"[WARNING] ..."</span></span><br><span class="line">LogMsg <span class="string">"[ERROR]..."</span></span><br></pre></td></tr></table></figure>
<p>Actually, this style <code>[INFO] [2019-10-11 15:59:26-0081] ...</code> it better.</p>
<h1 id="check-last-command-result"><a href="#check-last-command-result" class="headerlink" title="check last command result"></a>check last command result</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">echo_success_failure</span></span>() &#123;</span><br><span class="line">  <span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span> </span><br><span class="line">    LogMsg <span class="string">"###### INFO: Success..."</span></span><br><span class="line">  <span class="keyword">else</span> </span><br><span class="line">    LogMsg <span class="string">"###### INFO: Failure..."</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="run-as-root"><a href="#run-as-root" class="headerlink" title="run as root"></a>run as root</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">effective_uid=`id -u` 2&gt;/dev/null</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$effective_uid</span> -ne 0 ]; <span class="keyword">then</span></span><br><span class="line"> LogMsg <span class="string">"###### ERROR: Please run this script as root or sudo"</span>  </span><br><span class="line"> <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<h1 id="delimited-string-to-array"><a href="#delimited-string-to-array" class="headerlink" title="delimited string to array"></a>delimited string to array</h1><p>Convert delimited string to array, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">string=<span class="string">"item1 item2 item3"</span></span><br><span class="line">IFS=<span class="string">' '</span> <span class="built_in">read</span> -a array &lt;&lt;&lt; <span class="string">"<span class="variable">$&#123;string&#125;</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>This version has no globbing problem, the split character is set in <code>$IFS</code> (here is space), variables quoted. Don’t forget to do sanity check after converting.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$&#123;array[0]&#125;</span>  ===&gt; item1</span><br><span class="line"><span class="variable">$&#123;array[1]&#125;</span>  ===&gt; item2</span><br><span class="line"><span class="variable">$&#123;array[2]&#125;</span>  ===&gt; item3</span><br></pre></td></tr></table></figure></p>
<p>Actually if the string use spaces as delimiter, we can loop items directly:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">string=<span class="string">"item1 item2 item3"</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;string&#125;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$&#123;i&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<h1 id="loop-array"><a href="#loop-array" class="headerlink" title="loop array"></a>loop array</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">declare</span> -a array=(<span class="string">"element1"</span> <span class="string">"element2"</span> <span class="string">"element3"</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;array[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;i&#125;</span>"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p><code>declare</code> or <code>typeset</code> are an explicit way of declaring variable in shell scripts.</p>
<p>In BASH it is safer to quote the variable using <code>&quot;&quot;</code> for the cases when <code>$i</code> may contain white spaces or shell expandable characters.</p>
<p>If you want to use index of array element<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get length of an array</span></span><br><span class="line">arraylength=<span class="variable">$&#123;#array[@]&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># use for loop to read all values and indexes</span></span><br><span class="line"><span class="keyword">for</span> (( i=0; i&lt;<span class="variable">$&#123;arraylength&#125;</span>; i++ ));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="comment">## $&#123;array[$i]&#125; 这里注意，先解析的$i</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$i</span> <span class="string">" / "</span> <span class="variable">$&#123;arraylength&#125;</span> <span class="string">" : "</span> <span class="variable">$&#123;array[$i]&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<p>If we use <code>declare</code> to define a integer variable:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">declare</span> -i x=10</span><br><span class="line"><span class="keyword">while</span> (( x &gt; 0 ));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$x</span></span><br><span class="line">  <span class="comment">## no need to use 'let x=x-1'</span></span><br><span class="line">  x=x-1</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<p>In ZSH shell, you can use foreach loop:<br><figure class="highlight zsh"><table><tr><td class="code"><pre><span class="line"><span class="comment">## () is a must</span></span><br><span class="line">foreach item (`ls /tmp`)</span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$item</span></span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<h1 id="chmod"><a href="#chmod" class="headerlink" title="chmod"></a>chmod</h1><p><code>chmod</code> recursively for directory and it’s content<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod -R 0755 &lt;target directory&gt;</span><br></pre></td></tr></table></figure></p>
<p>Or only add executable for file<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find . -name <span class="string">'&lt;file name&gt;'</span> -<span class="built_in">type</span> f | xargs chmod +x</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-rwxr-xr-x ...</span><br></pre></td></tr></table></figure>
<h1 id="pass-parameters-to-script"><a href="#pass-parameters-to-script" class="headerlink" title="pass parameters to script"></a>pass parameters to script</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># invoke, must stick to this format</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"admin</span></span><br><span class="line"><span class="string">admin"</span> | ./script.sh</span><br><span class="line"><span class="comment"># receive code snippet in script.sh</span></span><br><span class="line">MsgLog <span class="string">"###### Please enter args1  ..."</span></span><br><span class="line"><span class="built_in">read</span> args1</span><br><span class="line">LogMsg <span class="string">"###### Please enter password ..."</span></span><br><span class="line"><span class="built_in">read</span> -s password</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$&#123;args1&#125;</span>     ===&gt; admin</span><br><span class="line"><span class="variable">$&#123;password&#125;</span>  ===&gt; admin</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: <code>read</code> <code>-s</code> flag: do not echo input coming from a terminal, used for password</p>
</blockquote>
<h1 id="setup-ssh-password-less"><a href="#setup-ssh-password-less" class="headerlink" title="setup ssh password-less"></a>setup ssh password-less</h1><p>Idempotence：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keyscan -H <span class="variable">$&#123;remote&#125;</span> &gt;&gt; ~/.ssh/known_hosts</span><br><span class="line">sshpass -p <span class="string">"&lt;password&gt;"</span> ssh-copy-id -i ~/.ssh/id_rsa.pub root@<span class="variable">$&#123;remote&#125;</span></span><br><span class="line"><span class="keyword">if</span> [[ $? -ne 0 ]]; <span class="keyword">then</span></span><br><span class="line">  LogMsg <span class="string">"######ERROR: Something went wrong with ssh-copy-id. Check for incorrect credentials ... "</span></span><br><span class="line">  <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<h1 id="recursive-call"><a href="#recursive-call" class="headerlink" title="recursive call"></a>recursive call</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">example()</span><br><span class="line">&#123;</span><br><span class="line">  &lt;execute sth&gt;</span><br><span class="line">  <span class="keyword">if</span> [[ $? -ne 0 ]]; <span class="keyword">then</span></span><br><span class="line">       LogMsg <span class="string">"######ERROR: Something went wrong… "</span></span><br><span class="line">       example</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="tee-command"><a href="#tee-command" class="headerlink" title="tee command"></a>tee command</h1><p><code>tee</code> command reads the standard input and writes it to both the standard output and one or more files, <code>-a</code> flag used to append output to existing file, if no <code>-a</code>, tee will create the file if not exist.<br>  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">LogMsg()</span><br><span class="line">&#123;</span><br><span class="line">  logMsg=<span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"["</span>`date +<span class="string">"%Y/%m/%d %r"</span>`<span class="string">"]"</span> <span class="variable">$&#123;logMsg&#125;</span> | tee -a logs/ds_<span class="variable">$&#123;stage&#125;</span>_<span class="variable">$&#123;timeStamp&#125;</span>.<span class="built_in">log</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------------+     +-------+    +--------------+</span><br><span class="line">|  command    |     | tee   |    |   stdout     |</span><br><span class="line">|   output    +----&gt;+       +---&gt;+              |</span><br><span class="line">+-------------+     +---+---+    +--------------+</span><br><span class="line">                        |</span><br><span class="line">                    +---v---+</span><br><span class="line">                    |  file |</span><br><span class="line">                    |       |</span><br><span class="line">                    +-------+</span><br></pre></td></tr></table></figure>
<h1 id="statement-block"><a href="#statement-block" class="headerlink" title="statement block"></a>statement block</h1><p>  这个很有意思，之前都没见过: <code>{}</code><br>  <a href="https://unix.stackexchange.com/questions/390329/statement-blocks-mechanism-in-shell-scripting" target="_blank" rel="noopener">Statement block in shell script</a></p>
<h1 id="do-something-after-reboot"><a href="#do-something-after-reboot" class="headerlink" title="do something after reboot"></a>do something after reboot</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"><span class="comment"># this script will do sth after reboot </span></span><br><span class="line"><span class="comment"># in /root/completeme.sh</span></span><br><span class="line"><span class="comment"># then restore /etc/profile</span></span><br><span class="line"><span class="comment">#################################################</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Warning! This script is going to reboot now to complate the procedure"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"After reboot, login as root to perform the final steps"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Press Ctrl-C now to stop this script in case you don\'t want to reboot"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## heredoc</span></span><br><span class="line">cat &lt;&lt; REBOOT &gt;&gt; /root/completeme.sh</span><br><span class="line"><span class="comment">## do sth after reboot</span></span><br><span class="line"></span><br><span class="line">touch /tmp/after-reboot                            </span><br><span class="line">rm -f /etc/profile</span><br><span class="line">mv /etc/profile.bak /etc/profile</span><br><span class="line"><span class="built_in">echo</span> DONE</span><br><span class="line">REBOOT</span><br><span class="line"></span><br><span class="line">chmod +x /root/completeme.sh</span><br><span class="line">cp /etc/profile /etc/profile.bak</span><br><span class="line"><span class="comment">## after reboot /etc/profile will be executed so /root/completeme.sh</span></span><br><span class="line"><span class="built_in">echo</span> /root/completeme.sh &gt;&gt; /etc/profile</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure>
<h1 id="monitor-CPU-load"><a href="#monitor-CPU-load" class="headerlink" title="monitor CPU load"></a>monitor CPU load</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## to increase CPU load</span></span><br><span class="line"><span class="comment">## dd if=/dev/zero of=/dev/null</span></span><br><span class="line"><span class="comment">## or use stress command!</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> sleep 60</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="comment">## to remove header of ps output, append `=` or user --no-headers flag</span></span><br><span class="line">  <span class="comment">## CPU$ 0.0 will be in part if CPU$ &gt; 0.0</span></span><br><span class="line">  REC=`ps -eo pcpu=,pid= -o comm= | sort -k1 -n -r | head -1`</span><br><span class="line">  USAGE=`<span class="built_in">echo</span> <span class="variable">$REC</span> | awk <span class="string">'&#123;print $1&#125;'</span>`</span><br><span class="line">  <span class="comment">## truncate decimal part</span></span><br><span class="line">  USAGE=<span class="variable">$&#123;USAGE%.*&#125;</span></span><br><span class="line">  PID=`<span class="built_in">echo</span> <span class="variable">$REC</span> | awk <span class="string">'&#123;print $2&#125;'</span>`</span><br><span class="line">  PNAME=`<span class="built_in">echo</span> <span class="variable">$REC</span> | awk <span class="string">'&#123;print $3&#125;'</span>`</span><br><span class="line"></span><br><span class="line">  <span class="comment"># Only if we have a high CPU load on one process, run a check within 7 seconds</span></span><br><span class="line">  <span class="comment"># In this check, we should monitor if the process is still that active</span></span><br><span class="line">  <span class="comment"># If that's the case, root gets a message</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## man test</span></span><br><span class="line">  <span class="keyword">if</span> [ <span class="variable">$USAGE</span> -gt 80 ] </span><br><span class="line">  <span class="keyword">then</span></span><br><span class="line">    USAGE1=<span class="variable">$USAGE</span></span><br><span class="line">    PID1=<span class="variable">$PID</span></span><br><span class="line">    PNAME1=<span class="variable">$PNAME</span></span><br><span class="line">    sleep 7</span><br><span class="line">    REC=`ps --no-headers -eo pcpu,pid -o comm= | sort -k1 -n -r | head -1`</span><br><span class="line">    USAGE2=`<span class="built_in">echo</span> <span class="variable">$REC</span> | awk <span class="string">'&#123;print $1&#125;'</span>`</span><br><span class="line">    USAGE2=<span class="variable">$&#123;USAGE2%.*&#125;</span></span><br><span class="line">    PID2=`<span class="built_in">echo</span> <span class="variable">$REC</span> | awk <span class="string">'&#123;print $2&#125;'</span>`</span><br><span class="line">    PNAME2=`<span class="built_in">echo</span> <span class="variable">$REC</span> | awk <span class="string">'&#123;print $3&#125;'</span>`</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Now we have variables with the old process information and with the</span></span><br><span class="line">    <span class="comment"># new information</span></span><br><span class="line"></span><br><span class="line">    [ <span class="variable">$USAGE2</span> -gt 80 ] &amp;&amp; [ <span class="variable">$PID1</span> = <span class="variable">$PID2</span> ] &amp;&amp; mail -s <span class="string">"CPU load of <span class="variable">$PNAME</span> is above 80%"</span> root@blah.com &lt; .</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell Pattern Matching</title>
    <url>/2020/11/28/shell-pattern-match/</url>
    <content><![CDATA[<h1 id="Parameter-expansion"><a href="#Parameter-expansion" class="headerlink" title="Parameter expansion"></a>Parameter expansion</h1><p>对于变量值的检查(比如是否是dash 开头)，提取(比如提取一个文件名去掉后缀)很有帮助，这个手册概括了所有情况，但可能不好理解，可以动手试一下就知道了, <a href="https://www.gnu.org/software/bash/manual/html_node/Shell-Parameter-Expansion.html" target="_blank" rel="noopener">Shell parameter expansion</a>.  其实用pipeline 也可以达到相同的结构，但是会麻烦一些。</p>
<p>这是中文总结，还不错<a href="https://juejin.cn/post/6844903842966929422" target="_blank" rel="noopener">Shell扩展(Shell Expansions)-参数扩展(Shell Parameter Expansion)</a>. 有个地方写错了 <code>$$</code> 才是当前shell 的PID。</p>
<p>注意<code>null</code> 和 <code>unset</code> variable的区别, <code>set -u</code> 可以检测没有定义的variable (也就是unset), <code>null</code> 在这里就是empty的意思，比如<code>var=</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">var=</span><br><span class="line"><span class="comment"># 空</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$var</span></span><br><span class="line"><span class="comment"># true</span></span><br><span class="line">[[ -z <span class="variable">$var</span> ]]</span><br><span class="line"><span class="comment"># false</span></span><br><span class="line">[[ -n <span class="variable">$var</span> ]]</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span> -u</span><br><span class="line"><span class="built_in">unset</span> var</span><br><span class="line"><span class="comment"># 报错</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$var</span></span><br></pre></td></tr></table></figure></p>
<p>Bash’s various forms of parameter expansion can also distinguish between unset and null values:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># `w` can be literal or another variable</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># if a is unset, value of w is used</span></span><br><span class="line">a=<span class="variable">$&#123;a-w&#125;</span></span><br><span class="line"><span class="comment"># if a is unset or null, value of w is used</span></span><br><span class="line"><span class="comment"># for example, used for positional parameter passed from outside</span></span><br><span class="line">a=<span class="variable">$&#123;a:-w&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># if a is unset or null, value of w is assigned to a</span></span><br><span class="line"><span class="comment"># 不能用于positional parameters的赋值, 比如 $&#123;3:=hello&#125;</span></span><br><span class="line"><span class="variable">$&#123;a:=w&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># if a is unset or null, w is written to stderr</span></span><br><span class="line">a=<span class="variable">$&#123;a:?w&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>Indirect parameter expansion:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">parameter=<span class="string">"var"</span></span><br><span class="line">var=<span class="string">"hello"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># echo is hello</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;!parameter&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>Substring expansion，来自上面的链接中 <code>Shell parameter expansion</code> 的例子:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ string=01234567890abcdefgh</span><br><span class="line"><span class="comment"># 7 is start index</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;string:7&#125;</span></span><br><span class="line">7890abcdefgh</span><br><span class="line"><span class="comment"># 0 is number of char to cut</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;string:7:0&#125;</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;string:7:2&#125;</span></span><br><span class="line">78</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;string:7:-2&#125;</span></span><br><span class="line">7890abcdef</span><br><span class="line"><span class="comment"># 要空格, 防止:- 混淆</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;string: -7&#125;</span></span><br><span class="line">bcdefgh</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;string: -7:0&#125;</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;string: -7:2&#125;</span></span><br><span class="line">bc</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;string: -7:-2&#125;</span></span><br><span class="line">bcdef</span><br><span class="line"></span><br><span class="line"><span class="comment"># set $1 positional parameter</span></span><br><span class="line">$ <span class="built_in">set</span> -- 01234567890abcdefgh</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;1:7&#125;</span></span><br><span class="line">7890abcdefgh</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;1:7:0&#125;</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;1:7:2&#125;</span></span><br><span class="line">78</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;1:7:-2&#125;</span></span><br><span class="line">7890abcdef</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;1: -7&#125;</span></span><br><span class="line">bcdefgh</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;1: -7:0&#125;</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;1: -7:2&#125;</span></span><br><span class="line">bc</span><br><span class="line"><span class="comment"># -2:  start from end</span></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;1: -7:-2&#125;</span></span><br><span class="line">bcdef</span><br><span class="line"></span><br><span class="line"><span class="comment"># array</span></span><br><span class="line">$ array[0]=01234567890abcdefgh</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;array[0]:7&#125;</span></span><br><span class="line">7890abcdefgh</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;array[0]:7:0&#125;</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;array[0]:7:2&#125;</span></span><br><span class="line">78</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;array[0]:7:-2&#125;</span></span><br><span class="line">7890abcdef</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;array[0]: -7&#125;</span></span><br><span class="line">bcdefgh</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;array[0]: -7:0&#125;</span></span><br><span class="line"></span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;array[0]: -7:2&#125;</span></span><br><span class="line">bc</span><br><span class="line">$ <span class="built_in">echo</span> <span class="variable">$&#123;array[0]: -7:-2&#125;</span></span><br><span class="line">bcdef</span><br></pre></td></tr></table></figure></p>
<p>其他常见的用法:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 检查第一个位置参数是不是以-开头，扩展结果是删除最短的match部分</span></span><br><span class="line"><span class="comment"># 对 $&#123;1&#125; 的操作, for example $&#123;1&#125; content is --verbose</span></span><br><span class="line"><span class="comment"># get: -verbose</span></span><br><span class="line"><span class="variable">$&#123;1#-&#125;</span> </span><br><span class="line"><span class="comment"># 同上，但删除最长的match部分</span></span><br><span class="line"><span class="comment"># get: verbose</span></span><br><span class="line"><span class="variable">$&#123;1##-&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># get filename name from a download url</span></span><br><span class="line"><span class="comment"># \ is used to escape / in path</span></span><br><span class="line"><span class="variable">$&#123;1##*\/&#125;</span></span><br><span class="line"><span class="comment"># get path of a url</span></span><br><span class="line"><span class="variable">$&#123;1%\/*&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>其实<code>#</code> or <code>##</code> 后面可以使用<a href="https://www.gnu.org/software/bash/manual/html_node/Pattern-Matching.html#Pattern-Matching" target="_blank" rel="noopener">pattern matching</a>, 这样功能更强, 比如:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$&#123;1#+(-)&#125;</span></span><br><span class="line"><span class="variable">$&#123;1##+(-)&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># remove leading space or blank</span></span><br><span class="line"><span class="comment"># note that double [[]] wrapper!</span></span><br><span class="line"><span class="built_in">shopt</span> -s extglob</span><br><span class="line"><span class="variable">$&#123;1##*([[:blank:]]|[[:space:]])&#125;</span></span><br><span class="line"><span class="comment"># remove trailing space or blank</span></span><br><span class="line"><span class="variable">$&#123;1%%*([[:blank:]]|[[:space:]])&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># remove .tar.gz or .tgz suffix</span></span><br><span class="line"><span class="variable">$&#123;1%@(.tgz|.tar.gz)&#125;</span></span><br></pre></td></tr></table></figure></p>
<p><a href="https://juejin.cn/post/6844903842966929422#heading-19" target="_blank" rel="noopener">参数替换</a> ${parameter/pattern/string}, replace pattern in parameter with string.<br><a href="https://juejin.cn/post/6844903842966929422#heading-20" target="_blank" rel="noopener">大小写变换</a></p>
<h1 id="Shell-Globs"><a href="#Shell-Globs" class="headerlink" title="Shell Globs"></a>Shell Globs</h1><p>A glob is a wildcard that is processed by the shell and expands into a list of arguments.</p>
<p>Glob is like regular expression but less expressive and eaiser to use. Glob match file names, for example <code>ls [0-9]?file*.txt</code>, whereas regular expression match text, for example <code>ls | grep &#39;[0-9].file.*\.txt&#39;</code>. Sometimes the funtionality can look blurred depending on how you use it. 都可以用在if condition [[ =~ ]], case中.</p>
<p>In <code>ls [0-9]?file*.txt</code>, <code>ls</code> does not support regular expression, shell expands the glob and used by <code>ls</code>.</p>
<p><code>grep &#39;^A.*\.txt&#39; *.txt</code>, grep is using regular expression on the files context that file name is expanded by shell from glob.</p>
<p>Shell expansion types and execution order (precedence high to low from up to bottom):</p>
<ol>
<li>brace expansion <code>touch file{1..2}</code></li>
<li>tilde expansion <code>ls ~</code></li>
<li>parameter and variable expansion <code>${1:1:1}</code></li>
<li>command substitution <code>$()</code> or <code></code></li>
<li>word splitting</li>
<li>arithmetic expansion <code>echo $((11 + 22))</code></li>
<li>filename expansion <code>echo file{1..2}.*</code></li>
<li>quote removal <code>echo &quot;$USER&quot;</code></li>
</ol>
<h2 id="Wildcards"><a href="#Wildcards" class="headerlink" title="Wildcards"></a>Wildcards</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls *.txt</span><br><span class="line"><span class="comment"># ? as one char</span></span><br><span class="line">ls file?.txt</span><br><span class="line">ls file??.txt</span><br></pre></td></tr></table></figure>
<h2 id="Character-Set"><a href="#Character-Set" class="headerlink" title="Character Set"></a>Character Set</h2><p>注意和brace expansion <code>{}</code> 区别，brace expansion是展开，character set是一种match:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># character set</span></span><br><span class="line"><span class="comment"># match one of them</span></span><br><span class="line">ls [123abc]file.txt</span><br><span class="line">ls file[0-9].txt</span><br><span class="line">ls file[a-z9].txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个显示的结果和bash设置有关</span></span><br><span class="line"><span class="comment"># locale, In bash terminal, set LC_COLLATE=C (collation)</span></span><br><span class="line">ls file[A-G].txt</span><br><span class="line"><span class="comment"># ! is inversion, not include a-z</span></span><br><span class="line">ls file[!a-z].txt</span><br><span class="line"><span class="comment"># put at end to match !, it is a special char</span></span><br><span class="line">ls file[a-z!].txt</span><br><span class="line">ls file[az-].txt</span><br></pre></td></tr></table></figure></p>
<h2 id="Character-classes"><a href="#Character-classes" class="headerlink" title="Character classes"></a>Character classes</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># [:upper:] is the character class</span></span><br><span class="line"><span class="comment"># put char class in char set</span></span><br><span class="line">ls file[[:upper:]?].txt</span><br><span class="line">ls file[[:lower:]?].txt</span><br><span class="line">ls file[![:lower:][:space:]].txt</span><br></pre></td></tr></table></figure>
<p>Others class useful:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># numbers</span></span><br><span class="line">[:digit:]</span><br><span class="line"><span class="comment"># upper and lower case</span></span><br><span class="line">[:alpha:]</span><br><span class="line"><span class="comment"># upper and lower and numbers</span></span><br><span class="line">[:alnum:]</span><br><span class="line"><span class="comment"># spaces, tabs, newlines, carriage return</span></span><br><span class="line"><span class="comment"># is superset of [:blank:]</span></span><br><span class="line">[:space:]</span><br><span class="line"><span class="comment"># space and tab</span></span><br><span class="line">[:blank:]</span><br></pre></td></tr></table></figure></p>
<h2 id="Shell-globbing-Options"><a href="#Shell-globbing-Options" class="headerlink" title="Shell globbing Options"></a>Shell globbing Options</h2><p>使用<code>shopt</code> command的设置 glob的一些特性，比如设置nullglob, extglob, etc.</p>
<p><code>shopt -s extglob</code>, when using extended pattern matching operators. see <a href="https://www.gnu.org/software/bash/manual/html_node/Pattern-Matching.html#Pattern-Matching" target="_blank" rel="noopener">here</a><br><code>shopt -s nocasematch</code>, set bash case-insensitive match in <code>case</code> or <code>[[ ]]</code> condition.<br>这个是从bash tutorial 中文版中学到的, <code>shopt</code> is bash built-in setting, unlike <code>set</code> is from POSIX.</p>
<h1 id="Extended-Globs"><a href="#Extended-Globs" class="headerlink" title="Extended Globs"></a>Extended Globs</h1><p>You need to open it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">shopt</span> | grep extglob</span><br><span class="line"><span class="built_in">shopt</span> -s extglob</span><br></pre></td></tr></table></figure></p>
<p>For example, create test cases:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">touch file1.png photo.jpg photo photo.png file.png photo.png.jpg</span><br><span class="line">rm -f file1.png photo.jpg photo photo.png file.png photo.png.jpg</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># @(match): match one or others</span></span><br><span class="line"><span class="comment"># match photo.jpg</span></span><br><span class="line">ls photo@(.jpg)</span><br><span class="line">ls @(file)</span><br><span class="line"><span class="comment"># photo.jpg or photo.png</span></span><br><span class="line">ls photo@(.jpg|.png)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ?(match): match 0 or 1</span></span><br><span class="line">ls photo?(.jpg|.png)</span><br><span class="line"></span><br><span class="line"><span class="comment"># +(match): match 1 or more</span></span><br><span class="line">ls photo+(.jpg|.png)</span><br><span class="line"></span><br><span class="line"><span class="comment"># *(match): match 0 or more</span></span><br><span class="line">ls photo*(.jpg|.png)</span><br><span class="line"></span><br><span class="line"><span class="comment"># !(match): invert match</span></span><br><span class="line"><span class="comment"># all files that do not have photo or file name and do not end with jpg or png</span></span><br><span class="line">!(+(file|photo)*+(.jpg|.png))</span><br></pre></td></tr></table></figure>
<p>主要用在command line, <code>if condition [[ =~ ]]</code>, case condition上，比regular expression matching更快。</p>
<h1 id="Brace-Expansion"><a href="#Brace-Expansion" class="headerlink" title="Brace Expansion"></a>Brace Expansion</h1><p>这个用在比如for loop的counter, create file pre/suffix.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create file1.txt file2.txt file4.txt</span></span><br><span class="line">touch file&#123;1,2,4&#125;.txt</span><br><span class="line">touch file&#123;1..1000&#125;.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># expand from left to right, 两两组合</span></span><br><span class="line"><span class="built_in">echo</span> &#123;a..c&#125;&#123;10..15&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># specify increase step</span></span><br><span class="line"><span class="built_in">echo</span> &#123;1..100..2&#125;</span><br><span class="line"><span class="comment"># can pad heading 0</span></span><br><span class="line"><span class="built_in">echo</span> &#123;0001..10..2&#125;</span><br><span class="line"><span class="built_in">echo</span> &#123;10..0&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> &#123;a..z..2&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># can be nested</span></span><br><span class="line"><span class="built_in">echo</span> file-201&#123;1..9&#125;-&#123;0&#123;0..9&#125;,1&#123;1..2&#125;&#125;-&#123;1..30&#125;.&#123;tar,bak&#125;.&#123;tgz,bz2&#125;</span><br><span class="line"><span class="comment"># create folder structure</span></span><br><span class="line">mkdir -p 20&#123;10..20&#125;/&#123;01-12&#125;</span><br></pre></td></tr></table></figure></p>
<p>For easy copy and rename file:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># match before and after ,</span></span><br><span class="line"><span class="comment"># file file.bkp</span></span><br><span class="line">cp -f a/long/path/file&#123;,.bkp&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Regular-Expression"><a href="#Regular-Expression" class="headerlink" title="Regular Expression"></a>Regular Expression</h1><p>注意regular expression 和 globs 的区别，regular expression 是match text的，globs是 shell来扩展.</p>
<ol>
<li>match text</li>
<li>grep</li>
<li>sed</li>
<li>awk</li>
<li>if [[ =~ ]]</li>
<li>bash</li>
<li>vim</li>
</ol>
<p><a href="https://www.regular-expressions.info/" target="_blank" rel="noopener">Regular Expression Info</a><br>POSIX regular expression has basic regular expression(BRE) and extended regular expression(ERE).</p>
<p>Syntax:</p>
<ul>
<li><code>.</code> matches one char</li>
<li><code>[ ]</code> character set</li>
<li><code>\</code> escape single char</li>
<li><code>( )</code> pattern grouping</li>
<li><code>|</code> alternation</li>
<li><code>? * + { }</code> repetition operators</li>
<li><code>^abc</code> leading anchor</li>
<li><code>abc$</code> trailing anchor</li>
<li><code>[^abc]</code> netates pattern</li>
</ul>
<p>Use ERE whenever possible, regexp support in GNU tools:</p>
<ol>
<li><code>grep -E</code> ERE, <code>grep [-G]</code> default is BRE</li>
<li><code>sed -E</code> ERE, <code>sed</code> default BRE</li>
<li><code>awk</code> only supports ERE</li>
<li><code>[[ =~ ]]</code> ERE</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># match one char with zero to 3 occurances</span></span><br><span class="line">.&#123;,3&#125;</span><br><span class="line"><span class="comment"># match one char with 3 to 7 occurances</span></span><br><span class="line">.&#123;3,7&#125;</span><br><span class="line"><span class="comment"># match one char with 3 to more occurances</span></span><br><span class="line">.&#123;3,&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Backreferences"><a href="#Backreferences" class="headerlink" title="Backreferences"></a>Backreferences</h2><p>A pattern stored in a buffer to be recalled later, limit of nine for example: <code>\1</code> to <code>\9</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># \1 is (ss) pattern</span></span><br><span class="line">(ss).*\1</span><br><span class="line">(ss).*\1.*\1</span><br><span class="line"></span><br><span class="line"><span class="comment"># radar</span></span><br><span class="line"><span class="comment"># opapo</span></span><br><span class="line">^(.)(.).\2\1$</span><br></pre></td></tr></table></figure></p>
<p>POSIX ERE does not support <code>backreferences</code>, GNU version supports it.</p>
<h1 id="Bash-Extended-Regexp"><a href="#Bash-Extended-Regexp" class="headerlink" title="Bash Extended Regexp"></a>Bash Extended Regexp</h1><p>Used in <code>[[ =~ ]]</code> in if condition, it is simple to write then extended globs but less efficiency.</p>
<p>BASH_REMATCH: regular expression match, the matched text is placed into array <code>BASH_REMATCH</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[[ abcdef =~ b.d ]]</span><br><span class="line"><span class="comment"># the matched is bcd in BASH_REMATCH[0]</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;BASH_REMATCH[0]&#125;</span></span><br><span class="line"><span class="comment"># if no match BASH_REMATCH[0] is null</span></span><br></pre></td></tr></table></figure></p>
<p><code>${BASH_REMATCH[0]}</code>很有用，因为存了match的内容，如果是多个group <code>( )</code> pattern的组合，则每个group一次存放在<code>${BASH_REMATCH[0]}</code>后面。</p>
<h1 id="Grep-EREs"><a href="#Grep-EREs" class="headerlink" title="Grep EREs"></a>Grep EREs</h1><p><code>Grep</code> is global regular expression print. Stick to <code>grep -E &#39;xxxx&#39;</code>.<br><code>grep -E -w</code> only match a whole word.<br><code>grep -E -x</code> only match whole line, same as using anchors.<br><code>grep -E -o</code> only return the text that match the expression.<br><code>grep -E -q</code> quiet mode, used to verfiy existence of search item, 用于以前没有<code>[[ =~ ]]</code>的时候.</p>
<h1 id="Sed-EREs"><a href="#Sed-EREs" class="headerlink" title="Sed EREs"></a>Sed EREs</h1><p>See my Sed blog.</p>
<h1 id="Awk-EREs"><a href="#Awk-EREs" class="headerlink" title="Awk EREs"></a>Awk EREs</h1><p>Only support ERE by default, see my awk dedicated blog.</p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>regular expression</tag>
        <tag>parameter expansion</tag>
      </tags>
  </entry>
  <entry>
    <title>BASH Pipeline Demo</title>
    <url>/2019/02/24/shell-pipeline/</url>
    <content><![CDATA[<p>This blog reformats and builds on top of this <em>stackoverflow</em> <a href="https://unix.stackexchange.com/questions/30759/whats-a-good-example-of-piping-commands-together" target="_blank" rel="noopener">topic</a>. Big thanks to <strong>rahmu</strong> and people contributed.</p>
<h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>Let’s say the command <code>conky</code> stopped responding on my desktop, and I want to kill it manually. I know a little bit of Unix, so I know that what I need to do is execute the command <code>kill &lt;PID&gt;</code>. In order to retrieve the PID, I can use <code>ps</code> or <code>top</code> or whatever tool my Unix distribution has given me. But how can I do this in one command?</p>
<h3 id="Answer"><a href="#Answer" class="headerlink" title="Answer"></a>Answer</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps aux | grep conky | grep -v grep | awk <span class="string">'&#123;print $2&#125;'</span> | xargs <span class="built_in">kill</span></span><br></pre></td></tr></table></figure>
<p><em>DISCLAIMER</em>: This command only works in certain cases. Don’t copy/paste it in your terminal and start using it, it could kill processes unsuspectingly. Rather learn <strong>how to build it</strong>.</p>
<h3 id="How-it-works"><a href="#How-it-works" class="headerlink" title="How it works"></a>How it works</h3><ul>
<li><strong><code>ps aux</code></strong></li>
</ul>
<p>This command will output the list of running processes and some info about them. The interesting info is that it’ll output the PID of each process in its 2nd column. Here’s an extract from the output of the command on my box:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ps aux</span><br><span class="line"> rahmu     1925  0.0  0.1 129328  6112 ?        S    11:55   0:06 tint2</span><br><span class="line"> rahmu     1931  0.0  0.3 154992 12108 ?        S    11:55   0:00 volumeicon</span><br><span class="line"> rahmu     1933  0.1  0.2 134716  9460 ?        S    11:55   0:24 parcellite</span><br><span class="line"> rahmu     1940  0.0  0.0  30416  3008 ?        S    11:55   0:10 xcompmgr -cC -t-5 -l-5 -r4.2 -o.55 -D6</span><br><span class="line"> rahmu     1941  0.0  0.2 160336  8928 ?        Ss   11:55   0:00 xfce4-power-manager</span><br><span class="line"> rahmu     1943  0.0  0.0  32792  1964 ?        S    11:55   0:00 /usr/lib/xfconf/xfconfd</span><br><span class="line"> rahmu     1945  0.0  0.0  17584  1292 ?        S    11:55   0:00 /usr/lib/gamin/gam_server</span><br><span class="line"> rahmu     1946  0.0  0.5 203016 19552 ?        S    11:55   0:00 python /usr/bin/system-config-printer-applet</span><br><span class="line"> rahmu     1947  0.0  0.3 171840 12872 ?        S    11:55   0:00 nm-applet --sm-disable</span><br><span class="line"> rahmu     1948  0.2  0.0 276000  3564 ?        Sl   11:55   0:38 conky -q</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong><code>grep conky</code></strong></li>
</ul>
<p>I’m only interested in one process, so I use <code>grep</code> to find the entry corresponding to my program <code>conky</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ps aux | grep conky</span><br><span class="line"> rahmu     1948  0.2  0.0 276000  3564 ?        Sl   11:55   0:39 conky -q</span><br><span class="line"> rahmu     3233  0.0  0.0   7592   840 pts/1    S+   16:55   0:00 grep conky</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong><code>grep -v grep</code></strong></li>
</ul>
<p>As you can see in step 2, the command ps outputs the <code>grep conky</code> process in its list (it’s a running process after all). In order to filter it, I can run <code>grep -v grep</code>. The option<code>-v</code> tells grep to match all the lines excluding the ones containing the pattern.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ps aux | grep conky | grep -v grep</span><br><span class="line"> rahmu     1948  0.2  0.0 276000  3564 ?        Sl   11:55   0:39 conky -q</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong><code>awk &#39;{print $2}&#39;</code></strong></li>
</ul>
<p>Now that I have isolated my target process. I want to retrieve its PID. In other words I want to retrieve the 2nd word of the output. Lucky for me, most (all?) modern unices will provide some version of <code>awk</code>, a scripting language that does wonders with tabular data. Our task becomes as easy as <code>print $2</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ps aux | grep conky | grep -v grep | awk <span class="string">'&#123;print $2&#125;'</span></span><br><span class="line"> 1948</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong><code>xargs kill</code></strong></li>
</ul>
<p>I have the PID. All I need is to pass it to <code>kill</code>. To do this, I will use <code>xargs</code>.</p>
<p><code>xargs kill</code> will read from the input (in our case from the pipe), form a command consisting of <code>kill &lt;items&gt;</code> (<code>&lt;items&gt;</code> are whatever it read from the input), and then execute the command created. In our case it will execute <code>kill 1948</code>. Mission accomplished.</p>
<h3 id="Final-words"><a href="#Final-words" class="headerlink" title="Final words"></a>Final words</h3><p>Note that depending on what version of unix you’re using, certain programs may behave a little differently (for example, <code>ps</code> might output the PID in column $3). If something seems wrong or different, read your vendor’s documentation (or better, the man pages). Also be careful as <strong>long pipes can be dangerous</strong>. Don’t make any assumptions especially when using commands like <code>kill</code> or <code>rm</code>. For example, if there was another user named ‘conky’ (or ‘Aconkyous’) my command may kill all his running processes too!</p>
<h3 id="Complement"><a href="#Complement" class="headerlink" title="Complement"></a>Complement</h3><p>actually you can simplify the pipeline further to<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pkill conky</span><br></pre></td></tr></table></figure></p>
<p>or<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">kill</span> $(pgrep conky)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell Script Template</title>
    <url>/2019/09/14/shell-script-template/</url>
    <content><![CDATA[<p>This is a good script template which returns JSON response, it has exit hook, logs and arguments checking. I will continuously update it if I find good patterns. </p>
<p>Use <code>Python</code> script is more developer friendly and easy to maintain.</p>
<p>对于一般用途的script，有几点需要注意:</p>
<ol>
<li>shebang 必须有 <code>#!/usr/bin/env bash</code> or <code>#!/usr/bin/env sh</code></li>
<li>debug <code>set</code> 放开头， 如同这里一样</li>
<li>usage 函数格式要清晰，可以参考这个例子，且必须有<code>-h/--help</code> flag</li>
<li>传入的argument 要检查个数，以及是否为空</li>
<li>参数输入多多测试不同情况</li>
<li>可能需要log，可用temp 以及 exit hook解决，log放 <code>/tmp</code> directory</li>
<li>输出信息用[date time] prefix, 可以用LogMsg function wrap一下</li>
</ol>
<p>Using <code>#</code> for comment is preferred, but you can comment multi-line by heredoc:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">: &lt;&lt;<span class="string">'END_COMMENT'</span></span><br><span class="line">...</span><br><span class="line">END_COMMENT</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"><span class="comment">#########################################################################</span></span><br><span class="line"><span class="comment"># Please insert the update at top of the logs</span></span><br><span class="line"><span class="comment"># Date           Author           Description</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#########################################################################</span></span><br><span class="line"><span class="comment">## syntax check only, dry run</span></span><br><span class="line"><span class="comment">#set -n</span></span><br><span class="line"><span class="comment">## add line number for -x</span></span><br><span class="line"><span class="built_in">export</span> PS4=<span class="string">'$LINENO + '</span></span><br><span class="line"><span class="comment">## pipeline subcommand failure check</span></span><br><span class="line"><span class="built_in">set</span> -o pipefail</span><br><span class="line"><span class="comment">## e: command line failure check</span></span><br><span class="line"><span class="comment">## u: undefined variable check</span></span><br><span class="line"><span class="comment">## x: print command executed</span></span><br><span class="line"><span class="built_in">set</span> -eux</span><br><span class="line"></span><br><span class="line"><span class="comment">## find canonical file path</span></span><br><span class="line"><span class="comment">## or you can restrict run script in it's current directory</span></span><br><span class="line">CUR_PATH=$(dirname $(readlink -f <span class="variable">$0</span>))</span><br><span class="line"><span class="built_in">source</span> <span class="variable">$CUR_PATH</span>/&lt;env file&gt;</span><br><span class="line">JQ=<span class="string">"<span class="variable">$CUR_PATH</span>/jq"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## create log file for this script</span></span><br><span class="line">OUT_FILE=$(mktemp /tmp/log.XXXX)</span><br><span class="line"><span class="comment">#OUT_FILE=/tmp/log</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########################### function #########################</span></span><br><span class="line"><span class="keyword">function</span> exitHook &#123;</span><br><span class="line">  rm -f <span class="variable">$OUT_FILE</span></span><br><span class="line">  rm -f <span class="variable">$&#123;OUT_FILE&#125;</span>.out</span><br><span class="line">  rm -f <span class="variable">$&#123;OUT_FILE&#125;</span>.err</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">## clean job for log file, you can add other signals</span></span><br><span class="line"><span class="built_in">trap</span> exitHook EXIT</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">usage</span></span>() &#123;</span><br><span class="line"> <span class="built_in">echo</span> <span class="string">"&lt;Description&gt;"</span></span><br><span class="line"> <span class="built_in">echo</span></span><br><span class="line"> <span class="built_in">echo</span> <span class="string">"Usage:"</span></span><br><span class="line"> <span class="built_in">echo</span> <span class="string">"  <span class="variable">$0</span> [...]"</span></span><br><span class="line"> <span class="built_in">echo</span></span><br><span class="line"> <span class="built_in">echo</span> <span class="string">"Flags:"</span></span><br><span class="line"> <span class="built_in">echo</span> <span class="string">"  -h, --help     help info"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## this is for return json format messages</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">returnError</span></span>() &#123;</span><br><span class="line">  msg=<span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"&#123;\"result\": \"Failure\", \"message\": \"<span class="variable">$msg</span>\"&#125;"</span> |<span class="variable">$&#123;JQ&#125;</span> <span class="string">'.'</span></span><br><span class="line">  <span class="built_in">exit</span> 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">returnInfo</span></span>() &#123;</span><br><span class="line">  msg=<span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"&#123;\"result\": \"Success\", \"message\": \"<span class="variable">$msg</span>\"&#125;"</span> |<span class="variable">$&#123;JQ&#125;</span> <span class="string">'.'</span></span><br><span class="line">  <span class="built_in">exit</span> 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">########################## main ##############################</span></span><br><span class="line"><span class="comment">## declare input parameters</span></span><br><span class="line">P1=<span class="string">""</span></span><br><span class="line">P2=<span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## check script parameters</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$#</span> -eq 0 ]]; <span class="keyword">then</span></span><br><span class="line">  msg=<span class="string">"No command-line arguments were specified..."</span></span><br><span class="line">  returnError <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> [[ <span class="variable">$#</span> -gt 0 ]]</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">    -p1|--p11)</span><br><span class="line">       <span class="built_in">shift</span></span><br><span class="line">       P1=<span class="variable">$1</span></span><br><span class="line">       <span class="built_in">shift</span>;;</span><br><span class="line"></span><br><span class="line">    -p2|--p22)</span><br><span class="line">       <span class="built_in">shift</span></span><br><span class="line">       P2=<span class="variable">$1</span></span><br><span class="line">       <span class="built_in">shift</span>;;</span><br><span class="line"></span><br><span class="line">    *) msg=<span class="string">"<span class="variable">$0</span>: Bad Usage..."</span></span><br><span class="line">       returnError <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line">  <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## double check or restrict parameters</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">"X<span class="variable">$&#123;P1&#125;</span>"</span> = <span class="string">"X"</span> ]]; <span class="keyword">then</span></span><br><span class="line">  msg=<span class="string">"-p1 was not specified"</span></span><br><span class="line">  returnError <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line"><span class="keyword">elif</span> [[ <span class="string">"X<span class="variable">$&#123;P2&#125;</span>"</span> = <span class="string">"X"</span> ]]; <span class="keyword">then</span></span><br><span class="line">  msg=<span class="string">"-p2 was not specified"</span></span><br><span class="line">  returnError <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## then do the job, when you run some commands in script </span></span><br><span class="line"><span class="comment">## you can redirect the normal output to $&#123;OUT_FILE&#125;.out</span></span><br><span class="line"><span class="comment">## and error output to $&#123;OUT_FILE&#125;.err</span></span><br><span class="line"><span class="built_in">command</span> 1&gt;&gt;<span class="variable">$&#123;OUT_FILE&#125;</span>.out 2&gt;&gt;<span class="variable">$&#123;OUT_FILE&#125;</span>.err</span><br><span class="line"><span class="keyword">if</span> [[ $? = 0 ]]; <span class="keyword">then</span></span><br><span class="line">    msg=<span class="string">"Run command successfully..."</span></span><br><span class="line">    returnInfo <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="comment">## parse err log file and return message</span></span><br><span class="line">    msg=$(cat <span class="variable">$&#123;OUT_FILE&#125;</span>.err|sed -e <span class="string">'s/"/\\"/g'</span>)</span><br><span class="line">    returnError <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Source vs Execute Script</title>
    <url>/2019/05/07/shell-source-vs-execute/</url>
    <content><![CDATA[<p>Understand the difference between <code>source</code> and execute a script is important, otherwise you will be confused why something doesn’t run as you expect.</p>
<h1 id="Source-Script"><a href="#Source-Script" class="headerlink" title="Source Script"></a>Source Script</h1><p>The file may <strong>not</strong> necessary to be a executable (<code>chmod -x</code>) but should be valid shell script. We usually use <code>source</code> to load shell functions and export environment variables into current shell process.</p>
<p>For example, both syntax are good:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ./xx.env</span><br><span class="line">. ./xx.env</span><br></pre></td></tr></table></figure></p>
<p>注意<code>source</code> 在当前上下文中执行脚本，不会生成新的进程！！执行完毕后回到当前进程。</p>
<blockquote>
<p>Note that <code>.</code> is not an alias for <code>source</code>, but rather the other way around. <code>source</code> is a bash extension, while <code>.</code> works in any POSIX compatible shell.</p>
</blockquote>
<p>You can also put the file path in <code>$PATH</code> so that you don’t need to specify the path in command.</p>
<h1 id="Execute-Script"><a href="#Execute-Script" class="headerlink" title="Execute Script"></a>Execute Script</h1><p>The file is <strong>executable</strong> (<code>chmod +x</code>) and you are in right permission to run it. And you need to specify the path even in current directory, or put path in <code>$PATH</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./xx.sh</span><br></pre></td></tr></table></figure></p>
<p>The current shell spawns a new shell to run the script. The script is running in the new shell and all changes to the environment only in the new shell. After the script is done all changes to the environment in the new shell are destroyed.</p>
<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>Use execution method will run the script as another process, so variables and functions in child script will not be accessible in parent shell. </p>
<p>The <code>source</code> method executes the child script in the parent script’s process, the parent process can access the variabels or functions in child script. If you are using <code>exit</code> in script, it will exit the parent script as well. Which will not happen in execution method.</p>
<h1 id="exec-Command"><a href="#exec-Command" class="headerlink" title="exec Command"></a>exec Command</h1><p><code>exec</code> command, 这个命令在docker container的entry script中很常见:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=nwm7rJG90i8" target="_blank" rel="noopener">https://www.youtube.com/watch?v=nwm7rJG90i8</a></li>
<li><a href="https://askubuntu.com/questions/819910/what-are-possible-use-of-exec-command" target="_blank" rel="noopener">https://askubuntu.com/questions/819910/what-are-possible-use-of-exec-command</a></li>
</ul>
<p>此外还有<code>su-exec</code> 命令，但这个不是built-in的:<br><a href="https://github.com/ncopa/su-exec" target="_blank" rel="noopener">https://github.com/ncopa/su-exec</a></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell Process Demystify</title>
    <url>/2019/06/02/shell-subshell/</url>
    <content><![CDATA[<p>Understanding how <code>SHELL</code> works under the hood is a must for me, I have encountered several interesting and confusing issues in my daily work about <code>SHELL</code>. Let’s dive deeply into shell process and its relationships to explore how subshells are created and their relationship to the parent shell; The varied commands that create child processes are explored as well as built-in commands.</p>
<h2 id="Shell-Type"><a href="#Shell-Type" class="headerlink" title="Shell Type"></a>Shell Type</h2><p>Due to the <code>bash</code> shell’s popularity, it’s rare to use any other shell as a default shell.</p>
<p>The <code>default interactive shell</code> starts whenever a user logs into a virtual console terminal or starts a terminal emulator in the GUI. Another default shell, <code>/bin/sh</code>, is the <code>default system shell</code>. The <code>default system shell</code> is used for system shell scripts, such as those needed at startup.</p>
<p>In my Redhat and CentOS system, actually they are the same:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lrwxrwxrwx. 1 root root 4 Apr 13  2018 /bin/sh -&gt; bash</span><br></pre></td></tr></table></figure></p>
<p>To see the default user login shell, go to see <code>/etc/passwd</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fyre:x:1000:1000::/home/fyre:/bin/bash</span><br><span class="line">demo:x:1001:1001::/home/demo:/bin/bash</span><br></pre></td></tr></table></figure></p>
<h2 id="Shell-Relationships"><a href="#Shell-Relationships" class="headerlink" title="Shell Relationships"></a>Shell Relationships</h2><p>You can use <code>ps -f</code> to see difference before you run <code>bash</code>(child) in a shell(parent):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root      7762  7758  0 Jun03 pts/0    00:00:00 -bash</span><br><span class="line">root     14957  7762  0 17:12 pts/0    00:00:00 bash</span><br><span class="line">root     15028 14957  0 17:13 pts/0    00:00:00 ps -f</span><br></pre></td></tr></table></figure></p>
<p>Here PID <code>14957</code> has parent <code>7762</code>.</p>
<p>A child shell is also called a <strong>subshell</strong>. A subshell can be created from a parent shell, and a subshell can be created from another subshell:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps --forest</span><br></pre></td></tr></table></figure></p>
<p>can be used to show the nesting of the subshells. For example, run <code>bash</code> 3 times:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps --forest -f</span><br><span class="line"></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root      7762  7758  0 Jun03 pts/0    00:00:00 -bash</span><br><span class="line">root      2264  7762  0 23:52 pts/0    00:00:00  \_ bash</span><br><span class="line">root      2467  2264  0 23:55 pts/0    00:00:00      \_ bash</span><br><span class="line">root      2487  2467  0 23:55 pts/0    00:00:00          \_ bash</span><br><span class="line">root      2510  2487  0 23:55 pts/0    00:00:00              \_ ps --forest -f</span><br></pre></td></tr></table></figure></p>
<h2 id="Constructs-Create-SubShell"><a href="#Constructs-Create-SubShell" class="headerlink" title="Constructs Create SubShell"></a>Constructs Create SubShell</h2><p>Refer to this <a href="https://unix.stackexchange.com/questions/442692/is-a-subshell" target="_blank" rel="noopener">what is a subshell</a></p>
<blockquote>
<p>Note subshells are often used for multi-processing in shell scripts. However, entering into a subshell is an expensive method and can significantly slow down processing.</p>
</blockquote>
<p>A subshell is typically implemented by <code>forking</code> a new process (but some shells may optimize this in some cases).</p>
<ul>
<li><p>Subshell for grouping: <code>(...)</code> does nothing but create a subshell and <strong>wait</strong> for it to terminate. Contrast with <code>{...}</code> which groups commands purely for syntactic purposes and does not create a subshell.</p>
</li>
<li><p>Background <code>&amp;</code>: creates a subshell and does not wait for it to terminate.</p>
</li>
<li><p>Pipeline: <code>|</code> creates two subshells, one for the left-hand side and one for the right-hand side, and waits for both to terminate. The shell creates a pipe and connects the left-hand side’s standard output to the write end of the pipe and the right-hand side’s standard input to the read end. In some shells (ksh88, ksh93, zsh, bash with the lastpipe option set and effective), the right-hand side runs in the original shell, so the pipeline construct only creates one subshell.</p>
</li>
<li><p>Command substitution: <code>$()</code> creates a subshell with its standard output set to a pipe, collects the output in the parent and expands to that output, minus its trailing newlines. (And the output may be further subject to splitting and globbing, but that’s another story.)</p>
</li>
<li><p>Process substitution: <code>&lt;()</code> creates a subshell with its standard output set to a pipe and expands to the name of the pipe. The parent (or some other process) may open the pipe to communicate with the subshell. <code>&gt;()</code> does the same but with the pipe on standard input.</p>
</li>
<li><p>Coprocess: <code>coproc</code> creates a subshell and does not wait for it to terminate. The subshell’s standard input and output are each set to a pipe with the parent being connected to the other end of each pipe.</p>
</li>
</ul>
<h3 id="Process-List"><a href="#Process-List" class="headerlink" title="Process List"></a>Process List</h3><p>For a command list to be considered a <code>process list</code> (a grouping), the commands must be encased in parentheses <code>()</code>. Adding parentheses and turning the command list into a process list created a subshell to execute the commands.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># echo $BASH_SUBSHELL</span><br><span class="line">0</span><br><span class="line"></span><br><span class="line"># (echo $BASH_SUBSHELL)</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line"># ( (echo $BASH_SUBSHELL) ) </span><br><span class="line">2</span><br></pre></td></tr></table></figure></p>
<p>For parent variables act in subshell <code>()</code>, from <a href="https://stackoverflow.com/questions/26079488/bash-subshell-mystery" target="_blank" rel="noopener">this</a>, <a href="https://unix.stackexchange.com/questions/157957/why-is-a-variable-visible-in-a-subshell?noredirect=1&amp;lq=1" target="_blank" rel="noopener">this</a> and <a href="https://unix.stackexchange.com/questions/138463/do-parentheses-really-put-the-command-in-a-subshell?noredirect=1&amp;lq=1" target="_blank" rel="noopener">this</a> posts, long story short: Subshell <code>()</code> inherit all variables. Even <code>$$</code> (the PID of the original shell) is kept. The reason is that for a subshell, the shell just <strong>forks</strong> and doesn’t execute a new shell (such as run a script <code>./xx</code>)</p>
<blockquote>
<p>Note, usually use subshell <code>()</code> with <code>&amp;</code>.</p>
</blockquote>
<h3 id="Background-mode"><a href="#Background-mode" class="headerlink" title="Background mode"></a>Background mode</h3><p>Background mode is very handy. And it provides a method for creating useful subshells at the CLI.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># jobs -l</span><br><span class="line"></span><br><span class="line">[1]+  7552 Running                 sleep 40 &amp;</span><br></pre></td></tr></table></figure></p>
<p><code>[1]</code> is job number, <code>7552</code> is PID, then <code>Running</code> is job status. The <code>jobs</code> command displays <strong>any</strong> user’s processes (jobs) currently running in background mode:</p>
<p>Using a <code>process list</code> in background mode is one creative method for using subshells at the CLI. Remember we start Jetty in conductor container? <code>docker load</code> and <code>scp</code> are also suitable for background execution sometimes.</p>
<h3 id="Co-processing"><a href="#Co-processing" class="headerlink" title="Co-processing"></a>Co-processing</h3><p>Co-processing performs almost identically to putting a command in background mode, <strong>except</strong> for the fact that it creates a subshell.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coproc sleep 2</span><br><span class="line">[1] 8174</span><br><span class="line"></span><br><span class="line">[1]+  Done                    coproc COPROC sleep 2</span><br></pre></td></tr></table></figure></p>
<p>it the same as:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># (sleep2) &amp;</span><br></pre></td></tr></table></figure></p>
<p>The <code>COPROC</code> is a name given to the porcess, you can change it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coproc My_Job &#123; sleep 10; &#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>The only time you need to name a co-process is when you have multiple co-processes running, and you need to communicate with them all. Otherwise, just let the coproc command set the name to the default, <code>COPROC</code>.</p>
</blockquote>
<p>This will create a nested subshell:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coproc ( sleep 10; sleep 2 )</span><br></pre></td></tr></table></figure></p>
<h3 id="My-question"><a href="#My-question" class="headerlink" title="My question"></a>My question</h3><p>Remember in conductor container we start Jetty using the <code>(...) &amp;</code>. We want to run it in a separate process in background. Why not just <code>&amp;</code>? So If I want to run something in background, should I use <code>&amp;</code> to put command in background or <code>()&amp;</code> to put subshell in background?</p>
<p>I haven’t fully understaned it, refer to my <a href="https://unix.stackexchange.com/questions/523675/run-script-in-background-using-or" target="_blank" rel="noopener">post</a>.</p>
<h2 id="Shell-Build-in-Commands"><a href="#Shell-Build-in-Commands" class="headerlink" title="Shell Build-in Commands"></a>Shell Build-in Commands</h2><p>An external command, sometimes called a filesystem command, is a program that exists outside of the bash shell. They are not built into the shell program. An external command program is typically located in <code>/bin</code>, <code>/usr/bin</code>, <code>/sbin</code>, or <code>/usr/sbin</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># which ps</span><br><span class="line">/usr/bin/ps</span><br><span class="line"></span><br><span class="line"># type -a ps</span><br><span class="line">ps is /usr/bin/ps</span><br></pre></td></tr></table></figure></p>
<p>Whenever an external command is executed, a child process is created. This action is termed <code>forking</code>. It takes time and effort to set up the new child process’s environment. Thus, external commands can be a little expensive.</p>
<p>When using a built-in command, no forking is required. Therefore, built-in commands are less expensive.</p>
<p>Built-in commands are different in that they do not need a child process to execute. They were compiled into the shell and thus are part of the shell’s toolkit.</p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell timeout Command</title>
    <url>/2019/09/04/shell-timeout/</url>
    <content><![CDATA[<p><code>timeout</code> command used to run command with a time limit. One case is when you know exactly how long you want a process to run for. A common use-case is to have timeout control a logging or data-capture program so that the log files don’t relentlessly devour your hard drive space.</p>
<p>Another case is when you don’t know how long you want a process to run for, but you do know you don’t want it to run indefinitely. You might have a habit of setting processes running, minimizing the terminal window, and forgetting about them. For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">timeout 12 ping 127.0.0.1</span><br></pre></td></tr></table></figure></p>
<p>By default 12 is second unit, to use a time value measured in minutes, hours or days add an <code>m</code>, <code>h</code> or a <code>d</code>.</p>
<h2 id="Send-Right-Signal"><a href="#Send-Right-Signal" class="headerlink" title="Send Right Signal"></a>Send Right Signal</h2><p>When <code>timeout</code> wants to stop a program it sends the <code>SIGTERM</code> signal. This politely asks the program to terminate. Some programs may choose to ignore the <code>SIGTERM</code> signal. When that happens, we need to tell timeout to be a little more forceful.</p>
<p>Send <code>KILL</code> signal if program is still running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">timeout -s SIGKILL 10 sudo tcpdump &gt; capture.txt</span><br></pre></td></tr></table></figure></p>
<p>We can use the <code>-s (signal)</code> option to tell timeout to send the <code>SIGKILL</code> signal.</p>
<p>Or give it a buffer:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">timeout -k 20 10 sudo tcpdump &gt; capture.txt</span><br></pre></td></tr></table></figure></p>
<p>we use the <code>-k (kill after)</code> option. The <code>-k</code> option requires a time value as a parameter. If tcpdump is still running after 20 seconds, it means the <code>SIGTERM</code> was ignored and timeout should send in <code>SIGKILL</code> to finish the job.</p>
<h2 id="Retrieving-the-Program’s-Exit-Code"><a href="#Retrieving-the-Program’s-Exit-Code" class="headerlink" title="Retrieving the Program’s Exit Code"></a>Retrieving the Program’s Exit Code</h2><p><code>timeout</code> provides its own exit code, The exit code is <code>124</code>. This is the value timeout uses to indicate the program was terminated using SIGTERM.</p>
<p>But we may not care about that. We are probably more interested in the exit code from the process that timeout is controlling.</p>
<p>If the execution of the program ends <strong>before</strong> timeout terminates it, timeout <strong>can</strong> pass the exit code from the program back to the shell. (no need <code>--preserve-status</code>)</p>
<p>we must use the <code>--preserve-status</code> option if the program timeout but we still want to get its status exit code! For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">timeout --preserve-status 10 &lt;program&gt;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">##Start Engine Conductor</span></span><br><span class="line">LogMsg <span class="string">"Starting Engine Conductor Pod..."</span></span><br><span class="line">(<span class="built_in">cd</span> <span class="variable">$BASE</span>/Engine/engine-conductor; <span class="built_in">pwd</span>; ./createConductorDepAndSvc.sh <span class="variable">$NAME_SPACE</span> <span class="variable">$ENGINE_HOST</span>)</span><br><span class="line">check_return_code $?</span><br><span class="line">conductor_pod=$(kubectl get pods -n <span class="variable">$NAME_SPACE</span> | grep -i -E <span class="variable">$POD_STATES</span> | grep -v NAME|awk <span class="string">'&#123;print $1&#125;'</span>|grep <span class="variable">$ENGINE_HOST</span>)</span><br><span class="line"><span class="comment">##Check for Engine  background processes to complete</span></span><br><span class="line">timeout --preserve-status 3.0m cat &lt;(check_k8s_start_loop <span class="variable">$conductor_pod</span> 7 <span class="variable">$NAME_SPACE</span>)</span><br><span class="line">check_timeout_return $? <span class="variable">$conductor_pod</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>what is <code>cat &lt;()</code>?<br><code>a &lt;(b)</code> replaces the argument to <code>a</code> with an named pipe. <code>a</code> and <code>b</code> run in parallel. </p>
</blockquote>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Socket Quick Start</title>
    <url>/2020/09/13/socket-learn/</url>
    <content><![CDATA[<p>//TODO:</p>
<ol>
<li>python <code>socket</code> module demos: <a href="https://pymotw.com/2/socket/uds.html" target="_blank" rel="noopener">https://pymotw.com/2/socket/uds.html</a></li>
</ol>
<p>最近在做Proxy的工作，重新回顾和学习了很多相关的东西，这里把Socket的分类和概念梳理一下。</p>
<h1 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h1><p><a href="https://en.wikipedia.org/wiki/Socket" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Socket</a></p>
<ul>
<li><code>Network socket</code>, an end-point in a bidirectional communication across a network or the Internet</li>
<li><code>Unix domain socket</code>, an end-point in local bidirectional inter-process communication</li>
<li><code>socket()</code>, a system call defined by the Berkeley sockets API</li>
</ul>
<p><a href="https://serverfault.com/a/124518" target="_blank" rel="noopener">Unix socket vs Network socket</a></p>
<h2 id="Unix-Domain-Socket"><a href="#Unix-Domain-Socket" class="headerlink" title="Unix Domain Socket"></a>Unix Domain Socket</h2><p><a href="https://en.wikipedia.org/wiki/Unix_domain_socket" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Unix_domain_socket</a><br>A <strong>Unix domain socket</strong> or <strong>IPC socket</strong> (inter-process communication socket) is a data communications endpoint for exchanging data between processes executing on the same host operating system. </p>
<blockquote>
<p><code>IPC</code> 也是一种概念，有多种实现的方式。</p>
</blockquote>
<p>The API for Unix domain sockets is similar to that of an Internet socket, but rather than using an underlying network protocol, all communication occurs entirely within the operating system kernel. Unix domain sockets may use the file system as their address name space. (Some operating systems, like Linux, offer additional namespaces.) Processes reference Unix domain sockets as file system inodes, so two processes can communicate by opening the same socket.</p>
<p>Valid socket types in the UNIX domain are:</p>
<ul>
<li>SOCK_STREAM (compare to TCP) – for a stream-oriented socket</li>
<li>SOCK_DGRAM (compare to UDP) – for a datagram-oriented socket that preserves message boundaries (as on most UNIX implementations, UNIX domain datagram sockets are always reliable and don’t reorder datagrams)</li>
<li>SOCK_SEQPACKET (compare to SCTP) – for a sequenced-packet socket that is connection-oriented, preserves message boundaries, and delivers messages in the order that they were sent</li>
</ul>
<h2 id="Network-Socket"><a href="#Network-Socket" class="headerlink" title="Network Socket"></a>Network Socket</h2><p>仔细读一下维基, network socket是指一种连接，这种连接有很多具体的实现方法。<br><a href="https://en.wikipedia.org/wiki/Network_socket" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Network_socket</a><br>Also referred to as <strong>Internet socket</strong>.</p>
<p>A network socket is a software structure within a network node of a computer network that serves as an endpoint for sending and receiving data across the network. The structure and properties of a socket are defined by an application programming interface (API) for the networking architecture. Sockets are created only during the lifetime of a process of an application running in the node.</p>
<p><code>Socket Address</code> is comprised of:</p>
<ul>
<li>protocol type</li>
<li>IP address</li>
<li>port number</li>
</ul>
<p>On Unix-like operating systems and Microsoft Windows, the command-line tools <code>netstat</code> or <code>ss</code> are used to list established sockets and related information.</p>
<p>Several <strong>types</strong> of Internet socket are available:</p>
<ul>
<li>Datagram sockets: connectless sockets, which use UDP.</li>
<li>Stream sockets: connection-oriented sockets, which use TCP.</li>
<li>Raw sockets: IP packet.</li>
</ul>
<h2 id="Berkeley-Sockets"><a href="#Berkeley-Sockets" class="headerlink" title="Berkeley Sockets"></a>Berkeley Sockets</h2><p><a href="https://en.wikipedia.org/wiki/Berkeley_sockets" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Berkeley_sockets</a><br>Berkeley sockets is an application programming interface (API) for <strong>Internet sockets</strong> and <strong>Unix domain sockets</strong>, used for inter-process communication (IPC). 是以上几个socket的一种统一的抽象表示。</p>
<p>The term <strong>POSIX sockets</strong> is essentially synonymous with <strong>Berkeley sockets</strong>, but they are also known as <strong>BSD sockets</strong>.</p>
]]></content>
      <categories>
        <category>Socket</category>
      </categories>
      <tags>
        <tag>socket</tag>
      </tags>
  </entry>
  <entry>
    <title>Variables in Shell</title>
    <url>/2019/06/02/shell-variables/</url>
    <content><![CDATA[<p>This article talks about the <code>variable scope</code> in shell, especially how to access variables between different scripts.</p>
<h1 id="Local-Variables"><a href="#Local-Variables" class="headerlink" title="Local Variables"></a>Local Variables</h1><p>The <code>set</code> command displays <strong>all</strong> functions and local variables defined for a specific process:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># this definition will be in `set`, not in `env`</span></span><br><span class="line">HELLO=999</span><br><span class="line"><span class="comment"># run `set` will see `HELLO`</span></span><br><span class="line"><span class="built_in">set</span></span><br></pre></td></tr></table></figure></p>
<p>It also sorts the display alphabetically.</p>
<p>注意<code>set</code>中的variables 不一定出现在<code>env</code>中，顾名思义, <code>env</code>中显示的才是当前运行shell会被采用的variables.</p>
<h1 id="ENV-Variables"><a href="#ENV-Variables" class="headerlink" title="ENV Variables"></a>ENV Variables</h1><p>Environment variables are visible from the shell session and from <strong>any</strong> spawned child subshells, and also visable by the command launched from that shell. This makes environment variables useful in applications that create child subshells, which require parent shell information.</p>
<p>To view environment variables, use the <code>env</code> or the <code>printenv</code> command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">env | grep ^HOME</span><br><span class="line">printenv HOME</span><br></pre></td></tr></table></figure></p>
<p>You can use <code>export</code> to create environment variable.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> demo=<span class="string">'hello world'</span></span><br></pre></td></tr></table></figure></p>
<p>You can use <code>unset</code> to remove an existing environment variable.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">unset</span> demo</span><br></pre></td></tr></table></figure></p>
<p>If you want to only set the variable for one command in one use, just prefix it, eg:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># EDITOR will only works for crontab command</span></span><br><span class="line">EDITOR=vim crontab -e</span><br><span class="line"><span class="comment"># hot KUBECONFIG env variable</span></span><br><span class="line">KUBECONFIG=xx.yml kubectl get nodes</span><br></pre></td></tr></table></figure></p>
<p>A common trick for programmers is to include the <code>single dot</code> symbol in their <code>PATH</code> environment variable. The single dot symbol represents the current directory:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PATH=<span class="variable">$PATH</span>:.</span><br></pre></td></tr></table></figure></p>
<h1 id="Declare-Command"><a href="#Declare-Command" class="headerlink" title="Declare Command"></a>Declare Command</h1><p>Note that <code>declare</code> can print both <code>set</code> and <code>env</code> variables:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">declare</span> | grep ^HOME=</span><br></pre></td></tr></table></figure></p>
<p><code>declare</code> command can be used to create local variables in <code>set</code> or export to <code>env</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># -i: integer</span></span><br><span class="line"><span class="built_in">declare</span> -i n=34</span><br><span class="line"><span class="comment"># can do arithmetic operations directly without let or expr</span></span><br><span class="line">n=n/2</span><br><span class="line"><span class="comment"># the result is 17</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$n</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># -l: convert to lower case</span></span><br><span class="line"><span class="built_in">declare</span> -l hello=WORLD</span><br><span class="line"><span class="comment"># -u: convert to upper case</span></span><br><span class="line"><span class="built_in">declare</span> -u hello=world</span><br><span class="line"><span class="comment"># if reassign value to hello, will be convert to lower/upper case automatically</span></span><br><span class="line"></span><br><span class="line">hello=world</span><br><span class="line"><span class="comment"># -p: display the attributes and values of each name</span></span><br><span class="line"><span class="built_in">declare</span> -p hello</span><br><span class="line"><span class="comment">## result is below, -- means local variable with no options compare to others like -x -i, etc</span></span><br><span class="line"><span class="built_in">declare</span> -- hello=<span class="string">"world"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## declare can also export variable</span></span><br><span class="line"><span class="built_in">declare</span> -x apple=123</span><br><span class="line"><span class="comment">## will see apple in env</span></span><br><span class="line">env | grep apple</span><br><span class="line"></span><br><span class="line"><span class="built_in">declare</span> -p apple</span><br><span class="line"><span class="comment">## result is below, -x means exported variable</span></span><br><span class="line"><span class="built_in">declare</span> -x apple=<span class="string">"123"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## remove from env</span></span><br><span class="line"><span class="built_in">declare</span> +x apple</span><br></pre></td></tr></table></figure></p>
<p>You can mix the option:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">declare</span> -x -l EDITOR</span><br><span class="line">EDITOR=vIM</span><br><span class="line"></span><br><span class="line"><span class="built_in">declare</span> -p EDITOR</span><br><span class="line"><span class="comment">## auto fix it to lower case</span></span><br><span class="line"><span class="built_in">declare</span> -xl EDITOR=<span class="string">"vim"</span></span><br></pre></td></tr></table></figure></p>
<p>Create constant (read-only) variable, cannot be unset and sustain for the shell session:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## set name as readonly</span></span><br><span class="line"><span class="built_in">declare</span> -r name=bob</span><br><span class="line"><span class="comment">## export it and readonly</span></span><br><span class="line"><span class="built_in">declare</span> -xr name=alice</span><br><span class="line"><span class="comment">## define a readonly array</span></span><br><span class="line"><span class="built_in">declare</span> -ra array=(1 2 3 4)</span><br></pre></td></tr></table></figure></p>
<p>Declare different kind of arrays, see my other blog <a href="https://chengdol.github.io/2019/08/13/shell-array/" target="_blank" rel="noopener"><code>Array in Script</code></a>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## index-based</span></span><br><span class="line"><span class="built_in">declare</span> -a user_name</span><br><span class="line"><span class="comment">## associated-based</span></span><br><span class="line"><span class="built_in">declare</span> -A user_name</span><br></pre></td></tr></table></figure></p>
<h1 id="Shell-Variables"><a href="#Shell-Variables" class="headerlink" title="Shell Variables"></a>Shell Variables</h1><p>Shell variables (actually the local variable) are available <strong>only</strong> in the shell that creates them. In fact, the Linux system also defines standard shell environment variables for you by default. </p>
<p>How to define a Shell environment variable:<br><strong>No</strong> space can appear between the variable, the equal sign, and the value:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">var1=value</span><br></pre></td></tr></table></figure></p>
<p>Variables defined within the shell script maintain their values throughtout the life of the shell script but are vanished when the shell script completes.</p>
<p>If you want to assign the value of one variable to another, must use <code>$</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">var2=<span class="variable">$&#123;var1&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>otherwise, <code>var1</code> will be interpreted as text string.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">var2=var1</span><br></pre></td></tr></table></figure></p>
<h1 id="Variable-Scope"><a href="#Variable-Scope" class="headerlink" title="Variable Scope"></a>Variable Scope</h1><p>My question is how to pass variables from one script to another?<br>Basically there are 3 options:</p>
<ol>
<li><p>Make the variable an environment variable (<code>export</code> it) before calling the child script (<code>./script2</code>).</p>
</li>
<li><p><code>source</code> the child script and it will run in the same shell, This would let you share more complex variables like arrays easily, but also means that the other script could modify variables in the caller shell.</p>
</li>
<li><p>pass as parameters to child script: <code>./script2 var1 var2</code></p>
</li>
<li><p>if use <code>exec</code> to replace current process, still need export variable.</p>
</li>
</ol>
<h1 id="Preserve-ENV-variables"><a href="#Preserve-ENV-variables" class="headerlink" title="Preserve ENV variables"></a>Preserve ENV variables</h1><p>Refer to <a href="https://unix.stackexchange.com/questions/188144/why-is-a-variable-passed-to-the-su-command-but-not-an-array-from-the-same-scope" target="_blank" rel="noopener">this</a> question. This is interesting and easy to make mistake, if I want to preserve global ENV variable when switch user in shell, use <code>su xxx</code> instead of <code>su - xxx</code>, <code>-</code> option will do:</p>
<ol>
<li>clears all environment variables except for TERM</li>
<li>initializes the environment variables HOME, SHELL, USER, LOGNAME, PATH</li>
<li>changes to the target user’s home directory</li>
<li>sets argv[0] of the shell to ‘-‘ in order to make the shell a login shell</li>
</ol>
<p>But be very careful not let shell do variable expanding in command option:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su xxx -c <span class="string">"... echo <span class="variable">$a</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>Here <code>$a</code> will be expanded before executing, use single quote or escape the <code>$</code> sign:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su xxx -c <span class="string">'... echo $a'</span></span><br><span class="line">su xxx -c <span class="string">"... echo \$a"</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Daily Talk</title>
    <url>/2019/04/11/softskill-daily-talk/</url>
    <content><![CDATA[<blockquote>
<p>04/30/2020 目前来看，感受是我的职业发展一大障碍并不是技术，而是soft skills，比如如何高效直接又不失礼貌的<strong>沟通</strong> (not just what you say but how you say it!!!)，how to email, phone call effectively，如何协作多个团队以及个人，以及管理一个团队(interpersonal skill)。PluralSight上这方面的课程很不错，也有一些BQ相关的书籍需要阅读。总之，这非常重要！</p>
</blockquote>
<h1 id="Dialog"><a href="#Dialog" class="headerlink" title="Dialog"></a>Dialog</h1><h2 id="Dail-in"><a href="#Dail-in" class="headerlink" title="Dail in"></a>Dail in</h2><p>(not hear clearly) Sorry, I miss some points. I didn’t hear you.<br>Are your voice broken?</p>
<p>Who do we have on the call?<br>Do you want to go first?</p>
<p>This is from SVL, we have x1 x2 and myself, we are waiting for x3 to dail in.<br>only three of us here</p>
<p>go ahead badal…<br>we are waiting for more folks to join.</p>
<p>xx is on her way.<br>Even I saw her.</p>
<h2 id="Meeting"><a href="#Meeting" class="headerlink" title="Meeting"></a>Meeting</h2><ol>
<li>Introduce yourself</li>
<li>Articulate High level design and questions<br>feel free to interrupt if you have any questions.<br>let me know if you have questions so far.</li>
<li>If you can provided code fragment, resources</li>
<li>Chat normally</li>
<li>Bye</li>
</ol>
<p>Do you go by xxx?  你用过xxx这个名字吗？</p>
<h2 id="Describe-Problem"><a href="#Describe-Problem" class="headerlink" title="Describe Problem"></a>Describe Problem</h2><p>obscure problems came up.</p>
<p>some of the files must have setuid bit set in order to function properly.<br>run something without killing my setuid bit?<br>Jaijeet can take the topic.</p>
<p>(别再说 I don’t know了😂)<br>it’s unknown to me.<br>It’s a complete black box to me.<br>I don’t have answer to this question.<br>I don’t have answer to all of these now.<br>I cannot make any promise now.<br>It’s hard to have a binary answer yes or no.</p>
<p>I ran into the same issue.<br>I don’t want to clutter/mess up the cluster…<br>Is there any workaround for this?</p>
<p>let us talk over on this on monday - seems convoluted (费解的).</p>
<p>not sure it’s possible or not</p>
<p>So what happends right now …<br>what happening is that …<br>How come the output file is missing ..</p>
<p>Let me know if any issues.<br>What is your opinion Badal?</p>
<p>Elaborate the reason, open the git issue if necessary. We need to understand the problem exactly.</p>
<p>I would say don’t do that.<br>we do have this fix.<br>I will take a look at it today.</p>
<p>They didn’t articulate what need to test.</p>
<p>I haven’t got time to stay with Deep to discuss…<br>That’s what I am discussing with you.<br>We don’t have anything to lose.</p>
<p>we are still facing the issue.<br>Something is failing intermittently, hard to figure it out what is the problem.</p>
<p>What am I supposed to conclude?</p>
<p>I take what I said back.<br>I am still struggleing myself for this issue.</p>
<p>Nothing is working, we need to engage UI team,  API team.<br>I am able to open the defect (ticket/issue) but not able to assign.</p>
<p>It is much easier said then done.<br>It is a big list <code>but by no means</code> it is a exhausted list</p>
<p>Make sure that it stays a useful tool and doesn’t become a maintenance headache/nightmare.</p>
<p>check out(pull)/in(push) the code (github).</p>
<p>Other things are more or less similar.<br>There are a few notable differences from …</p>
<p>go/read through ..<br>sth is populated from … 什么被什么填充</p>
<p>analogy to sth. 类比什么<br>After updates, take the appropriate next steps.</p>
<p>OLM is an evolving project. As such, be sure to <code>consult</code> its GitHub repository to find the latest installation instructions</p>
<p>It is commonly understood as the <code>elapsed time</code>/<code>lag time</code> between a request and its completion.</p>
<p>I don’t get your question?</p>
<p>From the technical perspective,…<br>As oppose to running locally using docker compose, use kubernetes right away so you can spot the problems early.</p>
<p>Sorry for confusion,…</p>
<h2 id="Progress"><a href="#Progress" class="headerlink" title="Progress"></a>Progress</h2><p>Give me 1 hour please, in the middile of something.</p>
<p>I have some pending items.</p>
<p>It’s a overkill for me.</p>
<p>I was primarily working on …<br>I would suggest…</p>
<p>I did’t make much progress yesterday.</p>
<p>I am going to mimic what you did.<br>I will continue on the effort to …</p>
<p>we need to do that standalone..<br>I haven’t started, it will not take too long.</p>
<p>Kannu covered a lot we did last week.</p>
<p>This is a <code>ad hoc task</code>. (Ad hoc tasks are work items that can be created extemporaneously that are not initially part of a modeled process flow)</p>
<p>Anything else on your side?</p>
<p>That is my status.<br>That is all in my side.</p>
<p>(什么时候完成?)<br>When do you think you can put these in place?</p>
<p>This is our major block.<br>We plan to finish it by 8/28 or schedule need to be extended.<br>Please let me know ASAP as I have to report to …</p>
<p>I am done, can I go/drop?<br>The things left for me are …<br>it’s not <code>urgent</code>.</p>
<p>I will let someone know and ask .. so we get <code>immidiate attention</code>.<br>more or less the same<br>Is this still something that needs attention? It is unclear from the comments. Pl advise.<br>Also DM(direct message) me the cluster info if this still needs attention.</p>
<p>I need to go back and see all the notes.<br>go over your notes</p>
<p>There may be some potential issues we cannot see right now.<br>To be complete, let me mention …</p>
<p>XX seems to be waiting on some inputs.<br>Do you think a discuss with XX will help?</p>
<p>I am not sure what do we need to proceed here.</p>
<p>Let’s keep debug details aside (放一边) and proceed with …<br>For now we leave the .. outside until we figure it out.</p>
<p>Meanwhile(in parallel) 与此同时做什么</p>
<p>Not sure how far did you get with debugging?<br>Need some time, since I am not admin.</p>
<h2 id="Office-Talk"><a href="#Office-Talk" class="headerlink" title="Office Talk"></a>Office Talk</h2><p>examine/outline sth.<br>iterating over time 如此往复..<br>sth is discernable in .. 有迹可循</p>
<p>I will sync up/ set with you later…<br>We are on the same page now.<br>Hopefully we can walk through the doc and fill in the existing gaps and identify any others.</p>
<p>I’m not familiar with this.. I’ll have a look later today and will let you know if I figure out how it works.</p>
<p>强硬催人:<br>Sorry for the push. When you have some time - please do check and let us know.<br>Please let know.<br>Any luck with someone?</p>
<p>I just stop by.<br>can you come over?</p>
<p>Hi chengdol, can you come to my office for a sec?</p>
<p>My bad for not being clear, I was specifically asking about<br>Apologize for the long delay…</p>
<p>One query, …</p>
<p>if you have bandwidth you can start to work on ….</p>
<p>Can you give me a quick overview about …, share with us.</p>
<p>Distracted by the conversations…<br>will find comfort room to dail in</p>
<p>Thanks, this is a big call.<br>Appreciate someone’s services to something.</p>
<p>we have a hard stop at 11:00AM (for meeting)</p>
<p>you raise/give a bunch of information..</p>
<p>can I drop off（挂断） or stay here?<br>This issue sometime surfaces.</p>
<p>Is your system back on line?<br>Getting system up today.</p>
<p>users are allowed to elevate their privileges to root.<br>we don’t want to escalate this issue..<br>we will raise this question to XX team and get approval for not using it.</p>
<p>I get lost at this part.. I feel a little bit abstract on .<br>please don’t deviate my question.<br>I don’t know whether .. will fit in.</p>
<p>Make sense?<br>He can leverage me when thing is not going</p>
<p>Nevermind I got what I needed (问了问题别人还没回答自己找到答案了)</p>
<p>who may know better on this.</p>
<p>(别人说了sorry什么的)<br>That’s OK.</p>
<p>How can I get plugged into the project/team/community?</p>
<p>Get educated ourselves<br>This is a necessity</p>
<p>Use the navigation on the left to … 左边的菜单栏</p>
<p>Just in case the above link <code>vanishes</code> some day, I am <code>capturing</code> the <code>main piece</code> of the solution below</p>
<p>Sorry if it’s offtopic, …</p>
<p>A rather unusual situation, ….</p>
<p>kubernetes and docker will part ways (分道扬镳)</p>
<h2 id="Issue"><a href="#Issue" class="headerlink" title="Issue"></a>Issue</h2><p>This issue doesn’t appear to be related to xxx,  but an underlying xxx issue with networking..</p>
<p>We should <code>investigate</code> why the network performance is so bad.</p>
<p>This likely also explains some of the poor performance seen for the NFS mounts.</p>
<p>I’m going to remove my name from this one as the software appears to be functioning as designed, but is limited by the underlying infrastructure. </p>
<p>If addition information comes up and anything else you want me to look at let me know.<br>Per previous discussion, assigning this to you for now.</p>
<p>Not mission critical.<br>incurs/introduces overhead.</p>
<p>provide context and a shared language to describe …</p>
<p>pinpoint the problem.</p>
<h2 id="Leaving"><a href="#Leaving" class="headerlink" title="Leaving"></a>Leaving</h2><h3 id="For-other-people"><a href="#For-other-people" class="headerlink" title="For other people"></a>For other people</h3><p>All the best and was nice working with you.<br>whom can I reach to now, I mean your replacement.<br>please carry on the good work!</p>
<p>We will be having farewell lunch for xx at xx on Monday, Febr 3rd. Let’s meet and wish him all the best in his new role and Thank him for all the GREAT work he did for our team.Please RSVP by Thursday.</p>
<p>Thanks for all the work you did… I will surely miss your expertise.</p>
<h3 id="Myself"><a href="#Myself" class="headerlink" title="Myself"></a>Myself</h3><p><strong>Resignation letter to manager</strong><br>Dear XXX,</p>
<p>Please accept this message as notification that I am going to leaving my position and my last day will be July 24, two weeks from today.</p>
<p>I have enjoyed my time at XXX and will miss working with you and the team. I’m proud of the work we’ve done. Thank you for your professional guidance and support, I wish you and XXX the best success in the future. </p>
<p>Please let me know what to expect as far as my final work schedule, accrued vacation leave, and my employee benefits.</p>
<p>I’m also happy to help assist in training my replacement during the transition and make it as smooth as possible.</p>
<p>Sincerely,</p>
<ul>
<li><a href="https://www.thebalancecareers.com/resignation-email-message-example-and-tips-2063055" target="_blank" rel="noopener">https://www.thebalancecareers.com/resignation-email-message-example-and-tips-2063055</a></li>
<li><a href="https://www.indeed.com/career-advice/starting-new-job/how-to-write-a-resignation-letter" target="_blank" rel="noopener">https://www.indeed.com/career-advice/starting-new-job/how-to-write-a-resignation-letter</a></li>
<li><a href="https://howtowiki.net/resignation-email-to-manager/" target="_blank" rel="noopener">https://howtowiki.net/resignation-email-to-manager/</a></li>
</ul>
<p>I was previously working at XXX in San Jose as a software engineer, I’m particularly interested in Linux, Cloud Computing, especially the container orchestration. In my free time I enjoy hiking, playing piano, and writing on my blog.</p>
<p><strong>Resignation letter to peers</strong><br>Dear colleagues and friends, this Friday, Jan 24th will be my last day at xx, but this Is not a note to say good bye. This is a note to say thank you.<br>I am so thankful for my time here at xxx and for all of the wonderful people who have I have had the privilege to work with.<br>I have learned so much and been inspired by many of you over the years. I am so grateful for all the gifts the people of xx have given me and I can only hope in some way I have inspired some of you as well.<br>I take my leave from xx because of a unique opportunity to leverage all I have learned, and build some really cool xx solutions right here in my beloved Chicago. Leaving IBM and all the people I love here was the hard part, even with the exciting opportunity ahead of me.</p>
]]></content>
      <categories>
        <category>Soft Skill</category>
      </categories>
      <tags>
        <tag>soft skill</tag>
        <tag>daily talk</tag>
      </tags>
  </entry>
  <entry>
    <title>SSL/TLS Demystify</title>
    <url>/2019/11/29/ssl-tls-learn/</url>
    <content><![CDATA[<p>This is all about securing servers with <code>SSL/TLS certificates</code> from udemy course <strong>SSL complete guide</strong>.</p>
<p>The quality of SSL varies, you have SSL setup doesn’t mean your site is good secured. The HTTPS may not work correctly, sub-optimal, you can test it here:<br><a href="https://www.ssllabs.com/index.html" target="_blank" rel="noopener">https://www.ssllabs.com/index.html</a></p>
<p>If you click the <code>lock</code> icon at left of the website address, it will show you if the connection is secured or not, it’s certificates, cookies and so on. further click the certificate icon, you will see <code>root CA</code>, <code>intermediate CA</code> and <code>certificate</code>.</p>
<blockquote>
<p>Install wireshark on Mac, go to download the <code>stable</code> version dmg package and double click to install.</p>
</blockquote>
<blockquote>
<p>You can use Chrome inspect -&gt; Network to see traffic or use wireshark</p>
</blockquote>
<p>For example, from <code>Network</code> select one item, check <code>HEADER</code> information you can get IP address of remote server, or just use <code>host</code>, <code>nslookup</code> commands to get IP address.</p>
<blockquote>
<p>Interesting, from <code>Network</code> I see the the chrome browser sometime uses IPV6 address talk to server, for example facebook and some other sites. see this <a href="https://superuser.com/questions/1199129/how-web-browser-determines-when-to-use-ipv4-or-ipv6-to-connect-to-the-destinatio" target="_blank" rel="noopener">question</a></p>
</blockquote>
<p><strong>大概总结一下:</strong><br>openssl 目前有command 一次性生成(或分开生成 private key -&gt; CSR -&gt; self-signed certificate) private key 和 (self-signed) certificate, 一般用pem 的格式。这2个东西是放在web server上的，也可以把private key 和 certificate 合并到一个pem 文件中。还要注意的是，这里没有用到public key，但public key可以从 private key 中生成(其实里面已经包含了public key的信息)。还要注意，web server 给 client的certificate 就只是certificate，不会有private key尽管它们可能在一个pem file中。</p>
<p>在client部分，对于slef-signed certificate, 需要设置操作系统trust it，但如果是用的let’s encrypt，已经OK了。联想一下TLS handshake, 得到web serverd的certificate 后，会逐层验证到root CA(会下载所有相关的certificates), 由于client自身已经携带了well-known root CA的证书了，并且也知道CA的public key，所以就会知道这个root CA是否合法。如果合法，就会进行symmetric key的生成和交换，用于之后的数据传输。</p>
<p>具体命令操作可以参考: <code>&lt;&lt;Set up Secure Docker Registry Container&gt;&gt;</code><br>如果要把这个过程自动化，比如自动给网站安排证书，更新，撤销等，需要用到一些框架机制，比如certbot，见下面一章:</p>
<h1 id="Certbot"><a href="#Certbot" class="headerlink" title="Certbot"></a>Certbot</h1><p>Get free HTTPs certificates forever, it utilizes <code>Let&#39;s Encrypt</code> CA to automatically refresh the certificate for your web site:<br><a href="https://certbot.eff.org/" target="_blank" rel="noopener">https://certbot.eff.org/</a></p>
<p>How it works:<br><a href="https://letsencrypt.org/getting-started/" target="_blank" rel="noopener">https://letsencrypt.org/getting-started/</a><br><a href="https://letsencrypt.org/how-it-works/" target="_blank" rel="noopener">https://letsencrypt.org/how-it-works/</a><br>This is accomplished by running a certificate management agent on the web server.</p>
<p>To understand how the technology works, let’s walk through the process of setting up <code>https://example.com/</code> with a certificate management agent that supports Let’s Encrypt.</p>
<p>There are two steps to this process. First, the agent proves to the CA that the web server controls a domain. Then, the agent can request, renew, and revoke certificates for that domain.</p>
<h1 id="Encryption"><a href="#Encryption" class="headerlink" title="Encryption"></a>Encryption</h1><p><code>symmetric</code> encryption, the same key is used by both sides, for example: <code>AES</code>. This algorithm is embedded in SSL with HTTPS protocol.<br><code>asymmetric</code> encryption, for example: <code>RSA</code>.</p>
<h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><p>How does hash work to verify data integrity:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data + hash(data)  ---------&gt; data + hash(data)</span><br><span class="line">                                |         |</span><br><span class="line">                                |--hash--&gt;| (compare if they are the same)</span><br></pre></td></tr></table></figure></p>
<p>Notice that in database the password is hashed, not plain text.</p>
<p>Hash algorithms: <code>MD5</code>, <code>SHA</code>…</p>
<ul>
<li>MD5: 128 bits, <code>echo 123 | md5</code></li>
</ul>
<p>for <code>SHA</code>, use <code>shasum</code> command in linux or use inline tool.</p>
<ul>
<li>SHA-1: 160 bits</li>
<li>SHA-256: 256 bits</li>
<li><p>SHA-512: 512 bits</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## SHA-256</span></span><br><span class="line">shasum -a 256 -t test.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>HMAC: can be used with md5 or sha. In cryptography, an HMAC (sometimes expanded as either keyed-hash message authentication code or hash-based message authentication code) is a specific type of message authentication code (MAC) involving a cryptographic hash function and a secret cryptographic <code>key</code>. It may be used to simultaneously verify <code>both</code> the data integrity and the authenticity of a message, as with any MAC. Any cryptographic hash function, such as SHA-256 or SHA-3, may be used in the calculation of an HMAC.</p>
</li>
</ul>
<h2 id="Asymmetric-Keys"><a href="#Asymmetric-Keys" class="headerlink" title="Asymmetric Keys"></a>Asymmetric Keys</h2><p><code>Encryption</code><br><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">data -------------&gt; code =========&gt;  code -------------&gt; data  (owner side)</span><br><span class="line">      public key                          private key</span><br><span class="line">      encryption                          decryption</span><br></pre></td></tr></table></figure></p>
<p>Usually(but not necessarily), the keys are <code>interchangeable</code>, in the sense that if key A encrypts a message, then B can decrypt it, and if key B encrypts a message, then key A can decrypt it. While common, this property is not essential to asymmetric encryption.</p>
<p><code>Signature</code><br><figure class="highlight js"><table><tr><td class="code"><pre><span class="line">            data                          |----------&gt; hash value</span><br><span class="line">             | (hash)     ==========&gt;     |  compare      /|\</span><br><span class="line">             |                            |                |</span><br><span class="line">         private key encrypt              |           public key decrypte</span><br><span class="line">            \|<span class="regexp">/                           | (hash)         |</span></span><br><span class="line"><span class="regexp">data   +   encrypted hash              data    +   encrypted hash</span></span><br></pre></td></tr></table></figure></p>
<p>Signing ensures the data is sent by the <code>owner of private key</code> and not has been modified inbetween.</p>
<p>What is the difference of digest and signature?<br><a href="https://www.ibm.com/support/knowledgecenter/SSFKSJ_9.2.0/com.ibm.mq.sec.doc/q009810_.htm" target="_blank" rel="noopener">https://www.ibm.com/support/knowledgecenter/SSFKSJ_9.2.0/com.ibm.mq.sec.doc/q009810_.htm</a><br>A message <code>digest</code> is a fixed size numeric representation of the contents of a message, computed by a hash function. A message digest can be encrypted by the sender’s private key, forming a <code>digital signature</code>.</p>
<p>More readings:<br><a href="https://stackoverflow.com/questions/18257185/how-does-a-public-key-verify-a-signature" target="_blank" rel="noopener">How does a public key verify a signature?</a></p>
<h2 id="PKI"><a href="#PKI" class="headerlink" title="PKI"></a>PKI</h2><p><code>public key infrastructure</code> is a set of roles, policies, hardware, software and procedures needed to create, manage, distribute, use, store and revoke digital certificates and manage public-key encryption. The purpose of a PKI is to facilitate the secure electronic transfer of information for a range of network activities such as e-commerce, internet banking and confidential email.</p>
<h2 id="Certificate"><a href="#Certificate" class="headerlink" title="Certificate"></a>Certificate</h2><p>A file with some contents:</p>
<ol>
<li>certificate owner</li>
<li>certificate issuer</li>
<li>signature (RSA created, made by issuer)</li>
<li>public key (from owner, we then use this public key to HTTPS)</li>
</ol>
<p><code>Self-signed certificate</code>: issued and signed by the owner.<br>The basic rule is we trust the CA (the issuer) so on the certificate owner.</p>
<h2 id="Why-we-need-intermediary-CAs"><a href="#Why-we-need-intermediary-CAs" class="headerlink" title="Why we need intermediary CAs?"></a>Why we need intermediary CAs?</h2><p>There are not so much public root CAs because of problem of trust. Actually anybody can create own root CA but nobody will trust it. That’s why there is limited set of global root CAs that are trusted worldwide by operating systems and browsers. You can view list of such global CAs with their root certificates in any browser or OS.</p>
<p>Such root CAs have certificates with long period of validity and their main responsibility is simple create “source of trust”. That’s why they don’t issue certificates to end users to avoid additional work and minimize risk that their private keys will be compromised. Intermediate CAs certificates don’t necessarily need to be in the list of trusted certificates in the OS or browser. They need simply be issued by trusted root CA.</p>
<h1 id="Chain-of-Trust"><a href="#Chain-of-Trust" class="headerlink" title="Chain of Trust"></a>Chain of Trust</h1><p>Let’s see <code>openssl</code> command, generate RSA private key and public key:<br>这里没有谈到self-signed certificate,见后面<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## check help for sub-command genrsa</span></span><br><span class="line">openssl genrsa -h</span><br><span class="line"></span><br><span class="line"><span class="comment">## generate private.pem file private key with aes256 encryption method</span></span><br><span class="line"><span class="comment">## will ask you input pass phrase </span></span><br><span class="line"><span class="comment">## 实际上private.pem 包含了public key 的信息了！</span></span><br><span class="line">openssl genrsa -aes256 -out private.pem</span><br><span class="line"></span><br><span class="line"><span class="comment">## generate public key from above private key</span></span><br><span class="line"><span class="comment">## will ask you pass phrase from private key</span></span><br><span class="line">openssl rsa -<span class="keyword">in</span> private.pem -outform PEM -pubout -out public.pem</span><br></pre></td></tr></table></figure></p>
<h2 id="Root-CAs-in-OS"><a href="#Root-CAs-in-OS" class="headerlink" title="Root CAs in OS"></a>Root CAs in OS</h2><p>How does web browser trust the root CAs and certificates?<br>The OS ships a list of trusted certificates, in Mac search <code>Keychain Access</code>. </p>
<p>In Linux, see this <a href="https://blog.confirm.ch/adding-a-new-trusted-certificate-authority/" target="_blank" rel="noopener">link</a>: On Red Hat/Centos, It includes all trusted certificate authorities under <code>/etc/pki/ca-trust/extracted/openssl/ca-bundle.trust.crt</code>. Just add your new certificate authority file(s) to the directory <code>/etc/pki/ca-trust/source/anchors</code>, then run <code>/bin/update-ca-trust</code> for update the certificate authority file.</p>
<h2 id="Verify-chain-of-trust"><a href="#Verify-chain-of-trust" class="headerlink" title="Verify chain of trust"></a>Verify chain of trust</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">           <span class="string">root</span> <span class="string">CA</span>         <span class="string">|     intermediate CA       |        end user</span></span><br><span class="line"><span class="string">----------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="string">  self-singed certificate  |     signed by root CA     |   signed by intermediate CA</span></span><br><span class="line"><span class="string">----------------------------------------------------------------------------------------</span></span><br><span class="line"><span class="string"></span><span class="attr">   signature:</span> <span class="string">encrpty</span>      <span class="string">|    signature: encrpty     |       signature: encrpty</span></span><br><span class="line"><span class="string"> by private key of root CA | by private key of root CA |  by private key of intermediate</span></span><br><span class="line"><span class="string">                           |                           |  CA</span></span><br></pre></td></tr></table></figure>
<p><code>CSR</code>: certificate signing request (the root CA receive CSR from intermediate CA, the signature of intermediate CA is signed by root CA, the root CA also provide issuer info for intermediate CA. Similarly, end user is signed by intermediate CA)</p>
<p>Web server (the end user) sends you its certificate and all intermediate certificates. Then on your side start the verification process from end user certificates back to top intermediate certificate then root certificate. 这里如何验证的: To verify a certificate, a browser will obtain a sequence of certificates, each one having signed the next certificate in the sequence, connecting the signing CA’s root to the server’s certificate.</p>
<p>There is a online tool to check the certificates chain:<br><a href="https://www.geocerts.com/ssl-checker" target="_blank" rel="noopener">https://www.geocerts.com/ssl-checker</a>.</p>
<h1 id="Create-Self-signed-Certificate"><a href="#Create-Self-signed-Certificate" class="headerlink" title="Create Self-signed Certificate"></a>Create Self-signed Certificate</h1><p><a href="https://www.digitalocean.com/community/tutorials/openssl-essentials-working-with-ssl-certificates-private-keys-and-csrs#generating-csrs" target="_blank" rel="noopener">Openssl Essential, several ways to generate certificates</a></p>
<p>Before creating certificate, you need <code>CSR</code>, and before <code>CSR</code>, you need first generate asymmetric keys. (Becuase certificate needs to include signature from upstream and also your public key)</p>
<blockquote>
<p>Choose common name (CN) according to the main domain where certificate will be used. (for example, in secure docker registry, CN is the registry address)</p>
</blockquote>
<blockquote>
<p>What is <code>/etc/ssl/certs</code> directory? Actually this is a softlink to <code>/etc/pki/tls/certs</code>.</p>
</blockquote>
<p>Generate self-signed certificate, see this <a href="https://stackoverflow.com/questions/10175812/how-to-create-a-self-signed-certificate-with-openssl" target="_blank" rel="noopener">post</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openssl req \</span><br><span class="line">        -newkey rsa:4096 -nodes -x509 -sha256\</span><br><span class="line">        -keyout key.pem -out cert.pem -days 365 \</span><br><span class="line">        -subj <span class="string">"/C=US/ST=CA/L=San Jose/O=Company Name/OU=Org/CN=&lt;domain&gt;"</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li>-nodes: short for No DES, if you don’t want to protect your private key with a passphrase.</li>
<li>Add <code>-subj &#39;/CN=localhost&#39;</code> to suppress questions about the contents of the certificate (replace localhost with your desired domain).</li>
<li>For anyone else using this in automation, here’s all of the common parameters for the subject: <code>-subj &quot;/C=US/ST=CA/L=San Jose/O=Company Name/OU=Org/CN=&lt;domain&gt;&quot;</code></li>
<li>Remember to use <code>-sha256</code> to generate SHA-256-based certificate.</li>
</ul>
<blockquote>
<p>注意有时遇到的cert 文件中可能包含多个CERTIFICATE 块，其中有intermediate CA. 在kubernetes 中构造tls secret的时候，直接使用即可。</p>
</blockquote>
<h1 id="SSL-TLS-and-HTTPS"><a href="#SSL-TLS-and-HTTPS" class="headerlink" title="SSL/TLS and HTTPS"></a>SSL/TLS and HTTPS</h1><p>Both are cryptographic protocols used in HTTPS:</p>
<ul>
<li><code>SSL</code>: Secure Socket Layer</li>
<li><code>TLS</code>: Transport Layer Security. </li>
</ul>
<p>Difference between <code>SSL</code> vs <code>TLS</code>: <code>TLS</code> is an update and secure version of SSL.<br><a href="https://www.globalsign.com/en/blog/ssl-vs-tls-difference/" target="_blank" rel="noopener">https://www.globalsign.com/en/blog/ssl-vs-tls-difference/</a><br>It’s important to note that certificates are not dependent on protocols. Sometimes you hear <code>SSL/TLS certificate</code>, it may be more accurate to call them <code>Certificates for use with SSL and TLS</code>, since the protocols are determined by your server configuration, not the certificates themselves.</p>
<p>Go to <a href="https://www.ssllabs.com/ssltest/" target="_blank" rel="noopener"><code>ssllab</code></a>, you can check which version of TLS the web server use, input the web server address and scan, then click IP icon.</p>
<p>Why <code>RSA</code> is not used in data encryption?</p>
<ol>
<li>too slow.</li>
<li>bi-directional data encryption requires RSA key pairs on both sides.<br>We encrypt data use symmetic key after setup secure connection.</li>
</ol>
<blockquote>
<p>Why need rsa key pairs on both sides? If the key is interchangeable, everyone has public key can decrypt data encrypted by private key!</p>
</blockquote>
<h2 id="Establish-TLS-Session"><a href="#Establish-TLS-Session" class="headerlink" title="Establish TLS Session"></a>Establish TLS Session</h2><ol>
<li>establish tcp session</li>
<li>establish tls session (negotiate protocol)</li>
<li>web server sends its <strong>certifiate</strong> (intermediate and others) to browser</li>
<li>browser generate symmetic key secured by public key from server and send to server. Or use <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange" target="_blank" rel="noopener"><code>Diffie–Hellman key exchange</code></a>.</li>
</ol>
<p>Let’s see wireshark for wikipedia connection:<br>The top 3 are TCP handshakes, then you see TLS client hello, then TLS server hello.<br><img src="https://drive.google.com/uc?id=1BqEQwaHXUIBIJguBGifnGIc_AnHJtoBB" alt=""></p>
<p>In client hello, there are lots of information to negoitate with server, here you see some supported version of TLS, also cipher suites.<br><img src="https://drive.google.com/uc?id=1eLDoipLHyJ72aXeUPv5ERcSLHlAYNU1N" alt=""></p>
<p>In server hello, you see the the server has selected one of cipher suites. The <code>TLS_ECDHE.._SHA256</code> means it uses Diffie–Hellman key exchange and sha256 as hash.<br><img src="https://drive.google.com/uc?id=1lC9yZ5vy1T-geCDnJoN1aq--QZIe3eOm" alt=""></p>
<h3 id="Other-Readings"><a href="#Other-Readings" class="headerlink" title="Other Readings"></a>Other Readings</h3><p>这个网站上的资源可以好好看看:<br><a href="https://www.cloudflare.com/learning/" target="_blank" rel="noopener">https://www.cloudflare.com/learning/</a></p>
<p>–&gt;&gt; <a href="https://www.cloudflare.com/learning/ssl/how-does-ssl-work/" target="_blank" rel="noopener">How Does SSL Work? </a><br>The main use case for SSL/TLS is securing communications between a client and a server, but it can also secure email, VoIP, and other communications over unsecured networks.</p>
<p>–&gt;&gt; <a href="https://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/" target="_blank" rel="noopener">TLS handshakes</a><br>During a TLS handshake, the two communicating sides exchange messages to acknowledge each other, verify each other, establish the encryption algorithms they will use, and agree on session keys.</p>
<p>SSL handshakes are now called TLS handshakes, although the “SSL” name is still in wide use.</p>
<p>A TLS handshake also happens whenever any other communications use HTTPS, including API calls and DNS over HTTPS queries.</p>
<p>这里讲到了2种不同的TLS handshake过程，一个是public-private key参与，另一个是Diffie–Hellman handshake. 对于第一种方式，提到了client从server cerficiate extract public key:<br><a href="https://stackoverflow.com/questions/17143606/how-to-save-public-key-from-a-certificate-in-pem-format" target="_blank" rel="noopener">https://stackoverflow.com/questions/17143606/how-to-save-public-key-from-a-certificate-in-pem-format</a></p>
<p>–&gt;&gt; <a href="https://security.stackexchange.com/questions/115762/how-is-it-possible-to-do-tls-through-proxy-without-anyone-noticing/115764" target="_blank" rel="noopener">How does proxy handle TLS handshakes</a><br>HTTPS knows how to tunnel the TLS handshake even through the proxy.<br>也就说TLS/SSL through proxy就是通过HTTP CONNECT tunnel去实现的, 特别是看一下第二个回答, comments:</p>
<p>So, the proxy is not MITM’ing the HTTPS connection, by replacing the server’s certificate with its own - it’s simply passing the HTTPS connection straight through between the client and the server. Is that right?</p>
<p>Normally, when HTTPS is done through a proxy, this is done with the CONNECT mechanism: the client talks to the proxy and asks it to provide a bidirectional tunnel for bytes with the target system. In that case, the certificate that the client sees is really from the server, not from the proxy. In that situation, the proxy is kept on the outside of the SSL/TLS session – it can see that some SSL/TLS is taking place, but it has no access to the encryption keys.</p>
<h2 id="Diffie–Hellman"><a href="#Diffie–Hellman" class="headerlink" title="Diffie–Hellman"></a>Diffie–Hellman</h2><p>Diffie–Hellman uses one-way function, for example, mod operation.<br><img src="https://drive.google.com/uc?id=1lXCys7VAEXJxZ-sytIWUVQGXgxxRTCTi" alt=""><br>See, here <code>a</code>, <code>b</code> are priviate keys on both side, <code>g</code>, <code>p</code> are public key. <code>A</code>, <code>B</code> are mod result, <code>K</code> is the final result that both side can get use to encrypt the data.</p>
<p>Elliptic-curve cryptography is used in Diffie–Hellman.</p>
<h1 id="Custom-Domain"><a href="#Custom-Domain" class="headerlink" title="Custom Domain"></a>Custom Domain</h1><p>Purchase custom domain and use free hosting to setup our website.</p>
]]></content>
      <categories>
        <category>SSL/TLS</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssl</tag>
        <tag>tls</tag>
      </tags>
  </entry>
  <entry>
    <title>Effective Email</title>
    <url>/2020/05/24/softskill-email/</url>
    <content><![CDATA[<h1 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose"></a>Purpose</h1><p>Understand the purpose of every email, for example:</p>
<ul>
<li>to educate or inform</li>
<li>make a request</li>
<li>introduction</li>
<li>respond</li>
</ul>
<p>Before sending, review for purpose alignment. If not, adjust the message.</p>
<p>Key elements for good email:</p>
<ul>
<li>Subject line: keep email from getting deleted</li>
<li>Introduction: create context, build trust, remind who you are</li>
<li>Message: bulk of the email</li>
<li>Call to action: request, the last part of the body</li>
<li>Signature: provide contact information, your brand</li>
</ul>
<p>Adjust the <code>From</code> name and email address, for example <code>chengdol &lt;email address&gt;</code>, this can be done through <code>Send email as</code> in Gmail.</p>
<p>The <code>Signature</code> helps people understand your skill set, value proposition, may include:</p>
<ul>
<li>your name</li>
<li>tagline: directly under your name, a few words, can be your title (senior software engineer) or pluralsight skills IQ</li>
<li>phone, address, links</li>
</ul>
<p><strong>To, CC and BCC</strong><br><code>To</code>: directly talk to a person.<br><code>CC</code>: who can hear the conversation, don’t have to act on it.<br><code>BCC</code>: blind from others, only the person put you in BCC feild knows you are listening, no one else know you are on recipient list, fine to reply to sender but not reply all.</p>
<p><strong>Time</strong><br>Email complements other communications, when there is a lot of information, highly visual. Usually not time urgent.</p>
<h1 id="Communicating-Better"><a href="#Communicating-Better" class="headerlink" title="Communicating Better"></a>Communicating Better</h1><p>Visuals may help, but not make it distracting, <code>bold or highlighting</code> is good to make response stand out.</p>
<p>When many people involved, use <code>Reply All</code>, unless you intend to start a side conversation. Move to <code>Reply</code>, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Thank again for the introduction, I&apos;ll move this conversation with xx to another thread so we don&apos;t clutter your inbox.</span><br></pre></td></tr></table></figure></p>
<p>Set <code>out-of-office auto reply</code>, for example, at a conference, on leave. A good example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">I’m currently consumed with a project that is taking almost all of my time. If you are emailing me with a product or support question, please email Liz. Otherwise, I will try to respond within 24 hours.</span><br></pre></td></tr></table></figure></p>
<p><code>Proofread</code> before sending it:</p>
<ul>
<li>purpose aligned</li>
<li>body</li>
<li>distraction</li>
<li>call to action is clear</li>
<li>spelling and grammar</li>
<li>proper audience</li>
<li>any attachment</li>
</ul>
<p>When the stakes are high, and your email can have a major impact on the outcome, it can pay to invest your time in proper proofreading.</p>
<h1 id="Demos"><a href="#Demos" class="headerlink" title="Demos"></a>Demos</h1><p><code>The first communication</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## subject</span></span><br><span class="line">Reaching out from Twitter</span><br><span class="line"></span><br><span class="line"><span class="comment">## introduction</span></span><br><span class="line">Hi Chris, I have been following you on Twitter <span class="keyword">for</span> a <span class="keyword">while</span>, and have interacted a little with you over the last few weeks. I wanted to bring the conversation over to email.</span><br><span class="line"></span><br><span class="line"><span class="comment">## message</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## call to action</span></span><br><span class="line">Can we get on a call <span class="keyword">in</span> the next week or so? I am open all day Thursday, just <span class="built_in">let</span> me know what works <span class="keyword">for</span> you.</span><br><span class="line"></span><br><span class="line"><span class="comment">## signature</span></span><br></pre></td></tr></table></figure></p>
<p><code>Vitual introduction</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## subject</span></span><br><span class="line">Virtual introduction: Matt and Jesse</span><br><span class="line"></span><br><span class="line"><span class="comment">## introduction</span></span><br><span class="line">Hi Matt and Jesse, as per our previous conversations I wanted to introduce you to one another.</span><br><span class="line"></span><br><span class="line"><span class="comment">## message</span></span><br><span class="line">Matt, I’ve known Jesse <span class="keyword">for</span> a few years and know him to be a very clever developer, and a loyal friend. I know he can <span class="built_in">help</span> you with some of the coding challenges you are facing right now.</span><br><span class="line"></span><br><span class="line">Jesse, Matt is my friend and colleague, and can better explain his challenges than I can, but I think you are the right person <span class="keyword">for</span> him to talk to.</span><br><span class="line"></span><br><span class="line"><span class="comment">## call to action</span></span><br><span class="line">I hope you two can get together soon. I’ll <span class="built_in">let</span> you take it from here.</span><br><span class="line"></span><br><span class="line"><span class="comment">## signature</span></span><br></pre></td></tr></table></figure></p>
<p><code>Information heavy</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Follow-up on job search information</span><br><span class="line"></span><br><span class="line">Hi Laurie, you had asked <span class="keyword">for</span> information to <span class="built_in">help</span> you with your job search Thursday morning when we spoke.</span><br><span class="line"></span><br><span class="line">Below are a few of my favorite blog posts <span class="built_in">which</span> I think are relevant to <span class="built_in">where</span> you are, based on our conversation. I am happy to talk about any of this with you, over email or on a call. Just <span class="built_in">let</span> me know what works best <span class="keyword">for</span> you.</span><br><span class="line"></span><br><span class="line"><span class="comment">## some links here</span></span><br><span class="line"></span><br><span class="line">I have been blogging <span class="keyword">for</span> over 14 years, and have plenty to share, but I thought these would be the most interesting and meaningful to you.</span><br><span class="line"></span><br><span class="line">I would love to jump on a call this week to talk about your next steps. Are you available <span class="keyword">for</span> a call Friday before 2?</span><br><span class="line"></span><br><span class="line"><span class="comment">## signature</span></span><br></pre></td></tr></table></figure></p>
<p><code>Respond to questions</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Hi Jim, thank you <span class="keyword">for</span> your thoughtful email. You have a lot of questions and ideas <span class="keyword">in</span> there. Please scroll down and see my comments <span class="keyword">in</span> `yellow`</span><br><span class="line"><span class="comment">## copy the original email and answer right after each question and highlight with yellow</span></span><br></pre></td></tr></table></figure></p>
<p><code>Negative situation</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Team performance</span><br><span class="line"></span><br><span class="line">Mike, I promised you an email follow-up from our conversation this morning. I know this is an uncomfortable conversation and I appreciate your willingness to address this with me.</span><br><span class="line"></span><br><span class="line">There are two issues we need to address.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Project Foo meeting this morning</span><br><span class="line"></span><br><span class="line">Hi Carlos, <span class="built_in">let</span> me first apologize <span class="keyword">for</span> how the meeting went this afternoon. I could tell that you were uncomfortable. I wanted to share my perspective on what was happening.</span><br><span class="line"></span><br><span class="line">While I knew there was a chance your Project Foo was going to be killed, I was not aware of the reasons stated <span class="keyword">in</span> the meeting. I have seen what you and your team have <span class="keyword">done</span> with Project Foo and I have been very impressed.</span><br></pre></td></tr></table></figure>
<h2 id="Seek-Help"><a href="#Seek-Help" class="headerlink" title="Seek Help"></a>Seek Help</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Hi xx,</span><br><span class="line">Hope you are doing well!</span><br><span class="line"></span><br><span class="line">We have started the work related to ... </span><br><span class="line"><span class="comment">## body</span></span><br><span class="line"></span><br><span class="line">At this point it is not clear <span class="keyword">for</span> us how to proceed ...</span><br><span class="line">Can you please provide guidance, or point us to someone who can assist?</span><br><span class="line">Appreciate your <span class="built_in">help</span>!</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Soft Skill</category>
      </categories>
      <tags>
        <tag>soft skill</tag>
        <tag>email</tag>
      </tags>
  </entry>
  <entry>
    <title>Visual Studio Code Setup</title>
    <url>/2020/05/28/vsc-setup/</url>
    <content><![CDATA[<p>There is a Settings Sync plugin:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;Sync Update/upload settings or Download</span><br></pre></td></tr></table></figure></p>
<ol>
<li>Theme setting: command + P: &gt;theme, then select the theme you like</li>
<li>Material Icon plugin</li>
<li>Fira Code: <a href="https://github.com/tonsky/FiraCode" target="_blank" rel="noopener">https://github.com/tonsky/FiraCode</a></li>
<li>Still hold picture on google drive, refer by <code>![](https://drive.google.com/uc?id=xxx)</code></li>
<li><p>Open settings: &gt;settings, &gt;default settings</p>
<ul>
<li>autoSave afterdelay</li>
</ul>
</li>
<li><p>Remote Development plug-in, similar to remote ssh emulator.</p>
</li>
</ol>
<h1 id="Other-Settings"><a href="#Other-Settings" class="headerlink" title="Other Settings"></a>Other Settings</h1><p><a href="https://stackoverflow.com/questions/29957456/change-default-terminal-app-in-visual-studio-code-on-mac" target="_blank" rel="noopener">Change default terminal app in Visual Studio Code on Mac</a><br>You cannot set iTerm as the integrated terminal for VSC, because iTerm is a emulator! But you can use <code>starship</code> to customize the bash.</p>
]]></content>
      <categories>
        <category>Visual Studio Code</category>
      </categories>
      <tags>
        <tag>vsc</tag>
      </tags>
  </entry>
  <entry>
    <title>WebSocket Quick Start</title>
    <url>/2020/09/13/websocket-learn/</url>
    <content><![CDATA[<h1 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h1><p>Git repo, create basic and secure websocket server and client via Python websockets module:<br><a href="https://github.com/chengdol/websocket-demo" target="_blank" rel="noopener">https://github.com/chengdol/websocket-demo</a></p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><a href="https://stackoverflow.com/a/4973689/5282011" target="_blank" rel="noopener">Difference between socket and websocket?</a></p>
<p>如果你已经理解了HTTP, HTTP CONNECT method 以及Proxy的知识，那么维基百科的描述已经比较清楚了.<br><a href="https://en.wikipedia.org/wiki/WebSocket" target="_blank" rel="noopener">WebSocket Wiki</a><br>WebSocket is a computer communications <strong>protocol</strong>, providing <strong>full-duplex</strong> communication channels over a single TCP connection.</p>
<p>WebSocket is distinct from HTTP (<strong>half-duplex</strong>, clients issue request). Both protocols are located at layer 5 in the OSI model and depend on TCP at layer 4. Although they are different, RFC 6455 states that WebSocket “is designed to work over HTTP ports 443 and 80 as well as to support HTTP proxies and intermediaries,” thus making it <strong>compatible</strong> with the HTTP protocol. To achieve compatibility, the WebSocket handshake uses the HTTP(1.1 version) Upgrade header to change from the HTTP protocol to the WebSocket protocol.</p>
<blockquote>
<p>Some proxies also support WebSocket, for example, Envoy, some may not.</p>
</blockquote>
<p>WebSocket handshake <code>ws://</code> or <code>wss:// (WebSocket Secure)</code>:<br><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="comment">// client request</span></span><br><span class="line">GET /chat HTTP/<span class="number">1.1</span></span><br><span class="line">Host: server.example.com</span><br><span class="line">Upgrade: websocket</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Sec-WebSocket-Key: x3JJHMbDL1EzLkh9GBhXDw==</span><br><span class="line">Sec-WebSocket-Protocol: chat, superchat</span><br><span class="line">Sec-WebSocket-Version: <span class="number">13</span></span><br><span class="line">Origin: http:<span class="comment">//example.com</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// server response</span></span><br><span class="line">HTTP/<span class="number">1.1</span> <span class="number">101</span> Switching Protocols</span><br><span class="line">Upgrade: websocket</span><br><span class="line">Connection: Upgrade</span><br><span class="line">Sec-WebSocket-Accept: HSmrc0sMlYUkAGmm5OPpG2HaGWk=</span><br><span class="line">Sec-WebSocket-Protocol: chat</span><br></pre></td></tr></table></figure></p>
<p>WebSockets use cases:</p>
<ul>
<li>chatting</li>
<li>live feed</li>
<li>multiplayer gaming</li>
<li>showing client progress/logging</li>
</ul>
<p>Pros:</p>
<ul>
<li>full-duplex (no polling)</li>
<li>HTTP compatible</li>
<li>firewall friendly</li>
</ul>
<p>Cons:</p>
<ul>
<li>lots of proxies and transparent proxies don’t support it yet</li>
<li>L7, LB challenging (timeouts)</li>
<li>stateful, difficult to horizontal scale</li>
</ul>
<p>Do you have to use Web Sockets ? (alternatives)<br>It is important to note that WebSockets is not the only HTTP realtime based solution, there are other ways to achieve real time such as <strong>eventsource</strong>, and <strong>long polling</strong>. </p>
]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>websocket</tag>
      </tags>
  </entry>
  <entry>
    <title>Leadership Principle</title>
    <url>/2020/05/23/softskill-leadership/</url>
    <content><![CDATA[<p>今天决定把Soft Skill相关的总结单独分出来。除了日常工作对话，后续重要的技能包括email, phone, technical writing 以及 negotiation, management等.</p>
<p>关注并接触Leadership 是始于Amazon的面试准备，虽然我很烦在面试中考察这种形式化的东西，但我不得不说它非常重要，特别是在英文背景中我这方面欠缺挺大的，必须要系统性的总结一下。</p>
<h1 id="Leadership-view"><a href="#Leadership-view" class="headerlink" title="Leadership view"></a>Leadership view</h1><p>I think you have been doing a nice job.</p>
<p>figure out customer requirements<br>hold meetings<br>write agendas<br>status reports</p>
<p>Critical skill of being a leader:</p>
<ul>
<li>Communication</li>
<li>Effective management skill</li>
<li>Emotional intelligence (情商) and Empathy</li>
</ul>
<p>Communicate in clear, credible and authentic way.<br>Use passion and confidence to enhance the message.(口音，表情，肢体语言)<br>Inspire, motivate others<br>Informs, persuades, guides, assures</p>
<p>when you be a leader in your new team:</p>
<ul>
<li>devote time and energy to establishing how you want your team to work</li>
<li>first few weeks are critical</li>
<li>get to know your team members</li>
<li>showcase your values</li>
<li>explain how you want the team to work</li>
<li>set and clarify goals, walk the talk</li>
<li>don’t be afraid to over communicate</li>
</ul>
<p>Don’t:</p>
<ul>
<li>不要认为没建立关系也能完成工作</li>
<li>不要假设成员理解你的工作模式和期望</li>
<li>不要担心在开始阶段过多的重复谈话</li>
</ul>
<p>What does leadership mean to you?<br>connection:</p>
<ul>
<li>focus on the person</li>
<li>influence</li>
<li>words</li>
</ul>
<p>changes:</p>
<ul>
<li>vision</li>
<li>action</li>
<li>drive change</li>
</ul>
<p>motivate:</p>
<ul>
<li>inspire motivation</li>
<li>long-lasting motivation</li>
</ul>
<p>Why they will follow you?<br>make them feel comfortable, configent and satisfied:</p>
<ul>
<li>trust<ul>
<li>be open, fair and listen</li>
<li>admit mistake</li>
<li>be decisive</li>
<li>respect the opinions of others</li>
</ul>
</li>
<li>compassion</li>
<li>stability</li>
<li>hope</li>
</ul>
]]></content>
      <categories>
        <category>Soft Skill</category>
      </categories>
      <tags>
        <tag>soft skill</tag>
        <tag>leadership</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Up and Running, 2nd Edition</title>
    <url>/2019/03/13/book-ansible-up-and-running/</url>
    <content><![CDATA[<p>这本书其实挺不错的，我还总结了在工作中ansible的常用模块在另一个blog里面。</p>
<p>Could we remove major architectural components from the IT automation stack? Eliminating management daemons and relying instead on OpenSSH meant the system could start managing a computer fleet immediately, without having to set up anything on the managed machines.</p>
<p>the “Making Ansible Go Even Faster” chapter now covers asynchronous tasks, and the “Debugging Ansible Playbooks” chapter now covers the debugger that was introduced in version 2.1.</p>
<p>we are all slowly turning into system engineers.</p>
<h1 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1. Introduction"></a>Chapter 1. Introduction</h1><p>When we talk about configuration management, we are typically talking about writing some kind of state description for our servers, and then using a tool to enforce that the servers are, indeed, in that state: the right packages are installed, configuration files contain the expected values and have the expected permissions, the right services are running, and so on.</p>
<p>Ansible is a great tool for deployment as well as configuration management. Using a single tool for both configuration management and deployment makes life simpler for the folks responsible for operations.</p>
<p>Some people talk about the need for <em>orchestration</em> of deployment. This is where multiple remote servers are involved, and things have to happen in a specific order.</p>
<h2 id="How-Ansible-works"><a href="#How-Ansible-works" class="headerlink" title="How Ansible works"></a>How Ansible works</h2><p>In Ansible, a script is called a playbook. A playbook describes which hosts (what Ansible calls remote servers) to configure, and an ordered list of tasks to perform on those hosts.</p>
<p>Ansible will make SSH connections in parallel to web1, web2, and web3. It will execute the first task on the list on all three hosts simultaneously</p>
<p>To manage a remote server with Ansible, the server needs to have SSH and Python 2.5 or later installed, or Python 2.4 with the Python <code>simplejsonlibrary</code> installed. There’s no need to preinstall an agent or anyother software on the host.</p>
<p>The control machine (the one that you use to control remote machines) needs to have Python 2.6 or later installed.</p>
<p>Ansible is <strong>push based</strong>, and has been used successfully in production with thousands of nodes, and has excellent support for environments where servers are dynamically added and removed.</p>
<p>Ansible modules are declarative; you use them to describe the state you want the server to be in. Modules are also idempotent.</p>
<p>Ansible has excellent support for templating, as well as defining variables at different scopes. Anybody who thinks Ansible is equivalent to working with shell scripts has never had to maintain a nontrivial program written in shell. I’ll always choose Ansible over shell scripts for config management tasks if given a choice.</p>
<p>To be productive with Ansible, you need to be familiar with basic Linux system administration tasks. Ansible makes it easy to automate your tasks, but it’s not the kind of tool that “automagically” does things that you otherwise wouldn’t know how to do.</p>
<p>Ansible uses the YAML file format and the Jinja2 templating languages, so you’ll need to learn some YAML and Jinja2 to use Ansible, but both technologies are easy to pick up.</p>
<p>If you prefer not to spend the money on a public cloud, I recommend you install Vagrant on your machine. Vagrant is an excellent open source tool for managing virtual machines. You can use Vagrant to boot a Linux virtual machine inside your laptop, and you can use that as a test server.</p>
<p>Vagrant needs the VirtualBox virtualizer to be installed on your machine. Download <a href="http://www.virtualbox.org/" target="_blank" rel="noopener">VirtualBox</a> and then download <a href="http://www.vagrantup.com/" target="_blank" rel="noopener">Vagrant</a>.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir playbooks</span><br><span class="line">cd playbooks</span><br><span class="line">vagrant init ubuntu/trusty64</span><br><span class="line">vagrant up</span><br></pre></td></tr></table></figure>
<p>The first time you use vagrant up, it will download the virtual machine image file, which might take a while, depending on your internet connection.</p>
<p>You should be able to SSH into your new Ubuntu 14.04 virtual machine by running the following:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant ssh</span><br></pre></td></tr></table></figure></p>
<p>This approach lets us interact with the shell, but Ansible needs to connect to the virtual machine by using the regular SSH client, not the vagrant ssh command.</p>
<p>Tell Vagrant to output the SSH connection details by typing the following:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant ssh-config</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh vagrant@127.0.0.1 -p 2222 -i /Users/lorin/dev/ansiblebook/ch01/</span><br><span class="line">playbooks/.vagrant/machines/default/virtualbox/private_key</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">testserver ansible_host=127.0.0.1 ansible_port=2222 ansible_user=vagrant ansible_private_key_file=.vagrant/machines/default/virtualbox/private_key</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">~/.ansible.cfg</span><br></pre></td></tr></table></figure>
<p>Ansible supports the ssh-agent program, so you don’t need to explicitly specify SSH key files in your inventory files. See <a href="https://learning.oreilly.com/library/view/Ansible:+Up+and+Running,+2nd+Edition/9781491979792/app01.html#SSH_AGENT" target="_blank" rel="noopener">“SSH Agent”</a> for more details if you haven’t used ssh-agent before</p>
<p>If Ansible did not succeed, add the <code>-vvvv</code> flag to see more details about the error:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible testserver -i hosts -m ping -vvvv</span><br></pre></td></tr></table></figure></p>
<h2 id="Simplify-by-ansible-cfg-file"><a href="#Simplify-by-ansible-cfg-file" class="headerlink" title="Simplify by ansible.cfg file"></a>Simplify by <em>ansible.cfg</em> file</h2><p>we’ll use one such mechanism, the <code>ansible.cfg</code> file, to set some defaults so we don’t need to type as much.</p>
<p>Ansible looks for an <code>ansible.cfg</code> file in the following places, in this order:</p>
<ul>
<li>File specified by the ANSIBLE_CONFIG environment variable</li>
<li>./ansible.cfg (ansible.cfg in the current directory)</li>
<li>~/.ansible.cfg (.ansible.cfg in your home directory)</li>
<li>/etc/ansible/ansible.cfg</li>
</ul>
<p>I typically put <em>ansible.cfg</em> in the current directory, alongside my playbooks. That way, I can check it into the same version-control repository that my playbooks are in.</p>
<figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[defaults]</span></span><br><span class="line"><span class="attr">inventory</span> = hosts</span><br><span class="line"><span class="attr">remote_user</span> = vagrant</span><br><span class="line"><span class="attr">private_key_file</span> = .vagrant/machines/default/virtualbox/private_key</span><br><span class="line"><span class="attr">host_key_checking</span> = <span class="literal">False</span></span><br></pre></td></tr></table></figure>
<p>Disables SSH host-key checking. Otherwise, we need to edit our <em>~/.ssh/known_hosts</em> file every time we destroy and re-create a nodes.</p>
<p>Ansible uses <code>/etc/ansible/hosts</code> as the default location for the inventory file. However, I never use this because I like to keep my inventory files version-controlled alongside my playbooks.</p>
<p>The <code>command</code> module is so commonly used that it’s the default module, so we can omit it<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ansible testserver -a uptime</span><br><span class="line"><span class="comment">## spaces in command use quotes</span></span><br><span class="line">ansible testserver -a <span class="string">"tail /var/log/dmesg"</span></span><br><span class="line"><span class="comment">## -b becomes root user</span></span><br><span class="line">ansible testserver -b -a <span class="string">"tail /var/log/syslog"</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Chapter-2-Playbooks-A-Beginning"><a href="#Chapter-2-Playbooks-A-Beginning" class="headerlink" title="Chapter 2. Playbooks: A Beginning"></a>Chapter 2. Playbooks: A Beginning</h1><p>Most of your time in Ansible will be spent writing <em>playbooks</em>. A playbook is the term that Ansible uses for a configuration management script.</p>
<p>vargant virtual machine ports mapping in <em>vagrantfile</em>:<br><figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">VAGRANTFILE_API_VERSION = <span class="string">"2"</span></span><br><span class="line"></span><br><span class="line">Vagrant.configure(VAGRANTFILE_API_VERSION) <span class="keyword">do</span> <span class="params">|config|</span></span><br><span class="line">  config.vm.box = <span class="string">"ubuntu/trusty64"</span></span><br><span class="line">  config.vm.network <span class="string">"forwarded_port"</span>, <span class="symbol">guest:</span> <span class="number">80</span>, <span class="symbol">host:</span> <span class="number">8080</span></span><br><span class="line">  config.vm.network <span class="string">"forwarded_port"</span>, <span class="symbol">guest:</span> <span class="number">443</span>, <span class="symbol">host:</span> <span class="number">8443</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant reload</span><br><span class="line"></span><br><span class="line">==&gt; default: Forwarding ports...</span><br><span class="line">    default: 80 =&gt; 8080 (adapter 1)</span><br><span class="line">    default: 443 =&gt; 8443 (adapter 1)</span><br><span class="line">    default: 22 =&gt; 2222 (adapter 1)</span><br></pre></td></tr></table></figure>
<h2 id="TLS-VERSUS-SSL"><a href="#TLS-VERSUS-SSL" class="headerlink" title="TLS VERSUS SSL"></a>TLS VERSUS SSL</h2><p>You might be familiar with the term <em>SSL</em> rather than <em>TLS</em>(Transport Layer Security) in the context of secure web servers. SSL is an older protocol that was used to secure communications between browsers and web servers, and it has been superseded by a newer protocol named TLS. Although many continue to use the term <em>SSL</em> to refer to the current secure protocol, in this book, I use the more accurate <em>TLS</em>.</p>
<h2 id="WHY-DO-YOU-USE-TRUE-IN-ONE-PLACE-AND-YES-IN-ANOTHER"><a href="#WHY-DO-YOU-USE-TRUE-IN-ONE-PLACE-AND-YES-IN-ANOTHER" class="headerlink" title="WHY DO YOU USE TRUE IN ONE PLACE AND YES IN ANOTHER?"></a>WHY DO YOU USE TRUE IN ONE PLACE AND YES IN ANOTHER?</h2><p>Strictly speaking, module arguments (for example, update_cache=yes) are treated differently from values elsewhere in playbooks (for example, sudo: True). Values elsewhere are handled by the YAML parser and so use the YAML conventions of truthiness:</p>
<p>YAML truthy</p>
<blockquote>
<p>true, True, TRUE, yes, Yes, YES, on, On, ON, y, Y</p>
</blockquote>
<p>YAML falsey</p>
<blockquote>
<p>false, False, FALSE, no, No, NO, off, Off, OFF, n, N</p>
</blockquote>
<p>Module arguments are passed as strings and use Ansible’s internal conventions:</p>
<p>module arg truthy</p>
<blockquote>
<p>yes, on, 1, true</p>
</blockquote>
<p>module arg falsey</p>
<blockquote>
<p>no, off, 0, false</p>
</blockquote>
<p>I tend to follow the examples in the official Ansible documentation. These typically use yes and no when passing arguments to modules (since that’s consistent with the module documentation), and True and False elsewhere in playbooks.</p>
<h2 id="NOTE"><a href="#NOTE" class="headerlink" title="NOTE"></a>NOTE</h2><p>An Ansible convention is to keep files in a subdirectory named <em>files</em>, and Jinja2 templates in a subdirectory named <em>templates</em>. I follow this convention throughout the book.</p>
<p>For <code>.j2</code> file, when Ansible renders this template, it will replace this variable with the real value.</p>
<p>Inventory files are in the <code>.ini</code> file format.</p>
<h2 id="COWSAY"><a href="#COWSAY" class="headerlink" title="COWSAY"></a><a href="https://michaelheap.com/cowsay-and-ansible/" target="_blank" rel="noopener">COWSAY</a></h2><p>If you have the <em>cowsay</em> program installed on your local machine, Ansible output will look like this instead:</p>
<p>you can download <em>cowsay</em> rpm and install it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cowsay -l</span><br><span class="line"></span><br><span class="line">Cow files in /usr/share/cowsay:</span><br><span class="line">beavis.zen blowfish bong bud-frogs bunny cheese cower default dragon</span><br><span class="line">dragon-and-cow elephant elephant-in-snake eyes flaming-sheep ghostbusters</span><br><span class="line">head-in hellokitty kiss kitty koala kosh luke-koala mech-and-cow meow milk</span><br><span class="line">moofasa moose mutilated ren satanic sheep skeleton small sodomized</span><br><span class="line">stegosaurus stimpy supermilker surgery telebears three-eyes turkey turtle</span><br><span class="line">tux udder vader vader-koala www</span><br></pre></td></tr></table></figure></p>
<p>set what animal you like:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export ANSIBLE_COW_SELECTION=tux</span><br></pre></td></tr></table></figure></p>
<p>enable cowsay:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export ANSIBLE_NOCOWS=0</span><br></pre></td></tr></table></figure></p>
<p>then if you run playbook:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt; PLAY [Configure webserver with nginx] &gt;</span><br><span class="line"> ---------------------------------------</span><br><span class="line">        \   ^__^</span><br><span class="line">         \  (oo)\_______</span><br><span class="line">            (__)\       )\/\</span><br><span class="line">                ||----w |</span><br><span class="line">                ||     ||</span><br></pre></td></tr></table></figure></p>
<p>If you don’t want to see the cows, you can disable cowsay by setting the <code>ANSIBLE_NOCOWS</code> environment variable like this:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export ANSIBLE_NOCOWS=1</span><br></pre></td></tr></table></figure>
<p>You can also disable cowsay by adding the following to your <em>ansible.cfg</em> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">nocows = 1</span><br></pre></td></tr></table></figure></p>
<h2 id="TIP"><a href="#TIP" class="headerlink" title="TIP"></a>TIP</h2><p>If your playbook file is marked as executable and starts with a line that looks like this<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/usr/bin/env ansible-playbook</span><br></pre></td></tr></table></figure></p>
<p>then you can execute it by invoking it directly, like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./playbook-file.yml</span><br></pre></td></tr></table></figure></p>
<h2 id="YAML-syntax"><a href="#YAML-syntax" class="headerlink" title="YAML syntax"></a>YAML syntax</h2><h3 id="Start-of-file"><a href="#Start-of-file" class="headerlink" title="Start of file"></a>Start of file</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br></pre></td></tr></table></figure>
<p>However, if you forget to put those three dashes at the top of your playbook files, Ansible won’t complain.</p>
<h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><p>In general, YAML strings don’t have to be quoted, although you can quote them if you prefer. Even if there are spaces, you don’t need to quote them.</p>
<p>In some scenarios in Ansible, you will need to quote strings. These typically involve the use of  for variable substitution. </p>
<h3 id="Boolean"><a href="#Boolean" class="headerlink" title="Boolean"></a>Boolean</h3><p>YAML has a native Boolean type, and provides you with a wide variety of strings that can be interpreted as true or false.</p>
<h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- My Fair Lady</span><br><span class="line">- Oklahoma</span><br><span class="line">- The Pirates of Penzance</span><br></pre></td></tr></table></figure>
<h3 id="Dictionary"><a href="#Dictionary" class="headerlink" title="Dictionary"></a>Dictionary</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">address: 742 Evergreen Terrace</span><br><span class="line">city: Springfield</span><br><span class="line">state: North Takoma</span><br></pre></td></tr></table></figure>
<h3 id="Line-folding"><a href="#Line-folding" class="headerlink" title="Line folding"></a>Line folding</h3><p>When writing playbooks, you’ll often encounter situations where you’re passing many arguments to a module. For aesthetics, you might want to break this up across multiple lines in your file, but you want Ansible to treat the string as if it were a single line.</p>
<p>You can do this with YAML by using line folding with the greater than (<code>&gt;</code>) character. The YAML parser will replace line breaks with spaces. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">address: &gt;</span><br><span class="line">    Department of Computer Science,</span><br><span class="line">    A.V. Williams Building,</span><br><span class="line">    University of Maryland</span><br><span class="line">city: College Park</span><br><span class="line">state: Maryland</span><br></pre></td></tr></table></figure></p>
<h2 id="Anatomy-of-a-Playbook"><a href="#Anatomy-of-a-Playbook" class="headerlink" title="Anatomy of a Playbook"></a><a href="https://learning.oreilly.com/library/view/ansible-up-and/9781491979792/ch02.html#playbooks_a_beginning" target="_blank" rel="noopener">Anatomy of a Playbook</a></h2><p>A playbook is a list of plays:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">- name: Configure webserver with nginx</span><br><span class="line">  hosts: webservers</span><br><span class="line">  become: True</span><br><span class="line">  tasks:</span><br><span class="line">  - name: install nginx</span><br><span class="line">      apt: name=nginx update_cache=yes</span><br><span class="line"></span><br><span class="line">  - name: copy nginx config file</span><br><span class="line">    copy: src=files/nginx.conf dest=/etc/nginx/sites-available/default</span><br><span class="line"></span><br><span class="line">  - name: enable configuration</span><br><span class="line">    file: &gt;</span><br><span class="line">      dest=/etc/nginx/sites-enabled/default</span><br><span class="line">      src=/etc/nginx/sites-available/default</span><br><span class="line">      state=link</span><br><span class="line"></span><br><span class="line">  - name: copy index.html</span><br><span class="line">    template: src=templates/index.html.j2  dest=/usr/share/nginx/html/index.html mode=0644</span><br><span class="line"></span><br><span class="line">  - name: restart nginx</span><br><span class="line">    service: name=nginx state=restarted</span><br></pre></td></tr></table></figure></p>
<p>you’ll see in <a href="https://learning.oreilly.com/library/view/ansible-up-and/9781491979792/ch16.html#DEBUGGING" target="_blank" rel="noopener">Chapter 16</a>, you can use the <code>--start-at-task &lt;task name&gt;</code> flag to tell <code>ansible-playbook</code> to start a playbook in the middle of a play, but you need to reference the task by name.</p>
<p>Every task must contain a key with the name of a module and a value with the arguments to that module. In the preceding example, the module name is <code>apt</code> and the arguments are <code>name=nginx update_cache=yes</code>.</p>
<p>The arguments are treated as a string, not as a dictionary. This means that if you want to break arguments into multiple lines, you need to use the YAML folding syntax, like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: install nginx</span><br><span class="line">  apt: &gt;</span><br><span class="line">      name=nginx</span><br><span class="line">      update_cache=yes</span><br></pre></td></tr></table></figure></p>
<p>Ansible also supports a task syntax that will let you specify module arguments as a YAML dictionary, which is helpful when using modules that support complex arguments. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Install docker</span><br><span class="line">  any_errors_fatal: true</span><br><span class="line">  yum:</span><br><span class="line">    name: docker-ce</span><br><span class="line">    state: present</span><br><span class="line">    enablerepo: docker-local</span><br></pre></td></tr></table></figure></p>
<h2 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h2><p>Modules are scripts that come packaged with Ansible and perform some kind of action on a host.</p>
<p>commonly used modules:</p>
<ul>
<li>yum</li>
<li>copy</li>
<li>file</li>
<li>service</li>
<li>template</li>
</ul>
<h3 id="VIEWING-ANSIBLE-MODULE-DOCUMENTATION"><a href="#VIEWING-ANSIBLE-MODULE-DOCUMENTATION" class="headerlink" title="VIEWING ANSIBLE MODULE DOCUMENTATION"></a>VIEWING ANSIBLE MODULE DOCUMENTATION</h3><p>Ansible ships with the <code>ansible-doc</code> command-line tool, which shows documentation about modules. Think of it as man pages for Ansible modules.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-doc yum</span><br></pre></td></tr></table></figure></p>
<p>Recall from the first chapter that Ansible executes a task on a host by generating a custom script based on the module name and arguments, and then copies this script to the host and runs it.</p>
<p>More than 200 modules ship with Ansible, and this number grows with every release. You can also find third-party Ansible modules out there, or write your own.</p>
<h2 id="Putting-It-All-Together"><a href="#Putting-It-All-Together" class="headerlink" title="Putting It All Together"></a>Putting It All Together</h2><p>To sum up, a playbook contains one or more plays. A play associates an unordered set of hosts with an ordered list of tasks. Each task is associated with exactly one module.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">+-------------+</span>         <span class="string">+------------+</span>          <span class="string">+-------------+</span></span><br><span class="line"><span class="string">|             |     +---&gt;            |      +---&gt;             |</span></span><br><span class="line"><span class="string">|  playbook   +---------&gt;    play    +----------&gt;    hosts    |</span></span><br><span class="line"><span class="string">|             |     +---&gt;            |      +---&gt;             |</span></span><br><span class="line"><span class="string">+-------------+         +------+-----+          +-------------+</span></span><br><span class="line"><span class="string">                               |</span></span><br><span class="line"><span class="string">                               |</span></span><br><span class="line"><span class="string">                               |</span></span><br><span class="line"><span class="string">                             +---+</span></span><br><span class="line"><span class="string">                             | | |</span></span><br><span class="line"><span class="string">                        +----v-v-v----+         +-------------+</span></span><br><span class="line"><span class="string">                        |             |         |             |</span></span><br><span class="line"><span class="string">                        |   task      +--------&gt;+   module    |</span></span><br><span class="line"><span class="string">                        |             |         |             |</span></span><br><span class="line"><span class="string">                        +-------------+         +-------------+</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Did-Anything-Change-Tracking-Host-State"><a href="#Did-Anything-Change-Tracking-Host-State" class="headerlink" title="Did Anything Change? Tracking Host State"></a>Did Anything Change? Tracking Host State</h2><p>Ansible modules will first check to see whether the state of the host needs to be changed before taking any action. If the state of the host matches the arguments of the module, Ansible takes no action on the host and responds with a state of <code>ok</code>.</p>
<p>Ansible’s detection of state change can be used to trigger additional actions through the use of <em>handlers</em>. But, even without using handlers, it is still a useful form of feedback to see whether your hosts are changing state as the playbook runs.</p>
<h2 id="Variables-and-Handlers"><a href="#Variables-and-Handlers" class="headerlink" title="Variables and Handlers"></a>Variables and Handlers</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Configure webserver with nginx and tls</span><br><span class="line">  hosts: webservers</span><br><span class="line">  become: True</span><br><span class="line">  vars:</span><br><span class="line">    key_file: /etc/nginx/ssl/nginx.key</span><br><span class="line">    cert_file: /etc/nginx/ssl/nginx.crt</span><br><span class="line">    conf_file: /etc/nginx/sites-available/default</span><br><span class="line">    server_name: localhost</span><br><span class="line">  tasks:</span><br><span class="line">    - name: Install nginx</span><br><span class="line">      apt: name=nginx update_cache=yes cache_valid_time=3600</span><br><span class="line"></span><br><span class="line">    - name: create directories for ssl certificates</span><br><span class="line">      file: path=/etc/nginx/ssl state=directory</span><br><span class="line"></span><br><span class="line">    - name: copy TLS key</span><br><span class="line">      copy: src=files/nginx.key dest=&#123;&#123; key_file &#125;&#125; owner=root mode=0600</span><br><span class="line">      notify: restart nginx</span><br><span class="line"></span><br><span class="line">    - name: copy TLS certificate</span><br><span class="line">      copy: src=files/nginx.crt dest=&#123;&#123; cert_file &#125;&#125;</span><br><span class="line">      notify: restart nginx</span><br><span class="line"></span><br><span class="line">    - name: copy nginx config file</span><br><span class="line">      template: src=templates/nginx.conf.j2 dest=&#123;&#123; conf_file &#125;&#125;</span><br><span class="line">      notify: restart nginx</span><br><span class="line"></span><br><span class="line">    - name: enable configuration</span><br><span class="line">      file: dest=/etc/nginx/sites-enabled/default src=&#123;&#123; conf_file &#125;&#125; state=link</span><br><span class="line">      notify: restart nginx</span><br><span class="line"></span><br><span class="line">    - name: copy index.html</span><br><span class="line">      template: src=templates/index.html.j2 dest=/usr/share/nginx/html/index.html</span><br><span class="line">             mode=0644</span><br><span class="line"></span><br><span class="line">  handlers:</span><br><span class="line">    - name: restart nginx</span><br><span class="line">      service: name=nginx state=restarted</span><br></pre></td></tr></table></figure>
<h3 id="Generating-a-TLS-Certificate"><a href="#Generating-a-TLS-Certificate" class="headerlink" title="Generating a TLS Certificate"></a>Generating a TLS Certificate</h3><p>In a production environment, you’d purchase your TLS certificate from a certificate authority, or use a free service such as <a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s Encrypt</a>, which Ansible supports via the letsencrypt module.</p>
<p>Here we use self-signed certificate generated free of charge:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir files</span><br><span class="line">openssl req -x509 -nodes -days 3650 -newkey rsa:2048 \</span><br><span class="line">    -subj /CN=localhost \</span><br><span class="line">    -keyout files/nginx.key -out files/nginx.crt</span><br></pre></td></tr></table></figure></p>
<p>Any valid YAML can be used as the value of a variable. You can use lists and dictionaries in addition to strings and Booleans.</p>
<h3 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h3><p>Variables can be used in tasks, as well as in template files. You reference variables by using the <code></code> notation. Ansible replaces these braces with the value of the variable.</p>
<h3 id="WHEN-QUOTING-IS-NECESSARY"><a href="#WHEN-QUOTING-IS-NECESSARY" class="headerlink" title="WHEN QUOTING IS NECESSARY"></a>WHEN QUOTING IS NECESSARY</h3><p>bad:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: perform some task</span><br><span class="line">  command: &#123;&#123; myapp &#125;&#125; -a foo</span><br></pre></td></tr></table></figure></p>
<p>good:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: perform some task</span><br><span class="line">  command: &quot;&#123;&#123; myapp &#125;&#125; -a foo&quot;</span><br></pre></td></tr></table></figure></p>
<p>A similar problem arises if your argument contains a colon. For example, bad:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: show a debug message</span><br><span class="line">  debug: msg=&quot;The debug module will print a message: neat, eh?&quot;</span><br></pre></td></tr></table></figure></p>
<p>good:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: show a debug message</span><br><span class="line">  debug: &quot;msg=&apos;The debug module will print a message: neat, eh?&apos;&quot;</span><br></pre></td></tr></table></figure></p>
<h2 id="Generating-the-Template"><a href="#Generating-the-Template" class="headerlink" title="Generating the Template"></a>Generating the Template</h2><p>We put templates in <code>templates</code> folder, we use the <code>.j2</code> extension to indicate that the file is a Jinja2 template. However, you can use a different extension if you like; Ansible doesn’t care.</p>
<p>You can use all of the Jinja2 features in your templates, you probably won’t need to use those advanced templating features, though. One Jinja2 feature you probably will use with Ansible is filters: <a href="http://jinja.pocoo.org/docs/dev/templates/" target="_blank" rel="noopener">Jinja2 Template Designer Documentation</a>.</p>
<h3 id="Handlers"><a href="#Handlers" class="headerlink" title="Handlers"></a>Handlers</h3><p>Handlers are one of the conditional forms that Ansible supports. A handler is similar to a task, but it runs only if it has been notified by a task. A task will fire the notification if Ansible recognizes that the task has changed the state of the system. A task notifies a handler by passing the handler’s name as the argument. </p>
<h3 id="A-FEW-THINGS-TO-KEEP-IN-MIND-ABOUT-HANDLERS"><a href="#A-FEW-THINGS-TO-KEEP-IN-MIND-ABOUT-HANDLERS" class="headerlink" title="A FEW THINGS TO KEEP IN MIND ABOUT HANDLERS"></a>A FEW THINGS TO KEEP IN MIND ABOUT HANDLERS</h3><p>Handlers usually run after all of the tasks are run at the end of the <em>play</em>. They run only <em>once</em>, even if they are notified multiple times. If a play contains multiple handlers, the handlers always run in the order that they are <em>defined</em> in the handlers section, not the notification order.</p>
<p>The official Ansible docs mention that the only common uses for handlers are for restarting services and for reboots. Personally, I’ve always used them only for restarting services.Even then, it’s a pretty small optimization, since we can always just unconditionally restart the service at the end of the playbook instead of notifying it on change, and restarting a service doesn’t usually take very long.</p>
<h1 id="Chapter-3-Inventory-Describing-Your-Servers"><a href="#Chapter-3-Inventory-Describing-Your-Servers" class="headerlink" title="Chapter 3. Inventory: Describing Your Servers"></a>Chapter 3. Inventory: Describing Your Servers</h1><p>The collection of hosts that Ansible knows about is called the inventory. In this chapter, you will learn how to describe a set of hosts as an Ansible inventory.</p>
<p>Ansible automatically adds one host to the inventory by default: <em>localhost</em>. Ansible understands that localhost refers to your local machine, so it will interact with it directly rather than connecting by SSH.</p>
<h2 id="Preliminaries-Multiple-Vagrant-Machines"><a href="#Preliminaries-Multiple-Vagrant-Machines" class="headerlink" title="Preliminaries: Multiple Vagrant Machines"></a>Preliminaries: Multiple Vagrant Machines</h2><p>Before you modify your existing Vagrantfile, make sure you destroy your existing virtual machine by running the following:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vagrant destroy --force</span><br></pre></td></tr></table></figure></p>
<p><em>vagrantfile</em> for three servers:<br><figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">VAGRANTFILE_API_VERSION = <span class="string">"2"</span></span><br><span class="line"></span><br><span class="line">Vagrant.configure(VAGRANTFILE_API_VERSION) <span class="keyword">do</span> <span class="params">|config|</span></span><br><span class="line">  <span class="comment"># Use the same key for each machine</span></span><br><span class="line">  config.ssh.insert_key = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  config.vm.define <span class="string">"vagrant1"</span> <span class="keyword">do</span> <span class="params">|vagrant1|</span></span><br><span class="line">    vagrant1.vm.box = <span class="string">"ubuntu/trusty64"</span></span><br><span class="line">    vagrant1.vm.network <span class="string">"forwarded_port"</span>, <span class="symbol">guest:</span> <span class="number">80</span>, <span class="symbol">host:</span> <span class="number">8080</span></span><br><span class="line">    vagrant1.vm.network <span class="string">"forwarded_port"</span>, <span class="symbol">guest:</span> <span class="number">443</span>, <span class="symbol">host:</span> <span class="number">8443</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  config.vm.define <span class="string">"vagrant2"</span> <span class="keyword">do</span> <span class="params">|vagrant2|</span></span><br><span class="line">    vagrant2.vm.box = <span class="string">"ubuntu/trusty64"</span></span><br><span class="line">    vagrant2.vm.network <span class="string">"forwarded_port"</span>, <span class="symbol">guest:</span> <span class="number">80</span>, <span class="symbol">host:</span> <span class="number">8081</span></span><br><span class="line">    vagrant2.vm.network <span class="string">"forwarded_port"</span>, <span class="symbol">guest:</span> <span class="number">443</span>, <span class="symbol">host:</span> <span class="number">8444</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line">  config.vm.define <span class="string">"vagrant3"</span> <span class="keyword">do</span> <span class="params">|vagrant3|</span></span><br><span class="line">    vagrant3.vm.box = <span class="string">"ubuntu/trusty64"</span></span><br><span class="line">    vagrant3.vm.network <span class="string">"forwarded_port"</span>, <span class="symbol">guest:</span> <span class="number">80</span>, <span class="symbol">host:</span> <span class="number">8082</span></span><br><span class="line">    vagrant3.vm.network <span class="string">"forwarded_port"</span>, <span class="symbol">guest:</span> <span class="number">443</span>, <span class="symbol">host:</span> <span class="number">8445</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<p>Using the same key on each host simplifies our Ansible setup because we can specify a single SSH key in the <em>ansible.cfg</em> file:<br><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[defaults]</span></span><br><span class="line"><span class="attr">inventory</span> = inventory</span><br><span class="line"><span class="attr">remote_user</span> = vagrant</span><br><span class="line"><span class="attr">private_key_file</span> = ~/.vagrant.d/insecure_private_key</span><br><span class="line"><span class="attr">host_key_checking</span> = <span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<p>In the inventory file, you can use <code>ansible_host</code> to explicitly specify IP and <code>ansible_port</code> indicates SSH port number:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant1 ansible_host=127.0.0.1 ansible_port=2222</span><br><span class="line">vagrant2 ansible_host=127.0.0.1 ansible_port=2200</span><br><span class="line">vagrant3 ansible_host=127.0.0.1 ansible_port=2201</span><br></pre></td></tr></table></figure></p>
<h2 id="Behavioral-Inventory-Parameters"><a href="#Behavioral-Inventory-Parameters" class="headerlink" title="Behavioral Inventory Parameters"></a>Behavioral Inventory Parameters</h2><p><a href="https://www.tablesgenerator.com/markdown_tables" target="_blank" rel="noopener">Markdown table generator</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">|            Name            	|     Default     	|                                   Description                                   	|</span><br><span class="line">|:--------------------------:	|:---------------:	|:-------------------------------------------------------------------------------:	|</span><br><span class="line">| ansible_host               	| Name of host    	| Hostname or IP address to SSH to                                                	|</span><br><span class="line">| ansible_port               	| 22              	| Port to SSH to                                                                  	|</span><br><span class="line">| ansible_user               	| Root            	| User to SSH as                                                                  	|</span><br><span class="line">| ansible_password           	| (None)          	| Password to use for SSH authentication                                          	|</span><br><span class="line">| ansible_connection         	| smart           	| How Ansible will connect to host (see the following section)                    	|</span><br><span class="line">| ansible_private_key_file   	| (None)          	| SSH private key to use for SSH authenticatio                                    	|</span><br><span class="line">| ansible_shell_type         	| sh              	| Shell to use for commands (see the following section)                           	|</span><br><span class="line">| ansible_python_interpreter 	| /usr/bin/python 	| Python interpreter on host (see the following section)                          	|</span><br><span class="line">| ansible_*_interpreter      	| (None)          	| Like ansible_python_interpreter for other languages (see the following section) 	|</span><br></pre></td></tr></table></figure></p>
<p>Explanation:</p>
<ul>
<li><p>ansible_connection<br>Ansible supports multiple <em>transports</em>, which are mechanisms that Ansible uses to connect to the host. The default transport, <code>smart</code>, will check whether the locally installed SSH client supports a feature called <em>ControlPersist</em>. If the SSH client supports ControlPersist, Ansible will use the local SSH client. If the SSH client doesn’t support ControlPersist, the smart transport will fall back to using a Python-based SSH client library called <em>Paramiko</em>.</p>
</li>
<li><p>ansible_shell_type<br>Ansible works by making SSH connections to remote machines and then invoking scripts. By default, Ansible assumes that the remote shell is the Bourne shell located at <em>/bin/sh</em>, and will generate the appropriate command-line parameters that work with Bourne shell.</p>
<p>Ansible also accepts <code>csh</code>, <code>fish</code>, and (on Windows) <code>powershell</code> as valid values for<br>this parameter. I’ve never encountered a need for changing the shell type.</p>
</li>
<li><p>ansible_python_interpreter<br>Because the modules that ship with Ansible are implemented in Python 2, Ansible needs to know the location of the Python interpreter on the remote machine. You might need to change this if your remote host does not have a Python 2 interpreter at <em>/usr/bin/python</em>. For example, if you are managing hosts that run Arch Linux, you will need to change this to <em>/usr/bin/python2</em>, because Arch Linux installs Python 3 at <em>/usr/bin/python</em>, and Ansible modules are not (yet) compatible with Python 3.</p>
</li>
<li><p>ansible_*_interpreter<br>If you are using a custom module that is not written in Python, you can use this parameter to specify the location of the interpreter (e.g., /usr/bin/ruby).</p>
</li>
</ul>
<p><strong>Note</strong>: You can override some of the behavioral parameter default values in the defaults section of the <code>ansible.cfg</code> file<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Behavioral inventory parameter 	| ansible.cfg option 	|</span><br><span class="line">|:------------------------------:	|:------------------:	|</span><br><span class="line">| ansible_port                   	| remote_port        	|</span><br><span class="line">| ansible_user                   	| remote_user        	|</span><br><span class="line">| ansible_private_key_file       	| private_key_file   	|</span><br><span class="line">| ansible_shell_type             	| executable         	|</span><br></pre></td></tr></table></figure></p>
<h2 id="Groups"><a href="#Groups" class="headerlink" title="Groups"></a>Groups</h2><p>Ansible automatically defines a group called <code>all</code> (or <code>*</code>), which includes all of the hosts in the inventory. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible all -a &quot;date&quot;</span><br><span class="line">ansible &apos;*&apos; -a &quot;date&quot;</span><br></pre></td></tr></table></figure></p>
<p>We can define our own groups in the inventory file. Ansible uses the <em>.ini</em> file format for inventory files. In the <em>.ini</em> format, configuration values are grouped together into sections. For example:<br><figure class="highlight ini"><table><tr><td class="code"><pre><span class="line"><span class="section">[master]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[workers]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[nodes]</span></span><br><span class="line"></span><br><span class="line"><span class="section">[all:vars]</span></span><br><span class="line"><span class="attr">ansible_connection</span>=ssh</span><br><span class="line"><span class="attr">ansible_user</span>=root</span><br><span class="line"><span class="attr">ansible_ssh_private_key_file</span>=null</span><br><span class="line"><span class="attr">gather_facts</span>=<span class="literal">True</span></span><br><span class="line"><span class="attr">gathering</span>=smart</span><br><span class="line"><span class="attr">host_key_checking</span>=<span class="literal">False</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Alias-and-Ports"><a href="#Alias-and-Ports" class="headerlink" title="Alias and Ports:"></a>Alias and Ports:</h2><p>In inventory file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[master]</span><br><span class="line">&lt;hostname&gt;</span><br><span class="line">&lt;hostname&gt;:&lt;port number&gt;</span><br><span class="line">&lt;alias&gt; ansible_host=&lt;IP&gt; ansible_port=&lt;port number&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Groups-of-groups"><a href="#Groups-of-groups" class="headerlink" title="Groups of groups"></a>Groups of groups</h2><p>Ansible also allows you to define groups that are made up of other groups. Here web and task are groups, diango subgroup wrap them up.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[django:children]</span><br><span class="line">web</span><br><span class="line">task</span><br></pre></td></tr></table></figure></p>
<h2 id="Numbered-hosts"><a href="#Numbered-hosts" class="headerlink" title="Numbered hosts"></a>Numbered hosts</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[host]</span><br><span class="line">web[1:20].example.com</span><br><span class="line">## leading 0</span><br><span class="line">web[01:20].example.com</span><br><span class="line">web-[a-t].example.com</span><br></pre></td></tr></table></figure>
<h2 id="Host-and-Group-Variables"><a href="#Host-and-Group-Variables" class="headerlink" title="Host and Group Variables"></a>Host and Group Variables</h2><p>Format: [<group name="">:vars]<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[all:vars]</span><br><span class="line"></span><br><span class="line">[production:vars]</span><br><span class="line"></span><br><span class="line">[staging:vars]</span><br></pre></td></tr></table></figure></group></p>
<p>Additionally, though Ansible variables can hold Booleans, strings, lists, and dictionaries, in an inventory file, you can specify only Booleans and strings.</p>
<p>Ansible offers a more scalable approach to keep track of host and group variables: you can create a separate variable file for each host and each group. Ansible expects these variable files to be in YAML format.</p>
<p>Ansible looks for host variable files in a directory called <code>host_vars</code> and group variable files in a directory called <code>group_vars</code>. Ansible expects these directories to be either in the directory that contains your playbooks or in the directory adjacent to your inventory file. For example:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">playbooks</span> <span class="attr">folder:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">playbook.yml</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">group_vars</span> <span class="string">folder</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">production</span></span><br></pre></td></tr></table></figure></p>
<p>If we use YAML dictionary format in group variable file:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">db:</span></span><br><span class="line"><span class="attr">    user:</span> <span class="string">widgetuser</span></span><br><span class="line"><span class="attr">    password:</span> <span class="string">pFmMxcyD;Fc6)6</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">widget_production</span></span><br><span class="line"><span class="attr">    primary:</span></span><br><span class="line"><span class="attr">        host:</span> <span class="string">rhodeisland.example.com</span></span><br><span class="line"><span class="attr">        port:</span> <span class="number">5432</span></span><br><span class="line"><span class="attr">    replica:</span></span><br><span class="line"><span class="attr">        host:</span> <span class="string">virginia.example.com</span></span><br><span class="line"><span class="attr">        port:</span> <span class="number">5432</span></span><br><span class="line"></span><br><span class="line"><span class="attr">rabbitmq:</span></span><br><span class="line"><span class="attr">    host:</span> <span class="string">pennsylvania.example.com</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">5672</span></span><br></pre></td></tr></table></figure></p>
<p>when reference in playbook:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123; db.primary.host &#125;&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Dynamic-Inventory"><a href="#Dynamic-Inventory" class="headerlink" title="Dynamic Inventory"></a>Dynamic Inventory</h2><p>If the inventory file is marked executable, Ansible will assume it is a dynamic inventory script and will execute the file instead of reading it.</p>
<p>If some other system, such as AWS EC2, will keep track of the virtual machine information for us, we don’t necessarily need to write the inventory file manually, we can use dynamic inventory script to query about which machines are running and use them.</p>
<p><a href="https://github.com/ansible/ansible/blob/devel/contrib/inventory/vagrant.py" target="_blank" rel="noopener">preexisting inventory scripts</a></p>
<h2 id="Adding-Entries-at-Runtime-with-add-host-and-group-by"><a href="#Adding-Entries-at-Runtime-with-add-host-and-group-by" class="headerlink" title="Adding Entries at Runtime with add_host and group_by"></a>Adding Entries at Runtime with add_host and group_by</h2><p>Ansible will let you add hosts and groups to the inventory during the execution of a playbook.<br><strong>not use yet</strong></p>
<h1 id="Chapter-4-Variables-and-Facts"><a href="#Chapter-4-Variables-and-Facts" class="headerlink" title="Chapter 4. Variables and Facts"></a>Chapter 4. Variables and Facts</h1><p>Ansible is not a full-fledged programming language, but it does have several programming language features, and one of the most important of these is <strong>variable substitution</strong>. This chapter presents Ansible’s support for variables in more detail, including a certain type of variable that Ansible calls a <em>fact</em>.</p>
<h2 id="Defining-Variables-in-Playbooks"><a href="#Defining-Variables-in-Playbooks" class="headerlink" title="Defining Variables in Playbooks"></a>Defining Variables in Playbooks</h2><p>There are two scenarios, for example:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Configure</span> <span class="string">Kubeadm</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">  become:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  vars:</span></span><br><span class="line"><span class="attr">    NODE_COUNT:</span> <span class="string">"<span class="template-variable">&#123;&#123; groups['nodes'] | length &#125;&#125;</span>"</span></span><br><span class="line"><span class="attr">  roles:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">setup.master</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## or</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Configure</span> <span class="string">Kubeadm</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">master</span></span><br><span class="line"><span class="attr">  become:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  vars_files:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">config.yml</span></span><br><span class="line"><span class="attr">  roles:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">setup.master</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Viewing-the-Values-of-Variables"><a href="#Viewing-the-Values-of-Variables" class="headerlink" title="Viewing the Values of Variables"></a>Viewing the Values of Variables</h2><p>We use the <code>debug</code> module to print out an arbitrary message. We can also use it to output the value of the variable.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- debug: var=&lt;myvarname&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Registering-Variables"><a href="#Registering-Variables" class="headerlink" title="Registering Variables"></a>Registering Variables</h2><p>Often, you’ll find that you need to set the value of a variable based on the result of a task.To do so, we create a <em>registered variable</em> using the <code>register</code> clause when invoking a module. Below shows how to capture the output of the <code>whoami</code> command to a variable named <code>login</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: capture output of whoami command</span><br><span class="line">  command: whoami</span><br><span class="line">  register: login</span><br></pre></td></tr></table></figure></p>
<p><strong>Note</strong>, if you want to use <code>login</code> variable registered here, it’s not like that you can call it as <code></code></p>
<p>In order to use the login variable later, we need to know the type of value to expect. The value of a variable set using the register clause is always a dictionary, but the specific keys of the dictionary are different, depending on the module that was invoked.</p>
<p>Unfortunately, the official Ansible module documentation doesn’t contain information about what the return values look like for each module. The module docs do often contain examples that use the register clause, which can be helpful. I’ve found the simplest way to find out what a module returns is to register a variable and then output that variable with the debug module.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: show return value of command module</span><br><span class="line">  hosts: server1</span><br><span class="line">  tasks:</span><br><span class="line">    - name: capture output of id command</span><br><span class="line">      command: id -un</span><br><span class="line">      register: login</span><br><span class="line">    - debug: var=login</span><br></pre></td></tr></table></figure></p>
<p>The <code>shell</code> module has the same output structure as the <code>command</code> module, but other modules contain different keys, the output here is:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK: [debug var=login] *******************************************************</span><br><span class="line">ok: [server1] =&gt; &#123;</span><br><span class="line">    &quot;login&quot;: &#123;</span><br><span class="line">        &quot;changed&quot;: true, 1</span><br><span class="line">        &quot;cmd&quot;: [ 2</span><br><span class="line">            &quot;id&quot;,</span><br><span class="line">            &quot;-un&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;delta&quot;: &quot;0:00:00.002180&quot;,</span><br><span class="line">        &quot;end&quot;: &quot;2015-01-11 15:57:19.193699&quot;,</span><br><span class="line">        &quot;invocation&quot;: &#123;</span><br><span class="line">            &quot;module_args&quot;: &quot;id -un&quot;,</span><br><span class="line">            &quot;module_name&quot;: &quot;command&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;rc&quot;: 0, 3</span><br><span class="line">        &quot;start&quot;: &quot;2015-01-11 15:57:19.191519&quot;,</span><br><span class="line">        &quot;stderr&quot;: &quot;&quot;, 4</span><br><span class="line">        &quot;stdout&quot;: &quot;vagrant&quot;, 5</span><br><span class="line">        &quot;stdout_lines&quot;: [ 6</span><br><span class="line">            &quot;vagrant&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;warnings&quot;: []</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>The <code>changed</code> key is present in the return value of all Ansible modules, and Ansible uses it to determine whether a state change has occurred. For the <code>command</code> and <code>shell</code>module, this will always be set to <code>true</code> unless overridden with the <code>changed_when</code>clause.</p>
</li>
<li><p>The <code>cmd</code> key contains the invoked command as a list of strings.</p>
</li>
<li><p>The <code>rc</code> key contains the return code. If it is nonzero, Ansible will assume the task failed to execute.</p>
</li>
<li><p>The <code>stdout</code> key contains any text written to standard out, as a single string.</p>
</li>
<li><p>The <code>stdout_lines</code> key contains any text written to split by newline. It is a list, and each element of the list is a line of output.</p>
</li>
</ul>
<p>So now you can access <code>login</code> with:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: capture output of id command</span><br><span class="line">  command: id -un</span><br><span class="line">  register: login</span><br><span class="line">- debug: msg=&quot;Logged in as user &#123;&#123; login.stdout &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<h3 id="ACCESSING-DICTIONARY-KEYS-IN-A-VARIABLE"><a href="#ACCESSING-DICTIONARY-KEYS-IN-A-VARIABLE" class="headerlink" title="ACCESSING DICTIONARY KEYS IN A VARIABLE"></a>ACCESSING DICTIONARY KEYS IN A VARIABLE</h3><p>If a variable contains a dictionary, you can access the keys of the dictionary by using either a dot (.) or a subscript ([]).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123; login.stdout &#125;&#125;</span><br><span class="line">&#123;&#123; login[&apos;stdout&apos;] &#125;&#125;</span><br><span class="line"></span><br><span class="line">ansible_eth1[&apos;ipv4&apos;][&apos;address&apos;]</span><br><span class="line">ansible_eth1[&apos;ipv4&apos;].address</span><br><span class="line">ansible_eth1.ipv4[&apos;address&apos;]</span><br><span class="line">ansible_eth1.ipv4.address</span><br></pre></td></tr></table></figure></p>
<h3 id="CAUTION"><a href="#CAUTION" class="headerlink" title="CAUTION"></a>CAUTION</h3><p>If your playbooks use registered variables, make sure you know the content of those variables, both for cases where the module changes the host’s state and for when the module doesn’t change the host’s state. Otherwise, your playbook might fail when it tries to access a key in a registered variable that doesn’t exist.</p>
<h2 id="Facts"><a href="#Facts" class="headerlink" title="Facts"></a>Facts</h2><p>As you’ve already seen, when Ansible runs a playbook, before the first task runs, this happens:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GATHERING FACTS **************************************************</span><br><span class="line">ok: [servername]</span><br></pre></td></tr></table></figure></p>
<p>When Ansible gathers facts, it connects to the host and queries it for all kinds of details about the host: CPU architecture, operating system, IP addresses, memory info, disk info, and more. This information is stored in variables that are called <em>facts</em>, and they behave just like any other variable. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: print out operating system</span><br><span class="line">  hosts: all</span><br><span class="line">  gather_facts: True</span><br><span class="line">  tasks:</span><br><span class="line">  - debug: var=ansible_distribution</span><br></pre></td></tr></table></figure></p>
<p>List of facts variable can be found <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#information-discovered-from-systems-facts" target="_blank" rel="noopener">here</a></p>
<h3 id="Viewing-All-Facts-Associated-with-a-Server"><a href="#Viewing-All-Facts-Associated-with-a-Server" class="headerlink" title="Viewing All Facts Associated with a Server"></a>Viewing All Facts Associated with a Server</h3><p>Ansible implements fact collecting through the use of a special module called the <code>setup</code>module. You don’t need to call this module in your playbooks because Ansible does that automatically when it gathers facts.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible server1 -m setup</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server1 | success &gt;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;ansible_all_ipv4_addresses&quot;: [</span><br><span class="line">            &quot;10.0.2.15&quot;,</span><br><span class="line">            &quot;192.168.4.10&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;ansible_all_ipv6_addresses&quot;: [</span><br><span class="line">            &quot;fe80::a00:27ff:fefe:1e4d&quot;,</span><br><span class="line">            &quot;fe80::a00:27ff:fe67:bbf3&quot;</span><br><span class="line">        ],</span><br><span class="line">(many more facts)</span><br></pre></td></tr></table></figure>
<p>Note that the returned value is a dictionary whose key is <code>ansible_facts</code> and whose value is a dictionary that contains the name and value of the actual facts.</p>
<h3 id="Viewing-a-Subset-of-Facts"><a href="#Viewing-a-Subset-of-Facts" class="headerlink" title="Viewing a Subset of Facts"></a>Viewing a Subset of Facts</h3><p>The <code>setup</code> module supports a <code>filter</code> parameter that lets you filter by fact name by specifying a glob.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible web -m setup -a &apos;filter=ansible_eth*&apos;</span><br></pre></td></tr></table></figure></p>
<h3 id="Any-Module-Can-Return-Facts"><a href="#Any-Module-Can-Return-Facts" class="headerlink" title="Any Module Can Return Facts"></a>Any Module Can Return Facts</h3><p>The use of <code>ansible_facts</code> in the return value is an Ansible idiom. If a module returns a dictionary that contains <code>ansible_facts</code> as a key, Ansible will create variable names in the environment with those values and associate them with the active host.</p>
<p>For modules that return facts, there’s no need to register variables, since Ansible creates these variables for you automatically.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: get ec2 facts</span><br><span class="line">  ec2_facts:</span><br><span class="line"></span><br><span class="line">- debug: var=ansible_ec2_instance_id</span><br></pre></td></tr></table></figure></p>
<p>Several modules ship with Ansible that return facts. You’ll see another one of them, the <code>docker</code> module.</p>
<h3 id="Local-Facts"><a href="#Local-Facts" class="headerlink" title="Local Facts"></a>Local Facts</h3><p>Ansible provides an additional mechanism for associating facts with a host. You can place one or more files on the remote host machine in the <code>/etc/ansible/facts.d</code> directory.<br><strong>not used yet</strong></p>
<h3 id="Using-set-fact-to-Define-a-New-Variable"><a href="#Using-set-fact-to-Define-a-New-Variable" class="headerlink" title="Using set_fact to Define a New Variable"></a>Using set_fact to Define a New Variable</h3><p>Ansible also allows you to set a fact (effectively the same as defining a new variable) in a task by using the <code>set_fact</code> module. I often like to use <code>set_fact</code> immediately after <code>register</code> to make it simpler to refer to a variable.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: get snapshot id</span><br><span class="line">  shell: &gt;</span><br><span class="line">    aws ec2 describe-snapshots --filters</span><br><span class="line">    Name=tag:Name,Values=my-snapshot</span><br><span class="line">    | jq --raw-output &quot;.Snapshots[].SnapshotId&quot;</span><br><span class="line">  register: snap_result</span><br><span class="line"></span><br><span class="line">- set_fact: snap=&#123;&#123; snap_result.stdout &#125;&#125;</span><br><span class="line"></span><br><span class="line">- name: delete old snapshot</span><br><span class="line">  command: aws ec2 delete-snapshot --snapshot-id &quot;&#123;&#123; snap &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<h2 id="Built-in-Variables"><a href="#Built-in-Variables" class="headerlink" title="Built-in Variables"></a>Built-in Variables</h2><p>Ansible defines several variables that are always available in a playbook<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Parameter                	| Description                                                                                                                                                                                 	|</span><br><span class="line">|--------------------------	|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|</span><br><span class="line">| hostvars                 	| A dict whose keys are Ansible hostnames and values are dicts  that map variable names to values                                                                                             	|</span><br><span class="line">| inventory_hostname       	| Fully qualified domain name of the current host as known by Ansible  (e.g., myhost.example.com)                                                                                             	|</span><br><span class="line">| inventory_hostname_short 	| Name of the current host as known by Ansible, without the domain name  (e.g., myhost)                                                                                                       	|</span><br><span class="line">| group_names              	| A list of all groups that the current host is a member of                                                                                                                                   	|</span><br><span class="line">| groups                   	| A dict whose keys are Ansible group names and values are a list of  hostnames that are members of the group. Includes all and ungrouped groups:  &#123;&quot;all&quot;: […], &quot;web&quot;: […], &quot;ungrouped&quot;: […]&#125; 	|</span><br><span class="line">| ansible_check_mode       	| A boolean that is true when running in check mode                                                                                                                                           	|</span><br><span class="line">| ansible_play_batch       	| A list of the inventory hostnames that are active in the current batch                                                                                                                      	|</span><br><span class="line">| ansible_play_hosts       	| A list of all of the inventory hostnames that are active in the current  play                                                                                                               	|</span><br><span class="line">| ansible_version          	| A dict with Ansible version info:  &#123;&quot;full&quot;: 2.3.1.0&quot;, &quot;major&quot;: 2, &quot;minor&quot;: 3, &quot;revision&quot;: 1, &quot;string&quot;: &quot;2.3.1.0&quot;&#125;                                                                           	|</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p><strong>hostvars</strong><br>This is a dictionary that contains all of the variables defined on all of the hosts, keyed by the hostname as known to Ansible. If Ansible has not yet gathered facts on a host, you will not be able to access its facts by using the hostvars variable, unless fact caching is enabled.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123; hostvars[&apos;db.example.com&apos;].ansible_eth1.ipv4.address &#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>inventory_hostname</strong><br>The inventory_hostname is the hostname of the current host, as known by Ansible.</p>
</li>
<li><p><strong>groups</strong><br>The groups variable can be useful when you need to access variables for a group of hosts.</p>
</li>
</ul>
<p>I encounter this in playbook vars section:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: xxx</span><br><span class="line">  hosts: master</span><br><span class="line">  become: true</span><br><span class="line">  any_errors_fatal: true</span><br><span class="line">  vars:</span><br><span class="line">    NODE_COUNT: &quot;&#123;&#123; groups[&apos;nodes&apos;] | length &#125;&#125;&quot;</span><br><span class="line">  roles:</span><br><span class="line">    - ...</span><br><span class="line"></span><br><span class="line">- name: xxx</span><br><span class="line">  any_errors_fatal: true</span><br><span class="line">  shell: &quot;...&quot;</span><br><span class="line">  when: &quot;inventory_hostname == groups.master[0]&quot;</span><br></pre></td></tr></table></figure></p>
<h2 id="Setting-Variables-on-the-Command-Line"><a href="#Setting-Variables-on-the-Command-Line" class="headerlink" title="Setting Variables on the Command Line"></a>Setting Variables on the Command Line</h2><p>Variables set by passing <code>-e var=value</code> to <code>ansible-playbook</code> have the highest precedence, which means you can use this to override variables that are already defined.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook greet.yml -e &apos;greeting=&quot;hi there&quot;&apos;</span><br></pre></td></tr></table></figure></p>
<p>Ansible also allows you to pass a file containing the variables instead of passing them directly on the command line by passing @filename.yml as the argument to <code>-e</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook greet.yml -e @greetvars.yml</span><br></pre></td></tr></table></figure></p>
<p>content in <code>greetvars.yml</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">greeting: hiya</span><br></pre></td></tr></table></figure></p>
<h2 id="Precedence"><a href="#Precedence" class="headerlink" title="Precedence"></a>Precedence</h2><p>We’ve covered several ways of defining variables, and it can happen that you define the same variable multiple times for a host, using different values. Avoid this when you can, but if you can’t, then keep in mind Ansible’s precedence rules.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. (Highest) ansible-playbook -e var=value</span><br><span class="line">2. Task variables</span><br><span class="line">3. Block variables</span><br><span class="line">4. Role and include variables</span><br><span class="line">5. set_fact</span><br><span class="line">6. Registered variables</span><br><span class="line">7. vars_files</span><br><span class="line">8. vars_prompt</span><br><span class="line">9. Play variables</span><br><span class="line">10. Host facts</span><br><span class="line">11. host_vars set on a playbook</span><br><span class="line">12. group_vars set on a playbook</span><br><span class="line">13. host_vars set in the inventory</span><br><span class="line">14. group_vars set in the inventory</span><br><span class="line">15. Inventory variables</span><br><span class="line">16. In defaults/main.yml of a role</span><br></pre></td></tr></table></figure></p>
<h1 id="Chapter-5-Introducing-Mezzanine-Our-Test-Application"><a href="#Chapter-5-Introducing-Mezzanine-Our-Test-Application" class="headerlink" title="Chapter 5. Introducing Mezzanine: Our Test Application"></a>Chapter 5. Introducing Mezzanine: Our Test Application</h1><p>Let’s take a little detour and talk about the differences between running software in development mode on your laptop versus running the software in production. Mezzanine is a great example of an application that is much easier to run in development mode than it is to deploy.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">virtualenv venv</span><br><span class="line">source venv/bin/activate</span><br><span class="line">pip install mezzanine</span><br><span class="line">mezzanine-project myproject</span><br><span class="line">cd myproject</span><br><span class="line">sed -i &apos;s/ALLOWED_HOSTS = \[\]/ALLOWED_HOSTS = [&quot;127.0.0.1&quot;]/&apos; settings.py</span><br><span class="line">python manage.py createdb</span><br><span class="line">python manage.py runserver</span><br></pre></td></tr></table></figure></p>
<p>You’ll be prompted to answer several questions. I answered “yes” to each yes/no question, and accepted the default answer whenever one was available.</p>
<p>Now, let’s look at what happens when you deploy to production.</p>
<ul>
<li><p><strong>PostgreSQL: The Database</strong><br>In production, we want to run a server-based database, because those have better support for multiple, concurrent requests, and server-based databases allow us to run multiple HTTP servers for load balancing. This means we need to deploy a database management system such as MySQL or PostgreSQL (aka Postgres). </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Install the database software.</span><br><span class="line">Ensure the database service is running.</span><br><span class="line">Create the database inside the database management system.</span><br><span class="line">Create a database user who has the appropriate permissions for the database system.</span><br><span class="line">Configure our Mezzanine application with the database user credentials and </span><br><span class="line">connection information.</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Gunicorn: The Application Server</strong></p>
</li>
<li><p><strong>Nginx: The Web Server</strong></p>
</li>
</ul>
<blockquote>
<p>Note: Application server and Web server, their usage is different. Here Nginx is like a <a href="https://www.cnblogs.com/Anker/p/6056540.html" target="_blank" rel="noopener">reverse proxy</a> for Gunicorn.</p>
</blockquote>
<ul>
<li><strong>Supervisor: The Process Manager</strong></li>
</ul>
<h1 id="Chapter-7-Roles-Scaling-Up-Your-Playbooks"><a href="#Chapter-7-Roles-Scaling-Up-Your-Playbooks" class="headerlink" title="Chapter 7. Roles: Scaling Up Your Playbooks"></a>Chapter 7. Roles: Scaling Up Your Playbooks</h1><p>Ansible scales down well because simple tasks are easy to implement. It scales up well because it provides mechanisms for decomposing complex jobs into smaller pieces.</p>
<p>In Ansible, the <code>role</code> is the primary mechanism for breaking a playbook into multiple files. This simplifies writing complex playbooks, and it makes them easier to reuse.</p>
<h2 id="Basic-Structure-of-a-Role"><a href="#Basic-Structure-of-a-Role" class="headerlink" title="Basic Structure of a Role"></a>Basic Structure of a Role</h2><p>An Ansible role has a name, such as <code>database</code>. Files associated with the <code>database</code> role go in the <em>roles/database</em> directory, which contains the following files and directories:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| roles/database/tasks/main.yml    	| Tasks                                    	|</span><br><span class="line">| roles/database/files/            	| Holds files to be uploaded to hosts      	|</span><br><span class="line">| roles/database/templates/        	| Holds Jinja2 template files              	|</span><br><span class="line">| roles/database/handlers/main.yml 	| Handlers                                 	|</span><br><span class="line">| roles/database/vars/main.yml     	| Variables that shouldn’t be overridden   	|</span><br><span class="line">| roles/database/defaults/main.yml 	| Default variables that can be overridden 	|</span><br><span class="line">| roles/database/meta/main.yml     	| Dependency information about a role      	|</span><br></pre></td></tr></table></figure></p>
<p>Each individual file is optional; if your role doesn’t have any handlers, there’s no need to have an empty handlers/main.yml file.</p>
<h2 id="WHERE-DOES-ANSIBLE-LOOK-FOR-MY-ROLES"><a href="#WHERE-DOES-ANSIBLE-LOOK-FOR-MY-ROLES" class="headerlink" title="WHERE DOES ANSIBLE LOOK FOR MY ROLES?"></a>WHERE DOES ANSIBLE LOOK FOR MY ROLES?</h2><p>Ansible looks for roles in the <em>roles</em> directory alongside your playbooks. It also looks for systemwide roles in <em>/etc/ansible/roles</em>. You can customize the systemwide location of roles by setting the <code>roles_path</code> setting in the <code>defaults</code> section of your <em>ansible.cfg</em> file.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">roles_path = ~/ansible_roles</span><br></pre></td></tr></table></figure></p>
<h2 id="Using-Roles-in-Your-Playbooks"><a href="#Using-Roles-in-Your-Playbooks" class="headerlink" title="Using Roles in Your Playbooks"></a>Using Roles in Your Playbooks</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: deploy mezzanine on vagrant</span><br><span class="line">  ## target hosts</span><br><span class="line">  hosts: web</span><br><span class="line">  vars_files:</span><br><span class="line">    - secrets.yml</span><br><span class="line">  ## role section</span><br><span class="line">  roles:</span><br><span class="line">    - role: database</span><br><span class="line">       ## pass variables into role task</span><br><span class="line">      database_name: &quot;&#123;&#123; mezzanine_proj_name &#125;&#125;&quot;</span><br><span class="line">      database_user: &quot;&#123;&#123; mezzanine_proj_name &#125;&#125;&quot;</span><br><span class="line"></span><br><span class="line">    - role: mezzanine</span><br><span class="line">      live_hostname: 192.168.33.10.xip.io</span><br><span class="line">      domains:</span><br><span class="line">        - 192.168.33.10.xip.io</span><br><span class="line">        - www.192.168.33.10.xip.io</span><br></pre></td></tr></table></figure>
<p>Note that we can pass in variables when invoking the roles. If these variables have already been defined in the role (either in vars/main.yml or defaults/main.yml), then the values will be overridden with the variables that were passed in.</p>
<h2 id="Pre-Tasks-and-Post-Tasks"><a href="#Pre-Tasks-and-Post-Tasks" class="headerlink" title="Pre-Tasks and Post-Tasks"></a>Pre-Tasks and Post-Tasks</h2><p>Sometimes you want to run tasks before or after you invoke your roles. Let’s say you want to update the apt cache before you deploy Mezzanine, and you want to send a notification to a Slack channel after you deploy.</p>
<p>Ansible allows you to define a list of tasks that execute before the roles with a <code>pre_tasks</code> section, and a list of tasks that execute after the roles with a <code>post_tasks</code>section.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">deploy</span> <span class="string">mezzanine</span> <span class="string">on</span> <span class="string">vagrant</span></span><br><span class="line"><span class="attr">  hosts:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">  vars_files:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">secrets.yml</span></span><br><span class="line"><span class="attr">  pre_tasks:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">update</span> <span class="string">the</span> <span class="string">apt</span> <span class="string">cache</span></span><br><span class="line"><span class="attr">      apt:</span> <span class="string">update_cache=yes</span></span><br><span class="line"><span class="attr">  roles:</span></span><br><span class="line"><span class="attr">    - role:</span> <span class="string">mezzanine</span></span><br><span class="line"><span class="attr">  post_tasks:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">notify</span> <span class="string">Slack</span> <span class="string">that</span> <span class="string">the</span> <span class="string">servers</span> <span class="string">have</span> <span class="string">been</span> <span class="string">updated</span></span><br><span class="line"><span class="attr">      local_action:</span> <span class="string">&gt;</span></span><br><span class="line"><span class="string">        slack</span></span><br><span class="line"><span class="string">        domain=acme.slack.com</span></span><br><span class="line"><span class="string">        token=<span class="template-variable">&#123;&#123; slack_token &#125;&#125;</span></span></span><br><span class="line"><span class="string">        msg="web server <span class="template-variable">&#123;&#123; inventory_hostname &#125;&#125;</span> configured"</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: you need to define and put variables in right place, for example, the variables that would be used by multiple roles or playbooks should be put in <code>group_vars/all</code> file.</p>
</blockquote>
<h2 id="WHY-ARE-THERE-TWO-WAYS-TO-DEFINE-VARIABLES-IN-ROLES"><a href="#WHY-ARE-THERE-TWO-WAYS-TO-DEFINE-VARIABLES-IN-ROLES" class="headerlink" title="WHY ARE THERE TWO WAYS TO DEFINE VARIABLES IN ROLES?"></a>WHY ARE THERE TWO WAYS TO DEFINE VARIABLES IN ROLES?</h2><p>When Ansible first introduced support for roles, there was only one place to define role variables, in <em>vars/main.yml</em>. Variables defined in this location have a higher precedence than those defined in the <code>vars</code> section of a play, which meant you couldn’t override the variable unless you explicitly passed it as an argument to the role.</p>
<p>Ansible later introduced the notion of default role variables that go in <em>defaults/main.yml</em>.This type of variable is defined in a role, but has a low precedence, so it will be overridden if another variable with the same name is defined in the playbook.</p>
<p>If you think you might want to change the value of a variable in a role, use a default variable. If you don’t want it to change, use a regular variable.</p>
<h2 id="Some-role-practices"><a href="#Some-role-practices" class="headerlink" title="Some role practices"></a>Some role practices</h2><p><strong>Note</strong> that if for role variables, it’s better to add prefix like <code>&lt;role name&gt;_&lt;var name&gt;</code>. It’s good practice to do this with role variables because Ansible doesn’t have any notion of namespace across roles. This means that variables that are defined in other roles, or elsewhere in a playbook, will be accessible everywhere. This can cause some unexpected behavior if you accidentally use the same variable name in two different roles. For example, for the role called <code>mezzanine</code>, in <code>roles/mezzanine/vars/main.yml</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mezzanine_user: &quot;&#123;&#123; ansible_user &#125;&#125;&quot;</span><br><span class="line">mezzanine_venv_home: &quot;&#123;&#123; ansible_env.HOME &#125;&#125;&quot;</span><br><span class="line">mezzanine_venv_path: &quot;&#123;&#123; mezzanine_venv_home &#125;&#125;/&#123;&#123; mezzanine_proj_name &#125;&#125;&quot;</span><br><span class="line">mezzanine_repo_url: git@github.com:lorin/mezzanine-example.git</span><br><span class="line">mezzanine_proj_dirname: project</span><br></pre></td></tr></table></figure></p>
<p>For role variables in <em>default/main.yml</em>, no need to add prefix because we may intentionally override them elsewhere.</p>
<p>If the role task is very long, you can break it into several task files, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">roles/mezzanine/tasks/django.yml</span><br><span class="line">roles/mezzanine/tasks/main.yml</span><br><span class="line">roles/mezzanine/tasks/nginx.yml</span><br></pre></td></tr></table></figure></p>
<p>In the <code>main.yml</code> task file you can invoke other tasks by using <code>include</code> statement:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: install apt packages</span><br><span class="line">  apt: pkg=&#123;&#123; item &#125;&#125; update_cache=yes cache_valid_time=3600</span><br><span class="line">  become: True</span><br><span class="line">  with_items:</span><br><span class="line">    - git</span><br><span class="line">    - supervisor</span><br><span class="line"></span><br><span class="line">- include: django.yml</span><br><span class="line">- include: nginx.yml</span><br></pre></td></tr></table></figure></p>
<p><strong>Note</strong>: there’s one important difference between tasks defined in a role and tasks defined in a regular playbook, and that’s when using the <code>copy</code> or <code>template</code> modules.</p>
<p>When invoking <code>copy</code> in a task defined in a role, Ansible will first check the <em>rolename/files/</em> directory for the location of the file to copy. Similarly, when invoking <code>template</code> in a task defined in a role, Ansible will first check the <em>rolename/templates</em> directory for the location of the template to use.</p>
<p>This means that a task that used to look like this in a playbook:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: set the nginx config file</span><br><span class="line">  template: src=templates/nginx.conf.j2 \</span><br><span class="line">  dest=/etc/nginx/sites-available/mezzanine.conf</span><br></pre></td></tr></table></figure></p>
<p>now looks like this when invoked from inside the role (note the change of the src parameter):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: set the nginx config file</span><br><span class="line">  template: src=nginx.conf.j2 dest=/etc/nginx/sites-available/mezzanine.conf</span><br><span class="line">  notify: restart nginx</span><br></pre></td></tr></table></figure></p>
<h2 id="Creating-Role-Files-and-Directories-with-ansible-galaxy"><a href="#Creating-Role-Files-and-Directories-with-ansible-galaxy" class="headerlink" title="Creating Role Files and Directories with ansible-galaxy"></a>Creating Role Files and Directories with ansible-galaxy</h2><p>Ansible ships with another command-line tool we haven’t talked about yet, <code>ansible-galaxy</code>. Its primary purpose is to download roles that have been shared by the Ansible community. But it can also be used to generate <em>scaffolding</em>, an initial set of files and directories involved in a role:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-galaxy init &lt;path&gt;/roles/web</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">└── roles</span><br><span class="line">    └── web</span><br><span class="line">        ├── README.md</span><br><span class="line">        ├── defaults</span><br><span class="line">        │   └── main.yml</span><br><span class="line">        ├── files</span><br><span class="line">        ├── handlers</span><br><span class="line">        │   └── main.yml</span><br><span class="line">        ├── meta</span><br><span class="line">        │   └── main.yml</span><br><span class="line">        ├── tasks</span><br><span class="line">        │   └── main.yml</span><br><span class="line">        ├── templates</span><br><span class="line">        ├── tests</span><br><span class="line">        │   ├── inventory</span><br><span class="line">        │   └── test.yml</span><br><span class="line">        └── vars</span><br><span class="line">            └── main.yml</span><br></pre></td></tr></table></figure>
<h2 id="Dependent-Roles"><a href="#Dependent-Roles" class="headerlink" title="Dependent Roles"></a>Dependent Roles</h2><p>Ansible supports a feature called <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_roles.html#role-dependencies" target="_blank" rel="noopener">dependent roles</a> to deal with this scenario. When you define a role, you can specify that it depends on one or more other roles. Ansible will ensure that roles that are specified as dependencies are executed first.</p>
<p>Let’s say that we create an<code>ntp</code> role that configures a host to synchronize its time with an NTP server. Ansible allows us to pass parameters to dependent roles, so let’s also assume that we can pass the NTP server as a parameter to that role.</p>
<p>We specify that the <code>web</code> role depends on the <code>ntp</code> role by creating a <em>roles/web/meta/main.yml</em> file and listing <code>ntp</code> as a role, with a parameter:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dependencies:</span><br><span class="line">    - &#123; role: ntp, ntp_server=ntp.ubuntu.com &#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Ansible-Galaxy"><a href="#Ansible-Galaxy" class="headerlink" title="Ansible Galaxy"></a>Ansible Galaxy</h2><p>Whether you want to reuse a role somebody has already written, or you just want to see how someone else solved the problem you’re working on, <a href="https://galaxy.ansible.com/" target="_blank" rel="noopener">Ansible Galaxy</a> can help you out. Ansible Galaxy is an open source repository of Ansible roles contributed by the Ansible community. The roles themselves are stored on GitHub.</p>
<h1 id="Chapter-8-Complex-Playbooks"><a href="#Chapter-8-Complex-Playbooks" class="headerlink" title="Chapter 8. Complex Playbooks"></a>Chapter 8. Complex Playbooks</h1><p>This chapter touches on those additional features, which makes it a bit of a grab bag.</p>
<h2 id="Dealing-with-Badly-Behaved-Commands"><a href="#Dealing-with-Badly-Behaved-Commands" class="headerlink" title="Dealing with Badly Behaved Commands"></a>Dealing with Badly Behaved Commands</h2><p>What if we didn’t have a module that could invoke equivalent commands (wasn’t idempotent)? The answer is to use <code>changed_when</code> and <code>failed_when</code> clauses to change how Ansible identifies that a task has changed state or failed.</p>
<p>First, we need to understand the output of this command the first time it’s run, and the output when it’s run the second time.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: initialize the database</span><br><span class="line">  django_manage:</span><br><span class="line">    command: createdb --noinput --nodata</span><br><span class="line">    app_path: &quot;&#123;&#123; proj_path &#125;&#125;&quot;</span><br><span class="line">    virtualenv: &quot;&#123;&#123; venv_path &#125;&#125;&quot;</span><br><span class="line">  failed_when: False</span><br><span class="line">  register: result</span><br><span class="line"></span><br><span class="line">- debug: var=result</span><br><span class="line"></span><br><span class="line">- fail:</span><br></pre></td></tr></table></figure></p>
<p><code>failed_when: False</code> is to close task fail, so ansible play will continue to execute. We can run several times of the playbook and see different register variable output.<br><code>fail</code> statement here is to stop the execution.</p>
<p>Some module may not report changed state even though it did make change in target machine, so we can check if state changed ourselves by using <code>changed_when</code> clause:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: initialize the database</span><br><span class="line">  django_manage:</span><br><span class="line">    command: createdb --noinput --nodata</span><br><span class="line">    app_path: &quot;&#123;&#123; proj_path &#125;&#125;&quot;</span><br><span class="line">    virtualenv: &quot;&#123;&#123; venv_path &#125;&#125;&quot;</span><br><span class="line">  register: result</span><br><span class="line">  changed_when: &apos;&quot;Creating tables&quot; in result.out|default(&quot;&quot;)&apos;</span><br></pre></td></tr></table></figure></p>
<p>We use filter here in <code>changed_when</code> since register variable sometimes doesn’t have <code>out</code> field. Alternatively, we could provide a default value for <code>result.out</code> if it doesn’t exist by using the Jinja2 default filter.</p>
<h2 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h2><p><em>Filters</em> are a feature of the Jinja2 templating engine. Since Ansible uses Jinja2 for evaluating variables, as well as for templates, you can use filters inside <code></code> in your playbooks, as well as inside your template files. Using filters resembles using Unix pipes, whereby a variable is piped through a filter. Jinja2 ships with a set of <a href="http://bit.ly/1FvOGzI" target="_blank" rel="noopener">built-in filters</a>. In addition, Ansible ships with its own filters to augment the <a href="http://bit.ly/1FvOIrj" target="_blank" rel="noopener">Jinja2 filters</a>.</p>
<h3 id="The-Default-Filter"><a href="#The-Default-Filter" class="headerlink" title="The Default Filter"></a>The Default Filter</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;HOST&quot;: &quot;&#123;&#123; database_host | default(&apos;localhost&apos;) &#125;&#125;&quot;</span><br></pre></td></tr></table></figure>
<p>If the variable <code>database_host</code> is defined, the braces will evaluate to the value of that variable. If the variable <code>database_host</code> is not defined, the braces will evaluate to the string localhost.</p>
<h3 id="Filters-for-Registered-Variables"><a href="#Filters-for-Registered-Variables" class="headerlink" title="Filters for Registered Variables"></a>Filters for Registered Variables</h3><p>Let’s say we want to run a task and print out its output, even if the task fails. However, if the task does fail, we want Ansible to fail for that host after printing the output.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Run myprog</span><br><span class="line">  command: /opt/myprog</span><br><span class="line">  register: result</span><br><span class="line">  ignore_errors: True</span><br><span class="line"></span><br><span class="line">- debug: var=result</span><br><span class="line"></span><br><span class="line">- debug: msg=&quot;Stop running the playbook if myprog failed&quot;</span><br><span class="line">  failed_when: result|failed</span><br></pre></td></tr></table></figure></p>
<p> a list of filters you can use on registered variables to check the status:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Name    	| Description                                           	|</span><br><span class="line">|---------	|-------------------------------------------------------	|</span><br><span class="line">| failed  	| True if a registered value is a task that failed      	|</span><br><span class="line">| changed 	| True if a registered value is a task that changed     	|</span><br><span class="line">| success 	| True if a registered value is a task that succeeded   	|</span><br><span class="line">| skipped 	| True if a registered value is a task that was skipped 	|</span><br></pre></td></tr></table></figure></p>
<p>The basename filter will let us extract the index.html part of the filename from the full path, allowing us to write the playbook without repeating the filename:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vars:</span><br><span class="line">    homepage: /usr/share/nginx/html/index.html</span><br><span class="line">  tasks:</span><br><span class="line">  - name: copy home page</span><br><span class="line">    copy: src=files/&#123;&#123; homepage | basename &#125;&#125; dest=&#123;&#123; homepage &#125;&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Lookups"><a href="#Lookups" class="headerlink" title="Lookups"></a>Lookups</h2><p>Sometimes a piece of configuration data you need lives somewhere else. Maybe it’s in a text file or a <em>.csv</em> file, and you don’t want to just copy the data into an Ansible variable file because now you have to maintain two copies of the same data. </p>
<p>Ansible has a feature called <code>lookups</code> that allows you to read in configuration data from various sources and then use that data in your playbooks and template.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Name     	| Description                        	|</span><br><span class="line">|----------	|------------------------------------	|</span><br><span class="line">| file     	| Contents of a file                 	|</span><br><span class="line">| password 	| Randomly generate a password       	|</span><br><span class="line">| pipe     	| Output of locally executed command 	|</span><br><span class="line">| env      	| Environment variable               	|</span><br><span class="line">| template 	| Jinja2 template after evaluation   	|</span><br><span class="line">| csvfile  	| Entry in a .csv file               	|</span><br><span class="line">| dnstxt   	| DNS TXT record                     	|</span><br><span class="line">| redis_kv 	| Redis key lookup                   	|</span><br><span class="line">| etcd     	| etcd key lookup                    	|</span><br></pre></td></tr></table></figure></p>
<p>You can invoke lookups in your playbooks between <code></code>, or you can put them in templates. </p>
<p><strong>Note</strong> all Ansible lookup plugins execute on the control machine, not the remote host.</p>
<h3 id="file"><a href="#file" class="headerlink" title="file"></a>file</h3><p>Let’s say you have a text file on your control machine that contains a public SSH key that you want to copy to a remote server.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Add my public key as an EC2 key</span><br><span class="line">  ec2_key: name=mykey key_material=&quot;&#123;&#123; lookup(&apos;file&apos;,  &apos;/Users/lorin/.ssh/id_rsa.pub&apos;) &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<h3 id="pipe"><a href="#pipe" class="headerlink" title="pipe"></a>pipe</h3><p>The <code>pipe</code> lookup invokes an external program on the control machine and evaluates to the program’s output on standard out.</p>
<p>For example, if our playbooks are version controlled using <code>git</code>, and we want to get the <code>SHA-1</code> value of the most recent <code>git commit</code>, we could use the <code>pipe</code> lookup<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: get SHA of most recent commit</span><br><span class="line">  debug: msg=&quot;&#123;&#123; lookup(&apos;pipe&apos;, &apos;git rev-parse HEAD&apos;) &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK: [get the sha of the current commit] *************************************</span><br><span class="line">ok: [myserver] =&gt; &#123;</span><br><span class="line">    &quot;msg&quot;: &quot;e7748af0f040d58d61de1917980a210df419eae9&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="env"><a href="#env" class="headerlink" title="env"></a>env</h3><p>The <code>env</code> lookup retrieves the value of an environment variable set on the control machine.For example, we could use the lookup like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: get the current shell</span><br><span class="line">  debug: msg=&quot;&#123;&#123; lookup(&apos;env&apos;, &apos;SHELL&apos;) &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK: [get the current shell] *************************************************</span><br><span class="line">ok: [myserver] =&gt; &#123;</span><br><span class="line">    &quot;msg&quot;: &quot;/bin/zsh&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="password"><a href="#password" class="headerlink" title="password"></a>password</h3><p>The <code>password</code> lookup evaluates to a random password, and it will also write the password to a file specified in the argument. For example, if we want to create a Postgres user named <code>deploy</code> with a random password and write that password to <em>deploy-password.txt</em>on the control machine, we can do this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: create deploy postgres user</span><br><span class="line">  postgresql_user:</span><br><span class="line">    name: deploy</span><br><span class="line">    password: &quot;&#123;&#123; lookup(&apos;password&apos;, &apos;deploy-password.txt&apos;) &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<h3 id="template"><a href="#template" class="headerlink" title="template"></a>template</h3><p>The <code>template</code> lookup lets you specify a Jinja2 template file, and then returns the result of evaluating the template.</p>
<h3 id="csvfile"><a href="#csvfile" class="headerlink" title="csvfile"></a>csvfile</h3><p>The <code>csvfile</code> lookup reads an entry from a <em>.csv</em> file.<br>For example, we have a <code>users.csv</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">username,email</span><br><span class="line">lorin,lorin@ansiblebook.com</span><br><span class="line">john,john@example.com</span><br><span class="line">sue,sue@example.org</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lookup(&apos;csvfile&apos;, &apos;sue file=users.csv delimiter=, col=1&apos;)</span><br></pre></td></tr></table></figure>
<p>In the case of <code>csvfile</code>, the first argument is an entry that must appear exactly once in column 0 (the first column, 0-indexed) of the table.</p>
<p>In our example, we want to look in the file named <code>users.csv</code> and locate where the fields are delimited by commas, look up the row where the value in the first column is <code>sue</code>, and return the value in the second column (column 1, indexed by 0). This evaluates to <a href="mailto:sue@example.org" target="_blank" rel="noopener">sue@example.org</a>.</p>
<h3 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h3><p>Etcd is a distributed key-value store, commonly used for keeping configuration data and for implementing service discovery. You can use the <code>etcd</code> lookup to retrieve the value of a key.</p>
<p>For example, let’s say that we have an etcd server running on our control machine, and we set the key weather to the value cloudy by doing something like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -L http://127.0.0.1:4001/v2/keys/weather -XPUT -d value=cloudy</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: look up value in etcd</span><br><span class="line">  debug: msg=&quot;&#123;&#123; lookup(&apos;etcd&apos;, &apos;weather&apos;) &#125;&#125;&quot;</span><br><span class="line"></span><br><span class="line">TASK: [look up value in etcd] *************************************************</span><br><span class="line">ok: [localhost] =&gt; &#123;</span><br><span class="line">    &quot;msg&quot;: &quot;cloudy&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>By default, the etcd lookup looks for the etcd server at <a href="http://127.0.0.1:4001" target="_blank" rel="noopener">http://127.0.0.1:4001</a>, but you can change this by setting the <code>ANSIBLE_ETCD_URL</code> environment variable before invoking ansible-playbook.</p>
<h2 id="More-Complicated-Loops"><a href="#More-Complicated-Loops" class="headerlink" title="More Complicated Loops"></a>More Complicated Loops</h2><p>Up until this point, whenever we’ve written a task that iterates over a list of items, we’ve used the <code>with_items</code> clause to specify a list of items. Although this is the most common way to do loops, Ansible supports other mechanisms for iteration.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Name                     	| Input                	| Looping strategy                  	|</span><br><span class="line">|--------------------------	|----------------------	|-----------------------------------	|</span><br><span class="line">| with_items               	| List                 	| Loop over list elements           	|</span><br><span class="line">| with_lines               	| Command to execute   	| Loop over lines in command output 	|</span><br><span class="line">| with_fileglob            	| Glob                 	| Loop over filenames               	|</span><br><span class="line">| with_first_found         	| List of paths        	| First file in input that exists   	|</span><br><span class="line">| with_dict                	| Dictionary           	| Loop over dictionary elements     	|</span><br><span class="line">| with_flattened           	| List of lists        	| Loop over flattened list          	|</span><br><span class="line">| with_indexed_items       	| List                 	| Single iteration                  	|</span><br><span class="line">| with_nested              	| List                 	| Nested loop                       	|</span><br><span class="line">| with_random_choice       	| List                 	| Single iteration                  	|</span><br><span class="line">| with_sequence            	| Sequence of integers 	| Loop over sequence                	|</span><br><span class="line">| with_subelements         	| List of dictionaries 	| Nested loop                       	|</span><br><span class="line">| with_together            	| List of lists        	| Loop over zipped list             	|</span><br><span class="line">| with_inventory_hostnames 	| Host pattern         	| Loop over matching hosts          	|</span><br></pre></td></tr></table></figure></p>
<p>The <a href="http://bit.ly/1F6kfCP" target="_blank" rel="noopener">official documentation</a> covers these quite thoroughly, so I’ll show examples from just a few of them to give you a sense of how they work.</p>
<h3 id="with-lines"><a href="#with-lines" class="headerlink" title="with_lines"></a>with_lines</h3><p>The with_lines looping construct lets you run an arbitrary command on your control machine and iterate over the output, one line at a time. For example, read a file and iterate over its contents line by line.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Send out a slack message</span><br><span class="line">  slack:</span><br><span class="line">    domain: example.slack.com</span><br><span class="line">    token: &quot;&#123;&#123; slack_token &#125;&#125;&quot;</span><br><span class="line">    msg: &quot;&#123;&#123; item &#125;&#125; was in the list&quot;</span><br><span class="line">  with_lines:</span><br><span class="line">    - cat files/turing.txt</span><br></pre></td></tr></table></figure></p>
<h3 id="with-fileglob"><a href="#with-fileglob" class="headerlink" title="with_fileglob"></a>with_fileglob</h3><p>The with_fileglob construct is useful for iterating over a set of files on the control machine.</p>
<p>For example, iterate over files that end in <code>.pub</code> in the /var/keys directory, as well as a keys directory next to your playbook. It then uses the <code>file</code> lookup plugin to extract the contents of the file, which are passed to the authorized_key module.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: add public keys to account</span><br><span class="line">  authorized_key: user=deploy key=&quot;&#123;&#123; lookup(&apos;file&apos;, item) &#125;&#125;&quot;</span><br><span class="line">  with_fileglob:</span><br><span class="line">    - /var/keys/*.pub</span><br><span class="line">    - keys/*.pub</span><br></pre></td></tr></table></figure></p>
<h3 id="with-dict"><a href="#with-dict" class="headerlink" title="with_dict"></a>with_dict</h3><p>The <code>with_dict</code> construct lets you iterate over a dictionary instead of a list. When you use this looping construct, the <code>item</code> loop variable is a dictionary with two fields:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: iterate over ansible_eth0</span><br><span class="line">   debug: msg=&#123;&#123; item.key &#125;&#125;=&#123;&#123; item.value &#125;&#125;</span><br><span class="line">   with_dict: &quot;&#123;&#123; ansible_eth0.ipv4 &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<h3 id="Looping-Constructs-as-Lookup-Plugins"><a href="#Looping-Constructs-as-Lookup-Plugins" class="headerlink" title="Looping Constructs as Lookup Plugins"></a>Looping Constructs as Lookup Plugins</h3><p>Ansible implements looping constructs as lookup plugins. That means you can alter the form of lookup to perform as a loop:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Add my public key as an EC2 key</span><br><span class="line">  ec2_key: name=mykey key_material=&quot;&#123;&#123; item &#125;&#125;&quot;</span><br><span class="line">  with_file: /Users/lorin/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure></p>
<p>Here we prefix <code>with_</code> with <code>file</code> lookup plugin. Typically, you use a lookup plugin as a looping construct only if it returns a list,</p>
<h2 id="Loop-Controls"><a href="#Loop-Controls" class="headerlink" title="Loop Controls"></a>Loop Controls</h2><p>With version 2.1, Ansible provides users with more control over loop handling.</p>
<h3 id="Setting-the-Variable-Name"><a href="#Setting-the-Variable-Name" class="headerlink" title="Setting the Variable Name"></a>Setting the Variable Name</h3><p>The <code>loop_var</code> control allows us to give the iteration variable a different name than the default name, <code>item</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- user:</span><br><span class="line">    name: &quot;&#123;&#123; user.name &#125;&#125;&quot;</span><br><span class="line">  with_items:</span><br><span class="line">  ## list of dict</span><br><span class="line">    - &#123; name: gil &#125;</span><br><span class="line">    - &#123; name: sarina &#125;</span><br><span class="line">    - &#123; name: leanne &#125;</span><br><span class="line">  loop_control:</span><br><span class="line">    loop_var: user</span><br></pre></td></tr></table></figure></p>
<p>Next one is a advanced usage, use <code>include</code> with <code>with_items</code>, we loop over multiple task at once, in current task we include a task called <code>vhosts.yml</code> which will be executed 3 times with different parameters passed in:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: run a set of tasks in one loop</span><br><span class="line">  include: vhosts.yml</span><br><span class="line">  with_items:</span><br><span class="line">    - &#123; domain: www1.example.com &#125;</span><br><span class="line">    - &#123; domain: www2.example.com &#125;</span><br><span class="line">    - &#123; domain: www3.example.com &#125;</span><br><span class="line">  loop_control:</span><br><span class="line">    loop_var: vhost</span><br></pre></td></tr></table></figure></p>
<p>The <code>vhosts.yml</code> file that is going to be included may also contain <code>with_items</code> in some tasks. This would produce a conflict, as the default loop_var <code>item</code> is used for both loops at the same time.</p>
<p>To prevent a naming collision, we specify a different name for loop_var in the outer loop.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: create nginx directories</span><br><span class="line">  file:</span><br><span class="line">    path: /var/www/html/&#123;&#123; vhost.domain &#125;&#125;/&#123;&#123; item &#125;&#125;</span><br><span class="line">  state: directory</span><br><span class="line">  with_items:</span><br><span class="line">    - logs</span><br><span class="line">    - public_http</span><br><span class="line">    - public_https</span><br><span class="line">    - includes</span><br><span class="line"></span><br><span class="line">- name: create nginx vhost config</span><br><span class="line">  template:</span><br><span class="line">    src: &quot;&#123;&#123; vhost.domain &#125;&#125;.j2&quot;</span><br><span class="line">    dest: /etc/nginx/conf.d/&#123;&#123; vhost.domain &#125;&#125;.conf</span><br></pre></td></tr></table></figure></p>
<h3 id="Labeling-the-Output"><a href="#Labeling-the-Output" class="headerlink" title="Labeling the Output"></a>Labeling the Output</h3><p>The <code>label</code> control was added in Ansible 2.2 and provides some control over how the loop output will be shown to the user during execution.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: create nginx vhost configs</span><br><span class="line">  template:</span><br><span class="line">    src: &quot;&#123;&#123; item.domain &#125;&#125;.conf.j2&quot;</span><br><span class="line">    dest: &quot;/etc/nginx/conf.d/&#123;&#123; item.domain &#125;&#125;.conf&quot;</span><br><span class="line">  with_items:</span><br><span class="line">    - &#123; domain: www1.example.com, ssl_enabled: yes &#125;</span><br><span class="line">    - &#123; domain: www2.example.com &#125;</span><br><span class="line">    - &#123; domain: www3.example.com,</span><br><span class="line">      aliases: [ edge2.www.example.com, eu.www.example.com ] &#125;</span><br><span class="line">  loop_control:</span><br><span class="line">    label: &quot;for domain &#123;&#123; item.domain &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK [create nginx vhost configs] **********************************************</span><br><span class="line">ok: [localhost] =&gt; (item=for domain www1.example.com)</span><br><span class="line">ok: [localhost] =&gt; (item=for domain www2.example.com)</span><br><span class="line">ok: [localhost] =&gt; (item=for domain www3.example.com)</span><br></pre></td></tr></table></figure>
<h2 id="Includes"><a href="#Includes" class="headerlink" title="Includes"></a>Includes</h2><p>The <code>include</code> feature allows you to include tasks or even whole playbooks, depending on where you define an include. It is often used in roles to separate or even group tasks and task arguments to each task in the included file.</p>
<p>For example, you can extract different part of tasks, put them into a separate yml file and include it into another task along with common arguments:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># nginx_include.yml file</span><br><span class="line">- name: install nginx</span><br><span class="line">  package:</span><br><span class="line">    name: nginx</span><br><span class="line"></span><br><span class="line">- name: ensure nginx is running</span><br><span class="line">  service:</span><br><span class="line">    name: nginx</span><br><span class="line">    state: started</span><br><span class="line">    enabled: yes</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- include: nginx_include.yml</span><br><span class="line">  tags: nginx</span><br><span class="line">  become: yes</span><br><span class="line">  when: ansible_os_family == &apos;RedHat&apos;</span><br></pre></td></tr></table></figure>
<p>Ansible <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html" target="_blank" rel="noopener">Tags</a>: If you have a large playbook, it may become useful to be able to run only a specific part of it rather than running everything in the playbook. Ansible supports a <code>tags:</code> attribute for this reason.</p>
<h3 id="Dynamic-includes"><a href="#Dynamic-includes" class="headerlink" title="Dynamic includes"></a>Dynamic includes</h3><p>A common pattern in roles is to define tasks specific to a particular operating system into separate task files.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- include: Redhat.yml</span><br><span class="line">  when: ansible_os_family == &apos;Redhat&apos;</span><br><span class="line"></span><br><span class="line">- include: Debian.yml</span><br><span class="line">  when: ansible_os_family == &apos;Debian&apos;</span><br></pre></td></tr></table></figure></p>
<p>Since version 2.0, Ansible allows us to dynamically include a file by using variable substitution:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- include: &quot;&#123;&#123; ansible_os_family &#125;&#125;.yml&quot;</span><br><span class="line">  static: no</span><br></pre></td></tr></table></figure></p>
<p>However, there is a drawback to using dynamic includes: <code>ansible-playbook --list-tasks</code> might not list the tasks from a dynamic include if Ansible does not have enough information to populate the variables that determine which file will be included.</p>
<p>You can use <code>ansible-playbook &lt;playbook&gt; --list-tasks</code> to list all the tasks in it.</p>
<h3 id="Role-includes"><a href="#Role-includes" class="headerlink" title="Role includes"></a>Role includes</h3><p>A special include is the <code>include_role</code> clause. In contrast with the <code>role</code> clause, which will use all parts of the role, the <code>include_role</code> not only allows us to selectively choose what parts of a role will be included and used, but also where in the play.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: install php</span><br><span class="line">  include_role:</span><br><span class="line">    name: php</span><br></pre></td></tr></table></figure></p>
<p>This will include and run main.yml from the php role, remember a role can have multiple tasks yml files: main.yml and others.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: install php</span><br><span class="line">  include_role:</span><br><span class="line">    name: php</span><br><span class="line">    tasks_from: install</span><br></pre></td></tr></table></figure></p>
<p>This will include and run install.yml from php role.</p>
<h2 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h2><p>Much like the <code>include</code> clause, the <code>block</code> clause provides a mechanism for grouping tasks. The <code>block</code> clause allows you to set conditions or arguments for all tasks within a block at once:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- block:</span><br><span class="line">  - name: install nginx</span><br><span class="line">    package:</span><br><span class="line">      name: nginx</span><br><span class="line">  - name: ensure nginx is running</span><br><span class="line">    service:</span><br><span class="line">      name: nginx</span><br><span class="line">      state: started</span><br><span class="line">      enabled: yes</span><br><span class="line">  become: yes</span><br><span class="line">  when: &quot;ansible_os_family == &apos;RedHat&apos;&quot;</span><br></pre></td></tr></table></figure></p>
<p>The <code>become</code> and <code>when</code> apply for both tasks.</p>
<h3 id="Error-Handling-with-Blocks"><a href="#Error-Handling-with-Blocks" class="headerlink" title="Error Handling with Blocks"></a>Error Handling with Blocks</h3><p>Dealing with error scenarios has always been a challenge. Historically, Ansible has been error agnostic in the sense that errors and failures may occur on a host. Ansible’s default error-handling behavior is to take a host out of the play if a task fails and continue as long as there are hosts remaining that haven’t encountered errors.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- block:</span><br><span class="line">  - debug: msg=&quot;You will see a failed tasks right after this&quot;</span><br><span class="line">  - command: /bin/false</span><br><span class="line">  - debug: &quot;You won&apos;t see this message&quot;</span><br><span class="line">  rescue: # Tasks to be executed in case of a failure in block clause</span><br><span class="line">  - debug: &quot;You only see this message in case of an failure in the block&quot;</span><br><span class="line">  always: # Tasks to always be executed</span><br><span class="line">  - debug: &quot;This will be always executed&quot;</span><br></pre></td></tr></table></figure></p>
<p>If you have some programming experience, the way error handling is implemented may remind you of the <code>try-catch-finally</code> paradigm, and it works much the same way.</p>
<h2 id="Encrypting-Sensitive-Data-with-Vault"><a href="#Encrypting-Sensitive-Data-with-Vault" class="headerlink" title="Encrypting Sensitive Data with Vault"></a>Encrypting Sensitive Data with Vault</h2><p>Ansible provides an alternative solution: instead of keeping the <code>secrets.yml</code> file out of version control, we can commit an encrypted version. That way, even if our version-control repository were compromised, the attacker would not have access to the contents of the <code>secrets.yml</code> file unless he also had the password used for the encryption.</p>
<p>The <code>ansible-vault</code> command-line tool allows you to create and edit an encrypted file that <code>ansible-playbook</code> will recognize and decrypt automatically, given the password.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-vault create secrets.yml</span><br><span class="line">ansible-vault encrypt secrets.yml</span><br></pre></td></tr></table></figure></p>
<p>You will be prompted for a password, and then <code>ansible-vault</code> will launch a text editor so that you can populate the file. It launches the editor specified in the <code>$EDITOR</code> environment variable. If that variable is not defined, it defaults to <code>vim</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook &lt;playbook&gt; --ask-vault-pass</span><br><span class="line">ansible-playbook &lt;playbook&gt; --vault-password-file ~/password.txt</span><br></pre></td></tr></table></figure></p>
<p>If the argument to <code>--vault-password-file</code> has the executable bit set, Ansible will execute it and use the contents of standard out as the vault password. This allows you to use a script to provide the password to Ansible.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Command                        	| Description                                       	|</span><br><span class="line">|--------------------------------	|---------------------------------------------------	|</span><br><span class="line">| ansible-vault encrypt file.yml 	| Encrypt the plain-text file.yml file              	|</span><br><span class="line">| ansible-vault decrypt file.yml 	| Decrypt the encrypted file.yml file               	|</span><br><span class="line">| ansible-vault view file.yml    	| Print the contents of the encrypted file.yml file 	|</span><br><span class="line">| ansible-vault create file.yml  	| Create a new encrypted file.yml file              	|</span><br><span class="line">| ansible-vault edit file.yml    	| Edit an encrypted file.yml file                   	|</span><br><span class="line">| ansible-vault rekey file.yml   	| Change the password on an encrypted file.yml file 	|</span><br></pre></td></tr></table></figure></p>
<h1 id="Chapter-9-Customizing-Hosts-Runs-and-Handlers"><a href="#Chapter-9-Customizing-Hosts-Runs-and-Handlers" class="headerlink" title="Chapter 9. Customizing Hosts, Runs, and Handlers"></a>Chapter 9. Customizing Hosts, Runs, and Handlers</h1><p>In this chapter, we cover Ansible features that provide customization by controlling which hosts to run against, how tasks are run, and how handlers are run.</p>
<h2 id="Patterns-for-Specifying-Hosts"><a href="#Patterns-for-Specifying-Hosts" class="headerlink" title="Patterns for Specifying Hosts"></a>Patterns for Specifying Hosts</h2><p>Instead of specifying a single host or group for a play, you can specify a <em>pattern</em>. You’ve already seen the <code>all</code> pattern, which will run a play against all known hosts:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hosts: all</span><br></pre></td></tr></table></figure></p>
<p>You can specify a union of two groups with a colon. You specify all dev and staging machines as follows:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hosts: dev:staging</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Action                    	| Example Usage               	|</span><br><span class="line">|---------------------------	|-----------------------------	|</span><br><span class="line">| All hosts                 	| all                         	|</span><br><span class="line">| All hosts                 	| *                           	|</span><br><span class="line">| Union                     	| dev:staging                 	|</span><br><span class="line">| Intersection              	| dev:&amp;database               	|</span><br><span class="line">| Exclusion                 	| dev:!queue                  	|</span><br><span class="line">| Wildcard                  	| *.example.com               	|</span><br><span class="line">| Range of numbered servers 	| web[5:12]                   	|</span><br><span class="line">| Regular expression        	| ~web\d+\.example\.(com|org) 	|</span><br></pre></td></tr></table></figure>
<p>Ansible supports multiple combinations of patterns—for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hosts: dev:staging:&amp;database:!queue</span><br></pre></td></tr></table></figure></p>
<h2 id="Limiting-Which-Hosts-Run"><a href="#Limiting-Which-Hosts-Run" class="headerlink" title="Limiting Which Hosts Run"></a>Limiting Which Hosts Run</h2><p>Use the <code>-l hosts</code> or <code>--limit hosts</code> flag to tell Ansible to limit the hosts to run the playbook against the specified list of hosts<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook -l hosts playbook.yml</span><br><span class="line">ansible-playbook --limit hosts playbook.yml</span><br><span class="line">ansible-playbook -l &apos;staging:&amp;database&apos; playbook.yml</span><br></pre></td></tr></table></figure></p>
<h2 id="Running-a-Task-on-the-Control-Machine"><a href="#Running-a-Task-on-the-Control-Machine" class="headerlink" title="Running a Task on the Control Machine"></a>Running a Task on the Control Machine</h2><p>Sometimes you want to run a particular task on the control machine instead of on the remote host. Ansible provides the <code>local_action</code> clause for tasks to support this. For example, when we check the node ready status in k8s cluster.</p>
<p>Imagine that the server we want to install Mezzanine onto has just booted, so that if we run our playbook too soon, it will error out because the server hasn’t fully started up yet. We could start off our playbook by invoking the <code>wait_for</code> module to wait until the SSH server is ready to accept connections before we execute the rest of the playbook.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: wait for ssh server to be running</span><br><span class="line">  local_action: wait_for port=22 host=&quot;&#123;&#123; inventory_hostname &#125;&#125;&quot; search_regex=OpenSSH</span><br></pre></td></tr></table></figure></p>
<p>Note that <code>inventory_hostname</code> evaluates to the name of the remote host, not <code>localhost</code>. That’s because the scope of these variables is still the remote host, even though the task is executing locally.</p>
<p>If your play involves multiple hosts, and you use <code>local_action</code>, the task will be executed multiple times, one for each host. You can restrict this by using <code>run_once</code></p>
<h2 id="Running-a-Task-on-a-Machine-Other-Than-the-Host"><a href="#Running-a-Task-on-a-Machine-Other-Than-the-Host" class="headerlink" title="Running a Task on a Machine Other Than the Host"></a>Running a Task on a Machine Other Than the Host</h2><p>Sometimes you want to run a task that’s associated with a host, but you want to execute the task on a different server. You can use the <code>delegate_to</code> clause to run the task on a different host.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: enable alerts for web servers</span><br><span class="line">  hosts: web</span><br><span class="line">  tasks:</span><br><span class="line">    - name: enable alerts</span><br><span class="line">      nagios: action=enable_alerts service=web host=&#123;&#123; inventory_hostname &#125;&#125;</span><br><span class="line">      delegate_to: nagios.example.com</span><br></pre></td></tr></table></figure></p>
<p>In this example, Ansible would execute the <code>nagios task</code> on nagios.example.com, but the <code>inventory_hostname</code> variable referenced in the play would evaluate to the web host.</p>
<blockquote>
<p>Note: if you specify <code>delegate_to: localhost</code> to control machine, it’s the same as <code>local_action</code>, also the same as <code>connection: local</code></p>
</blockquote>
<h2 id="Running-on-One-Host-at-a-Time"><a href="#Running-on-One-Host-at-a-Time" class="headerlink" title="Running on One Host at a Time"></a>Running on One Host at a Time</h2><p>By default, Ansible runs each task in parallel across all hosts. Sometimes you want to run your task on one host at a time. The canonical example is when upgrading application servers that are behind a load balancer. Typically, you take the application server out of the load balancer, upgrade it, and put it back. But you don’t want to take all of your application servers out of the load balancer, or your service will become unavailable.</p>
<p>You can use the <code>serial</code> clause on a play to tell Ansible to restrict the number of hosts that a play runs on.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: upgrade packages on servers behind load balancer</span><br><span class="line">  hosts: myhosts</span><br><span class="line">  serial: 1</span><br><span class="line">  tasks:</span><br><span class="line">    - name: get the ec2 instance id and elastic load balancer id</span><br><span class="line">      ec2_facts:</span><br><span class="line"></span><br><span class="line">    - name: take the host out of the elastic load balancer</span><br><span class="line">      local_action: ec2_elb</span><br><span class="line">      args:</span><br><span class="line">        instance_id: &quot;&#123;&#123; ansible_ec2_instance_id &#125;&#125;&quot;</span><br><span class="line">        state: absent</span><br><span class="line"></span><br><span class="line">    - name: upgrade packages</span><br><span class="line">      apt: update_cache=yes upgrade=yes</span><br><span class="line"></span><br><span class="line">    - name: put the host back in the elastic load balancer</span><br><span class="line">      local_action: ec2_elb</span><br><span class="line">      args:</span><br><span class="line">        instance_id: &quot;&#123;&#123; ansible_ec2_instance_id &#125;&#125;&quot;</span><br><span class="line">        state: present</span><br><span class="line">        ec2_elbs: &quot;&#123;&#123; item &#125;&#125;&quot;</span><br><span class="line">      with_items: ec2_elbs</span><br></pre></td></tr></table></figure></p>
<p>In our example, we pass 1 as the argument to the serial clause, telling Ansible to run on only one host at a time. If we had passed 2, Ansible would have run two hosts at a time.</p>
<p>Normally, when a task fails, Ansible stops running tasks against the host that fails, <strong>but</strong> continues to run against other hosts. In the load-balancing scenario, you might want Ansible to fail the entire play before all hosts have failed a task. Otherwise, you might end up with the situation where you have taken each host out of the load balancer, and have it fail, leaving no hosts left inside your load balancer.</p>
<p>You can use a <code>max_fail_percentage</code> clause along with the <code>serial</code> clause to specify the maximum percentage of failed hosts before Ansible fails the entire play. For example, assume that we specify a maximum fail percentage of 25%, as shown here:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: upgrade packages on servers behind load balancer</span><br><span class="line">  hosts: myhosts</span><br><span class="line">  serial: 1</span><br><span class="line">  max_fail_percentage: 25</span><br><span class="line">  tasks:</span><br><span class="line">    # tasks go here</span><br></pre></td></tr></table></figure></p>
<p>If you want Ansible to fail if any of the hosts fail a task, set the <code>max_fail_percentage</code> to 0.</p>
<blockquote>
<p>Note: <code>any_errors_fatal: true</code> is just like set <code>max_fail_percentage</code> to 0, with the <code>any_errors_fatal</code> option, any failure on any host in a multi-host play will be treated as fatal and Ansible will exit immediately without waiting for the other hosts.</p>
</blockquote>
<p>We can get even more sophisticated. For example, you might want to run the play on one host first, to verify that the play works as expected, and then run the play on a larger number of hosts in subsequent runs.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: configure CDN servers</span><br><span class="line">  hosts: cdn</span><br><span class="line">  serial:</span><br><span class="line">    - 1</span><br><span class="line">    - 30%</span><br><span class="line">  tasks:</span><br><span class="line">    # tasks go here</span><br></pre></td></tr></table></figure></p>
<p>In the preceding play with 30 CDN hosts, on the first batch run Ansible would run against one host, and on each subsequent batch run it would run against at most 30% of the hosts (e.g., 1, 10, 10, 9).</p>
<h2 id="Running-Only-Once"><a href="#Running-Only-Once" class="headerlink" title="Running Only Once"></a>Running Only Once</h2><p>Using <code>run_once</code> can be particularly useful when using <code>local_action</code> if your playbook involves multiple hosts, and you want to run the local task only once:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: run the task locally, only once</span><br><span class="line">  local_action: command /opt/my-custom-command</span><br><span class="line">  run_once: true</span><br></pre></td></tr></table></figure></p>
<h2 id="Running-Strategies"><a href="#Running-Strategies" class="headerlink" title="Running Strategies"></a>Running Strategies</h2><p>The strategy clause on a play level gives you additional control over how Ansible behaves per task for all hosts.</p>
<p>The default behavior we are already familiar with is the <code>linear</code> strategy. This is the strategy in which Ansible executes one task on all hosts and waits until the task has completed (of failed) on all hosts before it executes the next task on all hosts. As a result, a task takes as much time as the slowest host takes to complete the task.</p>
<h3 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h3><p><strong>Note</strong>: I forget that host file can define variable, here <code>sleep_seconds</code> can be referred in task:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">one   sleep_seconds=1</span><br><span class="line">two   sleep_seconds=6</span><br><span class="line">three  sleep_seconds=10</span><br></pre></td></tr></table></figure></p>
<p><strong>Note</strong> that the orders show up is the complete order in target host, first done at top.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK [setup] *******************************************************************</span><br><span class="line">ok: [two]</span><br><span class="line">ok: [three]</span><br><span class="line">ok: [one]</span><br></pre></td></tr></table></figure></p>
<h3 id="Free"><a href="#Free" class="headerlink" title="Free"></a>Free</h3><p>Another strategy available in Ansible is the <code>free</code> strategy. In contrast to <code>linear</code>, Ansible will not wait for results of the task to execute on all hosts. Instead, if a host completes one task, Ansible will execute the next task on that host.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- hosts: all</span><br><span class="line">  strategy: free</span><br><span class="line">  tasks:</span><br><span class="line">     ...</span><br></pre></td></tr></table></figure></p>
<h2 id="Advanced-Handlers"><a href="#Advanced-Handlers" class="headerlink" title="Advanced Handlers"></a>Advanced Handlers</h2><p>When we covered handlers, you learned that they are usually executed after all tasks, once, and only when they get notified. But keep in mind there are not only <code>tasks</code>, but <code>pre_tasks</code>, <code>tasks</code>, and <code>post_tasks</code>.</p>
<p>Each tasks section in a playbook is handled separately; any handler notified in <code>pre_tasks</code>, <code>tasks</code>, or <code>post_tasks</code> is executed at the end of each section. As a result, it is possible to execute one handler several times in one play:</p>
<p><strong>Note</strong>: the rest of Chapter 9 is useless for me now, just skip it.</p>
<h1 id="Chapter-16-Debugging-Ansible-Playbooks"><a href="#Chapter-16-Debugging-Ansible-Playbooks" class="headerlink" title="Chapter 16. Debugging Ansible Playbooks"></a>Chapter 16. Debugging Ansible Playbooks</h1><h2 id="Humane-Error-Messages"><a href="#Humane-Error-Messages" class="headerlink" title="Humane Error Messages"></a>Humane Error Messages</h2><p>Enable the plugin by adding the following to the <code>defaults</code> section of <em>ansible.cfg</em>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">stdout_callback = debug</span><br></pre></td></tr></table></figure></p>
<p>the <code>debug</code> callback plugin makes this output much easier for a human to read, for example the format is like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK [check out the repository on the host] *************************************</span><br><span class="line">fatal: [web]: FAILED! =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;cmd&quot;: &quot;/usr/bin/git clone --origin origin &apos;&apos; /home/vagrant/mezzanine/mezzani</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">STDERR:</span><br><span class="line"></span><br><span class="line">Cloning into &apos;/home/vagrant/mezzanine/mezzanine_example&apos;...</span><br><span class="line">Permission denied (publickey).</span><br><span class="line">fatal: Could not read from remote repository.</span><br><span class="line">...</span><br><span class="line">MSG:</span><br><span class="line"></span><br><span class="line">Cloning into &apos;/home/vagrant/mezzanine/mezzanine_example&apos;...</span><br><span class="line">Permission denied (publickey).</span><br><span class="line">fatal: Could not read from remote repository.</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h2 id="Debugging-SSH-Issues"><a href="#Debugging-SSH-Issues" class="headerlink" title="Debugging SSH Issues"></a>Debugging SSH Issues</h2><p>Sometimes Ansible fails to make a successful SSH connection with the host. When this happens, it’s helpful to see exactly what arguments Ansible is passing to the underlying SSH client so you can reproduce the problem manually on the command line.</p>
<p>If you invoke <code>ansible-playbook</code> with the <code>-vvv</code> argument, you can see the exact SSH commands that Ansible invokes. This can be handy for debugging.</p>
<blockquote>
<p>Note that usually I use <code>-v</code> flag</p>
</blockquote>
<p>Sometimes you might need to use -vvvv when debugging a connection issue, in order to see an error message that the SSH client is throwing. </p>
<h2 id="The-Debug-Module"><a href="#The-Debug-Module" class="headerlink" title="The Debug Module"></a>The Debug Module</h2><p>We’ve used the <code>debug</code> module several times in this book. It’s Ansible’s version of a <code>print</code> statement.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- debug: var=myvariable</span><br><span class="line">- debug: msg=&quot;The value of myvariable is &#123;&#123; var &#125;&#125;&quot;</span><br><span class="line">- debug: var=hostvars[inventory_hostname]</span><br></pre></td></tr></table></figure></p>
<h2 id="Playbook-Debugger"><a href="#Playbook-Debugger" class="headerlink" title="Playbook Debugger"></a>Playbook Debugger</h2><p>Ansible 2.1 added support for an <strong>interactive debugger</strong>. To enable debugging, add <code>strategy: debug</code> to your play; for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: an example play</span><br><span class="line">  strategy: debug</span><br><span class="line">  tasks:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p>
<p>If debugging is enabled, Ansible drops into the debugger when a task fails, for example, I write a task like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: install xxx package</span><br><span class="line">  yum:</span><br><span class="line">    name: xxx</span><br><span class="line">    state: latest</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK [install.components : interactive debug] ************************************************************************</span><br><span class="line">fatal: [myk8s2.fyre.ibm.com]: FAILED! =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;rc&quot;: 126,</span><br><span class="line">    &quot;results&quot;: [</span><br><span class="line">        &quot;No package matching &apos;xxx&apos; found available, installed or updated&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">MSG:</span><br><span class="line"></span><br><span class="line">No package matching &apos;xxx&apos; found available, installed or updated</span><br><span class="line"></span><br><span class="line">Debugger invoked</span><br><span class="line">(debug) p task</span><br></pre></td></tr></table></figure>
<p>Let’s see the command list<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Command              | Description                                 |</span><br><span class="line">|----------------------|---------------------------------------------|</span><br><span class="line">| p var                | Print out the value of a supported variable |</span><br><span class="line">| task.args[key]=value | Modify an argument for the failed task      |</span><br><span class="line">| vars[key]=value      | Modify the value of a variable              |</span><br><span class="line">| r                    | rerun the failed task                       |</span><br><span class="line">| c                    | continue execute next                       |</span><br><span class="line">| q                    | abort the play                              |</span><br><span class="line">| help                 | show help message                           |</span><br></pre></td></tr></table></figure></p>
<p>variables supported by the debugger<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Command     | Description                            |</span><br><span class="line">|-------------|----------------------------------------|</span><br><span class="line">| p task      | the name of the failed task            |</span><br><span class="line">| p task.args | The module arguments                   |</span><br><span class="line">| p result    | The result returned by the failed task |</span><br><span class="line">| p vars      | Value of all known variables           |</span><br><span class="line">| p vars[key] | Value of one variable                  |</span><br></pre></td></tr></table></figure></p>
<h2 id="The-Assert-Module"><a href="#The-Assert-Module" class="headerlink" title="The Assert Module"></a>The Assert Module</h2><p>The <code>assert</code> module will fail with an error if a specified condition is not met. For example, to fail the playbook if there’s no <code>eth1</code> interface:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: assert that eth1 interface exists</span><br><span class="line">  assert:</span><br><span class="line">    that: ansible_eth1 is defined</span><br></pre></td></tr></table></figure></p>
<p>When debugging a playbook, it can be helpful to insert assertions so that a failure happens as soon as any assumption you’ve made has been violated.</p>
<p>Keep in mind that the code in an <code>assert</code> statement is Jinja2, not Python.</p>
<h2 id="Checking-Your-Playbook-Before-Execution"><a href="#Checking-Your-Playbook-Before-Execution" class="headerlink" title="Checking Your Playbook Before Execution"></a>Checking Your Playbook Before Execution</h2><p>The <code>ansible-playbook</code> command supports several flags that allow you to sanity check your playbook before you execute it.</p>
<h3 id="Syntax-Check"><a href="#Syntax-Check" class="headerlink" title="Syntax Check"></a>Syntax Check</h3><p>The <code>--syntax-check</code> flag checks that your playbook’s syntax is valid, but it does not execute it.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook --syntax-check -i &lt;host file&gt; playbook.yml</span><br></pre></td></tr></table></figure></p>
<h3 id="List-Hosts"><a href="#List-Hosts" class="headerlink" title="List Hosts"></a>List Hosts</h3><p>The –list-hosts flag outputs the hosts that the playbook will run against, but it does not execute the playbook.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook --list-hosts -i &lt;host file&gt; playbook.yml</span><br></pre></td></tr></table></figure></p>
<h3 id="List-Tasks"><a href="#List-Tasks" class="headerlink" title="List Tasks"></a>List Tasks</h3><p>Outputs the tasks that the playbook will run against. It does not execute the playbook.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook --list-tasks -i &lt;host file&gt; playbook.yml</span><br></pre></td></tr></table></figure></p>
<h3 id="Check-Mode"><a href="#Check-Mode" class="headerlink" title="Check Mode"></a>Check Mode</h3><p>The <code>-C</code> and <code>--check</code> flags run Ansible in check mode (sometimes known as <em>dry-run</em>), which tells you whether each task in the playbook will modify the host, but does not make any changes to the server.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook --check -i &lt;host file&gt; playbook.yml</span><br></pre></td></tr></table></figure>
<p>One of the challenges with using check mode is that later parts of a playbook might succeed only if earlier parts of the playbook were executed.</p>
<h3 id="Diff-Show-File-Changes"><a href="#Diff-Show-File-Changes" class="headerlink" title="Diff (Show File Changes)"></a>Diff (Show File Changes)</h3><p>The <code>-D</code> and <code>-diff</code> flags output differences for any files that are changed on the remote machine. It’s a helpful option to use in conjunction with <code>--check</code> to show how Ansible would change the file if it were run normally:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook --diff --check -i &lt;host file&gt; playbook.yml</span><br></pre></td></tr></table></figure></p>
<p>If Ansible would modify any files (e.g., using modules such as <code>copy</code>, <code>template</code>, and <code>lineinfile</code>), it will show the changes in .diff format, like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK: [set the gunicorn config file] ******************************************</span><br><span class="line">--- before: /home/vagrant/mezzanine-example/project/gunicorn.conf.py</span><br><span class="line">+++ after: /Users/lorin/dev/ansiblebook/ch06/playbooks/templates/gunicor</span><br><span class="line">n.conf.py.j2</span><br><span class="line">@@ -1,7 +1,7 @@</span><br><span class="line"> from __future__ import unicode_literals</span><br><span class="line"> import multiprocessing</span><br><span class="line"></span><br><span class="line"> bind = &quot;127.0.0.1:8000&quot;</span><br><span class="line"> workers = multiprocessing.cpu_count() * 2 + 1</span><br><span class="line">-loglevel = &quot;error&quot;</span><br><span class="line">+loglevel = &quot;warning&quot;</span><br><span class="line"> proc_name = &quot;mezzanine-example&quot;</span><br></pre></td></tr></table></figure></p>
<h2 id="Limiting-Which-Tasks-Run"><a href="#Limiting-Which-Tasks-Run" class="headerlink" title="Limiting Which Tasks Run"></a>Limiting Which Tasks Run</h2><p>Sometimes you don’t want Ansible to run every single task in your playbook, particularly when you’re first writing and debugging the playbook. Ansible provides several command-line options that let you control which tasks run.</p>
<h3 id="Step"><a href="#Step" class="headerlink" title="Step"></a>Step</h3><p>The <code>--step</code> flag, shown in <a href="https://learning.oreilly.com/library/view/ansible-up-and/9781491979792/ch16.html#step-example" target="_blank" rel="noopener">Example 16-7</a>, has Ansible prompt you before running each task, like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Perform task: install packages (y/n/c):</span><br></pre></td></tr></table></figure></p>
<p>You can choose to execute the task (y), skip it (n), or tell Ansible to continue running the rest of the playbook without prompting you (c).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook -i &lt;host file&gt; --step playbook.yml</span><br></pre></td></tr></table></figure></p>
<h3 id="Start-at-Task"><a href="#Start-at-Task" class="headerlink" title="Start-at-Task"></a>Start-at-Task</h3><p>The <code>--start-at-task taskname</code> flag tells Ansible to start running the playbook at the specified task, instead of at the beginning. This can be handy if one of your tasks failed because there was a bug in one of your tasks, and you want to rerun your playbook starting at the task you just fixed.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook -i &lt;host file&gt; --start-at-task=&quot;install packages&quot; playbook.yml</span><br></pre></td></tr></table></figure></p>
<h3 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a>Tags</h3><p>Ansible allows you to add one or more tags to a task or a play. For example, here’s a play that’s tagged with <code>foo</code> and a task that’s tagged with <code>bar</code> and <code>quux</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- hosts: myservers</span><br><span class="line">  tags:</span><br><span class="line">   - foo</span><br><span class="line">  tasks:</span><br><span class="line">   - name: install editors</span><br><span class="line">     apt: name=&#123;&#123; item &#125;&#125;</span><br><span class="line">     with_items:</span><br><span class="line">       - vim</span><br><span class="line">       - emacs</span><br><span class="line">       - nano</span><br><span class="line"></span><br><span class="line">   - name: run arbitrary command</span><br><span class="line">     command: /opt/myprog</span><br><span class="line">     tags:</span><br><span class="line">       - bar</span><br><span class="line">       - quux</span><br></pre></td></tr></table></figure></p>
<p>Use the <code>-t tagnames</code> or <code>--tags tagnames</code> flag to tell Ansible to run only plays and tasks that have certain tags. Use the <code>--skip-tags tagnames</code> flag to tell Ansible to skip plays and tasks that have certain tags.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook -t foo,bar playbook.yml</span><br><span class="line">ansible-playbook --tags=foo,bar playbook.yml</span><br><span class="line">ansible-playbook --skip-tags=baz,quux playbook.yml</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>How Linux Works, 2nd Edition</title>
    <url>/2019/04/19/book-how-linux-works/</url>
    <content><![CDATA[<p>Great book for all Linux developers and administrators! Just note for future quick revisit!</p>
<h2 id="Chapter1-The-Big-picture"><a href="#Chapter1-The-Big-picture" class="headerlink" title="Chapter1. The Big picture"></a>Chapter1. The Big picture</h2><p>The most effective way to understand how an operating system works is through abstraction—a fancy way of saying that you can ignore most of the details.</p>
<p>The <code>kernel</code> is software residing in memory that tells the CPU what to do. The kernel manages the hardware and acts primarily as an interface between the hardware and any running program.</p>
<p>Processes—the running programs that the kernel manages—collectively make up the system’s upper level, called <code>user space</code>.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line">|                                                                         |</span><br><span class="line">|  User process                                                           |</span><br><span class="line">|                                                                         |</span><br><span class="line">|   +-------------------+   +-----------------+    +---------------+      |</span><br><span class="line">|   |  GUI              |   |  Servers        |    |  Shell        |      |</span><br><span class="line">|   |                   |   |                 |    |               |      |</span><br><span class="line">|   +-------------------+   +-----------------+    +---------------+      |</span><br><span class="line">|                                                                         |</span><br><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line">|                                                                         |</span><br><span class="line">|  Linux kernel                                                           |</span><br><span class="line">|  +--------------+     +--------------------------+                      |</span><br><span class="line">|  |  system calls|     |   process management     |                      |</span><br><span class="line">|  +--------------+     +--------------------------+                      |</span><br><span class="line">|                                                                         |</span><br><span class="line">|  +---------------------+        +-------------------------------+       |</span><br><span class="line">|  |  device driver      |        |   memory management           |       |</span><br><span class="line">|  +---------------------+        +-------------------------------+       |</span><br><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line">|                                                                         |</span><br><span class="line">|  Hardware                                                               |</span><br><span class="line">|                                                                         |</span><br><span class="line">|  +-------------------+   +-------------------+   +---------------+      |</span><br><span class="line">|  |   CPU             |   |    RAM            |   |  Disk         |      |</span><br><span class="line">|  +-------------------+   +-------------------+   +---------------+      |</span><br><span class="line">|  +---------------------+                                                |</span><br><span class="line">|  |   Network           |                                                |</span><br><span class="line">|  +---------------------+                                                |</span><br><span class="line">+-------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<p>There is a critical difference between the ways that the kernel and user processes run: The kernel runs in kernel mode, and the user processes run in user mode. Code running in kernel mode has unrestricted access to the processor and main memory. This is a powerful but dangerous privilege that allows a kernel process to easily crash the entire system. The area that only the kernel can access is called kernel space.</p>
<p>User mode, in comparison, restricts access to a (usually quite small) subset of memory and safe CPU operations. User space refers to the parts of main memory that the user processes can access. If a process makes a mistake and crashes, the consequences are limited and can be cleaned up by the kernel. This means that if your web browser crashes, it probably won’t take down the scientific computation that you’ve been running in the background for days.</p>
<h3 id="Hardware"><a href="#Hardware" class="headerlink" title="Hardware"></a>Hardware</h3><p>A CPU is just an operator on memory; it reads its instructions and data from the memory and writes data back out to the memory.</p>
<p>You’ll often hear the term <code>state</code> in reference to memory, processes, the kernel, and other parts of a computer system. Strictly speaking, a state is a particular arrangement of bits. For example, if you have four bits in your memory, 0110, 0001, and 1011 represent three different states.</p>
<p>The term <code>image</code> refers to a particular physical arrangement of bits.</p>
<h3 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h3><p>Nearly everything that the kernel does revolves around main memory. One of the kernel’s tasks is to split memory into many subdivisions, and it must maintain certain state information about those subdivisions at all times. Each process gets its own share of memory, and the kernel must ensure that each process keeps to its share.</p>
<p>The kernel is in charge of managing tasks in four general system areas:<br><strong>Processes</strong>. The kernel is responsible for determining which processes are allowed to use the CPU.</p>
<p><strong>Memory</strong>. The kernel needs to keep track of all memory—what is currently allocated to a particular process, what might be shared between processes, and what is free.</p>
<p><strong>Device drivers</strong>. The kernel acts as an interface between hardware (such as a disk) and processes. It’s usually the kernel’s job to operate the hardware.</p>
<p><strong>System calls and support</strong>. Processes normally use system calls to communicate with the kernel.</p>
<p>The act of one process giving up control of the CPU to another process is called a <strong>context switch</strong>.</p>
<p>The kernel is responsible for context switching. To understand how this works, let’s think about a situation in which a process is running in user mode but its time slice is up. Here’s what happens:</p>
<ol>
<li>The CPU (the actual hardware) interrupts the current process based on an internal timer, switches into kernel mode, and hands control back to the kernel.</li>
<li>The kernel records the current state of the CPU and memory, which will be essential to resuming the process that was just interrupted.</li>
<li>The kernel performs any tasks that might have come up during the preceding time slice (such as collecting data from input and output, or I/O, operations).</li>
<li>The kernel is now ready to let another process run. The kernel analyzes the list of processes that are ready to run and chooses one.</li>
<li>The kernel prepares the memory for this new process, and then prepares the CPU.</li>
<li>The kernel tells the CPU how long the time slice for the new process will last.</li>
<li>The kernel switches the CPU into user mode and hands control of the CPU to the process.</li>
</ol>
<p>The context switch answers the important question of <strong>when</strong> the kernel runs. The answer is that it runs <strong>between</strong> process time slices during a context switch.</p>
<p>Modern CPUs include a <code>memory management unit (MMU)</code> that enables a memory access scheme called <code>virtual memory</code>. When using virtual memory, a process does not directly access the memory by its physical location in the hardware. Instead, the kernel sets up each process to act as if it had an entire machine to itself. When the process accesses some of its memory, the MMU intercepts the access and uses a memory address map to translate the memory location from the process into an actual physical memory location on the machine. The kernel must still initialize and continuously maintain and alter this memory address map. For example, during a context switch, the kernel has to change the map from the outgoing process to the incoming process.</p>
<blockquote>
<p>The implementation of a memory address map is called a page table.</p>
</blockquote>
<p>The kernel’s role with devices is pretty simple. A device is typically accessible only in kernel mode because improper access (such as a user process asking to turn off the power) could crash the machine. Another problem is that different devices rarely have the same programming interface, even if the devices do the same thing, such as two different network cards. Therefore, device drivers have traditionally been part of the kernel.</p>
<p>There are several other kinds of kernel features available to user processes. For example, <code>system calls</code> (or syscalls) perform specific tasks that a user process alone cannot do well or at all. For example, the acts of opening, reading, and writing files all involve system calls.</p>
<p>Other than <code>init</code>, <strong>all</strong> user processes on a Linux system start as a result of <code>fork()</code>, and most of the time, you also run <code>exec()</code> to start a new program instead of running a copy of an existing process.</p>
<h3 id="User-Space"><a href="#User-Space" class="headerlink" title="User Space"></a>User Space</h3><p>As mentioned earlier, the main memory that the kernel allocates for user processes is called <code>user space</code>. Because a process is simply a state (or image) in memory, user space also refers to the memory for the entire collection of running processes. </p>
<h3 id="Users"><a href="#Users" class="headerlink" title="Users"></a>Users</h3><p>A <code>user</code> is an entity that can run processes and own files. A user is associated with a username. For example, a system could have a user named billyjoe. However, the kernel does not manage the usernames; instead, it identifies users by simple numeric identifiers called userids.</p>
<p>Users exist primarily to support permissions and boundaries.</p>
<p>In addition, as powerful as the <strong>root</strong> user is, it still runs in the operating system’s user mode, not kernel mode.</p>
<p><code>Groups</code> are sets of users. The primary purpose of groups is to allow a user to share file access to other users in a group.</p>
<h2 id="Chapter-2-Basic-Commands-and-Directory-Hierarchy"><a href="#Chapter-2-Basic-Commands-and-Directory-Hierarchy" class="headerlink" title="Chapter 2. Basic Commands and Directory Hierarchy"></a>Chapter 2. Basic Commands and Directory Hierarchy</h2><p>Some resources:<br><code>&lt;&lt;UNIX for the Impatient&gt;&gt;</code><br><code>&lt;&lt;Learning the UNIX Operating System&gt;&gt;</code></p>
<p>The <code>shell</code> is one of the most important parts of a Unix system. A shell is a program that runs commands. The shell also serves as a small programming environment.</p>
<p>Many important parts of the system are actually <code>shell scripts</code>—text files that contain a sequence of shell commands. </p>
<p>There are many different Unix shells, but all derive several of their features from the <code>Bourne shell</code> (/bin/sh), a standard shell developed at Bell Labs for early versions of Unix. Every Unix system needs the Bourne shell in order to function correctly, as you will see throughout this book.</p>
<p>Linux uses an enhanced version of the Bourne shell called <code>bash</code> or the “Bourne-again” shell. The bash shell is the default shell on most Linux distributions, and /bin/sh is normally a link to bash on a Linux system. </p>
<blockquote>
<p><code>cat</code> command: The command is called cat because it performs concatenation when it prints the contents of more than one file.</p>
</blockquote>
<p>Pressing <code>CTRL-D</code> on an empty line stops the current standard input entry from the terminal (and often terminates a program). Don’t confuse this with <code>CTRL-C</code>, which terminates a program regardless of its input or output.</p>
<blockquote>
<p>Unix filenames do not need extensions and often do not carry them.</p>
</blockquote>
<p><code>shell globs</code> don’t match dot files unless you explicitly use a pattern such as <code>.*</code>. This is why <code>rm -rf ./*</code> doesn’t remove hidden objects.</p>
<blockquote>
<p>You can run into problems with globs because <code>.*</code> matches <code>.</code> and <code>..</code> (the current and parent directories)</p>
</blockquote>
<p>The shell can store temporary variables, called <code>shell variables</code>, containing the values of text strings. Shell variables are very useful for keeping track of values in scripts, and some shell variables control the way the shell behaves.</p>
<p>An <code>environment variable</code> is like a shell variable, but it’s not specific to the shell. All processes on Unix systems have environment variable storage. The main difference between environment and shell variables is that the operating system passes all of your shell’s <code>environment variables</code> to programs that the shell runs (for example, the sub-script), whereas shell variables cannot be accessed in the commands that you run.</p>
<p>Assign an environment variable with the shell’s <code>export</code> command. For example, if you’d like to make the <code>$STUFF</code> shell variable into an environment variable, use the following:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">STUFF=123</span><br><span class="line">export STUFF</span><br></pre></td></tr></table></figure></p>
<p><code>PATH</code> is a special environment variable that contains the <code>command path</code> (or path for short). A command path is a list of system directories that the shell searches when trying to locate a command.</p>
<p>resource:<br><code>&lt;&lt;Learning the vi and Vim Editor&gt;&gt;</code></p>
<p>Some <code>kill process</code> ways.There are many types of signals. The default is <code>TERM</code>, or terminate.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kill -STOP pid</span><br><span class="line">kill -CONT pid</span><br><span class="line">kill -KILL pid  # the same as kill -9 pid</span><br></pre></td></tr></table></figure></p>
<p>To see if you’ve accidentally suspended any processes on your current terminal, run the <code>jobs</code> command.</p>
<p>You can detach a process from the shell and put it in the “background” with the ampersand <code>&amp;</code>. The best way to make sure that a background process doesn’t bother you is to redirect its output (and possibly input).</p>
<p>Some executable files have an <code>s</code> in the <code>owner permissions</code> listing instead of an x. This indicates that the executable is <code>setuid</code>, meaning that when you execute the program, it runs as though the file owner is the user instead of you. Many programs use this <code>setuid</code> bit to run as root in order to get the privileges they need to change system files. One example is the <code>passwd</code> program, which needs to change the <code>/etc/passwd</code> file.</p>
<p>Directories also have permissions. You can list the contents of a directory if it’s readable, but you can only access a file in a directory if the directory is <code>executable</code>. (One common mistake people make when setting the permissions of directories is to accidentally remove the execute permission when using absolute modes.)</p>
<p>You can specify a set of default permissions with the <code>umask (user file-creation mode mask)</code>shell command, which applies a predefined set of permissions to any new file you create. In general, use <code>umask 022</code> if you want everyone to be able to see all of the files and directories that you create, and use <code>umask 077</code> if you don’t. (You’ll need to put the umask command with the desired mode in one of your startup files to make your new default permissions apply to later sessions).</p>
<blockquote>
<p>How to calculate the <code>umask</code>?</p>
<p>For directories, the base permissions are (rwxrwxrwx) <code>0777</code> and for files they are <code>0666</code> (rw-rw-rw).</p>
<p>You can simply subtract the umask from the base permissions to determine the final permission for file as follows:<br>666 – 022 = 644<br>subtract to get permissions of new file (666-022) : 644 (rw-r–r–)</p>
<p>You can simply subtract the umask from the base permissions to determine the final permission for directory as follows:<br>777 – 022 = 755<br>Subtract to get permissions of new directory (777-022) : 755 (rwxr-xr-x)</p>
</blockquote>
<p>Another compression program in Unix is <code>bzip2</code>, whose compressed files end with <code>.bz2</code>. While marginally slower than gzip, bzip2 often compacts text files a little more, and it is therefore increasingly popular in the distribution of source code. </p>
<p>The <code>bzip2</code> compression/decompression option for tar is <code>j</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar jcvf xx.bz2 file...</span><br><span class="line">tar jxvf xx.bz2</span><br></pre></td></tr></table></figure></p>
<h3 id="Linux-Directory-Hierarchy-Essentials"><a href="#Linux-Directory-Hierarchy-Essentials" class="headerlink" title="Linux Directory Hierarchy Essentials"></a>Linux Directory Hierarchy Essentials</h3><p>Simplified overview of the hierarchy<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">                                                  +---------+</span><br><span class="line">                                                  |   /     |</span><br><span class="line">                                                  +-----+---+</span><br><span class="line">                                                        |</span><br><span class="line">    +-------------+-------------+-----------+----------------------+-----------+-----------+----------+</span><br><span class="line">    |             |             |           |           |          |           |           |          |</span><br><span class="line">    |             |             |           |           |          |           |           |          |</span><br><span class="line">    |             |             |           |           |          |           |           |          |</span><br><span class="line">    v             v             v           v           v          v           v           v          v</span><br><span class="line">+---+----+    +---+----+   +----+---+  +----+---+  +----+---+  +---+---+  +----+---+  +----+----+ +---------+</span><br><span class="line">|  /bin  |    |  /dev  |   |  /etc  |  |   /usr |  | /home  |  | /lib  |  |  /sbin |  |   /tmp  | |  /var   |</span><br><span class="line">+--------+    +--------+   +--------+  +----+---+  +--------+  +-------+  +--------+  +---------+ +----+----+</span><br><span class="line">                                            |                                                          |</span><br><span class="line">                                            |                                                     +----+-----+</span><br><span class="line">                                            |                                                     |          |</span><br><span class="line">              +---------+----------+--------------------+----------+                              |          |</span><br><span class="line">              |         |          |        |           |          |                              |          |</span><br><span class="line">              v         v          v        v           v          v                              v          v</span><br><span class="line">         +----+--+  +---+--+  +----+---+  +-+----+  +---+---+  +---+---+                     +----+---+  +---+----+</span><br><span class="line">         | bin/  |  | man/ |  |  lib/  |  |local/|  | sbin/ |  | share/|                     | log/   |  |  /tmp  |</span><br><span class="line">         +-------+  +------+  +--------+  +------+  +-------+  +-------+                     +--------+  +--------+</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p><code>/bin</code> Contains ready-to-run programs (also known as an executables), including most of the basic Unix commands such as ls and cp. Most of the programs in /bin are in binary format, having been created by a C compiler, but some are shell scripts in modern systems.</p>
</li>
<li><p><code>/dev</code> Contains device files.</p>
</li>
<li><p><code>/etc</code> This core system configuration directory contains the user password, boot, device, networking, and other setup files. Many items in /etc are specific to the machine’s hardware. </p>
</li>
<li><p><code>/home</code> Holds personal directories for regular users. </p>
</li>
<li><p><code>/lib</code> An abbreviation for library, this directory holds library files containing code that executables can use.</p>
</li>
<li><p><code>/proc</code> Provides system statistics through a browsable directory-and-file interface. The <code>/proc</code> directory contains information about currently running processes as well as some kernel parameters.</p>
</li>
<li><p><code>/sys</code> This directory is similar to /proc in that it provides a device and system interface.</p>
</li>
<li><p><code>/sbin</code> The place for system executables. Programs in /sbin directories relate to system management.</p>
</li>
<li><p><code>/tmp</code> A storage area for smaller, temporary files that you don’t care much about. If something is extremely important, don’t put it in /tmp because most distributions clear /tmp when the machine boots and some even remove its old files periodically. Also, don’t let /tmp fill up with garbage because its space is usually shared with something critical  </p>
</li>
<li><p><code>/usr</code> Although pronounced “user,” this subdirectory has no user files. Instead, it contains a large directory hierarchy, including the bulk of the Linux system. Many of the directory names in /usr are the same as those in the root directory (like /usr/bin and /usr/lib), and they hold the same type of files. (The reason that the root directory does not contain the complete system is primarily historic—in the past, it was to keep space requirements low for the root.)</p>
</li>
<li><p><code>/var</code> The variable subdirectory, where programs record runtime information. System logging, user tracking, caches, and other files that system programs create and manage are here.</p>
</li>
<li><p><code>/boot</code> Contains kernel boot loader files. These files pertain only to the very first stage of the Linux startup procedure.</p>
</li>
<li><p><code>/media</code> A base attachment point for removable media such as flash drives that is found in many distributions.</p>
</li>
<li><p><code>/opt</code> This may contain additional third-party software. </p>
</li>
</ul>
<h3 id="Kernel-Location"><a href="#Kernel-Location" class="headerlink" title="Kernel Location"></a>Kernel Location</h3><p>On Linux systems, the kernel is normally in <code>/vmlinuz</code> or <code>/boot/vmlinuz</code>. A boot loader loads this file into memory and sets it in motion when the system boots.</p>
<p>Once the boot loader runs and sets the kernel in motion, the main kernel file is no longer used by the running system. However, you’ll find many modules that the kernel can load and unload on demand during the course of normal system operation. Called loadable kernel modules, they are located under <code>/lib/modules</code>.</p>
<h2 id="Chapter-3-Devices"><a href="#Chapter-3-Devices" class="headerlink" title="Chapter 3. Devices"></a>Chapter 3. Devices</h2><p>It’s important to understand how the kernel interacts with user space when presented with new devices. The <code>udev</code> system enables user-space programs to automatically configure and use new devices. </p>
<blockquote>
<p><code>udev</code> (userspace /dev) is a device manager for the Linux kernel. As the successor of devfsd and hotplug, udev primarily manages device nodes in the /dev directory.</p>
</blockquote>
<h3 id="Device-Files"><a href="#Device-Files" class="headerlink" title="Device Files"></a>Device Files</h3><p>It is easy to manipulate most devices on a Unix system because the kernel presents many of the device I/O interfaces to user processes as <strong>files</strong>. These device files are sometimes called <code>device nodes</code>. Not only can a programmer use regular file operations to work with a device, but some devices are also accessible to standard programs like <code>cat</code>. However, not all devices or device capabilities are accessible with standard file I/O.</p>
<p>Device files are in the <code>/dev</code> directory, and running <code>ls /dev</code> reveals more than a few files in <code>/dev</code>.</p>
<p>if run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -l</span><br><span class="line">brw-rw----     1 root disk 8, 1 Sep  6 08:37 sda1</span><br><span class="line">crw-rw-rw-     1 root root 1, 3 Sep  6 08:37 null</span><br><span class="line">prw-r--r--     1 root root    0 Mar  3 19:17 fdata</span><br><span class="line">srw-rw-rw-     1 root root    0 Dec 18 07:43 log</span><br></pre></td></tr></table></figure></p>
<p>if the first char in file mode is <code>b</code>, <code>c</code>, <code>p</code>, or <code>s</code>, the file is a device. These letters stand for block, character, pipe, and socket, respectively.</p>
<p>The numbers before the dates in the first two lines are the <code>major</code> and <code>minor</code> device numbers that help the kernel identify the device. Similar devices usually have the same major number.</p>
<h4 id="Block-device"><a href="#Block-device" class="headerlink" title="Block device"></a>Block device</h4><p>Programs access data from a block device in fixed chunks. The sda1 in the preceding example is a disk device, a type of block device.</p>
<h4 id="Character-device"><a href="#Character-device" class="headerlink" title="Character device"></a>Character device</h4><p>Character devices work with data streams. Printers directly attached to your computer are represented by character devices. It’s important to note that during character device interaction, the kernel cannot back up and reexamine the data stream after it has passed data to a device or process.</p>
<h4 id="Pipe-device"><a href="#Pipe-device" class="headerlink" title="Pipe device"></a>Pipe device</h4><p>Named pipes are like character devices, with another process at the other end of the I/O stream instead of a kernel driver.</p>
<h3 id="Socket-device"><a href="#Socket-device" class="headerlink" title="Socket device"></a>Socket device</h3><p>Sockets are special-purpose interfaces that are frequently used for <code>interprocess communication</code>. </p>
<blockquote>
<p>Not all devices have device files because the block and character device I/O interfaces are not appropriate in all cases. For example, <code>network interfaces</code> don’t have device files. It is theoretically possible to interact with a network interface using a single character device, but because it would be exceptionally difficult, the kernel uses other I/O interfaces.</p>
</blockquote>
<h3 id="The-sysfs-Device-Path"><a href="#The-sysfs-Device-Path" class="headerlink" title="The sysfs Device Path"></a>The sysfs Device Path</h3><p>To provide a uniform view for attached devices based on their actual hardware attributes, the Linux kernel offers the <code>sysfs</code> interface through a system of files and directories. The base path for devices is <code>/sys/devices</code> (this is a real directory!).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -ltr /sys/devices/</span><br><span class="line"></span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x 21 root root 0 Apr 25 23:18 virtual</span><br><span class="line">drwxr-xr-x  3 root root 0 Apr 25 23:18 tracepoint</span><br><span class="line">drwxr-xr-x 10 root root 0 Apr 25 23:18 system</span><br><span class="line">drwxr-xr-x  3 root root 0 Apr 25 23:18 software</span><br><span class="line">drwxr-xr-x  8 root root 0 Apr 25 23:18 pnp0</span><br><span class="line">drwxr-xr-x  9 root root 0 Apr 25 23:18 platform</span><br><span class="line">drwxr-xr-x 15 root root 0 Apr 25 23:18 pci0000:00</span><br><span class="line">drwxr-xr-x  5 root root 0 Apr 25 23:18 msr</span><br><span class="line">drwxr-xr-x  6 root root 0 Apr 25 23:18 LNXSYSTM:00</span><br><span class="line">drwxr-xr-x  3 root root 0 Apr 25 23:18 breakpoint</span><br></pre></td></tr></table></figure></p>
<p>The <code>/dev</code> file is there so that user processes can use the device, whereas the <code>/sys/devices</code> path is used to view information and manage the device. In <code>/dev</code> you can run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">udevadm info --query=all --name=/dev/null</span><br><span class="line"></span><br><span class="line">P: /devices/virtual/mem/null</span><br><span class="line">N: null</span><br><span class="line">E: DEVMODE=0666</span><br><span class="line">E: DEVNAME=/dev/null</span><br><span class="line">E: DEVPATH=/devices/virtual/mem/null</span><br><span class="line">E: MAJOR=1</span><br><span class="line">E: MINOR=3</span><br><span class="line">E: SUBSYSTEM=mem</span><br></pre></td></tr></table></figure></p>
<p>this command will show the sysfs location <code>/devices/virtual/mem/null</code></p>
<h3 id="dd-and-Devices"><a href="#dd-and-Devices" class="headerlink" title="dd and Devices"></a>dd and Devices</h3><p>The program <code>dd</code> is extremely useful when working with block and character devices. This program’s sole function is to read from an input file or stream and write to an output file or stream, possibly doing some encoding conversion on the way.</p>
<p>I am not using it.</p>
<h3 id="Device-Name-Summary"><a href="#Device-Name-Summary" class="headerlink" title="Device Name Summary"></a>Device Name Summary</h3><p>Not necessarily as described below, may be some variations:</p>
<ul>
<li>Hard Disks: /dev/sd*</li>
</ul>
<p>Most hard disks attached to current Linux systems correspond to device names with an <code>sd</code> prefix, such as <code>/dev/sda</code>, <code>/dev/sdb</code>, and so on. These devices represent entire disks; the kernel makes separate device files, such as <code>/dev/sda1</code> and <code>/dev/sda2</code>, for the partitions on a disk.</p>
<blockquote>
<p>The <code>sd</code> portion of the name stands for SCSI disk.</p>
</blockquote>
<p>Linux assigns devices to device files in the <strong>order</strong> in which its drivers encounter devices. This may cause problem when you remove one disk and insert another, because the device name changed for old disk. Most modern Linux systems use the Universally Unique Identifier (<code>UUID</code>) for persistent disk device access.</p>
<ul>
<li>CD and DVD Drives: /dev/sr*</li>
</ul>
<p>Linux recognizes most optical storage drives as the SCSI devices /dev/sr0, /dev/sr1, and so on. </p>
<ul>
<li><p>PATA Hard Disks: /dev/hd*</p>
</li>
<li><p>Terminals: /dev/tty<em>, /dev/pts/</em>, and /dev/tty</p>
</li>
</ul>
<p>Terminals are devices for moving characters between a user process and an I/O device, usually for text output to a terminal screen. </p>
<p><code>Pseudoterminal</code> devices are emulated terminals that understand the I/O features of real terminals. </p>
<p>Two common terminal devices are <code>/dev/tty1</code> (the first virtual console) and <code>/dev/pts/0</code> (the first pseudoterminal device). The <code>/dev/tty</code> device is the controlling terminal of the current process.</p>
<blockquote>
<p>teletypewriter, <code>tty</code> in shorthand</p>
</blockquote>
<p>I am always confused, at least you need to know <strong>shell</strong> is the command line interpreter!<br><a href="https://askubuntu.com/questions/506510/what-is-the-difference-between-terminal-console-shell-and-command-line" target="_blank" rel="noopener">What is the difference between Terminal, Console, Shell, and Command Line?</a></p>
<p>Linux has two primary display modes: <code>text mode</code> and an <code>X Window System server</code> (graphics mode, usually via a display manager). Although Linux systems traditionally booted in text mode, most distributions now use kernel parameters and interim graphical display mechanisms to completely hide text mode as the system is booting. In such cases, the system switches over to full graphics mode near the end of the boot process.</p>
<p>OK, skip rest of the content in Chapter 3.</p>
<h2 id="Chapter-4-Disks-and-Filesystems"><a href="#Chapter-4-Disks-and-Filesystems" class="headerlink" title="Chapter 4. Disks and Filesystems"></a>Chapter 4. Disks and Filesystems</h2><p>Schematic of a typical Linux disk:</p>
<p><img src="https://drive.google.com/uc?id=1e0ziORmoEx6zPk6J6qEid26aWl-zw21G" alt=""></p>
<p><code>Partitions</code> are subdivisions of the whole disk. On Linux, they’re denoted with a number after the whole block device, and therefore have device names such as <code>/dev/sda1</code> and <code>/dev/sdb3</code>.</p>
<p>Partitions are defined on a small area of the disk called a <code>partition table</code>.</p>
<p>The next layer after the partition is the <code>filesystem</code>, the database of files and directories that you’re accustomed to interacting with in user space.</p>
<p>To access data on a disk, the Linux kernel uses the system of layers like this:</p>
<p><img src="https://drive.google.com/uc?id=1Hy8vWUIBuo33oH976PNEkVzvAOzCuyKJ" alt=""></p>
<blockquote>
<p>Notice that you can work with the disk through the filesystem as well as directly through the disk devices.</p>
</blockquote>
<h3 id="Partitioning-Disk-Devices"><a href="#Partitioning-Disk-Devices" class="headerlink" title="Partitioning Disk Devices"></a>Partitioning Disk Devices</h3><blockquote>
<p>You can view RedHat <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/ch-partitions" target="_blank" rel="noopener">Doc</a> for more information about partition</p>
</blockquote>
<p>Let’s view the partition table:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">parted -l</span><br><span class="line"></span><br><span class="line">Model: ATA WDC WD3200AAJS-2 (scsi)</span><br><span class="line">Disk /dev/sda: 320GB</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: msdos</span><br><span class="line"></span><br><span class="line">Number   Start   End    Size   Type      File system    Flags</span><br><span class="line"> 1       1049kB  316GB  316GB  primary   ext4           boot</span><br><span class="line"> 2       316GB   320GB  4235MB extended</span><br><span class="line"> 5       316GB   320GB  4235MB logical   linux-swap(v1)</span><br><span class="line"></span><br><span class="line">Model: FLASH Drive UT_USB20 (scsi)</span><br><span class="line">Disk /dev/sdf: 4041MB</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: gpt</span><br><span class="line"></span><br><span class="line">Number  Start   End     Size     File system  Name        Flags</span><br><span class="line"> 1      17.4kB  1000MB  1000MB                myfirst</span><br><span class="line"> 2      1000MB  4040MB  3040MB                mysecond</span><br></pre></td></tr></table></figure></p>
<p>There are 2 different partition tables: MBR (msdos) and GPT (gpt). The MBR table in this example contains primary, extended, and logical partitions. </p>
<h3 id="Changing-Partition-Tables"><a href="#Changing-Partition-Tables" class="headerlink" title="Changing Partition Tables"></a>Changing Partition Tables</h3><p>You can use <code>parted</code> command to change partition. Check <code>/proc/partitions</code> can get full partition information.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /proc/partitions</span><br><span class="line"></span><br><span class="line">major minor  #blocks  name</span><br><span class="line"> 252        0  262144000 vda</span><br><span class="line"> 252        1    1048576 vda1</span><br><span class="line"> 252        2  260976640 vda2</span><br><span class="line"> 253        0  252706816 dm-0</span><br><span class="line"> 253        1    8257536 dm-1</span><br></pre></td></tr></table></figure></p>
<h3 id="Filesystems"><a href="#Filesystems" class="headerlink" title="Filesystems"></a>Filesystems</h3><p>The last link between the kernel and user space for disks is typically the file-system; this is what you’re accustomed to interacting with when you run commands such as <code>ls</code> and <code>cd</code>. As previously mentioned, the <strong>filesystem is a form of database</strong>; it supplies the structure to transform a simple block device into the sophisticated hierarchy of files and subdirectories that users can understand.</p>
<h4 id="Filesystem-Types"><a href="#Filesystem-Types" class="headerlink" title="Filesystem Types"></a>Filesystem Types</h4><ul>
<li>The <code>Fourth Extended filesystem (ext4)</code> is the current iteration of a line of filesystems native to Linux. The <code>Second Extended filesystem (ext2)</code> was a longtime default for Linux systems inspired by traditional Unix filesystems such as the Unix File System (UFS) and the Fast File System (FFS). The <code>Third Extended filesystem (ext3)</code> added a journal feature (a small cache outside the normal filesystem data structure) to enhance data integrity and hasten booting. The ext4 filesystem is an incremental improvement with support for larger files than ext2 or ext3 support and a greater number of subdirectories.</li>
</ul>
<h4 id="Create-a-Filesystems"><a href="#Create-a-Filesystems" class="headerlink" title="Create a Filesystems"></a>Create a Filesystems</h4><p>Once you’re done with the partitioning process, you’re ready to create filesystems. As with partitioning, you’ll do this in user space because a user-space process can directly access and manipulate a block device. </p>
<p>For example, you can create an ext4 partition on /dev/sdf2<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkfs -t ext4 /dev/sdf2</span><br></pre></td></tr></table></figure></p>
<p>Filesystem creation is a task that you should only need to perform after adding a new disk or repartitioning an old one. You should create a filesystem just once for each new partition that has no preexisting data (or that has data that you want to remove). Creating a new filesystem on top of an existing filesystem will effectively destroy the old data.</p>
<p>It turns out that mkfs is only a frontend for a series of filesystem creation programs:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -l /sbin/mkfs.*</span><br><span class="line"></span><br><span class="line">-rwxr-xr-x. 1 root root 375240 Mar  7  2017 /sbin/mkfs.btrfs</span><br><span class="line">-rwxr-xr-x  1 root root  37080 Jul 12  2018 /sbin/mkfs.cramfs</span><br><span class="line">-rwxr-xr-x  4 root root  96384 Apr 10  2018 /sbin/mkfs.ext2</span><br><span class="line">-rwxr-xr-x  4 root root  96384 Apr 10  2018 /sbin/mkfs.ext3</span><br><span class="line">-rwxr-xr-x  4 root root  96384 Apr 10  2018 /sbin/mkfs.ext4</span><br><span class="line">-rwxr-xr-x  1 root root  37184 Jul 12  2018 /sbin/mkfs.minix</span><br><span class="line">-rwxr-xr-x. 1 root root 368504 Feb 27  2018 /sbin/mkfs.xfs</span><br></pre></td></tr></table></figure></p>
<h4 id="Mounting-a-Filesystem"><a href="#Mounting-a-Filesystem" class="headerlink" title="Mounting a Filesystem"></a>Mounting a Filesystem</h4><p>On Unix, the process of attaching a filesystem is called <code>mounting</code>. When the system boots, the kernel reads some configuration data and mounts root (/) based on the configuration data.</p>
<p>When mounting a filesystem, the common terminology is <em>mount a device on a mount point.</em></p>
<p>To see current system mount status:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount </span><br><span class="line">...</span><br><span class="line">cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)</span><br><span class="line">/dev/mapper/rhel-root on / type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">mqueue on /dev/mqueue type mqueue (rw,relatime)</span><br><span class="line">hugetlbfs on /dev/hugepages type hugetlbfs (rw,relatime)</span><br><span class="line">/dev/vda1 on /boot type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">tmpfs on /run/user/0 type tmpfs (rw,nosuid,nodev,relatime,size=800956k,mode=700)</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>There are 3 key fields:</p>
<ul>
<li>The filesystem’s device, such as a disk partition; where the actual file-system data resides</li>
<li>The filesystem type</li>
<li>The mount point—that is, the place in the current system’s directory hierarchy where the filesystem will be attached. </li>
</ul>
<p>For example, to mount the Fourth Extended filesystem /dev/sdf2 on /home/extra, use this command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount -t ext4 /dev/sdf2 /home/extra</span><br></pre></td></tr></table></figure></p>
<p>To unmount (detach) a filesystem, use the umount command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">umount mountpoint</span><br></pre></td></tr></table></figure></p>
<h4 id="Filesystem-UUID"><a href="#Filesystem-UUID" class="headerlink" title="Filesystem UUID"></a>Filesystem UUID</h4><p>You can identify and mount filesystems by their <code>Universally Unique Identifier (UUID)</code>, a software standard. The UUID is a type of serial number, and each one should be different.</p>
<p>For example, if you know the UUID of /dev/sdf2 is a9011c2b-1c03-4288-b3fe-8ba961ab0898, so you can mount it as:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount UUID=a9011c2b-1c03-4288-b3fe-8ba961ab0898 /home/extra</span><br></pre></td></tr></table></figure></p>
<p>Here no <code>-t  ext4</code> option, because mount know that.</p>
<p>To view a list of devices and the corresponding filesystems and UUIDs on your system, use the blkid (block ID) program:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">blkid</span><br><span class="line"></span><br><span class="line">/dev/sdf2: UUID=&quot;a9011c2b-1c03-4288-b3fe-8ba961ab0898&quot; TYPE=&quot;ext4&quot;</span><br><span class="line">/dev/sda1: UUID=&quot;70ccd6e7-6ae6-44f6-812c-51aab8036d29&quot; TYPE=&quot;ext4&quot;</span><br><span class="line">/dev/sda5: UUID=&quot;592dcfd1-58da-4769-9ea8-5f412a896980&quot; TYPE=&quot;swap&quot;</span><br><span class="line">/dev/sde1: SEC_TYPE=&quot;msdos&quot; UUID=&quot;3762-6138&quot; TYPE=&quot;vfat&quot;</span><br></pre></td></tr></table></figure></p>
<p>For one thing, they’re the preferred way to automatically mount filesystems in <code>/etc/fstab</code> at boot time.</p>
<h4 id="Disk-Buffering-Caching-and-Filesystems"><a href="#Disk-Buffering-Caching-and-Filesystems" class="headerlink" title="Disk Buffering, Caching, and Filesystems"></a>Disk Buffering, Caching, and Filesystems</h4><p>Linux, like other versions of Unix, buffers writes to the disk. This means that the kernel usually doesn’t immediately write changes to filesystems when processes request changes. <strong>Instead it stores the changes in RAM until the kernel can conveniently make the actual change to the disk</strong>. This buffering system is transparent to the user and improves performance.</p>
<blockquote>
<p>This is the reason why before we remove the USB, we need to unmount it in case of data lose.</p>
</blockquote>
<p>When you unmount a filesystem with umount, the kernel automatically synchronizes with the disk. At any other time, you can force the kernel to write the changes in its buffer to the disk by running the <code>sync</code> command.</p>
<h4 id="The-etc-fstab-Filesystem-Table"><a href="#The-etc-fstab-Filesystem-Table" class="headerlink" title="The /etc/fstab Filesystem Table"></a>The /etc/fstab Filesystem Table</h4><p>I encounter this when write <code>/etc/fstab</code> file with NFS when developing k8s.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/dev/mapper/rhel-root   /                       xfs     defaults        0 0</span><br><span class="line">UUID=a44461e9-e1d7-45fd-a387-255fafd14746 /boot                   xfs     defaults        0 0</span><br><span class="line">/dev/mapper/rhel-swap   swap                    swap    defaults        0 0</span><br><span class="line">halos1.fyre.ibm.com:/data /mnt nfs defaults,timeo=10,retrans=3,rsize=1048576,wsize=1048576 0 0</span><br></pre></td></tr></table></figure></p>
<p>To mount filesystems at boot time and take the drudgery out of the mount command, Linux systems keep a permanent list of filesystems and options in <code>/etc/fstab</code>.</p>
<ul>
<li><p><code>The device or UUID</code>. Most current Linux systems no longer use the device in /etc/fstab, preferring the UUID. </p>
</li>
<li><p><code>The mount point</code>. Indicates where to attach the filesystem.</p>
</li>
<li><p><code>The filesystem type</code>.</p>
</li>
<li><p><code>Options</code>. Use long mount options separated by commas.</p>
</li>
<li><p><code>Backup information for use by the dump command</code>. You should always use a 0 in this field.</p>
</li>
<li><p><code>The filesystem integrity test order.</code> To ensure that fsck always runs on the root first, always set this to 1 for the root filesystem and 2 for any other filesystems on a hard disk. Use <code>0</code> to disable the bootup check for everything else, including CD-ROM drives, swap, and the /proc file-system</p>
</li>
</ul>
<p>You can also try to mount all entries at once in /etc/fstab that do not contain the noauto option with this command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount -a</span><br></pre></td></tr></table></figure></p>
<p>Let’s see some commonly use options:</p>
<ul>
<li><p><code>defaults</code>. This uses the mount defaults: read-write mode, enable device files, executables, the setuid bit, and so on. Use this when you don’t want to give the filesystem any special options but you do want to fill all fields in /etc/fstab.</p>
</li>
<li><p><code>noauto</code>. This option tells a mount -a command to ignore the entry. </p>
</li>
</ul>
<h4 id="Filesystem-Capacity"><a href="#Filesystem-Capacity" class="headerlink" title="Filesystem Capacity"></a>Filesystem Capacity</h4><p>To view the size and utilization of your currently mounted filesystems, use the <code>df</code> command.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -BM</span><br><span class="line"></span><br><span class="line">Filesystem                1M-blocks   Used Available Use% Mounted on</span><br><span class="line">/dev/mapper/rhel-root       245640M 75636M   170005M  31% /</span><br><span class="line">devtmpfs                      7931M     0M     7931M   0% /dev</span><br><span class="line">tmpfs                         7943M     0M     7943M   0% /dev/shm</span><br><span class="line">tmpfs                         7943M   835M     7109M  11% /run</span><br><span class="line">tmpfs                         7943M     0M     7943M   0% /sys/fs/cgroup</span><br><span class="line">/dev/vda1                     1014M   183M      832M  19% /boot</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h4 id="Checking-and-Repairing-Filesystems"><a href="#Checking-and-Repairing-Filesystems" class="headerlink" title="Checking and Repairing Filesystems"></a>Checking and Repairing Filesystems</h4><p>Filesystem errors are usually due to a user shutting down the system in a rude way (for example, by pulling out the power cord). In such cases, the filesystem cache in memory may not match the data on the disk, and the system also may be in the process of altering the filesystem when you happen to give the computer a kick. Although a new generation of filesystems supports journals to make filesystem corruption far less common, you should always shut the system down properly. And regardless of the filesystem in use, filesystem checks are still necessary every now and to maintain sanity.</p>
<p>The tool to check a filesystem is <code>fsck</code>.</p>
<p>In the worst cases, you can try:</p>
<ul>
<li><p>You can try to extract the entire filesystem image from the disk with <code>dd</code> and transfer it to a partition on another disk of the same size.</p>
</li>
<li><p>You can try to patch the filesystem as much as possible, mount it in read-only mode, and salvage what you can.</p>
</li>
<li><p>You can try <code>debugfs</code>.</p>
</li>
</ul>
<h4 id="Special-Purpose-Filesystems"><a href="#Special-Purpose-Filesystems" class="headerlink" title="Special-Purpose Filesystems"></a>Special-Purpose Filesystems</h4><p>Not all filesystems represent storage on physical media. Specifically, most versions of Unix have filesystems that serve as system interfaces. That is, rather than serving only as a means to store data on a device, a filesystem can represent system information such as process IDs and kernel diagnostics.</p>
<p>The special filesystem types in common use on Linux include the following:</p>
<ul>
<li><p><code>proc</code>. Mounted on /proc. The name proc is actually an abbreviation for process. Each numbered directory inside /proc is actually the process ID of a current process on the system; the files in those directories represent various aspects of the processes. The file /proc/self represents the current process. </p>
</li>
<li><p><code>sysfs</code>. Mounted on /sys.</p>
</li>
<li><p><code>tmpfs</code>. Mounted on /run and other locations. With tmpfs, you can use your physical memory and swap space as temporary storage, stored in volatile memory instead of a persistent storage device.</p>
</li>
</ul>
<h3 id="Swap-Space"><a href="#Swap-Space" class="headerlink" title="Swap Space"></a>Swap Space</h3><p>Not every partition on a disk contains a filesystem. It’s also possible to augment the RAM on a machine with disk space. The disk area used to store memory pages is called <code>swap space</code> (or just swap for short).</p>
<p>you can use <code>free</code> command to see the swap usage:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">free -m</span><br><span class="line"></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          32010       10894        3992        1605       17123       18811</span><br><span class="line">Swap:          8063          64        7999</span><br></pre></td></tr></table></figure></p>
<p>you can use a disk partition and a regular file as swap space, for disk:</p>
<ol>
<li>Ensure partition is empty</li>
<li>Run <code>mkswap dev</code>, dev is the partition device</li>
<li>Execute <code>swapon dev</code> to register the space with the kernel.</li>
<li>Register in <code>/etc/fstab</code> file</li>
</ol>
<p>Use these commands to create an empty file, initialize it as swap, and add it to the swap pool:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dd if=/dev/zero of=swap_file bs=1024k count=num_mb</span><br><span class="line">mkswap swap_file</span><br><span class="line">swapon swap_file</span><br></pre></td></tr></table></figure></p>
<p>Here, <code>swap_file</code> is the name of the new swap file, and <code>num_mb</code> is the desired size, in megabytes.</p>
<p>To remove a swap partition or file from the kernel’s active pool, use the <code>swapoff</code> command.</p>
<p><strong>Note</strong> some administrators configure certain systems with <strong>no</strong> swap space at all. For example, high-performance network servers should never dip into swap space and should avoid disk access if at all possible.</p>
<p>It’s dangerous to do this on a general-purpose machine. If a machine completely runs out of both real memory and swap space, the Linux kernel invokes the <code>out-of-memory (OOM)</code> killer to kill a process in order to free up some memory. You obviously don’t want this to happen to your desktop applications. On the other hand, high-performance servers include sophisticated monitoring and load-balancing systems to ensure that they never reach the danger zone.</p>
<h3 id="Looking-Forward-Disks-and-User-Space"><a href="#Looking-Forward-Disks-and-User-Space" class="headerlink" title="Looking Forward: Disks and User Space"></a>Looking Forward: Disks and User Space</h3><p>In disk-related components on a Unix system, the boundaries between user space and the kernel can be difficult to characterize. As you’ve seen, the kernel handles raw block I/O from the devices, and user-space tools can use the block I/O through device files. However, user space typically uses the block I/O only for initializing operations such as partitioning, file-system creation, and swap space creation.</p>
<p>In normal use, user space uses only the filesystem support that the kernel provides on top of the block I/O.</p>
<h2 id="Chapter-5-How-the-Linux-Kernel-Boots"><a href="#Chapter-5-How-the-Linux-Kernel-Boots" class="headerlink" title="Chapter 5. How the Linux Kernel Boots"></a>Chapter 5. How the Linux Kernel Boots</h2><p>You’ll learn how the kernel moves into memory up to the point where the first user process starts.</p>
<p><strong>A simplified view of the boot process looks like this:</strong></p>
<ol>
<li>The machine’s BIOS or boot firmware loads and runs a boot loader.</li>
<li>The boot loader finds the kernel image on disk, loads it into memory, and starts it.</li>
<li>The kernel initializes the devices and its drivers.</li>
<li>The kernel mounts the root filesystem.</li>
<li>The kernel starts a program called init with a process ID of 1. This point is the user space start.</li>
<li>init sets the rest of the system processes in motion.</li>
<li>At some point, init starts a process allowing you to log in, usually at the end or near the end of the boot.</li>
</ol>
<h3 id="Startup-Messages"><a href="#Startup-Messages" class="headerlink" title="Startup Messages"></a>Startup Messages</h3><p>There are two ways to view the kernel’s boot and runtime diagnostic messages:</p>
<ul>
<li><p>Look at the kernel system log file. You’ll often find this in <code>/var/log/ kern.log</code>, but depending on how your system is configured, it might also be lumped together with a lot of other system logs in <code>/var/log/messages</code> or elsewhere.</p>
</li>
<li><p>Use the <code>dmesg</code> command, but be sure to pipe the output to less because there will be much more than a screen’s worth. The <code>dmesg</code> command uses the kernel ring buffer, which is of limited size, but most newer kernels have a large enough buffer to hold boot messages for a long time.</p>
</li>
</ul>
<h3 id="Kernel-Initialization-and-Boot-Options"><a href="#Kernel-Initialization-and-Boot-Options" class="headerlink" title="Kernel Initialization and Boot Options"></a>Kernel Initialization and Boot Options</h3><p>Upon startup, the Linux kernel initializes in this general order:</p>
<ol>
<li>CPU inspection</li>
<li>Memory inspection</li>
<li>Device bus discovery</li>
<li>Device discovery</li>
<li>Auxiliary kernel subsystem setup (networking, and so on)</li>
<li>Root filesystem mount</li>
<li>User space start</li>
</ol>
<p>The following memory management messages are a good indication that the user-space handoff is about to happen because this is where the kernel protects its own memory from user-space processes:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[    0.972934] Freeing unused kernel memory: 1844k freed</span><br><span class="line">[    0.973411] Write protecting the kernel read-only data: 12288k</span><br><span class="line">[    0.975623] Freeing unused kernel memory: 832k freed</span><br><span class="line">[    0.977405] Freeing unused kernel memory: 676k freed</span><br></pre></td></tr></table></figure></p>
<h3 id="Kernel-Parameters"><a href="#Kernel-Parameters" class="headerlink" title="Kernel Parameters"></a>Kernel Parameters</h3><p>I just encountered an issue about kernel parameters for Db2… Let’s see.</p>
<p>When running the Linux kernel, the boot loader passes in a set of text-based <strong>kernel parameters</strong> that tell the kernel how it should start. The parameters specify many different types of behavior, such as the amount of diagnostic output the kernel should produce and device driver–specific options.</p>
<p>You can view the kernel parameters from your system’s boot by looking at the <code>/proc/cmdline</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BOOT_IMAGE=/vmlinuz-3.10.0-862.14.4.el7.x86_64 root=/dev/mapper/rhel-root ro crashkernel=auto rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet elevator=noop LANG=en_US.UTF-8</span><br></pre></td></tr></table></figure></p>
<p>The <code>root=/dev/mapper/rhel-root</code> is where root filesystem resides.</p>
<h3 id="Boot-Loader"><a href="#Boot-Loader" class="headerlink" title="Boot Loader"></a>Boot Loader</h3><p><a href="https://searchdatacenter.techtarget.com/definition/boot-loader-boot-manager" target="_blank" rel="noopener">Other boot loader intro</a></p>
<p>At the start of the boot process, before the kernel and init start, a boot loader starts the kernel. The task of a boot loader sounds simple: It loads the kernel into memory, and then starts the kernel with a set of kernel parameters.</p>
<p>Kernel and its parameters are usually somewhere on the root filesystem.</p>
<p>On PCs, boot loaders use the <code>Basic Input/Output System (BIOS)</code> or <code>Unified Extensible Firmware Interface (UEFI)</code> to access disks. Nearly all disk hardware has firmware that allows the BIOS to access attached storage hardware with <code>Linear Block Addressing (LBA)</code>. Although it exhibits poor performance, this mode of access does allow universal access to disks. Boot loaders are often the only programs to use the BIOS for disk access; the kernel uses its own high-performance drivers.</p>
<p>Most modern boot loaders can read partition tables and have built-in support for read-only access to filesystems. </p>
<h4 id="Boot-loader-tasks"><a href="#Boot-loader-tasks" class="headerlink" title="Boot loader tasks"></a>Boot loader tasks</h4><ol>
<li>Select among multiple kernels.</li>
<li>Switch between sets of kernel parameters.</li>
<li>Allow the user to manually override and edit kernel image names and parameters </li>
<li>Provide support for booting other operating systems.</li>
</ol>
<h4 id="Boot-loader-typres"><a href="#Boot-loader-typres" class="headerlink" title="Boot loader typres"></a>Boot loader typres</h4><ul>
<li>GRUB. A near-universal standard on Linux systems (mainly talks about this)</li>
<li>LILO. One of the first Linux boot loaders.</li>
<li>LOADLIN. Boots a kernel from MS-DOS</li>
</ul>
<h3 id="GRUB-Introduction"><a href="#GRUB-Introduction" class="headerlink" title="GRUB Introduction"></a>GRUB Introduction</h3><p>GRUB stands for Grand Unified Boot Loader. We’ll cover GRUB 2.</p>
<p>This section talks about GRUB menu and look into some boot options, actually, if you check <code>/boot</code> directory, you will see kernel image file and initial RAM filesystem:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">-rwxr-xr-x. 1 root root  6381872 Mar 21  2018 vmlinuz-3.10.0-862.el7.x86_64</span><br><span class="line">-rw-r--r--. 1 root root   304926 Mar 21  2018 symvers-3.10.0-862.el7.x86_64.gz</span><br><span class="line">drwx------. 5 root root       97 Oct  1  2018 grub2</span><br><span class="line">-rw-------  1 root root 21096334 Oct  1  2018 initramfs-3.10.0-862.9.1.el7.x86_64.img</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>Not interested in the rest of the content in this chapter.</p>
<h2 id="Chapter-6-How-User-Space-Starts"><a href="#Chapter-6-How-User-Space-Starts" class="headerlink" title="Chapter 6. How User Space Starts"></a>Chapter 6. How User Space Starts</h2><p>The point where the kernel starts its first user-space process, init, is significant—not just because that’s where the memory and CPU are finally ready for normal system operation, but because that’s where you can see how the rest of the system builds up as a whole. </p>
<p>User space is far more modular. It’s much easier to see what goes into the user space startup and operation.</p>
<p>User space starts in roughly this order:</p>
<ol>
<li>init</li>
<li>Essential low-level services such as udevd and syslogd</li>
<li>Network configuration</li>
<li>Mid- and high-level services (cron, printing, and so on)</li>
<li>Login prompts, GUIs, and other high-level applications</li>
</ol>
<h3 id="Introduction-to-init"><a href="#Introduction-to-init" class="headerlink" title="Introduction to init"></a>Introduction to init</h3><p><a href="https://en.wikipedia.org/wiki/Init" target="_blank" rel="noopener">wiki init</a></p>
<p>The init program is a <strong>user-space program</strong> like any other program on the Linux system, and you’ll find it in <code>/sbin</code> along with many of the other system binaries. Its main purpose is to start and stop the essential service processes on the system, but newer versions have more responsibilities.</p>
<p>In my vm <code>/sbin</code> directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lrwxrwxrwx  1 root root          22 Oct  1  2018 init -&gt; ../lib/systemd/systemd</span><br></pre></td></tr></table></figure></p>
<p>There are three major implementations of init in Linux distributions:</p>
<ul>
<li><code>System V</code> init. A traditional sequenced init (Sys V, usually <em>pronounced “sys-five”</em>). Red Hat Enterprise Linux and several other distributions use this version.</li>
<li><code>systemd</code>. The emerging standard for init. Many distributions have moved to systemd, and most that have not yet done so are planning to move to it.</li>
<li><code>Upstart</code>. The init on Ubuntu installations. However, as of this writing, Ubuntu has also planned to migrate to systemd.</li>
</ul>
<p>There are many different implementations of init because <code>System V</code> init and other older versions relied on a sequence that performed only one startup task at a time. <code>systemd</code> and <code>Upstart</code> attempt to remedy the performance issue by allowing many services to start in parallel thereby speeding up the boot process. </p>
<h3 id="System-V-Runlevels"><a href="#System-V-Runlevels" class="headerlink" title="System V Runlevels"></a>System V Runlevels</h3><p><a href="https://en.wikipedia.org/wiki/Runlevel" target="_blank" rel="noopener">wiki Runlevel</a></p>
<p>At any given time on a Linux system, a certain base set of processes is running. In System V init, this state of the machine is called its <code>runlevel</code>, which is denoted by a number from 0 through 6. A system spends most of its time in a single runlevel, but when you shut the machine down, init switches to a different runlevel in order to terminate the system services in an orderly fashion and to tell the kernel to stop.</p>
<p>You can check your system’s runlevel with the <code>who -r</code> command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">who -r</span><br><span class="line"></span><br><span class="line">run-level 3  2019-04-17 13:49</span><br></pre></td></tr></table></figure></p>
<p>Runlevels serve various purposes, but the most common one is to distinguish between system startup, shutdown, single-user mode, and console mode states.</p>
<p>But runlevels are becoming a thing of the past. Even though all three init versions in this book support them, systemd and Upstart consider runlevels obsolete as end states for the system. </p>
<h3 id="Identifying-Your-init"><a href="#Identifying-Your-init" class="headerlink" title="Identifying Your init"></a>Identifying Your init</h3><ul>
<li><p>If your system has /usr/lib/systemd and /etc/systemd directories, you have systemd.</p>
</li>
<li><p>If you have an /etc/init directory that contains several .conf files, you’re probably running Upstart </p>
</li>
<li><p>If neither of the above is true, but you have an /etc/inittab file, you’re probably running System V init.</p>
</li>
</ul>
<p><strong>Here I focus on systemd</strong></p>
<h3 id="systemd"><a href="#systemd" class="headerlink" title="systemd"></a>systemd</h3><p>The systemd init is one of the newest init implementations on Linux. In addition to handling the regular boot process, systemd aims to incorporate a number of standard Unix services such as cron and inetd. One of its most significant features is its ability to defer the start of services and operating system features until they are necessary.</p>
<p>Let’s outline what happens when systemd runs at boot time:</p>
<ol>
<li>systemd loads its configuration.</li>
<li>systemd determines its boot goal, which is usually named default.target.</li>
<li>systemd determines all of the dependencies of the default boot goal, dependencies of these dependencies, and so on.</li>
<li>systemd activates the dependencies and the boot goal.</li>
<li>After boot, systemd can react to system events (such as uevents) and activate additional components.</li>
</ol>
<h4 id="Units-and-Unit-Types"><a href="#Units-and-Unit-Types" class="headerlink" title="Units and Unit Types"></a>Units and Unit Types</h4><p>One of the most interesting things about <code>systemd</code> is that it does not just operate processes and services; it can also mount filesystems, monitor network sockets, run timers, and more. Each type of capability is called a <code>unit type</code>, and each specific capability is called a <code>unit</code>. When you turn on a unit, you activate it.</p>
<p>The default boot goal is usually a <code>target unit</code> that groups together a number of <code>service</code> and <code>mount</code> units as dependencies. </p>
<p><a href="https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files" target="_blank" rel="noopener">understand systemd unit and unit files</a></p>
<h4 id="systemd-Dependencies"><a href="#systemd-Dependencies" class="headerlink" title="systemd Dependencies"></a>systemd Dependencies</h4><p>To accommodate the need for flexibility and fault tolerance, systemd offers a myriad of dependency types and styles:</p>
<ul>
<li><p><code>Requires</code> Strict dependencies. When activating a unit with a Requires dependency unit, systemd attempts to activate the dependency unit. If the dependency unit fails, systemd deactivates the dependent unit.</p>
</li>
<li><p><code>Wants</code>. Dependencies for activation only. Upon activating a unit, systemd activates the unit’s Wants dependencies, but it doesn’t care if those dependencies fail.</p>
</li>
<li><p><code>Requisite</code>. Units that must already be active.</p>
</li>
<li><p><code>Conflicts</code>. Negative dependencies. When activating a unit with a Conflict dependency, systemd automatically deactivates the dependency if it is active.</p>
</li>
</ul>
<p>There are many other dependency syntax, like ordering, conditional, etc…</p>
<h4 id="systemd-Configuration"><a href="#systemd-Configuration" class="headerlink" title="systemd Configuration"></a>systemd Configuration</h4><p>The systemd configuration files are spread among many directories across the system, so you typically won’t find the files for all of the units on a system in one place.</p>
<p>That said, there are two main directories for systemd configuration: the system unit directory (globally configured, usually <code>/usr/lib/systemd/system</code>) and a system configuration directory (local definitions, usually <code>/etc/systemd/system</code>).</p>
<blockquote>
<p>Note: Avoid making changes to the system unit directory because your distribution will maintain it for you. Make your local changes to the system configuration directory.</p>
</blockquote>
<p>To see the system unit and configuration directories on your system, use the following commands:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pkg-config systemd --variable=systemdsystemunitdir</span><br></pre></td></tr></table></figure></p>
<p>Let’s see Unit files in <code>/usr/lib/systemd/system</code>, there is a sshd.service file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=OpenSSH server daemon</span><br><span class="line">Documentation=man:sshd(8) man:sshd_config(5)</span><br><span class="line">After=network.target sshd-keygen.service</span><br><span class="line">Wants=sshd-keygen.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">EnvironmentFile=/etc/sysconfig/sshd</span><br><span class="line">ExecStart=/usr/sbin/sshd -D $OPTIONS</span><br><span class="line">ExecReload=/bin/kill -HUP $MAINPID</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=42s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure></p>
<p>The [Unit] section gives some details about the unit and contains description and dependency information. </p>
<p>You’ll find the details about the service in the [Service] section, including how to prepare, start, and reload the service. </p>
<p>During normal operation, systemd ignores the [Install] section. However, consider the case when sshd.service is disabled on your system and you would like to turn it on. When you enable a unit, systemd reads the [Install] section.</p>
<p>The [Install] section is usually responsible for the the .wants and .requires directories in the system configuration directory (<code>/etc/systemd/system</code>), see:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">basic.target.wants                                       getty.target.wants           remote-fs.target.wants</span><br><span class="line">default.target                                           local-fs.target.wants        sockets.target.wants</span><br><span class="line">default.target.wants                                     multi-user.target.wants      sysinit.target.wants</span><br><span class="line">dev-virtio\x2dports-org.qemu.guest_agent.0.device.wants  network-online.target.wants  system-update.target.wants</span><br></pre></td></tr></table></figure></p>
<p>the $OPTIONS in unit file is the variable, also specifier is another variable-like feature often found in unit files, like %n and %H.</p>
<h3 id="systemd-Operation"><a href="#systemd-Operation" class="headerlink" title="systemd Operation"></a>systemd Operation</h3><p>You’ll interact with systemd primarily through the <code>systemctl</code> command, which allows you to activate and deactivate services, list status, reload the configuration, and much more.</p>
<p>List of active units:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl</span><br><span class="line"></span><br><span class="line">  UNIT                                           LOAD   ACTIVE SUB       DESCRIPTION</span><br><span class="line">...</span><br><span class="line">  sys-kernel-debug.mount                         loaded active mounted   Debug File System</span><br><span class="line">  var-lib-nfs-rpc_pipefs.mount                   loaded active mounted   RPC Pipe File System</span><br><span class="line">  brandbot.path                                  loaded active waiting   Flexible branding</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>List all units, includes inactives:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl --all</span><br></pre></td></tr></table></figure></p>
<p>Get status of a unit:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl status sshd.service</span><br></pre></td></tr></table></figure></p>
<p>To activate, deactivate, and restart units, use the systemd <code>start</code>, <code>stop</code>, and <code>restart</code> commands. However, if you’ve changed a unit configuration file, you can tell systemd to reload the file in one of two ways:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl reload unit #Reloads just the configuration for unit.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload #Reloads all unit configurations.</span><br></pre></td></tr></table></figure>
<h4 id="systemd-Process-Tracking-and-Synchronization"><a href="#systemd-Process-Tracking-and-Synchronization" class="headerlink" title="systemd Process Tracking and Synchronization"></a>systemd Process Tracking and Synchronization</h4><p>systemd wants a reasonable amount of information and control over every process that it starts. The main problem that it faces is that a service can start in different ways; it may fork new instances of itself or even daemonize and detach itself from the original process.</p>
<p>To minimize the work that a package developer or administrator needs to do in order to create a working unit file, systemd uses <code>control groups (cgroups)</code>, an optional Linux kernel feature that allows for finer tracking of a process hierarchy.</p>
<h4 id="systemd-On-Demand-and-Resource-Parallelized-Startup"><a href="#systemd-On-Demand-and-Resource-Parallelized-Startup" class="headerlink" title="systemd On-Demand and Resource-Parallelized Startup"></a>systemd On-Demand and Resource-Parallelized Startup</h4><p>One of systemd’s most significant features is its ability to delay a unit startup until it is absolutely needed. </p>
<h4 id="systemd-Auxiliary-Programs"><a href="#systemd-Auxiliary-Programs" class="headerlink" title="systemd Auxiliary Programs"></a>systemd Auxiliary Programs</h4><p>When starting out with systemd, you may notice the exceptionally large number of programs in <code>/lib/systemd</code>. These are primarily support programs for units. For example, <code>udevd</code> is part of systemd, and you’ll find it there as <code>systemd-udevd</code>. Another, the <code>systemd-fsck</code> program, works as a middleman between systemd and fsck.</p>
<h3 id="Shutting-Down-Your-System"><a href="#Shutting-Down-Your-System" class="headerlink" title="Shutting Down Your System"></a>Shutting Down Your System</h3><p>init controls how the system shuts down and reboots. The commands to shut down the system are the same regardless of which version of init you run. The proper way to shut down a Linux machine is to use the <code>shutdown</code> command.</p>
<p>to shutdown machine immediately:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">shutdown -h now</span><br></pre></td></tr></table></figure></p>
<p>to reboot the machine now:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">shutdown -r now</span><br></pre></td></tr></table></figure></p>
<p>When system shutdown time finally arrives, shutdown tells init to begin the shutdown process. On systemd, it means activating the shutdown units; and on System V init, it means changing the runlevel to 0 or 6.</p>
<h3 id="The-Initial-RAM-Filesystem"><a href="#The-Initial-RAM-Filesystem" class="headerlink" title="The Initial RAM Filesystem"></a>The Initial RAM Filesystem</h3><p>The <code>initramfs</code> is in <code>/boot</code> directory.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -ltr | grep init</span><br><span class="line"></span><br><span class="line">-rw-------. 1 root root 55376391 Apr 13  2018 initramfs-0-rescue-e57cfe9136e9430587366e04f14195e1.img</span><br><span class="line">-rw-------. 1 root root 13131435 Apr 13  2018 initramfs-3.10.0-862.el7.x86_64kdump.img</span><br><span class="line">-rw-------  1 root root 21098233 Jul 23  2018 initramfs-3.10.0-862.el7.x86_64.img</span><br><span class="line">-rw-------  1 root root 21134858 Oct  1  2018 initramfs-3.10.0-862.14.4.el7.x86_64.img</span><br><span class="line">-rw-------  1 root root 21096334 Oct  1  2018 initramfs-3.10.0-862.9.1.el7.x86_64.img</span><br></pre></td></tr></table></figure></p>
<p>The problem stems from the availability of many different kinds of storage hardware. Remember, the Linux kernel does not talk to the PC BIOS or EFI interfaces to get data from disks, so in order to mount its root file-system, it needs driver support for the underlying storage mechanism.</p>
<p>The workaround is to gather a small collection of kernel driver modules along with a few other utilities into an archive. The boot loader loads this archive into memory before running the kernel.</p>
<h2 id="Chapter-7-System-Configuration"><a href="#Chapter-7-System-Configuration" class="headerlink" title="Chapter 7. System Configuration"></a>Chapter 7. System Configuration</h2><p>When you first look in the <code>/etc</code> directory, you might feel a bit overwhelmed. Although most of the files that you see affect a system’s operations to some extent, a few are fundamental.</p>
<h3 id="The-Structure-of-etc"><a href="#The-Structure-of-etc" class="headerlink" title="The Structure of /etc"></a>The Structure of /etc</h3><p>Most system configuration files on a Linux system are found in <code>/etc</code>. Historically, each program had one or more configuration files there, and because there are so many packages on a Unix system, /etc would accumulate files quickly.</p>
<p>The trend for many years now has been to place system configuration files into subdirectories under <code>/etc</code>. There are still a few individual configuration files in /etc, but for the most part, if you run <code>ls -F /etc</code>, you’ll see that most of the items there are now subdirectories.</p>
<p>What kind of configuration files are found in <code>/etc</code>? The basic guideline is that customizable configurations for a single machine. And you’ll often find that noncustomizable system configuration files may be found elsewhere, as with the prepackaged systemd unit files in <code>/usr/lib/systemd</code>.</p>
<h3 id="System-Logging"><a href="#System-Logging" class="headerlink" title="System Logging"></a>System Logging</h3><p>Most system programs write their diagnostic output to the <code>syslog</code> service. The traditional syslogd daemon waits for messages and, depending on the type of message received, funnels the output to a file, the screen, users, or some combination of these, or just ignores it.</p>
<h4 id="The-System-Logger"><a href="#The-System-Logger" class="headerlink" title="The System Logger"></a>The System Logger</h4><p>Most Linux distributions run a new version of syslogd called <code>rsyslogd</code> that does much more than simply write log messages to files. For example, in my vm:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl status rsyslog</span><br><span class="line"></span><br><span class="line">   rsyslog.service - System Logging Service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/rsyslog.service; enabled; vendor preset: enabled)</span><br><span class="line">   Active: active (running) since Wed 2019-04-17 13:49:14 PDT; 2 weeks 6 days ago</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>Many of the files in <code>/var/log</code> aren’t maintained by the system logger. The only way to know for sure which ones belong to rsyslogd is to look at its configuration file.</p>
<h4 id="Configuration-Files"><a href="#Configuration-Files" class="headerlink" title="Configuration Files"></a>Configuration Files</h4><p>The base rsyslogd configuration file is <code>/etc/rsyslog.conf</code>, but you’ll find certain configurations in other directories, such as <code>/etc/rsyslog.d</code>.</p>
<p>It talks about the syntax in the configuration file:<br>The configuration format is a blend of traditional rules and <code>rsyslog-specific</code> extensions. One rule of thumb is that anything beginning with a dollar sign ($) is an extension.</p>
<h3 id="User-Management-Files"><a href="#User-Management-Files" class="headerlink" title="User Management Files"></a>User Management Files</h3><p>Unix systems allow for multiple independent users. At the kernel level, users are simply numbers (user IDs).</p>
<h4 id="The-etc-passwd-File"><a href="#The-etc-passwd-File" class="headerlink" title="The /etc/passwd File"></a>The /etc/passwd File</h4><p>The plaintext file /etc/passwd maps usernames to user IDs.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root:x:0:0:Superuser:/root:/bin/sh</span><br><span class="line">######</span><br><span class="line">daemon:*:1:1:daemon:/usr/sbin:/bin/sh</span><br><span class="line">#or</span><br><span class="line">daemon:x:2:2:daemon:/sbin:/sbin/nologin</span><br><span class="line">######</span><br><span class="line">bin:*:2:2:bin:/bin:/bin/sh</span><br><span class="line">sys:*:3:3:sys:/dev:/bin/sh</span><br><span class="line">nobody:*:65534:65534:nobody:/home:/bin/false</span><br><span class="line">juser:x:3119:1000:J. Random User:/home/juser:/bin/bash</span><br><span class="line">beazley:x:143:1000:David Beazley:/home/beazley:/bin/bash</span><br></pre></td></tr></table></figure></p>
<p>The fields are as follows:</p>
<ul>
<li><p>The username.</p>
</li>
<li><p>The user’s encrypted password. On most Linux systems, the password is not actually stored in the <code>passwd</code> file, but rather, in the <code>shadow</code> file . Normal users do not have read permission for shadow. The second field in <code>passwd</code> or <code>shadow</code> is the encrypted password, Unix passwords are never stored as clear text.</p>
</li>
<li><p>An <code>x</code> in the second passwd file field indicates that the encrypted password is stored in the <code>shadow</code> file. A <code>*</code> indicates that the user cannot log in, and if the field is blank (that is, you see two colons in a row, like ::), no password is required to log in. (Beware of blank passwords. You should never have a user without a password.)</p>
</li>
<li><p>The user ID (UID), which is the user’s representation in the kernel.</p>
</li>
<li><p>The group ID (GID). This should be one of the numbered entries in the <code>/etc/group</code> file. Groups determine file permissions and little else. This group is also called the user’s <code>primary</code> group.</p>
</li>
<li><p>The user’s real name. You’ll sometimes find commas in this field, denoting room and telephone numbers.</p>
</li>
<li><p>The user’s home directory.</p>
</li>
<li><p>The user’s shell (the program that runs when the user runs a terminal session).</p>
</li>
</ul>
<h4 id="Special-Users"><a href="#Special-Users" class="headerlink" title="Special Users"></a>Special Users</h4><p>The superuser (root) always has UID 0 and GID 0. Some users, such as daemon, have no login privileges. The nobody user is an underprivileged user. Some processes run as nobody because the nobody user cannot write to anything on the system.</p>
<p>The users that cannot log in are called <code>pseudo-users</code>. Although they can’t log in, the system can start processes with their user IDs. Pseudo-users such as nobody are usually created for security reasons.</p>
<h4 id="The-etc-shadow-File"><a href="#The-etc-shadow-File" class="headerlink" title="The /etc/shadow File"></a>The /etc/shadow File</h4><p>The shadow password file <code>/etc/shadow</code> on a Linux system normally contains user authentication information, including the encrypted passwords and password expiration information that correspond to the users in <code>/etc/passwd</code>.</p>
<p>Regular users interact with <code>/etc/passwd</code> using the <code>passwd</code> command. By default, <code>passwd</code> changes the user’s password. The <code>passwd</code> command is an <code>suid-root</code> program, because only the superuser can change the <code>/etc/passwd</code> file.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rwsr-xr-x. 1 root root 27832 Jan 29  2014 /usr/bin/passwd</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>in <code>/etc/shells</code> file have multiple shell types:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; /bin/sh</span><br><span class="line">&gt; /bin/bash</span><br><span class="line">&gt; /sbin/nologin</span><br><span class="line">&gt; /usr/bin/sh</span><br><span class="line">&gt; /usr/bin/bash</span><br><span class="line">&gt; /usr/sbin/nologin</span><br><span class="line">&gt; /bin/ksh</span><br><span class="line">&gt; /bin/rksh</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>Because /etc/passwd is plaintext, the superuser may use any text editor to make changes. To add a user, simply add an appropriate line and create a home directory for the user; to delete, do the opposite. However, to edit the file, you’ll most likely want to use the <code>vipw</code> program</p>
<p>Use <code>adduser</code> and <code>userde</code>l to add and remove users. Run <code>passwd user</code> as the superuser.</p>
<h4 id="Working-with-Groups"><a href="#Working-with-Groups" class="headerlink" title="Working with Groups"></a>Working with Groups</h4><p>Groups in Unix offer a way to <strong>share</strong> files with certain users but deny access to all others. The idea is that you can set read or write permission bits for a particular group, excluding everyone else.</p>
<p>The <code>/etc/group</code> file defines the group IDs:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root:*:0:juser</span><br><span class="line">daemon:*:1:</span><br><span class="line">bin:*:2:</span><br><span class="line">disk:*:6:juser,beazley</span><br><span class="line">nogroup:*:65534:</span><br><span class="line">user:*:1000:</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>The group name.</p>
</li>
<li><p>The group password. This is hardly ever used, nor should you use it. Use * or any other default value.</p>
</li>
<li><p>The group ID (a number). The GID must be unique within the group file. This number goes into a user’s group field in that user’s <code>/etc/passwd</code> entry.</p>
</li>
<li><p>An optional list of users that belong to the group. In addition to the users listed here, users with the corresponding group ID in their passwd file entries also belong to the group.</p>
</li>
</ul>
<blockquote>
<p>Linux distributions often create a new group for each new user added, with the same name as the user.</p>
</blockquote>
<h3 id="Setting-the-Time"><a href="#Setting-the-Time" class="headerlink" title="Setting the Time"></a>Setting the Time</h3><p>Unix machines depend on accurate timekeeping. The kernel maintains the system clock, which is the clock that is consulted when you run commands like date.</p>
<p>PC hardware has a battery-backed <code>real-time clock (RTC)</code>. The RTC isn’t the best clock in the world, but it’s better than nothing. The kernel usually sets its time based on the RTC at boot time, and you can reset the system clock to the current hardware time with <code>hwclock</code>.</p>
<p>You should not try to fix the time drift with <code>hwclock</code> because time-based system events can get lost or mangled. Usually it’s best to keep your system time correct with a network time daemon.</p>
<h4 id="Network-Time"><a href="#Network-Time" class="headerlink" title="Network Time"></a>Network Time</h4><p>If your machine is permanently connected to the Internet, you can run a <code>Network Time Protocol (NTP)</code> daemon to maintain the time using a remote server. Many distributions have built-in support for an NTP daemon, but it may not be enabled by default. You might need to install an ntpd package to get it to work.</p>
<h3 id="Scheduling-Recurring-Tasks-with-cron"><a href="#Scheduling-Recurring-Tasks-with-cron" class="headerlink" title="Scheduling Recurring Tasks with cron"></a>Scheduling Recurring Tasks with cron</h3><p>The Unix cron service runs programs repeatedly on a fixed schedule. Most experienced administrators consider cron to be <strong>vital</strong> to the system because it can perform automatic system maintenance. For example, cron runs log file rotation utilities to ensure that your hard drive doesn’t fill up with old log files. You should know how to use cron because it’s just plain useful.</p>
<blockquote>
<p>Also see <code>cronjob</code> in k8s <a href="https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/" target="_blank" rel="noopener">doc</a>.</p>
</blockquote>
<p>You can run any program with <code>cron</code> at whatever times suit you. The program running through cron is called a <code>cron job</code>. To install a cron job, you’ll create an entry line in your <code>crontab</code> file, usually by running the <code>crontab</code> command.</p>
<p>for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">15 09 * * * /home/juser/bin/spmake</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>Minute (0 through 59). The cron job above is set for minute 15.</p>
</li>
<li><p>Hour (0 through 23). The job above is set for the ninth hour.</p>
</li>
<li><p>Day of month (1 through 31).</p>
</li>
<li><p>Month (1 through 12).</p>
</li>
<li><p>Day of week (0 through 7). The numbers 0 and 7 are Sunday.</p>
</li>
</ul>
<p>A <code>*</code> in any field means to match every value. The preceding example runs spmake daily because the day of month, month, and day of week fields are all filled with stars, which cron reads as “run this job every day, of every month, of every week.”</p>
<p>also can be 5th and the 14th day of each month:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">15 09 5,14 * * /home/juser/bin/spmake</span><br></pre></td></tr></table></figure></p>
<h4 id="Installing-Crontab-Files"><a href="#Installing-Crontab-Files" class="headerlink" title="Installing Crontab Files"></a>Installing Crontab Files</h4><p>Each user can have his or her own crontab file, which means that every system may have multiple crontabs, usually found in <code>/var/spool/cron/</code> folder. the <code>crontab</code> command installs, lists, edits, and removes a user’s crontab.</p>
<p>The easiest way to install a crontab is to put your crontab entries into a file and then use <code>crontab file</code> to install file as your current crontab.</p>
<p>Actually, there is a default place for every user crontab file includes root. Once you create a crontab file for the user, the corresponding folder is put under /var/spool/cron/`.</p>
<p>For example, run as root, I want to set a recurring task for user <code>dsadm</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -u dsadm -e</span><br></pre></td></tr></table></figure></p>
<p>Then edit like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">00 21 * * * /home/dsadm/test.sh &gt; /tmp/cron-log 2&gt;&amp;1</span><br></pre></td></tr></table></figure></p>
<p>after run the job, go to <code>/tmp</code> folder you will see the log file.</p>
<p>to list the <code>dsadm</code> cron job:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -l -u dsadm</span><br></pre></td></tr></table></figure></p>
<p>to remove cron job for <code>dsadm</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -r -u dsadm</span><br></pre></td></tr></table></figure></p>
<h4 id="System-Crontab-Files"><a href="#System-Crontab-Files" class="headerlink" title="System Crontab Files"></a>System Crontab Files</h4><p>Linux distributions normally have an <code>/etc/crontab</code> file. You can also edit here, but the format is a little bit difference:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Example of job definition:</span><br><span class="line"># .---------------- minute (0 - 59)</span><br><span class="line"># |  .------------- hour (0 - 23)</span><br><span class="line"># |  |  .---------- day of month (1 - 31)</span><br><span class="line"># |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...</span><br><span class="line"># |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat</span><br><span class="line"># |  |  |  |  |</span><br><span class="line"># *  *  *  *  * user-name  command to be executed</span><br></pre></td></tr></table></figure></p>
<h3 id="Understanding-User-IDs-and-User-Switching"><a href="#Understanding-User-IDs-and-User-Switching" class="headerlink" title="Understanding User IDs and User Switching"></a>Understanding User IDs and User Switching</h3><p>We’ve discussed how <code>setuid</code> programs such as <code>sudo</code> and <code>su</code> allow you to change users:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---s--x--x 1 root root 143248 May 28  2018 /usr/bin/sudo</span><br><span class="line">-rwsr-xr-x 1 root root 32184 Jul 12  2018 /usr/bin/su</span><br></pre></td></tr></table></figure></p>
<p>In reality, every process has more than one user ID. When you run a setuid program, Linux sets the effective user ID to the program’s owner during execution, but it keeps your original user ID in the real user ID.</p>
<p>Think of the effective user ID as the actor and the real user ID as the owner. The real user ID defines the user that can interact with the running process—most significantly, which user can kill and send signals to a process. For example, if user A starts a new process that runs as user B (based on setuid permissions), user A still owns the process and can kill it.</p>
<p>On normal Linux systems, most processes have the <strong>same</strong> <code>effective user ID</code> and <code>real user ID</code>. I verify this by a test.sh script run as<code>dsadm</code>, the euser and ruser are the same:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rwsr-xr-x 1 root  root        56 May 11 22:17 test.sh</span><br></pre></td></tr></table></figure></p>
<p>By default, <code>ps</code> and other system diagnostic programs show the <code>effective user ID</code>.</p>
<p>In conductor container, I run many su commands, you can see this, the euser and ruser are different:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -eo pid,euser,ruser,comm</span><br><span class="line"></span><br><span class="line">1574 root     dsadm    su</span><br><span class="line">2735 root     dsadm    su</span><br><span class="line">4535 root     dsadm    su</span><br></pre></td></tr></table></figure></p>
<h3 id="PAM"><a href="#PAM" class="headerlink" title="PAM"></a>PAM</h3><p>In 1995 Sun Microsystems proposed a new standard called <code>Pluggable Authentication Modules (PAM)</code>, a system of shared libraries for authentication. To authenticate a user, an application hands the user to PAM to determine whether the user can successfully identify itself. </p>
<p>Because there are many kinds of authentication scenarios, PAM employs a number of dynamically <code>loadable authentication modules</code>. Each module performs a specific task; for example, the <code>pam_unix.so</code> module can check a user’s password.</p>
<h4 id="PAM-Configuration"><a href="#PAM-Configuration" class="headerlink" title="PAM Configuration"></a>PAM Configuration</h4><p>You’ll normally find PAM’s application configuration files in the <code>/etc/pam.d</code> directory (older systems may use a single <code>/etc/pam.conf</code> file). </p>
<p>Let’s see an example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auth       requisite     pam_shells.so</span><br></pre></td></tr></table></figure></p>
<p>Each configuration line has three fields: <code>function type</code>, <code>control argument</code>, and <code>module</code>:</p>
<ul>
<li><p>Function type. The function that a user application asks PAM to perform. Here, it’s <code>auth</code>, the task of authenticating the user.</p>
</li>
<li><p>Control argument. This setting controls what PAM does after success or failure of its action for the current line (<code>requisite</code> in this example).</p>
</li>
<li><p>Module. The authentication module that runs for this line, determining what the line actually does. Here, the <code>pam_shells.so</code> module checks to see whether the user’s current shell is listed in <code>/etc/shells</code>.</p>
</li>
</ul>
<p>PAM configuration is detailed on the pam.conf(5) manual page:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">man 5 pam.conf</span><br></pre></td></tr></table></figure></p>
<h2 id="Chapter-8-A-Closer-Look-at-Processes-and-Resource-Utilization"><a href="#Chapter-8-A-Closer-Look-at-Processes-and-Resource-Utilization" class="headerlink" title="Chapter 8. A Closer Look at Processes and Resource Utilization"></a>Chapter 8. A Closer Look at Processes and Resource Utilization</h2><p>This chapter takes you deeper into the relationships between processes, the kernel, and system resources.</p>
<p>Many of the tools that you see in this chapter are often thought of as performance-monitoring tools. They’re particularly helpful if your system is slowing to a crawl and you’re trying to figure out why.</p>
<h3 id="Tracking-Processes"><a href="#Tracking-Processes" class="headerlink" title="Tracking Processes"></a>Tracking Processes</h3><p>The <code>top</code> program is often more useful than <code>ps</code> because it displays the current system status as well as many of the fields in a <code>ps</code> listing, and it updates the display every second.</p>
<p>You can send commands to <code>top</code> with keystrokes. When you enter <code>top</code> command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Tasks: 382 total,   2 running, 380 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s):  1.2 us,  0.5 sy,  0.0 ni, 96.4 id,  0.4 wa,  0.0 hi,  0.2 si,  1.3 st</span><br><span class="line">KiB Mem :  8009536 total,   441360 free,   930236 used,  6637940 buff/cache</span><br><span class="line">KiB Swap:        0 total,        0 free,        0 used.  6284448 avail Mem</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line">10438 root      20   0  519148 282140  19392 S   4.6  3.5 586:19.28 kube-apiserver</span><br><span class="line">10449 root      20   0  275308  80184  14584 S   4.3  1.0 516:46.86 kube-controller</span><br><span class="line"> 9691 root      20   0 1648968 159104  30708 S   2.6  2.0 492:06.83 kubelet</span><br><span class="line">10206 root      20   0   10.1g  56568   7760 S   2.0  0.7 262:08.45 etcd</span><br><span class="line">19459 root      20   0   82100  53780   9392 S   1.7  0.7 209:35.52 calico-node</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: if you want to see memory in MB, GB… Typing <code>shift + e</code> cycle through.</p>
</blockquote>
<p>then type followings:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Spacebar: Updates the display immediately.</span><br><span class="line">M: Sorts by current resident memory usage.</span><br><span class="line">T: Sorts by total (cumulative) CPU usage.</span><br><span class="line">P: Sorts by current CPU usage (the default).</span><br><span class="line">u: Displays only one user’s processes.</span><br><span class="line">f: Selects different statistics to display. (use arrow to move and space to select)</span><br><span class="line">?: Displays a usage summary for all top commands.</span><br></pre></td></tr></table></figure></p>
<h3 id="Finding-Open-Files-by-lsof"><a href="#Finding-Open-Files-by-lsof" class="headerlink" title="Finding Open Files by lsof"></a>Finding Open Files by lsof</h3><p>One use for this command is when a disk cannot be unmounted because (unspecified) files are in use. The listing of open files can be consulted (suitably filtered if necessary) to identify the process that is using the files.</p>
<p>The <code>lsof</code> command lists open files and the processes using them. <code>lsof</code> doesn’t stop at regular files, it can list network resources, dynamic libraries, pipes, and more.</p>
<p>For example:<br>Display entries for open files in <code>/usr</code> directory and successors.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lsof /usr/*</span><br></pre></td></tr></table></figure></p>
<p>List open files for a particular PID:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lsof -p 1623</span><br></pre></td></tr></table></figure></p>
<h3 id="Tracing-Program-Execution-and-System-Calls"><a href="#Tracing-Program-Execution-and-System-Calls" class="headerlink" title="Tracing Program Execution and System Calls"></a>Tracing Program Execution and System Calls</h3><p>The most common use is to start a program using <code>strace</code>, which prints a list of <code>system calls</code> made by the program. This is useful if the program continually crashes, or does not behave as expected; for example using strace may reveal that the program is attempting to access a file which does not exist or cannot be read.</p>
<p>The <code>strace</code> (system call trace) and <code>ltrace</code> (library trace) commands can help you discover what a program attempts to do. These tools produce extraordinarily large amounts of output, but once you know what to look for, you’ll have more tools at your disposal for tracking down problems.</p>
<p>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">strace cat not_a_file</span><br></pre></td></tr></table></figure></p>
<p>you get errors in <code>open(&quot;not_a_file&quot;, O_RDONLY)</code> line:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">execve(&quot;/usr/bin/cat&quot;, [&quot;cat&quot;, &quot;not_a_file&quot;], [/* 23 vars */]) = 0</span><br><span class="line">brk(NULL)                               = 0x81f000</span><br><span class="line">mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fc85159d000</span><br><span class="line">access(&quot;/etc/ld.so.preload&quot;, R_OK)      = -1 ENOENT (No such file or directory)</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">close(3)                                = 0</span><br><span class="line">fstat(1, &#123;st_mode=S_IFCHR|0620, st_rdev=makedev(136, 0), ...&#125;) = 0</span><br><span class="line">open(&quot;not_a_file&quot;, O_RDONLY)            = -1 ENOENT (No such file or directory)</span><br><span class="line">write(2, &quot;cat: &quot;, 5cat: )                    = 5</span><br><span class="line">write(2, &quot;not_a_file&quot;, 10not_a_file) </span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h3 id="Threads"><a href="#Threads" class="headerlink" title="Threads"></a>Threads</h3><p>In Linux, some processes are divided into pieces called threads.</p>
<p>To display the thread information in <code>ps</code>, add the m option.<br>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps axm -o pid,tid,command</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PID   TID   COMMAND</span><br><span class="line">1891     - db2ckpwd 0</span><br><span class="line">    -  1891 -</span><br><span class="line">1892     - db2ckpwd 0</span><br><span class="line">    -  1892 -</span><br><span class="line">3501     - db2fmp ( ,1,0,0,0,0,0,00000000,0,0,0,0000000000000000,0000000000000000,00000000,00000000,00000000,0000000</span><br><span class="line">    -  3501 -</span><br><span class="line">    -  3502 -</span><br><span class="line">    -  3503 -</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>The main thread ID is the as the process ID</p>
<h3 id="Introduction-to-Resource-Monitoring"><a href="#Introduction-to-Resource-Monitoring" class="headerlink" title="Introduction to Resource Monitoring"></a>Introduction to Resource Monitoring</h3><p>To monitor one or more specific processes over time, use the <code>-p</code> option to <code>top</code>, with this syntax:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">top -p &lt;pid&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="Adjusting-Process-Priorities"><a href="#Adjusting-Process-Priorities" class="headerlink" title="Adjusting Process Priorities"></a>Adjusting Process Priorities</h4><p>You can change the way the kernel <strong>schedules</strong> a process in order to give the process more or less CPU time than other processes. </p>
<p>The kernel runs each process according to its scheduling priority, which is a number between <code>–20</code> and <code>20</code>, with <code>–20</code> being the <strong>foremost</strong> priority.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps axl</span><br><span class="line"></span><br><span class="line">F   UID   PID  PPID PRI  NI    VSZ   RSS WCHAN  STAT TTY        TIME COMMAND</span><br><span class="line">4  1000     1     0  20   0  15120  1596 do_wai Ss   ?          0:00 /bin/bash /opt/IBM/InformationServer/initScripts</span><br><span class="line">4     0  1882     1  20   0 1225076 48936 futex_ Sl  ?          0:00 db2wdog 0 [db2inst1]</span><br><span class="line">4  1000  1884  1882  20   0 10302284 1699292 futex_ Sl ?       58:25 db2sysc 0</span><br><span class="line">5     0  1890  1882  20   0 1227236 18292 do_msg S   ?          0:13 db2ckpwd 0</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">top</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line"> 1884 db2inst1  20   0    9.8g   1.6g   1.6g S   1.3 10.4  58:25.82 db2sysc</span><br><span class="line">    1 db2inst1  20   0   15120   1596   1360 S   0.0  0.0   0:00.01 startcontainer.</span><br><span class="line"> 1882 root      20   0 1225076  48936  33072 S   0.0  0.3   0:00.13 db2syscr</span><br></pre></td></tr></table></figure>
<p><code>PR</code> is the priority value. <code>NI</code> (nice value), high nice value means nicer, more likely to give up CPU time.</p>
<p>Alter the nice value:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">renice &lt;value&gt; &lt;pid&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="Load-Averages"><a href="#Load-Averages" class="headerlink" title="Load Averages"></a>Load Averages</h4><p>The <code>load average</code> is the average number of processes currently ready to run. Keep in mind that most processes on your system are usually waiting for input (from the keyboard, mouse, or network, for example), meaning that most processes are not ready to run and should contribute nothing to the load average. Only processes that are actually doing something affect the load average.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># uptime</span><br><span class="line"></span><br><span class="line">... up 91 days, ... load average: 0.08, 0.03, 0.01</span><br></pre></td></tr></table></figure>
<p>The three numbers are the load averages for the past 1 minute, 5 minutes, and 15 minutes, respectively. An average of only 0.01 processes have been running across all processors for the past 15 minutes. </p>
<p>If a load average goes up to around 1, a single process is probably using the CPU nearly all of the time. To identify that process, use the top command; the process will usually rise to the the top of the display.</p>
<p>If you have two cores, a load average of 1 means that only one of the cores is likely active at any given time, and a load average of 2 means that both cores have just enough to do all of the time.</p>
<p>A high load average does not necessarily mean that your system is having trouble. A system with enough memory and I/O resources can easily handle many running processes. If your load average is high and your system still responds well, don’t panic</p>
<p>However, if you sense that the system is slow and the load average is high, you might be running into memory performance problems. </p>
<h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><p>CPU has a <code>memory management unit (MMU)</code> that translates the virtual memory addresses used by processes into real ones. The kernel assists the MMU by breaking the memory used by processes into smaller chunks called <code>pages</code>.</p>
<p>The kernel maintains a data structure, called a <code>page table</code>, that contains a mapping of a processes’ virtual page addresses to real page addresses in memory. As a process accesses memory, the MMU translates the virtual addresses used by the process into real addresses based on the kernel’s page table.</p>
<p>A user process does not actually need all of its pages to be immediately available in order to run. The kernel generally loads and allocates pages as a process needs them; this system is known as <code>on-demand paging</code> or just <code>demand paging</code>.</p>
<h4 id="Page-Faults"><a href="#Page-Faults" class="headerlink" title="Page Faults"></a>Page Faults</h4><p>If a memory page is not ready when a process wants to use it, the process triggers a <code>page fault</code>.</p>
<ul>
<li><p>MINOR PAGE FAULTS<br>A minor page fault occurs when the desired page is actually in main memory but the MMU doesn’t know where it is. This can happen when the process requests more memory or when the MMU doesn’t have enough space to store all of the page locations for a process. In this case, the kernel tells the MMU about the page and permits the process to continue. Minor page faults aren’t such a big deal, and many occur as a process runs. Unless you need maximum performance from some memory-intensive program, you probably shouldn’t worry about them.</p>
</li>
<li><p>MAJOR PAGE FAULTS<br>A major page fault occurs when the desired memory page isn’t in main memory at all, which means that the <strong>kernel must load it from the disk or some other slow storage mechanism</strong>. Some major page faults are unavoidable, such as those that occur when you load the code from disk when running a program for the first time. </p>
</li>
</ul>
<p>Let’s see the page faults:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># /usr/bin/time netstat &gt; /dev/null</span><br><span class="line"></span><br><span class="line">0.05user 0.02system 0:01.74elapsed 4%CPU (0avgtext+0avgdata 2556maxresident)k</span><br><span class="line">1752inputs+0outputs (3major+781minor)pagefaults 0swaps</span><br></pre></td></tr></table></figure></p>
<p>There are 3 major page faults and 781 minor page faults when running <code>netstat</code> program. The major page faults occurred when the kernel needed to load the program from the disk for the first time. If you ran the command again, you probably wouldn’t get any major page faults because the kernel would have cached the pages from the disk:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># /usr/bin/time netstat &gt; /dev/null</span><br><span class="line"></span><br><span class="line">0.04user 0.02system 0:01.61elapsed 3%CPU (0avgtext+0avgdata 2552maxresident)k</span><br><span class="line">0inputs+0outputs (0major+783minor)pagefaults 0swaps</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>time</code> here is not the shell built-in <code>time</code> command! If you run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; type -a time</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>you will see<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; time is a shell keyword</span><br><span class="line">&gt; time is /usr/bin/time</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>see this <a href="https://www.cyberciti.biz/faq/linux-command-to-see-major-minor-pagefaults/" target="_blank" rel="noopener">doc</a></p>
</blockquote>
<p>If you’d rather see the <strong>number</strong> of page faults of processes as they’re running, use <code>top</code> or <code>ps</code>. When running <code>top</code>, use <code>f</code> to add the displayed fields and space to display the <code>nMaj</code> and <code>nMin</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># top</span><br><span class="line"></span><br><span class="line">  PID USER      %CPU  PR  NI    VIRT    RES    SHR S %MEM     TIME+ COMMAND                                nMaj nMin</span><br><span class="line"> 1303 dsadm      1.7  20   0 4753196  82704  13412 S  0.5 158:31.05 java                                      0  25k</span><br><span class="line"> 1929 dsadm      0.3  20   0  203344   2556   2116 S  0.0   2:16.80 ResTrackApp                               0 1028</span><br></pre></td></tr></table></figure></p>
<p>When using <code>ps</code>, you can use a custom output format to view the page faults for a particular process:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ps -o pid,min_flt,maj_flt 1</span><br><span class="line"></span><br><span class="line">  PID  MINFL  MAJFL</span><br><span class="line">    1   2059      6</span><br></pre></td></tr></table></figure></p>
<h3 id="Monitoring-CPU-and-Memory-Performance"><a href="#Monitoring-CPU-and-Memory-Performance" class="headerlink" title="Monitoring CPU and Memory Performance"></a>Monitoring CPU and Memory Performance</h3><p>Among the many tools available to monitor system performance, the <code>vmstat</code> command is one of the oldest, with minimal overhead. You’ll find it handy for getting a high-level view of how often the kernel is swapping pages in and out, how busy the CPU is, and IO utilization.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vmstat 2</span><br><span class="line"></span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line"> 2  0      0 174452   1064 6874152    0    0    17    55    4    0  2  2 95  0  1</span><br><span class="line"> 2  0      0 173900   1064 6874168    0    0     0    16 10362 12869  5  3 90  0  2</span><br><span class="line"> 3  0      0 173932   1064 6874180    0    0     0   291 9110 10761  2  1 95  1  1</span><br><span class="line"> 0  0      0 174056   1064 6874180    0    0     0    59 9126 12447  3  3 92  0  1</span><br><span class="line"> 0  0      0 174228   1064 6874184    0    0     0   167 7100 9601  1  1 97  0  1</span><br></pre></td></tr></table></figure>
<p>Not easy to understand, can dig deeper into it by reading vmstat(8) manual page. </p>
<h3 id="I-O-Monitoring"><a href="#I-O-Monitoring" class="headerlink" title="I/O Monitoring"></a>I/O Monitoring</h3><p>Like <code>vmstat</code> and <code>netstat</code> (talk later), we have <code>iostat</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iostat 2 -d -p ALL</span><br><span class="line"></span><br><span class="line">Linux 3.10.0-862.14.4.el7.x86_64 (dstest1.fyre.ibm.com)         05/21/2019      _x86_64_        (8 CPU)</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">vda              18.12        87.72       201.61  270042131  620650624</span><br><span class="line">vda1              0.00         0.00         0.00      11165       2270</span><br><span class="line">vda2             13.59        87.71       201.61  270022634  620648353</span><br><span class="line">dm-0             17.99        86.13       201.61  265157850  620648353</span><br><span class="line">dm-1              0.06         1.58         0.00    4860836          0</span><br></pre></td></tr></table></figure></p>
<p>This means update every 2 seconds, show device only and show all partitions.</p>
<p>If you need to dig even deeper to see I/O resources used by individual processes, the <code>iotop</code> tool can help. Using <code>iotop</code> is similar to using top.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iotop</span><br><span class="line"></span><br><span class="line">Total DISK READ:         4.76 K/s | Total DISK WRITE:     333.31 K/s</span><br><span class="line">  TID  PRIO  USER       DISK READ DISK  WRITE  SWAPIN     IO&gt; COMMAND</span><br><span class="line">  260 be/3 root          0.00 B/s  38.09 K/s  0.00 %  6.98 % [jbd2/sda1-8]</span><br><span class="line"> 2611 be/4 juser         4.76 K/s  10.32 K/s  0.00 %  0.21 % zeitgeist-daemon</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure></p>
<p>It shows TID (thread ID) instead of PID, PRIO (priority) indicates the IO priority, <code>be/3</code> is more important than <code>be/4</code>. The kernel uses the <code>scheduling class</code> to add more control for I/O scheduling. You’ll see three scheduling classes from <code>iotop</code>:</p>
<ul>
<li><p><strong>be</strong> Best-effort. The kernel does its best to fairly schedule I/O for this class. Most processes run under this I/O scheduling class.</p>
</li>
<li><p><strong>rt</strong> Real-time. The kernel schedules any real-time I/O before any other class of I/O, no matter what.</p>
</li>
<li><p><strong>idle</strong> Idle. The kernel performs I/O for this class only when there is no other I/O to be done. There is no priority level for the idle scheduling class.</p>
</li>
</ul>
<h3 id="Per-Process-Monitoring"><a href="#Per-Process-Monitoring" class="headerlink" title="Per-Process Monitoring"></a>Per-Process Monitoring</h3><p>The <code>pidstat</code> utility allows you to see the resource consumption of a process over time in the style of <code>vmstat</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># pidstat -p 27946 1</span><br><span class="line"></span><br><span class="line">Linux 3.10.0-862.14.4.el7.x86_64 (myk8s1.fyre.ibm.com)  05/21/2019      _x86_64_        (4 CPU)</span><br><span class="line"></span><br><span class="line">08:16:27 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">08:16:28 PM  1002     27946    0.00    0.00    0.00    0.00     3  tail</span><br><span class="line">08:16:29 PM  1002     27946    0.00    0.00    0.00    0.00     3  tail</span><br><span class="line">08:16:30 PM  1002     27946    0.00    0.00    0.00    0.00     3  tail</span><br></pre></td></tr></table></figure></p>
<p>The <code>CPU</code> column tells you about this process is running on which CPU.</p>
<h2 id="Chapter-9-Network-and-Configuration"><a href="#Chapter-9-Network-and-Configuration" class="headerlink" title="Chapter 9. Network and Configuration"></a>Chapter 9. Network and Configuration</h2><blockquote>
<p>Note that the <code>ifconfig</code> command, as well some of the others you’ll see later in this chapter (such as <code>route</code> and <code>arp</code>), has been technically supplanted with the newer <code>ip</code> command. The ip command can do more than the old commands, and it is preferable when writing scripts. However, most people still use the old commands when manually working with the network, and these commands can also be used on other versions of Unix. For this reason, we’ll use the old-style commands.</p>
</blockquote>
<h3 id="Routes-and-the-Kernel-Routing-Table"><a href="#Routes-and-the-Kernel-Routing-Table" class="headerlink" title="Routes and the Kernel Routing Table"></a>Routes and the Kernel Routing Table</h3><p>Let’s see the routing table by <code>route</code> command, <code>-n</code> means show numerical address instead of hostname:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># route -n</span><br><span class="line"></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         9.30.94.1       0.0.0.0         UG    0      0        0 eth1</span><br><span class="line">9.30.94.0       0.0.0.0         255.255.254.0   U     0      0        0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">172.16.0.0      0.0.0.0         255.255.0.0     U     0      0        0 eth0</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.0.0     0.0.0.0         255.255.255.0   U     0      0        0 *</span><br><span class="line">192.168.0.2     0.0.0.0         255.255.255.255 UH    0      0        0 calib4daf4f1db0</span><br><span class="line">192.168.0.3     0.0.0.0         255.255.255.255 UH    0      0        0 cali987b4d0c33f</span><br><span class="line">192.168.1.0     172.16.182.156  255.255.255.0   UG    0      0        0 eth0</span><br><span class="line">192.168.2.0     172.16.182.187  255.255.255.0   UG    0      0        0 eth0</span><br></pre></td></tr></table></figure></p>
<p>The <code>Destination</code> column tells you a network prefix (outside network), and the <code>Genmask</code> column is the netmask corresponding to that network. Each network has a <code>U</code> under its <code>Flags</code> column, indicating that the route is active (“up”).</p>
<p>There is a <code>G</code> in the <code>Flags</code> column, meaning that communication for this network must be sent through the gateway in the Gateway column, for example, for networl <code>0.0.0.0/0</code> send through it’s gateway <code>9.30.94.1</code>. If no <code>G</code> in <code>Flags</code>, indicating that the network is directly connected in some way.</p>
<p>An entry for <code>0.0.0.0/0</code> in the routing table has special significance because it matches any address on the Internet. This is the default route, and the address configured under the Gateway column (in the <code>route -n</code> output) in the default route is the <code>default gateway</code>.</p>
<h3 id="Basic-ICMP-and-DNS-Tools"><a href="#Basic-ICMP-and-DNS-Tools" class="headerlink" title="Basic ICMP and DNS Tools"></a>Basic ICMP and DNS Tools</h3><h4 id="ping"><a href="#ping" class="headerlink" title="ping"></a>ping</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ping baidu.com</span><br><span class="line"></span><br><span class="line">PING baidu.com (123.125.114.144) 56(84) bytes of data.</span><br><span class="line">64 bytes from 123.125.114.144 (123.125.114.144): icmp_seq=1 ttl=40 time=212 ms</span><br><span class="line">64 bytes from 123.125.114.144 (123.125.114.144): icmp_seq=2 ttl=40 time=212 ms</span><br><span class="line">64 bytes from 123.125.114.144 (123.125.114.144): icmp_seq=3 ttl=40 time=212 ms</span><br><span class="line">^C</span><br><span class="line">--- baidu.com ping statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 2002ms</span><br><span class="line">rtt min/avg/max/mdev = 212.335/212.495/212.578/0.393 ms</span><br></pre></td></tr></table></figure>
<p><code>56(84) bytes of data</code> means send a 56 bytes packet (84 bytes when include header).<br><code>icmp_seq</code> is sequence number, sometimes you will have gap, usually means there’s some kind of connectivity problem.<br><code>time</code> is round-trip time.</p>
<h4 id="traceroute"><a href="#traceroute" class="headerlink" title="traceroute"></a>traceroute</h4><p>One of the best things about <code>traceroute</code> is that it reports return trip times at each step in the route:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## -n will not do hostname lookup for IP in output</span><br><span class="line"># traceroute -n google.com</span><br><span class="line"></span><br><span class="line">traceroute to google.com (172.217.1.206), 30 hops max, 60 byte packets</span><br><span class="line"> 1  9.30.94.3  0.626 ms  0.742 ms  0.845 ms</span><br><span class="line"> 2  9.30.156.13  0.529 ms  0.801 ms  0.918 ms</span><br><span class="line"> 3  9.55.129.109  0.668 ms  0.852 ms 9.55.129.105  0.515 ms</span><br><span class="line"> 4  9.55.187.13  0.476 ms  0.255 ms  0.425 ms</span><br><span class="line"> 5  9.55.128.6  0.326 ms  0.433 ms  0.294 ms</span><br><span class="line"> 6  9.64.38.194  0.941 ms  0.898 ms  0.843 ms</span><br><span class="line"> 7  9.64.3.86  18.220 ms  18.230 ms  18.229 ms</span><br><span class="line"> 8  9.64.3.85  31.521 ms  31.527 ms  31.563 ms</span><br><span class="line"> 9  9.17.3.35  31.803 ms  31.613 ms  31.875 ms</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure></p>
<h4 id="DNS-and-host"><a href="#DNS-and-host" class="headerlink" title="DNS and host"></a>DNS and host</h4><p>To find the IP address behind a domain name, use the <code>host</code> command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># host www.google.com</span><br><span class="line"></span><br><span class="line">www.google.com has address 172.217.11.228</span><br><span class="line">www.google.com has IPv6 address 2607:f8b0:400f:801::2004</span><br></pre></td></tr></table></figure></p>
<p>You can also use <code>host</code> in reverse: Enter an IP address instead of a hostname to try to discover the hostname behind the IP address. But don’t expect this to work reliably. Many hostnames can represent a single IP address, and DNS doesn’t know how to determine which hostname should correspond to an IP address. </p>
<h3 id="Kernel-Network-Interfaces"><a href="#Kernel-Network-Interfaces" class="headerlink" title="Kernel Network Interfaces"></a>Kernel Network Interfaces</h3><p>Network interfaces have names that usually indicate the kind of hardware underneath, such as <code>eth0</code> (the first Ethernet card in the computer) and <code>wlan0</code> (a wireless interface).</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 9.30.94.85  netmask 255.255.254.0  broadcast 9.30.95.255</span><br><span class="line">        ether 00:20:09:1e:5e:55  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 17164860  bytes 9046289828 (8.4 GiB)</span><br><span class="line">        RX errors 0  dropped 6  overruns 0  frame 0</span><br><span class="line">        TX packets 11669220  bytes 9566003426 (8.9 GiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure>
<p><code>UP,RUNNING</code> means this interface is active.</p>
<h3 id="Resolving-Hostnames"><a href="#Resolving-Hostnames" class="headerlink" title="Resolving Hostnames"></a>Resolving Hostnames</h3><p>On most systems, you can <strong>override</strong> hostname lookups with the <code>/etc/hosts</code> file.<br>Usually resolution will first check this file before resort to DNS server.</p>
<p>The traditional configuration file for DNS servers is <code>/etc/resolv.conf</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## this is the search pattern:</span><br><span class="line">search fyre.ibm.com. svl.ibm.com.</span><br><span class="line">nameserver 172.16.200.52</span><br><span class="line">nameserver 172.16.200.50</span><br></pre></td></tr></table></figure></p>
<p><code>172.16.200.52</code> and <code>172.16.200.50</code> are the DNS server IP.</p>
<h3 id="netstat-command"><a href="#netstat-command" class="headerlink" title="netstat command"></a>netstat command</h3><p>This <code>netstat</code> command is extremely important and common in use. Ususally I use <code>netstat -tunlp</code>, let’s dig deeper into it:</p>
<ul>
<li><code>-t</code>: show TCP connection.</li>
<li><code>-u</code>: show UDP connection.</li>
<li><code>-n</code>: show numerical addresses.</li>
<li><code>-l</code>: show only listening sockets.</li>
<li><code>-p</code>: show PID belongs to.</li>
</ul>
<p>Instead of <code>ifconfig</code> to see the interface, you can use:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># netstat -i</span><br><span class="line"></span><br><span class="line">Kernel Interface table</span><br><span class="line">Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg</span><br><span class="line">cali9550  1440 60880456      0      6 0      37444050      0      0      0 BMRU</span><br><span class="line">cali986f  1440        0      0      0 0             0      0      0      0 BMRU</span><br><span class="line">docker0   1500        0      0      0 0             0      0      0      0 BMU</span><br><span class="line">eth0      1500 5606028968      0      0 0      33647018      0      0      0 BMRU</span><br><span class="line">eth1      1500 60880456      0      6 0      37444050      0      0      0 BMRU</span><br><span class="line">lo       65536 431426103      0      0 0      431426103      0      0      0 LRU</span><br></pre></td></tr></table></figure></p>
<p>Instead of <code>route -n</code> to see route table, you can use:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># netstat -rn</span><br></pre></td></tr></table></figure></p>
<p>Show TCP connections (not include listening sockets):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># netstat -tn</span><br></pre></td></tr></table></figure></p>
<p>To see well-known ports translate into names. check <code>/etc/services</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">http            80/tcp          www www-http    # WorldWideWeb HTTP</span><br><span class="line">http            80/udp          www www-http    # HyperText Transfer Protocol</span><br><span class="line">http            80/sctp                         # HyperText Transfer Protoco</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>On Linux, only processes running as the superuser can use ports 1 through 1023. All user processes may listen on and create connections from ports 1024 and up.</p>
<p><strong>I skip the rest of this chapter, majority is concept</strong></p>
<h2 id="Chapter-10-Network-Applications-and-Services"><a href="#Chapter-10-Network-Applications-and-Services" class="headerlink" title="Chapter 10. Network Applications and Services"></a>Chapter 10. Network Applications and Services</h2><p>Let’s mainly focus on some important commands here:</p>
<h3 id="curl-command"><a href="#curl-command" class="headerlink" title="curl command"></a>curl command</h3><p><code>curl</code> is a command line tool to transfer data to or from a server, using any of the supported protocols (HTTP, FTP, IMAP, POP3, SCP, SFTP, SMTP, TFTP, TELNET, LDAP or FILE). <code>curl</code> is powered by <code>Libcurl</code>. This tool is preferred for automation, since it is designed to work without user interaction. curl can transfer multiple file at once.</p>
<p>you can refer this <a href="https://www.geeksforgeeks.org/curl-command-in-linux-with-examples/" target="_blank" rel="noopener">article</a>.</p>
<h3 id="Diagnostic-Tools"><a href="#Diagnostic-Tools" class="headerlink" title="Diagnostic Tools"></a>Diagnostic Tools</h3><p><code>lsof</code>(list open files) can track open files, but it can also list the programs currently using or listening to ports. Please read more when you need this tool.</p>
<p><code>tcpdump</code>, a command tool version of wireshark.</p>
<p><code>netcat</code>(or <code>nc</code>) I used it before for developing PXEngine, we use TCP to replace ssh connection between conductor and compute containers. <code>netcat</code> can connect to remote TCP/UDP ports, specify a local port, listen on ports, scan ports, redirect standard I/O to and from network connections, and more.</p>
<p>I remember I use <code>nc</code> to listen on a port and on other side connect to that port and transfer data.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install</span></span><br><span class="line">yum install -y nc</span><br><span class="line">apt install -y netcat</span><br><span class="line"></span><br><span class="line"><span class="comment">## -l: listening mode</span></span><br><span class="line"><span class="comment">## -p: port</span></span><br><span class="line">nc -l -p 1234</span><br><span class="line"><span class="comment">## client</span></span><br><span class="line">nc localhost 1234</span><br></pre></td></tr></table></figure></p>
<p><code>netcat</code> can be used for TCP, UDP, Unix-domain sockets.</p>
<p><code>nmap</code> scans all ports on a machine or network of machines looking for open ports, and it lists the ports it finds.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># nmap myk8s1.fyre.ibm.com</span><br><span class="line"></span><br><span class="line">Starting Nmap 6.40 ( http://nmap.org ) at 2019-05-22 23:33 PDT</span><br><span class="line">Nmap scan report for myk8s1.fyre.ibm.com (9.30.94.85)</span><br><span class="line">Host is up (0.00024s latency).</span><br><span class="line">Not shown: 995 closed ports</span><br><span class="line">PORT     STATE SERVICE</span><br><span class="line">22/tcp   open  ssh</span><br><span class="line">111/tcp  open  rpcbind</span><br><span class="line">179/tcp  open  bgp</span><br><span class="line">2049/tcp open  nfs</span><br><span class="line">5000/tcp open  upnp</span><br><span class="line"></span><br><span class="line">Nmap done: 1 IP address (1 host up) scanned in 0.20 seconds</span><br></pre></td></tr></table></figure></p>
<h2 id="Chapter-11-Introduction-to-Shell-Scripts"><a href="#Chapter-11-Introduction-to-Shell-Scripts" class="headerlink" title="Chapter 11. Introduction to Shell Scripts"></a>Chapter 11. Introduction to Shell Scripts</h2><p>A shell script is a series of commands written in a file.<br>The <code>#!</code> part is called a <code>shebang</code>.</p>
<p>When writing scripts and working on the command line, just remember what happens whenever the shell runs a command:</p>
<ol>
<li>Before running the command, the shell looks for variables, globs, and other substitutions and performs the substitutions if they appear.</li>
<li>The shell passes the results of the substitutions to the command.</li>
</ol>
<p>if you use single quote:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep &apos;r.*t&apos; /etc/passwd</span><br></pre></td></tr></table></figure></p>
<p>This will prevent sheel from expanding the <code>*</code> in current directory.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep &apos;r.*t /etc/passwd&apos;</span><br></pre></td></tr></table></figure></p>
<p>This will fail, because things wrapped by single/double quote treat as one parameter.</p>
<p>Double quotes (“) work just like single quotes, except that the shell expands <strong>variables</strong> that appear within double quotes. It will not expand globs like <code>*</code> in double quotes!</p>
<p>Just like I saw, use <code>shift</code> to forward arguments passed in:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">echo $1</span><br><span class="line">shift</span><br><span class="line">echo $1</span><br></pre></td></tr></table></figure></p>
<p><code>$#</code> is the number of arguments passed in, used in loop to pick up parameters.<br><code>$@</code> represents all of the script arguments.<br><code>$$</code> holds the PID of current shell.</p>
<p>bad message should go to standard error, just like redriect standard error to standard output:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo $0: bad option ... 1&gt;&amp;2</span><br></pre></td></tr></table></figure></p>
<p><code>$?</code> exit code: If you intend to use the exit code of a command, you <strong>must</strong> use or store the code immediately after running the command. </p>
<h3 id="if-condition"><a href="#if-condition" class="headerlink" title="if condition"></a>if condition</h3><p>Let’s see an example, these 2 are good:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if [ &quot;$1&quot; = hi ]; then</span><br><span class="line">if [ x&quot;$1&quot; = x&quot;hi&quot; ]; then</span><br></pre></td></tr></table></figure></p>
<p>Here, <code>&quot;&quot;</code> is vital, since user may not input <code>$1</code>, if no double quotes, it could be:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if [ = hi ]; then</span><br></pre></td></tr></table></figure></p>
<p>the test (<code>[</code>) command aborts immediately.</p>
<blockquote>
<p>Note that the stuff follows <code>if</code> is a command! so we have <code>;</code> before <code>then</code>.</p>
</blockquote>
<p>So you can use other commands instead of <code>[</code> command, cool!<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">if grep -q daemon /etc/passwd; then</span><br><span class="line">    echo The daemon user is in the passwd file.</span><br><span class="line">else</span><br><span class="line">    echo There is a big problem. daemon is not in the passwd file.</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></p>
<p>Let’s see <code>&amp;&amp;</code> and <code>||</code> and test condition:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">if [ &quot;$1&quot; = hi ] || [ &quot;$1&quot; = bye ]; then</span><br><span class="line">    echo &apos;The first argument was &quot;&apos;$1&apos;&quot;&apos;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></p>
<p>The <code>-a</code> and <code>-o</code> flags are the logical <code>and</code> and <code>or</code> operators in test:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ &quot;$1&quot; = hi -o &quot;$1&quot; = ho ]</span><br></pre></td></tr></table></figure></p>
<h3 id="test-command"><a href="#test-command" class="headerlink" title="test command"></a>test command</h3><p>There are dozens of test operations, all of which fall into three general categories: file tests, string tests, and arithmetic tests.</p>
<h4 id="file-filter"><a href="#file-filter" class="headerlink" title="file filter"></a>file filter</h4><p><code>-f</code>: regular file return 0<br><code>-e</code>: file exist return 0<br><code>-s</code>: not empty file return 0<br><code>-d</code>: directory return 0<br><code>-h</code>: softlink return 0</p>
<p>File permission:<br><code>-r</code>: readable<br><code>-w</code>: writable<br><code>-x</code>: executable<br><code>-u</code>: setuid<br><code>-g</code>: setgid<br><code>-k</code>: sticky</p>
<blockquote>
<p>The test command follows symbolic links (except for the <code>-h</code> test). That is, if link is a symbolic link to a regular file, [ <code>-f</code> link ] returns an exit code of true (0).</p>
</blockquote>
<p>Finally, three binary operators (tests that need two files as arguments) are used in file tests, but they’re not terribly common.<br><code>[ file1 -nt file2 ]</code>: if file1 has a newer modification date than file2 return 0<br><code>[ file1 -ot file2 ]</code>: if file1 has a older modification date than file2 return 0<br><code>[ file1 -ef file2 ]</code>: compares two files and returns true if they share inode numbers and devices.</p>
<h4 id="string-test"><a href="#string-test" class="headerlink" title="string test"></a>string test</h4><p><code>=</code>: equal<br><code>!=</code>: not equal<br><code>-z</code>: empty string return 0<br><code>-n</code>: not empty return 0</p>
<h4 id="arithmetic-test"><a href="#arithmetic-test" class="headerlink" title="arithmetic test"></a>arithmetic test</h4><p><code>-eq</code>: equal to<br><code>-ne</code>: not equal to<br><code>-lt</code>: less than<br><code>-gt</code>: greater than<br><code>-le</code>: less than or equal to<br><code>-ge</code>: greater than or equal to</p>
<h3 id="case-condition"><a href="#case-condition" class="headerlink" title="case condition"></a>case condition</h3><p>The case keyword forms another conditional construct that is exceptionally useful for matching strings, it can do pattern matching:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">case $1 in</span><br><span class="line">    bye)</span><br><span class="line">        echo Fine, bye.</span><br><span class="line">        ;;</span><br><span class="line">    hi|hello)</span><br><span class="line">        echo Nice to see you.</span><br><span class="line">        ;;</span><br><span class="line">    what*)</span><br><span class="line">        echo Whatever.</span><br><span class="line">        ;;</span><br><span class="line">    *)</span><br><span class="line">        echo &apos;Huh?&apos;</span><br><span class="line">        ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Each case must end with a double semicolon (;;) or you risk a syntax error.</p>
</blockquote>
<h3 id="loop"><a href="#loop" class="headerlink" title="loop"></a>loop</h3><p>for loop:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">for str in one two three four; do</span><br><span class="line">    echo $str</span><br><span class="line">done</span><br></pre></td></tr></table></figure></p>
<p>while loop:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">FILE=/tmp/whiletest.$$;</span><br><span class="line">echo firstline &gt; $FILE</span><br><span class="line">while tail -10 $FILE | grep -q firstline; do</span><br><span class="line">    # add lines to $FILE until tail -10 $FILE no longer prints &quot;firstline&quot;</span><br><span class="line">    echo -n Number of lines in $FILE:&apos; &apos;</span><br><span class="line">    wc -l $FILE | awk &apos;&#123;print $1&#125;&apos;</span><br><span class="line">    echo newline &gt;&gt; $FILE</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">rm -f $FILE</span><br></pre></td></tr></table></figure></p>
<p>In fact, if you find that you need to use while, you should probably be using a language like awk or Python instead.</p>
<h3 id="Command-Substitution"><a href="#Command-Substitution" class="headerlink" title="Command Substitution"></a>Command Substitution</h3><p>You can use a command’s output as an argument to another command, or you can store the command output in a shell variable by enclosing a command in <code>$()</code>.</p>
<h3 id="Temporary-File-Management"><a href="#Temporary-File-Management" class="headerlink" title="Temporary File Management"></a>Temporary File Management</h3><p>Note the <code>mktemp</code> command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">TMPFILE1=$(mktemp /tmp/im1.XXXXXX)</span><br><span class="line">TMPFILE2=$(mktemp /tmp/im2.XXXXXX)</span><br><span class="line"></span><br><span class="line">cat /proc/interrupts &gt; $TMPFILE1</span><br><span class="line">sleep 2</span><br><span class="line">cat /proc/interrupts &gt; $TMPFILE2</span><br><span class="line">diff $TMPFILE1 $TMPFILE2</span><br><span class="line">rm -f $TMPFILE1 $TMPFILE2</span><br></pre></td></tr></table></figure></p>
<p>If the script is aborted, the temporary files could be left behind. In the preceding example, pressing <code>CTRL-C</code> before the second cat command leaves a temporary file in <code>/tmp</code>. Avoid this if possible. Instead, use the <code>trap</code> command to create a signal handler to catch the signal that <code>CTRL-C</code> generates and remove the temporary files, as in this handler:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">TMPFILE1=$(mktemp /tmp/im1.XXXXXX)</span><br><span class="line">TMPFILE2=$(mktemp /tmp/im2.XXXXXX)</span><br><span class="line">trap &quot;rm -f $TMPFILE1 $TMPFILE2; exit 1&quot; INT</span><br></pre></td></tr></table></figure></p>
<p>You must use exit in the handler to explicitly end script execution, or the shell will continue running as usual after running the signal handler.</p>
<blockquote>
<p>Note that in <code>startcontainer.sh</code> we also have trap and we use shell function there, now I understand!</p>
</blockquote>
<h3 id="Important-Shell-Script-Utilities"><a href="#Important-Shell-Script-Utilities" class="headerlink" title="Important Shell Script Utilities"></a>Important Shell Script Utilities</h3><h4 id="basename"><a href="#basename" class="headerlink" title="basename"></a>basename</h4><p>This one strip the extension of file name:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># basename example.html .html</span><br><span class="line"></span><br><span class="line">example</span><br></pre></td></tr></table></figure></p>
<p>This one git rid of directory in full path:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># basename /usr/local/bin/example</span><br><span class="line"></span><br><span class="line">example</span><br></pre></td></tr></table></figure></p>
<h4 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h4><p>The <code>awk</code> command is not a simple single-purpose command; it’s actually a powerful programming language. Unfortunately, awk usage is now something of a lost art, having been replaced by larger languages such as Python.</p>
<h4 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h4><p>The sed program (sed stands for stream editor) is an automatic <strong>text editor</strong> that takes an input stream (a file or the standard input), alters it according to some expression, and prints the results to standard output.</p>
<h4 id="xargs"><a href="#xargs" class="headerlink" title="xargs"></a>xargs</h4><p>When you have to run one command on a huge number of files, the command or shell may respond that it can’t fit all of the arguments in its buffer.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># find . -name &apos;*.gif&apos; -print0 | xargs -0 file</span><br></pre></td></tr></table></figure></p>
<p>xargs starts a lot of processes, so don’t expect great performance if you have a large list of files.</p>
<p>There’s an alternative to <code>xargs</code> when using <code>find</code>: the <code>-exec</code> option. However, the syntax is somewhat tricky because you need to supply a <code>{}</code> to substitute the filename and a literal <code>;</code> to indicate the end of the command.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -name &apos;*.gif&apos; -exec file &#123;&#125; \;</span><br></pre></td></tr></table></figure></p>
<h4 id="expr"><a href="#expr" class="headerlink" title="expr"></a>expr</h4><p>The <code>expr</code> command is a clumsy, slow way of doing math. If you find yourself using it frequently, you should probably be using a language like Python instead of a shell script.</p>
<h3 id="Subshells"><a href="#Subshells" class="headerlink" title="Subshells"></a>Subshells</h3><p>An entirely <strong>new</strong> shell process that you can create just to run a command or two. The new shell has a <strong>copy</strong> of the original shell’s environment, and when the new shell exits, any changes you made to its shell environment disappear, leaving the initial shell to run as normal.</p>
<p>Using a subshell to make a single-use alteration to an environment variable is such a common task:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># (PATH=/usr/confusing:$PATH; ./runprogram.sh)</span><br></pre></td></tr></table></figure></p>
<h2 id="Chapter-12-Moving-Files-Across-the-Network"><a href="#Chapter-12-Moving-Files-Across-the-Network" class="headerlink" title="Chapter 12. Moving Files Across the Network"></a>Chapter 12. Moving Files Across the Network</h2><h3 id="Quick-copy-browser"><a href="#Quick-copy-browser" class="headerlink" title="Quick copy browser"></a>Quick copy browser</h3><p>Go to target directory run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python -m SimpleHTTPServer</span><br></pre></td></tr></table></figure></p>
<p>This usually open 8000 port on your machine, then go to another machine open:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># use ifconfig to check the source machine IP</span><br><span class="line">192.168.1.29:8000</span><br></pre></td></tr></table></figure></p>
<p>you can see the content there.</p>
<h3 id="rsync"><a href="#rsync" class="headerlink" title="rsync"></a>rsync</h3><p>Actually you can first enable Mac ssh access then use <code>rsync</code> to backup files:<br>System Preference -&gt; Sharing -&gt; check remote login</p>
<p>To get <code>rsync</code> working between two hosts, the rsync program must be installed on both the source and destination, and you’ll need a way to access one machine from the other.</p>
<p>Copy files to remote home:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync files remote:</span><br><span class="line">rsync files user@remote:</span><br></pre></td></tr></table></figure></p>
<p>If <code>rsync</code> isn’t in the remote path but is on the system, use <code>--rsync-path=path</code> to manually specify its location.</p>
<p>Unless you supply extra options, <code>rsync</code> copies only files. You will see:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skipping directory xxx</span><br></pre></td></tr></table></figure></p>
<p>To transfer entire directory hierarchies, complete with symbolic links, permissions, modes, and devices—use the <code>-a</code> option.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -nv files -a dir user@remote:</span><br></pre></td></tr></table></figure></p>
<p><code>-n</code>: dry-run, this is vital when you are not sure.<br><code>-vv</code>: verbose mode</p>
<p>To make an exact replica of the source directory, you must delete files in the destination directory that do not exist in the source directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -v --delete -a dir user@remote:</span><br></pre></td></tr></table></figure></p>
<p>Please use <code>-n</code> dry-run to see what will be deleted before performing command.</p>
<p>Be particular careful with tailing slash after dir:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -a dir/ user@remote:dest</span><br></pre></td></tr></table></figure></p>
<p>This will copy all files under dir to dest folder in remote instead of copy dir into dest.</p>
<p>You can also <code>--exclude=</code>, <code>--exclude-from=</code> and <code>--include=</code> in command.</p>
<p>To speed operation, <code>rsync</code> uses a quick check to determine whether any files on the transfer source are already on the destination. The quick check uses a combination of the file size and its last-modified date. </p>
<p>When the files on the source side are not identical to the files on the destination side, <code>rsync</code> transfers the source files and overwrites any files that exist on the remote side. The default behavior may be inadequate, though, because you may need additional reassurance that files are indeed the same before skipping over them in transfers, or you may want to put in some extra safeguards.</p>
<ul>
<li><p><code>--checksum</code>(abbreviation: <code>-c</code>) Compute checksums (mostly unique signatures) of the files to see if they’re the same. This consumes additional I/O and CPU resources during transfers, but if you’re dealing with sensitive data or files that often have uniform sizes, this option is a must. (This will focus on file content, not date stamp)</p>
</li>
<li><p><code>--ignore-existing</code> Doesn’t clobber files already on the target side.</p>
</li>
<li><p><code>--backup</code> (abbreviation: <code>-b</code>) Doesn’t clobber files already on the target but rather renames these existing files by adding a <code>~</code> suffix to their names before transferring the new files.</p>
</li>
<li><p><code>--suffix=s</code> Changes the suffix used with –backup from <code>~</code> to <code>s</code>.</p>
</li>
<li><p><code>--update</code> (abbreviation: <code>-u</code>) Doesn’t clobber any file on the target that has a later date than the corresponding file on the source.</p>
</li>
</ul>
<p>You can also compress the dir when transfer:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -az dir user@remote:</span><br></pre></td></tr></table></figure></p>
<p>You can also reverse the process:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -a user@remote:dir dest</span><br></pre></td></tr></table></figure></p>
<p>The rest of this chapter talks <code>samba</code> for file sharing, I skip it.</p>
<h2 id="Chapter-13-User-Environments"><a href="#Chapter-13-User-Environments" class="headerlink" title="Chapter 13. User Environments"></a>Chapter 13. User Environments</h2><p>Startup files play an important role at this point, because they set defaults for the shell and other interactive programs. They determine how the system behaves when a user logs in.</p>
<p>I see vi theme config in <code>~/.bashrc</code> file.</p>
<h3 id="The-Command-Path"><a href="#The-Command-Path" class="headerlink" title="The Command Path"></a>The Command Path</h3><p>The most important part of any shell startup file is the command path. The path should cover the directories that contain every application of interest to a regular user. At the very least, the path should contain these components, in order:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/usr/local/bin</span><br><span class="line">/usr/bin</span><br><span class="line">/bin</span><br></pre></td></tr></table></figure></p>
<p>If the application is on another directory, use symbolic link to <code>/usr/local/bin</code> or you defined <code>bin</code> folder.</p>
<h3 id="The-prompt"><a href="#The-prompt" class="headerlink" title="The prompt"></a>The prompt</h3><p>I never use this so far, usually prompt shows hostname, username, current directory and sign (<code>$</code> or <code>#</code>). you can change the color and more.</p>
<h3 id="Alias"><a href="#Alias" class="headerlink" title="Alias"></a>Alias</h3><p>This is common use, sometimes I use shell functions too.</p>
<h3 id="Permission-mask"><a href="#Permission-mask" class="headerlink" title="Permission mask"></a>Permission mask</h3><p>It depends on your needs:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">umask 022/077</span><br></pre></td></tr></table></figure></p>
<h3 id="Startup-file-order"><a href="#Startup-file-order" class="headerlink" title="Startup file order"></a>Startup file order</h3><p>These startup files are used to create <strong>environment</strong>. Each script has a specific use and affects the login environment differently. Every subsequent script executed can override the values assigned by previous scripts.</p>
<p>The two main shell <code>instance types</code> are <code>interactive</code> and <code>noninteractive</code>, but of those, only interactive shells are of interest because noninteractive shells (such as those that run shell scripts) usually don’t read any startup files. </p>
<p>Interactive shells are the ones that you use to <strong>run commands from a terminal</strong>, they can be classified as <code>login</code> or <code>non-login</code>.</p>
<p>I know there are lots of startup files under each user’s home directory or in other system folder, how do they take effect? In what order:<br><strong>Reference Doc</strong><br><a href="http://howtolamp.com/articles/difference-between-login-and-non-login-shell/" target="_blank" rel="noopener">Difference between Login shell and Non login shell</a></p>
<p>Logging in remotely with <code>SSH</code> also gives you a login shell. </p>
<p>You can tell if a shell is a login shell by running <code>echo $0</code>; if the first character is a <code>-</code>, the shell’s a login shell.</p>
<p>When Bash is invoked as a <code>Login</code> shell:</p>
<ol>
<li>Login process calls <code>/etc/profile</code></li>
<li><code>/etc/profile</code> calls the scripts in <code>/etc/profile.d/</code></li>
<li>Login process calls <code>~/.bash_profile</code>, <code>~/.bash_login</code> and <code>~/.profile</code>. running only the first one that it sees.</li>
</ol>
<p>Login Shells created by explicitly telling to login.<br>examples: <code># su - | # su -l | # su --login | # su USERNAME - | # su -l USERNAME | # su --login USERNAME | # sudo -i</code></p>
<p>When bash is invoked as a <code>Non-login</code> shell;</p>
<ol>
<li>Non-login process(shell) calls <code>/etc/bashrc</code></li>
<li>then calls <code>~/.bashrc</code></li>
</ol>
<p><code>Non-Login</code> shells created using the below command syntax:<br>examples: <code># su | # su USERNAME</code></p>
<p>Note that I can run <code>bash</code> or <code>sh</code> or <code>csh</code> in terminal, it will give me a new simple prompt without user profile or setting…</p>
<p>It seems if you use non-login like <code>su dsadm</code>, the export env vars are still there in <code>env</code> scope, I think the reason is it’s not login! still use current environment. But if you run <code>su - dsadm</code>, it is gone.</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
