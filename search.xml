<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Ansible Quick Test</title>
    <url>/2020/01/24/ansible-quick-test/</url>
    <content><![CDATA[<p>This is a ansible quick setup to help me test and understand module functionality.<br>Download from my github project <a href="https://github.com/chengdol/ansible-test" target="_blank" rel="noopener">ansible-test</a>.</p>
<p>TODO:<br>Use Vagrant to provision virtual machine cluster.</p>
]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Awesome Resources</title>
    <url>/2019/03/09/awesome-resource/</url>
    <content><![CDATA[<p>List of some awesome resources for learning:</p>
<ul>
<li><a href="https://github.com/sindresorhus/awesome" target="_blank" rel="noopener">awesome-list</a></li>
<li><a href="https://github.com/alebcay/awesome-shell" target="_blank" rel="noopener">awesome-shell</a></li>
<li><a href="https://github.com/veggiemonk/awesome-docker" target="_blank" rel="noopener">awwsome-docker</a></li>
<li><a href="https://github.com/ramitsurana/awesome-kubernetes" target="_blank" rel="noopener">awesome-kubernetes</a></li>
<li><a href="https://github.com/akullpp/awesome-java" target="_blank" rel="noopener">awesome-java</a></li>
</ul>
<p>Open source book:</p>
<ul>
<li><a href="https://github.com/dylanaraps/pure-bash-bible" target="_blank" rel="noopener">pure bash bible</a><br>这个是中文版的简明教程，非常不错了</li>
<li><a href="https://wangdoc.com/bash/" target="_blank" rel="noopener">Bash tutorial</a></li>
<li><a href="https://www.usenix.org/sites/default/files/conference/protected-files/lisa19_maheshwari.pdf" target="_blank" rel="noopener">Linux Productivity Tools</a></li>
<li><a href="https://github.com/xjh22222228/git-manual" target="_blank" rel="noopener">git manual</a></li>
</ul>
<p>Other people’s Blog</p>
<ul>
<li><a href="https://www.liaoxuefeng.com/" target="_blank" rel="noopener">廖雪峰的官方网站</a></li>
</ul>
]]></content>
      <categories>
        <category>Awesome Resources</category>
      </categories>
  </entry>
  <entry>
    <title>Docker Advanced</title>
    <url>/2019/06/22/book-docker-concept/</url>
    <content><![CDATA[<p>最近看了一本书，书名是<code>&lt;&lt;Docker进阶与实战&gt;&gt;</code>， 这里并不是讲一些基础入门，而是在已经掌握和应用的基础上，告诉你背后的原理和技术细节。平时留意到的很多现象都在这里得到了解释，还是很值得记一下要点的。</p>
<h2 id="Chapter-3-镜像"><a href="#Chapter-3-镜像" class="headerlink" title="Chapter 3 镜像"></a>Chapter 3 镜像</h2><p>主要介绍 Docker Image，其实就是启动容器的只读模板，是容器启动所需的rootfs。</p>
<p>Image 表示方法：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dockerhub-web-address/namespace/repository:tag</span><br></pre></td></tr></table></figure></p>
<ul>
<li>namespace: 用于划分用户或组织，有时并没有用到</li>
<li>repository: 类似于Git仓库，一个仓库有很多镜像</li>
<li>tag: 区分同一镜像不同版本</li>
</ul>
<p>Layer这个东西类似于git commit。Image ID是最上层layer的ID。</p>
<p>Docker开源了镜像存储部分的代码，也就是docker registry, 在接触Docker的开始阶段我一直没明白<code>registry</code>与<code>repository</code>的区别，这2个词长得有点像哦，新手稍不注意就用混了，中文意思也有点类似，一个是档案室，一个是仓库，都可以放东西。</p>
<p>一般来说，docker registry需要与nginx去添加基本鉴权功能，才是一个合格的secure私有镜像库，但有时我并没有这么做。</p>
<p>已经下载到本地的镜像默认是存储在<code>/var/lib/docker</code>路径下的。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /var/lib/docker/image/devicemapper</span><br><span class="line">ls -ltr</span><br><span class="line"></span><br><span class="line">total 4</span><br><span class="line">drwx------ 4 root root   37 May  8 15:21 imagedb</span><br><span class="line">drwx------ 5 root root   45 May  8 15:22 layerdb</span><br><span class="line">drwx------ 4 root root   58 May  8 15:29 distribution</span><br><span class="line">-rw------- 1 root root 1269 Jun 17 09:21 repositories.json</span><br></pre></td></tr></table></figure></p>
<h3 id="使用Docker镜像"><a href="#使用Docker镜像" class="headerlink" title="使用Docker镜像"></a>使用Docker镜像</h3><p><code>dangling</code> image doesn’t have name and tag (present as <code>&lt;none&gt;</code>), <code>docker commit</code> sometimes can generate dangling image, you can use filter to show dangling:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images --filter &quot;dangling=true&quot;</span><br></pre></td></tr></table></figure></p>
<p>只显示image ID:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images -q</span><br></pre></td></tr></table></figure></p>
<p>Remove all dangling images:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images --filter &quot;dangling=true&quot; -q | xargs docker rmi</span><br></pre></td></tr></table></figure></p>
<p>There is a tool <a href="https://github.com/justone/dockviz" target="_blank" rel="noopener"><code>dockviz</code></a> can do image analysis job. 可以图形化的展示image的层次。</p>
<p><code>docker load</code>用于被<code>docker save</code>导出的镜像，还有一个<code>docker import</code>用于导入包含根文件系统的归档，并将之变为镜像, <code>docker import</code>常用来制作Docker baseimage。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker save -o busybox.tar busybox</span><br><span class="line">docker load -i busybox.tar</span><br></pre></td></tr></table></figure></p>
<p><code>docker commit</code>用于增量生成镜像，效率较低，一般用于前期测试（比如当时non-root开发），最终确定步骤后，可以用<code>docker build</code>。</p>
<h3 id="镜像的组织结构"><a href="#镜像的组织结构" class="headerlink" title="镜像的组织结构"></a>镜像的组织结构</h3><p>可以用这2个命令去窥探一下镜像结构和元数据<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker history</span><br><span class="line">docker inspect</span><br></pre></td></tr></table></figure></p>
<h3 id="镜像扩展知识"><a href="#镜像扩展知识" class="headerlink" title="镜像扩展知识"></a>镜像扩展知识</h3><p>Docker引入了联合挂载<code>Union mount</code>技术，使镜像分层成为可能：<br>发展路径:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">unionfs -&gt; aufs -&gt; overlayfs</span><br></pre></td></tr></table></figure></p>
<p><code>写时复制 (copy-on-write)</code> 是Docker image强大的一个重要原因，操作系统中也广泛用到了，比如<code>fork</code>.当父进程fork子进程时，并没有真正分配内存给子进程，而是共享，当2者之一修改共享内存时，触发缺页异常才导致真正的内存分配。这样加速了子进程的创建，也减少了内存消耗。</p>
<p>联合文件系统是实现写时复制的基础，Ubuntu自带<code>aufs</code>, Red Hat和Suse采用<code>deivcemapper</code>方案（在<code>/var/lib/docker/image</code>下就是这个东西），作为Docker的存储驱动，它们的存储结构和性能都有显著差异，要根据实际情况选用。</p>
<h2 id="Chapter-4-仓库进阶"><a href="#Chapter-4-仓库进阶" class="headerlink" title="Chapter 4 仓库进阶"></a>Chapter 4 仓库进阶</h2><p>对Docker registry的API访问，传输对象主要包括镜像layer的块数据(<code>blob</code>)和表单(<code>manifest</code>)。layer数据以二进制方式存放于registry中。主要讲了一下用API进行pull, push的过程，步骤。其实都划分了很多步。</p>
<p>List and Dlete Image 可以参考我这篇博客<a href="https://chengdol.github.io/2019/06/10/docker-registry-api/" target="_blank" rel="noopener"><code>&lt;&lt;Docker Registry API&gt;&gt;</code></a>。</p>
<p>鉴权机制，这里使用的是Docker Engine, Registry和Auth Server协作完成。Auth Server由Registry开发者部署搭建，Registry完全信任Auth Server.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+---------------+               +------------------------+</span><br><span class="line">|               +-------+       |                        |</span><br><span class="line">|  Registry     |       |       | Authorization Service  |</span><br><span class="line">|               +&lt;--+   |       |                        |</span><br><span class="line">+-+--+----------+   |   |       +---------------+--+-----+</span><br><span class="line">  ^  |              |   |                       ^  |</span><br><span class="line">  |  |            5 |   | 6                     |  |</span><br><span class="line">  |  |              |   |                       |  |</span><br><span class="line">1 |  | 2            |   |                     3 |  | 4</span><br><span class="line">  |  |          +---+---v---------+             |  |</span><br><span class="line">  |  +---------&gt;+                 +-------------+  |</span><br><span class="line">  |             |  Docker Daemon  |                |</span><br><span class="line">  +-------------+                 +&lt;---------------+</span><br><span class="line">                +--------+--------+</span><br><span class="line">                         ^</span><br><span class="line">                         |</span><br><span class="line">           +-------------+----------------+</span><br><span class="line">           |      Docker Client           |</span><br><span class="line">           |    $docker pull busybox      |</span><br><span class="line">           |                              |</span><br><span class="line">           +------------------------------+</span><br></pre></td></tr></table></figure>
<ol>
<li>Docker Engine试图赋予HTTP请求一个鉴权的token，如果没有，Daemon会试图fetch/refresh一个新的token。</li>
<li>如果请求没有做过认证且不含token则Registry会返回401 Unauthorized状态</li>
<li>用户带着Registry返回的信息以及证书去访问Auth Server申请token （<strong>这里具体怎么操作？证书在哪里？</strong>）</li>
<li>Auth Server后端账户记录着用户名和密码，获取用户请求后，会将鉴权信息的token返回给用户</li>
<li><p>用户带着token再次访问Regisrty, HEADER中包含:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Authorization: Bearer &lt;token content&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Registry检验token，如通过则开始工作</p>
</li>
</ol>
<h3 id="构建私有仓库"><a href="#构建私有仓库" class="headerlink" title="构建私有仓库"></a>构建私有仓库</h3><p>In general, we can simply run a private docker registry:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --hostname localhost \</span><br><span class="line">  --name registry-v2 \</span><br><span class="line">  -v /opt/data:/var/lib/registry \</span><br><span class="line">  -p 5000:5000 \</span><br><span class="line">  registry:2.0</span><br></pre></td></tr></table></figure></p>
<p>这里将本地目录<code>/opt/data</code>挂载到容器镜像存储目录<code>/var/lib/registry</code>，方便查看和管理镜像数据，在DataStage Installer中也是如此。这时的registry是不安全的，能访问本机5000端口的人都可以上传和下载镜像。</p>
<p>需要为其加上HTTPS反向代理，这里以Nginx来实现。然后代理服务器会接受HTTPS请求，然后将请求转发给内部网络上的registry服务器，并将registry访问结果返回给用户。</p>
<p>可以参考我的这篇blog关于如何搭建<a href=""><code>Secure Docker Registry</code></a>.</p>
<h2 id="Chapter-5-Docker网络"><a href="#Chapter-5-Docker网络" class="headerlink" title="Chapter 5 Docker网络"></a>Chapter 5 Docker网络</h2>]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes 进阶实战</title>
    <url>/2019/09/15/book-k8s-adv-practical/</url>
    <content><![CDATA[<p>这是最近几周看的书（中文），年初从国内带过来的。</p>
<p>最近的项目涉及到很多微服务架构设计的问题，和组里大佬讨论的时候发现自己有的地方理解得不太正确甚至一张白纸，给不出一个完善的设计方案和想法，赶紧更新和归纳一下自己之前学到的知识点。</p>
<p>其实接触Kubernetes也快一年了，但一直是对之前项目的维护和更新操作，这次难得机会要集成一个新组件到已有的集群里，从头开始设计这些功能组件的各种配置，结构，生命周期，存储卷，依赖等。这本书算是一个由点到面的总结，提供了不少的帮助。</p>
<p>最近逐渐体会到一个好的，完善的，充分考虑的顶层设计是多么重要，否则每次设计改动对应到底层可能耗时耗力，甚至积重难返，不得不相互妥协。</p>
<p>这本书不打算做细致的笔记，但会记录一些以前没意识到或没见过的概念和工具。之后打算更细致的看一看<code>&lt;&lt;Kubernetes in Action&gt;&gt;</code>。我看最近<code>O&#39;REILLY</code>出版了或即将出版很多关于Kubernetes的新书，其中比较吸引我的是<code>pattern</code>，<code>best practices</code>, <code>Operator</code>以及一些<code>cloud native devops</code>相关的知识点，当然还包括一些重要系统组件和插件，比如<code>SSL/TLS</code>, <code>CoreDNS</code>和<code>etcd</code>等。看来2019剩下的日子是真的会很忙了。</p>
<h1 id="笔记"><a href="#笔记" class="headerlink" title="笔记"></a>笔记</h1><p>按照计划在2019年10月之前把这本书看完了第一遍，在书中做了不少标记和勾画，接下来快速记录一下其中的我比较注意的地方：</p>
<hr>
<p>Kubernetes通过其附加组件之一的CoreDNS为系统内置了服务注册和服务发现功能，为每个Service配置了DNS名称，允许客户端通过此名称发出访问，并且Service通过kube-proxy creates iptabls or ipvs内建了负载均衡机制。Service本质上讲是一个四层代理服务，也可将外部流量引入集群内部。</p>
<p>网络存储系统，诸如：NFS, GlusterFS, Ceph, Cinder…目前项目里面其实用的是本地存储，只不过额外设置了NFS将本地存储连接了起来，并没有直接只用K8s中的NFS配置。</p>
<p>API Server是整个集群的网关。</p>
<p>etcd是由CoreOS基于raft协议开发的分布式键值存储，可用于服务发现，共享配置以及一致性保障，它是独立的服务组件，并不隶属于K8s。etcd中键值发生变化时会通知API Server，并通过watch API向客户端输出，实现高效协同。</p>
<p>K8s supports container runtime: Docker, cri-o, RKT, Fraki<br>cri-o use gRPC(Remote procedure call)</p>
<p>K8s Dashborad<br>Prometheus and it’s add-ons<br>Ingress controller: 应用层负载均衡机制: Nginx, HAProxy…</p>
<p>Pod网络由网络插件实现(for example: fannel, calico, weave…), Service网络由K8s指定。</p>
<hr>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Modern Java in Action</title>
    <url>/2019/12/06/book-modern-java/</url>
    <content><![CDATA[<p>2019年12月6日，拿到了<code>&lt;&lt;Modern Java in Action&gt;&gt;</code>，主要介绍Lambdas, streams, functional and reactive programming. </p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Design Data-Intensive Applications</title>
    <url>/2020/05/21/book-design-dataintensive-app/</url>
    <content><![CDATA[<p>2018年7月18号收货到手的，但一直没有花时间去读😳，评价挺高的一本书。</p>
<p>这次WFH抽时间看了看，其实是一本很好的关于系统设计的书(重点关注的是Data-Intensive System，需要一些数据库的使用知识和经验，然鹅我并没有😂)，如果你曾经准备过系统设计相关的面试，或者有几年系统相关的开发经验，会发现读起来还是挺有收获的。</p>
<p>目前是第一遍阅读，这种书得读个几遍才能全面消化，特别对我这种writing不好的人🙁，作者的用词遣句，叙述逻辑也很值得学习！</p>
<h2 id="Part-I"><a href="#Part-I" class="headerlink" title="Part I"></a>Part I</h2><p>主要介绍了Data Sysytem Foundation.</p>
<p><code>Reliable, Scalable and Maintainable</code><br>各自的定义，分类和要点，从这3个方面考虑去构建适合需求的系统。比如Relability，有hardware, software and human faults; Scalability，用什么去describe workload and performance, 如何处理越来越多的workload; Mainyainability，要多多考虑operations team (run smoothly), new engineer (easy to pick up)的感受，以及对未来可能的需求改动留有余地。</p>
<p><code>Data Models and Query Language</code><br>主要讲了传统的relational DB 和 NoSQL中的document DB (suitable for one to many relation), 如何随着需求的改变不断进化，还提到了Graph-like Data Model (many to many relation). 讲到了Declarative language 对比 Imperative的好处，比如SQL，系统可以在内部优化而不影响Query语句本身。</p>
<p><code>Storage and Retrieval</code><br>数据库的底层实现，从Hash Indexes，到SSTables (String Sorted Table)，再到LSM-Trees (Log Structure Merge Tree), 最后到B-Trees (一种在disk上保持sorted structure的结构).<br>Advantages and downsides of LSM-Trees. 特别是read/write的performance, LSM-Tree的write operation一般来说比B-Trees效率高，但这里没有一个普世法则，需要通过实际测试才能知道哪种模式适合你。</p>
<p>In-memory database也提到了，相比于non in-memory，它快于不需要encode data in the strucutre to store in disk, 并且可以实现以下disk上难以实现的index 结构.</p>
<p>最后提到了data warehouse, 这和传统的处理transaction的数据库独立开来了，优化于适合analytics. column-oriented storage经常在data warehouse中使用，但不全是。要注意的是Cassandra有column families的概念，但它并不是属于column-oriented storage.</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>system design</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes 网络权威指南</title>
    <url>/2020/02/03/book-k8s-networking-guide/</url>
    <content><![CDATA[<p>网络在云计算中又起着至关重要的作用。大概浏览了一下目录和内容总结，很符合我的需求。类似的英文版书籍我一直在寻找，但还真没见到过。很赞同作者在前言中的一句话：工程师不能只当使用者，还要理解底层的实现。其实很多新技术都是原有技术的再封装和创新应用，真正理解了本质的东西对快速学习非常有帮助。</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>The Linux Command Line</title>
    <url>/2019/08/15/book-linux-command-line/</url>
    <content><![CDATA[<p>This is the latest version and the second time I read this book, record something that I forget, just for future quick review.</p>
<p>When we speak of the command line, we are really referring to the shell. The shell is a program that takes keyboard commands and passes them to the operating system to carry out.</p>
<p>If the last character of the prompt is a <code>hash mark(#)</code> rather than a <code>dollar sign</code>, the terminal session has superuser privileges.</p>
<h1 id="Chapter-2-Navigation"><a href="#Chapter-2-Navigation" class="headerlink" title="Chapter 2 Navigation"></a>Chapter 2 Navigation</h1><p><code>pwd, cd, ls</code>, basic things, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -ltrhF</span><br><span class="line">ls -lSrhF</span><br><span class="line">ls -Rla</span><br><span class="line">ls -ld</span><br></pre></td></tr></table></figure></p>
<h1 id="Chapter-3-Exploring-the-System"><a href="#Chapter-3-Exploring-the-System" class="headerlink" title="Chapter 3 Exploring the System"></a>Chapter 3 Exploring the System</h1><p>determine file type:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">file &lt;filename&gt;</span><br></pre></td></tr></table></figure></p>
<p><code>less</code> is more.</p>
<p>This is the supplement of <code>&lt;&lt;How Linux Works&gt;&gt;</code><br><strong>/boot</strong><br>Contains the <code>Linux kernel</code>, initial RAM disk image (for drivers needed at boot time), and the boot loader. Interesting files include <code>/boot/grub/grub.conf</code>, or <code>menu.lst</code>, which is used to configure the boot loader, and <code>/boot/vmlinuz</code> (or something similar), the Linux kernel.</p>
<p><strong>/dev</strong><br>This is a special directory that contains device nodes. “Everything is a file” also applies to devices. Here is where the kernel maintains a list of all the devices it understands.</p>
<p><strong>/etc</strong><br>The /etc directory contains all the system-wide configuration files. It also contains a collection of shell scripts that start each of the system services at boot time. Everything in this directory should be readable text. While everything in <code>/etc</code> is interesting, here are some all-time favorites: <code>/etc/crontab</code>, a file that defines when automated jobs will run; <code>/etc/fstab</code>, a table of storage devices and their associated mount points; and <code>/etc/passwd</code>, a list of the user accounts.</p>
<p><strong>/proc</strong><br>The <code>/proc</code> directory is special. It’s not a real file system in the sense of files stored on your hard drive. Rather, it is a <code>virtual file system</code> maintained by the Linux kernel. The <code>files</code> it contains are peepholes into the kernel itself. The files are readable and will give you a picture of how the kernel sees your computer.</p>
<p><strong>/var/log</strong><br><code>/var/log</code> contains log files, records of various system activity. These are important and should be monitored from time to time. The most useful ones are <code>/var/log/</code> messages and <code>/var/log/syslog</code>. Note that for security reasons on some systems, you must be the superuser to view log files.</p>
<h1 id="Chapter-4-Manipluating-Files-and-Directories"><a href="#Chapter-4-Manipluating-Files-and-Directories" class="headerlink" title="Chapter 4 Manipluating Files and Directories"></a>Chapter 4 Manipluating Files and Directories</h1><p><code>cp</code> command useful options:<br><code>-a</code>: same as <code>-dR --preserve=all</code><br><code>-u</code>: copy only when the SOURCE file is newer than the destination file or when the destination file is missing<br><code>-r/R</code>: copy directories recursively<br><code>-f</code>: if  an  existing destination file cannot be opened, remove it and try again, will overwrite existing files.<br><code>-p</code>: same as –preserve=mode,ownership,timestamps</p>
<p><code>hard link:</code><br>A hard link is indistinguishable from the file itself. Unlike a symbolic link, when you list a directory containing a hard link, you will see <strong>no</strong> special indication of the link. When a hard link is deleted, the link is removed, but the contents of the file itself continue to exist (that is, its space is not deallocated) <strong>until</strong> all links to the file are deleted.</p>
<blockquote>
<p>Hard links cannot reference directories, only files.</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -li</span><br><span class="line"></span><br><span class="line">269191713 -rw-------  2 root root      6614 Jul 28 20:53 config-hard.json</span><br><span class="line">269191713 -rw-------  2 root root      6614 Jul 28 20:53 config.json</span><br></pre></td></tr></table></figure>
<p>The first field is the inode number, they are the same.</p>
<p><code>symbolic link:</code><br>The same way as a Windows shortcut:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ln -s /root/config.json /tmp/config-link.json</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that should use absolute path! although relative is fine. <code>/root/config.yaml</code> is   the source<br>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  lrwxrwxrwx 1 root root 17 Aug 16 10:10 config-link.json -&gt; /root/config.json</span><br><span class="line">  ``` </span><br><span class="line"></span><br><span class="line">remove symbolic link:</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>rm -f /tmp/config-link.json<br><code>`</code></p>
<h1 id="Chapter-5-Working-with-Commands"><a href="#Chapter-5-Working-with-Commands" class="headerlink" title="Chapter 5 Working with Commands"></a>Chapter 5 Working with Commands</h1><p><code>type</code>: Indicate how a command name is interpreted<br><code>which</code>: Display which executable program will be executed<br><code>help</code>: Get help for shell builtins<br><code>man</code>: Display a command’s manual page<br><code>apropos</code>: Display a list of appropriate commands<br><code>info</code>: Display a command’s info entry<br><code>whatis</code>: Display one-line manual page descriptions<br><code>alias</code>: Create an alias for a command</p>
<h1 id="Chapter-6-Redirection"><a href="#Chapter-6-Redirection" class="headerlink" title="Chapter 6 Redirection"></a>Chapter 6 Redirection</h1>]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Car Insurance</title>
    <url>/2020/06/04/car-insurance/</url>
    <content><![CDATA[<p>最近疫情比较严重，在家办公了，大家出行减少，于是上个月保险公司给我退了$11的汽车保费。今年我感觉疫情很难结束，并且wfh将会持续很长一段时间，平时出门也就买个菜，于是想把保险换成更便宜一些的。</p>
<p>我目前的投保的公司是Progressive，之前是Farmers。但我开车一向比较注意，所以从来没出过事故。</p>
<p>这里有篇文章介绍了一下美国汽车保险的情况:<br><a href="https://www.guruin.com/guides/car-insurance" target="_blank" rel="noopener">https://www.guruin.com/guides/car-insurance</a><br><a href="https://www.dealmoon.com/guide/773024" target="_blank" rel="noopener">https://www.dealmoon.com/guide/773024</a></p>
]]></content>
      <categories>
        <category>Car</category>
      </categories>
      <tags>
        <tag>car</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Command Line and Shell Scripting Bible</title>
    <url>/2019/07/08/book-linux-cmd-shell-bible/</url>
    <content><![CDATA[<p>This is a thick, comprehensive book about Linux command line and shell scripting.</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Renew Driver License</title>
    <url>/2019/09/19/car-driver-license/</url>
    <content><![CDATA[<p>我的临时驾照过期了快一周了，忘记去renew，新的驾照也没寄过来（也不知道是不是给我办的real ID？？），准备明天去DMV。仔细观察了一下，当时办事人员在我的临时驾照上写了一个Legal Presence号码（916-657-7790），应该是快过期的时候打过去查询进度和催促用的，但是我忘了。。。我印象里以为10月份才过期😌。。。</p>
<p>所以说，明天去了之后有几件事需要确认：</p>
<ol>
<li>继续renew</li>
<li>查询驾照审批进度</li>
<li>再次确认地址</li>
</ol>
<p>保险起见还是带上<a href="https://www.dmv.ca.gov/portal/wcm/connect/2db22455-e270-47a3-819c-d7c7716d5194/List_of_Docs_REALID.pdf?MOD=AJPERES" target="_blank" rel="noopener">必要的材料</a>：<br>护照，I-94，过期驾照，SSN，EAD, H1B。</p>
<p>后续：<br>上次去renew的时候用的是OPT学生身份，但在审批过程中我的身份变成了H1B，不一致导致了pending，这次去更新了一下，所以一定要用最新的身份去办理。</p>
<p>此外，每年renew car sticker也不要忘了，否则超时会被罚款。去DMV可以网上交钱renew然后过一两周就会给你寄过来了。</p>
<p>09/30/2019, 今天收到了新的driver license，居然不是Real ID, 之后还得再去更换，否则2020以后乘机还得带护照了。决定2020之后再去办理了，因为会搬家。记得要2份不同的住址证明，否则不给办。。。</p>
<p>10/18/2019, 过了一个月sticker还是没有收到，去DMV一问才知道地址居然还是以前的，原来car registration的地址和Drive license的地址都要修改。花了22刀现场办了一个，算是了结一件事。</p>
]]></content>
      <categories>
        <category>Car</category>
      </categories>
      <tags>
        <tag>car</tag>
      </tags>
  </entry>
  <entry>
    <title>汽车的日常</title>
    <url>/2019/10/18/car-repair/</url>
    <content><![CDATA[<p>这篇blog主要记录一下汽车维修和保养方面的总结吧。</p>
<p>来美国的第一辆车是2009 Camry，主要是为了方便平时买菜，图个省心买了辆二手北美神车，到这篇blog创建的时候已经开了快3年，只能说名副其实，已经10年的车了，大毛病一个都没有。目前为止的车况我只能说非常棒，10年的车，接近16万公里，只有一些小部件损耗的更换，丰田，了不起。<br><img src="https://drive.google.com/uc?id=1ff9jmfxgTJhXn5TO8Y1kLf5jl-TjC5RW" alt=""></p>
<p>说实话，10年了，外形真没有过时😃，经济适用，打算还继续使用一段时间🌹。</p>
<p>02/04/2020 100k miles! 纪念一下<br><img src="https://drive.google.com/uc?id=1j9zDS1ZE-dnzIdN8IPTwXIIBmf9uN65c" alt=""></p>
<h2 id="目前遇到的问题："><a href="#目前遇到的问题：" class="headerlink" title="目前遇到的问题："></a>目前遇到的问题：</h2><ol>
<li><p>刹车尾灯<br><img src="https://drive.google.com/uc?id=1tfLBOmP_42bb07in1trmjCXbNxmbDU11" alt=""><br>某次出游发现右边的刹车尾灯不亮了，很好办，网上买一对和车型兼容的尾灯就行了，自己安装非常容易。花费$4.99.</p>
</li>
<li><p>遮阳挡板<br><img src="https://drive.google.com/uc?id=1a8Ocq57jXSBVqjD3h7RYE48J0zi-YRkC" alt=""><br>这个买来的时候就是破损的，我一直没管它，但有时阳光太强这个挡板活动有点问题导致体验不是很好，于是就在网上买了一个自己装上，花费$29.98.</p>
</li>
<li><p>胎压传感器<br>这种传感器的电池寿命一般在5~10年之间，看来这车之前都没换过，不巧被我遇到了。我在亚马逊上一次性买了4个兼容的传感器，准备把四个轮胎上的都换掉。<br><img src="https://drive.google.com/uc?id=1LONYlXCAsOcAX82hj2JQmMqUIKG3LCMw" alt=""></p>
</li>
</ol>
<p>需要注意的是，TPMS胎压传感器需要专业人士和工具更换，要先确认工具能正确的识别它，然后再安装。安装步骤一般是先将轮胎放气，卸载，然后更换。特别要注意传感器需兼容车载电脑。我买的是pre-programmed的产品，315MHz + 433MHz兼容，不过安装后仍需要relearn车载控制器。一定要仔细阅读说明书哦。</p>
<p>我找了Costco Tire Center帮我更换，很不幸，他们的工具无法识别我买的sensor (I doubt)…于是就只能使用他们的sensor了，价格$44.99/个。最后加上labor fee总共花了$252.61。之前我去咨询了其他的auto repair，有的4个要charge $500，呵呵😑。</p>
<p>要注意的是他们会询问车的年份和型号，以及发动机类型（几缸）。然后交钱，给你一个磁性号码牌，放在车顶上，然后你就可以到处闲逛，比如去Costco看看烤鸡，完事后会打电话叫你去取车。</p>
<p>还需要注意的是，随着气温骤降，TPMS warning light may go on，这是因为气温降低，轮胎里的空气收缩导致胎压下降。可以参考这篇文章: <a href="https://www.lesschwab.com/article/tpms-light-coming-on-in-cold-weather-heres-why.html" target="_blank" rel="noopener">https://www.lesschwab.com/article/tpms-light-coming-on-in-cold-weather-heres-why.html</a></p>
<p>可以去gas station去自己打气，最好自己买个tire gauge，Amazon上很多选择，感觉这很必要。<br><a href="https://www.dummies.com/home-garden/car-repair/wheels-tires/how-to-add-air-to-your-tires/" target="_blank" rel="noopener">https://www.dummies.com/home-garden/car-repair/wheels-tires/how-to-add-air-to-your-tires/</a><br>我仔细研究了一下Amazon上售卖的tire gauge with inflation and deflation，感觉一般般呀，特别是便携12DV车充的，看差评可能会烧保险丝。。。 最后就没买😂，不过可以考虑入手一个机械式测压的。</p>
<p>我直接去了costco，在 <a href="https://www.costcotireappointments.com" target="_blank" rel="noopener">https://www.costcotireappointments.com</a> 上进行预约即可。或者早上早点去直接听到garage门口让工作人员帮忙补补气即可，打气后一般过一会就正常了。</p>
<h2 id="车辆正常保养维护"><a href="#车辆正常保养维护" class="headerlink" title="车辆正常保养维护"></a>车辆正常保养维护</h2><p>又到了该保养的时候了，maintenance light blinks everyday! 为了做到心里有数，pre-research is a must! 最该看的，其实就是car manual了，每个车都会有的，里面会告诉你一些基本的使用和保养常识，当然了，很多人也不关心这个，反正交给4S店或者其他auto repair去做了。</p>
<p>就拿我的车来说吧，5k miles左右会做一个保养，我一般会做的项目包括:</p>
<ol>
<li>change engine oil (must)</li>
<li>change engine oil filter (must)</li>
<li>tire check, brake pads check</li>
<li>battery get tested</li>
<li>change engine air filter (depends, but should)</li>
<li>change cabin air filter (recommand)</li>
<li>washer fluid</li>
</ol>
<p>机油不说了，保养主要就是换机油，有的auto repair如果你不说，他不会给你换机油过滤器的。。。但最好换了。轮胎检查一下，特别是spare，没气了打气，否则爆胎了你拿啥顶上？刹车片看看需不需要更换。</p>
<p>电池看看是否正常，电压测测，现代车辆都是车载电脑操控，需要一个稳定输出的电池。</p>
<p>引擎滤网需要更换，我这几次观察了一下，如果汽车的使用环境比较好，污染物少，用了10k miles的滤网还算干净，但还是换了，很简单的操作. 车厢空气滤网，这个很容易脏，建议更换。更换engine air filter非常简单，工具只需要Ratchet Socket Wrench and Sockets, 注意socket的直径匹配就行:<br><img src="https://drive.google.com/uc?id=1T15bCJjRchNlHtuKXpvJGueovD54g0wl" alt=""><br>其他相关工具的如下:<br><img src="https://drive.google.com/uc?id=1fooPl36_amOsChHWWDYKEPydzg37EMjL" alt=""></p>
<p>雨刮水不够了，自己加满，但最好不要用tap water，网上有很多去污剂可以考虑混合一下，如果在零下的环境中使用，还需要加防冻剂。我买的是QWIX windshield washer fluid, 1/4 oz makes one gallon windshield washer fluid.</p>
<p>100k miles保养，还需要考虑:</p>
<ol>
<li>coolant</li>
<li>power steering fluid</li>
<li>transmission fluid</li>
<li>brake fluid</li>
<li>change spark plugin</li>
<li>tire rotate</li>
</ol>
<p>这些项目都有自己的更换周期，特别是那几个fluid。取决于你车的具体情况。<br>所有这些保养，经过研究，都可以自己完成😃，就是要自己买工具。这个以后准备妥当了再更新一下。</p>
<p>这次保养，我除了change engine oil (filter), spark-plugin, 检查rear brake pads磨损殆尽，也和brake fluid一起更新了，花费$420 (＃￣～￣＃)~ Coolant 和 power steering fluid 没有更换，说没什么必要，人工费也挺贵的。其实我觉得brake change去costco或许会便宜很多，但当时嫌麻烦就没去问，下次就注意了。</p>
]]></content>
      <categories>
        <category>Car</category>
      </categories>
      <tags>
        <tag>car</tag>
      </tags>
  </entry>
  <entry>
    <title>Lookup Bounded Memory Support</title>
    <url>/2018/09/18/design-pxengine-lookup/</url>
    <content><![CDATA[<h1 id="How-Does-lookup-operator-work-now"><a href="#How-Does-lookup-operator-work-now" class="headerlink" title="How Does lookup operator work now"></a>How Does lookup operator work now</h1><ol>
<li><p>Process every record that would compose to be a lookup table,  read one record at a time, and add the record to the memory (<code>may overflow here</code>). Until all the records are processed, then save the lookup table in the memory into disk. </p>
</li>
<li><p>Reads the lookup table file back to memory (<code>may overflow here</code>) to setup the hash bucket for each record (set next record offset) , then write to disk again.</p>
</li>
<li><p>Load the entire lookup table file from the disk to memory to do lookup(<code>may overflow here</code>).</p>
</li>
</ol>
<p>As we can see, there are 3 parts that will cause memory overflow, the main reason is that we load the <strong>whole</strong> lookup table into memory. </p>
<p>To solve this problem, the easy and straightforward way to do is to divide the lookup table into several parts (we call this as <code>section</code>), then process these sections accordingly.</p>
<h1 id="New-Design"><a href="#New-Design" class="headerlink" title="New Design"></a>New Design</h1><p>Let’s see the diagram to illustrate the workflow:<br><img src="https://drive.google.com/uc?id=1Dzv6L3U7TA_aqFxboe6h6mZaoH6N9UAB" alt=""></p>
<p><strong>Header</strong>: meta data about lookup table: address, offset…<br><strong>Bucket vector</strong>: speed up lookup by chaining the records to different bucket using hash. </p>
<p><img src="https://drive.google.com/uc?id=10fgUeAvzYKlp8YKlj3vjgPRypo7KUiQh" alt=""><br>Here assume we have 5 records and 2 buckets, so when we lookup record 4, after hashing, we search from bucket2, so we will only walk through record 2, skip record 1,3 and 5. Of course, the pointer is stored in each record, actually it’s an offset value.</p>
<p><strong>section file container</strong>: we fix the size of section file container in memory (can be configured by client or set by some logic according to the size of memory in client machine)</p>
<h2 id="Current-Design-to-minimize-the-memory-usage"><a href="#Current-Design-to-minimize-the-memory-usage" class="headerlink" title="Current Design to minimize the memory usage"></a>Current Design to minimize the memory usage</h2><ol>
<li><p>Set a max memory cap (section file container size).</p>
</li>
<li><p>Process each record as it got read in, add the size of the record, when the size will exceed or be the same as max memory cap, save the records that collected so far into a file (called section file, size of section file <code>&lt;=</code> max memory cap size).   </p>
</li>
<li><p>Repeat the step above until all records have been saved into section file. Therefore, one big lookup table file now has been divided into several chunks of section files.</p>
</li>
<li><p>Process the input record and use its key to get the hash bucket number, chain the records(namely add offect in placeholder left, then we need to wirte new content back to disk, need to swap section files with writing and reading operations).</p>
</li>
<li><p>when do lookup operation, hash the key and get the entry to lookup it, walk through and compare each record until find it or not, may need to read several section file from disk (now write operation).</p>
</li>
</ol>
<p>If the size of input data <code>&lt;=</code> 2 * available memory size (ignore other small overhead), we will only have 2 section files, the performance will be only corroded slightl(assume the read/write file operation is good).</p>
]]></content>
      <categories>
        <category>PXEngine</category>
      </categories>
      <tags>
        <tag>pxengine</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker USER Directive</title>
    <url>/2019/07/23/docker-USER/</url>
    <content><![CDATA[<p>From major security hardening items: <code>Try to explicitly set a USER/uid – to avoid even accidental startup as root</code>. This is a good point I agree. But in our case it’s impossible to use <code>USER</code> directive with non-root user in dockerfile at beginning, we need root user to install and configure services in containers, then alter the settings that cater to non-root user.</p>
<p>The solution is in the last <code>docker commit</code>, use <code>--change &#39;USER 1000&#39;</code> to set default user as non-root. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker commit --change &apos;USER 1000&apos; --change &apos;ENTRYPOINT [&quot;/opt/xx/initScripts/startcontainer.sh&quot;]&apos; -c &apos;ENV SETUPINPROGRESS &quot;&quot;&apos; $&#123;SERVICES_HOST&#125; $&#123;DOCKER_TEMPIMAGE_TAG_SERVICES&#125;:3</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that the non-root user must <strong>exist</strong> in image, if it belongs to multiple groups (one primary and several supplementaries), only specify <code>id</code> is enough.</p>
</blockquote>
<p>If later we need to run as root, just specify <code>runAsUser: 0</code> in K8s yaml or <code>--user 0</code> in <code>docker run</code> command, it will <strong>overwrite</strong> the default setting.</p>
<p>You can use <code>docker inspect</code> to check default <code>USER</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect &lt;image&gt;:&lt;tag&gt; | grep -i user</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Daemon Log</title>
    <url>/2019/12/02/docker-daemon-log/</url>
    <content><![CDATA[<p>When I was working on securing docker registry, I followed the instructions but when run <code>docker push</code> I always get <code>x509: certificate signed by unknown authority</code> error, this means the self-signed certificate is still not identified by docker daemon.</p>
<p>This time to get more detail information, need to check the docker daemon log.</p>
<h1 id="How-to-enable-debug-mode"><a href="#How-to-enable-debug-mode" class="headerlink" title="How to enable debug mode?"></a>How to enable debug mode?</h1><p>By default, the debug mode is off, not much helpful info from logs, check here: <a href="https://docs.docker.com/config/daemon/" target="_blank" rel="noopener">https://docs.docker.com/config/daemon/</a>, enable debugging section.</p>
<p>Edit the <code>daemon.json</code> file, which is usually located in <code>/etc/docker/</code>. You may need to create this file, if it is not there.<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"debug"</span>: <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Then send a <code>HUP</code> signal to the daemon to cause it to reload its configuration. On Linux hosts, use the following command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo kill -SIGHUP $(pidof dockerd)</span><br></pre></td></tr></table></figure></p>
<h1 id="Where-is-the-log"><a href="#Where-is-the-log" class="headerlink" title="Where is the log?"></a>Where is the log?</h1><p><a href="https://stackoverflow.com/questions/30969435/where-is-the-docker-daemon-log" target="_blank" rel="noopener">https://stackoverflow.com/questions/30969435/where-is-the-docker-daemon-log</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Ubuntu (old using upstart ) - /var/log/upstart/docker.log</span><br><span class="line">Ubuntu (new using systemd ) - sudo journalctl -fu docker.service</span><br><span class="line">Amazon Linux AMI - /var/log/docker</span><br><span class="line">Boot2Docker - /var/log/docker.log</span><br><span class="line">Debian GNU/Linux - /var/log/daemon.log</span><br><span class="line">CentOS - /var/log/daemon.log | grep docker</span><br><span class="line">CoreOS - journalctl -u docker.service</span><br><span class="line">Fedora - journalctl -u docker.service</span><br><span class="line">Red Hat Enterprise Linux Server - /var/log/messages | grep docker</span><br></pre></td></tr></table></figure></p>
<p>In Red Hat, from <code>/var/log/messages</code> file I clearly see that the docker daemon pick certificate under <code>/etc/docker/certs.d/&lt;domain, no port number!&gt;</code> folder.</p>
<p>If your OS is using <code>systemd</code>, the <code>journalctl</code> command can help, but the output from container is also dumping here, see this issue: <a href="https://github.com/moby/moby/issues/23339" target="_blank" rel="noopener">https://github.com/moby/moby/issues/23339</a>.</p>
<p>You can filter it by (works fine in Red Hat):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">journalctl -fu docker _TRANSPORT=stdout + OBJECT_EXE=docker</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Runtime Capabilities</title>
    <url>/2019/05/15/docker-capability/</url>
    <content><![CDATA[<p>In my blog <a href="https://chengdol.github.io/2019/05/13/linux-capability/" target="_blank" rel="noopener"><code>&lt;&lt;Linux Capability&gt;&gt;</code></a>. I talk the basic and general knowlwdge about <code>Capability</code>. This blog will focus on Capability in Docker container.</p>
<p>In <code>docker run</code> command, there are some flags about runtime privilege and capabilities:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--cap-add: Add Linux capabilities</span><br><span class="line">--cap-drop: Drop Linux capabilities</span><br><span class="line">--privileged=false: Give extended privileges to this container</span><br><span class="line">--device=[]: Allows you to run devices inside the container without the --privileged flag.</span><br></pre></td></tr></table></figure></p>
<p>By default, Docker containers are <strong>unprivileged</strong> and cannot, for example, run a Docker daemon inside a Docker container. This is because by default a container is not allowed to access any devices (<code>/dev</code>) on host, but a “privileged” container is given access to all devices on host.</p>
<p>The <code>--privileged</code> flag gives <strong>all</strong> capabilities to the container, and it also lifts all the limitations enforced by the device cgroup controller. In other words, the container can then do almost everything that the host can do. This flag exists to allow special use-cases, like running Docker within Docker.</p>
<p>How to verify? you can run a busybox with <code>--privileged</code> enabled or not, first try enable it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --rm -it --privileged busybox sh</span><br></pre></td></tr></table></figure></p>
<p>then let’s check init process capabilities (busybox doesn’t have <code>getpcaps</code>):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat /proc/1/status | grep -i cap</span><br><span class="line"></span><br><span class="line">CapInh: 0000001fffffffff</span><br><span class="line">CapPrm: 0000001fffffffff</span><br><span class="line">CapEff: 0000001fffffffff</span><br><span class="line">CapBnd: 0000001fffffffff</span><br><span class="line">CapAmb: 0000000000000000</span><br></pre></td></tr></table></figure></p>
<p>then decode in another machine, we can see full capabilities here:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># capsh --decode=0000001fffffffff</span><br><span class="line"></span><br><span class="line">0x0000001fffffffff=cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,</span><br><span class="line">cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,</span><br><span class="line">cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,</span><br><span class="line">cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,</span><br><span class="line">cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,</span><br><span class="line">cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,</span><br><span class="line">35,36</span><br></pre></td></tr></table></figure></p>
<p>if not enabled, only see default ones:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># capsh --decode=00000000a80425fb</span><br><span class="line"></span><br><span class="line">0x00000000a80425fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,</span><br><span class="line">cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_sys_chroot,cap_mknod,</span><br><span class="line">cap_audit_write,cap_setfcap</span><br></pre></td></tr></table></figure></p>
<p>By default, Docker has a default list of capabilities that are kept. The following table lists the Linux capability options which are allowed by default and can be dropped.</p>
<ol>
<li>SETPCAP: Modify process capabilities.</li>
<li>MKNOD: Create special files using mknod(2).</li>
<li>AUDIT_WRITE: Write records to kernel auditing log.</li>
<li>CHOWN: Make arbitrary changes to file UIDs and GIDs (see chown(2)).</li>
<li>NET_RAW: Use RAW and PACKET sockets.</li>
<li>DAC_OVERRIDE: Bypass file read, write, and execute permission checks.</li>
<li>FOWNER    Bypass: permission checks on operations that normally require the file system UID of the process to match the UID of the file.</li>
<li>FSETID: Don’t clear set-user-ID and set-group-ID permission bits when a file is modified.</li>
<li>KILL: Bypass permission checks for sending signals.</li>
<li>SETGID: Make arbitrary manipulations of process GIDs and supplementary GID list.</li>
<li>SETUID: Make arbitrary manipulations of process UIDs.</li>
<li>NET_BIND_SERVICE: Bind a socket to internet domain privileged ports (port numbers less than 1024).</li>
<li>SYS_CHROOT: Use chroot(2), change root directory.</li>
<li>SETFCAP: Set file capabilities.</li>
</ol>
<p>Further reference information is available on the <a href="http://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">capabilities(7) - Linux man page</a></p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p><a href="https://docs.docker.com/engine/reference/run/" target="_blank" rel="noopener">Docker run reference</a><br><a href="https://docs.docker.com/engine/security/security/" target="_blank" rel="noopener">Docker security</a></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>capability</tag>
      </tags>
  </entry>
  <entry>
    <title>Configuring Container DNS</title>
    <url>/2019/07/30/docker-dnsdomainname/</url>
    <content><![CDATA[<p>I have some doubts about <code>dnsdomainname</code> command in docker container when I developed non-root DataStage, in <code>engine conductor</code> tier.</p>
<p>References to <a href="https://docs.docker.com/v17.09/engine/userguide/networking/default_network/configure-dns/" target="_blank" rel="noopener">Configure container DNS</a></p>
<p>How can Docker supply each container a <code>hostname</code> and <code>DNS configuration</code> without having to build a custom image with the hostname written inside? The trick is to <strong>overlay</strong> three crucial <code>/etc</code> files inside the container with virtual files where it can write fresh information.</p>
<p>In container, run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># mount | grep etc</span><br><span class="line"></span><br><span class="line">/dev/mapper/rhel-root on /etc/resolv.conf type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/mapper/rhel-root on /etc/hostname type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">/dev/mapper/rhel-root on /etc/hosts type xfs (rw,relatime,attr2,inode64,noquota)</span><br></pre></td></tr></table></figure></p>
<p>Four different options affect container domain name services, please see official documentation for explanation:</p>
<ul>
<li><code>-h HOSTNAME</code> or <code>--hostname=HOSTNAME</code></li>
<li><code>--link=CONTAINER_NAME</code> or <code>ID:ALIAS</code></li>
<li><code>--dns=IP_ADDRESS</code></li>
<li><code>--dns-search=DOMAIN</code></li>
<li><code>--dns-opt=OPTION</code></li>
</ul>
<p>So what should <code>dnsdomainname</code> return exactly? for non-root engine docker container, the hostname is <code>is-en-conductor-0.en-cond</code>, but why sometimes <code>dnsdomainname</code> return empty but sometimes return <code>en.cond</code>.</p>
<p>I find the return depends on <code>/etc/hosts</code> file first non-self-loop IP hostname pair, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">9.30.223.186    is-en-conductor-0.en-cond is-servicesdocker is-xmetadocker</span><br></pre></td></tr></table></figure></p>
<p>the <code>dnsdomainname</code> will return <code>en-cond</code>, but if change to<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">9.30.223.186    is-xmetadocker is-en-conductor-0.en-cond is-servicesdocker</span><br></pre></td></tr></table></figure></p>
<p>the command returns empty, and if you run <code>hostname -f</code> (long host name), it returns <code>is-xmetadocker</code>.</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Commit</title>
    <url>/2019/10/11/docker-commit/</url>
    <content><![CDATA[<p>When build docker images, sometimes we need to use some files to install some packages inside container, for example when build redhat docker image: <code>redhat.repo</code>, <code>entitlement/</code> and <code>rpm-gpg/</code> are needed for package installation.</p>
<p>But we don’t want to use <code>COPY</code> command in dockerfile to copy them into image, that will add layers to store them when run <code>docker build</code>, not safe. The solution is mount these files in <code>docker run</code>, after install then commit, <code>docker commit</code> <strong>will not</strong> include any data in volumes mounted inside the container.</p>
<p>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## mount redhat repo and keys, install packages</span><br><span class="line">docker run --detach \</span><br><span class="line">  --name=serviceosbase \</span><br><span class="line">  --user 0 \</span><br><span class="line">  -v /etc/yum.repos.d/redhat.repo:/etc/yum.repos.d/redhat.repo \</span><br><span class="line">  -v /etc/pki/rpm-gpg:/etc/pki/rpm-gpg \</span><br><span class="line">  -v /etc/pki/entitlement:/etc/pki/entitlement \</span><br><span class="line">  --entrypoint=/bin/sh \</span><br><span class="line">  $&#123;DOCKER_IMAGE_TAG&#125;:1 \</span><br><span class="line">  -c &apos;tail -f /dev/null&apos;</span><br><span class="line"></span><br><span class="line">docker exec serviceosbase /bin/sh -c &quot;yum install -y glibc glibc-common systemd</span><br><span class="line">    systemd-libs openssl-libs &amp;&amp; yum update -y &amp;&amp; rm -rf /var/tmp/yum-* &amp;&amp; yum</span><br><span class="line">    makecache fast&quot;</span><br><span class="line"></span><br><span class="line">docker commit serviceosbase $&#123;DOCKER_IMAGE_TAG&#125;:1</span><br></pre></td></tr></table></figure></p>
<p>You can check the layers with <code>docker history &lt;image&gt;</code> command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">IMAGE               CREATED              CREATED BY                                      SIZE                COMMENT</span><br><span class="line">1f6e112efb83        About a minute ago   /bin/sh -c <span class="comment">#(nop)  ENV LANG=en_US.UTF-8 LANGU   0 B</span></span><br><span class="line">6060bfb14056        About a minute ago   /bin/sh -c rm /etc/yum.repos.d/ubi.repo &amp;&amp;      10.83 MB</span><br><span class="line">543fa76542de        2 minutes ago        /bin/sh -c <span class="comment">#(nop)  MAINTAINER XXX               0 B</span></span><br><span class="line">6558c4297a5d        2 minutes ago        /bin/sh -c <span class="comment">#(nop)  LABEL name=IIS Services ve   0 B</span></span><br><span class="line">6fecccc91c83        5 weeks ago                                                          7.06 kB</span><br><span class="line">&lt;missing&gt;           5 weeks ago                                                          204.8 MB            Imported from -</span><br></pre></td></tr></table></figure></p>
<p>Compare with dockerfile, no layer is for mount data after commit.</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Container IPC Share</title>
    <url>/2019/07/31/docker-ipc/</url>
    <content><![CDATA[<p>I have a post talks about IPC <a href="https://chengdol.github.io/2019/05/01/linux-ipc/" target="_blank" rel="noopener"><code>&lt;&lt;Linux IPC&gt;&gt;</code></a>, it’s about IPC resource requirements for DB2 and how to adjust the ipc parameters permanently or temporarily. This time we faced different ipc issue, interesting.</p>
<h2 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h2><p>We bring up DataStage container in particular order to make them function correctly, but when Engine is running, Xmeta DB2 went down silently whihout any warning or error messages. unquiesce will make DB2 up again, but it’s not stable.</p>
<p>This did not happen in K8s cluster, things get weired.</p>
<h2 id="Reason"><a href="#Reason" class="headerlink" title="Reason"></a>Reason</h2><p>We update docker run command for Xmeta and Engine with <code>--ipc=host</code>, so they will share the ipc resouces with host machine (They reside on the same machine) and each other. </p>
<p>The trick is there are some <code>ipcrm -a</code> in the Engine start and quiesce scripts. So when Engine is up, it cleans host ipc resource and DB2 goes down.</p>
<p>we remove all <code>ipcrm -a</code> commands inside container and things get work.</p>
<p>Another thing is before start up the containers, <strong>make sure the ipc is clean</strong>, we encountered the problem that the old non-used ipc overstep in new containers, so run <code>ipcrm -a</code> in host machine to clean them.</p>
<p><strong>Why K8s does not have this problem?</strong> Because we schedule Xmeta and Engine in different nodes, the <code>ipcrm -a</code> will not affect each other, but docker we hold all containers in one node.</p>
<p>Some usefully commands<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ipcs -l      <span class="comment">## list ipc configuration</span></span><br><span class="line"></span><br><span class="line">ipcrm -a     <span class="comment">## remove all ipc resources</span></span><br><span class="line">ipcs -a      <span class="comment">## list ipc in use</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux</tag>
        <tag>ipc</tag>
      </tags>
  </entry>
  <entry>
    <title>Non-Root Docker Update Summary</title>
    <url>/2019/05/06/docker-nonroot-update-summary/</url>
    <content><![CDATA[<p>I haven’t got time to learn Docker systematically so far, but I still gain a lot from daily tasks. This post is a brief summary for what I have done to upgrade the container from owned by root to noon-root for security reason required by our customers.</p>
<p>I will talk the development workflow instead of the detail about how to set and modify the configurations inside the container:</p>
<p>I have a base image at beginning, let’s say <code>root_is_engine.tar.gz</code>, load it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker load -i root_is_engine.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>you can check the loaded image by running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure></p>
<p>Now I am going to create the container from this image, but wait, I don’t want the container to run any script or program when it starts, what I need is it just hangs without doing anything.</p>
<p>That means I need to override the default <code>entrypoint</code> (entrypoint sets the command and parameters that will be executed first when spin up a container) in docker run command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --detach \</span><br><span class="line">         --cap-add=SYS_ADMIN \</span><br><span class="line">         --privileged=false --name=$&#123;ENGINE_HOST&#125; --hostname=$&#123;ENGINE_HOST&#125; \</span><br><span class="line">         --restart=always --add-host=&quot;$&#123;SERVICES_HOST&#125; $&#123;DB2_XMETA_HOST&#125; $&#123;ENGINE_HOST&#125;&quot;:$&#123;ENGINE_HOST_IP&#125; \</span><br><span class="line">         -p 8449:8449 \</span><br><span class="line">         -v $&#123;DEDICATED_ENGINE_VOLPATH&#125;/$&#123;ENGINE_HOST&#125;/EngineClients/db2_client/dsadm:/home/dsadm \</span><br><span class="line">         --entrypoint=/bin/sh \</span><br><span class="line">         $&#123;DOCKER_IMAGE_TAG_ENGINE&#125;:$&#123;DOCKER_IMAGE_VERSION&#125; \</span><br><span class="line">         -c &apos;tail -f /dev/null&apos;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that place the arguments to your entrypoint at the <strong>end</strong> of your docker command <code>-c &#39;tail -f /dev/null&#39;</code></p>
</blockquote>
<p>Run <code>docker ps</code> command, you can see under <code>COMMAND</code> column the entrypoint is what I specified:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CONTAINER ID        IMAGE                   COMMAND                  CREATED             STATUS              PORTS                     NAMES</span><br><span class="line">b462f6123684        is-engine-image:1       &quot;/bin/sh -c &apos;tail -f...&quot;   2 days ago          Up 2 days           0.0.0.0:8449-&gt;8449/tcp   is-en-conductor-0.en-cond</span><br></pre></td></tr></table></figure></p>
<p>Then get into the container by running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker exec -it &lt;container id or container name&gt; [bash|sh]</span><br></pre></td></tr></table></figure></p>
<p>Then if you check the process status, you can see the init process with PID #1 is running <code>tail</code> command to track <code>/dev/null</code> device file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux</span><br><span class="line"></span><br><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root         1  0.0  0.0   5968   616 ?        Ss   16:47   0:00 tail -f /dev/null</span><br><span class="line">root        27  1.5  0.0  13420  1992 pts/0    Ss   16:50   0:00 bash</span><br><span class="line">root        45  0.0  0.0  53340  1864 pts/0    R+   16:50   0:00 ps aux</span><br></pre></td></tr></table></figure></p>
<p>OK, now I can make changes, for example, create and switch to ordinary user with specified user id and group id, grant them privileges, modify the owner and permission of some files, run and update startup script line by line to see if the applications setup correctly with non-root.</p>
<blockquote>
<p>Note if you have mount path in host machine, you may need to <code>chown</code> correct uid and gid, otherwise ordinary user in container may get permission denied issue.</p>
</blockquote>
<p>After running some tests and they succeed, I need to <strong>commit</strong> the changes into a new image. </p>
<ul>
<li><p>First understand how does <code>docker commit</code> work? what will be committed into new image?</p>
<p>The container has a writable layer that stacks on top of the image layers. This writable layer allows you to <em>make changes</em> to the container since the lower layers in the image are read-only.</p>
<p>From the docker documentation, it said: It can be useful to commit a container’s <strong>file</strong> changes or <strong>settings</strong> into a new image.</p>
<p>The commit operation will <strong>not</strong> include any data contained in volumes mounted inside the container.</p>
<p>By default, the container being committed and its processes will be paused while the image is committed. This reduces the likelihood of encountering data corruption during the process of creating the commit. If this behavior is undesired, set the <code>--pause</code> option to false.</p>
<p>The <code>--change</code> option will apply Dockerfile instructions to the image that is created. Supported Dockerfile instructions: <code>CMD|ENTRYPOINT|ENV|EXPOSE|LABEL|ONBUILD|USER|VOLUME|WORKDIR</code></p>
</li>
<li><p>How about processes in the running container?</p>
<p>When you start container from image then process will start here - processes exists <strong>only</strong> in executing container, when container stops there are no processes anymore - only files from container’s filesystem.</p>
</li>
</ul>
<blockquote>
<p>Note that before committing, you need to quiesce the services and remove the mount path content to unlink all broken symbolic links.</p>
</blockquote>
<p>Also remember to put the old entrypoint back:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker commit \</span><br><span class="line">       --change &apos;ENTRYPOINT [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;/opt/xx/initScripts/startcontainer.sh&quot;]&apos; \</span><br><span class="line">       &lt;container ID&gt; is-engine-image:1</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>podman</code> commit format is different.</p>
</blockquote>
<blockquote>
<p>Note that you may use <code>bin/sh</code> instead of <code>/bin/bash</code>.</p>
</blockquote>
<p>OK, now start to run the new image with non-root user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --detach \</span><br><span class="line">         --user 1000 \</span><br><span class="line">         --cap-add=SYS_ADMIN \</span><br><span class="line">         --privileged=false --name=$&#123;ENGINE_HOST&#125; --hostname=$&#123;ENGINE_HOST&#125; \</span><br><span class="line">         --restart=always --add-host=&quot;$&#123;SERVICES_HOST&#125; $&#123;DB2_XMETA_HOST&#125; $&#123;ENGINE_HOST&#125;&quot;:$&#123;ENGINE_HOST_IP&#125; \</span><br><span class="line">         -p 8449:8449 \</span><br><span class="line">         -v $&#123;DEDICATED_ENGINE_VOLPATH&#125;/$&#123;ENGINE_HOST&#125;/EngineClients/db2_client/dsadm:/home/dsadm \</span><br><span class="line">         $&#123;DOCKER_IMAGE_TAG_ENGINE&#125;:$&#123;DOCKER_IMAGE_VERSION&#125;</span><br></pre></td></tr></table></figure></p>
<p>Let’s see the processes in the non-root container:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">dsadm        1  0.0  0.0  13288  1604 ?        Ss   18:29   0:00 /bin/bash /opt/xx/initScripts/startcontainer.sh</span><br><span class="line">dsadm      540  0.0  0.0   5968   620 ?        S    18:29   0:00 tail -f /dev/null</span><br><span class="line">dsadm      568  0.1  0.3 2309632 24792 ?       Sl   18:29   0:00 /opt/xx/../../jdk</span><br><span class="line">dsadm      589  2.5  0.0  13420  2012 pts/0    Ss   18:36   0:00 bash</span><br><span class="line">dsadm      610  0.0  0.0  53340  1868 pts/0    R+   18:36   0:00 ps aux</span><br></pre></td></tr></table></figure></p>
<p>If all things are in good shape, save the image into tar.gz format, of course you can use a new tag before saving:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker save is-engine-image:1 | gzip &gt; ~/nonroot_is_engine.tar.gz</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that there is a <code>gzip</code> to compress the image.</p>
</blockquote>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>entry point</tag>
        <tag>docker commit</tag>
        <tag>docker save</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Image Default Parameters</title>
    <url>/2019/05/15/docker-image-default/</url>
    <content><![CDATA[<p>This blog is a subsection from <a href="https://chengdol.github.io/2019/05/15/docker-run/" target="_blank" rel="noopener"><code>&lt;&lt;Docker Run Reference&gt;&gt;</code></a>.</p>
<p>When a developer builds an image from a Dockerfile or when commits it, the developer can set a number of default parameters that take effect when the image starts up as a container.</p>
<p>Four of the Dockerfile commands cannot be overridden at runtime: <code>FROM</code>, <code>MAINTAINER</code>, <code>RUN</code>, and <code>ADD</code>. Everything else has a corresponding override in <code>docker run</code>.</p>
<h2 id="CMD-default-command-or-options"><a href="#CMD-default-command-or-options" class="headerlink" title="CMD [default command or options]"></a>CMD [default command or options]</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]</span><br></pre></td></tr></table></figure>
<p>This command is optional because the person who created the IMAGE may have already provided a default <code>COMMAND</code> using the Dockerfile <code>CMD</code> instruction. </p>
<p>If the image also specifies an <code>ENTRYPOINT</code> then the <code>CMD</code> or <code>COMMAND</code> get appended as arguments to the <code>ENTRYPOINT</code>(see nect section).</p>
<p>For example, we override the <code>CMD</code> in busybox by <code>/bin/sh -c ls -ltr</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -it --rm  busybox /bin/sh -c ls -ltr</span><br></pre></td></tr></table></figure></p>
<p>You can use<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect -f &quot;&#123;&#123;.Config.Cmd&#125;&#125;&quot; busybox</span><br></pre></td></tr></table></figure></p>
<p>to check the default <code>CMD</code> in image, it shows the default <code>CMD</code> for busybox is <code>[sh]</code>. If you override it by <code>/bin/sh -c ls -ltr</code> like above example, then you run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker ps -a --no-trunc</span><br></pre></td></tr></table></figure></p>
<p>You can see under the <code>COMMAND</code> column, it changes to <code>/bin/sh -c ls -ltr</code>, easy to verify.</p>
<h2 id="ENTRYPOINT-default-command-to-execute-at-runtime"><a href="#ENTRYPOINT-default-command-to-execute-at-runtime" class="headerlink" title="ENTRYPOINT [default command to execute at runtime]"></a>ENTRYPOINT [default command to execute at runtime]</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--entrypoint=&quot;&quot;: Overwrite the default entrypoint set by the image</span><br></pre></td></tr></table></figure>
<p>The <code>ENTRYPOINT</code> of an image is similar to a <code>COMMAND</code> because it specifies what executable to run when the container starts, but it is (purposely) more difficult to override. The <code>ENTRYPOINT</code> gives a container its default nature or behavior, so that when you set an ENTRYPOINT you can run the container as if it was that binary, complete with default options, and you can pass in more options via the <code>COMMAND</code>.</p>
<p>you can check the default entrypoint of a image by:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect -f &quot;&#123;&#123;.Config.Entrypoint&#125;&#125;&quot; is-services-image:1</span><br></pre></td></tr></table></figure></p>
<p>If I want to override the default one and pass parameters <code>tail -f /dev/null</code> to entrypoint <code>/bin/bash</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d --entrypoint=/bin/bash is-services-image:1 -c &quot;tail -f /dev/null&quot;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: Passing <code>--entrypoint</code> will clear out any default command set on the image</p>
</blockquote>
<h2 id="EXPOSE-incoming-ports"><a href="#EXPOSE-incoming-ports" class="headerlink" title="EXPOSE [incoming ports]"></a>EXPOSE [incoming ports]</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--expose=[]: Expose a port or a range of ports inside the container.</span><br><span class="line">             These are additional to those exposed by the `EXPOSE` instruction</span><br><span class="line">-P         : Publish all exposed ports to the host interfaces</span><br><span class="line">-p=[]      : Publish a container&apos;s port or a range of ports to the host</span><br><span class="line">               format: ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort | containerPort</span><br><span class="line">               Both hostPort and containerPort can be specified as a</span><br><span class="line">               range of ports. When specifying ranges for both, the</span><br><span class="line">               number of container ports in the range must match the</span><br><span class="line">               number of host ports in the range, for example:</span><br><span class="line">                   -p 1234-1236:1234-1236/tcp</span><br><span class="line"></span><br><span class="line">               When specifying a range for hostPort only, the</span><br><span class="line">               containerPort must not be a range.  In this case the</span><br><span class="line">               container port is published somewhere within the</span><br><span class="line">               specified hostPort range. (e.g., `-p 1234-1236:1234/tcp`)</span><br><span class="line"></span><br><span class="line">               (use &apos;docker port&apos; to see the actual mapping)</span><br><span class="line"></span><br><span class="line">--link=&quot;&quot;  : Add link to another container (&lt;name or id&gt;:alias or &lt;name or id&gt;)</span><br></pre></td></tr></table></figure>
<p>With the exception of the <code>EXPOSE</code> directive, an image developer hasn’t got much control over networking. The <code>EXPOSE</code> instruction defines the initial <strong>incoming</strong> ports (listens on specific network ports) that provide services. These ports are available to processes inside the container. An operator can use the –expose option to add to the exposed ports.</p>
<blockquote>
<p><code>EXPOSE</code> will not allow communication via the defined ports to containers outside of the same network or to the host machine. To allow this to happen you need to publish the ports.</p>
</blockquote>
<p>To expose a container’s internal port, an operator can start the container with the <code>-P</code> or <code>-p</code> flag. The exposed port is accessible on the host and the ports are available to any client that can reach the host.</p>
<blockquote>
<p>Note that in K8s, if the pods in the same namespace, the pods can communicate with each others if the ports are running, no additional setting needed except you want to access the applications from outside the cluster.</p>
</blockquote>
<h2 id="USER"><a href="#USER" class="headerlink" title="USER"></a>USER</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-u=&quot;&quot;, --user=&quot;&quot;: Sets the username or UID used and optionally the groupname or GID for the specified command.</span><br><span class="line"></span><br><span class="line">The followings examples are all valid:</span><br><span class="line">--user=[ user | user:group | uid | uid:gid | user:gid | uid:group ]</span><br></pre></td></tr></table></figure>
<p>root (id = 0) is the <strong>default</strong> user within a container. The image developer can create additional users. Those users are accessible by name. When passing a numeric ID, the user does not have to exist in the container.</p>
<h2 id="ENV-environment-variables"><a href="#ENV-environment-variables" class="headerlink" title="ENV [environment variables]"></a>ENV [environment variables]</h2><p>Docker automatically sets some environment variables when creating a Linux container. Docker does not set any environment variables when creating a Windows container.</p>
<p>The following environment variables are set for Linux containers:</p>
<ul>
<li>HOME: Set based on the value of USER</li>
<li>HOSTNAME: The hostname associated with the container</li>
<li>PATH: Includes popular directories, for example:<br><code>/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</code></li>
<li>TERM: xterm if the container is allocated a pseudo-TTY</li>
</ul>
<p>Additionally, the operator can set any environment variable in the container by using one or more <code>-e</code> flags, even overriding those mentioned above, or already defined by the developer with a Dockerfile <code>ENV</code>. If the operator names an environment variable without specifying a value, then the current value of the named variable is propagated into the container’s environment.</p>
<h2 id="VOLUME-shared-filesystems"><a href="#VOLUME-shared-filesystems" class="headerlink" title="VOLUME [shared filesystems]"></a>VOLUME [shared filesystems]</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-v, --volume=[host-src:]container-dest[:&lt;options&gt;]: Bind mount a volume.</span><br><span class="line">The comma-delimited `options` are [rw|ro], [z|Z],</span><br><span class="line">[[r]shared|[r]slave|[r]private], and [nocopy].</span><br><span class="line">The &apos;host-src&apos; is an absolute path or a name value.</span><br><span class="line"></span><br><span class="line">If neither &apos;rw&apos; or &apos;ro&apos; is specified then the volume is mounted in</span><br><span class="line">read-write mode.</span><br><span class="line"></span><br><span class="line">The `nocopy` mode is used to disable automatically copying the requested volume</span><br><span class="line">path in the container to the volume storage location.</span><br><span class="line">For named volumes, `copy` is the default mode. Copy modes are not supported</span><br><span class="line">for bind-mounted volumes.</span><br><span class="line"></span><br><span class="line">--volumes-from=&quot;&quot;: Mount all volumes from the given container(s)</span><br></pre></td></tr></table></figure>
<p>The volumes commands are complex enough to have their own <a href="https://docs.docker.com/storage/volumes/" target="_blank" rel="noopener">documentation</a>. </p>
<p>he <code>container-dest</code> must always be an absolute path such as <code>/src/docs</code>. The <code>host-src</code> can either be an absolute path or a name value. If you supply an absolute path for the <code>host-src</code>, Docker bind-mounts to the path you specify. If you supply a name, Docker creates a named volume by that name.</p>
<p>For example, you can specify either <code>/foo</code> or <code>foo</code> for a <code>host-src</code> value. If you supply the <code>/foo</code> value, Docker creates a bind mount. If you supply the <code>foo</code> specification, Docker creates a named volume.</p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p><a href="https://docs.docker.com/engine/reference/run/" target="_blank" rel="noopener">Docker run reference</a><br><a href="https://docs.docker.com/engine/reference/builder/#understand-how-cmd-and-entrypoint-interact" target="_blank" rel="noopener">Dockerfile reference</a><br><a href="https://medium.freecodecamp.org/expose-vs-publish-docker-port-commands-explained-simply-434593dbc9a3" target="_blank" rel="noopener">Expose vs publish: Docker port commands explained simply</a></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Podman</title>
    <url>/2020/02/26/docker-podman/</url>
    <content><![CDATA[<p><a href="https://podman.io/" target="_blank" rel="noopener"><code>Podman</code></a> is a pod manager tool, a daemonless container engine for developing, managing, and running OCI Containers on your Linux System. Containers can either be run as <strong>root</strong> or in <strong>rootless</strong> mode. Simply put: <code>alias docker=podman</code>.</p>
<blockquote>
<p>实际使用中发现podman commit命令和docker格式有不同，且commit后的image使用上有不正常的地方，比如HOSTNAME不见了。</p>
</blockquote>
<p><a href="https://github.com/containers/buildah/tree/master/docs/containertools" target="_blank" rel="noopener"><code>Container tool guide</code></a>, it shows the difference between <code>buildha</code> and <code>podman</code>:</p>
<p>Both Buildah and Podman are command line tools that work on OCI images and containers. The two projects differentiate in their specialization.</p>
<p>Buildah specializes in building OCI images. Buildah’s commands replicate all of the commands that are found in a Dockerfile. Buildah’s goal is also to provide a lower level coreutils interface to build images, allowing people to build containers without requiring a Dockerfile. The intent with Buildah is to allow other scripting languages to build container images, without requiring a daemon.</p>
<p>Podman specializes in all of the commands and functions that help you to maintain and modify OCI images, such as pulling and tagging. It also allows you to create, run, and maintain containers created from those images.</p>
<p>A major difference between Podman and Buildah is their concept of a container. Podman allows users to create “traditional containers” where the intent of these containers is to be long lived. While Buildah containers are really just created to allow content to be added back to the container image. An easy way to think of it is the buildah run command emulates the RUN command in a Dockerfile while the podman run command emulates the docker run command in functionality. Because of this you cannot see Podman containers from within Buildah or vice versa.</p>
<blockquote>
<p>so buildah mainly is used to <strong>build</strong> images (to build images you need to run containers before commit updates), podman is used to <strong>run</strong> container in production environment.</p>
</blockquote>
<p>In short Buildah is an efficient way to create OCI images while Podman allows you to manage and maintain those images and containers in a production environment using familiar container cli commands.</p>
<blockquote>
<p>Some commands overlaps between the projecs</p>
</blockquote>
<p>Let’s see some example when I was working on deploy ds assembly on portworx:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install podman in redhat/centos</span></span><br><span class="line">yum install podman -y</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same as docker login</span></span><br><span class="line">podman login -u &lt;user name&gt; -p &lt;password&gt; docker.io</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same as docker pull/tag/push</span></span><br><span class="line">podman pull k8s.gcr.io/pause:3.1</span><br><span class="line">podman tag k8s.gcr.io/pause:3.1 &lt;regisrty path&gt;/pause:3.1</span><br><span class="line"></span><br><span class="line"><span class="comment">## --tls-verify=false </span></span><br><span class="line"><span class="comment">## disable HTTPS and verify certificates when contacting registry</span></span><br><span class="line"><span class="comment">## you may also need is when login</span></span><br><span class="line">podman push &lt;registry path&gt;/pause:3.1 --tls-verify=<span class="literal">false</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>podman</tag>
      </tags>
  </entry>
  <entry>
    <title>Drone View</title>
    <url>/2019/12/04/drone-view/</url>
    <content><![CDATA[<p>2019年12月4日，我拿到了DJI Mavic 2 Pro，其他配件正在陆续抵达中。很高兴，要开始一个体验生活的新分支了，并且是从一个前所未有的角度看世界。我准备用几年时间打造一个自己的channel，分享鸟瞰美景，记录足迹。很多东西要学，除了维护保养，操控，还有摄影，剪辑等等目前我也是几乎没有经验，Let’s go!</p>
<p>在这里我会记录一些关于无人机拍摄的技巧，以及其他相关的方面，当然，还有我的作品。<br>我想提醒的是无人机是一件复杂设备，前期学习很重要，否则会对产品，人身安全或其他财产造成伤害。</p>
<blockquote>
<p>02/01/2020 还未首飞😑，还在忙其他非常重要的事情！春天已经来了.</p>
</blockquote>
<blockquote>
<p>04/09/2020 还未首飞😌，新冠肺炎疫情爆发了，重要的事情还没忙完！唉。。。</p>
</blockquote>
<p>Some references:<br><a href="https://www.youtube.com/watch?v=tYrnNYgbglY" target="_blank" rel="noopener">DJI mavic 2 pro beginner guide</a></p>
<h1 id="电池指南"><a href="#电池指南" class="headerlink" title="电池指南"></a>电池指南</h1><p>一定要仔细阅读大疆的电池手册，挺多注意事项的，总结一下:</p>
<h2 id="使用注意"><a href="#使用注意" class="headerlink" title="使用注意"></a>使用注意</h2><ol>
<li>禁止接触任何液体</li>
<li>不要使用非大疆官方电池</li>
<li>不要给abnormal电池充电</li>
<li>不要在电池turn on时从无人机上安装或拆卸</li>
<li>使用温度范围-10 ~ 40摄氏度，温度过高请自然冷却后使用</li>
<li>远离强电磁环境，可能损害电池控制板</li>
<li>不要重压</li>
<li>不要exhaust电池</li>
<li>注意电池的隔离，防止接口短路</li>
<li>飞行前确保电池充满</li>
</ol>
<h2 id="充电注意"><a href="#充电注意" class="headerlink" title="充电注意"></a>充电注意</h2><ol>
<li>使用大疆认证的充电器</li>
<li>充电前请turn off电池</li>
<li>不要在充电时离开</li>
<li>不要飞行后立马充电，防止温度过高，理想充电温度22 ~ 28摄氏度</li>
<li>大疆充电器会在充满后自己切断，但最好人为及时断开</li>
</ol>
<h2 id="存放注意"><a href="#存放注意" class="headerlink" title="存放注意"></a>存放注意</h2><ol>
<li>长期存贮确保充电至40 ~ 60%</li>
<li>不要在天热时将电池放在车内</li>
<li>电池在10天未使用时会自动发热放电至60%</li>
<li>每3个月至少完整充放电一次</li>
<li>电池存储温度-10 ~ 45摄氏度</li>
<li>长期不使用电池会休眠，充电唤醒</li>
<li>将电池从无人机上取下单独长期存放</li>
</ol>
<h2 id="旅行注意"><a href="#旅行注意" class="headerlink" title="旅行注意"></a>旅行注意</h2><ol>
<li>登机前，将电池释放至30%以下，可以通过飞行消耗实现</li>
</ol>
<h1 id="安全须知"><a href="#安全须知" class="headerlink" title="安全须知"></a>安全须知</h1><h2 id="飞行环境"><a href="#飞行环境" class="headerlink" title="飞行环境"></a>飞行环境</h2><ol>
<li>飞行远离复杂电磁环境</li>
<li>飞行高度在6000米以上可能影响性能</li>
<li>飞行环境温度:-10 ~ 40摄氏度</li>
<li>环境风速小于10m/s</li>
<li>注意所在地是否允许无人机飞行</li>
</ol>
<h2 id="飞前检查"><a href="#飞前检查" class="headerlink" title="飞前检查"></a>飞前检查</h2><ol>
<li>检查传感器无遮挡</li>
<li>遥控器以及无人机电池充满状态</li>
<li>电池安装正确牢固</li>
<li>螺旋桨臂正确展开</li>
<li>螺旋桨无破损，安装牢固</li>
<li>摄像头清洁无污染，伸缩旋转无阻碍</li>
<li>仅在设备要求时校准罗盘</li>
<li>熟悉选择的飞行模式，理解各项功能以及航行警报</li>
</ol>
<h2 id="飞行操作"><a href="#飞行操作" class="headerlink" title="飞行操作"></a>飞行操作</h2><ol>
<li>在智能飞行模式时，不要靠近强反射面，比如水面或雪地，传感器或受影响</li>
<li>降落后，首先关闭引擎，然后依次关闭电池，遥控器</li>
</ol>
]]></content>
      <categories>
        <category>Drone View</category>
      </categories>
      <tags>
        <tag>drone</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Registry Configure</title>
    <url>/2019/06/16/docker-registry-config/</url>
    <content><![CDATA[<p><a href="https://docs.docker.com/registry/configuration/" target="_blank" rel="noopener">https://docs.docker.com/registry/configuration/</a></p>
<p>if you change the setting in docker registry running container, try<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker restart &lt;container id&gt;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker registry</tag>
      </tags>
  </entry>
  <entry>
    <title>Skopeo</title>
    <url>/2019/09/26/docker-skopeo/</url>
    <content><![CDATA[<p><code>skopeo</code> is a command line utility that performs various operations on container images and image repositories. see it’s <a href="https://github.com/containers/skopeo" target="_blank" rel="noopener">git repos</a>. This is really a fantastic tool! Other two complementaries are <code>buildah</code> and <code>podman</code>.</p>
<p>Command usage see <a href="https://github.com/containers/skopeo/tree/master/docs" target="_blank" rel="noopener">here</a>.</p>
<p>In Red Hat/Centos, you can use <code>yum</code> to install skopeo.</p>
<blockquote>
<p>Note the docker registry should be secured by SSL/TLS, basic authentication can also apply.</p>
</blockquote>
<blockquote>
<p>Skopeo can do paralelly copy, you can run several skopeo processes in background then wait.</p>
</blockquote>
<h2 id="Docker-Installed"><a href="#Docker-Installed" class="headerlink" title="Docker Installed"></a>Docker Installed</h2><p>In docker environmet, skopeo will check <code>$HOME/.docker/config.json</code> file for authentication (created by docker login command). If the auth file is there, you are good and you can directly copy image tar (or gzip tar) to docker registry and copy image directly from docker registry to local docker daemon for example (can use docker hub to do test):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo copy \</span><br><span class="line">       docker-archive:&lt;absolute or relative path&gt;/&lt;tar name&gt;.tar.gz \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br><span class="line"></span><br><span class="line">skopeo copy \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag \</span><br><span class="line">       docker-daemon:&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<p>This is extremely efficient compare to old load/tag/push method. Many other benefits like no docker daemon needed, rootless please see doc.</p>
<p>Inspect docker image in registry:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo inspect \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<p>Delete image in registry<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo delete \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>You must enable deletion in docker registry <a href="https://docs.docker.com/registry/configuration/#override-specific-configuration-options" target="_blank" rel="noopener">configuration</a>: </p>
</blockquote>
<h2 id="No-Docker-Installed"><a href="#No-Docker-Installed" class="headerlink" title="No Docker Installed"></a>No Docker Installed</h2><p>If there is no docker daemon, skopeo will still work, but you need to explicitly give the auth creds and ssl/tls certificates path of the target registry, for example, the destination registry login user name and password are both <code>demo</code>, and the certificates path for ssl/tls is <code>/root/certs</code> (<strong>must</strong> include *.key, *.crt and *.cert, the *.crt and *.cert could be the same content if it’s self-signed).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo copy \</span><br><span class="line">       --dest-creds demo:demo \</span><br><span class="line">       --dest-cert-dir /root/certs \</span><br><span class="line">       docker-archive:&lt;absolute or relative path&gt;/&lt;tar name&gt;.tar.gz \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br><span class="line"></span><br><span class="line">skopeo copy \</span><br><span class="line">       --src-creds demo:demo \</span><br><span class="line">       --src-cert-dir /root/certs \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag \</span><br><span class="line">       docker-daemon:&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<p>Inspect docker image in registry:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo inspect \</span><br><span class="line">       --creds demo:demo \</span><br><span class="line">       --cert-dir /root/certs \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<p>Delete image in registry<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo delete \</span><br><span class="line">       --creds demo:demo \</span><br><span class="line">       --cert-dir /root/certs \</span><br><span class="line">       docker://&lt;registry&gt;[:5000]/&lt;image name&gt;:tag</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>You must enable deletion in docker registry <a href="https://docs.docker.com/registry/configuration/#override-specific-configuration-options" target="_blank" rel="noopener">configuration</a>: </p>
</blockquote>
<h2 id="Other-Use-Case"><a href="#Other-Use-Case" class="headerlink" title="Other Use Case"></a>Other Use Case</h2><p>One important use case is we pre-load image to target host machine because we pre-assign some application runs on some dedicated nodes. Pre-load will save much time from pull if the image is big, the application pod will up and run instantly.</p>
<p>So, how to copy image tarball from local to remote machine docker daemon? Yes there are <code>--src-daemon-host</code> and <code>--dest-daemon-host</code> options, but how?</p>
<p>Refer <a href="https://docs.docker.com/install/linux/linux-postinstall/#configure-where-the-docker-daemon-listens-for-connections" target="_blank" rel="noopener">document</a> from docker:<br>By default, the Docker daemon listens for connections on a <code>UNIX socket</code> to accept requests from local clients. It is possible to allow Docker to accept requests from remote hosts by configuring it to <code>listen</code> on an IP address and port as well as the UNIX socket.</p>
<p>So, let first open the port in target host:<br>It is conventional to use port <code>2375</code> for un-encrypted, and port <code>2376</code> for encrypted communication with the daemon.</p>
<blockquote>
<p>注意，这里我只考虑了un-encrypted，因为设置encrypted connection可能会影响kubelet对docker的操控，我在使用完后关闭了这一端口，并且如果集群有单独的网关且访问worker nodes的IP是内部的，影响也不大。</p>
</blockquote>
<p>Here we can configure remote access with <strong>systemd unit file</strong> or with <strong>daemon.json</strong>, I prefer the second one, because after systemd unit file update, I need to reload then restart docker:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></p>
<p>Using daemon json file only need to restart, just add this line to it:<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"hosts"</span>: [<span class="string">"unix:///var/run/docker.sock"</span>, <span class="string">"tcp://0.0.0.0:2375"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>You can listen on port <code>2375</code> on all network interfaces(eg: <code>0.0.0.0</code>), or on a particular network interface using its IP address(eg: <code>172.192.10.1</code>). </p>
<p>After restart docker service, check the port status:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">netstat -lntp | grep 2375</span><br></pre></td></tr></table></figure></p>
<p>Now we can execute copy:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skopeo copy \</span><br><span class="line">       --dest-daemon-host http://&lt;target machine hostname or ip&gt;:2375 \</span><br><span class="line">       docker-archive:&lt;path&gt;/&lt;image tarball name&gt;.tar.gz \</span><br><span class="line">       docker-daemon:&lt;image name&gt;:&lt;tag&gt;</span><br></pre></td></tr></table></figure></p>
<p>Check these articles:<br><a href="https://www.redhat.com/en/blog/skopeo-copy-rescue" target="_blank" rel="noopener">Skopeo Copy to the Rescue</a></p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>skopeo</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Run Reference</title>
    <url>/2019/05/15/docker-run/</url>
    <content><![CDATA[<p>This is a summary from <a href="https://docs.docker.com/engine/reference/run/#entrypoint-default-command-to-execute-at-runtime" target="_blank" rel="noopener">Docker run reference</a></p>
<p>Docker runs processes in isolated containers. <strong>A container is a process</strong> which runs on a host. The host may be local or remote. When an operator executes <code>docker run</code>, the container process that runs is isolated in that it has its own file system, its own networking, and its own isolated process tree separate from the host.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]</span><br></pre></td></tr></table></figure>
<p>The <code>docker run</code> command can override nearly all the defaults set by the Docker runtime itself.</p>
<p>Let’s first see the <code>docker run</code> command I encountered:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --detach \</span><br><span class="line">      --name=$&#123;DB2_XMETA_HOST&#125; \</span><br><span class="line">      --restart=always \</span><br><span class="line">      --privileged=false \</span><br><span class="line">      --cap-add=SYS_NICE --cap-add=IPC_OWNER --cap-add=SETFCAP  \</span><br><span class="line">      --user 1000 \</span><br><span class="line">      -e MY_POD_NAMESPACE=$&#123;MY_POD_NAMESPACE&#125; \</span><br><span class="line">      -e SHARED_VOL=$&#123;SHARED_REPOS_VOLPATH&#125; \</span><br><span class="line">      --hostname=$&#123;DB2_XMETA_HOST&#125; \</span><br><span class="line">      -p $&#123;DB2_XMETA_PORT&#125;:$&#123;DB2_XMETA_PORT&#125; \</span><br><span class="line">      -v $&#123;SHARED_VOL&#125;:$&#123;SHARED_VOL&#125; \</span><br><span class="line">      is-xmetadocker:11.7.1 \</span><br></pre></td></tr></table></figure></p>
<h2 id="Detched-d"><a href="#Detched-d" class="headerlink" title="Detched [-d]"></a>Detched [-d]</h2><p>To start a container in detached mode, you use <code>-d=true</code> or just <code>-d</code> option. By design, containers started in detached mode exit when the root process used to run the container exits, unless you also specify the <code>--rm</code> option. If you use <code>-d</code> with <code>--rm</code>, the container is removed when it exits or when the daemon exits, whichever happens first.</p>
<blockquote>
<p>This is why we specify <code>tail -f /dev/null</code> at end of start script in container.</p>
</blockquote>
<h2 id="Foreground"><a href="#Foreground" class="headerlink" title="Foreground"></a>Foreground</h2><p>In foreground mode (the default when <code>-d</code> is not specified), docker run can start the process in the container and attach the console to the process’s standard input, output, and standard error. It can even pretend to be a TTY (this is what most command line executables expect) and pass along signals.</p>
<p>For interactive processes (like a shell), you must use <code>-it</code> together in order to allocate a tty for the container process. </p>
<p>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -it --rm busybox /bin/sh</span><br></pre></td></tr></table></figure></p>
<p>This will directly open a shell to operate on container, once exit, container will be removed.</p>
<h2 id="Name-name"><a href="#Name-name" class="headerlink" title="Name [--name]"></a>Name [<code>--name</code>]</h2><p>Specify container name. If you do not assign a container name with the <code>--name</code> option, then the daemon generates a random string name for you. Defining a name can be a handy way to add meaning to a container.</p>
<h3 id="IPC-settings-ipc"><a href="#IPC-settings-ipc" class="headerlink" title="IPC settings [--ipc]"></a>IPC settings [<code>--ipc</code>]</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--ipc=&quot;MODE&quot;  : Set the IPC mode for the container</span><br></pre></td></tr></table></figure>
<p>IPC (POSIX/SysV IPC) namespace provides separation of named shared memory segments, semaphores and message queues.</p>
<p>Shared memory segments are used to accelerate inter-process communication at memory speed, rather than through pipes or through the network stack. </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--ipc=&lt;Value&gt;</span><br></pre></td></tr></table></figure>
<p>Value    Description</p>
<ul>
<li>“”:    Use daemon’s default.</li>
<li>“none”:    Own private IPC namespace, with /dev/shm not mounted.</li>
<li>“private”:    Own private IPC namespace.</li>
<li>“shareable”:Own private IPC namespace, with a possibility to share it with other containers.</li>
<li>“container: &lt;<em>name-or-ID</em>&gt;”: Join another (“shareable”) container’s IPC namespace.</li>
<li>“*host”: Use the host system’s IPC namespace.</li>
</ul>
<p>If not specified, daemon default is used, which can either be <code>private</code> or <code>shareable</code>, depending on the daemon version and configuration.</p>
<p>If these types of applications are broken into multiple containers, you might need to share the IPC mechanisms of the containers, using “shareable” mode for the main container, and <code>container:&lt;donor-name-or-ID&gt;</code> for other containers.</p>
<h2 id="Network-settings"><a href="#Network-settings" class="headerlink" title="Network settings"></a>Network settings</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--dns=[]           : Set custom dns servers for the container</span><br><span class="line">--network=&quot;bridge&quot; : Connect a container to a network</span><br><span class="line">                      &apos;bridge&apos;: create a network stack on the default Docker bridge</span><br><span class="line">                      &apos;none&apos;: no networking</span><br><span class="line">                      &apos;container:&lt;name|id&gt;&apos;: reuse another container&apos;s network stack</span><br><span class="line">                      &apos;host&apos;: use the Docker host network stack</span><br><span class="line">                      &apos;&lt;network-name&gt;|&lt;network-id&gt;&apos;: connect to a user-defined network</span><br><span class="line">--network-alias=[] : Add network-scoped alias for the container</span><br><span class="line">--add-host=&quot;&quot;      : Add a line to /etc/hosts (host:IP)</span><br><span class="line">--mac-address=&quot;&quot;   : Sets the container&apos;s Ethernet device&apos;s MAC address</span><br><span class="line">--ip=&quot;&quot;            : Sets the container&apos;s Ethernet device&apos;s IPv4 address</span><br><span class="line">--ip6=&quot;&quot;           : Sets the container&apos;s Ethernet device&apos;s IPv6 address</span><br><span class="line">--link-local-ip=[] : Sets one or more container&apos;s Ethernet device&apos;s link local IPv4/IPv6 addresses</span><br></pre></td></tr></table></figure>
<p>I meet <code>--add-host</code> flag in service docker:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--add-host=&quot;$&#123;SERVICES_HOST&#125; $&#123;DB2_XMETA_HOST&#125; $&#123;ENGINE_HOST&#125;&quot;:$&#123;SERVICES_HOST_IP&#125; \</span><br></pre></td></tr></table></figure></p>
<h2 id="Restart-policies-restart"><a href="#Restart-policies-restart" class="headerlink" title="Restart policies (--restart)"></a>Restart policies (<code>--restart</code>)</h2><p>Using the <code>--restart</code> flag on Docker run you can specify a restart policy for how a container should or should not be restarted on exit.</p>
<p>When a restart policy is active on a container, it will be shown as either <code>Up</code> or <code>Restarting</code> in <code>docker ps</code>.</p>
<h2 id="Exit-Status"><a href="#Exit-Status" class="headerlink" title="Exit Status"></a>Exit Status</h2><p>The exit code from <code>docker run</code> gives information about why the container failed to run or why it exited. When <code>docker run</code> exits with a non-zero code, the exit codes follow the chroot standard.</p>
<h2 id="Clean-up-rm"><a href="#Clean-up-rm" class="headerlink" title="Clean up [--rm]"></a>Clean up [<code>--rm</code>]</h2><p>By default a container’s file system persists even after the container exits. This makes debugging a lot easier (since you can inspect the final state) and you retain all your data by default. But if you are running <strong>short-term</strong> foreground processes, these container file systems can really pile up. If instead you’d like Docker to automatically clean up the container and remove the file system when the container exits, you can add the <code>--rm</code> flag.</p>
<h2 id="HOSTNAME-hostname"><a href="#HOSTNAME-hostname" class="headerlink" title="HOSTNAME [--hostname]"></a>HOSTNAME [<code>--hostname</code>]</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">--hostname=&quot;xxx&quot;		Container host name</span><br></pre></td></tr></table></figure>
<p>Set the hostname of the container.</p>
<h2 id="Runtime-privilege-and-Linux-capabilities"><a href="#Runtime-privilege-and-Linux-capabilities" class="headerlink" title="Runtime privilege and Linux capabilities"></a>Runtime privilege and Linux capabilities</h2><p>I separate this section to the blog <a href="https://chengdol.github.io/2019/05/15/docker-capability/" target="_blank" rel="noopener"><code>&lt;&lt;Docker Capability&gt;&gt;</code></a> since it’s important to me.</p>
<h2 id="Logging-drivers-log-driver"><a href="#Logging-drivers-log-driver" class="headerlink" title="Logging drivers [--log-driver]"></a>Logging drivers [<code>--log-driver</code>]</h2><p>The container can have a different logging driver than the Docker daemon. Use the <code>--log-driver=VALUE</code> with the <code>docker run</code> command to configure the container’s logging driver.</p>
<p>Default logging driver is json format. The <code>docker logs</code> command is available only for the <code>json-file</code> and <code>journald</code> logging drivers.</p>
<h2 id="Overriding-Dockerfile-image-defaults"><a href="#Overriding-Dockerfile-image-defaults" class="headerlink" title="Overriding Dockerfile image defaults"></a>Overriding Dockerfile image defaults</h2><p>I separate this section to the blog <a href="https://chengdol.github.io/2019/05/15/docker-image-default/" target="_blank" rel="noopener"><code>&lt;&lt;Docker Image Defaults&gt;&gt;</code></a> since it’s important to me.</p>
<h2 id="p"><a href="#p" class="headerlink" title="-p"></a>-p</h2><p>Remember, the first part of the -p value is the host port and the second part is the port within the container</p>
<h2 id="VOLUME-shared-filesystems"><a href="#VOLUME-shared-filesystems" class="headerlink" title="VOLUME (shared filesystems)"></a>VOLUME (shared filesystems)</h2><p>When use <code>-v</code> option binds mount a volume from host machine to inside container, if the container originally has contents inside the mount target folder, they will all be removed when mount and replaced by contents from source host machine folder.</p>
<blockquote>
<p>Note that <code>docker commit</code> will not include any data contained in volumes mounted inside the container.</p>
</blockquote>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Create Working Branch</title>
    <url>/2019/09/12/git-create-working-branch/</url>
    <content><![CDATA[<p>Let me record the workflow about how to create your own working branch from master.</p>
<p>I <code>git clone</code> the original repo to local, then <code>git checkout -b</code> to a <code>develop</code> branch based on the <code>master</code> branch, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(cd /GitRepos; git clone git@github.xxx.com:xxx.git)</span><br></pre></td></tr></table></figure></p>
<p>then go to local git repository<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git checkout -b develop</span><br></pre></td></tr></table></figure></p>
<p>After checkout to new branch, if you do nothing and get files changed, this is sometimes a format issue, go to edit <code>.gitattributes</code>, comment out the regex, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># * text=auto</span><br></pre></td></tr></table></figure></p>
<p>Save and run <code>git status</code>, you will see the change now is on <code>.gitattributes</code>, then undo the change and save.</p>
<p>Now you are in <code>develop</code> branch, let’s check the config information:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --list</span><br></pre></td></tr></table></figure></p>
<p>Focus on the <code>user.name</code> and <code>user.email</code>, if they are empty, set them by<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --global user.name xxx</span><br><span class="line">git config --global user.email xxx</span><br><span class="line">git commit --amend --reset-author</span><br></pre></td></tr></table></figure></p>
<p>Then working on <code>develop</code> branch, when you run <code>git push origin develop</code>, this will create a pull request (you can decide merge to which branch) and a remote <code>develop</code> branch at first time, then you can review and merge to <code>master</code> branch on git web.</p>
<p>Because there is no git repos fork, so run <code>git pull origin master</code> in <code>develop</code> branch to get sync up with latest updates from <code>master</code> branch.</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Set up Secure Docker Registry Container</title>
    <url>/2019/06/16/docker-secure-registry/</url>
    <content><![CDATA[<p>This post is about configuring secure docker registry as <strong>docker container</strong>, check <a href="https://chengdol.github.io/2020/01/06/k8s-secure-registry/" target="_blank" rel="noopener">this</a> for setting up secure docker registry pod in K8s. </p>
<blockquote>
<p>More about SSL please check my blog <a href="https://chengdol.github.io/2019/11/29/ssl-demystify/" target="_blank" rel="noopener"><code>SSL Demystify</code></a>. It contains the theory, workflow and practice.</p>
</blockquote>
<p>Securing access to your hosted images is paramount, the registry natively supports <code>TLS</code> and <code>basic authentication</code>, let’s do it.</p>
<p>The Registry GitHub repository includes additional information about advanced authentication and authorization methods. Only very large or public deployments are expected to extend the Registry in this way.</p>
<p>Finally, the Registry ships with a robust notification system, calling webhooks in response to activity, and both extensive logging and reporting, mostly useful for large installations that want to collect metrics.</p>
<h2 id="Generate-Self-signed-Certificate"><a href="#Generate-Self-signed-Certificate" class="headerlink" title="Generate Self-signed Certificate"></a>Generate Self-signed Certificate</h2><p>See <a href="(https://docs.docker.com/registry/deploying/#run-an-externally-accessible-registry">document</a>) from docker.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/certs</span><br><span class="line"></span><br><span class="line"><span class="comment">## generate domain.key and self-signed domain.crt</span></span><br><span class="line"><span class="comment">## I use -days 3650</span></span><br><span class="line">openssl req \</span><br><span class="line">      -newkey rsa:4096 -nodes -x509 -sha256\</span><br><span class="line">      -keyout certs/domain.key -out certs/domain.crt -days 3650 \</span><br><span class="line">      -subj <span class="string">"/C=US/ST=CA/L=San Jose/O=&lt;Company Name&gt;/OU=Org/CN=chengdol.registry.com"</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Notice that the <code>CN=chengdol.registry.com</code> must be the registry access url, no port number suffix needed.</p>
</blockquote>
<p>Parameters explanation from <a href="https://linux.die.net/man/1/req" target="_blank" rel="noopener">here</a>:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">openssl</span> <span class="attr">req:</span> </span><br><span class="line">  <span class="string">The</span> <span class="string">req</span> <span class="string">command</span> <span class="string">primarily</span> <span class="string">creates</span> <span class="string">and</span> <span class="string">processes</span> <span class="string">certificate</span> <span class="string">requests</span> <span class="string">in</span> <span class="string">PKCS#10</span> <span class="string">format.</span> <span class="string">It</span> <span class="string">can</span> <span class="string">additionally</span> <span class="string">create</span> <span class="string">self</span> <span class="string">signed</span> <span class="string">certificates</span> <span class="string">for</span> <span class="string">use</span> <span class="string">as</span> <span class="string">root</span> <span class="string">CAs</span> <span class="string">for</span> <span class="string">example.</span></span><br><span class="line"><span class="attr">-newkey:</span> </span><br><span class="line">   <span class="string">this</span> <span class="string">option</span> <span class="string">creates</span> <span class="string">a</span> <span class="string">new</span> <span class="string">certificate</span> <span class="string">request</span> <span class="string">and</span> <span class="string">a</span> <span class="string">new</span> <span class="string">private</span> <span class="string">key.</span> </span><br><span class="line"><span class="attr">  rsa:</span><span class="attr">nbits:</span> </span><br><span class="line">    <span class="string">where</span> <span class="string">nbits</span> <span class="string">is</span> <span class="string">the</span> <span class="string">number</span> <span class="string">of</span> <span class="string">bits,</span> <span class="string">generates</span> <span class="string">an</span> <span class="string">RSA</span> <span class="string">key</span> <span class="string">nbits</span> <span class="string">in</span> <span class="string">size.</span></span><br><span class="line"><span class="attr">-nodes:</span></span><br><span class="line">  <span class="string">if</span> <span class="string">this</span> <span class="string">option</span> <span class="string">is</span> <span class="string">specified</span> <span class="string">then</span> <span class="string">if</span> <span class="string">a</span> <span class="string">private</span> <span class="string">key</span> <span class="string">is</span> <span class="string">created</span> <span class="string">it</span> <span class="string">will</span> <span class="string">not</span> <span class="string">be</span> <span class="string">encrypted.</span></span><br><span class="line"><span class="attr">-x509:</span> </span><br><span class="line">  <span class="string">this</span> <span class="string">option</span> <span class="string">outputs</span> <span class="string">a</span> <span class="string">self</span> <span class="string">signed</span> <span class="string">certificate</span> <span class="string">instead</span> <span class="string">of</span> <span class="string">a</span> <span class="string">certificate</span> <span class="string">request.</span> <span class="string">This</span> <span class="string">is</span> <span class="string">typically</span> <span class="string">used</span> <span class="string">to</span> <span class="string">generate</span> <span class="string">a</span> <span class="string">test</span> <span class="string">certificate</span> <span class="string">or</span> <span class="string">a</span> <span class="string">self</span> <span class="string">signed</span> <span class="string">root</span> <span class="string">CA</span> <span class="string">.</span></span><br><span class="line"><span class="bullet">-</span><span class="string">[digest]:</span></span><br><span class="line">  <span class="string">this</span> <span class="string">specifies</span> <span class="string">the</span> <span class="string">message</span> <span class="string">digest</span> <span class="string">to</span> <span class="string">sign</span> <span class="string">the</span> <span class="string">request</span> <span class="string">with</span> <span class="string">(such</span> <span class="string">as</span> <span class="bullet">-md5,</span> <span class="bullet">-sha1,</span> <span class="bullet">-sha256)</span></span><br><span class="line"><span class="attr">-keyout:</span></span><br><span class="line">  <span class="string">this</span> <span class="string">gives</span> <span class="string">the</span> <span class="string">filename</span> <span class="string">to</span> <span class="string">write</span> <span class="string">the</span> <span class="string">newly</span> <span class="string">created</span> <span class="string">private</span> <span class="string">key</span> <span class="string">to.</span></span><br><span class="line"><span class="attr">-out:</span></span><br><span class="line">  <span class="string">this</span> <span class="string">specifies</span> <span class="string">the</span> <span class="string">output</span> <span class="string">filename</span> <span class="string">to</span> <span class="string">write</span> <span class="string">to</span> <span class="string">or</span> <span class="string">standard</span> <span class="string">output</span> <span class="string">by</span> <span class="string">default.</span></span><br><span class="line"><span class="attr">-days:</span></span><br><span class="line">  <span class="string">when</span> <span class="string">the</span> <span class="bullet">-x509</span> <span class="string">option</span> <span class="string">is</span> <span class="string">being</span> <span class="string">used</span> <span class="string">this</span> <span class="string">specifies</span> <span class="string">the</span> <span class="string">number</span> <span class="string">of</span> <span class="string">days</span> <span class="string">to</span> <span class="string">certify</span> <span class="string">the</span> <span class="string">certificate</span> <span class="string">for.</span> <span class="string">The</span> <span class="string">default</span> <span class="string">is</span> <span class="number">30</span> <span class="string">days.</span></span><br><span class="line"><span class="attr">-subj:</span></span><br><span class="line">  <span class="string">replaces</span> <span class="string">subject</span> <span class="string">field</span> <span class="string">of</span> <span class="string">input</span> <span class="string">request</span> <span class="string">with</span> <span class="string">specified</span> <span class="string">data</span> <span class="string">and</span> <span class="string">outputs</span> <span class="string">modified</span> <span class="string">request.</span> <span class="string">The</span> <span class="string">arg</span> <span class="string">must</span> <span class="string">be</span> <span class="string">formatted</span> <span class="string">as</span> <span class="string">/type0=value0/type1=value1/type2=...,</span> <span class="string">characters</span> <span class="string">may</span> <span class="string">be</span> <span class="string">escaped</span> <span class="string">by</span> <span class="string">\</span> <span class="string">(backslash),</span> <span class="literal">no</span> <span class="string">spaces</span> <span class="string">are</span> <span class="string">skipped.</span></span><br></pre></td></tr></table></figure></p>
<p>Also know that there are mutli-way to do the same thing:<br>Create a private key and then generate a certificate request from it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openssl genrsa -out key.pem 1024</span><br><span class="line">openssl req -new -key key.pem -out req.pem</span><br></pre></td></tr></table></figure></p>
<p>The same but just using <code>req</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openssl req -newkey rsa:1024 -keyout key.pem -out req.pem</span><br></pre></td></tr></table></figure></p>
<p>Generate a self signed root certificate:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openssl req -x509 -newkey rsa:1024 -keyout key.pem -out req.pem</span><br></pre></td></tr></table></figure></p>
<h2 id="Setup-Secure-Docker-Registry"><a href="#Setup-Secure-Docker-Registry" class="headerlink" title="Setup Secure Docker Registry"></a>Setup Secure Docker Registry</h2><p>see <a href="https://docs.docker.com/registry/deploying/#run-the-registry-as-a-service" target="_blank" rel="noopener">document</a> from docker.</p>
<p>We have the <code>certs</code> folder with crt and key created by openssl.<br>Start the docker registry container, using TLS certificate:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --restart=always \</span><br><span class="line">  --name registry \</span><br><span class="line">  -v /root/certs:/certs \</span><br><span class="line">  -e REGISTRY_HTTP_ADDR=0.0.0.0:443 \</span><br><span class="line">  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \</span><br><span class="line">  -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \</span><br><span class="line">  -p 443:443 \</span><br><span class="line">  registry:2</span><br></pre></td></tr></table></figure></p>
<p>Here we overwrite some env variables to change the default configuration.</p>
<p>Also follow the instruction in docker web, instruct <code>every</code> docker daemon to trust that certificate. The way to do this depends on your OS, for Linux:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/docker/certs.d/&lt;docker registry domain&gt;/</span><br><span class="line"><span class="comment">## copy domain.crt (generate by openssl) to this folder on every Docker host</span></span><br><span class="line">cp /root/certs/domain.crt /etc/docker/certs.d/&lt;docker registry domain&gt;/</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意，Docker官方文档中用的是<code>&lt;docker registry domain&gt;:5000/</code>文件夹名，但如果你配置的是443端口,则会出错，通过Docker daemon中的log，发现对于443端口，这里不需要<code>:5000</code>. 但如果设置了basic authentication且用的是5000端口，则需要了。</p>
</blockquote>
<blockquote>
<p>当时还发生了奇怪的事情，我发现不需要这个trust操作居然也能进行push，后来才发现原来是旧配置在docker daemon json 文件中设置了insecure registry，这样一来根本就不会检查证书了。</p>
</blockquote>
<p>If you don’t do this, when run docker push you will get this error:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Error response from daemon: Get https://chengdol.registry.com/v2/: x509: certificate signed by unknown authority</span><br></pre></td></tr></table></figure></p>
<p>If docker still complains about the certificate when using authentication?<br>When using authentication, some versions of Docker also require you to trust the certificate at the OS level.</p>
<p>For RedHat, do:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp certs/domain.crt /etc/pki/ca-trust/<span class="built_in">source</span>/anchors/myregistrydomain.com.crt</span><br><span class="line">update-ca-trust</span><br></pre></td></tr></table></figure></p>
<p>Now you can push and pull like, no need to specify port number, it will use 443 port:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull ubuntu</span><br><span class="line">docker tag ubuntu chengdol.registry.com/ubuntu:v1</span><br><span class="line">docker push chengdol.registry.com/ubuntu:v1</span><br><span class="line">docker pull chengdol.registry.com/ubuntu:v1</span><br></pre></td></tr></table></figure></p>
<p>So far, secure configuration is done, now the docker registry will use <code>HTTPS</code> in <code>443</code> port to communciate with docker client. If you want to also setup basic authentication, see below:</p>
<h2 id="Setup-Basic-Authrntication"><a href="#Setup-Basic-Authrntication" class="headerlink" title="Setup Basic Authrntication"></a>Setup Basic Authrntication</h2><blockquote>
<p>Warning: You cannot use authentication with authentication schemes that send credentials as clear text. You <strong>must</strong> configure <code>TLS</code> first for authentication to work.</p>
</blockquote>
<p>Use <code>htpasswd</code> to create the user info:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/auth</span><br><span class="line">htpasswd -Bbn demo demo &gt; /root/auth/htpasswd</span><br></pre></td></tr></table></figure></p>
<p>Then, we switch back to <code>5000</code> port: (注意这里没用443端口)<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  -p 5000:5000 \</span><br><span class="line">  --restart=always \</span><br><span class="line">  --name registry \</span><br><span class="line">  -v /root/auth:/auth \</span><br><span class="line">  -e &quot;REGISTRY_AUTH=htpasswd&quot; \</span><br><span class="line">  -e &quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm&quot; \</span><br><span class="line">  -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd \</span><br><span class="line">  -v /root/certs:/certs \</span><br><span class="line">  -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/domain.crt \</span><br><span class="line">  -e REGISTRY_HTTP_TLS_KEY=/certs/domain.key \</span><br><span class="line">  registry:2</span><br></pre></td></tr></table></figure></p>
<p>Do the same trust thing in <code>every</code> docker host, under <code>/etc/docker/certs.d/</code> directory, we create a folder <code>&lt;docker registry domain&gt;:5000</code> and put domain.crt in it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/docker/certs.d/&lt;docker registry domain&gt;:5000/</span><br><span class="line"><span class="comment">## copy domain.crt (generate by openssl) to this folder on every Docker host</span></span><br><span class="line">cp domain.crt /etc/docker/certs.d/&lt;docker registry domain&gt;:5000/</span><br></pre></td></tr></table></figure></p>
<p>Then, you need to first login to push or pull:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker login &lt;docker registry domain&gt;:5000 -u demo -p demo</span><br></pre></td></tr></table></figure></p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>OK, now a secure docker registry container with basic authentication is up and running. You can push and pull after docker login.</p>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Clean Local Working Branch</title>
    <url>/2019/06/28/git-clean-reset/</url>
    <content><![CDATA[<p>Sometimes if the local working branch mess up and you want to sync up with your remote branch, for example origin master:</p>
<p>First remove all untracked files:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clean -df</span><br></pre></td></tr></table></figure></p>
<p>you can have a dry-run first to see what files will be removed<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clean -dfn</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note <code>git clean -dfx</code> will remove ignored files as well!</p>
</blockquote>
<p>Check the commit logs:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git log --oneline --color -n 10</span><br></pre></td></tr></table></figure></p>
<p>This will list latest 20 commits<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2065fc4 Merge branch &apos;master&apos; of github.ibm.com:InformationServer/cognitive-designer-api into chengdol_master</span><br><span class="line">980c539 disable git pull prompt message</span><br><span class="line">b508666 Merge pull request #7576 from InformationServer/b_kannu</span><br><span class="line">6d4b450 updating python and python-libs version for baseosimages</span><br><span class="line">8e68090 Merge pull request #7575 from InformationServer/issue7377</span><br><span class="line">8e3f0fa Merge pull request #7558 from InformationServer/Henry-FixDupValidation</span><br><span class="line">1fd5a7a Merge branch &apos;master&apos; into issue7377</span><br><span class="line">84472b1 Improve testcase</span><br><span class="line">3ea5bf8 Merge pull request #7571 from InformationServer/chu_template_changes_7529</span><br><span class="line">60551e0 Add step to source dsenv in dsadm .bashrc</span><br></pre></td></tr></table></figure></p>
<p>Then properly select one good commit that also appears in remote master branch, run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git reset --hard &lt;good commit ID&gt;</span><br></pre></td></tr></table></figure></p>
<p>All the commits and commit history will be gone after the specified good commit ID, then you can just run the command below to sync up with master branch.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git pull origin master</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that it’s safe to do git reset here because only I use this branch and I want to clean</p>
</blockquote>
<p>Sometimes I see people use:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git reset --hard HEAD</span><br></pre></td></tr></table></figure></p>
<p><code>HEAD</code> points to your current commit, check by:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git rev-parse --short HEAD</span><br></pre></td></tr></table></figure></p>
<p>so all that <code>git reset --hard HEAD</code> will do is to throw away any uncommitted changes you have.</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Ceph</title>
    <url>/2020/01/20/fs-ceph/</url>
    <content><![CDATA[<h2 id="ceph-github"><a href="#ceph-github" class="headerlink" title="ceph github"></a>ceph github</h2><p><a href="https://github.com/ceph/ceph" target="_blank" rel="noopener">https://github.com/ceph/ceph</a></p>
<h2 id="Ceph-for-object-storage-block-storage-and-network-file-system"><a href="#Ceph-for-object-storage-block-storage-and-network-file-system" class="headerlink" title="Ceph for object storage, block storage and network file system"></a>Ceph for object storage, block storage and network file system</h2><p>Ceph uniquely delivers object, block, and file storage in one unified system.<br>differences:<br><a href="https://cloudian.com/blog/object-storage-vs-block-storage/" target="_blank" rel="noopener">https://cloudian.com/blog/object-storage-vs-block-storage/</a></p>
<h2 id="for-cephFS-https-docs-ceph-com-docs-master"><a href="#for-cephFS-https-docs-ceph-com-docs-master" class="headerlink" title="for cephFS, https://docs.ceph.com/docs/master/"></a>for cephFS, <a href="https://docs.ceph.com/docs/master/" target="_blank" rel="noopener">https://docs.ceph.com/docs/master/</a></h2><p>what does NFS/CIFS deployable mean?</p>
<h2 id="how-to-begin"><a href="#how-to-begin" class="headerlink" title="how to begin:"></a>how to begin:</h2><p><a href="https://docs.ceph.com/docs/master/start/intro/" target="_blank" rel="noopener">https://docs.ceph.com/docs/master/start/intro/</a><br>Whether you want to provide Ceph Object Storage and/or Ceph Block Device services to Cloud Platforms, deploy a Ceph File System or use Ceph for another purpose, all Ceph Storage Cluster deployments begin with setting up each Ceph Node, your network, and the Ceph Storage Cluster. </p>
<blockquote>
<p>ceph ansible playbook?</p>
</blockquote>
<h2 id="ceph-can-be-installed-by-cephadm-like-k8s-by-kubeadm-："><a href="#ceph-can-be-installed-by-cephadm-like-k8s-by-kubeadm-：" class="headerlink" title="ceph can be installed by cephadm (like k8s by kubeadm)："></a>ceph can be installed by cephadm (like k8s by kubeadm)：</h2><p><a href="https://docs.ceph.com/docs/master/bootstrap/#installation-cephadm" target="_blank" rel="noopener">https://docs.ceph.com/docs/master/bootstrap/#installation-cephadm</a><br>cannot get cephadm from yum install, need to install ceph repos and get rpms</p>
<p>构造好ceph cluster，现在的问题是怎么和k8s联合起来？</p>
]]></content>
      <categories>
        <category>File System</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ceph</tag>
        <tag>filesystem</tag>
      </tags>
  </entry>
  <entry>
    <title>NFS Server and Client Setup</title>
    <url>/2019/05/27/fs-nfs-setup/</url>
    <content><![CDATA[<p>This blog only sets up one NFS server that may be single point of failure.</p>
<p>NFS allows remote hosts to mount <code>filesystems</code>(can be any) over a network and interact with those filesystems as though they are mounted locally. </p>
<blockquote>
<p>NFS是一个概念，它不是一个文件系统，它是一种文件系统的共享方式, 这里默认使用本地Linux的文件系统了。</p>
</blockquote>
<p>NFS lets you leverage storage space in a different location and allows you to write onto the same space from multiple servers or clients in an effortless manner. It, thus, works fairly well for directories that users need to access frequently.</p>
<h2 id="Server-Setup"><a href="#Server-Setup" class="headerlink" title="Server Setup"></a>Server Setup</h2><p>Acutally there are many other package may needed, this <a href="https://www.youtube.com/watch?v=MBqZe5d9BNQ" target="_blank" rel="noopener">video</a> may give you more details.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install nfs package</span></span><br><span class="line">yum -y install nfs-utils</span><br></pre></td></tr></table></figure></p>
<p>Then enable and start nfs server:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## the rpc by default should be on, but may not</span></span><br><span class="line"><span class="comment">## rpc is called remote producture call</span></span><br><span class="line"><span class="comment">## nfs server needs this to access and operate on others</span></span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl start rpcbind</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> nfs-server.service</span><br><span class="line">systemctl start nfs-server.service</span><br><span class="line"><span class="comment">## create server side shared folder</span></span><br><span class="line">mkdir –p /data</span><br><span class="line">chmod –R 755 /data</span><br></pre></td></tr></table></figure></p>
<p>Edit <code>/etc/exports</code> file to expose shared folder<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/exports </span><br><span class="line"></span><br><span class="line"><span class="comment"># any client can access this folder</span></span><br><span class="line">/data *(rw,insecure,async,no_root_squash)   </span><br><span class="line"><span class="comment"># or specific client can access this folder</span></span><br><span class="line">/data &lt;client ip&gt;(rw,insecure,async,no_root_squash)</span><br></pre></td></tr></table></figure></p>
<p>Then export the shared folder:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">exportfs -a</span><br><span class="line">systemctl restart nfs-server.service</span><br></pre></td></tr></table></figure></p>
<p>Check shared folder is up <code>showmount -e &lt;server ip&gt;</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">showmount -e localhost</span><br></pre></td></tr></table></figure></p>
<p>If you change the content in <code>/etc/exports</code>, need to reload:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">exportfs -ra</span><br></pre></td></tr></table></figure></p>
<h2 id="Client-Setup"><a href="#Client-Setup" class="headerlink" title="Client Setup"></a>Client Setup</h2><p>First create or using existing folder as folder to mount, here I use <code>/mntiis</code> folder in client machine<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install nfs package</span></span><br><span class="line">yum -y install nfs-utils</span><br><span class="line"></span><br><span class="line"><span class="comment">## create client side shared folder</span></span><br><span class="line">mkdir -p /mntiis</span><br><span class="line">chmod -R 0755 /mntiis</span><br></pre></td></tr></table></figure></p>
<p>If you use non-persistent mount in command line, this connection will disappear after rebooting:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mount &lt;server ip&gt;:/data     /mntiis</span><br></pre></td></tr></table></figure></p>
<p>For persistent mount, go to <code>/etc/fstab</code> file, add this line<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;server ip&gt;:/data /mntiis nfs defaults 0 0</span><br><span class="line"><span class="comment">## or with other parameters</span></span><br><span class="line">&lt;server ip&gt;:/data /mntiis nfs defaults,timeo=10,retrans=3,rsize=1048576,wsize=1048576 0 0</span><br></pre></td></tr></table></figure></p>
<p>Enable mount:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mount /mntiis</span><br><span class="line"><span class="comment"># or reload all in fstab file</span></span><br><span class="line">mount -a</span><br></pre></td></tr></table></figure></p>
<p>Verify all set, you can see the <code>/mntiis</code> in the output:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -hk</span><br></pre></td></tr></table></figure></p>
<p>When you remove the entry in <code>/etc/fstab</code> filem, also unmount the folder, otherwise you will see <code>/mntiis</code> is marked by <code>?</code> in filesystem:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">umount /mntiis</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>File System</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>filesystem</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Create Pull Request</title>
    <url>/2019/12/24/git-create-pull-request/</url>
    <content><![CDATA[<p>In my blog <a href="https://chengdol.github.io/2019/09/12/git-create-working-branch/" target="_blank" rel="noopener">Create Working Branch</a>, when run <code>git push origin &lt;non-master&gt;</code>, we actually create a pull request.</p>
<p>More <a href="https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request" target="_blank" rel="noopener">references</a>, it also talks about create  pull request from fork</p>
<p>I am sometimes confusing about the term, why is called <code>pull request</code> not <code>push request</code> (because I push my code to other repo)? And I am not alone, a reasonable explanation see <a href="https://stackoverflow.com/questions/21657430/why-is-a-git-pull-request-not-called-a-push-request" target="_blank" rel="noopener">here</a>: Because You are asking the target repository grab your changes, stand on their side it is a pulling operation.</p>
<p>If the changes in local branch <code>develop</code> are ready, but the remote branch <code>develop</code> is out of date, after <code>git pull origin develop</code> your local get messy, you can use <code>git reset --hard</code> roll back to the last commit you made, next delete remote one on git web, then do the <code>git push origin develop</code>.</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Issue Layout</title>
    <url>/2020/02/26/git-issue-layout/</url>
    <content><![CDATA[<p>What should be the layout for a good issue, can configure this as template:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!---</span><br><span class="line">Please read this!</span><br><span class="line"></span><br><span class="line">Before opening a new issue, make sure to search for keywords in the issues</span><br><span class="line">and verify the issue you&apos;re about to submit isn&apos;t a duplicate.</span><br><span class="line">---&gt;</span><br><span class="line"></span><br><span class="line">## Environment information</span><br><span class="line">(cluster info, system info)</span><br><span class="line"></span><br><span class="line">## Problem Description</span><br><span class="line">(Summarize the bug encountered concisely)</span><br><span class="line"></span><br><span class="line">## Steps to reproduce</span><br><span class="line">(How one can reproduce the issue - this is very important)</span><br><span class="line"></span><br><span class="line">## Expected behaviour</span><br><span class="line">(what you should see?)</span><br><span class="line"></span><br><span class="line">## Observed behaviour</span><br><span class="line">(what actually happens?))</span><br><span class="line"></span><br><span class="line">## Additional info or screenshots</span><br><span class="line">(Paste any relevant logs - please use code blocks (```) to format console output,</span><br><span class="line">logs, and code as it&apos;s very hard to read otherwise.)</span><br><span class="line"></span><br><span class="line">## Workaround available</span><br><span class="line">(If you can, link to the line of code that might be responsible for the problem)</span><br><span class="line"></span><br><span class="line">## Per Meeting Minutes</span><br><span class="line"></span><br><span class="line">## TO-DO&apos;s</span><br></pre></td></tr></table></figure></p>
<p>More:</p>
<ol>
<li>add right pipelines</li>
<li>add right labels</li>
<li>@people when reply</li>
</ol>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Repository Browser</title>
    <url>/2019/06/28/git-gitk/</url>
    <content><![CDATA[<blockquote>
<p>Note in order to run <code>gitk</code> from terminal you need to have a Desktop GUI environment (for example VNC).</p>
</blockquote>
<p><code>gitk</code> is a graphical history viewer. Think of it like a powerful GUI shell over git log and git grep. This is the tool to use when you’re trying to find something that happened in the past, or visualize your project’s history</p>
<h2 id="Install-gitk"><a href="#Install-gitk" class="headerlink" title="Install gitk"></a>Install gitk</h2><p>For CentOS and RedHat:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y gitk</span><br></pre></td></tr></table></figure></p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p><code>gitk</code> is easy to invoke from the command-line. Just <code>cd</code> into your target git repository, and type:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitk</span><br></pre></td></tr></table></figure></p>
<p>Then a dedicated GUI will be launched for you:<br><img src="https://drive.google.com/uc?id=19b_uKeMXctg0QPFTqjzQCmL7b4VA3x4R" alt=""></p>
<p>You can get a brief usage introduction from <code>man gitk</code>, for example, if I want to see the commit history of <code>hello.sh</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitk &lt;path to file&gt;/hello.sh</span><br></pre></td></tr></table></figure></p>
<p>Show all branches:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gitk --all</span><br></pre></td></tr></table></figure></p>
<h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h2><p><a href="https://lostechies.com/joshuaflanagan/2010/09/03/use-gitk-to-understand-git/" target="_blank" rel="noopener">Use gitk to understand git</a></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>gitk</tag>
      </tags>
  </entry>
  <entry>
    <title>Pull Request Merge Strategy</title>
    <url>/2019/09/11/git-merge-strategy/</url>
    <content><![CDATA[<p><a href="https://help.github.com/en/articles/about-merge-methods-on-github#squashing-your-merge-commits" target="_blank" rel="noopener">https://help.github.com/en/articles/about-merge-methods-on-github#squashing-your-merge-commits</a></p>
<p><a href="https://help.github.com/en/articles/merging-a-pull-request" target="_blank" rel="noopener">https://help.github.com/en/articles/merging-a-pull-request</a></p>
<p><a href="https://help.github.com/en/articles/configuring-commit-squashing-for-pull-requests" target="_blank" rel="noopener">https://help.github.com/en/articles/configuring-commit-squashing-for-pull-requests</a></p>
<p><a href="https://github.com/ros-planning/moveit_tutorials/issues/280" target="_blank" rel="noopener">https://github.com/ros-planning/moveit_tutorials/issues/280</a></p>
<p><a href="https://github.blog/2016-04-01-squash-your-commits/" target="_blank" rel="noopener">https://github.blog/2016-04-01-squash-your-commits/</a></p>
<p>delete my branch remote in git web<br><a href="https://help.github.com/en/articles/creating-and-deleting-branches-within-your-repository" target="_blank" rel="noopener">https://help.github.com/en/articles/creating-and-deleting-branches-within-your-repository</a></p>
<p>rm -rf will not delete git hidden files !!</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Origin Vs Upstream</title>
    <url>/2019/07/09/git-origin-upstream/</url>
    <content><![CDATA[<p>Using Git everyday and pull push everyday, let’s spend time to undestand the concept <code>origin</code> and <code>upstream</code> fully. </p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p><a href="https://stackoverflow.com/questions/9257533/what-is-the-difference-between-origin-and-upstream-on-github" target="_blank" rel="noopener">Difference Upstream and Origin</a></p>
<ul>
<li><code>upstream</code> generally refers to the original repo that you forked from</li>
<li><code>origin</code> is your fork: your own repo on GitHub, clone of the original repo of GitHub</li>
</ul>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Disable Pull Prompt</title>
    <url>/2019/06/27/git-mute-pull-prompt/</url>
    <content><![CDATA[<p>When run <code>git pull origin master</code> to make your local branch up-to-date, if there are files need to be merged, you will get prompt to confirm the merge and make commit. This is not good for automation, need to mute this prompt.</p>
<blockquote>
<p>Note this method fits this situation, but not sure if this is a general way to go, because <code>git pull</code> has different syntax format.</p>
</blockquote>
<p>Actually, <code>git pull</code> does a <code>git fetch</code> followed by <code>git merge</code>, so can sepetate it into two steps:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git pull origin master</span><br></pre></td></tr></table></figure></p>
<p>Changes to<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git fetch origin master</span><br><span class="line">git merge FETCH_HEAD --no-edit</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that The <code>--no-edit</code> option can be used to accept the auto-generated message (this is generally discouraged).</p>
</blockquote>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Versioning Large File in Git</title>
    <url>/2019/02/24/git-lfs/</url>
    <content><![CDATA[<p>I want to introduce you <a href="https://git-lfs.github.com/" target="_blank" rel="noopener">Git LFS</a>, it is a command line extension and <a href="https://github.com/git-lfs/git-lfs/blob/master/docs/spec.md" target="_blank" rel="noopener">specification</a> for managing large files with Git. LFS is great for <strong>large, changing files</strong>, there is basically a text pointer to the large file archived some place else.</p>
<h3 id="Install-Git-LFS"><a href="#Install-Git-LFS" class="headerlink" title="Install Git LFS"></a>Install Git LFS</h3><blockquote>
<p>Note: you need to install <code>Git LFS</code> if you <code>git pull</code> from a remote repository that has it</p>
</blockquote>
<p>For example, I am working on a RHEL machine.<br>First go to source page, follow the installation guide to install:</p>
<p><img src="https://drive.google.com/uc?id=1c2hUDmTQwOnD3GNz8S1QHfkyGwLzO5ur" alt=""></p>
<p><img src="https://drive.google.com/uc?id=1Zhnjd815gHSBJFySqdAyvfqSDeZtd0oc" alt=""></p>
<p>This will create a yum repos for git-lfs:</p>
<p><img src="https://drive.google.com/uc?id=1BtoVGRjTz1PHXplO5OuJnhYMy8oJPzKl" alt=""></p>
<p><img src="https://drive.google.com/uc?id=1F4NO7fUTtq0cP0bfgm8EGNlIrvKAjp1T" alt=""></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y git-lfs</span><br></pre></td></tr></table></figure>
<p>you can see git-lfs is installed in your machine:<br><img src="https://drive.google.com/uc?id=12xtxpkkbAzSjSXAecwjqb-dV0SFEt_qz" alt=""></p>
<p>Once downloaded and installed, set up Git LFS and its respective hooks by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git lfs install</span><br></pre></td></tr></table></figure></p>
<p><img src="https://drive.google.com/uc?id=1gTK8WwQi7i1Vfjq7_ysTU5H9jXN4w_Jo" alt=""></p>
<blockquote>
<p>Note: You’ll need to run this in your repository directory, once per repository.</p>
</blockquote>
<h3 id="Track-Large-File"><a href="#Track-Large-File" class="headerlink" title="Track Large File"></a>Track Large File</h3><p>Select the file types you’d like Git LFS to manage (or directly edit your <code>.gitattributes</code>). You can configure additional file extensions at anytime.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git lfs track <span class="string">"*.tar.gz"</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: run this track command at the top level of your repository, then you need to git add <code>.gitattributes</code> file</p>
</blockquote>
<h3 id="Manage-Large-File"><a href="#Manage-Large-File" class="headerlink" title="Manage Large File"></a>Manage Large File</h3><p>Then, just do normal <code>git add</code> and <code>git commit</code> to manage your large size file.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git add *.tar.gz</span><br><span class="line">git commit -m <span class="string">"add tar.gz file"</span></span><br><span class="line">git push origin &lt;your branch&gt;</span><br></pre></td></tr></table></figure></p>
<p><img src="https://drive.google.com/uc?id=1x9TX8NBIEZaaG51_dQxEKljdeL0ziKK8" alt=""></p>
<p>Actually, you can check the large files you managed by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git lfs ls-files</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git-lfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Pull Not Clean</title>
    <url>/2019/06/14/git-pull-not-clean/</url>
    <content><![CDATA[<p>Sometimes after I <code>git pull</code> from the master branch, if I run <code>git status</code>, there are some files (for me it’s mainly <code>xxx.dsx</code>) are modified that need to be added and committed, that’s strange.</p>
<p>It seems the format issue that can be solved by editting the top level <code>.gitattributes</code> in your local repository. Open <code>.gitattributes</code>, comment out the formulas, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#* text=auto</span><br></pre></td></tr></table></figure></p>
<p>Now if I run <code>git status</code> again, the clutters are gone and git outputs only show<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">modified:   .gitattributes</span><br></pre></td></tr></table></figure></p>
<p>Then revert back to origin in <code>.gitattributes</code> and run <code>git status</code> again, the branch will be clean.</p>
<p>Acutally there are some commands can exterminate editor operation:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -i -e &apos;s/^\(\*[ ][ ]*text.*\)/#\1/&apos; .gitattributes</span><br><span class="line">git status</span><br><span class="line">sed -i -e &apos;s/^#\(\*[ ][ ]*text.*\)/\1/&apos; .gitattributes</span><br><span class="line">git status</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>gitattributes</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Partial Merge</title>
    <url>/2019/07/10/git-partial-merge/</url>
    <content><![CDATA[<p>I was previously working on a separate branch <code>branch-tmp</code>, now I want to merge some files in that branch into my main personal branch <code>chengdol_master</code>, and finally create a pull request to merge int <code>master</code>.</p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p><a href="https://jasonrudolph.com/blog/2009/02/25/git-tip-how-to-merge-specific-files-from-another-branch/" target="_blank" rel="noopener">Git tip: How to “merge” specific files from another branch</a><br><a href="https://stackoverflow.com/questions/18115411/how-to-merge-specific-files-from-git-branches" target="_blank" rel="noopener">Interactive merge</a></p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><blockquote>
<p>Notice that in my case, the target files in <code>branch-tmp</code> are completely applicable for <code>chengdol_master</code>, so I just want to overwrite corresponding files in <code>chengdol_master</code>. If we need to pick some changes and leave others in the file, do an <code>interactive merge</code>, run this from <code>chengdol_master</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git checkout --patch brach-tmp &lt;relative path to target file&gt;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>First check if you have <code>origin/branch-tmp</code> locally<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git branch -r | grep branch-tmp</span><br></pre></td></tr></table></figure></p>
<p>If not, you need to fetch it alone or fetch all origin branches:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git fetch origin branch-tmp</span><br><span class="line">git fetch origin</span><br></pre></td></tr></table></figure></p>
<p>Then go to your target branch <code>chengdol_master</code>, use <code>git checkout</code> command to do the job:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git checkout origin/branch-tmp &lt;relative path to target file&gt;</span><br></pre></td></tr></table></figure></p>
<p>then the merged files from <code>branch-tmp</code> are in staging phase, you can directly commit or unstage them in the <code>chengdol_master</code> branch, then push and handle the pull request.</p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo Quick Start</title>
    <url>/2019/01/27/hexo-setup/</url>
    <content><![CDATA[<p>Several weeks ago I decided to summarize and post what I have learned to online Blog platform, I struggled several days to choose which platform is better. Finally I think create my own blog and host it somewhere is a good way to go.</p>
<h2 id="Hexo-and-GitHub-Pages"><a href="#Hexo-and-GitHub-Pages" class="headerlink" title="Hexo and GitHub Pages"></a>Hexo and GitHub Pages</h2><p>First understand what is <strong>GitHub Pages</strong> and <strong>Hexo</strong>.</p>
<p><strong><a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a></strong>  is a website for you and your project that hosted directly from your GitHub repository. There is no Database to setup and no server to configure, you even don’t need to know HTML, CSS and other web development toolkits. You just follow the basic git add, commit and push operations and it will automatically build and deploy your blog site for you.</p>
<p> <strong><a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a></strong> is a open source blog framework that transfers plain text files into static website with beautiful theme. You associate it with your GitHub Pages repository, then use <a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet" target="_blank" rel="noopener">Markdown</a> write posts and deploy. Hexo provides basic features for manage the blog site, such as <em>categories</em>, <em>tag</em>, <em>profile</em>, etc. There are a lot of extensions and customizations for Hexo, more details please refer it’s website.</p>
<p>There is a Chinese version explanation, refer this <a href="https://www.yuque.com/skyrin/coding/tm8yf5" target="_blank" rel="noopener">link</a></p>
<h2 id="Set-up-GitHub-Pages"><a href="#Set-up-GitHub-Pages" class="headerlink" title="Set up GitHub Pages"></a>Set up GitHub Pages</h2><p>Head over to <a href="https://github.com/" target="_blank" rel="noopener">GitHub</a> and <a href="https://github.com/new" target="_blank" rel="noopener">create a new repository</a> named <em>username</em>.github.io, where <em>username</em> is your username (or organization name) on GitHub.</p>
<p>If the first part of the repository doesn’t exactly match your username, it won’t work, so make sure to get it right.<br><img src="https://drive.google.com/uc?id=18TZ7ee5zWHLS_aaP-pLC6BrevrAaRpA8" alt=""></p>
<h2 id="Set-up-Hexo"><a href="#Set-up-Hexo" class="headerlink" title="Set up Hexo"></a>Set up Hexo</h2><p>You need first install <a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git" target="_blank" rel="noopener">Git</a> and <a href="https://nodejs.org/en/" target="_blank" rel="noopener">Node.js</a>, at the time build this blog I use Node version <code>10.15.2</code>, download and install it:<br><img src="https://drive.google.com/uc?id=1IWR24a6-IJirz1o_f9r7LmceSFUdSoS3" alt=""></p>
<blockquote>
<p>Note: for Mac users, you may encounter some other problems, please refer this <a href="https://hexo.io/docs/index.html" target="_blank" rel="noopener">link</a>. </p>
</blockquote>
<p>Once all requirements are set, install Hexo by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo npm install -g hexo-cli</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: for Mac users, you need to <a href="https://support.apple.com/en-us/HT204012" target="_blank" rel="noopener">enable root user privilege</a> first.</p>
</blockquote>
<p>The installation process may generate some warnings even errors, do a sanity check to see if it is good:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo -v</span><br><span class="line"></span><br><span class="line">hexo-cli: 1.1.0</span><br><span class="line">os: Darwin 18.2.0 darwin x64</span><br><span class="line">http_parser: 2.8.0</span><br><span class="line">node: 10.15.0</span><br><span class="line">v8: 6.8.275.32-node.45</span><br><span class="line">uv: 1.23.2</span><br><span class="line">zlib: 1.2.11</span><br><span class="line">ares: 1.15.0</span><br><span class="line">modules: 64</span><br><span class="line">nghttp2: 1.34.0</span><br><span class="line">napi: 3</span><br><span class="line">openssl: 1.1.0j</span><br><span class="line">icu: 62.1</span><br><span class="line">unicode: 11.0</span><br><span class="line">cldr: 33.1</span><br><span class="line">tz: 2018e</span><br></pre></td></tr></table></figure></p>
<h2 id="Initialize-blog"><a href="#Initialize-blog" class="headerlink" title="Initialize blog"></a>Initialize blog</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/Desktop/</span><br><span class="line"><span class="comment">## create a directory called `chengdol.blog`</span></span><br><span class="line">hexo init chengdol.blog</span><br></pre></td></tr></table></figure>
<p>Go to <code>chengdol.blog</code> and <code>hexo server</code> and open the URL<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo server</span><br><span class="line"></span><br><span class="line">INFO  Start processing</span><br><span class="line">INFO  Hexo is running at http://localhost:4000 . Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure></p>
<p>If you see this webpage, congratulations! you now have a workable blog with default setting:<br><img src="https://drive.google.com/uc?id=15FS4S4Lfi33giFDmf7NzeWMTq4N8p65M" alt=""></p>
<h2 id="Customize-blog"><a href="#Customize-blog" class="headerlink" title="Customize blog"></a>Customize blog</h2><p>Let’s open the <code>chengdol.blog</code> directory<br><img src="https://drive.google.com/uc?id=1UkhbU2jxwuw6Kd14YDPcBCc80kSXL5Jr" alt=""></p>
<p>The Hexo offical <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> contains lots of configuration setting you can follow, Here I just go through what I have applied.</p>
<p>由于写的Blog越来越多了，查找的需求就来了，刚好Hexo有search plugin, 就用上了。</p>
<h3 id="Word-count"><a href="#Word-count" class="headerlink" title="Word count"></a>Word count</h3><p>The is the word count and read time plug:<br><a href="https://github.com/theme-next/hexo-symbols-count-time" target="_blank" rel="noopener">https://github.com/theme-next/hexo-symbols-count-time</a></p>
<p>这个插件好像有点问题，阅读时间总是显示InfinityNA。</p>
<h3 id="Search"><a href="#Search" class="headerlink" title="Search"></a>Search</h3><p>This will generate local search DB and create a new search UI in webpage<br><a href="https://github.com/theme-next/hexo-generator-searchdb" target="_blank" rel="noopener">https://github.com/theme-next/hexo-generator-searchdb</a></p>
<p>不需要对Next的_config.yml进行改动，初次安装后需要run <code>hexo g</code>去生成数据库。部署的操作不变。</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>gitpage</tag>
      </tags>
  </entry>
  <entry>
    <title>Terraform Quick Start</title>
    <url>/2020/05/16/infra-terraform/</url>
    <content><![CDATA[<h1 id="Terraform"><a href="#Terraform" class="headerlink" title="Terraform"></a>Terraform</h1><p>From Hashicorp, removing manual build process, adopting declarative approach to deploy <strong>infrastructure as code</strong>, reusable, idempotent and consistent repeatable deployment.</p>
<p>Terrafrom provision GKS<br><a href="https://learn.hashicorp.com/terraform/kubernetes/provision-gke-cluster" target="_blank" rel="noopener">https://learn.hashicorp.com/terraform/kubernetes/provision-gke-cluster</a></p>
<p>This post from IBM can give you a good overview:<br><a href="https://www.ibm.com/cloud/learn/terraform" target="_blank" rel="noopener">https://www.ibm.com/cloud/learn/terraform</a><br>Terraform vs Kubernetes<br>Terraform vs Ansible</p>
<p>CSDN:<br><a href="https://www.cnblogs.com/sparkdev/p/10052310.html" target="_blank" rel="noopener">https://www.cnblogs.com/sparkdev/p/10052310.html</a></p>
<p>Terraform 文档非常informative，结构清晰:<br><a href="https://www.terraform.io/docs/" target="_blank" rel="noopener">https://www.terraform.io/docs/</a></p>
<p>Terraform之于cloud infra就相当于 helm之于K8s, 大大简化了操作复杂性，自动快速部署，同时做到了复用，versioning等特性。但首先得去了解cloud provider中提供的资源的用途，搭配。</p>
<h2 id="Play-around"><a href="#Play-around" class="headerlink" title="Play around"></a>Play around</h2><p>resource files in github:<br><a href="https://github.com/ned1313/Getting-Started-Terraform" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Terraform</a></p>
<p>what are needed:<br>Aws account, may get charged, ask for GCP free access.</p>
<h2 id="Composition"><a href="#Composition" class="headerlink" title="Composition"></a>Composition</h2><p>Terraform executable: download from web<br>Terraform files: using hashicorp configure language DSL<br>Terraform plugin: interact with provider: AWS, GCP, Azure, etc<br>Terraform state file: json and don’t touch it</p>
<p>You can have multiple terraform file: <code>.tf</code>, when run terraform it will stitch them together to form a single configuration. 比如把variables, outputs, resources, tfvars分开。</p>
<p>tfvars file be default named as <code>terraform.tfvars</code>. otherwise when run <code>plan</code> you need to specify the file path.</p>
<h2 id="Command"><a href="#Command" class="headerlink" title="Command"></a>Command</h2><p>If you update the terraform file with different configuration, rerun <code>init</code>, <code>plan</code> and <code>apply</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list all commands</span></span><br><span class="line">terraform -<span class="built_in">help</span></span><br><span class="line">terraform version</span><br><span class="line"><span class="comment">## linter</span></span><br><span class="line">terraform validate</span><br><span class="line"></span><br><span class="line">terraform init</span><br><span class="line"><span class="comment">## will show you the diff if you update your terraform file</span></span><br><span class="line"><span class="comment">## load terraform.tfvars by default</span></span><br><span class="line">terraform plan -out plan.tfplan</span><br><span class="line"><span class="comment">## will generate a tfstate file</span></span><br><span class="line"><span class="comment">## perform creation as much parallel as possible</span></span><br><span class="line">terraform apply <span class="string">"plan.tfplan"</span></span><br><span class="line"></span><br><span class="line">terraform show</span><br><span class="line"><span class="comment">## for example, show you igress url</span></span><br><span class="line">terraform output</span><br><span class="line"><span class="comment">## destroy Terraform-managed infrastructure</span></span><br><span class="line">terraform destroy</span><br></pre></td></tr></table></figure></p>
<p>Provisioning k8s in GCP:<br><a href="https://learn.hashicorp.com/terraform/kubernetes/provision-gke-cluster" target="_blank" rel="noopener">https://learn.hashicorp.com/terraform/kubernetes/provision-gke-cluster</a></p>
<h2 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h2><p>Hashicorp configuration language:<br><a href="https://www.terraform.io/docs/configuration/index.html" target="_blank" rel="noopener">https://www.terraform.io/docs/configuration/index.html</a></p>
<p>参考这些例子中的tf文件，格式还是比较固定的<br><a href="https://github.com/ned1313/Getting-Started-Terraform" target="_blank" rel="noopener">https://github.com/ned1313/Getting-Started-Terraform</a></p>
<p>怎么知道resource的名称呢? 有很多provider现成的resource可用:<br><a href="https://www.terraform.io/docs/configuration/resources.html" target="_blank" rel="noopener">https://www.terraform.io/docs/configuration/resources.html</a><br>还有random provider，比如产生随机数</p>
<p>Object types:</p>
<ul>
<li>string</li>
<li>number (integer/decimal)</li>
<li>bool (true/false)</li>
<li>list (index start from 0)</li>
<li>map</li>
</ul>
<h3 id="Provisioner"><a href="#Provisioner" class="headerlink" title="Provisioner"></a>Provisioner</h3><p>类似于ansible的配置操作，在deploy infrastructure 之后。<br>post-deployment configuration, last resort, prefer ansible/puppet or chef.<br>provisioner can be local or remote</p>
<p>common provisioner:</p>
<ul>
<li>file</li>
<li>local-exec</li>
<li>remote-exec</li>
</ul>
<h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><p><a href="https://www.terraform.io/docs/configuration/functions.html" target="_blank" rel="noopener">https://www.terraform.io/docs/configuration/functions.html</a></p>
<p>You can experiment with functions in Terraform console, this can help with troubleshooting.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">terraform console</span><br><span class="line">&gt; min(2,5,90)</span><br><span class="line"><span class="comment">## load var from terraform state file</span></span><br><span class="line">&gt; cidrsubnet(var.network_address_space, 8, 0)</span><br><span class="line">&gt; lookup(local.common_tags, <span class="string">"Bill"</span>, <span class="string">"Unknown"</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="Provider"><a href="#Provider" class="headerlink" title="Provider"></a>Provider</h2><p>Support mutliple providers, all written in Go.<br><a href="https://www.terraform.io/docs/providers/index.html" target="_blank" rel="noopener">https://www.terraform.io/docs/providers/index.html</a></p>
<h3 id="Resource-arguments"><a href="#Resource-arguments" class="headerlink" title="Resource arguments"></a>Resource arguments</h3><p><a href="https://www.terraform.io/docs/configuration/resources.html#depends_on-explicit-resource-dependencies" target="_blank" rel="noopener">https://www.terraform.io/docs/configuration/resources.html#depends_on-explicit-resource-dependencies</a><br>common ones:</p>
<ul>
<li>depends_on: make sure terraform creates things in right order</li>
<li>count: create similar resources</li>
<li>for_each: create resources not similar</li>
<li>provider</li>
</ul>
<h2 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h2><p>Other way to use variables rather than specifying in single <code>.tf</code> file.</p>
<p>The scenario, we need development, QA/UAT, production environment, how to implement via one configuratio and multiple inputs?</p>
<p>The variable can be from:</p>
<ul>
<li>file</li>
<li>environment variable</li>
<li>var option</li>
</ul>
<p>You can override variables and precedence, select value based on environment, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## specify default value in tf file</span></span><br><span class="line">variable <span class="string">"env_name"</span> &#123;</span><br><span class="line">  <span class="built_in">type</span> = string</span><br><span class="line">  default = <span class="string">"develop"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## specify in tfvars file</span></span><br><span class="line">env_name = <span class="string">"uat"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## specify in command line</span></span><br><span class="line">terraform plan -var <span class="string">'env_name=production'</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Workspace"><a href="#Workspace" class="headerlink" title="Workspace"></a>Workspace</h2><p>Workspace is the recommended way to working with multiple environments, for example:</p>
<ul>
<li>state management</li>
<li>variables data</li>
<li>credentials management</li>
</ul>
<p>State file example, we have dev, QA, prod three environments, put them each into separate folder, when run command, specify the input and output:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## for dev environment</span></span><br><span class="line"><span class="comment">## -state: where to write state file</span></span><br><span class="line"><span class="comment">## -var-file: load file</span></span><br><span class="line">terraform plan -state=<span class="string">"./dev/dev.state"</span> \</span><br><span class="line">               -var-file=<span class="string">"common.tfvars"</span> \</span><br><span class="line">               -var-file=<span class="string">"./dev/dev.tfvars"</span></span><br></pre></td></tr></table></figure></p>
<p>Workspace example, there is a <code>terraform.workspace</code> built-in variable can be used to indicate the workspace currently in, then use it in map variable to select right value for different environment. (不用再去分别创建不同的folder for different environment了)<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create dev workspace and switch to it</span></span><br><span class="line">terraform workspace new dev</span><br><span class="line"><span class="comment">## show workspace</span></span><br><span class="line">terraform workspace list</span><br><span class="line">terraform plan -out dev.tfplan</span><br><span class="line">terraform apply <span class="string">"dev.tfplan"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## now create another workspace for QA</span></span><br><span class="line">terraform workspace new QA</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment">## switch workspace</span></span><br><span class="line">terraform workspace select dev</span><br></pre></td></tr></table></figure></p>
<h2 id="Managing-secrets"><a href="#Managing-secrets" class="headerlink" title="Managing secrets"></a>Managing secrets</h2><p>Hashicorp <strong>vault</strong> is for this purpose. it can hand over credentials from cloud provider to terraform and set ttl for the secrets.</p>
<p>Or you can use environment variable to specify the credentials, terraform will pick it automatically, but bear in mind to use the right env var name.</p>
<h2 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h2><p>Make code reuse eaiser:<br><a href="https://www.terraform.io/docs/configuration/modules.html" target="_blank" rel="noopener">https://www.terraform.io/docs/configuration/modules.html</a></p>
<p>Terraform registry, similar concept with Helm, Docker:<br><a href="https://registry.terraform.io/" target="_blank" rel="noopener">https://registry.terraform.io/</a><br>Using module block to invoke local or remote modules.</p>
<ol>
<li>root module</li>
<li>support versioning</li>
<li>provider inheritance</li>
</ol>
<p>Module components:</p>
<ul>
<li>variables input</li>
<li>resources</li>
<li>output values (calling part will take this in)</li>
</ul>
]]></content>
      <categories>
        <category>Infra</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>terraform</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Exception</title>
    <url>/2020/04/11/java-exception/</url>
    <content><![CDATA[<p>Reference: <a href="https://docs.oracle.com/javase/tutorial/essential/exceptions/definition.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/tutorial/essential/exceptions/definition.html</a></p>
<p>Code that fails to honor the Catch or Specify Requirement will not compile.</p>
<p>Not all exceptions are subject to the Catch or Specify Requirement. To understand why, we need to look at the three basic categories of exceptions, only one of which is subject to the Requirement.</p>
<h2 id="The-Three-Kinds-of-Exceptions"><a href="#The-Three-Kinds-of-Exceptions" class="headerlink" title="The Three Kinds of Exceptions"></a>The Three Kinds of Exceptions</h2><p>The first kind of exception is the <code>checked exception</code>.</p>
<p>Checked exceptions are subject to the <code>Catch or Specify Requirement</code>. <strong>All</strong> exceptions are checked exceptions, except for those indicated by Error, RuntimeException, and their subclasses.</p>
<p>The second kind of exception is the <code>error</code>. These are exceptional conditions that are external to the application, and that the application usually cannot anticipate or recover from.<br>Errors are not subject to the Catch or Specify Requirement. Errors are those exceptions indicated by Error and its subclasses.</p>
<p>The third kind of exception is the <code>runtime exception</code>.<br>Runtime exceptions are not subject to the Catch or Specify Requirement. Runtime exceptions are those indicated by RuntimeException and its subclasses.</p>
<p>Errors and runtime exceptions are collectively known as <code>unchecked exceptions</code>.</p>
<blockquote>
<p>unchecked exception 也可以被catch，只要match就行，也可以被throws, but we don’t have to do that: <a href="https://stackoverflow.com/questions/8104407/cant-java-unchecked-exceptions-be-handled-using-try-catch-block" target="_blank" rel="noopener">https://stackoverflow.com/questions/8104407/cant-java-unchecked-exceptions-be-handled-using-try-catch-block</a></p>
</blockquote>
<p><a href="https://crunchify.com/better-understanding-on-checked-vs-unchecked-exceptions-how-to-handle-exception-better-way-in-java/" target="_blank" rel="noopener">Better Understanding on Checked Vs. Unchecked Exceptions</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">try</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// code that could throw an exception</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// check in order</span></span><br><span class="line"><span class="keyword">catch</span> (IOException | SQLException ex)</span><br><span class="line">&#123;</span><br><span class="line">    logger.log(ex);</span><br><span class="line">    <span class="keyword">throw</span> ex;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">catch</span> (IndexOutOfBoundsException e) </span><br><span class="line">&#123;</span><br><span class="line">    System.err.println(<span class="string">"IndexOutOfBoundsException: "</span> + e.getMessage());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// The finally block always executes when the try block exits.</span></span><br><span class="line"><span class="keyword">finally</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span> (out != <span class="keyword">null</span>) &#123; </span><br><span class="line">        System.out.println(<span class="string">"Closing PrintWriter"</span>);</span><br><span class="line">        out.close(); </span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">        System.out.println(<span class="string">"PrintWriter not open"</span>);</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>finally</code> block it allows the programmer to avoid having cleanup code accidentally bypassed by a return, continue, or break. Putting cleanup code in a finally block is always a good practice, even when no exceptions are anticipated.</p>
<p>The <code>try-with-resources</code> statement ensures that each resource is closed at the end of the statement. Any object that implements <code>java.lang.AutoCloseable</code>, which includes all objects which implement <code>java.io.Closeable</code>, can be used as a resource.<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> String <span class="title">readFirstLineFromFile</span><span class="params">(String path)</span> <span class="keyword">throws</span> IOException </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">try</span> (BufferedReader br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> FileReader(path))) </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// try block</span></span><br><span class="line">        <span class="keyword">return</span> br.readLine();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: A try-with-resources statement can have catch and finally blocks just like an ordinary try statement. In a try-with-resources statement, any catch or finally block is run <strong>after</strong> the resources declared have been closed.</p>
</blockquote>
<h2 id="Throw-exception"><a href="#Throw-exception" class="headerlink" title="Throw exception"></a>Throw exception</h2><p>declare throws exception for method<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeList</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;&#125;</span><br></pre></td></tr></table></figure></p>
<p>throw an exception<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (size == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> EmptyStackException();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Create custom exception: <a href="https://www.baeldung.com/java-new-custom-exception" target="_blank" rel="noopener">https://www.baeldung.com/java-new-custom-exception</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// create custom exception</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IncorrectFileNameException</span> <span class="keyword">extends</span> <span class="title">Exception</span> </span>&#123; </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">IncorrectFileNameException</span><span class="params">(String errorMessage)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(errorMessage);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Inprogress</title>
    <url>/2019/01/01/inprogress/</url>
    <content><![CDATA[<p><strong>This is the blog incubator</strong></p>
<p>最近在做一些pipeline的工作，需要快速上手，主要涉及到的:<br>Jenkins (已经OK)<br>gradle  (基本OK)<br>Groovy  (即将OK)<br>现在不清楚的地方是各自文件的语法。<br>先从groovy，gradle入手，然后jenkins。</p>
<h1 id="Groovy"><a href="#Groovy" class="headerlink" title="Groovy"></a>Groovy</h1><p>Books, course and presentations, recommend:<br><a href="https://groovy-lang.org/learn.html#books" target="_blank" rel="noopener">https://groovy-lang.org/learn.html#books</a><br>O’relly course</p>
<p><a href="http://groovy-lang.org/syntax.html" target="_blank" rel="noopener">http://groovy-lang.org/syntax.html</a><br>alternative java language</p>
<p><code>DSL</code>: domain specific language<br><code>sdkman</code> very good installation toolkit (also for gradle!)<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## must have jdk installed</span></span><br><span class="line">yum install java-1.8.0-openjdk-devel -y</span><br><span class="line"><span class="comment">## specify version 2.5.2</span></span><br><span class="line">sdk install groovy 2.5.2</span><br></pre></td></tr></table></figure></p>
<p>others:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">groovysh</span><br><span class="line">println <span class="string">"123"</span></span><br><span class="line"></span><br><span class="line">def xx is <span class="built_in">local</span> scope</span><br><span class="line"></span><br><span class="line">:<span class="built_in">help</span></span><br><span class="line">:show variable</span><br><span class="line"></span><br><span class="line">xx.groovy</span><br><span class="line"><span class="comment">## compile</span></span><br><span class="line">groovyc xx.groovy</span><br><span class="line"><span class="comment">## run </span></span><br><span class="line">groovy xx.groovy</span><br><span class="line"><span class="comment">## this is ok</span></span><br><span class="line"><span class="variable">$abc</span></span><br><span class="line">List = [1,2,3]</span><br></pre></td></tr></table></figure></p>
<h1 id="Gradle"><a href="#Gradle" class="headerlink" title="Gradle"></a>Gradle</h1><p>don’t see latest book,  please refer to official doc<br><a href="https://gradle.org/guides/" target="_blank" rel="noopener">https://gradle.org/guides/</a><br>Ant and Maven are also build tools, gradle wrapper, incremental builds.</p>
<ol>
<li>build by convention</li>
<li>Groovy DSL</li>
<li>supports dependencies</li>
<li>support mutli-project build</li>
<li>easily customizable</li>
</ol>
<p>To install Gradle, using <code>sdkman</code> tool.</p>
<p>有几个概念搞清楚:</p>
<ol>
<li>gradle wrapper -&gt; gradlew (version control)</li>
<li>build.gradle: syntax, plugin</li>
<li>gradle.properties</li>
<li>extract env variable </li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apply plugin: &apos;java&apos;</span><br><span class="line"></span><br><span class="line">task &#123;</span><br><span class="line">  doLast &#123;</span><br><span class="line">    // groovy syntax</span><br><span class="line">    println &quot;hello, gradle!&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h1><p>using use/passowrd instead of ssh<br>need to setup personal access credential:<br><a href="https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line" target="_blank" rel="noopener">https://help.github.com/en/github/authenticating-to-github/creating-a-personal-access-token-for-the-command-line</a></p>
<p>for example,  mypersonal access token<br><code>456f6facec85415b91588f581sfsdfssfe56c0</code><br>I can embed the user/cred to push command:<br><a href="https://stackoverflow.com/questions/29776439/username-and-password-in-command-for-git-push" target="_blank" rel="noopener">https://stackoverflow.com/questions/29776439/username-and-password-in-command-for-git-push</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git push <span class="string">'https://chengdol%40ibm.com:456f6facec85415b91588f58182dd1cfe27e56c0@github.ibm.com/repo/hello.git'</span></span><br></pre></td></tr></table></figure></p>
<p>use <code>%40</code> replace <code>@</code>.<br><code>github.ibm.com/repo/hello.git</code> is the url to your repo</p>
<h3 id="deploy-keys"><a href="#deploy-keys" class="headerlink" title="deploy keys"></a>deploy keys</h3><p><a href="https://github.blog/2015-06-16-read-only-deploy-keys/" target="_blank" rel="noopener">https://github.blog/2015-06-16-read-only-deploy-keys/</a></p>
<h1 id="承上启下"><a href="#承上启下" class="headerlink" title="承上启下"></a>承上启下</h1><p>interpersonal skill, BQ</p>
<p>现在能接触到的基础打好<br>k8s, docker, jenkins (groovy + gradle), ansible, helm<br>git -&gt; gitlab (with jenkins)<br>常用工具:<br>visual studio<br>bash, zsh</p>
<p>composing database layer:<br>cassandra<br>elasticsearch (monitoring + log system)<br>consul<br>vault</p>
<p>monitoring:<br>prometheus<br>grafana<br>kibana</p>
<p>others:<br>kafka<br>zookeeper<br>istio<br>golang</p>
<p>我猜工作流程:<br>用terraform 构造k8s 环境 或其他， 用ansible增加或更改配置，然后在k8s中部署应用(prometheus + grafana and elk for logs)，最后集成CI/CD<br>development -&gt; QA/UAT - &gt; production</p>
<h2 id="understand"><a href="#understand" class="headerlink" title="understand"></a>understand</h2><p>如果不清楚这些则看不懂配置的含义, 要清楚各个cloud中resource的类型，配置，如何搭配:<br>instance, vpc, lb, dns, storage, routing, subnet, gateway</p>
<p>GCP/GKS<br>AWS: VPC, EC2</p>
<p>terraform -&gt; deploy k8s (EKS or GKS) -&gt; install vault, elasticsearch, cassandra by helm (need modify though)<br>-&gt;<br>Prometheus<br>Grafana<br>Kibana<br>-&gt;<br>CI/CD: jenkins + gitlab</p>
<p>把完全不知道是什么的快速过一遍。<br>先学terraform -&gt; elasticsearch -&gt; vault, cassandra -&gt; monitoring tools</p>
<h2 id="steps"><a href="#steps" class="headerlink" title="steps"></a>steps</h2><ol>
<li>terrform provision k8s on aws and gcp</li>
<li>k8s on fyre to test other components via helm</li>
<li>monitoring system: prometheus + grafana</li>
<li>log system: elasticsearch, kibaba, logstash, beats</li>
</ol>
<p>实验: 在k8s中部署prometheus + elastic stack, by helm or yaml，监控系统状态</p>
<ol start="5">
<li>Hashicorp: consul, vault</li>
<li>cassandra</li>
</ol>
<p>实验: 在k8s中部署cassandra<br>实验: 在k8s中部署jenkins pipeline + gitlab</p>
]]></content>
      <categories>
        <category>InPorgress</category>
      </categories>
      <tags>
        <tag>inprogress</tag>
      </tags>
  </entry>
  <entry>
    <title>Git Rename Limit</title>
    <url>/2019/10/22/git-rename-limit/</url>
    <content><![CDATA[<p>I encounter a git issue when I run these commands, they are used to sync up with origin/master:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">git_clean</span></span>() &#123;</span><br><span class="line">  git reset --hard HEAD</span><br><span class="line">  sed -i -e <span class="string">'s/^\(\*[ ][ ]*text.*\)/#\1/'</span> .gitattributes</span><br><span class="line">  git status</span><br><span class="line">  git clean -fdx</span><br><span class="line">  git checkout -- .</span><br><span class="line">  sed -i -e <span class="string">'s/^#\(\*[ ][ ]*text.*\)/\1/'</span> .gitattributes</span><br><span class="line">  git status</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>I get errors:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">warning: inexact rename detection was skipped due to too many files.</span><br><span class="line">warning: you may want to set your merge.renamelimit variable to at least 12454 and retry the command.</span><br><span class="line">Automatic merge failed; fix conflicts and then commit the result.</span><br></pre></td></tr></table></figure></p>
<p>Try to set <code>rename.limit</code> to larger value and run commands again but that does not help, <a href="https://stackoverflow.com/questions/4722423/how-to-merge-two-branches-with-different-directory-hierarchies-in-git" target="_blank" rel="noopener">https://stackoverflow.com/questions/4722423/how-to-merge-two-branches-with-different-directory-hierarchies-in-git</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config merge.renameLimit 999999</span><br><span class="line">git merge --abort</span><br><span class="line">git config --unset merge.renameLimit</span><br></pre></td></tr></table></figure></p>
<p>So far these commands help:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git reset --hard origin/master</span><br><span class="line">git fetch -p</span><br><span class="line">git pull origin master</span><br><span class="line"></span><br><span class="line"><span class="comment">## if failed again, run</span></span><br><span class="line">git merge --abort</span><br><span class="line">git reset --hard origin/master</span><br><span class="line">git pull origin master</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Deque</title>
    <url>/2020/04/11/java-deque/</url>
    <content><![CDATA[<p>关于Deque，之前我的总结是，如果要当作Stack使用，则stick to Stack methods，比如push, pop, peek。如果当作Queue使用，则stick to Queue method，比如add/offer, poll/remove, peek。在实现上，我一般使用的是ArrayDeque, a resizable double-ended array。</p>
<p>今天突然想到一个问题，用Deque实现的Queue或者Stack，在使用enhanced for loop的时候，Java是怎么知道元素弹出的正确顺序呢? 或者如果混用Queue和Stack的方法，peek会弹出什么结果？iterator会给出什么顺序的结果呢？</p>
<p>我们来看看ArrayDeque的源码:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> head;</span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> tail;</span><br></pre></td></tr></table></figure></p>
<p>这里有2个pointers, head和tail，当arraydeque是empty的时候，head和tail重叠。</p>
<p>对于push来说，移动的是head，head的值减1再使用，并且用的是modulus circularly decrement。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Pushes an element onto the stack represented by this deque.  In other</span></span><br><span class="line"><span class="comment">* words, inserts the element at the front of this deque.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* &lt;p&gt;This method is equivalent to &#123;<span class="doctag">@link</span> #addFirst&#125;.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> e the element to push</span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> NullPointerException if the specified element is null</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">push</span><span class="params">(E e)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    addFirst(e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Inserts the specified element at the front of this deque.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> e the element to add</span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> NullPointerException if the specified element is null</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addFirst</span><span class="params">(E e)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="keyword">final</span> Object[] es = elements;</span><br><span class="line">    es[head = dec(head, es.length)] = e;</span><br><span class="line">    <span class="keyword">if</span> (head == tail)</span><br><span class="line">        grow(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Circularly decrements i, mod modulus.</span></span><br><span class="line"><span class="comment">* Precondition and postcondition: 0 &lt;= i &lt; modulus.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">dec</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> modulus)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (--i &lt; <span class="number">0</span>) i = modulus - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>对于add/offer来说，tail的值用了再加1，并且用的是modulus circularl increment。<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Inserts the specified element at the end of this deque.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* &lt;p&gt;This method is equivalent to &#123;<span class="doctag">@link</span> #addLast&#125;.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> e the element to add</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span> &#123;<span class="doctag">@code</span> true&#125; (as specified by &#123;<span class="doctag">@link</span> Collection#add&#125;)</span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> NullPointerException if the specified element is null</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    addLast(e);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Inserts the specified element at the end of this deque.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* &lt;p&gt;This method is equivalent to &#123;<span class="doctag">@link</span> #add&#125;.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@param</span> e the element to add</span></span><br><span class="line"><span class="comment">* <span class="doctag">@throws</span> NullPointerException if the specified element is null</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addLast</span><span class="params">(E e)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="keyword">final</span> Object[] es = elements;</span><br><span class="line">    es[tail] = e;</span><br><span class="line">    <span class="keyword">if</span> (head == (tail = inc(tail, es.length)))</span><br><span class="line">        grow(<span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Circularly increments i, mod modulus.</span></span><br><span class="line"><span class="comment">* Precondition and postcondition: 0 &lt;= i &lt; modulus.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">inc</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> modulus)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (++i &gt;= modulus) i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>peek总是从head pointer取值<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Retrieves, but does not remove, the head of the queue represented by</span></span><br><span class="line"><span class="comment">* this deque, or returns &#123;<span class="doctag">@code</span> null&#125; if this deque is empty.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* &lt;p&gt;This method is equivalent to &#123;<span class="doctag">@link</span> #peekFirst&#125;.</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span> the head of the queue represented by this deque, or</span></span><br><span class="line"><span class="comment">*         &#123;<span class="doctag">@code</span> null&#125; if this deque is empty</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">peek</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> peekFirst();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>iterator总是从head pointer -&gt; tail pointer<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">* Returns an iterator over the elements in this deque.  The elements</span></span><br><span class="line"><span class="comment">* will be ordered from first (head) to last (tail).  This is the same</span></span><br><span class="line"><span class="comment">* order that elements would be dequeued (via successive calls to</span></span><br><span class="line"><span class="comment">* &#123;<span class="doctag">@link</span> #remove&#125; or popped (via successive calls to &#123;<span class="doctag">@link</span> #pop&#125;).</span></span><br><span class="line"><span class="comment">*</span></span><br><span class="line"><span class="comment">* <span class="doctag">@return</span> an iterator over the elements in this deque</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Iterator&lt;E&gt; <span class="title">iterator</span><span class="params">()</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> DeqIterator();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>所以现在情形就很清楚了，来看一个例子。首先按照顺序push [1 2 3], 这时peek是3，然后再add/offer [4 5 6], 这时peek还是3，然后iterator的结果是: [3 2 1 4 5 6]<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Deque&lt;Integer&gt; dq = <span class="keyword">new</span> ArrayDeque&lt;&gt;();</span><br><span class="line">dq.push(<span class="number">1</span>);</span><br><span class="line">dq.push(<span class="number">2</span>);</span><br><span class="line">dq.push(<span class="number">3</span>);</span><br><span class="line"><span class="comment">// now peek is 3</span></span><br><span class="line">dq.add(<span class="number">4</span>);</span><br><span class="line">dq.add(<span class="number">5</span>);</span><br><span class="line">dq.add(<span class="number">6</span>);</span><br><span class="line"><span class="comment">// now peek is still 3</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> ele: dq)</span><br><span class="line">&#123;</span><br><span class="line">    System.out.println(ele);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 3 2 1 4 5 6</span></span><br></pre></td></tr></table></figure></p>
<p><img src="https://drive.google.com/uc?id=1KaVUCoUDu-3o7_hqEyCwKyDEstJc-9_z" alt=""></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java equals Method</title>
    <url>/2019/11/03/java-overwrite-equals/</url>
    <content><![CDATA[<p>This is the first Java post in my blog, actually I have lots of summaries about Java in recently years, they just get accumulated so I decide to post here.</p>
<p>Also, start from next week, I will dive into API work.</p>
<p>When you define a new class and it will deal with hash thing, don’t forget to overwrite the <code>equals</code> method, or <code>compare</code> method if they need to be sorted in natural order, or implement <code>Comparator</code> interface for ordering by other rules.</p>
<p>For example:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Complex</span> </span>&#123; </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">double</span> re, im; </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Complex</span><span class="params">(<span class="keyword">double</span> re, <span class="keyword">double</span> im)</span> </span>&#123; </span><br><span class="line">        <span class="keyword">this</span>.re = re; </span><br><span class="line">        <span class="keyword">this</span>.im = im; </span><br><span class="line">    &#125; </span><br><span class="line">    <span class="comment">// Overriding equals() to compare two Complex objects </span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123; </span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123; <span class="keyword">return</span> <span class="keyword">false</span>; &#125;</span><br><span class="line">        <span class="keyword">if</span> (o == <span class="keyword">this</span>) &#123; <span class="keyword">return</span> <span class="keyword">true</span>; &#125; </span><br><span class="line">        <span class="keyword">if</span> (!(o <span class="keyword">instanceof</span> Complex)) &#123; <span class="keyword">return</span> <span class="keyword">false</span>; &#125; </span><br><span class="line">        Complex c = (Complex) o; </span><br><span class="line">        <span class="comment">// Compare the data members and return accordingly  </span></span><br><span class="line">        <span class="keyword">return</span> Double.compare(re, c.re) == <span class="number">0</span></span><br><span class="line">                &amp;&amp; Double.compare(im, c.im) == <span class="number">0</span>; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><a href="https://stackoverflow.com/questions/16970210/java-treeset-remove-and-contains-not-working" target="_blank" rel="noopener">https://stackoverflow.com/questions/16970210/java-treeset-remove-and-contains-not-working</a></p>
<p>One thing I want to emphasize is <code>TreeSet</code>, the object in tree set use its compareTo (or compare) method, so two elements that are deemed equal by this method are, from the standpoint of the set, equal. The behavior of a set is well-defined even if its ordering is inconsistent with equals; it just fails to obey the general contract of the Set interface.</p>
<p>To be more accurate, <code>TreeSet</code> is an implementation of <code>SortedSet</code><br>If you want a <code>.equals()/.hashCode()</code> compatible set, use, for instance, a HashSet.</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java LinkedList</title>
    <url>/2019/11/07/java-linkedlist/</url>
    <content><![CDATA[<p>About LinkedList operation time complexity:</p>
<p>Adding to either end of a linked list does not require a traversal, as long as you keep a reference to both ends of the list. This is what Java does for its <code>add</code> and <code>addFirst</code>/<code>addLast</code> methods.</p>
<p>Same goes for parameterless <code>remove</code> and <code>removeFirst</code>/<code>removeLast</code> methods - they operate on list ends.</p>
<p><code>remove(int)</code> and <code>remove(Object)</code> operations, on the other hand, are not O(1). They requires traversal, so their costs are O(n).</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins Git Check in</title>
    <url>/2020/06/02/jenkins-git-checkin/</url>
    <content><![CDATA[<p>有时有这种需求: pipeline 结束后，有新生成或被改动的文件，需要把这些变化check in 到 remote github repository中，其实就是git add/commit/push 操作。这在Jenkins中如何实现呢?</p>
<p>注意这里的Github repository is secured, 比如Github Enterprise。一般我们设置SSH credentials access (SSH Username with private key), 这个credential 会提前写到 Jenkins Credential Management中，在配置pipeline的时候，最后一步设置SCM -&gt; Git, 除了输入Reporsity URL, 还要add SSH credential. 这样Jenkins才能正常地check out code. 当然，在pipeline steps 中 check out code也行，比如使用 <code>git</code>, <code>checkout</code> snippets.</p>
<p>对于check in code, 也可以使用snippet 比如:</p>
<ul>
<li><p><code>withCredentials</code><br>Bind credential to variables, 这个snippet 可以提供通过环境变量访问credential. 但在这里对于git SSH credential access, 需要设置让git去使用这个变量，this is unknown to me.</p>
</li>
<li><p><code>sshagent</code>:<br>需要install plugin: <a href="https://plugins.jenkins.io/ssh-agent/" target="_blank" rel="noopener">https://plugins.jenkins.io/ssh-agent/</a>, pass credential to it. 然后把git 操作放在这个snippet中即可. 比如:</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">steps &#123;</span><br><span class="line">  sshagent([<span class="string">'&lt;credential id&gt;'</span>]) &#123;</span><br><span class="line">    <span class="comment">// fetch a branch, edit and check in the code</span></span><br><span class="line">    sh <span class="string">'''</span></span><br><span class="line"><span class="string">      ## or git pull other repository</span></span><br><span class="line"><span class="string">      git fetch</span></span><br><span class="line"><span class="string">      git checkout $TARGET_BRANCH</span></span><br><span class="line"><span class="string">      git reset --hard origin/$TARGET_BRANCH</span></span><br><span class="line"><span class="string">      git pull</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      CHECKOUT_BRANCH="feature/$&#123;TARGET_BRANCH&#125;-$&#123;COMPONENT_NAME&#125;-$&#123;COMPONENT_VERSION&#125;"</span></span><br><span class="line"><span class="string">      echo "Creating feature branch: $CHECKOUT_BRANCH"</span></span><br><span class="line"><span class="string">      git checkout -b $CHECKOUT_BRANCH</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">      sed -i "/.*version.*/c\  version: $COMPONENT_VERSION" files/$COMPONENT_NAME.yaml</span></span><br><span class="line"><span class="string">      git add files/$COMPONENT_NAME.yaml</span></span><br><span class="line"><span class="string">      ## list file changes</span></span><br><span class="line"><span class="string">      git status</span></span><br><span class="line"><span class="string">      git -c user.name="unibot" -c user.email="unibot@il.example.com" commit -m "Update $&#123;COMPONENT_NAME&#125; to $&#123;COMPONENT_VERSION&#125;"</span></span><br><span class="line"><span class="string">      git push --set-upstream origin $CHECKOUT_BRANCH</span></span><br><span class="line"><span class="string">      '''</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>参考这里的代码:<br><a href="https://github.com/jenkinsci/pipeline-examples/blob/master/pipeline-examples/push-git-repo/pushGitRepo.groovy" target="_blank" rel="noopener">https://github.com/jenkinsci/pipeline-examples/blob/master/pipeline-examples/push-git-repo/pushGitRepo.groovy</a></p>
</li>
</ul>
<p>在这里，如果我没有权限去安装<code>sshagent</code> plugin, 还有一个比较好的办法是，设置一个 dedicated node with pre-set SSH credential. 然后需要执行git check in任务的时候指定在这个node上进行即可。</p>
]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins CI/CD Concept</title>
    <url>/2019/07/22/jenkins-concepts/</url>
    <content><![CDATA[<p><code>Jenkins</code> is a great tool for continuous integration and continuous delivery but what exactly does the <code>CI/CD</code> mean?</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">            +-----------------------+           +----------------------+           +------------------------+</span><br><span class="line">            |                       |           |                      |           |                        |</span><br><span class="line">            |   continuous          |           |   continuous         |           |   continuous           |</span><br><span class="line">            |         integration   +-----------&gt;         delivery     +-----------+       development      |</span><br><span class="line">            |                       |           |                      |           |                        |</span><br><span class="line">            +---------+-------------+           +--------------+-------+           +---------------------+--+</span><br><span class="line">                      ^                                        ^                                         ^</span><br><span class="line">                      |                                        |                                         |</span><br><span class="line">                      |                                        |                                         |</span><br><span class="line">+---------------------+----------+              +--------------+----------------------+      +-----------+--------------------+</span><br><span class="line">|  kick off depends on commits   |              |  platform specific testings:        |      | ready to be used by customers  |</span><br><span class="line">|  or schedule                   |              |  security, performance, API...      |      |                                |</span><br><span class="line">+-----------+--------------------+------+       |                                     |      +--------------------------------+</span><br><span class="line">            |   code version control    |       +-------------------------------------+</span><br><span class="line">            |   branching strategy      |</span><br><span class="line">+-----------+-------------+-------------+</span><br><span class="line">|  regression testings    |</span><br><span class="line">|                         |</span><br><span class="line">+-------------------------+</span><br></pre></td></tr></table></figure>
<p><code>Regression testing</code>: re-running functional and non-functional tests to ensure that previously developed and tested software still performs after a change. If not, that would be called a <code>regression</code>. Changes that may require regression testing include bug fixes, software enhancements, configuration changes, etc.</p>
<p>Git branching:<br><a href="https://nvie.com/posts/a-successful-git-branching-model/" target="_blank" rel="noopener">Branching strategy: feature branch and primary development branch</a></p>
<p>Devops practice:<br><a href="https://docs.cloudfoundry.org/devguide/deploy-apps/blue-green.html" target="_blank" rel="noopener">Blue-green deploy</a><br><a href="https://en.wikipedia.org/wiki/Smoke_testing_(software" target="_blank" rel="noopener">Smoke/Sanity test</a>)</p>
<h2 id="Resoucrs"><a href="#Resoucrs" class="headerlink" title="Resoucrs"></a>Resoucrs</h2><p><a href="https://www.infoworld.com/article/3271126/what-is-cicd-continuous-integration-and-continuous-delivery-explained.html" target="_blank" rel="noopener"><strong>What is CI/CD? Continuous integration and continuous delivery explained</strong></a><br><code>Continuous integration</code> is a coding philosophy and set of practices that drive development teams to implement small changes and check in code to version control repositories frequently. </p>
<p><code>Continuous delivery</code> automates the delivery of applications to selected infrastructure environments.</p>
<p>A mature <code>CI/CD</code> practice has the option of implementing <code>continuous deployment</code> where application changes run through the <code>CI/CD</code> pipeline and passing builds are deployed directly to production environments. </p>
<p>A best practice is to enable and require developers to run all or a subset of <code>regressions tests</code> in their local environments (or use <code>Travis</code>). This step ensures that developers only commit code to version control after regression tests pass on the code changes.</p>
<p>Test that require a full delivery environment such as performance and security testing are often integrated into CD and performed after builds are delivered to target environments.</p>
<p>To recap, <code>CI</code> packages and tests software builds and alerts developers if their changes failed any unit tests. <code>CD</code> is the automation that delivers changes to infrastructure and executes additional tests. </p>
<p><code>CI/CD</code> is a devops best practice because it addresses the misalignment between developers who want to push changes frequently, with operations that want stable applications.</p>
<p><a href="https://www.redhat.com/en/topics/devops/what-is-ci-cd" target="_blank" rel="noopener"><strong>What is CI/CD</strong></a><br>Continuous deployment (the other possible “CD”) can refer to automatically releasing a developer’s changes from the repository to production, where it is usable by customers. </p>
]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes API curl Access</title>
    <url>/2019/11/06/k8s-api/</url>
    <content><![CDATA[<p>In the situation that issue k8s instructions from inside the container, usually we use <code>curl</code> command to do that (if you have kubectl binary in container’s execution path, you can use kubectl command as well).</p>
<p>First you need credentials and api server information:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## MY_POD_NAMESPACE</span></span><br><span class="line">NAMESPACE=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)</span><br><span class="line">K8S=https://<span class="variable">$KUBERNETES_SERVICE_HOST</span>:<span class="variable">$KUBERNETES_SERVICE_PORT</span></span><br><span class="line">CACERT=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)</span><br></pre></td></tr></table></figure></p>
<p>You can get these all from environment variables, when create the pod, k8s has already injected these information into the containers.</p>
<p>Of course, if the service account you use does not have full privilege, the API access is limited.</p>
<p>then for example, get the detail of current pod:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">POD_NAME=<span class="string">"<span class="variable">$MY_POD_NAME</span>"</span></span><br><span class="line">NS=<span class="string">"<span class="variable">$MY_POD_NAMESPACE</span>"</span></span><br><span class="line">OUT_FILE=$(mktemp /tmp/pod-schedule.XXXX)</span><br><span class="line"></span><br><span class="line"><span class="comment">## http_code is the return status code</span></span><br><span class="line">http_code=$(curl -w  <span class="string">"%&#123;http_code&#125;"</span> -sS  --cacert <span class="variable">$CACERT</span>  -H <span class="string">"Content-Type: application/json"</span> -H <span class="string">"Accept: application/json, */*"</span> -H <span class="string">"Authorization: Bearer <span class="variable">$TOKEN</span>"</span> <span class="string">"<span class="variable">$K8S</span>/api/v1/namespaces/<span class="variable">$NS</span>/pods/<span class="variable">$POD_NAME</span>"</span> -o <span class="variable">$OUT_FILE</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$http_code</span> -ne 200 ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"&#123;\"result\": \"Failure\", \"httpReturnCode\":<span class="variable">$http_code</span>&#125;"</span> |<span class="variable">$&#123;JQ&#125;</span> <span class="string">'.'</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">image=$(cat <span class="variable">$OUT_FILE</span> |jq <span class="string">'.spec.containers[] | select(.name=="xxx") | .image'</span>)</span><br></pre></td></tr></table></figure></p>
<p>How do I know the curl path to request?<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pod -v 10</span><br></pre></td></tr></table></figure></p>
<p>this will show you verbose message (curl under the hood), then you can get the path and use it in your curl command.</p>
<p>Not all kubectl commands are clearly with curl, for example <code>kubectl exec</code>, still need some efforts to know.</p>
<p>references:<br><a href="https://blog.openshift.com/executing-commands-in-pods-using-k8s-api/" target="_blank" rel="noopener">https://blog.openshift.com/executing-commands-in-pods-using-k8s-api/</a><br><a href="https://docs.okd.io/latest/rest_api/api/v1.Pod.html#Post-api-v1-namespaces-namespace-pods-name-exec" target="_blank" rel="noopener">https://docs.okd.io/latest/rest_api/api/v1.Pod.html#Post-api-v1-namespaces-namespace-pods-name-exec</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Commands Alias</title>
    <url>/2019/06/15/k8s-alias/</url>
    <content><![CDATA[<p>It’s very tedious to type full command when you operate on K8s cluster, this blog is the summary of alias I adopt in daily work.</p>
<p>Put these alias to <code>$HOME/.bashrc</code>, then source it or next time when you login they will take effect.</p>
<p>Some qucik commands used to create resources:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## --type default is ClusterIP</span></span><br><span class="line"><span class="comment">## --target-port default is --port</span></span><br><span class="line">kubectl expose pod &lt;podname&gt; [--<span class="built_in">type</span>=NodePort] --port=80 [--target-port=80] --name=&lt;svcname&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## run command in pod</span></span><br><span class="line">kubectl <span class="built_in">exec</span> -n &lt;namespace&gt; &lt;podname&gt; -- bash -c <span class="string">"commands"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## check log</span></span><br><span class="line">kubectl logs -f &lt;pod name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## scale up/down</span></span><br><span class="line">kubectl scale deploy &lt;deploy name&gt; --replicas=5</span><br></pre></td></tr></table></figure></p>
<p>These are some alias used to run test:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create and go into cirros pod to do network test</span></span><br><span class="line"><span class="comment">## exit will delete the pod</span></span><br><span class="line"><span class="comment">## --restart=Never means create a pod instead of deployment</span></span><br><span class="line"><span class="built_in">alias</span> kbt=<span class="string">'kubectl run testpod -it --rm --restart=Never --image=cirros -- /bin/sh'</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## docker shortcut</span></span><br><span class="line"><span class="built_in">alias</span> di=<span class="string">'docker images'</span></span><br><span class="line"><span class="built_in">alias</span> dp=<span class="string">'docker ps -a'</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">alias</span> kbc=<span class="string">'kubectl'</span></span><br><span class="line"><span class="built_in">alias</span> kbn=<span class="string">'kubectl get nodes'</span></span><br><span class="line"><span class="comment">## can replace with your working namespace</span></span><br><span class="line"><span class="comment">## pods</span></span><br><span class="line"><span class="built_in">alias</span> kbp=<span class="string">'kubectl get pods --all-namespaces'</span></span><br><span class="line"><span class="comment">## deployments</span></span><br><span class="line"><span class="built_in">alias</span> kbd=<span class="string">'kubectl get deploy -n zen | grep -E "xmeta|services"'</span></span><br><span class="line"><span class="comment">## statefulsets</span></span><br><span class="line"><span class="built_in">alias</span> kbsts=<span class="string">'kubectl get sts -n zen | grep -E "conductor|compute"'</span></span><br><span class="line"><span class="comment">## services</span></span><br><span class="line"><span class="built_in">alias</span> kbs=<span class="string">'kubectl get svc -n test-1'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## get into pods</span></span><br><span class="line">kbl()</span><br><span class="line">&#123;</span><br><span class="line">  pod=<span class="variable">$1</span></span><br><span class="line">  <span class="comment">## get namepace</span></span><br><span class="line">  ns=$(kubectl get pod --all-namespaces | grep <span class="variable">$pod</span> | awk &#123;<span class="string">'print $1'</span>&#125;)</span><br><span class="line">  kubectl <span class="built_in">exec</span> -it <span class="variable">$pod</span> sh -n <span class="variable">$ns</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">### for fixed pod name</span></span><br><span class="line"><span class="built_in">alias</span> gocond=<span class="string">'kubectl exec -it is-en-conductor-0 bash -n test-1'</span></span><br><span class="line"><span class="built_in">alias</span> gocomp0=<span class="string">'kubectl exec -it is-engine-compute-0 bash -n test-1'</span></span><br><span class="line"><span class="comment">### for dynamic pod name</span></span><br><span class="line">goxmeta()</span><br><span class="line">&#123;</span><br><span class="line">  isxmetadockerpod=`kubectl get pods --field-selector=status.phase=Running -n <span class="built_in">test</span>-1 | grep is-xmetadocker-pod | awk &#123;<span class="string">'print $1'</span>&#125;`</span><br><span class="line">  kubectl <span class="built_in">exec</span> -it <span class="variable">$&#123;isxmetadockerpod&#125;</span> bash -n <span class="built_in">test</span>-1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gosvc()</span><br><span class="line">&#123;</span><br><span class="line">  isservicesdockerpod=`kubectl get pods --field-selector=status.phase=Running -n <span class="built_in">test</span>-1 | grep is-servicesdocker-pod | awk &#123;<span class="string">'print $1'</span>&#125;`</span><br><span class="line">  kubectl <span class="built_in">exec</span> -it <span class="variable">$&#123;isservicesdockerpod&#125;</span> bash -n <span class="built_in">test</span>-1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## clean pods</span></span><br><span class="line"><span class="built_in">alias</span> rmxmeta=<span class="string">'kubectl delete svc is-xmetadocker -n test-1; kubectl delete deploy is-xmetadocker-pod -n test-1; rm -rf /mnt/IIS_test-1/Repository/*'</span></span><br><span class="line"><span class="built_in">alias</span> rmsvc=<span class="string">'kubectl delete svc is-servicesdocker -n test-1; kubectl delete deploy is-servicesdocker-pod -n test-1; rm -rf /mnt/IIS_test-1/Services/*'</span></span><br><span class="line"><span class="built_in">alias</span> rmcond=<span class="string">'kubectl delete svc is-en-conductor-0 -n test-1; kubectl delete svc en-cond -n test-1; kubectl delete statefulset is-en-conductor -n test-1; rm -rf /mnt/IIS_test-1/Engine/test-1/is-en-conductor-0/'</span></span><br><span class="line"><span class="built_in">alias</span> rmcomp=<span class="string">'kbc delete svc conductor-0 -n test-1; kbc delete statefulset is-engine-compute -n test-1; rm -rf /mnt/IIS_test-1/Engine/test-1/is-engine-compute*'</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins Pass Variables between Stages</title>
    <url>/2020/06/04/jenkins-pass-vars/</url>
    <content><![CDATA[<p>今天遇到一个问题，如何将在一个stage中产生的变量，传递到另一个stage中。一种解决办法是使用global variable, for example, in declarative pipeline:<br><a href="https://serverfault.com/questions/884764/jenkins-pipeline-file-passing-jenkinsfile-variables-into-further-commands/884798" target="_blank" rel="noopener">https://serverfault.com/questions/884764/jenkins-pipeline-file-passing-jenkinsfile-variables-into-further-commands/884798</a><br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="comment">// variable to be used</span></span><br><span class="line"><span class="keyword">def</span> jobBaseName</span><br><span class="line"></span><br><span class="line">stage (<span class="string">'Construct Img name'</span>) &#123;</span><br><span class="line">  <span class="comment">// this is from scripted pipeline syntax</span></span><br><span class="line">  jobBaseName = sh(</span><br><span class="line"><span class="symbol">    script:</span> <span class="string">"echo $&#123;BUILD_TAG&#125; | awk '&#123;print tolower($0)&#125;' | sed 's/jenkins-//'"</span>,</span><br><span class="line"><span class="symbol">    returnStdout:</span> <span class="literal">true</span></span><br><span class="line">  )</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">stage (<span class="string">'Build Target Container'</span>) &#123;</span><br><span class="line">  sh <span class="string">"ssh -i ~/ssh_keys/key.key user@somehost 'cd /dockerdata/build/$&#123;BUILD_TAG&#125; &amp;&amp; docker build -t localrepo/$&#123;jobBaseName&#125;:$&#123;BUILD_NUMBER&#125; .'"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>还有人通过将变量写入文件中，再从另一个stage读取加载的方式，但这需要保证Stages are running on the same node agent.</p>
<p>此外，关于Jenkins中的<code>environment variable</code> 和 <code>build parameters</code>，有如下需要注意的地方:<br><a href="https://stackoverflow.com/questions/50398334/what-is-the-relationship-between-environment-and-parameters-in-jenkinsfile-param" target="_blank" rel="noopener">https://stackoverflow.com/questions/50398334/what-is-the-relationship-between-environment-and-parameters-in-jenkinsfile-param</a></p>
<p>Basically it works as follow</p>
<ul>
<li><code>env</code> contains all environment variables, for example: <code>env.BUILD_NUMBER</code></li>
<li>Jenkins pipeline automatically creates a global variable for each environment variable</li>
<li>params contains all build parameters, for example: <code>params.WKC_BUILD_NUMBER</code></li>
<li>Jenkins also automatically creates an environment variable for each build parameter (and as a consequence of second point a global variable).</li>
</ul>
<p>Environment variables can be overridden or unset (via Groovy script block) but params is an <strong>immutable</strong> Map and cannot be changed. Best practice is to always use params when you need to get a build parameter.</p>
<p>这些信息哪里来的呢？在配置pipeline时，查看pipeline syntax -&gt; Global Variables Reference.</p>
]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Container Command and Args</title>
    <url>/2019/09/10/k8s-cmd-args-format/</url>
    <content><![CDATA[<p>The format of <code>command</code> and <code>args</code> syntax in kubernetes yaml really make me crazy, when the entrypoint has long or multiple arguments, can be wrote in multiple lines instead of one line for better view:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">  container:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">["/bin/bash",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"--"</span><span class="string">]</span></span><br><span class="line"><span class="attr">    args:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">echo</span> <span class="string">"start"</span><span class="string">;</span></span><br><span class="line">      <span class="string">while</span> <span class="literal">true</span><span class="string">;</span> <span class="string">do</span></span><br><span class="line">        <span class="string">echo</span> <span class="string">$(hostname)</span> <span class="string">$(date)</span> <span class="string">&gt;&gt;</span> <span class="string">/html/index.html;</span></span><br><span class="line">        <span class="string">sleep</span> <span class="number">10</span><span class="string">;</span></span><br><span class="line">      <span class="string">done;</span></span><br><span class="line">      <span class="string">echo</span> <span class="string">"done!"</span><span class="string">;</span></span><br></pre></td></tr></table></figure></p>
<p>Another format:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="string">...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">myapp-container</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">["/bin/bash",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"--"</span><span class="string">]</span></span><br><span class="line"><span class="attr">    args:</span></span><br><span class="line">       <span class="string">["echo</span> <span class="string">\"check</span> <span class="string">something...\";</span></span><br><span class="line">        <span class="string">if</span> <span class="string">[[</span> <span class="string">!</span> <span class="bullet">-f</span> <span class="string">/root/.link</span> <span class="string">]];</span> <span class="string">then</span></span><br><span class="line">          <span class="string">echo</span> <span class="string">\"file</span> <span class="string">does</span> <span class="string">not</span> <span class="string">exist!\";</span></span><br><span class="line">          <span class="string">echo</span> <span class="string">\"no!\";</span></span><br><span class="line">        <span class="string">else</span></span><br><span class="line">          <span class="string">echo</span> <span class="string">\"file</span> <span class="string">is</span> <span class="string">there!\";</span></span><br><span class="line">        <span class="string">fi;</span></span><br><span class="line">        <span class="string">echo</span> <span class="string">\"done!\""]</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that the format is error-prone, every command should end with <code>;</code>, for example the <code>while</code> and <code>if</code> above. I separate them into several lines for good looking, but they actually are one line command.</p>
</blockquote>
<p>For one command with multiple options or parameters, can be described as below, no <code>args</code> field:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="attr">- command:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">/usr/local/bin/etcd</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">--data-dir=/var/etcd/data</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">--name=example-etcd-cluster-65zvs2mt8b</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">--initial-advertise-peer-urls=http://example-etcd-cluster-65zvs2mt8b.example-etcd-cluster.default.svc:2380</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">--listen-peer-urls=http://0.0.0.0:2380</span></span><br><span class="line"><span class="bullet">  -</span> <span class="bullet">--listen-client-urls=http://0.0.0.0:2379</span></span><br><span class="line">  <span class="string">...</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Dashboard</title>
    <url>/2019/09/15/k8s-dashboard/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Dashboard relies on Metrics Server or Heapster to sample and provide running parameters of the cluster.<br><a href="https://github.com/kubernetes/dashboard" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard</a></p>
<p>Metrics server:<br><a href="https://github.com/kubernetes-incubator/metrics-server" target="_blank" rel="noopener">https://github.com/kubernetes-incubator/metrics-server</a><br>other tools:<br><a href="https://blog.containership.io/kubernetes-metrics-collection-options/" target="_blank" rel="noopener">https://blog.containership.io/kubernetes-metrics-collection-options/</a></p>
<p>TODO:</p>
<ol>
<li>how to setup dashboard can be accessed from outside of the cluster</li>
<li>cert things?</li>
<li>user admission, for example: cluster admin vs regular user</li>
<li>authenticate method: token or kubeconfig</li>
</ol>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Calico Bandwidth Explore</title>
    <url>/2019/07/30/k8s-calico-bandwidth/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>I have talked about setting up pod network in Kubernetes cluster using <code>Calico</code> network add-on in this post <a href="https://chengdol.github.io/2018/12/17/k8s-kubeadm-setup/" target="_blank" rel="noopener"><code>&lt;&lt;Set Up K8s Cluster by Kubeadm&gt;&gt;</code></a>. Recently I was involved in one issue from performance team, they complained that the network has bottleneck in calico, let’s see what happened and learn new things!</p>
<h2 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h2><p>The performance team set up a 6 nodes cluster with 1 master and 5 workers. Each machine has 48 cpu cores, 128GB memory, 2T+ disk and 10000Mb/s network speed.</p>
<p>These are the test cases:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="number">10</span> <span class="string">jobs</span> <span class="string">for</span> <span class="string">each</span> <span class="string">user(8</span> <span class="string">small</span> <span class="string">jobs,</span> <span class="number">1</span> <span class="string">middle</span> <span class="string">job</span> <span class="string">and</span> <span class="number">1</span> <span class="string">large</span> <span class="string">job)</span></span><br><span class="line"></span><br><span class="line"><span class="number">8</span> <span class="string">small</span> <span class="string">jobs(RowGen</span> <span class="bullet">-&gt;</span> <span class="string">XX</span> <span class="bullet">-&gt;</span> <span class="string">Peek),</span> <span class="number">1</span> <span class="string">job</span> <span class="string">unit</span></span><br><span class="line"><span class="string">aggregate</span> <span class="string">job</span>                         <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">filter</span> <span class="string">job</span>                            <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">funnel_continuous</span>                     <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">funnel</span> <span class="string">sort</span>                           <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">join</span> <span class="string">job</span>                              <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">lookup</span>                                <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">sort</span> <span class="string">job</span>                              <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"><span class="string">Transformation</span>                        <span class="bullet">--</span> <span class="number">10</span> <span class="string">millions</span> <span class="string">records</span> <span class="string">(neally</span> <span class="number">2.2</span><span class="string">G)</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="string">middle</span> <span class="string">job,</span> <span class="number">2</span> <span class="string">job</span> <span class="string">units</span></span><br><span class="line"><span class="string">Middle_Job</span>                            <span class="bullet">--</span> <span class="number">50</span> <span class="string">million</span> <span class="string">records(nearly</span> <span class="number">11</span><span class="string">G)</span></span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="string">Large</span> <span class="string">job,</span> <span class="number">3</span> <span class="string">job</span> <span class="string">units</span></span><br><span class="line"><span class="string">Large</span> <span class="string">job</span>                             <span class="bullet">--</span> <span class="number">10</span> <span class="string">million</span> <span class="string">records(nearly</span> <span class="number">2.1</span><span class="string">GB)</span></span><br></pre></td></tr></table></figure></p>
<p>They ran concurrent users with N compute pods and found that the bottleneck is in calico network:<br><img src="https://drive.google.com/uc?id=1FMc1eRf_FCG2TI1TRWeLLKE2GJ6qysBf" alt=""></p>
<p>BTY, there are still enough resources(CPU, Memory and Disk I/O) to support DataStage scale up for DS concurrent users to run jobs on nodes and pods. But the network bandwidth between pods is not enough to support it.</p>
<h2 id="iperf3-Command"><a href="#iperf3-Command" class="headerlink" title="iperf3 Command"></a>iperf3 Command</h2><p>They use <code>iperf3</code>, a TCP, UDP, and SCTP network bandwidth measurement tool, measure memory-to-memory performance access a network. Github <a href="https://github.com/esnet/iperf/blob/master/README.md" target="_blank" rel="noopener">link</a></p>
<p>The <a href="https://fasterdata.es.net/performance-testing/network-troubleshooting-tools/iperf/" target="_blank" rel="noopener">Usage</a> is simple, <code>wget</code> one version tar ball from release page, untar and build it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./configure; make; make install</span><br></pre></td></tr></table></figure></p>
<p>The <code>iperf3</code> will be added to exectution <code>PATH</code> automatically.</p>
<p>More simple <a href="https://datapacket.com/blog/10gbps-network-bandwidth-test-iperf-tutorial/" target="_blank" rel="noopener">demos</a></p>
<h3 id="Node-to-Node"><a href="#Node-to-Node" class="headerlink" title="Node to Node"></a>Node to Node</h3><p>in one node, set up server on default port 5201<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iperf3 -s</span><br></pre></td></tr></table></figure></p>
<p>in another node, set up client and run test:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iperf3 -c &lt;server IP&gt; -P &lt;parallel number&gt;</span><br></pre></td></tr></table></figure></p>
<p>more specific, this will transfer /large_file in client to /large_file in server, time interval is 40 seconds<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## server</span></span><br><span class="line">iperf3 -s -F /large_file</span><br><span class="line"><span class="comment">## client</span></span><br><span class="line">iperf3 -c &lt;server ip&gt; -i 1 -t 40 -F /large_file</span><br></pre></td></tr></table></figure></p>
<h3 id="Pod-to-Pod"><a href="#Pod-to-Pod" class="headerlink" title="Pod to Pod"></a>Pod to Pod</h3><p>The same as <code>Node to Node</code>, but wget and build <code>iperf3</code> inside pod container and use the container’s IP (in container run <code>hostname -I</code>), for example, I flood data from <code>is-en-conductor-0</code> pod to <code>is-engine-compute-12</code> pod, they reside in different host machine.<br><img src="https://drive.google.com/uc?id=1WPt2oBzL0bvq1_vCzF9eUqZXiwNfNzOX" alt=""><br><img src="https://drive.google.com/uc?id=1Y8nbhUAR0BBbdEcFeNqSG9g2xk8UjyEo" alt=""></p>
<h2 id="Thinking"><a href="#Thinking" class="headerlink" title="Thinking"></a>Thinking</h2><p>After I reproducing the tests, I was thinking <code>Calico</code> is a widely used add-on that shouldn’t have such obvious bottleneck, otherwise many people will complain and improve it.</p>
<p>Is there any improper configuration?</p>
<ul>
<li><p>Configuring IP-in-IP<br>By default, the manifests enable <code>IP-in-IP</code> encapsulation across subnets (additional overhead compare to non <code>IP-in-IP</code>), if don’t need it (when? I am not very clear), disable it in calico manifest yaml file:</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Enable IPIP</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">CALICO_IPV4POOL_IPIP</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">"off"</span></span><br></pre></td></tr></table></figure>
<p>See this <a href="https://github.com/projectcalico/calico/issues/922" target="_blank" rel="noopener"><code>IP-in-IP</code> issue</a><br>I am using <code>Calico</code> version 3.3, <a href="https://docs.projectcalico.org/v3.3/usage/configuration/ip-in-ip" target="_blank" rel="noopener">document</a> about <code>IP-in-IP</code></p>
</li>
<li><p>Which Network Interface is Used<br>Another question I have is which network interface is used for <code>node-to-node</code> and <code>pod-to-pod</code> test?</p>
<p>There are several network interfaces in host machine, one is for public IP with <code>MTU 9000</code> and in K8s we use private IP interface with <code>MTU 1500</code>. This will have impact on <code>iperf3</code> testing.</p>
<p>It shows that <code>pod-to-pod</code> test uses <code>MTU 1500</code> but <code>node-to-node</code> uses <code>MTU 9000</code>.</p>
<p>Need to test after enlarging MTU size to see if that change improves network throughput, also remember to update <code>Calico</code> manifest yaml, refer this <a href="https://docs.projectcalico.org/v3.3/usage/configuration/mtu" target="_blank" rel="noopener">document</a></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Configure the MTU to use</span></span><br><span class="line"><span class="attr">veth_mtu:</span> <span class="string">"9000"</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="ethtool-Command"><a href="#ethtool-Command" class="headerlink" title="ethtool Command"></a>ethtool Command</h2><p>The <code>ethtool</code> can display speed property of the network interface, for example:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ethtool eno1</span></span><br><span class="line"></span><br><span class="line"><span class="string">Settings</span> <span class="string">for</span> <span class="attr">eno1:</span></span><br><span class="line">        <span class="string">Supported</span> <span class="attr">ports:</span> <span class="string">[</span> <span class="string">TP</span> <span class="string">]</span></span><br><span class="line">        <span class="string">Supported</span> <span class="string">link</span> <span class="attr">modes:</span>   <span class="number">10</span><span class="string">baseT/Half</span> <span class="number">10</span><span class="string">baseT/Full</span></span><br><span class="line">                                <span class="number">100</span><span class="string">baseT/Half</span> <span class="number">100</span><span class="string">baseT/Full</span></span><br><span class="line">                                <span class="number">1000</span><span class="string">baseT/Half</span> <span class="number">1000</span><span class="string">baseT/Full</span></span><br><span class="line">        <span class="string">Supported</span> <span class="string">pause</span> <span class="string">frame</span> <span class="attr">use:</span> <span class="literal">No</span></span><br><span class="line">        <span class="string">Supports</span> <span class="attr">auto-negotiation:</span> <span class="literal">Yes</span></span><br><span class="line">        <span class="string">Supported</span> <span class="string">FEC</span> <span class="attr">modes:</span> <span class="string">Not</span> <span class="string">reported</span></span><br><span class="line">        <span class="string">Advertised</span> <span class="string">link</span> <span class="attr">modes:</span>  <span class="number">10</span><span class="string">baseT/Half</span> <span class="number">10</span><span class="string">baseT/Full</span></span><br><span class="line">                                <span class="number">100</span><span class="string">baseT/Half</span> <span class="number">100</span><span class="string">baseT/Full</span></span><br><span class="line">                                <span class="number">1000</span><span class="string">baseT/Half</span> <span class="number">1000</span><span class="string">baseT/Full</span></span><br><span class="line">        <span class="string">Advertised</span> <span class="string">pause</span> <span class="string">frame</span> <span class="attr">use:</span> <span class="string">Symmetric</span></span><br><span class="line">        <span class="string">Advertised</span> <span class="attr">auto-negotiation:</span> <span class="literal">Yes</span></span><br><span class="line">        <span class="string">Advertised</span> <span class="string">FEC</span> <span class="attr">modes:</span> <span class="string">Not</span> <span class="string">reported</span></span><br><span class="line">        <span class="string">Link</span> <span class="string">partner</span> <span class="string">advertised</span> <span class="string">link</span> <span class="attr">modes:</span>  <span class="number">10</span><span class="string">baseT/Full</span></span><br><span class="line">                                             <span class="number">100</span><span class="string">baseT/Full</span></span><br><span class="line">                                             <span class="number">1000</span><span class="string">baseT/Full</span></span><br><span class="line">        <span class="string">Link</span> <span class="string">partner</span> <span class="string">advertised</span> <span class="string">pause</span> <span class="string">frame</span> <span class="attr">use:</span> <span class="string">Transmit-only</span></span><br><span class="line">        <span class="string">Link</span> <span class="string">partner</span> <span class="string">advertised</span> <span class="attr">auto-negotiation:</span> <span class="literal">Yes</span></span><br><span class="line">        <span class="string">Link</span> <span class="string">partner</span> <span class="string">advertised</span> <span class="string">FEC</span> <span class="attr">modes:</span> <span class="string">Not</span> <span class="string">reported</span></span><br><span class="line"><span class="attr">        Speed:</span> <span class="number">1000</span><span class="string">Mb/s</span></span><br><span class="line"><span class="attr">        Duplex:</span> <span class="string">Full</span></span><br><span class="line"><span class="attr">        Port:</span> <span class="string">Twisted</span> <span class="string">Pair</span></span><br><span class="line"><span class="attr">        PHYAD:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">        Transceiver:</span> <span class="string">internal</span></span><br><span class="line"><span class="attr">        Auto-negotiation:</span> <span class="string">on</span></span><br><span class="line"><span class="attr">        MDI-X:</span> <span class="string">on</span></span><br><span class="line">        <span class="string">Supports</span> <span class="attr">Wake-on:</span> <span class="string">g</span></span><br><span class="line"><span class="attr">        Wake-on:</span> <span class="string">d</span></span><br><span class="line">        <span class="string">Current</span> <span class="string">message</span> <span class="attr">level:</span> <span class="number">0x000000ff</span> <span class="string">(255)</span></span><br><span class="line">                               <span class="string">drv</span> <span class="string">probe</span> <span class="string">link</span> <span class="string">timer</span> <span class="string">ifdown</span> <span class="string">ifup</span> <span class="string">rx_err</span> <span class="string">tx_err</span></span><br><span class="line">        <span class="string">Link</span> <span class="attr">detected:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure></p>
<p>The output depends on the what the network driver can provide, you may get nothing if the <strong>virtual machine</strong> does not have much data available (for example, in IBM softlayer cluster), refer to this <a href="https://serverfault.com/questions/447939/why-is-ethtool-not-showing-me-all-the-properties-for-a-nic" target="_blank" rel="noopener">question</a> </p>
<p>In a virtual machine the link speed or duplex mode is usually meaningless, as the network interface is most often just a <strong>virtual link</strong> to the host system, with no actual physical Ethernet layer. The speed is as high as the CPU and memory can handle (or as low, as the connection rate limit is configured), cabling type does no exist, as there is no cable, etc. This virtual interface is bridged or routed to the actual physical network by the host system and only on the host system the physical port parameters can be obtained.</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ol>
<li>Performance test big picture</li>
<li>iperf3, node-to-node, pod-to-pod tests</li>
<li>ethtool</li>
<li>Calico configutation: IP-in-IP, MTU</li>
<li>calicoctl, haven’t got time to learn</li>
</ol>
<h2 id="Other-Blogs"><a href="#Other-Blogs" class="headerlink" title="Other Blogs"></a>Other Blogs</h2><p><a href="https://www.jianshu.com/p/cfc4e62ff3ea" target="_blank" rel="noopener">k8s calico flannel cilium 网络性能测试</a><br><a href="https://itnext.io/benchmark-results-of-kubernetes-network-plugins-cni-over-10gbit-s-network-36475925a560" target="_blank" rel="noopener">Benchmark results of Kubernetes network plugins (CNI) over 10Gbit/s network</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>calico</tag>
      </tags>
  </entry>
  <entry>
    <title>External Provisioner</title>
    <url>/2019/12/10/k8s-external-provisioner/</url>
    <content><![CDATA[<p>Github <a href="https://github.com/kubernetes-incubator/external-storage" target="_blank" rel="noopener">external provisioner</a>.</p>
<p>The external provisioner can be backed by  many type of filesystem, here we focus on <code>nfs-client</code>.</p>
<blockquote>
<p>Notice that in this project, you will see <code>nfs-client</code> and <code>nfs</code> directories, <code>nfs-client</code> means we already has a nfs server and use it on client. <code>nfs</code> means we don’t have a nfs server, but we share other filesystem in nfs way.</p>
</blockquote>
<p>Another tool very similar is <a href="https://rook.io/" target="_blank" rel="noopener">Rook</a>, see my blog <a href="https://chengdol.github.io/2020/01/20/k8s-rook/" target="_blank" rel="noopener"><code>Rook Storage Orchestrator</code></a>.</p>
<p>The <code>Rook</code> is more heavy and this project is lightweight.</p>
<ol>
<li>Setup NFS server</li>
<li><p>Install nfs-utils on all worker nodes<br>See my blog <a href="https://chengdol.github.io/2019/05/27/fs-nfs-setup/" target="_blank" rel="noopener">NFS Server and Client Setup</a>, this <code>Server Setup</code> chapter.</p>
</li>
<li><p>Setup NFS provisioner<br>This blog give me clear instruction on how to adopt the <code>nfs-client</code> provisioner: <a href="https://medium.com/faun/openshift-dynamic-nfs-persistent-volume-using-nfs-client-provisioner-fcbb8c9344e" target="_blank" rel="noopener">openshift dynamic NFS persistent volume using NFS-client-provisioner</a>.</p>
</li>
</ol>
<p><strong>Notces</strong>:</p>
<ol>
<li><p>I find a bug in this project, when set rbac, you need to specify <code>-n test-1</code>, otherwise the role was created in <code>test-1</code> but rolebinding is created in default namespace.</p>
</li>
<li><p>The NFS provisioner is global scoped.</p>
</li>
<li><p>The <code>NFS_SERVER</code> env in deployment.yaml can be hostname or IP address.</p>
</li>
<li><p>If several pods use the same PVC, they share the same PV.</p>
</li>
<li><p>you can customize the storage class if it’s available. For example, set the reclaim policy as <code>retain</code> instead of <code>delete</code>. see <a href="https://kubernetes.io/docs/concepts/storage/storage-classes/" target="_blank" rel="noopener">doc</a>.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">standard</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">kubernetes.io/aws-ebs</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">gp2</span></span><br><span class="line"><span class="comment">## default is delete</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Retain</span></span><br><span class="line"><span class="comment">## allow resize the volume by editing the corresponding PVC object</span></span><br><span class="line"><span class="comment">## cannot shrink</span></span><br><span class="line"><span class="attr">allowVolumeExpansion:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">volumeBindingMode:</span> <span class="string">Immediate</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>external provisioner</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Feature Gates</title>
    <url>/2019/08/27/k8s-feature-gates/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Sometimes you will find the demo run in your kubernetes cluster doesn’t work exactly or doesn’t fit your expectation from official documentation. That maybe a feature gate you didn’t enable it or you don’t have it.</p>
<p>See this issue, I encountered the exactly the same:<br><a href="https://github.com/coreos/prometheus-operator/issues/2439" target="_blank" rel="noopener">https://github.com/coreos/prometheus-operator/issues/2439</a></p>
<p>This is the <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/feature-gates/" target="_blank" rel="noopener">Feature Gates link</a>.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Force Delete StatefulSet and Pods</title>
    <url>/2019/02/16/k8s-force-delete-statefulset/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<h2 id="Issue-description"><a href="#Issue-description" class="headerlink" title="Issue description"></a>Issue description</h2><p>I encountered the problem that when delete <code>statefulset</code> the execution hangs, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete statefulset is-en-conductor</span><br></pre></td></tr></table></figure></p>
<p>it cannot delete the <code>statefulset</code> and associated <code>pods</code> at all<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@opsft-lb-1 OpenShift] oc get all</span><br><span class="line">NAME                             DESIRED   CURRENT   AGE</span><br><span class="line">statefulsets/is-en-conductor     0         1         5h</span><br><span class="line">statefulsets/is-engine-compute   0         2         5h</span><br><span class="line"></span><br><span class="line">NAME                     READY     STATUS        RESTARTS   AGE</span><br><span class="line">po/is-en-conductor-0     0/1       Terminating   2          1h</span><br><span class="line">po/is-engine-compute-0   1/1       Running       0          5h</span><br><span class="line">po/is-engine-compute-1   0/1       Terminating   0          5h</span><br></pre></td></tr></table></figure></p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete statefulsets &lt;statefulset name&gt; --force --grace-period=0 --cascade=<span class="literal">false</span></span><br></pre></td></tr></table></figure>
<p>now we only have hanging pods, force delete them<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NAME                     READY     STATUS        RESTARTS   AGE</span><br><span class="line">po/is-en-conductor-0     0/1       Terminating   2          1h</span><br><span class="line">po/is-engine-compute-0   1/1       Running       0          5h</span><br><span class="line">po/is-engine-compute-1   0/1       Terminating   0          5h</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete pod &lt;pod name&gt; --force --grace-period=0</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>statefulset</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes NodePort vs LoadBalancer vs Ingress</title>
    <url>/2019/03/26/k8s-external-access/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>This <a href="https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0" target="_blank" rel="noopener">blog</a> talks about the ways that provide external access to kubernetes cluster and their difference.</p>
<p>This <a href="https://www.nginx.com/blog/wait-which-nginx-ingress-controller-kubernetes-am-i-using/" target="_blank" rel="noopener">blog</a> is about <code>NGINX</code> ingress controller.</p>
<p>I need to do further demo and research on them.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>ingress</tag>
      </tags>
  </entry>
  <entry>
    <title>Init Container</title>
    <url>/2019/06/10/k8s-initContainer/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>In ICP4D non-root development, I see in each tier the pod contains init container, for example:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">is-xmetadocker</span></span><br><span class="line"><span class="attr">    hostIPC:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    initContainers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">load-data</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">"mycluster.icp:8500/zen/is-db2xmeta-image:11.7.1-1.0"</span></span><br><span class="line"><span class="attr">      imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">      securityContext:</span></span><br><span class="line"><span class="attr">        capabilities:</span></span><br><span class="line"><span class="attr">         add:</span> <span class="string">["SETFCAP",</span> <span class="string">"SYS_NICE"</span><span class="string">,</span> <span class="string">"IPC_OWNER"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">['/bin/bash',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'--'</span><span class="string">]</span></span><br><span class="line"><span class="attr">      args:</span> <span class="string">[</span> <span class="string">" set -x;</span></span><br><span class="line"><span class="string">              ...</span></span><br><span class="line"><span class="string">              "</span></span><br><span class="line">             <span class="string">]</span></span><br><span class="line"><span class="attr">      env:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">DEDICATED_REPOS_VOLPATH</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">/mnt/dedicated_vol/Repository</span></span><br><span class="line"><span class="attr">      volumeMounts:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">xmeta-pv-volume</span></span><br><span class="line"><span class="attr">        mountPath:</span> <span class="string">"/mnt/dedicated_vol/Repository"</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Understanding"><a href="#Understanding" class="headerlink" title="Understanding"></a>Understanding</h2><p>What is this and what is it for? Let’s take a look. First reference to <a href="https://kubernetes.io/docs/concepts/workloads/pods/init-containers/" target="_blank" rel="noopener">official documentation</a>.</p>
<p>Init Containers, which are <strong>specialized</strong> Containers that run <strong>before</strong> app Containers and can <strong>contain</strong> utilities or setup scripts not present in an app image.</p>
<p>A Pod can have multiple Containers running apps within it, but it can also have one or more Init Containers, which are run before the app Containers are started.</p>
<p>Init Containers are exactly like regular Containers, except:</p>
<ul>
<li>They always run to completion.</li>
<li>Each one must complete successfully before the next one is started.</li>
</ul>
<p>If an Init Container fails for a Pod, Kubernetes restarts the Pod repeatedly until the Init Container succeeds. However, if the Pod has a restartPolicy of Never, it is not restarted.</p>
<h3 id="Differences-from-Regular-Containers"><a href="#Differences-from-Regular-Containers" class="headerlink" title="Differences from Regular Containers"></a>Differences from Regular Containers</h3><p>Init Containers support all the fields and features of app Containers, including resource limits, volumes, and security settings. However, the resource requests and limits for an Init Container are handled slightly differently.</p>
<p>Init Containers do not support readiness probes because they must run to completion before the Pod can be ready.</p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>Init Containers have separate images from app Containers (actually they can have the same), they have some advantages for start-up related code:</p>
<ul>
<li>They can contain and run utilities that are not desirable to include in the app Container image for security reasons.</li>
<li>They can contain utilities or custom code for setup that is not present in an app image. For example, there is no need to make an image FROM another image just to use a tool like sed, awk, python, or dig during setup.</li>
<li>The application image builder and deployer roles can work independently without the need to jointly build a single app image.</li>
<li>They use Linux namespaces so that they have different filesystem views from app Containers. Consequently, they can be given access to Secrets that app Containers are not able to access.</li>
<li>They run to completion before any app Containers start, whereas app Containers run in parallel, so Init Containers provide an easy way to block or delay the startup of app Containers until some set of preconditions are met.</li>
</ul>
<p>You can check the logs of init container:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl logs &lt;pod name&gt; -c &lt;init container&gt; -n test-1</span><br></pre></td></tr></table></figure></p>
<p>During the startup of a Pod, the Init Containers are started <strong>in order</strong>, after the network and volumes are initialized. Each Container must exit successfully before the next is started.</p>
<p>If the Pod is restarted, all Init Containers must execute again. Init Container code should be idempotent. </p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>initContainer</tag>
      </tags>
  </entry>
  <entry>
    <title>Helm Tiller Server Deploy</title>
    <url>/2019/07/19/k8s-helm-tiller/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<blockquote>
<p>Helm 3 removes the Tiller server, see this <a href="https://developer.ibm.com/technologies/containers/blogs/kubernetes-helm-3/" target="_blank" rel="noopener">post</a></p>
</blockquote>
<p>This blog primarily talks about <code>Tiller</code> server, especially creating service account and cluster role binding for it.</p>
<p>Zen uses <code>Helm</code> to install in ICP4D cluster. <code>Helm</code> is a tool for managing Kubernetes charts. <code>Charts</code> are packages of pre-configured Kubernetes resources. Think of <code>Helm</code> like apt(deb), yum(rpm), homebrew for Kubernetes.</p>
<h2 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h2><p><a href="https://github.com/helm/helm" target="_blank" rel="noopener">Helm Git Repos</a></p>
<h2 id="Download-Helm-Installer"><a href="#Download-Helm-Installer" class="headerlink" title="Download Helm Installer"></a>Download Helm Installer</h2><p>Download the Latest release from <a href="https://github.com/helm/helm/releases" target="_blank" rel="noopener">Helm Release</a>. For example in Linux, we use:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Linux amd64 (checksum / 9f50e69cf5cfa7268b28686728ad0227507a169e52bf59c99ada872ddd9679f0)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><code>Helm</code> needs to be put in the control node that already configured with <code>kubectl</code>.</p>
</blockquote>
<p>Untar the file and you can move <code>helm</code> binary to one of the exectuable path, such as <code>/usr/local/bin</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># which helm</span></span><br><span class="line">/usr/<span class="built_in">local</span>/bin/helm</span><br></pre></td></tr></table></figure></p>
<h2 id="Deploy-Tiller-Server"><a href="#Deploy-Tiller-Server" class="headerlink" title="Deploy Tiller Server"></a>Deploy Tiller Server</h2><p>Helm client needs to talk to <code>Tiller</code> server, which will be deploied in the K8s cluster.</p>
<p>Most cloud providers enable a feature called Role-Based Access Control - <code>RBAC</code> for short. If your cloud provider enables this feature, you will need to create a service account for Tiller with the right roles and permissions to access resources.</p>
<p>From <a href="https://helm.sh/docs/using_helm/#tiller-and-role-based-access-control" target="_blank" rel="noopener">here</a>, you need to create a <code>cluster role binding</code> which specifies a role and a <code>service account</code> name that have been set up in advance <code>rbac-config.yaml</code>:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tiller</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">tiller</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">  - kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">tiller</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">kube-system</span></span><br></pre></td></tr></table></figure></p>
<p>Then install <code>Helm</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl create -f rbac-config.yaml</span><br><span class="line">helm init --service-account tiller --<span class="built_in">history</span>-max 200</span><br></pre></td></tr></table></figure></p>
<p>If you forget to create <code>service account</code> and <code>cluster role binding</code> before you initiate <code>Helm</code>, no worries, create <code>rbac-config.yaml</code> objects and patch it by:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl patch deploy --namespace kube-system tiller-deploy -p <span class="string">'&#123;"spec":&#123;"template":&#123;"spec":&#123;"serviceAccount":"tiller"&#125;&#125;&#125;&#125;'</span></span><br></pre></td></tr></table></figure></p>
<p>Then check <code>Tiller</code> pod is running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods -n kube-system -l app=helm</span><br><span class="line"></span><br><span class="line">NAME                             READY   STATUS    RESTARTS   AGE</span><br><span class="line">tiller-deploy-845fb7cfc6-rn4nq   1/1     Running   0          20h</span><br></pre></td></tr></table></figure></p>
<p>Now, we are in good shape, actually I can config <code>SSL/TLS</code> between <code>Helm</code> and <code>Tiller</code>, not covered in this blog.</p>
<h2 id="Uninstall-Tiller-Server"><a href="#Uninstall-Tiller-Server" class="headerlink" title="Uninstall Tiller Server"></a>Uninstall Tiller Server</h2><p>There are 2 ways to uninstall:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">helm reset</span><br><span class="line">helm delete deploy tiller-deploy -n kube-system</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>helm</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Ingress</title>
    <url>/2019/10/21/k8s-ingress/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>This <a href="https://docs.microsoft.com/en-us/azure/aks/ingress-tls" target="_blank" rel="noopener">link</a> show you the instructions about how to setup ingress in an Azure Kubernetes Service (AKS) cluster.<br>It contains <a href="https://github.com/kubernetes/ingress-nginx" target="_blank" rel="noopener"><code>NGINX ingress controller</code></a> and <a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener"><code>cert-manager project</code></a> (used to automatically generate and configure <a href="https://letsencrypt.org/" target="_blank" rel="noopener"><code>Let&#39;s Encrypt</code></a> certificates).</p>
<p>First understand what is forward proxy and reverse proxy:<br><a href="https://www.linuxbabe.com/it-knowledge/differences-between-forward-proxy-and-reverse-proxy" target="_blank" rel="noopener">https://www.linuxbabe.com/it-knowledge/differences-between-forward-proxy-and-reverse-proxy</a></p>
<p>There’re many different kinds of forward proxy such as web proxy, HTTP proxy, SOCKS proxy etc. Please keep mind that using forward proxy to browse the Internet usually slows down your overall Internet speed. Another thing to be aware of is that there’re many free forward proxies which is built by hackers for malicious purpose. If you happen to be using one of these proxies, they will log every activity you do on the Internet.</p>
<p>Nginx can be acting both a web server and a reverse proxy at the same time. HAProxy is another well-known open-source reverse proxy software.</p>
<p>TLS termination proxy:<br><a href="https://en.wikipedia.org/wiki/TLS_termination_proxy" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/TLS_termination_proxy</a></p>
<p>A TLS termination proxy (or SSL termination proxy) is a proxy server that is used by an institution to handle incoming TLS connections, decrypting the TLS and passing on the unencrypted request to the institution’s other servers (it is assumed that the institution’s own network is secure so the user’s session data does not need to be encrypted on that part of the link). TLS termination proxies are used to reduce the load on the main servers by offloading the cryptographic processing to another machine, and to support servers that do not support SSL, like Varnish.</p>
<h2 id="Create-an-ingress-controller"><a href="#Create-an-ingress-controller" class="headerlink" title="Create an ingress controller"></a>Create an ingress controller</h2><p>To create the ingress controller, use <code>Helm</code> to install nginx-ingress (or use yaml). For added redundancy, two replicas of the NGINX ingress controllers are deployed with the <code>--set controller.replicaCount parameter</code>.</p>
<p>This is for AKS cluster, for bare-metal it’s different, since bare-metal does not have existing loadbalancer (please refer <a href="https://kubernetes.github.io/ingress-nginx/)" target="_blank" rel="noopener">https://kubernetes.github.io/ingress-nginx/)</a>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm install stable/nginx-ingress \</span><br><span class="line">    --namespace &lt;the namespace as your application&gt; \</span><br><span class="line">    --<span class="built_in">set</span> controller.replicaCount=2 \</span><br><span class="line">    --<span class="built_in">set</span> controller.nodeSelector.<span class="string">"beta\.kubernetes\.io/os"</span>=linux \</span><br><span class="line">    --<span class="built_in">set</span> defaultBackend.nodeSelector.<span class="string">"beta\.kubernetes\.io/os"</span>=linux</span><br></pre></td></tr></table></figure></p>
<p>Then go to get the public IP assigned for ingress controller:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAME                                             TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)                      AGE</span><br><span class="line">billowing-kitten-nginx-ingress-controller        LoadBalancer   10.0.182.160   51.145.155.210  80:30920/TCP,443:30426/TCP   20m</span><br><span class="line">billowing-kitten-nginx-ingress-default-backend   ClusterIP      10.0.255.77    &lt;none&gt;          80/TCP                       20m</span><br></pre></td></tr></table></figure></p>
<p>Until, we just set up a ingress controller, no ingress rules are specified.</p>
<h3 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## find helm release name</span></span><br><span class="line">helm list</span><br><span class="line"><span class="comment">## delete</span></span><br><span class="line">helm delete --purge &lt;name&gt;</span><br></pre></td></tr></table></figure>
<h2 id="Config-DNS-name"><a href="#Config-DNS-name" class="headerlink" title="Config DNS name"></a>Config DNS name</h2><p>For the HTTPS certificates to work correctly, configure an FQDN(fully qualified domain name) for the ingress controller IP address.</p>
<p>for Azure it is:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Public IP address of your ingress controller</span></span><br><span class="line">IP=<span class="string">"51.145.155.210"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Name to associate with public IP address</span></span><br><span class="line">DNSNAME=<span class="string">"demo-aks-ingress"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the resource-id of the public ip</span></span><br><span class="line">PUBLICIPID=$(az network public-ip list --query <span class="string">"[?ipAddress!=null]|[?contains(ipAddress, '<span class="variable">$IP</span>')].[id]"</span> --output tsv)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update public ip address with DNS name</span></span><br><span class="line">az network public-ip update --ids <span class="variable">$PUBLICIPID</span> --dns-name <span class="variable">$DNSNAME</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Install-cert-manager"><a href="#Install-cert-manager" class="headerlink" title="Install cert-manager"></a>Install cert-manager</h2><p>The NGINX ingress controller supports TLS termination.<br>see here <a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">https://github.com/jetstack/cert-manager</a>.<br>cert-manager is a Kubernetes add-on to automate the management and issuance of TLS certificates from various issuing sources.<br>It will ensure certificates are valid and up to date periodically, and attempt to renew certificates at an appropriate time before expiry</p>
<p>To install the cert-manager controller in an RBAC-enabled cluster, use the following helm install command (this is not the latest version)<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Install the CustomResourceDefinition resources separately</span></span><br><span class="line">kubectl apply -f https://raw.githubusercontent.com/jetstack/cert-manager/release-0.8/deploy/manifests/00-crds.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create the namespace for cert-manager</span></span><br><span class="line">kubectl create namespace cert-manager</span><br><span class="line"></span><br><span class="line"><span class="comment"># Label the cert-manager namespace to disable resource validation</span></span><br><span class="line">kubectl label namespace cert-manager certmanager.k8s.io/<span class="built_in">disable</span>-validation=<span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the Jetstack Helm repository</span></span><br><span class="line">helm repo add jetstack https://charts.jetstack.io</span><br><span class="line"></span><br><span class="line"><span class="comment"># Update your local Helm chart repository cache</span></span><br><span class="line">helm repo update</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install the cert-manager Helm chart</span></span><br><span class="line">helm install \</span><br><span class="line">  --name cert-manager \</span><br><span class="line">  --namespace cert-manager \</span><br><span class="line">  --version v0.8.0 \</span><br><span class="line">  jetstack/cert-manager</span><br></pre></td></tr></table></figure></p>
<h3 id="Create-a-CA-cluster-issuer"><a href="#Create-a-CA-cluster-issuer" class="headerlink" title="Create a CA cluster issuer"></a>Create a CA cluster issuer</h3><p>Create a cluster issuer yaml then run <code>kubectl apply -f</code>, more details see:<br><a href="https://cert-manager.readthedocs.io/en/latest/reference/issuers.html" target="_blank" rel="noopener">https://cert-manager.readthedocs.io/en/latest/reference/issuers.html</a></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">certmanager.k8s.io/v1alpha1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterIssuer</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">letsencrypt-prod</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  acme:</span></span><br><span class="line"><span class="attr">    server:</span> <span class="attr">https://acme-v02.api.letsencrypt.org/directory</span></span><br><span class="line"><span class="attr">    email:</span> <span class="string">&lt;your</span> <span class="string">email</span> <span class="string">address&gt;</span></span><br><span class="line"><span class="attr">    privateKeySecretRef:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">letsencrypt-prod</span></span><br><span class="line"><span class="attr">    http01:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="Delete-1"><a href="#Delete-1" class="headerlink" title="Delete"></a>Delete</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">helm list</span><br><span class="line">helm delete --purge &lt;name&gt;</span><br><span class="line">kubectl delete -f https://raw.githubusercontent.com/jetstack/cert-manager/release-0.8/deploy/manifests/00-crds.yaml</span><br><span class="line">kubectl delete -f cluster-issuer.yaml</span><br><span class="line">kubectl delete ns cert-manager</span><br></pre></td></tr></table></figure>
<h2 id="Create-ingress-route"><a href="#Create-ingress-route" class="headerlink" title="Create ingress route"></a>Create ingress route</h2><p>The apiVersion may update to stable, usually, if the AKS demo works but your application not, that means there are some miss configurations in the ingress annotations, please adjust according to your situation.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">&lt;ingress</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">&lt;ns&gt;</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">kubernetes.io/ingress.class:</span> <span class="string">nginx</span></span><br><span class="line">    <span class="string">certmanager.k8s.io/cluster-issuer:</span> <span class="string">letsencrypt-prod</span></span><br><span class="line">    <span class="comment">## if inside cluster use HTTPS</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/backend-protocol:</span> <span class="string">"HTTPS"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment">## this part is for add ssl/tls to ingress</span></span><br><span class="line"><span class="attr">  tls:</span></span><br><span class="line"><span class="attr">  - hosts:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">&lt;URL&gt;</span></span><br><span class="line"><span class="attr">    secretName:</span> <span class="string">tls-secret</span></span><br><span class="line">  <span class="comment">## routing rules</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line"><span class="attr">  - host:</span> <span class="string">&lt;URL&gt;</span></span><br><span class="line"><span class="attr">    http:</span></span><br><span class="line"><span class="attr">      paths:</span></span><br><span class="line"><span class="attr">      - path:</span> <span class="string">/mbi/sii</span></span><br><span class="line"><span class="attr">        backend:</span></span><br><span class="line"><span class="attr">          serviceName:</span> <span class="string">is-servicesdocker</span></span><br><span class="line"><span class="attr">          servicePort:</span> <span class="number">9446</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Delete-2"><a href="#Delete-2" class="headerlink" title="Delete"></a>Delete</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete -f ingress.yaml</span><br></pre></td></tr></table></figure>
<h2 id="Create-a-certificate-object"><a href="#Create-a-certificate-object" class="headerlink" title="Create a certificate object"></a>Create a certificate object</h2><p>Next, a certificate resource must be created. The certificate resource defines the desired X.509 certificate. For more information, see <a href="https://cert-manager.readthedocs.io/en/latest/reference/certificates.html" target="_blank" rel="noopener">https://cert-manager.readthedocs.io/en/latest/reference/certificates.html</a></p>
<p>Cert-manager has likely automatically created a certificate object for you using ingress-shim, which is automatically deployed with cert-manager since v0.2.2.<br>see <a href="https://docs.cert-manager.io/en/latest/tasks/issuing-certificates/ingress-shim.html" target="_blank" rel="noopener">https://docs.cert-manager.io/en/latest/tasks/issuing-certificates/ingress-shim.html</a></p>
<h2 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h2><p>If the things are going good, check the URL address in the browser:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;URL&gt;/mbi/sii/launchpad</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Istio</title>
    <url>/2019/12/05/k8s-istio/</url>
    <content><![CDATA[<p>Istio is the implementation of a service mesh that improves application resilience as you connect, manage, and secure microservices. It provides operational control and performance insights for a network of containerized applications. Istio provides services such as load balancing, authentication and monitoring.</p>
<p>It used <a href="https://www.envoyproxy.io/" target="_blank" rel="noopener"><code>envoy</code></a> sidecars and proxies.</p>
<p>Brief introduction to service mesh and istio, understand what is istio, how does it work, advantages, when to use:<br><a href="https://www.redhat.com/en/topics/microservices/what-is-a-service-mesh" target="_blank" rel="noopener">service mesh</a><br><a href="https://avinetworks.com/glossary/istio-service-mesh/" target="_blank" rel="noopener">istio</a><br>The Istio service mesh sits above the application layer, providing platform-independent communication between microservices. It sends quick, reliable, efficient and secure requests by relying on Envoy proxies. It uses a single control plane that monitors an underlying data plane.<br><a href="https://istio.io/docs/concepts/what-is-istio/" target="_blank" rel="noopener">istio offical</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>k8s</tag>
        <tag>istio</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Job and CronJob</title>
    <url>/2019/08/12/k8s-job-cronjob/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Recently I use Job to run some one time tasks (later switch back to regular pod because we want to control it’s start point), it’s just like other pod controller in K8s.</p>
<h2 id="Job"><a href="#Job" class="headerlink" title="Job"></a>Job</h2><p>Job setup pod, note that:<br>hostname<br>job-name, check<br>env pass</p>
<p>volume mount</p>
<p>Job type</p>
<p>In upgrade, usage</p>
<h2 id="CronJob"><a href="#CronJob" class="headerlink" title="CronJob"></a>CronJob</h2><p>crontab</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Specify Kubernetes API Server IP</title>
    <url>/2019/11/04/k8s-kubeadm-init-apiserver/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>When I was working on softlayer cluster, after installing kubernetes the kubectl command get stuck and return time execeeds error.</p>
<p>The issue is the master node has 3 IP address, but only one of them is accessable from client, if not specified, the <code>kubeadm init</code> command will choose the default network interface, sometimes it’s good but here does not fit.</p>
<p>the solution is use <code>--apiserver-advertise-address &lt;IP&gt;</code> in <code>kubeadm init</code>, then everything is good.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubectx and Kubens</title>
    <url>/2019/02/17/k8s-kubectx-kubens/</url>
    <content><![CDATA[<p>I want to introduce you two useful tools for kubernetes development, <a href="https://github.com/ahmetb/kubectx" target="_blank" rel="noopener">github link</a> with detail.</p>
<blockquote>
<p>Note: this is not an official Google product.</p>
</blockquote>
<h2 id="kubectx"><a href="#kubectx" class="headerlink" title="kubectx"></a>kubectx</h2><p><code>kubectx</code> helps you switch between clusters back and forth</p>
<h3 id="install"><a href="#install" class="headerlink" title="install"></a>install</h3><p>since kubectx/kubens are written in Bash, you should be able to install them to any POSIX environment that has Bash installed.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/ahmetb/kubectx /opt/kubectx</span><br></pre></td></tr></table></figure></p>
<p>make sure kubectx script is executable:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] ls /opt/kubectx/ -ltr</span><br><span class="line">total 40</span><br><span class="line">-rw-r--r-- 1 root root 11357 Feb 17 21:25 LICENSE</span><br><span class="line">-rw-r--r-- 1 root root   968 Feb 17 21:25 CONTRIBUTING.md</span><br><span class="line">-rw-r--r-- 1 root root  7784 Feb 17 21:25 README.md</span><br><span class="line">drwxr-xr-x 2 root root   121 Feb 17 21:25 completion</span><br><span class="line">drwxr-xr-x 2 root root    84 Feb 17 21:25 img</span><br><span class="line">drwxr-xr-x 3 root root   100 Feb 17 21:25 test</span><br><span class="line">-rwxr-xr-x 1 root root  5273 Feb 17 21:25 kubens</span><br><span class="line">-rwxr-xr-x 1 root root  5218 Feb 17 21:25 kubectx</span><br></pre></td></tr></table></figure></p>
<p>create symlinks to kubectx/kubens from somewhere in your PATH, like /usr/local/bin<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ln -s /opt/kubectx/kubectx /usr/<span class="built_in">local</span>/bin/kubectx</span><br></pre></td></tr></table></figure></p>
<h3 id="usage"><a href="#usage" class="headerlink" title="usage"></a>usage</h3><p>you should first understand how to switch among different clusters by using configuration files. please investigate this <a href="https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/" target="_blank" rel="noopener">link</a>, actually <code>kubectx</code> is built on top of it.</p>
<p>For example, I have one cluster on AWS and one cluster on Fyre, in each cluster there is a <code>~/.kube/config</code> file, rename it as <code>config.aws</code> and <code>config.fyre</code> and put them to another client machine <code>~/.kube/</code> folder with  kubectl installed.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centctl1 .kube]# ls -ltr</span><br><span class="line">total 16</span><br><span class="line">drwxr-xr-x 3 root root   23 Nov 26 16:38 cache</span><br><span class="line">-rw-r--r-- 1 root root 2214 Dec  6 10:16 config.aws</span><br><span class="line">drwxr-xr-x 2 root root   73 Dec  6 10:16 kubens</span><br><span class="line">drwxr-xr-x 3 root root 4096 Feb 17 22:05 http-cache</span><br><span class="line">-rw------- 1 root root 5474 Feb 17 22:22 config.fyre</span><br></pre></td></tr></table></figure></p>
<p>append config files to environment variable <code>KUBECONFIG</code>, you can add export to <code>.bashrc</code> file.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export KUBECONFIG=$KUBECONFIG:$HOME/.kube/config.aws:$HOME/.kube/config.fyre</span><br></pre></td></tr></table></figure></p>
<p>now if you run <code>kubectx</code> you will see there are 2 contexts<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centctl1 .kube] kubectx</span><br><span class="line">arn:aws:eks:us-west-2:296744932886:cluster/IIS-Test-Cluster</span><br><span class="line">kubernetes-admin@kubernetes</span><br></pre></td></tr></table></figure></p>
<p>switch to <code>kubernetes-admin@kubernetes</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centctl1 .kube] kubectx kubernetes-admin@kubernetes</span><br><span class="line">Switched to context &quot;kubernetes-admin@kubernetes&quot;.</span><br></pre></td></tr></table></figure></p>
<p>switch back<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centctl1 .kube] kubectx -</span><br><span class="line">Switched to context &quot;arn:aws:eks:us-west-2:296744932886:cluster/IIS-Test-Cluster&quot;.</span><br></pre></td></tr></table></figure></p>
<p>actually the effect is the same as<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl config view</span><br><span class="line">kubectl config --kubeconfig=config.fyre use-context kubernetes-admin@kubernetes</span><br></pre></td></tr></table></figure></p>
<h2 id="kubens"><a href="#kubens" class="headerlink" title="kubens"></a>kubens</h2><p><code>kubens</code> helps you switch between Kubernetes namespaces smoothly, so you don’t need to add <code>-n &lt;namespace&gt;</code> in every command.</p>
<h3 id="install-1"><a href="#install-1" class="headerlink" title="install"></a>install</h3><p>download the same Github repository as <code>kubectx</code>, add symlinks:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ln -s /opt/kubectx/kubens /usr/<span class="built_in">local</span>/bin/kubens</span><br></pre></td></tr></table></figure></p>
<h3 id="usage-1"><a href="#usage-1" class="headerlink" title="usage"></a>usage</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] kubens</span><br><span class="line">default</span><br><span class="line">kube-public</span><br><span class="line">kube-system</span><br><span class="line">[root@myk8s1 ~] kubens kube-system</span><br><span class="line">Context &quot;kubernetes-admin@kubernetes&quot; modified.</span><br><span class="line">Active namespace is &quot;kube-system&quot;.</span><br><span class="line">[root@myk8s1 ~] kubens -</span><br><span class="line">Context &quot;kubernetes-admin@kubernetes&quot; modified.</span><br><span class="line">Active namespace is &quot;default&quot;.</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubens</tag>
        <tag>kubectx</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Manages NFS</title>
    <url>/2020/01/21/k8s-nfs-example/</url>
    <content><![CDATA[<h2 id="Entry"><a href="#Entry" class="headerlink" title="Entry"></a>Entry</h2><p><a href="https://kubernetes.io/docs/concepts/storage/volumes/#nfs" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/storage/volumes/#nfs</a></p>
<p>这个demo很有意思，从之前来看，如果需要为K8s设置NFS，则我们需要一个physical NFS server，然后create PV based on that NFS server then PVC claim from PV. 这样需要自己去维护NFS的健康保证high availability.</p>
<p>这个例子完全将NFS交给了K8s来管理，它先提供一块存储去构造PVC(这块存储可能来自provisioner或者其他PV)，然后用这个PVC构造了一个NFS server pod以及给这个pod绑定了一个cluster IP，这样就相当于一个虚拟的physical NFS server node了。当我们需要PV的时候，就从这个NFS server pod中取(本质就是从一个PV中构造另一些PV)。</p>
<p>当然为了满足NFS的特性，这个NFS server的镜像必须要特别的构造，安装了NFS的组件，暴露相关端口，以及在初始化启动程序中配置好<code>/etc/export</code>的相关参数。以及当NFS server pod被重新构造时，保证之前的share不受影响。</p>
<p>这样的好处就是完全交给K8s去管理，不用担心NFS高可用性的问题，也不用自己去搭建物理的NFS cluster了，只要提供一块存储，就可以构造成NFS。</p>
<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><p>写这个blog的时候这个demo yaml中有一些错误参数，以我的blog准，这是demo git repository:<br><a href="https://github.com/kubernetes/examples/tree/master/staging/volumes/nfs" target="_blank" rel="noopener">https://github.com/kubernetes/examples/tree/master/staging/volumes/nfs</a></p>
<p>Under provisioner folder, it uses storageclass (internal provisioner) to create a PV, for example, in GCE:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-pv-provisioning-demo</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    demo:</span> <span class="string">nfs-pv-provisioning</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      storage:</span> <span class="number">20</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure></p>
<p>If no internal provisioner is available, you can create an external provisioner (for example: NFS), or just create a PV with hostPath:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-pv-provisioning-demo</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    demo:</span> <span class="string">nfs-pv-provisioning</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  capacity:</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="string">"20Gi"</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteOnce</span></span><br><span class="line"><span class="attr">  hostPath:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">"/nfs-server-pv"</span></span><br></pre></td></tr></table></figure></p>
<p>This <code>/nfs-server-pv</code> folder will be created on the host where nfs server pod reside. </p>
<p>Then it creates a <code>replicationController</code> for <strong>NFS server</strong> (just like a physical NFS server):<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ReplicationController</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-server</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    role:</span> <span class="string">nfs-server</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        role:</span> <span class="string">nfs-server</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nfs-server</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">k8s.gcr.io/volume-nfs:0.8</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">            containerPort:</span> <span class="number">2049</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">mountd</span></span><br><span class="line"><span class="attr">            containerPort:</span> <span class="number">20048</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">rpcbind</span></span><br><span class="line"><span class="attr">            containerPort:</span> <span class="number">111</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          privileged:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line">            <span class="comment">## the nfs exports folder</span></span><br><span class="line"><span class="attr">          - mountPath:</span> <span class="string">/exports</span></span><br><span class="line"><span class="attr">            name:</span> <span class="string">mypvc</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">mypvc</span></span><br><span class="line"><span class="attr">          persistentVolumeClaim:</span></span><br><span class="line">            <span class="comment">## mount the pvc from provisioner</span></span><br><span class="line"><span class="attr">            claimName:</span> <span class="string">nfs-pv-provisioning-demo</span></span><br></pre></td></tr></table></figure></p>
<p>Notice that the image is dedicated with nfs-utils pre-installed, and it expose some nfs dedicated ports, see the dockerfile:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">FROM</span> <span class="string">centos</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">yum</span> <span class="bullet">-y</span> <span class="string">install</span> <span class="string">/usr/bin/ps</span> <span class="string">nfs-utils</span> <span class="string">&amp;&amp;</span> <span class="string">yum</span> <span class="string">clean</span> <span class="string">all</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">mkdir</span> <span class="bullet">-p</span> <span class="string">/exports</span></span><br><span class="line"><span class="string">ADD</span> <span class="string">run_nfs.sh</span> <span class="string">/usr/local/bin/</span></span><br><span class="line"><span class="string">ADD</span> <span class="string">index.html</span> <span class="string">/tmp/index.html</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">chmod</span> <span class="number">644</span> <span class="string">/tmp/index.html</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## expose mountd 20048/tcp and nfsd 2049/tcp and rpcbind 111/tcp</span></span><br><span class="line"><span class="string">EXPOSE</span> <span class="number">2049</span><span class="string">/tcp</span> <span class="number">20048</span><span class="string">/tcp</span> <span class="number">111</span><span class="string">/tcp</span> <span class="number">111</span><span class="string">/udp</span></span><br><span class="line"><span class="comment">## init script to set up this nfs server</span></span><br><span class="line"><span class="string">ENTRYPOINT</span> <span class="string">["/usr/local/bin/run_nfs.sh",</span> <span class="string">"/exports"</span><span class="string">]</span></span><br></pre></td></tr></table></figure></p>
<p>Then create a service with cluster IP to expose the NFS server pod.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line">  </span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs-server</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">      port:</span> <span class="number">2049</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">mountd</span></span><br><span class="line"><span class="attr">      port:</span> <span class="number">20048</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">rpcbind</span></span><br><span class="line"><span class="attr">      port:</span> <span class="number">111</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    role:</span> <span class="string">nfs-server</span></span><br></pre></td></tr></table></figure></p>
<p>Then we can create application PV and PVC from this service:<br>refer to DNS for <a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/" target="_blank" rel="noopener">service and pod</a>.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  capacity:</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="number">1</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  nfs:</span></span><br><span class="line">    <span class="comment">## service name</span></span><br><span class="line">    <span class="comment">## 这里需要cluster IP，如果有其他DNS配置，可以直接用service name</span></span><br><span class="line"><span class="attr">    server:</span> <span class="string">&lt;nfs</span> <span class="string">server</span> <span class="string">service</span> <span class="string">cluster</span> <span class="string">IP&gt;</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">"/exports"</span></span><br></pre></td></tr></table></figure></p>
<p>Then you can create PVC bind this PV for other use.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>nfs</tag>
      </tags>
  </entry>
  <entry>
    <title>Local Persistent Volume</title>
    <url>/2020/04/02/k8s-local-persistent-volume/</url>
    <content><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><a href="https://kubernetes.io/blog/2019/04/04/kubernetes-1.14-local-persistent-volumes-ga/" target="_blank" rel="noopener">Kubernetes 1.14: Local Persistent Volumes GA</a><br><strong>Recap:</strong><br>A local persistent volume represents a local disk directly-attached to a single Kubernetes Node. With the Local Persistent Volume plugin, Kubernetes workloads can now consume high performance local storage using the same volume APIs that app developers have become accustomed to.</p>
<p>一个和hostPath的重要区别:<br>The biggest difference is that the Kubernetes scheduler understands which node a Local Persistent Volume belongs to. With HostPath volumes, a pod referencing a HostPath volume may be moved by the scheduler to a different node resulting in data loss. But with Local Persistent Volumes, the Kubernetes scheduler ensures that a pod using a Local Persistent Volume is <strong>always</strong> scheduled to the same node.</p>
<p>While HostPath volumes may be referenced via a Persistent Volume Claim (PVC) or directly inline in a pod definition, Local Persistent Volumes can only be referenced via a PVC. This provides additional security benefits since Persistent Volume objects are managed by the administrator, preventing Pods from being able to access any path on the host.</p>
<p>Additional benefits include support for formatting of block devices during mount, and volume ownership using fsGroup.</p>
<p>注意: 实际上emptyDir + fsGroup也可以实现类似hostPath的效果，emptyDir用的是<code>/sysroot</code> (RedHat Linux), 比如多个pods 使用emptyDir在同一个Node, 我在各自的emptyDir中touch了一个file: compute-0 和compute-3, 进入Node使用find command就可以看到了:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/sysroot/ostree/deploy/rhcos/var/lib/kubelet/pods/68e65ed4-4e62-4588-9269-8947dea9dd46/volumes/kubernetes.io~empty-dir/compute-dedicated-scratch/compute-0</span><br><span class="line"></span><br><span class="line">/sysroot/ostree/deploy/rhcos/var/lib/kubelet/pods/92b26b37-92f3-4609-83cb-da8cb8727ca2/volumes/kubernetes.io~empty-dir/compute-dedicated-scratch/compute-3</span><br></pre></td></tr></table></figure></p>
<p>还需要注意的是，local storage provisioning 在每个node上只会provision attach的disk个数一样的PV，并且这个PV会被一个PVC占据，尽管PV大小是500G但是PVC只请求5G。（不知道这个以后是否会有改进）</p>
<h2 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h2><blockquote>
<p>Only test on OCP <code>4.3</code> version</p>
</blockquote>
<p><a href="https://docs.openshift.com/container-platform/4.3/storage/persistent_storage/persistent-storage-local.html" target="_blank" rel="noopener">OpenShift persistent storage using local volumes</a><br><a href="https://github.com/openshift/local-storage-operator/blob/master/docs/deploy-with-olm.md" target="_blank" rel="noopener">Deploy local-storage Operator</a></p>
<ol>
<li>install local storage operator (it is by default set in <code>local-storage</code> namespace)</li>
<li>provision the local storage</li>
<li>create local volume persistentVolumeClaim and attach to pod</li>
</ol>
<p>After deploy the operator, then<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## get hostname of each worker node</span></span><br><span class="line"><span class="comment">## can use label -l to filter worker node if needed</span></span><br><span class="line">kbc describe node | grep hostname</span><br></pre></td></tr></table></figure></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">"local.storage.openshift.io/v1"</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">"LocalVolume"</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">"local-disks"</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">"local-storage"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  nodeSelector:</span></span><br><span class="line"><span class="attr">    nodeSelectorTerms:</span></span><br><span class="line"><span class="attr">    - matchExpressions:</span></span><br><span class="line"><span class="attr">        - key:</span> <span class="string">kubernetes.io/hostname</span></span><br><span class="line"><span class="attr">          operator:</span> <span class="string">In</span></span><br><span class="line"><span class="attr">          values:</span></span><br><span class="line">          <span class="comment">## put hostname above here</span></span><br><span class="line"><span class="bullet">          -</span> <span class="string">worker0.jc-portworx.os.xx.com</span></span><br><span class="line"><span class="bullet">          -</span> <span class="string">worker1.jc-portworx.os.xx.com</span></span><br><span class="line"><span class="bullet">          -</span> <span class="string">worker2.jc-portworx.os.xx.com</span></span><br><span class="line"><span class="attr">  storageClassDevices:</span></span><br><span class="line"><span class="attr">    - storageClassName:</span> <span class="string">"local-sc"</span></span><br><span class="line"><span class="attr">      volumeMode:</span> <span class="string">Filesystem</span></span><br><span class="line">      <span class="comment">## The file system that will be formatted when the local volume is mounted</span></span><br><span class="line"><span class="attr">      fsType:</span> <span class="string">xfs</span></span><br><span class="line"><span class="attr">      devicePaths:</span></span><br><span class="line">        <span class="comment">## use blkid command to get this devicePath</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">/dev/vdc</span></span><br></pre></td></tr></table></figure>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">blkid</span><br><span class="line"><span class="comment">## for clarity I remove unrelated output</span></span><br><span class="line"><span class="comment">## First colume is the device path</span></span><br><span class="line">/dev/vdc: LABEL=<span class="string">"mdvol"</span> UUID=<span class="string">"fdac344f-8d5f-48bd-9101-99cb416bb93d"</span> TYPE=<span class="string">"xfs"</span></span><br></pre></td></tr></table></figure></p>
<p>let’s check <code>/dev/vdc</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsblk /dev/vdc</span><br><span class="line"></span><br><span class="line">NAME MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT</span><br><span class="line">vdc  252:32   0  500G  0 disk</span><br></pre></td></tr></table></figure></p>
<p>After apply the CR <code>LocalVolume</code>, let’s check <code>local-storage</code> namespace status, you should see lcoal diskmaker and provisioner pods are up and running, corresponding PVs are ready as well.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-diskmaker-6787r         1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-diskmaker-jvwnq         1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-diskmaker-lfzq9         1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-provisioner-fzgs2       1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-provisioner-mqd86       1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-disks-local-provisioner-t2bvz       1/1     Running   0          52m</span><br><span class="line">pod/<span class="built_in">local</span>-storage-operator-7f8dbfb95c-7brlv   1/1     Running   0          16h</span><br><span class="line"></span><br><span class="line"><span class="comment">## PV</span></span><br><span class="line"><span class="built_in">local</span>-pv-38162728                          500Gi      RWO            Delete           Available                                                     <span class="built_in">local</span>-sc                7m45s</span><br><span class="line"><span class="built_in">local</span>-pv-64bcf276                          500Gi      RWO            Delete           Available                                                     <span class="built_in">local</span>-sc                7m45s</span><br><span class="line"><span class="built_in">local</span>-pv-bd2d227                           500Gi      RWO            Delete           Available</span><br></pre></td></tr></table></figure></p>
<p>If things are all set, we can consume the local storage provisioned by local-sc. Here I use <code>volumeClaimTemplates</code> instead of create separate PVC (这里应该不能使用分开的PVC，因为PVC的创建和pod位于的node有关，事先并不知道). </p>
<blockquote>
<p>Notice that if there is one PV per node, then one PVC will consume the whole PV. So if use statefulset with volume claim template, we will only have one pod per node.</p>
</blockquote>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-local-sc</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">nginx</span> <span class="comment"># has to match .spec.template.metadata.labels</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span> <span class="comment"># by default is 1</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">nginx</span> <span class="comment"># has to match .spec.selector.matchLabels</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">      securityContext:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">      serviceAccount:</span> <span class="string">wkc-iis-sa</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">wkc-iis-sa</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">xxx.swg.com/compute-image:b994-11_7_1_1-b191</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          allowPrivilegeEscalation:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">          privileged:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">          readOnlyRootFilesystem:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">          runAsNonRoot:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">          runAsUser:</span> <span class="number">10032</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">['/bin/sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'tail -f /dev/null'</span><span class="string">]</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">my-scratch</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/opt/xx/Scratch2</span></span><br><span class="line"><span class="attr">  volumeClaimTemplates:</span></span><br><span class="line"><span class="attr">  - metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">my-scratch</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">      storageClassName:</span> <span class="string">local-sc</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          storage:</span> <span class="number">5</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure>
<p>Now let’s check <code>/dev/vdc</code> again by <code>lsblk</code>, you will see it is associated with the pod.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Operator</title>
    <url>/2020/01/23/k8s-operator/</url>
    <content><![CDATA[<p>最近安排我去写一个operator的任务，挺有意思。<br>How to explain Kubernetes Operators in plain English:<br><a href="https://enterprisersproject.com/article/2019/2/kubernetes-operators-plain-english" target="_blank" rel="noopener">https://enterprisersproject.com/article/2019/2/kubernetes-operators-plain-english</a></p>
<p>brief introduction:<br><a href="https://www.youtube.com/watch?v=DhvYfNMOh6A" target="_blank" rel="noopener">https://www.youtube.com/watch?v=DhvYfNMOh6A</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>operator</tag>
      </tags>
  </entry>
  <entry>
    <title>Patch K8s Objects in Place</title>
    <url>/2020/02/07/k8s-patch-object/</url>
    <content><![CDATA[<p>For updating components secret or configmap, you can do complete replace:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get secret docker-registry-auth -o yaml -n default \</span><br><span class="line">        | sed -e <span class="string">"/htpasswd/c\  htpasswd: <span class="variable">$&#123;AUTH_BASE64&#125;</span>"</span> \</span><br><span class="line">        | kubectl replace -f -</span><br><span class="line">kubectl get configmap repl-pod-map -n <span class="variable">$NAMESPACE</span> -o yaml </span><br><span class="line">        | sed -e <span class="string">"/<span class="variable">$&#123;POD_NAME&#125;</span>/d"</span> </span><br><span class="line">        | kubectl replace -f-</span><br></pre></td></tr></table></figure></p>
<p>For patching pod controller like deployment and statefulset, see:<br><a href="https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/run-application/update-api-object-kubectl-patch/</a></p>
<h2 id="Strategic-merge-patch"><a href="#Strategic-merge-patch" class="headerlink" title="Strategic merge patch"></a>Strategic merge patch</h2><p>For example, add one more containers in the pod, give the yaml file <code>patch-file.yaml</code>:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">patch-demo-ctr-2</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">redis</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># this command use default patch strategy for containers field: merge</span></span><br><span class="line">kubectl patch deployment patch-demo --patch <span class="string">"<span class="variable">$(cat patch-file.yaml)</span>"</span></span><br></pre></td></tr></table></figure>
<p>This will get merged not replaced (the original container is kept), but not all fields have <code>merge</code> strategy, some use default strategy that is <code>replace</code>, for example: tolerations field.</p>
<p>How to know the patch strategy of each field?<br>see <a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/" target="_blank" rel="noopener">API document</a><br>It seems not all fields have specified patch strategy, for example, I don’t see that on configmap.</p>
<h2 id="Json-merge-patch"><a href="#Json-merge-patch" class="headerlink" title="Json merge patch"></a>Json merge patch</h2><p>A strategic merge patch is different from a JSON merge patch. With a JSON merge patch, if you want to update a list, you have to specify the <code>entire new list</code>. And the new list completely replaces the existing list.</p>
<p>The <code>kubectl patch</code> command has a <code>--type</code> parameter that you can set to one of these values:</p>
<ol>
<li>json (json patch)</li>
<li>merge (json merge patch)</li>
<li>strategic (default)</li>
</ol>
<blockquote>
<p>这里文档有问题，如果用json merge patch on configmap，其实还是做的merge操作(之前的数据被保留)，并不是replace.这个值得注意，比如以下2个commands效果是一样的:<br>  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## json merge patch</span></span><br><span class="line">kubectl patch configmap repl-pod-map -n pines --<span class="built_in">type</span> merge -p <span class="string">"&#123;\"data\": &#123;\"test1\":\"test1key\"&#125;&#125;"</span></span><br><span class="line"><span class="comment">## defaul strategic patch</span></span><br><span class="line">kubectl patch configmap repl-pod-map -n pines  -p <span class="string">"&#123;\"data\": &#123;\"test1\":\"test1key\"&#125;&#125;"</span></span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>  我猜可能是configmap没有明确的patch strategy定义，但对于其他有明确定义的field，则json merge patch会replace之前的数据。</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>patch</tag>
      </tags>
  </entry>
  <entry>
    <title>RBAC Authorization for K8s API Access</title>
    <url>/2019/01/27/k8s-role-rbac/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>We want to <strong>scale the compute pods by calling k8s API from inside the engine conductor container</strong>, this definitely need to be authorized and we need to grant privilege for this action.</p>
<p>There are some concepts you need to know in order to achieve the goal.</p>
<h2 id="Service-Account"><a href="#Service-Account" class="headerlink" title="Service Account"></a>Service Account</h2><blockquote>
<p><a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/" target="_blank" rel="noopener">what is Service Account</a></p>
</blockquote>
<p>Processes in containers inside pods can contact the apiserver. When they do, they are authenticated as a particular service account (for example, by default is <code>default</code> service account).</p>
<p>Once you create a namespace, for example <code>test-1</code>, there is a <code>default</code> service account automatically generated.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get sa -n <span class="built_in">test</span>-1</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NAME      SECRETS   AGE</span><br><span class="line">default   1         139m</span><br></pre></td></tr></table></figure>
<p>let’s see what is inside the service account<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl describe sa default -n <span class="built_in">test</span>-1</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Name:                default</span><br><span class="line">Namespace:           <span class="built_in">test</span>-1</span><br><span class="line">Labels:              &lt;none&gt;</span><br><span class="line">Annotations:         &lt;none&gt;</span><br><span class="line">Image pull secrets:  &lt;none&gt;</span><br><span class="line">Mountable secrets:   default-token-mtv4n</span><br><span class="line">Tokens:              default-token-mtv4n</span><br><span class="line">Events:              &lt;none&gt;</span><br></pre></td></tr></table></figure>
<p>Here we see there is a mountable secret <code>default-token-mtv4n</code>, that is the credentials to access the apiserver.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl describe secret default-token-mtv4n -n <span class="built_in">test</span>-1</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Name:         default-token-mtv4n</span><br><span class="line">Namespace:    <span class="built_in">test</span>-1</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: default</span><br><span class="line">              kubernetes.io/service-account.uid: 387381d3-2272-11e9-91a2-00163e0196e7</span><br><span class="line"></span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"></span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  6 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrd...</span><br></pre></td></tr></table></figure>
<h2 id="ClusterRole"><a href="#ClusterRole" class="headerlink" title="ClusterRole"></a>ClusterRole</h2><blockquote>
<p><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#role-and-clusterrole" target="_blank" rel="noopener">what is Role and ClusterRole</a></p>
</blockquote>
<p>A <code>ClusterRole</code> can be used to grant the same permissions as a <code>Role</code>, but because they are <code>cluster-scoped</code>, they can also be used to grant access to</p>
<ul>
<li>cluster-scoped resources (like nodes)</li>
<li>non-resource endpoints (like “/healthz”)</li>
<li>namespaced resources (like pods) across all namespaces</li>
</ul>
<p>Here we use a cluster role called <code>cluster-admin</code>, it’s generated by default<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get clusterrole | grep cluster-admin</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cluster-admin                        174m</span><br></pre></td></tr></table></figure>
<h2 id="ClusterRole-Binding"><a href="#ClusterRole-Binding" class="headerlink" title="ClusterRole Binding"></a>ClusterRole Binding</h2><blockquote>
<p><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#rolebinding-and-clusterrolebinding" target="_blank" rel="noopener">what is RoleBinding and ClusterRole Binding</a></p>
</blockquote>
<p>A role binding grants the permissions defined in a role to a user or set of users. It holds a list of subjects (users, groups, or service accounts), and a reference to the role being granted. Permissions can be granted within a namespace with a <code>RoleBinding</code>, or cluster-wide with a <code>ClusterRoleBinding</code>.</p>
<p>below we grant service account <code>default</code> in namespace <code>test-1</code> the <code>cluster-admin</code> level privilege.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">&lt;cluster</span> <span class="string">role</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line">    <span class="string">&lt;key:value&gt;</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"> <span class="bullet">-</span> <span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">   name:</span> <span class="string">default</span></span><br><span class="line"><span class="attr">   namespace:</span> <span class="string">&lt;namespace</span> <span class="string">of</span> <span class="string">sa&gt;</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line">  <span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line">  <span class="attr">name:</span> <span class="string">cluster-admin</span></span><br><span class="line">  <span class="attr">apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure></p>
<p>then we can write a script, using <code>curl</code> to call K8s API, for example, to scale the number of compute pods:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http_code=$(curl -w <span class="string">"%&#123;http_code&#125;"</span> -sS  --cacert <span class="variable">$CACERT</span>  -XPATCH -H <span class="string">"Content-Type: application/strategic-merge-patch+json"</span> -H <span class="string">"Accept: application/json"</span> -H <span class="string">"Authorization: Bearer <span class="variable">$TOKEN</span>"</span> <span class="string">"https://kubernetes.default/apis/apps/v1/namespaces/<span class="variable">$NAMESPACE</span>/statefulsets/is-engine-compute"</span> --data <span class="string">"&#123;\"spec\":&#123;\"replicas\":<span class="variable">$REP</span>&#125;&#125;"</span> -o <span class="variable">$OUT_FILE</span>)</span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$http_code</span> -ne 200 ]]; <span class="keyword">then</span></span><br><span class="line">    <span class="variable">$&#123;JQ&#125;</span> <span class="string">'&#123; result:.status, code: .code,  message: .message &#125;'</span> <span class="variable">$OUT_FILE</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<p>Where are these <code>CACERT</code>, <code>TOEKN</code> and <code>NAMESPACE</code> from? Actually each container has a default mount point reside in:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/var/run/secrets/kubernetes.io/serviceaccount</span><br></pre></td></tr></table></figure></p>
<p>You can see this when you run <code>kubectl describe pod</code>. Just like other mount files, there are 3 files, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">total 0</span><br><span class="line">lrwxrwxrwx 1 root root 13 Sep 14 16:21 ca.crt -&gt; ..data/ca.crt</span><br><span class="line">lrwxrwxrwx 1 root root 16 Sep 14 16:21 namespace -&gt; ..data/namespace</span><br><span class="line">lrwxrwxrwx 1 root root 12 Sep 14 16:21 token -&gt; ..data/token</span><br></pre></td></tr></table></figure></p>
<p>All of them are used in <code>curl</code> command above.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAMESPACE=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)</span><br><span class="line">CACERT=/var/run/secrets/kubernetes.io/serviceaccount/ca.crt</span><br><span class="line">TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>RBAC</tag>
        <tag>service account</tag>
      </tags>
  </entry>
  <entry>
    <title>K8s No Route to Host</title>
    <url>/2019/08/19/k8s-no-route-to-host/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Today I set up a 4 nodes cluster that 3 nodes belong to the same group and one node from another group. It works fine:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAME                   STATUS   ROLES    AGE     VERSION</span><br><span class="line">dstest1.fyre.xxx.com   Ready    master   4h22m   v1.13.2</span><br><span class="line">dstest2.fyre.xxx.com   Ready    &lt;none&gt;   4h15m   v1.13.2</span><br><span class="line">dstest3.fyre.xxx.com   Ready    &lt;none&gt;   4h15m   v1.13.2</span><br><span class="line">opsf3.fyre.xxx.com     Ready    &lt;none&gt;   4h15m   v1.13.2</span><br></pre></td></tr></table></figure></p>
<p>After I scheduling a pod in <code>opsf3.fyre.xxx.com</code> and run <code>kubectl exec -it</code>, I get this error:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Error from server: error dialing backend: dial tcp 172.16.11.239:10250: connect: no route to host</span><br></pre></td></tr></table></figure></p>
<p>The reason is the firewall is active in <code>opsf3.fyre.xxx.com</code> if you check by running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl status firewalld</span><br></pre></td></tr></table></figure></p>
<p>Run below commands to stop and disable it, then thing get works.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Rook Storage Orchestrator</title>
    <url>/2020/01/20/k8s-rook/</url>
    <content><![CDATA[<p><a href="https://medium.com/flant-com/to-rook-in-kubernetes-df13465ff553" target="_blank" rel="noopener">https://medium.com/flant-com/to-rook-in-kubernetes-df13465ff553</a></p>
<p><a href="https://rook.io/" target="_blank" rel="noopener">Rook</a> turns distributed storage systems into self-managing, self-scaling, self-healing storage services. It automates the tasks of a storage administrator: deployment, bootstrapping, configuration, provisioning, scaling, upgrading, migration, disaster recovery, monitoring, and resource management.</p>
<p>Rook uses the power of the Kubernetes platform to deliver its services: cloud-native container management, scheduling, and orchestration.</p>
<p>Another similar tool is <a href="https://chengdol.github.io/2019/12/10/k8s-external-provisioner/" target="_blank" rel="noopener">Kubernetes External Provisioner</a>.</p>
<h2 id="NFS"><a href="#NFS" class="headerlink" title="NFS"></a>NFS</h2><p>Now is <strong>alpha version</strong><br>in order to use rool NFS, we must have a NFS provisioner or PV first, then rook will work on top of that, manage the NFS storage and provision it again to other application.</p>
<p><a href="https://rook.io/docs/rook/v1.2/nfs.html" target="_blank" rel="noopener">https://rook.io/docs/rook/v1.2/nfs.html</a><br>好好理解一下这段话：<br>The desired volume to export needs to be attached to the NFS server pod via a PVC. Any type of PVC can be attached and exported, such as Host Path, AWS Elastic Block Store, GCP Persistent Disk, CephFS, Ceph RBD, etc. The limitations of these volumes also apply while they are shared by NFS. You can read further about the details and limitations of these volumes in the Kubernetes docs.</p>
<blockquote>
<p>NFS is just a pattern, the file system can be any.</p>
</blockquote>
<p>NFS client packages must be installed on all nodes where Kubernetes might run pods with NFS mounted. Install nfs-utils on CentOS nodes or nfs-common on Ubuntu nodes.</p>
<h2 id="Ceph"><a href="#Ceph" class="headerlink" title="Ceph"></a>Ceph</h2><p>rook will create a soft ceph cluster for us.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>rook</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Security</title>
    <url>/2019/06/24/k8s-security/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>I believe security is an unavoidable topic in Kubernetes or OpenShift, I have encountered lots of SCCs and restricted settings.</p>
<p><a href="https://stackoverflow.com/questions/52700507/k8s-what-is-the-difference-between-security-context-and-security-policy" target="_blank" rel="noopener">https://stackoverflow.com/questions/52700507/k8s-what-is-the-difference-between-security-context-and-security-policy</a></p>
<p><a href="https://kubernetes-security.info/" target="_blank" rel="noopener">https://kubernetes-security.info/</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>security</tag>
      </tags>
  </entry>
  <entry>
    <title>Set up Secure Docker Registry in K8s</title>
    <url>/2020/01/06/k8s-secure-registry/</url>
    <content><![CDATA[<p>The step to set up secure docker registry service in K8s is different from docker. There are some adjustments and changes to apply.</p>
<p>Toolkits we need to achieve our goal:</p>
<ol>
<li>openssl</li>
<li>htpasswd</li>
<li>skopeo</li>
</ol>
<h2 id="Create-SSL-TLS-Certificate-and-Key"><a href="#Create-SSL-TLS-Certificate-and-Key" class="headerlink" title="Create SSL/TLS Certificate and Key"></a>Create SSL/TLS Certificate and Key</h2><p>Use openssl command to generate certificate and private key for setup secure connection:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create certs</span></span><br><span class="line">mkdir -p /root/registry-certs</span><br><span class="line"><span class="comment">## get from master</span></span><br><span class="line"></span><br><span class="line">DOCKER_REGISTRY_URL=blair1.fyre.com</span><br><span class="line"><span class="comment">## make a copy of .crt and give suffix .cert</span></span><br><span class="line">openssl req \</span><br><span class="line">        -newkey rsa:4096 -nodes -x509 -sha256 \</span><br><span class="line">        -keyout /root/registry-certs/tls.key \</span><br><span class="line">        -out /root/registry-certs/tls.cert \</span><br><span class="line">        -days 3650 \</span><br><span class="line">        -subj <span class="string">"/C=US/ST=CA/L=San Jose/O=IBM/OU=Org/CN=<span class="variable">$&#123;DOCKER_REGISTRY_URL&#125;</span>"</span></span><br><span class="line"></span><br><span class="line">cp /root/registry-certs/tls.cert /root/registry-certs/tls.crt</span><br></pre></td></tr></table></figure></p>
<p>Then copy the crt file to every host under <code>/etc/docker/certs.d/&lt;${DOCKER_REGISTRY_URL}&gt;:5000</code> folder for self-signed certificate trust.</p>
<blockquote>
<p>Notice that if the docker daemon json file has enabled the insecure registry, it will not verify the ssl/tls cert! You get docker user account and password, then you can login without certs!</p>
</blockquote>
<h2 id="Create-Docker-User-Info"><a href="#Create-Docker-User-Info" class="headerlink" title="Create Docker User Info"></a>Create Docker User Info</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">##  create auth file</span></span><br><span class="line">DOCKER_USER=demo</span><br><span class="line">DOCKER_PASSWORD=demo</span><br><span class="line"></span><br><span class="line">mkdir -p /tmp/registry-auth</span><br><span class="line">htpasswd -Bbn <span class="variable">$&#123;DOCKER_USER&#125;</span> <span class="variable">$&#123;DOCKER_PASSWORD&#125;</span> &gt; /tmp/registry-auth/htpasswd</span><br></pre></td></tr></table></figure>
<h2 id="Generate-Secret"><a href="#Generate-Secret" class="headerlink" title="Generate Secret"></a>Generate Secret</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create secrets</span></span><br><span class="line"><span class="comment">## we want to setup docker registry in default namespace</span></span><br><span class="line">kubectl create secret tls docker-registry-tls  \</span><br><span class="line">    --key=/root/registry-certs/tls.key  \</span><br><span class="line">    --cert=/root/registry-certs/tls.cert \</span><br><span class="line">    -n default</span><br><span class="line"></span><br><span class="line">kubetctl create secret generic docker-registry-auth \</span><br><span class="line">    --from-file=htpasswd=/tmp/registry-auth/htpasswd \</span><br><span class="line">    -n default</span><br><span class="line"></span><br><span class="line"><span class="comment">## Assume the working namespace is test-1</span></span><br><span class="line">WORKING_NAME_SPACE=<span class="built_in">test</span>-1</span><br><span class="line">DOCKER_REGISTRY_SERVER=<span class="string">"<span class="variable">$&#123;DOCKER_REGISTRY_URL&#125;</span>:5000"</span></span><br><span class="line"></span><br><span class="line">kubectl create namespace <span class="variable">$&#123;NAME_SPACE&#125;</span></span><br><span class="line">kubectl create secret docker-registry docker-registry-creds \</span><br><span class="line">        --docker-server=<span class="variable">$DOCKER_REGISTRY_SERVER</span> \</span><br><span class="line">        --docker-username=<span class="variable">$DOCKER_USER</span> \</span><br><span class="line">        --docker-password=<span class="variable">$DOCKER_PASSWORD</span> \</span><br><span class="line">        -n <span class="variable">$&#123;WORKING_NAME_SPACE&#125;</span></span><br></pre></td></tr></table></figure>
<h2 id="Bind-Image-Pull-Secret-to-Service-Account"><a href="#Bind-Image-Pull-Secret-to-Service-Account" class="headerlink" title="Bind Image Pull Secret to Service Account"></a>Bind Image Pull Secret to Service Account</h2><p>see <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/#add-imagepullsecrets-to-a-service-account" target="_blank" rel="noopener">document</a> in K8s.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## patch creds to default service account in test-1</span></span><br><span class="line"><span class="comment">## assume we use default service account in yaml</span></span><br><span class="line">kubectl patch serviceaccount default \</span><br><span class="line">        -p <span class="string">'&#123;"imagePullSecrets": [&#123;"name": "docker-registry-creds"&#125;]&#125;'</span> \</span><br><span class="line">        -n <span class="variable">$&#123;WORKING_NAME_SPACE&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>Or you can specify imagePullSecrets in yaml explicitly, for example:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">private-reg</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">private-reg-container</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">&lt;your-private-image&gt;</span></span><br><span class="line"><span class="attr">  imagePullSecrets:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">&lt;secret</span> <span class="string">name&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Create-Secure-Docker-Registry"><a href="#Create-Secure-Docker-Registry" class="headerlink" title="Create Secure Docker Registry"></a>Create Secure Docker Registry</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## notice the </span></span><br><span class="line"><span class="comment">##        env field</span></span><br><span class="line"><span class="comment">##        secret mount field</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## deletion is enabled</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">docker-registry</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">docker-registry</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">docker-registry</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">docker-registry</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      affinity:</span></span><br><span class="line"><span class="attr">        nodeAffinity:</span></span><br><span class="line"><span class="attr">          requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line"><span class="attr">            nodeSelectorTerms:</span></span><br><span class="line"><span class="attr">            - matchExpressions:</span></span><br><span class="line"><span class="bullet">              -</span> <span class="string">&#123;key:</span> <span class="string">docker-registry,</span> <span class="attr">operator:</span> <span class="string">In,</span> <span class="attr">values:</span> <span class="string">["true"]&#125;</span></span><br><span class="line"><span class="attr">      hostNetwork:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      tolerations:</span></span><br><span class="line"><span class="attr">      - key:</span> <span class="string">"node-role.kubernetes.io/master"</span></span><br><span class="line"><span class="attr">        operator:</span> <span class="string">"Exists"</span></span><br><span class="line"><span class="attr">        effect:</span> <span class="string">"NoSchedule"</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">docker-registry</span></span><br><span class="line"><span class="attr">        image:</span> <span class="attr">localhost:5000/registry:2.7.1</span>        </span><br><span class="line"><span class="attr">        imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_STORAGE_DELETE_ENABLED</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_AUTH</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">"htpasswd"</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_AUTH_HTPASSWD_REALM</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">"Registry Realm"</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_AUTH_HTPASSWD_PATH</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">"/auth/htpasswd"</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_HTTP_TLS_CERTIFICATE</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">/certs/tls.crt</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">REGISTRY_HTTP_TLS_KEY</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">/certs/tls.key</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">registry</span></span><br><span class="line"><span class="attr">          containerPort:</span> <span class="number">5000</span></span><br><span class="line"><span class="attr">          hostPort:</span> <span class="number">5000</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">docker-data</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/var/lib/registry</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">docker-tls</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/certs</span></span><br><span class="line"><span class="attr">          readOnly:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">docker-auth</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/auth</span></span><br><span class="line"><span class="attr">          readOnly:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">docker-data</span></span><br><span class="line"><span class="attr">        persistentVolumeClaim:</span></span><br><span class="line"><span class="attr">          claimName:</span> <span class="string">registry-pv-claim</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">docker-tls</span></span><br><span class="line"><span class="attr">        secret:</span></span><br><span class="line"><span class="attr">          secretName:</span> <span class="string">docker-registry-tls</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">docker-auth</span></span><br><span class="line"><span class="attr">        secret:</span></span><br><span class="line"><span class="attr">          secretName:</span> <span class="string">docker-registry-auth</span></span><br></pre></td></tr></table></figure>
<p>So far the secure docker registry in K8s is up and running in default namespace, it’s host network true so can be accessed from remote. Later can expose it by ingress.</p>
<h2 id="Update-Docker-User-Info"><a href="#Update-Docker-User-Info" class="headerlink" title="Update Docker User Info"></a>Update Docker User Info</h2><p>See this <a href="https://stackoverflow.com/questions/38216278/update-k8s-configmap-or-secret-without-deleting-the-existing-one" target="_blank" rel="noopener">post</a>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create new htpasswd file</span></span><br><span class="line">DOCKER_USER=demonew</span><br><span class="line">DOCKER_PASSWORD=demonew</span><br><span class="line"></span><br><span class="line">mkdir -p /tmp/registry-auth</span><br><span class="line">htpasswd -Bbn <span class="variable">$&#123;DOCKER_USER&#125;</span> <span class="variable">$&#123;DOCKER_PASSWORD&#125;</span> &gt; /tmp/registry-auth/htpasswd</span><br><span class="line"><span class="comment">## then encode base64</span></span><br><span class="line">AUTH_BASE64=$(cat /tmp/registry-auth/htpasswd | base64 -w 0)</span><br><span class="line"><span class="comment">## replace old auth secret</span></span><br><span class="line"><span class="comment">## the change will be populated to registry pod</span></span><br><span class="line">kubectl get secret docker-registry-auth -o yaml -n default \</span><br><span class="line">        | sed -e <span class="string">"/htpasswd/c\  htpasswd: <span class="variable">$&#123;AUTH_BASE64&#125;</span>"</span> \</span><br><span class="line">        | kubectl replace -f -</span><br><span class="line"></span><br><span class="line"><span class="comment">## replace old docker config creds secret in used working namespaces</span></span><br><span class="line">NEW_REGISTRY_CREDS=$(kubectl create secret docker-registry docker-registry-creds \</span><br><span class="line">        --docker-server=<span class="variable">$DOCKER_REGISTRY_SERVER</span> \</span><br><span class="line">        --docker-username=<span class="variable">$DOCKER_USER</span> \</span><br><span class="line">        --docker-password=<span class="variable">$DOCKER_PASSWORD</span> \</span><br><span class="line">        -n default \</span><br><span class="line">        -o yaml --dry-run \</span><br><span class="line">        | grep <span class="string">"\.dockerconfigjson"</span> | cut -d<span class="string">":"</span> -f2)</span><br><span class="line"></span><br><span class="line">kubectl get secret docker-registry-creds -o yaml -n <span class="variable">$&#123;WORKING_NAME_SPACE&#125;</span> \</span><br><span class="line">        | sed -e <span class="string">"/\.dockerconfigjson/c\  .dockerconfigjson: <span class="variable">$&#123;NEW_REGISTRY_CREDS&#125;</span>"</span> \</span><br><span class="line">        | kubectl replace -f -</span><br></pre></td></tr></table></figure></p>
<h2 id="Skopeo-Operation"><a href="#Skopeo-Operation" class="headerlink" title="Skopeo Operation"></a>Skopeo Operation</h2><p>Please refer my skopeo <a href="https://chengdol.github.io/2019/09/26/docker-skopeo/" target="_blank" rel="noopener">blog</a> for more details.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">skopeo copy \</span><br><span class="line">       --dest-creds <span class="variable">$&#123;DOCKER_USER&#125;</span>:<span class="variable">$&#123;DOCKER_PASSWORD&#125;</span> \</span><br><span class="line">       --dest-cert-dir /root/registry-certs \</span><br><span class="line">       docker-archive:/root/busybox.tar.gz \</span><br><span class="line">       docker://<span class="variable">$&#123;DOCKER_REGISTRY_SERVER&#125;</span>/busybox:latest</span><br><span class="line"></span><br><span class="line">skopeo inspect \</span><br><span class="line">       --creds <span class="variable">$&#123;DOCKER_USER&#125;</span>:<span class="variable">$&#123;DOCKER_PASSWORD&#125;</span> \</span><br><span class="line">       --cert-dir /root/registry-certs \</span><br><span class="line">       docker://<span class="variable">$&#123;DOCKER_REGISTRY_SERVER&#125;</span>/busybox:latest</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Service and Ingress</title>
    <url>/2019/09/07/k8s-service-ingress/</url>
    <content><![CDATA[<p>Difference between NodePort, HostPort and Cluster IP<br><a href="https://stackoverflow.com/questions/50709001/rancher-2-difference-between-nodeport-hostport-and-cluster-ip" target="_blank" rel="noopener">https://stackoverflow.com/questions/50709001/rancher-2-difference-between-nodeport-hostport-and-cluster-ip</a></p>
<p>docker go template<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect xx:yy -f &#123;&#123;.Config.Cmd&#125;&#125;</span><br></pre></td></tr></table></figure></p>
<p>DNS for Services and Pods<br><a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/" target="_blank" rel="noopener">https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Lose Connection to K8s Server</title>
    <url>/2019/06/11/k8s-server-missing/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<h2 id="Server-Login-Failed"><a href="#Server-Login-Failed" class="headerlink" title="Server Login Failed"></a>Server Login Failed</h2><p>This morning I find I lose the connection with my icp4d kubernetes server (it was good last night), if I run:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get pods</span></span><br><span class="line"><span class="attr">error:</span> <span class="string">the</span> <span class="string">server</span> <span class="string">doesn't</span> <span class="string">have</span> <span class="string">a</span> <span class="string">resource</span> <span class="string">type</span> <span class="string">"pods"</span></span><br></pre></td></tr></table></figure></p>
<p>then:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl version</span></span><br><span class="line"><span class="string">Client</span> <span class="attr">Version:</span> <span class="string">version.Info&#123;Major:"1",</span> <span class="attr">Minor:"12",</span> <span class="attr">GitVersion:"v1.12.4+icp-ee",</span> <span class="attr">GitCommit:"d03f6421b5463042d87aa0211f116ba4848a0d0f",</span> <span class="attr">GitTreeState:"clean",</span> <span class="attr">BuildDate:"2019-01-17T13:14:09Z",</span> <span class="attr">GoVersion:"go1.10.4",</span> <span class="attr">Compiler:"gc",</span> <span class="attr">Platform:"linux/amd64"&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">error:</span> <span class="string">You</span> <span class="string">must</span> <span class="string">be</span> <span class="string">logged</span> <span class="string">in</span> <span class="string">to</span> <span class="string">the</span> <span class="string">server</span> <span class="string">(the</span> <span class="string">server</span> <span class="string">has</span> <span class="string">asked</span> <span class="string">for</span> <span class="string">the</span> <span class="string">client</span> <span class="string">to</span> <span class="string">provide</span> <span class="string">credentials)</span></span><br></pre></td></tr></table></figure></p>
<p>But it seems kubectl config is good, the token is there:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl config view</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">clusters:</span></span><br><span class="line"><span class="attr">- cluster:</span></span><br><span class="line"><span class="attr">    insecure-skip-tls-verify:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    server:</span> <span class="attr">https://172.16.3.23:8001</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">icp-cluster1</span></span><br><span class="line"><span class="attr">- cluster:</span></span><br><span class="line"><span class="attr">    certificate-authority:</span> <span class="string">mycluster/ca.pem</span></span><br><span class="line"><span class="attr">    server:</span> <span class="attr">https://172.16.3.23:8001</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">contexts:</span></span><br><span class="line"><span class="attr">- context:</span></span><br><span class="line"><span class="attr">    cluster:</span> <span class="string">icp-cluster1</span></span><br><span class="line"><span class="attr">    user:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">- context:</span></span><br><span class="line"><span class="attr">    cluster:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">    user:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">- context:</span></span><br><span class="line"><span class="attr">    cluster:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">zen</span></span><br><span class="line"><span class="attr">    user:</span> <span class="string">mycluster-user</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">mycluster-context</span></span><br><span class="line"><span class="attr">current-context:</span> <span class="string">mycluster-context</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Config</span></span><br><span class="line"><span class="attr">preferences:</span> <span class="string">&#123;&#125;</span></span><br><span class="line"><span class="attr">users:</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">admin</span></span><br><span class="line"><span class="attr">  user:</span></span><br><span class="line"><span class="attr">    client-certificate:</span> <span class="string">/etc/cfc/conf/kubecfg.crt</span></span><br><span class="line"><span class="attr">    client-key:</span> <span class="string">/etc/cfc/conf/kubecfg.key</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">mycluster</span></span><br><span class="line"><span class="attr">  user:</span></span><br><span class="line"><span class="attr">    client-certificate:</span> <span class="string">/ibm/InstallPackage/ibm-cp-app/cluster/cfc-certs/kubernetes/kubecfg.crt</span></span><br><span class="line"><span class="attr">    client-key:</span> <span class="string">/ibm/InstallPackage/ibm-cp-app/cluster/cfc-certs/kubernetes/kubecfg.key</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">mycluster-user</span></span><br><span class="line"><span class="attr">  user:</span></span><br><span class="line"><span class="attr">    token:</span> <span class="string">eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJhdF9oYXNoIjoiYjVkNDMxZDMwNGZmMGUyYWM0NWJlOTY1NjU5YTQyN2ViOWUwNzE5NCIsInJlYWxtTmFtZSI6ImN1c3RvbVJlYWxtIiwidW5pcXVlU2VjdXJpdHlOYW1lIjoiYWRtaW4iLCJpc3MiOiJodHRwczovL215Y2x1c3Rlci5pY3A6OTQ0My9vaWRjL2VuZHBvaW50L09QIiwiYXVkIjoiYTc1ZTZmZjQ3YzQyZTJhZDA3YjZiMjUzMTVmZTExMTQiLCJleHAiOjE1NjAyMzkwNzEsImlhdCI6MTU2MDIxMDI3MSwic3ViIjoiYWRtaW4iLCJ0ZWFtUm9sZU1hcHBpbmdzIjpbXX0.cwGioosvwjONIllJExWRADicgibShbSl2x05r3hpiMpXQQia_4HDuvfUCNNyvLiFkBfz1xvuoz9JeAkOdRa7QVR0RD8TGVnYyu10S50AQ5b_LjGaTNoxdGJjLLEGkBt5gzJCsZaVw49ttd-lzDV28badpUBtm1cih4-3o-wbM6inJqCqR97ujgImRW0BS0Jj1pbENAEidAquyZscGMje5vyyRc9A67VWWJxZXo0J1fG081yhvaryRWbvinLLSPRm8_eley1GqItUMvRmIpzC-X7xsg4zIvCE8QhPoKrJp2xRFjDwsvCN44wJv9hdkfx3cGxjjOBdg6ofsVkNND5njg</span></span><br></pre></td></tr></table></figure></p>
<p>I check the docker and kubelet status, all are active:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl status docker</span><br><span class="line">systemctl status kubelet</span><br></pre></td></tr></table></figure></p>
<p>Then I try to reboot all nodes, and it set up correctly. Don’t know how to reproduce this issue, no idea what happened and how to fix it (without rebooting), sadly.</p>
<h2 id="Server-Connection-Refused-6443"><a href="#Server-Connection-Refused-6443" class="headerlink" title="Server Connection Refused 6443"></a>Server Connection Refused 6443</h2><p>Similar issue happened again in my <code>dstest</code> cluster:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kubectl get pods -n test-1</span></span><br><span class="line"><span class="string">The</span> <span class="string">connection</span> <span class="string">to</span> <span class="string">the</span> <span class="string">server</span> <span class="number">9.30</span><span class="number">.188</span><span class="number">.95</span><span class="string">:6443</span> <span class="string">was</span> <span class="string">refused</span> <span class="bullet">-</span> <span class="string">did</span> <span class="string">you</span> <span class="string">specify</span> <span class="string">the</span> <span class="string">right</span> <span class="string">host</span> <span class="string">or</span> <span class="string">port?</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># kubectl version</span></span><br><span class="line"><span class="string">Client</span> <span class="attr">Version:</span> <span class="string">version.Info&#123;Major:"1",</span> <span class="attr">Minor:"13",</span> <span class="attr">GitVersion:"v1.13.2",</span> <span class="attr">GitCommit:"cff46ab41ff0bb44d8584413b598ad8360ec1def",</span> <span class="attr">GitTreeState:"clean",</span> <span class="attr">BuildDate:"2019-01-10T23:35:51Z",</span> <span class="attr">GoVersion:"go1.11.4",</span> <span class="attr">Compiler:"gc",</span> <span class="attr">Platform:"linux/amd64"&#125;</span></span><br><span class="line"><span class="string">The</span> <span class="string">connection</span> <span class="string">to</span> <span class="string">the</span> <span class="string">server</span> <span class="number">9.30</span><span class="number">.188</span><span class="number">.95</span><span class="string">:6443</span> <span class="string">was</span> <span class="string">refused</span> <span class="bullet">-</span> <span class="string">did</span> <span class="string">you</span> <span class="string">specify</span> <span class="string">the</span> <span class="string">right</span> <span class="string">host</span> <span class="string">or</span> <span class="string">port?</span></span><br></pre></td></tr></table></figure></p>
<p>Check this <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#check-required-ports" target="_blank" rel="noopener">required ports list</a>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># netstat -tunlp | grep 6443</span><br><span class="line">tcp6       0      0 :::6443                 :::*                    LISTEN      27047/kube-apiserve</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note, there is no <code>kube-apiserver</code> service in <code>systemctl</code>, so how to restart it? The <code>kube-apiserver</code> is from a static pod, so I think I can restart the container directly by <code>docker restart &lt;container ID&gt;</code>:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># docker ps -a | grep apiserver</span></span><br><span class="line"><span class="number">8</span><span class="string">f661411fa02</span>        <span class="number">177</span><span class="string">db4b8e93a</span>           <span class="string">"kube-apiserver --au..."</span>   <span class="string">About</span> <span class="string">an</span> <span class="string">hour</span> <span class="string">ago</span>   <span class="string">Up</span> <span class="number">4</span> <span class="string">minutes</span>                            <span class="string">k8s_kube-apiserver_kube-apiserver-dstest1.fyre.ibm.com_kube-system_d175f38c007e23cc443d6ba50ba15533_0</span></span><br><span class="line"><span class="number">0</span><span class="string">f05946a8a59</span>        <span class="string">k8s.gcr.io/pause:3.1</span>   <span class="string">"/pause"</span>                 <span class="string">About</span> <span class="string">an</span> <span class="string">hour</span> <span class="string">ago</span>   <span class="string">Up</span> <span class="string">About</span> <span class="string">an</span> <span class="string">hour</span>                        <span class="string">k8s_POD_kube-apiserver-dstest1.fyre.ibm.com_kube-system_d175f38c007e23cc443d6ba50ba15533_0</span></span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>Haven’t got chance to reproduce this issue, this solution may not work…</p>
<p>In a health cluster:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># kbc cluster-info</span></span><br><span class="line"><span class="string">Kubernetes</span> <span class="string">master</span> <span class="string">is</span> <span class="string">running</span> <span class="string">at</span> <span class="attr">https://9.30.188.95:6443</span></span><br><span class="line"><span class="string">KubeDNS</span> <span class="string">is</span> <span class="string">running</span> <span class="string">at</span> <span class="attr">https://9.30.188.95:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</span></span><br><span class="line"></span><br><span class="line"><span class="string">To</span> <span class="string">further</span> <span class="string">debug</span> <span class="string">and</span> <span class="string">diagnose</span> <span class="string">cluster</span> <span class="string">problems,</span> <span class="string">use</span> <span class="string">'kubectl cluster-info dump'</span><span class="string">.</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Server-Connection-Refused-8080"><a href="#Server-Connection-Refused-8080" class="headerlink" title="Server Connection Refused 8080"></a>Server Connection Refused 8080</h2><p>This issue is similar to 6443 one, but it shows:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">The</span> <span class="string">connection</span> <span class="string">to</span> <span class="string">the</span> <span class="string">server</span> <span class="attr">localhost:8080</span> <span class="string">was</span> <span class="string">refused</span> <span class="bullet">-</span> <span class="string">did</span> <span class="string">you</span> <span class="string">specify</span> <span class="string">the</span> <span class="string">right</span> <span class="string">host</span> <span class="string">or</span> <span class="string">port?</span></span><br></pre></td></tr></table></figure></p>
<p>Recall that when we set up K8s cluster by <code>kubeadm</code>, we run:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">[kubeconfig]</span> <span class="string">Using</span> <span class="string">kubeconfig</span> <span class="string">folder</span> <span class="string">"/etc/kubernetes"</span></span><br><span class="line"><span class="string">[kubeconfig]</span> <span class="string">Writing</span> <span class="string">"admin.conf"</span> <span class="string">kubeconfig</span> <span class="string">file</span></span><br><span class="line"><span class="string">[kubeconfig]</span> <span class="string">Writing</span> <span class="string">"kubelet.conf"</span> <span class="string">kubeconfig</span> <span class="string">file</span></span><br><span class="line"><span class="string">[kubeconfig]</span> <span class="string">Writing</span> <span class="string">"controller-manager.conf"</span> <span class="string">kubeconfig</span> <span class="string">file</span></span><br><span class="line"><span class="string">[kubeconfig]</span> <span class="string">Writing</span> <span class="string">"scheduler.conf"</span> <span class="string">kubeconfig</span> <span class="string">file</span></span><br><span class="line"><span class="string">[control-plane]</span> <span class="string">Using</span> <span class="string">manifest</span> <span class="string">folder</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line"><span class="string">[control-plane]</span> <span class="string">Creating</span> <span class="string">static</span> <span class="string">Pod</span> <span class="string">manifest</span> <span class="string">for</span> <span class="string">"kube-apiserver"</span></span><br><span class="line"><span class="string">[control-plane]</span> <span class="string">Creating</span> <span class="string">static</span> <span class="string">Pod</span> <span class="string">manifest</span> <span class="string">for</span> <span class="string">"kube-controller-manager"</span></span><br><span class="line"><span class="string">[control-plane]</span> <span class="string">Creating</span> <span class="string">static</span> <span class="string">Pod</span> <span class="string">manifest</span> <span class="string">for</span> <span class="string">"kube-scheduler"</span></span><br><span class="line"><span class="string">[etcd]</span> <span class="string">Creating</span> <span class="string">static</span> <span class="string">Pod</span> <span class="string">manifest</span> <span class="string">for</span> <span class="string">local</span> <span class="string">etcd</span> <span class="string">in</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">Your</span> <span class="string">Kubernetes</span> <span class="string">master</span> <span class="string">has</span> <span class="string">initialized</span> <span class="string">successfully!</span></span><br><span class="line"></span><br><span class="line"><span class="string">To</span> <span class="string">start</span> <span class="string">using</span> <span class="string">your</span> <span class="string">cluster,</span> <span class="string">you</span> <span class="string">need</span> <span class="string">to</span> <span class="string">run</span> <span class="string">the</span> <span class="string">following</span> <span class="string">as</span> <span class="string">a</span> <span class="string">regular</span> <span class="attr">user:</span></span><br><span class="line"></span><br><span class="line">  <span class="string">mkdir</span> <span class="bullet">-p</span> <span class="string">$HOME/.kube</span></span><br><span class="line">  <span class="string">sudo</span> <span class="string">cp</span> <span class="bullet">-i</span> <span class="string">/etc/kubernetes/admin.conf</span> <span class="string">$HOME/.kube/config</span></span><br><span class="line">  <span class="string">sudo</span> <span class="string">chown</span> <span class="string">$(id</span> <span class="bullet">-u):$(id</span> <span class="bullet">-g)</span> <span class="string">$HOME/.kube/config</span></span><br></pre></td></tr></table></figure></p>
<p>I can reproduce this issue if the environment variable <code>KUBECONFIG</code> is missing, so try to export it, both ways are fine:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> KUBECONFIG=<span class="variable">$HOME</span>/.kube/config</span><br><span class="line"><span class="built_in">export</span> KUBECONFIG=/etc/kubernetes/admin.conf</span><br></pre></td></tr></table></figure></p>
<p>A good <code>/etc/kubernetes</code> folder has these items:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ls -ltr /etc/kubernetes/</span></span><br><span class="line"><span class="string">total</span> <span class="number">36</span></span><br><span class="line"><span class="string">drwxr-xr-x</span> <span class="number">3</span> <span class="string">root</span> <span class="string">root</span> <span class="number">4096</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">pki</span></span><br><span class="line"><span class="bullet">-</span><span class="string">rw-------</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">5447</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">admin.conf</span></span><br><span class="line"><span class="bullet">-</span><span class="string">rw-------</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">5539</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">kubelet.conf</span></span><br><span class="line"><span class="bullet">-</span><span class="string">rw-------</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">5483</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">controller-manager.conf</span></span><br><span class="line"><span class="bullet">-</span><span class="string">rw-------</span> <span class="number">1</span> <span class="string">root</span> <span class="string">root</span> <span class="number">5435</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">scheduler.conf</span></span><br><span class="line"><span class="string">drwxr-xr-x</span> <span class="number">2</span> <span class="string">root</span> <span class="string">root</span>  <span class="number">113</span> <span class="string">Jun</span> <span class="number">20</span> <span class="number">10</span><span class="string">:02</span> <span class="string">manifests</span></span><br></pre></td></tr></table></figure></p>
<p>The <code>manifests</code> contains yaml files for creating etcd, kube-apiserver and kube-controller-manager, kube-scheduler.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes sysctl</title>
    <url>/2019/05/07/k8s-sysctl/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>In my article <a href="https://chengdol.github.io/2019/05/01/linux-ipcs/" target="_blank" rel="noopener"><code>&lt;&lt;Linux IPC&gt;&gt;</code></a>, I mentioned that there is a workaround to set IPC kernel parameters using <code>sysctl</code> in Kubernetes cluster if <code>SYS_RESOURCE</code> is not allowed.</p>
<h3 id="Clarification"><a href="#Clarification" class="headerlink" title="Clarification"></a>Clarification</h3><p>From the Kubernetes <a href="https://v1-14.docs.kubernetes.io/docs/tasks/administer-cluster/sysctl-cluster/" target="_blank" rel="noopener">document</a>, we see:</p>
<p>Sysctls are grouped into safe and unsafe sysctls. This means that setting a safe sysctl for one pod:</p>
<ul>
<li>must not have any influence on any other pod on the node</li>
<li>must not allow to harm the node’s health</li>
<li>must not allow to gain CPU or memory resources outside of the resource limits of a pod.</li>
</ul>
<p>By far, most of the namespaced sysctls are not necessarily considered safe (please check latest Kubernetes document to figure out), now it supports:</p>
<ul>
<li>kernel.shm_rmid_forced,</li>
<li>net.ipv4.ip_local_port_range,</li>
<li>net.ipv4.tcp_syncookies.</li>
</ul>
<p>This list will be extended in future Kubernetes versions when the kubelet supports better isolation mechanisms.</p>
<p>All <code>safe</code> sysctls are enabled by default (you can use it directly without additional configuration in kubelet).</p>
<p>All <code>unsafe</code> sysctls are disabled by default and must be allowed manually by the cluster admin on a per-node basis. Pods with disabled unsafe sysctls will be scheduled, but will fail to launch:</p>
<p><img src="https://drive.google.com/uc?id=1ROz7A1kQPzeaBtpLiYPyFHjii0jIvJ52" alt=""></p>
<p>If you describe the failed pod, you get:<br><img src="https://drive.google.com/uc?id=1T7tUI4jIgGXt_qURYSNME-Qtz2RZc-XI" alt=""></p>
<p>A number of sysctls are <code>namespaced</code> in today’s Linux kernels. This means that they can be set independently for each pod on a node. <strong>Only</strong> namespaced sysctls are configurable via the pod securityContext within Kubernetes.</p>
<p>The following sysctls are known to be namespaced. This list could change in future versions of the Linux kernel.</p>
<ul>
<li>kernel.shm*</li>
<li>kernel.msg*</li>
<li>kernel.sem</li>
<li>fs.mqueue.*</li>
<li>net.*</li>
</ul>
<p>Sysctls with no namespace are called <code>node-level</code> sysctls. If you need to set them, you must manually configure them on each node’s operating system, or by using a DaemonSet with privileged containers.</p>
<p>As with node-level sysctls it is recommended to use taints and toleration feature or taints on nodes to schedule those pods onto the right nodes.</p>
<p>Use the pod securityContext to configure namespaced sysctls. The securityContext applies to <strong>all</strong> containers in the same pod.</p>
<h3 id="Configure-kubelet"><a href="#Configure-kubelet" class="headerlink" title="Configure kubelet"></a>Configure kubelet</h3><p>If you need to use <strong>unsafe</strong> sysctls, configure kubelet in target node (configure the node that the unsafe sysctls pod will reside) is a must. Go to edit <code>10-kubeadm.conf</code> file in <code>/etc/systemd/system/kubelet.service.d/</code>, add<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Environment=&quot;KUBELET_UNSAFE_SYSCTLS=--allowed-unsafe-sysctls=&apos;kernel.shm*,kernel.sem,kernel.msg*&apos;&quot;</span><br></pre></td></tr></table></figure></p>
<p>Here I need <code>kernel.shm*</code>, <code>kernel.sem</code> and <code>kernel.msg*</code>.</p>
<p><img src="https://drive.google.com/uc?id=11mDU4EZv5p6MJJYahaRblXICFBUY52aD" alt=""></p>
<p>then run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart kubelet</span><br></pre></td></tr></table></figure></p>
<p>verify changes, you can see <code>--allowed-unsafe-sysctls</code> is there:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep kubelet</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>A brief digress: the kubelet service unit file is in <code>/etc/systemd/system/kubelet.service</code>.</p>
</blockquote>
<p>Then you can edit YAML file to add <code>sysctls</code> option:</p>
<p><img src="https://drive.google.com/uc?id=122vY73xveFwkFrtsipVJb50WTCiwgjUq" alt=""></p>
<p>Sometimes you need to disable <code>hostIPC</code>, if not you will get this problem:</p>
<p><img src="https://drive.google.com/uc?id=1s1sLiMy_FCCu_ClNJlX9r8C3k_Kw6c_E" alt=""></p>
<p>After things done, get into the container to check the kernel parameter vaule, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl -a | grep -i kernel.sem</span><br></pre></td></tr></table></figure></p>
<h3 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h3><p><a href="https://blog.csdn.net/horsefoot/article/details/53007177?utm_source=blogxgwz5" target="_blank" rel="noopener">kubernetes 1.4 new feature: support sysctls</a><br><a href="https://yq.aliyun.com/articles/603745?utm_content=m_1000003747" target="_blank" rel="noopener">configure kernel parameters in k8s cluster</a></p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>sysctl</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka Introduction</title>
    <url>/2019/08/29/kafka-introd/</url>
    <content><![CDATA[<p>Recently lots of Kafka and Zookeeper things are going on, I am not familiar with them so take time to learn.</p>
<p><a href="https://sookocheff.com/post/kafka/kafka-in-a-nutshell/" target="_blank" rel="noopener">Kafka in a Nutshell</a><br>Using Kafka as a central messaging bus. All incoming data is first placed in Kafka and all outgoing data is read from Kafka. Kafka centralizes communication between producers of data and consumers of that data.</p>
<p>Kafka is a distributed messaging system providing fast, highly scalable and redundant messaging through a pub-sub model. Kafka’s distributed design gives it several advantages.</p>
<p>All Kafka messages are organized into <code>topics</code>. A <code>consumer</code> pulls messages off of a Kafka topic while <code>producers</code> push messages into a Kafka <code>topic</code>. Kafka, as a distributed system, each node in the cluster is called a Kafka <code>broker</code>.</p>
<p>Each Kafka topics are divided into a number of <code>partitions</code>. Partitions allow you to parallelize a topic by splitting the data in a particular topic across multiple brokers.</p>
<p>Each message within a partition has an identifier called its <code>offset</code>. The <code>offset</code> the ordering of messages as an immutable sequence.</p>
<p><a href="http://kafka.apache.org/" target="_blank" rel="noopener">Apach Kafka Official Doc</a></p>
]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>K8s NFS Mount Volume Permission</title>
    <url>/2019/08/20/k8s-volumeMount-permission-problem/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>This is an interesting issue which involves 4 topices: <code>Volume</code>, <code>Security Context</code>, <code>NFS</code> and <code>initContainer</code>.</p>
<p>The issue comes from the <code>permission denied</code> error. The process fail to create the file under the mount path, I check the owner and group of that path, they are both <code>root</code>.</p>
<p>In the yaml file, I specify the <code>fsGroup</code> field as id <code>9092</code>, from the official document <a href="https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod" target="_blank" rel="noopener">here</a> (The example use id <code>2000</code>):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Since fsGroup field is specified, all processes of the container are also part of the supplementary group ID 2000. The owner for volume /data/demo and any files created in that volume will be Group ID 2000.</span><br></pre></td></tr></table></figure></p>
<p>so the owner of the volume should be <code>9092</code>, but they don’t.</p>
<p>I searched online and met the same issue from others:<br><a href="https://github.com/kubernetes/examples/issues/260" target="_blank" rel="noopener">https://github.com/kubernetes/examples/issues/260</a></p>
<p>It seems <code>fsGroup</code> securityContext <strong>does not</strong> apply to nfs mount especially we run the containers as non-root user we cannot access the mount. This issue may be solved in later version, need to take care.</p>
<blockquote>
<p>!!! Why this happens? Because we use <code>hostPath</code>, it by default will create root owned path if <code>path</code> does not exist. Here the <code>NFS</code> is not the <code>NFS</code> way kubernetes use, we use <code>hostPath</code> then manually nfs the nodes externally, not by the setting of K8s(need to do experiment).</p>
</blockquote>
<p>The workaround is using <code>initContainers</code> with <code>busybox</code> run as root and <code>chown</code> to the nfs mount with expected id, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">initContainers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: xxx.com:5000/busybox:latest</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">    command: [&quot;sh&quot;, &quot;-c&quot;, &quot;chown 9092:9092 /mnt&quot;]</span><br><span class="line">    securityContext:</span><br><span class="line">      runAsUser: 0</span><br><span class="line">    volumeMounts:</span><br><span class="line">    - name: &lt;volume name from Volumes&gt;</span><br><span class="line">      mountPath: /mnt</span><br></pre></td></tr></table></figure></p>
<p>then we are good.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title>Set systemd as Cgroup Driver</title>
    <url>/2019/03/09/k8s-systemd-cgroup-driver/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>We want to use <code>systemd</code> as cgroup driver for docker and kubelet, let’s see how to achieve that.</p>
<p>First you need to understand what is <code>systemd</code> and <code>cgroup</code>?<br>You can refer to <a href="https://linuxaria.com/article/how-to-manage-processes-with-cgroup-on-systemd" target="_blank" rel="noopener">this article</a>. </p>
<p><code>systemd</code> is a suite of system management daemons, libraries, and utilities designed as a central management and configuration platform for the GNU/Linux computer operating system. It provides a system and service manager that runs as PID <code>1</code> and starts the rest of the system as alternative to the traditional sysVinit.</p>
<p>systemd organizes processes with <code>cgroups</code>, this is a Linux kernel feature to limit, police and account the resource usage of certain processes (actually process groups).</p>
<h3 id="Configure-docker"><a href="#Configure-docker" class="headerlink" title="Configure docker"></a>Configure docker</h3><p>After you install and start docker, by default it will use <code>cgroupfs</code> as the cgroup driver, check by running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker info | grep Cgroup</span><br><span class="line"></span><br><span class="line">Cgroup Driver: cgroupfs</span><br></pre></td></tr></table></figure></p>
<p>Edit <code>/usr/lib/systemd/system/docker.service</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ExecStart=/usr/bin/dockerd --exec-opt native.cgroupdriver=systemd</span><br></pre></td></tr></table></figure></p>
<p>Then reload daemon and restart docker<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></p>
<p>Verify the change<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker info | grep Cgroup</span><br><span class="line"></span><br><span class="line">Cgroup Driver: systemd</span><br></pre></td></tr></table></figure></p>
<h3 id="Configure-kubelet"><a href="#Configure-kubelet" class="headerlink" title="Configure kubelet"></a>Configure kubelet</h3><p>Currently, the kubelet cannot automatically detects the cgroup driver used by the CRI runtime, but the value of <code>--cgroup-driver</code> must match the cgroup driver used by the CRI runtime to ensure the health of the kubelet.</p>
<p><strong>Note</strong>: interesting thing is <code>kubeadm init</code> now can automatically detect and set kubelet with the same cgroup driver as docker (I use version <code>1.13.x</code>). </p>
<p>There is a file:  <code>/var/lib/kubelet/kubeadm-flags.env</code>, that <code>kubeadm init</code> and <code>kubeadm join</code> generates at runtime, populating the <code>KUBELET_KUBEADM_ARGS</code> variable dynamically, in <code>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</code> you can see it:<br><img src="https://drive.google.com/uc?id=1Wn2J8wk_7e36Z-W_x5lgM93nFBkGJ7EV" alt=""></p>
<p>you will see <code>systemd</code> resides in <code>/var/lib/kubelet/kubeadm-flags.env</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">KUBELET_KUBEADM_ARGS=--cgroup-driver=systemd --network-plugin=cni --pod-infra-container-image=k8s.gcr.io/pause:3.1</span><br></pre></td></tr></table></figure></p>
<p>Anyway let’s see how to do the configuration manually. After install kubelet, go to edit <code>/etc/systemd/system/kubelet.service.d/10-kubeadm.conf</code> file, add this line:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Environment=&quot;KUBELET_CGROUP_ARGS=--cgroup-driver=systemd&quot;</span><br></pre></td></tr></table></figure></p>
<p>Append <code>$KUBELET_CGROUP_ARGS</code> at end of <code>ExecStart=/usr/bin/kubelet</code> statement:</p>
<p><img src="https://drive.google.com/uc?id=1AiZ-y12HevZivQm5TwIYYzY-OX7lfzho" alt=""></p>
<blockquote>
<p>Note: in the file <code>/etc/systemd/system/kubelet.service</code>, it seems you can also configure here: <code>ExecStart=/usr/bin/kubelet --cgroup-driver=systemd</code>, not very clear the difference.</p>
</blockquote>
<p>Then when you complete <code>kubeadm init</code>,  verify the change:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep kubelet</span><br><span class="line"></span><br><span class="line">root     19864  4.5  0.6 2326996 104192 ?      Ssl  01:21  32:49 /usr/bin/kubelet</span><br><span class="line">--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf </span><br><span class="line">--kubeconfig=/etc/kubernetes/kubelet.conf </span><br><span class="line">--config=/var/lib/kubelet/config.yaml </span><br><span class="line">--cgroup-driver=systemd </span><br><span class="line">--network-plugin=cni </span><br><span class="line">--pod-infra-container-image=k8s.gcr.io/pause:3.1 </span><br><span class="line">--cgroup-driver=systemd</span><br></pre></td></tr></table></figure></p>
<p>You see, there are 2 <code>--cgroup-driver=systemd</code> options, so I think manually configure kubelet service file is needless.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>systemd</tag>
        <tag>cgroup driver</tag>
      </tags>
  </entry>
  <entry>
    <title>Awk Command Daily Work Summary</title>
    <url>/2019/02/28/linux-awk-summary/</url>
    <content><![CDATA[<p>This blog is used to walk you through some <code>awk</code> operations. <code>awk</code> is its own programming language itself and contains a lot of really good tools, enables a programmer to write tiny but effective programs in the form of statements that define <strong>text patterns</strong> that are to be searched for in <strong>each line</strong> of a document and the action that is to be taken when a <strong>match</strong> is found within a line. </p>
<p><a href="https://www.geeksforgeeks.org/awk-command-unixlinux-examples/" target="_blank" rel="noopener">Reference from GeeksforGeeks</a><br><a href="https://ferd.ca/awk-in-20-minutes.html" target="_blank" rel="noopener">awk in 20 mins</a><br>WHAT CAN WE DO WITH AWK ?</p>
<ol>
<li><p>AWK Operations:<br>(a) Scans a file line by line<br>(b) Splits each input line into fields<br>(c) Compares input line/fields to pattern<br>(d) Performs action(s) on matched lines</p>
</li>
<li><p>Useful For:<br>(a) Transform data files<br>(b) Produce formatted reports</p>
</li>
<li><p>Programming Constructs:<br>(a) Format output lines<br>(b) Arithmetic and string operations<br>(c) Conditionals and loops</p>
</li>
</ol>
<p>日期记录的部分主要平时遇到的零散总结:<br>################################################################<br>#  &emsp; Date &emsp; &emsp; &emsp; &emsp; &emsp; Description<br>#  &emsp; 09/11/2019 &emsp; &emsp; skip first line<br>#  &emsp; 02/28/2019 &emsp; &emsp; print last column<br>#  &emsp; 02/26/2019 &emsp; &emsp; awk remote execution<br>#<br>################################################################</p>
<h3 id="02-26-2019"><a href="#02-26-2019" class="headerlink" title="02/26/2019"></a>02/26/2019</h3><p>When use <code>awk</code> in script, may suffer shell unexpected expanding:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -o StrictHostKeyChecking=no sshrm1 <span class="string">"ifconfig eth0 | grep \"inet\" | awk '&#123;print <span class="variable">$2</span>&#125;'"</span></span><br></pre></td></tr></table></figure></p>
<p>Above will not get right data, instead preceding <code>\</code> before <code>$</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -o StrictHostKeyChecking=no sshrm1 <span class="string">"ifconfig eth0 | grep \"inet\" | awk '&#123;print \$2&#125;'"</span></span><br></pre></td></tr></table></figure></p>
<p>Another method is <code>awk</code> the return value from <code>ssh</code> rather than wrap it in <code>ssh</code> command.</p>
<h3 id="02-28-2019"><a href="#02-28-2019" class="headerlink" title="02/28/2019"></a>02/28/2019</h3><p>Print last column separated by space:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## NF: count of fields of a line</span></span><br><span class="line">awk <span class="string">'&#123;print $NF&#125;'</span> &lt;file&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="09-11-2019"><a href="#09-11-2019" class="headerlink" title="09/11/2019"></a>09/11/2019</h3><p>Skip the first line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## NR: current count of lines</span></span><br><span class="line">awk <span class="string">'NR&gt;1 &#123;print $1&#125;'</span> &lt;file&gt;</span><br></pre></td></tr></table></figure></p>
<p>You can use <code>NR&gt;=2</code>, <code>NR&lt;5</code>, <code>NR==3</code>, etc to limit the range.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## check version</span></span><br><span class="line">awk -W version</span><br><span class="line"><span class="comment">## looks also works</span></span><br><span class="line">awk --version</span><br></pre></td></tr></table></figure>
<p><code>awk</code> has BEGIN and END block, between is the body:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## BEGIN and END run only once</span></span><br><span class="line"><span class="comment">## body run as line number times</span></span><br><span class="line">awk <span class="string">'BEGIN &#123;print "start..."&#125; &#123;print NR, $0&#125; END &#123;print NR&#125;'</span> /etc/hosts</span><br><span class="line"></span><br><span class="line"><span class="comment">## BEGIN</span></span><br><span class="line">start...</span><br><span class="line"><span class="comment">## body</span></span><br><span class="line">1 127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">2 ::1         localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">3 172.16.163.83 myk8s1.fyre.ibm.com myk8s1</span><br><span class="line">4 172.16.182.156 myk8s2.fyre.ibm.com myk8s2</span><br><span class="line">5 172.16.182.187 myk8s3.fyre.ibm.com myk8s3</span><br><span class="line"><span class="comment">## END</span></span><br><span class="line">5</span><br></pre></td></tr></table></figure></p>
<p>We can also put the awk option into awk script:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">awk -f file.awk /etc/passwd</span><br></pre></td></tr></table></figure></p>
<p><code>file.awk</code> content:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## FS is used to specify delimiter to parse line, by default awk use space</span></span><br><span class="line">BEGIN &#123; FS=<span class="string">":"</span> ; <span class="built_in">print</span> <span class="string">"User Name:"</span>&#125; </span><br><span class="line"><span class="comment">## $3 &gt; 999 is the condition match</span></span><br><span class="line"><span class="comment">## NR is internal variable of awk</span></span><br><span class="line"><span class="variable">$3</span> &gt; 999 &#123;<span class="built_in">print</span> NR, <span class="variable">$0</span>; count++ &#125; </span><br><span class="line">END &#123;<span class="built_in">print</span> <span class="string">"Total Lines: "</span> NR <span class="string">" Count Lines: "</span> count&#125;</span><br></pre></td></tr></table></figure></p>
<p>Let’s see more examples, actually sed may perform the same task but awk is more readable.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## set "," as delimiter, $1 to uppercase, $2 to lowercase</span></span><br><span class="line"><span class="comment">## toupper and tolower is awk internal functions</span></span><br><span class="line">awk -F<span class="string">","</span> <span class="string">'&#123;print toupper($1), tolower($2), $3&#125;'</span> &lt;file&gt;</span><br></pre></td></tr></table></figure></p>
<p>lastlog.awk file to show non-root user login statistics<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## exclude if match these:</span></span><br><span class="line">!(/Never logged <span class="keyword">in</span>/ || /^Username/ || /^root/) &#123;</span><br><span class="line">cnt++</span><br><span class="line"><span class="comment">## line fields == 8</span></span><br><span class="line"><span class="keyword">if</span> (NF == 8)</span><br><span class="line">    <span class="built_in">printf</span> <span class="string">"%8s %2s %3s %4s\n"</span>, <span class="variable">$1</span>, <span class="variable">$5</span>, <span class="variable">$4</span>, <span class="variable">$8</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="built_in">printf</span> <span class="string">"%8s %2s %3s %4s\n"</span>, <span class="variable">$1</span>, <span class="variable">$6</span>, <span class="variable">$5</span>, <span class="variable">$9</span></span><br><span class="line">&#125;</span><br><span class="line">END &#123;</span><br><span class="line"><span class="built_in">print</span> <span class="string">"==============================="</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">"Total # of user processed: "</span> cnt</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>awk</tag>
      </tags>
  </entry>
  <entry>
    <title>linux-change-homedir</title>
    <url>/2019/07/15/linux-change-homedir/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Linux Clean Memory Cache</title>
    <url>/2019/03/30/linux-clean-memory/</url>
    <content><![CDATA[<p>When deploying DS, I find the compute pod that assigned to the second node is always in <code>CreateContainer</code> status and hangs there. I ssh into that node and find its memory is occupied heavily by some other processes so the command response is so slow, and the cpu% is also busy with the swap daemon.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">free</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:        8168772      105152      295732     7491216     7767888      273448</span><br><span class="line">Swap:             0           0           0</span><br></pre></td></tr></table></figure></p>
<p>Compare the normal node:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">free</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">  Mem:        8168772      123504     7041388      270836     1003880     7424612</span><br><span class="line">  Swap:             0           0           0</span><br></pre></td></tr></table></figure></p>
<p>You see the shared and buff/cache parts are huge, I need to flush and clean it.</p>
<blockquote>
<p>Note: <code>free -h</code> is more readable</p>
</blockquote>
<p>If you have to clear the disk cache, this command is safest in enterprise and production, will clear the <code>PageCache</code> only:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sync; echo 1 &gt; /proc/sys/vm/drop_caches</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>What is <code>sync</code> command?<br>writes any data buffered in memory out to disk.</p>
</blockquote>
<p>More aggressively, Clear <code>dentries</code> and <code>inodes</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sync; echo 2 &gt; /proc/sys/vm/drop_caches</span><br></pre></td></tr></table></figure></p>
<p>Clear <code>PageCache</code>, <code>dentries</code> and <code>inodes</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sync; echo 3 &gt; /proc/sys/vm/drop_caches</span><br></pre></td></tr></table></figure></p>
<p>It is not recommended to use this in production until you know what you are doing, as it will clear <code>PageCache</code>, <code>dentries</code> and <code>inodes</code>. Because just after your run drop_caches, your server will get busy re-populating memory with <code>inodes</code> and <code>dentries</code>, original Kernel documentation recommends not to run this command outside of a testing or debugging environment. But what if you are a home user or your server is getting too busy and almost filling up it’s memory. You need to be able trade the benefits with the risk.</p>
<blockquote>
<p>what is <code>dirty cache</code>?<br>Dirty Cache refers to data which has not yet been committed to the database (or disk), and is currently held in computer memory. In short, the new/old data is available in Memory and it is different to what you have in database/disk.</p>
</blockquote>
<blockquote>
<p>what is <code>clean cache</code>?<br>Clean cache refers to data which has been committed to database (or disk) and is currently held in computer memory. This is what we desire where everything is in sync.</p>
</blockquote>
<blockquote>
<p>what is <code>dentries</code> and <code>inodes</code>?<br>A filesystem is represented in memory using dentries and inodes.  Inodes are<br>  the objects that represent the underlying files (and also directories). A dentry is an object with a string name (d_name), a pointer to an inode (d_inode), and a pointer to the parent dentry (d_parent)</p>
</blockquote>
<blockquote>
<p>what is <code>drop_caches</code>?<br>Writing to this will cause the kernel to drop <code>clean caches</code>, as well as reclaimable slab objects like dentries and inodes.  Once dropped, their memory becomes free. It will not kill any process.</p>
</blockquote>
<p>This <a href="https://www.blackmoreops.com/2014/10/28/delete-clean-cache-to-free-up-memory-on-your-slow-linux-server-vps/" target="_blank" rel="noopener">post</a> is good to reference.</p>
<p>If you want to clean swap space:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">swapoff -a &amp;&amp; swapon -a</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Commands Collect</title>
    <url>/2020/03/19/linux-cmd-collect/</url>
    <content><![CDATA[<p>Frequently used Linux commands collected and sorted by first letter:</p>
<h3 id="a"><a href="#a" class="headerlink" title="a"></a>a</h3><p><code>awk</code> (data processing and extracting), <code>alias</code>, <code>at</code> (schedule job one time), <code>arp</code> (check layer2 to layer3 mapping)</p>
<h3 id="b"><a href="#b" class="headerlink" title="b"></a>b</h3><p><code>base64</code> (encode/decode), <code>bg</code>, <code>basename</code> (last name), <code>blkid</code></p>
<h3 id="c"><a href="#c" class="headerlink" title="c"></a>c</h3><p><code>cat</code>, <code>cd</code>, <code>cp</code>, <code>cut</code> ,<code>curl</code> ,<code>chown</code> ,<code>chmod</code> ,<code>chgrp</code> ,<code>cron</code> ,<code>clear</code></p>
<h3 id="d"><a href="#d" class="headerlink" title="d"></a>d</h3><p><code>df</code> (disk space check), <code>dirname</code> (path prefix), <code>du</code> (occupied space check), <code>diff</code>, <code>date</code>, <code>dd</code> (convert and copy), <code>dnsdomainname</code>, <code>dig</code> (dns lookup utility)</p>
<h3 id="e"><a href="#e" class="headerlink" title="e"></a>e</h3><p><code>echo</code>, <code>exit</code>, <code>export</code>, <code>env</code>, <code>exportfs</code>, <code>ethtool</code> (physical card)</p>
<h3 id="f"><a href="#f" class="headerlink" title="f"></a>f</h3><p><code>file</code>, <code>free</code>, <code>find</code>, <code>fg</code>, <code>firewall-cmd</code>, <code>fallocate</code> (fast allocate space)</p>
<h3 id="g"><a href="#g" class="headerlink" title="g"></a>g</h3><p><code>gzip</code>, <code>grep</code>, <code>git</code>, <code>gitk</code>, <code>getfacl</code>, <code>getent</code>(look up /etc/hosts)</p>
<h3 id="h"><a href="#h" class="headerlink" title="h"></a>h</h3><p><code>hostname</code>, <code>host</code>, <code>htpasswd</code>, <code>history</code>, <code>hostnamectl</code> (permenant hostname)</p>
<h3 id="i"><a href="#i" class="headerlink" title="i"></a>i</h3><p><code>ip</code> (so powerful), <code>ifconfig</code> (obsolete), <code>id</code>, <code>iperf3</code>, <code>iptables</code>, <code>iostat</code>, <code>ifdown</code>, <code>ifup</code></p>
<h3 id="j"><a href="#j" class="headerlink" title="j"></a>j</h3><p><code>jq</code>, <code>jobs</code>, <code>journalctl</code></p>
<h3 id="k"><a href="#k" class="headerlink" title="k"></a>k</h3><p><code>kill</code></p>
<h3 id="l"><a href="#l" class="headerlink" title="l"></a>l</h3><p><code>ls</code>, <code>less</code>, <code>ln</code>, <code>lsblk</code>, <code>lvdisplay</code>, <code>lscpu</code>, <code>lastlog</code>, <code>last</code> (reboot)</p>
<h3 id="m"><a href="#m" class="headerlink" title="m"></a>m</h3><p><code>mv</code>, <code>mount</code>, <code>more</code>, <code>man</code>, <code>mkdir</code>, <code>mktemp</code></p>
<h3 id="n"><a href="#n" class="headerlink" title="n"></a>n</h3><p><code>nc</code>, <code>netstat</code>, <code>nslookup</code>, <code>nmap</code>, <code>nice</code> (process priority)</p>
<h3 id="o"><a href="#o" class="headerlink" title="o"></a>o</h3><p><code>openssl</code></p>
<h3 id="p"><a href="#p" class="headerlink" title="p"></a>p</h3><p><code>pwd</code>, <code>ping</code>, <code>ps</code>, <code>perf</code>, <code>pvdisplay</code>, <code>pmap</code>, <code>pwdx</code></p>
<h3 id="q"><a href="#q" class="headerlink" title="q"></a>q</h3><p>so far no!</p>
<h3 id="r"><a href="#r" class="headerlink" title="r"></a>r</h3><p><code>rm</code>, <code>rmdir</code>, <code>route</code>, <code>rsync</code>, <code>readlink</code>, <code>runlevel</code>, <code>renice</code>, <code>rpm</code></p>
<h3 id="s"><a href="#s" class="headerlink" title="s"></a>s</h3><p><code>ssh</code>, <code>scp</code>, <code>sftp</code>, <code>strace</code>, <code>sudo</code>, <code>su</code>, <code>sed</code> (stream editor), <code>setfacl</code>,<br><code>sleep</code>, <code>stat</code>, <code>systemctl</code>, <code>shutdown</code>, <code>sar</code> (system activity report), <code>ss</code>(similar to netstat)</p>
<h3 id="t"><a href="#t" class="headerlink" title="t"></a>t</h3><p><code>tar</code>, <code>tcpdump</code> (wireshark), <code>top</code> (keep update), <code>trap</code>, <code>touch</code>, <code>tee</code>, <code>tail</code>, <code>tree</code>, <code>tracepath</code>, <code>traceroute</code>, <code>tload</code>, <code>tc</code> (traffic control)</p>
<h3 id="u"><a href="#u" class="headerlink" title="u"></a>u</h3><p><code>uniq</code>, <code>uname</code>, <code>umount</code>, <code>unlink</code>, <code>uuidgen</code>, <code>uptime</code></p>
<h3 id="v"><a href="#v" class="headerlink" title="v"></a>v</h3><p><code>vim</code>, <code>vmstat</code></p>
<h3 id="w"><a href="#w" class="headerlink" title="w"></a>w</h3><p><code>w</code>, <code>who</code>, <code>wget</code>, <code>wc</code>, <code>wall</code>, <code>write</code>, <code>watch</code></p>
<h3 id="x"><a href="#x" class="headerlink" title="x"></a>x</h3><p><code>xargs</code></p>
<h3 id="y"><a href="#y" class="headerlink" title="y"></a>y</h3><p><code>yum</code></p>
<h3 id="z"><a href="#z" class="headerlink" title="z"></a>z</h3><p><code>zip</code></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>cURL Command Daily Work Summary</title>
    <url>/2019/05/23/linux-curl-summary/</url>
    <content><![CDATA[<p><code>cURL</code> stands for ‘Client URL’, it is a command-line tool for getting or sending data including files using URL syntax. Since <code>cURL</code> uses <code>libcurl</code>, it supports a range of common network protocols, currently including HTTP, HTTPS, FTP, FTPS, SCP, SFTP, TFTP, LDAP, DAP, DICT, TELNET, FILE, IMAP, POP3, SMTP and RTSP.</p>
<p>################################################################<br>#  &emsp; Date &emsp; &emsp; &emsp; &emsp; &emsp; Description<br>#  &emsp; 06/16/2019 &emsp; &emsp; http requestverbose<br>#  &emsp; 05/23/2019 &emsp; &emsp; download from file server<br>#<br>################################################################</p>
<h3 id="05-23-2019"><a href="#05-23-2019" class="headerlink" title="05/23/2019"></a>05/23/2019</h3><p>If the file server need user name and password (usually will prompt when you open in browser).<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">USER=<span class="string">"username"</span></span><br><span class="line">PASSWD=<span class="string">"passwd"</span></span><br><span class="line"></span><br><span class="line">USER_PWD=<span class="string">"<span class="variable">$USER</span>:<span class="variable">$PASSWD</span>"</span></span><br><span class="line">STREAMURL=<span class="string">"https://ips-file.xx.com/Builds/InformationServer/10.5.1/release/target.tar.gz"</span></span><br><span class="line"></span><br><span class="line">curl -k -u <span class="variable">$&#123;USER_PWD&#125;</span> -LO <span class="variable">$&#123;STREAMURL&#125;</span></span><br></pre></td></tr></table></figure></p>
<p><code>-O</code>: downloads the file and saves it with the same name as in the URL.<br><code>-u</code>: specify user and password<br><code>-k</code>: explicitly allows curl to perform ‘insecure’ SSL connections and transfers.<br><code>-L</code>: for redirect</p>
<p>If you don’t turn off the certificate check, you will get error message and fail:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl: (60) Peer&apos;s Certificate has expired.</span><br><span class="line">More details here: http://curl.haxx.se/docs/sslcerts.html</span><br><span class="line"></span><br><span class="line">curl performs SSL certificate verification by default, using a &quot;bundle&quot;</span><br><span class="line"> of Certificate Authority (CA) public keys (CA certs). If the default</span><br><span class="line"> bundle file isn&apos;t adequate, you can specify an alternate file</span><br><span class="line"> using the --cacert option.</span><br><span class="line">If this HTTPS server uses a certificate signed by a CA represented in</span><br><span class="line"> the bundle, the certificate verification probably failed due to a</span><br><span class="line"> problem with the certificate (it might be expired, or the name might</span><br><span class="line"> not match the domain name in the URL).</span><br><span class="line">If you&apos;d like to turn off curl&apos;s verification of the certificate, use</span><br><span class="line"> the -k (or --insecure) option.</span><br></pre></td></tr></table></figure></p>
<h3 id="06-16-2019"><a href="#06-16-2019" class="headerlink" title="06/16/2019"></a>06/16/2019</h3><p>When I was working on <a href="https://chengdol.github.io/2019/06/10/docker-registry-api/" target="_blank" rel="noopener">Docker Registry API</a>, I primarily use <code>curl</code> to do the job.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -v -k -X GET http://localhost:5000/v2/_catalog</span><br></pre></td></tr></table></figure></p>
<p><code>-v</code>: Makes the fetching more verbose/talkative. Mostly useful for debugging. A line starting with <code>&gt;</code> means <code>header data</code> sent by curl, <code>&lt;</code> means <code>header data</code> received by curl that is hidden in normal cases, and a line starting with <code>*</code> means additional info provided by curl.<br><code>-X</code>: (HTTP) Specifies a custom request method to use when communicating with the HTTP server.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title>Scheduling Recurring Tasks with cron</title>
    <url>/2019/05/28/linux-cronjob/</url>
    <content><![CDATA[<p>Let’s first see what does <code>cron</code> represent from <a href="https://en.wikipedia.org/wiki/Cron" target="_blank" rel="noopener">wiki</a>:</p>
<blockquote>
<p>The software utility <code>cron</code> is a time-based job scheduler in Unix-like computer operating systems. People who set up and maintain software environments use <code>cron</code> to schedule jobs (commands or shell scripts) to run periodically at fixed times, dates, or intervals. </p>
</blockquote>
<p><code>cron</code> is most suitable for scheduling repetitive tasks. For example, it runs log file rotation utilities to ensure that your hard drive doesn’t fill up with old log files. You should know how to use cron because it’s just plain useful.</p>
<blockquote>
<p>Also see <a href="https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/" target="_blank" rel="noopener">cronjob</a> in K8s.</p>
</blockquote>
<h2 id="Install-crontab"><a href="#Install-crontab" class="headerlink" title="Install crontab"></a>Install crontab</h2><p>In CentOS or RedHat, you can run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install cronie</span><br></pre></td></tr></table></figure></p>
<p>If you are not sure, try <code>yum provides crontab</code> to see which package will provide this service.</p>
<p>To check if <code>cron</code> service is running or not:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl status crond</span><br></pre></td></tr></table></figure></p>
<p>If inactive, enable and restart it. </p>
<h2 id="crontab-File"><a href="#crontab-File" class="headerlink" title="crontab File"></a>crontab File</h2><p>Cron is driven by a <code>crontab(cron table)</code> file, a configuration file that specifies shell commands to run periodically on a given schedule. </p>
<p>The program running through cron is called a <code>cron job</code>. To install a <code>cron job</code>, you’ll create an entry line in your <code>crontab</code> file, usually by running the <code>crontab</code> command.</p>
<p>Each user can have his or her own crontab file, which means that every system may have multiple crontabs, usually found in <code>/var/spool/cron/</code> folder. the crontab command installs, lists, edits, and removes a user’s crontab.</p>
<h2 id="crontab-Commands"><a href="#crontab-Commands" class="headerlink" title="crontab Commands"></a>crontab Commands</h2><p>For example, run as <code>root</code>, I want to set a recurring task for user <code>dsadm</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -u dsadm -e</span><br></pre></td></tr></table></figure></p>
<p>Then edit like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">00 21 * * * /home/dsadm/test.sh &gt; /tmp/cron-log 2&gt;&amp;1</span><br></pre></td></tr></table></figure></p>
<p>This means on everyday at 9:00PM, user <code>dsadm</code> will run <code>test.sh</code> and redirect output to <code>/tmp/cron-log</code> file. You can also put the entries into a file and run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -u dsadm &lt;entry file&gt;</span><br></pre></td></tr></table></figure></p>
<p>The meaning of the entry is:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ┌───────────── minute (0 - 59)</span><br><span class="line"># │ ┌───────────── hour (0 - 23)</span><br><span class="line"># │ │ ┌───────────── day of the month (1 - 31)</span><br><span class="line"># │ │ │ ┌───────────── month (1 - 12)</span><br><span class="line"># │ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday;</span><br><span class="line"># │ │ │ │ │                                   7 is also Sunday on some systems)</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># │ │ │ │ │</span><br><span class="line"># * * * * * command to execute</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>A <code>*</code> in any field means to match every value.</p>
</blockquote>
<p>Now, if you check <code>/var/spool/cron</code> directory, the <code>dsadm</code> crontab file is created there.</p>
<p>To list the <code>dsadm</code> cron job:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -u dsadm -l</span><br></pre></td></tr></table></figure></p>
<p>To remove <code>dsadm</code> cron job:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -u dsadm -r</span><br></pre></td></tr></table></figure></p>
<h2 id="Run-as-Non-Root"><a href="#Run-as-Non-Root" class="headerlink" title="Run as Non-Root"></a>Run as Non-Root</h2><p>If you want to run <code>crontab</code> as <code>dsadm</code>, you must set the cron permission:</p>
<ul>
<li><code>/etc/cron.allow</code> - If this file exists, it must contain your username for you to use cron jobs.</li>
<li><code>/etc/cron.deny</code> - If the cron.allow file does not exist but the <code>/etc/cron.deny</code> file does exist then, to use cron jobs, you must not be listed in the <code>/etc/cron.deny</code> file. </li>
</ul>
<p>So, if you put <code>dsadm</code> in <code>/etc/cron.allow</code> file, then you can use <code>crontab</code> directly.</p>
<h2 id="System-crontab-File"><a href="#System-crontab-File" class="headerlink" title="System crontab File"></a>System crontab File</h2><p>Linux distributions normally have an <code>/etc/crontab</code> file. You can also edit here, but the format is a little bit difference:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Example of job definition:</span><br><span class="line"># .---------------- minute (0 - 59)</span><br><span class="line"># |  .------------- hour (0 - 23)</span><br><span class="line"># |  |  .---------- day of month (1 - 31)</span><br><span class="line"># |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...</span><br><span class="line"># |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat</span><br><span class="line"># |  |  |  |  |</span><br><span class="line"># *  *  *  *  * user-name  command to be executed</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>cronjob</tag>
      </tags>
  </entry>
  <entry>
    <title>Kill Defunct Process</title>
    <url>/2019/06/05/linux-defunct-process/</url>
    <content><![CDATA[<p>Today after killing a running process, it didn’t disappear but was marked as <code>&lt;defunct&gt;</code> (run <code>ps</code> can see it). What’s this?</p>
<p>Processes marked <code>&lt;defunct&gt;</code> are dead processes (so-called <code>zombies</code>) that remain because their parent has not destroyed them properly. These processes will be destroyed by <code>init(8)</code> if the parent process exits.</p>
<p>On Unix and Unix-like computer operating systems, a <code>zombie process</code> or <code>defunct process</code> is a process that has completed execution but still has an entry in the process table. This entry is still needed to allow the parent process to read its child’s exit status.</p>
<p>There is no harm in letting such processes be unless there are many of them. <code>Zombie</code> is eventually reaped by its parent (by calling wait(2)). If original parent hasn’t reaped it before its own exit then init process (PID == <code>1</code>) does it at some later time.</p>
<p>I checked the PPID of that <code>defunct</code> process, it’s not PID 1 but other shell process. By killing its parent process, the zombie is gone. Determine which is the parent process of this defunct process and kill it. To know this run the command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -ef | grep defunct</span><br></pre></td></tr></table></figure></p>
<p>You can also use this command to verify defunct process is gone.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># To see every process on the system using standard syntax:</span></span><br><span class="line">ps -ef</span><br><span class="line"></span><br><span class="line"><span class="comment"># To see every process on the system using BSD syntax:</span></span><br><span class="line">ps aux</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>process</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux CPU Info</title>
    <url>/2019/11/14/linux-cpuinfo/</url>
    <content><![CDATA[<p>Check CPU information on Linux, just like check memory by watching <code>/proc/meminfo</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo</span><br><span class="line"></span><br><span class="line"><span class="comment">## each processor has a dedicated description</span></span><br><span class="line">processor       : 0</span><br><span class="line">vendor_id       : GenuineIntel</span><br><span class="line">cpu family      : 6</span><br><span class="line">model           : 61</span><br><span class="line">model name      : Intel Core Processor (Broadwell, IBRS)</span><br><span class="line">stepping        : 2</span><br><span class="line">microcode       : 0x1</span><br><span class="line">cpu MHz         : 2199.996</span><br><span class="line">cache size      : 4096 KB</span><br><span class="line">physical id     : 0</span><br><span class="line">siblings        : 1</span><br><span class="line">core id         : 0</span><br><span class="line">cpu cores       : 1</span><br><span class="line">apicid          : 0</span><br><span class="line">initial apicid  : 0</span><br><span class="line">fpu             : yes</span><br><span class="line">fpu_exception   : yes</span><br><span class="line">cpuid level     : 13</span><br><span class="line">wp              : yes</span><br><span class="line">flags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch ssbd ibrs ibpb tpr_shadow vnmi flexpriority ept vpid fsgsbase bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt spec_ctrl</span><br><span class="line">bogomips        : 4399.99</span><br><span class="line">clflush size    : 64</span><br><span class="line">cache_alignment : 64</span><br><span class="line">address sizes   : 40 bits physical, 48 bits virtual</span><br></pre></td></tr></table></figure></p>
<p>Count number of processing units<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo | grep processor | wc -l</span><br></pre></td></tr></table></figure></p>
<p>To get actualy number of cores<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /proc/cpuinfo | grep <span class="string">'core id'</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: The number of processors shown by <code>/proc/cpuinfo</code> might not be the actual number of cores on the processor. For example a processor with 2 cores and hyperthreading would be reported as a processor with 4 cores.</p>
</blockquote>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Check Disk Space</title>
    <url>/2019/08/11/linux-disk-check/</url>
    <content><![CDATA[<p>I get error messages when run <code>docker load</code> command, this is caused by disk space limit. How do I know the disk utilization?</p>
<p>Shows the amount of disk space used and available on Linux file systems.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ df -h</span><br><span class="line"></span><br><span class="line">Filesystem             Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/mapper/rhel-root  241G  219G   23G  91% /</span><br><span class="line">devtmpfs               3.9G     0  3.9G   0% /dev</span><br><span class="line">tmpfs                  3.9G     0  3.9G   0% /dev/shm</span><br><span class="line">tmpfs                  3.9G  8.6M  3.9G   1% /run</span><br><span class="line">tmpfs                  3.9G     0  3.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/vda1             1014M  208M  807M  21% /boot</span><br><span class="line">tmpfs                  783M     0  783M   0% /run/user/0</span><br></pre></td></tr></table></figure></p>
<p>Shows total size of the directory and it’s subdirectories<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">du -ch &lt;path to directory&gt;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux getfacl and setfacl Commands</title>
    <url>/2019/09/25/linux-getfacl-setfacl/</url>
    <content><![CDATA[<p>Today I learn a new method to operate on permission of files and directories, usually I use <code>chmod</code> and <code>chown</code>.</p>
<p>One thing you need to be clear is if for example <code>/etc</code> is owned by root, and <code>/etc/xxx</code> is owned by <code>demo</code> (non-root) user, <code>demo</code> cannot remove <code>/etc/xxx</code> because of permission deny, but <code>demo</code> can create soft link from <code>/etc/xxx</code> and do all other operations inside <code>/etc/xxx</code>.</p>
<p>What if <code>demo</code> want to remove <code>/etc/xxx</code> without changing permissiond of <code>/etc</code> by <code>chmod</code> or <code>chown</code> and without <code>sudo</code>? <code>setfacl</code> is a good choice.</p>
<blockquote>
<p>Note that docker will not allow commit the change of any permission of <code>/</code> directory into image.</p>
</blockquote>
<p>Each file and directory in a Linux filesystem is created with <code>Access Control Lists (ACLs)</code>. The permissions can be set using the <code>setfacl</code> utility. In order to know the access permissions of a file or directory we use <code>getfacl</code>.</p>
<p>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># getfacl /etc</span><br><span class="line"></span><br><span class="line">getfacl: Removing leading &apos;/&apos; from absolute path names</span><br><span class="line"># file: etc/</span><br><span class="line"># owner: root</span><br><span class="line"># group: root</span><br><span class="line">user::rwx</span><br><span class="line">group::r-x</span><br><span class="line">other::r-x</span><br></pre></td></tr></table></figure></p>
<p>then we add <code>demo</code> full permission to <code>/etc</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## run as root</span></span><br><span class="line">setfacl -m u:demo:rwx /etc</span><br></pre></td></tr></table></figure></p>
<p>check again:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># getfacl /etc</span><br><span class="line"></span><br><span class="line">getfacl: Removing leading &apos;/&apos; from absolute path names</span><br><span class="line"># file: etc</span><br><span class="line"># owner: root</span><br><span class="line"># group: root</span><br><span class="line">user::rwx</span><br><span class="line">user:demo:rwx</span><br><span class="line">group::r-x</span><br><span class="line">mask::rwx</span><br><span class="line">other::r-x</span><br></pre></td></tr></table></figure></p>
<p>I have this question:<br><a href="https://unix.stackexchange.com/questions/364517/difference-between-chmod-vs-acl" target="_blank" rel="noopener">Difference between chmod vs ACL</a></p>
<p>Under Linux, <code>ls -l</code> puts a <code>+</code> at the end of the permissions characters to indicate that <code>ACL</code> are present. If <code>ACL</code> are presenting then the basic permissions do not tell the full story: ACL override POSIX permissions:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ls -l /etc</span><br><span class="line"></span><br><span class="line">drwxrwxr-x+ 89 root root 8192 Sep 25 16:24</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux DNS Explore</title>
    <url>/2019/11/04/linux-dns/</url>
    <content><![CDATA[<p>这个问题很有意思，最开始我并没有意识到这其实是个DNS问题，后来随着逐步深入排查，解决了一些有干扰的边边角角的错误，才发现。</p>
<p>问题的开始是当集群中docker registry 已经正常运行的时候，docker push 以及 docker pull不能正常工作，retry 超时。当时的push 路径是以hostname为主的，比如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dal12-3m-3w-testcluster-03master-00.demo.ibmcloud.com:5000/is-realtime-busybox         latest              db8ee88ad75f        3 months ago        1.22MB</span><br></pre></td></tr></table></figure></p>
<p>很奇怪的是docker push操作就在docker registry pod的宿主机上进行，居然还是不行，如果把地址改成<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">localhost:5000/is-realtime-busybox         latest              db8ee88ad75f        3 months ago        1.22MB</span><br></pre></td></tr></table></figure></p>
<p>就可以，这让我首先意识到是域名解析的问题，我的第一反应是查看各个节点上的<code>/etc/hosts</code>文件，完全没问题, <code>ping</code>命令也OK，奇了怪了。</p>
<p>让我们来再仔细的检查一下域名配置：<br>参考这篇文章：<br><a href="https://www.tecmint.com/setup-local-dns-using-etc-hosts-file-in-linux/" target="_blank" rel="noopener">https://www.tecmint.com/setup-local-dns-using-etc-hosts-file-in-linux/</a><br>查看<code>/etc/nsswitch.conf</code>可知域名查询时的顺序:<br>值得注意的是，有的malicious scripting或病毒可能会更改你的nsswitch.conf文件。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#hosts:     db files nisplus nis dns</span></span><br><span class="line">hosts:      files dns</span><br></pre></td></tr></table></figure></p>
<p>files就是指<code>/etc/hosts</code>, dns指DNS server，说明确实是先看local file <code>/etc/hosts</code>的。</p>
<p>查看<code>/etc/resolv.conf</code>，这个就是DNS server的地址了，貌似也没啥问题。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nameserver 10.0.80.11</span><br><span class="line">nameserver 10.0.80.12</span><br></pre></td></tr></table></figure></p>
<p>我大胆猜测了一下有的命令可能不会使用local dns file <code>/etc/hosts</code>，我试了试<code>host</code> command，果然如此：<br><a href="https://serverfault.com/questions/498500/why-does-the-host-command-not-resolve-entries-in-etc-hosts" target="_blank" rel="noopener">Why does the host command not resolve entries in /etc/hosts?</a><br>这个答案还告诉了我另一个命令<code>getent</code>，对于查询<code>/etc/hosts</code>挺方便的。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">getent hosts halos1</span><br></pre></td></tr></table></figure></p>
<p>You will find that <code>dig</code> and <code>nslookup</code> behave the same way as <code>host</code>, the purpose of all of these commands is to do DNS lookups, not to look in files.</p>
<p>后来我让别人把master node的域名和IP加入到集群访问的DNS Server中，问题就解决了！</p>
<p>所以，下次遇到类似问题，除了检查本地DNS配置和文件，还要用<code>host</code> command试一下，看看外部DNS Server是否工作正常，最重要的是，有的命令不会使用<code>/etc/hosts</code>去查询。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Check Linux Distributions</title>
    <url>/2019/03/27/linux-distros/</url>
    <content><![CDATA[<p>I encounter a problem that check which OS is running in my docker container, or extend it as how to check which OS am I using?<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /etc/os-release</span><br><span class="line"></span><br><span class="line">NAME=&quot;Red Hat Enterprise Linux Server&quot;</span><br><span class="line">VERSION=&quot;7.5 (Maipo)&quot;</span><br><span class="line">ID=&quot;rhel&quot;</span><br><span class="line">ID_LIKE=&quot;fedora&quot;</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hostnamectl</span><br><span class="line"></span><br><span class="line">Static hostname: example.com</span><br><span class="line">        Icon name: computer-vm</span><br><span class="line">          Chassis: vm</span><br><span class="line">       Machine ID: e57cfe9136e9430587366e04f14195e1</span><br><span class="line">          Boot ID: 6ebe05de8b7f43c0bfa36d2c62b702de</span><br><span class="line">   Virtualization: kvm</span><br><span class="line"> Operating System: Red Hat Enterprise Linux Server 7.5 (Maipo)</span><br><span class="line">      CPE OS Name: cpe:/o:redhat:enterprise_linux:7.5:GA:server</span><br><span class="line">           Kernel: Linux 3.10.0-862.14.4.el7.x86_64</span><br><span class="line">     Architecture: x86-64</span><br></pre></td></tr></table></figure>
<p>For docker image, you can use <code>docker image inspect</code> command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker image inspect &lt;image name&gt;:&lt;tag&gt; | grep -i &quot;base image&quot;</span><br><span class="line"></span><br><span class="line">&quot;org.label-schema.schema-version&quot;: &quot;= 1.0  </span><br><span class="line">org.label-schema.name=CentOS Base Image  </span><br><span class="line">org.label-schema.vendor=CentOS</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Network Interface</title>
    <url>/2019/11/04/linux-network-interface/</url>
    <content><![CDATA[<p>Sometimes I need to fetch IP from specified network interface, for example <code>eth0</code>.</p>
<p>There are several ways to do it:</p>
<p><code>ifconfig</code> command, but you need to first yum install <code>net-tools.x86_64 : Basic networking tools</code> if it is not present.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ifconfig eth0 | grep &quot;inet&quot; | awk &apos;&#123;print $2&#125;&apos;</span><br></pre></td></tr></table></figure></p>
<p><code>ip</code> command, this command is pre-installed in most linux machine and powerful.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip addr show eth0 | grep &quot;inet\b&quot; | awk &apos;&#123;print $2&#125;&apos; | cut -d/ -f1</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Double Level Softlink</title>
    <url>/2019/09/27/linux-double-softlink/</url>
    <content><![CDATA[<p>This blog shows how double level softlink can be a good workaround for some situations.</p>
<p>We need to link persistent data to a directory under <code>/</code> in a container or pod, for example: <code>/data</code>, this folder is owned by <code>demo</code>, <code>demo</code> is also the start user of the container.</p>
<p>在pod中有个<code>/data</code> folder, owned by <code>demo</code>，我们想persist这个folder的内容. 在这个pod中有个mount point <code>/mnt</code>. 于是想把<code>/data</code> map到 <code>/mnt/data</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ln -s &lt;target&gt; &lt;link name&gt;</span></span><br><span class="line"><span class="comment"># 这样相当于/mnt/data 是个link</span></span><br><span class="line">ln -s /data /mnt/data</span><br></pre></td></tr></table></figure></p>
<p>这样是不对的，从pod外部的storage provisioner看 <code>/min/data</code>仅仅是个borken link.</p>
<p>The correct way is first remove <code>/data</code> then <code>ln -s /mnt/data /data</code> (<code>/data</code>变成了快捷方式，所以写入<code>/data</code>的内容实际上被写入了<code>/mnt/data</code>), but <code>demo</code> is a non-root user without super privilege, it cannot remove <code>/data</code> (<code>/</code> is owned by root).</p>
<p>Let’s see how double level softlink can help:</p>
<ol>
<li>first in docker build time remove <code>/data</code>: <code>rm -rf /data</code></li>
<li>create a intermediary: <code>mkdir -p /home/demo/data &amp;&amp; chown demo:demo /home/demo/data</code></li>
<li>link: <code>ln -s /home/demo/data /data</code></li>
</ol>
<p>then commit the changes into image.</p>
<p>when container start, in the entrypoint:</p>
<ol>
<li>first remove <code>/home/demo/data</code>: <code>rm -rf /home/demo/data</code>, this will make link to <code>/data</code> break.</li>
<li>create another link: <code>ln -s /mnt/data /home/demo/data</code>, now link connected and fixed.</li>
</ol>
<p>So finally the link structure is:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/mnt/data -&gt; /home/demo/data -&gt; /data</span><br></pre></td></tr></table></figure></p>
<p><code>/home/demo/data</code> is a agent between persistent mount<code>/mnt/data</code> and <code>/data</code>.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>ip Command</title>
    <url>/2020/02/04/linux-ip-command/</url>
    <content><![CDATA[<p><code>ip</code> command in Linux is present in the <code>iproute</code> package which is used for performing several network administration tasks. IP stands for Internet Protocol.</p>
<p><code>ifconfig</code> is obsolete.</p>
<p>It can perform several tasks like configuring and modifying the default and static routing, setting up tunnel over IP, listing IP addresses and property information, modifying the status of the interface, assigning, deleting and setting up IP addresses and routes.</p>
<p><a href="https://linuxize.com/post/linux-ip-command/" target="_blank" rel="noopener">https://linuxize.com/post/linux-ip-command/</a><br><a href="http://man7.org/linux/man-pages/man8/ip.8.html" target="_blank" rel="noopener">http://man7.org/linux/man-pages/man8/ip.8.html</a></p>
<p>Most frequently used subcommands:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">link (l) - Display and modify network interfaces.</span><br><span class="line">address (a) - Display and modify IP Addresses.</span><br><span class="line">route (r) - Display and alter the routing table.</span><br><span class="line">neigh (n) - Display and manipulate neighbor objects (ARP table).</span><br><span class="line">netns - deal with network namespace</span><br></pre></td></tr></table></figure></p>
<p>The configurations set with the ip command are <strong>not</strong> persistent. After a system restart, all changes are lost. For permanent settings, you need to edit the distro-specific configuration files or add the commands to a startup script.</p>
<h2 id="address"><a href="#address" class="headerlink" title="address"></a>address</h2><p>Show all IP address associated with all interfaces that are available<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip addr</span><br><span class="line"><span class="comment">## abbr</span></span><br><span class="line">ip a</span><br><span class="line"><span class="comment">## only show ipv4</span></span><br><span class="line">ip -4 a</span><br><span class="line"><span class="comment">## show specified device</span></span><br><span class="line">ip addr show eth0</span><br><span class="line"><span class="comment">## abbr</span></span><br><span class="line">ip a s eth0</span><br><span class="line"><span class="comment">## assign an IP address to an interface. (need append netmask)</span></span><br><span class="line"><span class="comment">## can assign multiple ip address to an interface</span></span><br><span class="line"><span class="comment">## not persistent</span></span><br><span class="line">ip addr add 192.168.1.50/24 dev eth0</span><br><span class="line"><span class="comment">## delete an assigned IP address to an interface. (need append netmask)</span></span><br><span class="line">ip addr del 192.168.1.50/24 dev eth0</span><br></pre></td></tr></table></figure></p>
<h2 id="link"><a href="#link" class="headerlink" title="link"></a>link</h2><p>It is used to display <code>link layer</code> information, like MAC address, it will fetch characteristics of the link layer devices currently available. Any networking device which has a driver loaded can be classified as an available device.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip link</span><br><span class="line"><span class="comment">## show statistic of device with human readable format</span></span><br><span class="line"><span class="comment">## 显示有多少error, drop packets来看是不是网络由问题</span></span><br><span class="line">ip -s -h link</span><br><span class="line">ip -s -h link show eth0</span><br><span class="line"><span class="comment">## bring up</span></span><br><span class="line">ip link <span class="built_in">set</span> eth0 up</span><br><span class="line"><span class="comment">## bring down</span></span><br><span class="line">ip link <span class="built_in">set</span> eth0 down</span><br></pre></td></tr></table></figure></p>
<h2 id="route"><a href="#route" class="headerlink" title="route"></a>route</h2><p>This command helps you to see the route packets your network will take as set in your <strong>kernel routing table</strong>. The first entry is the default route.<br>Other commands perform the same: <code>route</code>, <code>netstat -r</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip route</span><br><span class="line"><span class="comment">## route for a specific network</span></span><br><span class="line">ip route list 9.30.204.0/22</span><br><span class="line"><span class="comment">## add a route to 192.168.121.0/24 via the gateway at 192.168.121.1</span></span><br><span class="line">ip route add 192.168.121.0/24 via 192.168.121.1</span><br><span class="line"><span class="comment">## add a route to 192.168.121.0/24 that can be reached on device eth0.</span></span><br><span class="line">ip route add 192.168.121.0/24 dev eth0</span><br></pre></td></tr></table></figure></p>
<h2 id="neigh"><a href="#neigh" class="headerlink" title="neigh"></a>neigh</h2><h2 id="netns"><a href="#netns" class="headerlink" title="netns"></a>netns</h2>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Network Port Watching</title>
    <url>/2019/11/04/linux-network-port-watching/</url>
    <content><![CDATA[<p>This issue is from a machine without <code>net-tools.x86_64 : Basic networking tools</code> pre-installed, so <code>netstat</code> command does not exist. When watching docker registry pod setup, ansible runs <code>netstat -tunlp | grep 5000</code> to check 5000 port, failed.</p>
<p>Is there other way around to check if the 5000 port is up or not? Yes.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Wait</span> <span class="string">for</span> <span class="string">docker</span> <span class="string">registry</span> <span class="string">to</span> <span class="string">come</span> <span class="string">up</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  shell:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    declare -a array=($(cat /proc/net/tcp6 | cut -d":" -f"3"|cut -d" " -f"1"))</span></span><br><span class="line"><span class="string">    for port in $&#123;array[@]&#125;;</span></span><br><span class="line"><span class="string">    do</span></span><br><span class="line"><span class="string">      val=$(echo $((0x$port)) | grep 5000)</span></span><br><span class="line"><span class="string">      if ! [[ "X$&#123;val&#125;" == "X" ]]; then</span></span><br><span class="line"><span class="string">        break</span></span><br><span class="line"><span class="string">      fi</span></span><br><span class="line"><span class="string">    done</span></span><br><span class="line"><span class="string">    echo $&#123;val&#125; | grep 5000</span></span><br><span class="line"><span class="string"></span><span class="attr">  register:</span> <span class="string">docker_registry</span></span><br><span class="line"><span class="attr">  until:</span> <span class="string">docker_registry.rc</span> <span class="string">==</span> <span class="number">0</span></span><br><span class="line"><span class="attr">  retries:</span> <span class="string">"<span class="template-variable">&#123;&#123; 10 &#125;&#125;</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>Here I watch <code>/proc/net/tcp6</code> kernel file to see what ipv6 port is running (docker registry port is in ipv6 scope here). for ipv4, use <code>/proc/net/tcp</code>. </p>
<p>This file is not plain text, after use <code>cut</code> to extra the port field, then convert the number to decimal. see <a href="https://www.kernel.org/doc/Documentation/networking/proc_net_tcp.txt" target="_blank" rel="noopener">https://www.kernel.org/doc/Documentation/networking/proc_net_tcp.txt</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Offline Package Installation I</title>
    <url>/2019/02/25/linux-offline-package-install-1/</url>
    <content><![CDATA[<p>When I was working on the upgrade DS k8s installer issue, I ran into the problem that I need to install <code>ansible</code>, <code>docker</code> and <code>kubeadm</code> offline. In the production environment, we may not have internet access, that means we need to prepare the rpms and dependencies needed and create a self-contained installer.</p>
<h3 id="Download-missing-rpms-without-installing"><a href="#Download-missing-rpms-without-installing" class="headerlink" title="Download missing rpms without installing"></a>Download missing rpms without installing</h3><blockquote>
<p>Note: This method is (by-design) sensitive to the existence of already-installed packages. It will <strong>only</strong> download missing dependencies you need for that particular box, not all rpms.</p>
</blockquote>
<p>First let’s install the <code>yum-plugin-downloadonly</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y yum-plugin-downloadonly</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install --downloadonly --downloaddir=&lt;directory&gt; &lt;package:version&gt;</span><br></pre></td></tr></table></figure>
<p>For example, I want to get missing rpms for <em>vim</em> editor, reside them in <code>/root/vim</code> folder<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/vim</span><br><span class="line">yum install --downloadonly --downloaddir=/root/vim vim</span><br></pre></td></tr></table></figure></p>
<p><img src="https://drive.google.com/uc?id=1l5sohiuz020QXowIfKddAtIlUyjJWmFl" alt=""></p>
<p>List the target folder:</p>
<p><img src="https://drive.google.com/uc?id=1o9fPX-boaTBYl7r6y2uzDFePAsLa9G9B" alt=""></p>
<p>Another way is using <code>yumdownloader</code> that is from <code>yum-utils</code>. The difference is if the package is already installed completely, <code>yumdownloader</code> will download the outermost level rpm but <code>--downloadonly</code> will do nothing.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yumdownloader --resolve --destdir=/root/vim vim</span><br></pre></td></tr></table></figure>
<p><img src="https://drive.google.com/uc?id=1I_QfnLAWpj-CNKnfZAvF4yKjZ6U8xHET" alt=""></p>
<h3 id="Download-all-rpms-without-installing"><a href="#Download-all-rpms-without-installing" class="headerlink" title="Download all rpms without installing"></a>Download all rpms without installing</h3><h4 id="yum-amp-yumdownloader"><a href="#yum-amp-yumdownloader" class="headerlink" title="yum &amp; yumdownloader"></a>yum &amp; yumdownloader</h4><p>Usually what we really want is to resolve all dependencies and download them, even though some required rpms have already installed in box, <code>yumdownloader</code> or <code>yum --downloadonly</code> with <code>--installroot</code> option is the solution.</p>
<p>Keep in mind that <code>yumdownloader</code> will use your yum database when resolving dependencies.</p>
<p>For example if you download bash, which needs glibc, it will resolve glibc and skip it, since it is installed. <strong>If you want to download all dependencies</strong>, use a different <code>installroot</code> instead.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/vim</span><br><span class="line">mkdir -p /root/new_root</span><br><span class="line">yumdownloader --installroot=/root/new_root --destdir=/root/vim/ --resolve vim</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>This is what I need for a self-contained offline installer.</p>
</blockquote>
<p>Let’s check how many <code>vim</code> related rpms are here, way too many then what we get from the first section.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls -ltr /root/vim | wc -l</span><br><span class="line">57</span><br></pre></td></tr></table></figure></p>
<h4 id="repotrack"><a href="#repotrack" class="headerlink" title="repotrack"></a>repotrack</h4><p>This method can also resolve and download all dependencies, <code>repotrack</code> is from <code>yum-utils</code>, it will down all the dependencies for any architecture by default.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/vim</span><br><span class="line">repotrack -p /root/vim vim-enhanced</span><br></pre></td></tr></table></figure></p>
<p>if you check <code>/root/vim</code>, there are some <code>i686</code> rpms, once you delete them and count again, <code>57</code> the same as we use <code>yumdownloader</code> above.</p>
<blockquote>
<p>Note: actually <code>repotrack</code> has <code>-a</code> option to specify arch, but I am not able to use it, when I specify <code>x86_64</code>, it still downloads <code>i686</code>.</p>
</blockquote>
<h3 id="Install-local-rpms"><a href="#Install-local-rpms" class="headerlink" title="Install local rpms"></a>Install local rpms</h3><p>Now the problem is how to install these rpms in correct order, install them one by one is obviously infeasible, the method that can resolve their dependencies and install automatically is welcome, both command like:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum --disablerepo=* --skip-broken install -y /root/vim/*.rpm</span><br></pre></td></tr></table></figure></p>
<p>and<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm --force -ivh /root/vim/*.rpm</span><br></pre></td></tr></table></figure></p>
<p>may work but it’s not a good way, you may encounter rpm version upgrade issue and duplicate problem. Now from my knowledge create a local yum repository is clean and elegant, please refer my blog <code>Set up and Use Local Yum Repository</code>.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>/proc/$$ and /proc/self</title>
    <url>/2020/02/03/linux-proc-$$-self/</url>
    <content><![CDATA[<p><code>$$</code> is a special bash variable (special parameter <code>$</code> with a preceding expansion mark <code>$</code>) that gets expanded to the <code>pid of the shell</code>.</p>
<p><code>/proc/self</code> is a real symbolic link to the /proc/ subdirectory of the process that is <code>currently making the call</code>.</p>
<p>When you do <code>ls /proc/$$</code> the shell expands it to <code>ls /proc/pid-of-bash</code> and that is what you see, the contents of the shell process.</p>
<p>But when you do <code>ls /proc/self</code> you see the contents of the short lived <code>ls</code> process. If you write code which uses <code>/proc/self</code> that code will see its own pid, namely the process making the system call with <code>/proc/self</code> as part of the pathname in one of its arguments. </p>
<p>The <code>$$</code> is not limited to this usage, you can write echo $$ to see the bash pid; you can use it to kill yourself, etc.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Offline Package Installation II</title>
    <url>/2019/02/26/linux-offline-package-install-2/</url>
    <content><![CDATA[<p>Now, let’s practice what we have learned from <code>Offline package Installation I</code>. For example, I want to install <code>docker</code> and <code>kubeadm</code> etc offline in the target machine.</p>
<h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><blockquote>
<p>Note: here we only download actual dependencies need for installation, not all rpms if we use <code>--installroot</code> option</p>
</blockquote>
<p>I want to install <code>Docker 18.06.3</code> (currently kubeadm now properly recognizes <code>Docker 18.09.0</code> and newer, but still treats <code>18.06</code> as the default supported version). You should perform below steps on a machine that hasn’t installed docker yet.</p>
<blockquote>
<p>Note: <a href="https://docs.docker.com/install/linux/docker-ce/centos/#install-from-a-package" target="_blank" rel="noopener">install from a package</a>, rpms list in this link are not complete, they are in top level but can be used to upgrade version.</p>
</blockquote>
<h4 id="Uninstall-old-version"><a href="#Uninstall-old-version" class="headerlink" title="Uninstall old version"></a>Uninstall old version</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum remove docker \</span><br><span class="line">           docker-client \</span><br><span class="line">           docker-client-latest \</span><br><span class="line">           docker-common \</span><br><span class="line">           docker-latest \</span><br><span class="line">           docker-latest-logrotate \</span><br><span class="line">           docker-logrotate \</span><br><span class="line">           docker-engine</span><br></pre></td></tr></table></figure>
<p>The contents of <code>/var/lib/docker/</code>, including images, containers, volumes, and networks, are preserved. The Docker CE package is now called <code>docker-ce</code>.</p>
<h4 id="Set-up-docker-repository"><a href="#Set-up-docker-repository" class="headerlink" title="Set up docker repository"></a>Set up docker repository</h4><p>Before you install Docker CE for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils \</span><br><span class="line">  device-mapper-persistent-data \</span><br><span class="line">  lvm2</span><br></pre></td></tr></table></figure></p>
<p>Use the following command to set up the stable repository, <code>yum-utils</code> contains <code>yum-config-manager</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure></p>
<h4 id="List-docker-version"><a href="#List-docker-version" class="headerlink" title="List docker version"></a>List docker version</h4><p>List and sort the versions available in your repo. This example sorts results by version number, highest to lowest, and is truncated:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum list docker-ce --showduplicates | sort -r</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">docker-ce.x86_64            3:18.09.2-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64            3:18.09.1-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64            3:18.09.0-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.06.3.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.06.2.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.06.1.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.06.0.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.03.1.ce-1.el7.centos             docker-ce-stable</span><br><span class="line">docker-ce.x86_64            18.03.0.ce-1.el7.centos             docker-ce-stable</span><br><span class="line">docker-ce.x86_64            17.12.1.ce-1.el7.centos             docker-ce-stable</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h4 id="Download-docker-rpms"><a href="#Download-docker-rpms" class="headerlink" title="Download docker rpms"></a>Download docker rpms</h4><p>Install a specific version by its fully qualified package name, which is the package name (<code>docker-ce</code>) plus the version string (2nd column) starting at the first colon (:), up to the first hyphen, separated by a hyphen (-). For example, <code>docker-ce-18.06.3.ce</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/docker-18.06.3-rpms</span><br><span class="line">yum install --downloadonly --downloaddir=/root/docker-18.06.3-rpms docker-ce-18.06.3.ce</span><br></pre></td></tr></table></figure></p>
<p>list the rpms in the target folder:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">audit-2.8.4-4.el7.x86_64.rpm               libselinux-utils-2.5-14.1.el7.x86_64.rpm</span><br><span class="line">audit-libs-2.8.4-4.el7.x86_64.rpm          libsemanage-2.5-14.el7.x86_64.rpm</span><br><span class="line">audit-libs-python-2.8.4-4.el7.x86_64.rpm   libsemanage-python-2.5-14.el7.x86_64.rpm</span><br><span class="line">checkpolicy-2.5-8.el7.x86_64.rpm           libsepol-2.5-10.el7.x86_64.rpm</span><br><span class="line">container-selinux-2.68-1.el7.noarch.rpm    libtool-ltdl-2.4.2-22.el7_3.x86_64.rpm</span><br><span class="line">docker-ce-18.06.3.ce-3.el7.x86_64.rpm      policycoreutils-2.5-29.el7_6.1.x86_64.rpm</span><br><span class="line">libcgroup-0.41-20.el7.x86_64.rpm           policycoreutils-python-2.5-29.el7_6.1.x86_64.rpm</span><br><span class="line">libseccomp-2.3.1-3.el7.x86_64.rpm          python-IPy-0.75-6.el7.noarch.rpm</span><br><span class="line">libselinux-2.5-14.1.el7.x86_64.rpm         setools-libs-3.3.8-4.el7.x86_64.rpm</span><br><span class="line">libselinux-python-2.5-14.1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure></p>
<p>Note that the required components may be changed in later version, such as <code>18.09.2</code>, there are 2 more packages <code>docker-ce-cli-18.09.2</code> and <code>containerd.io</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p /root/docker-18.09.2-rpms</span><br><span class="line">yum install --downloadonly --downloaddir=/root/docker-18.09.2-rpms docker-ce-18.09.2 docker-ce-cli-18.09.2 containerd.io</span><br></pre></td></tr></table></figure></p>
<h4 id="Install-docker-rpms"><a href="#Install-docker-rpms" class="headerlink" title="Install docker rpms"></a>Install docker rpms</h4><p>now install docker <code>18.06.3</code> offline by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum --disablerepo=* -y install /root/docker-18.06.3-rpms/*.rpm</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: please refer my blog <code>Set up and Use Local Yum Repository</code> if you want to create and use local yum repository</p>
</blockquote>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>linux</tag>
        <tag>yum</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>Sync Up Files with rsync</title>
    <url>/2019/05/28/linux-rsync/</url>
    <content><![CDATA[<p>This command is awesome! I said I should do backup periodically and it suits the demands. It’s more elegant and smart than using portable storage or <code>scp</code> to transfer the files.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Let’s see what is <code>rsync</code> from <a href="https://en.wikipedia.org/wiki/Rsync" target="_blank" rel="noopener">wiki</a>:<br><code>rsync</code> is a utility for efficiently transferring and synchronizing files between a computer and an external hard drive and across networked computers by comparing the modification times and sizes of files.</p>
<p><code>rsync</code> will use <strong>SSH</strong> to connect. Once connected, it will invoke the remote host’s <code>rsync</code> and then the two programs will determine what parts of the local file need to be transferred so that the remote file matches the local one.</p>
<p><code>rsync</code> can also operate in a daemon mode, serving and receiving files in the native rsync protocol (using the <code>rsync://</code> syntax). Here I only talks SSH way.</p>
<h2 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h2><p>To get <code>rsync</code> working between two hosts, the <code>rsync</code> program must be installed on both the source and destination, and you’ll need a way to access one machine from the other.</p>
<p>Copy files to remote home or from remote to local<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync files remote:</span><br><span class="line">rsync files user@remote:</span><br><span class="line">rsync user@remote:source dest</span><br></pre></td></tr></table></figure></p>
<p>If <code>rsync</code> isn’t in the remote path but is on the system, use <code>--rsync-path=path</code> to manually specify its location.</p>
<p>Unless you supply extra options, <code>rsync</code> copies <strong>only</strong> files. You will see:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skipping directory xxx</span><br></pre></td></tr></table></figure></p>
<p>To transfer entire directory hierarchies, complete with symbolic links, permissions, modes, and devices, use the <code>-a</code> option.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -nv files -a dir user@remote:</span><br></pre></td></tr></table></figure></p>
<p><code>-n</code>: dry-run, this is vital when you are not sure.<br><code>-vv</code>: verbose mode</p>
<p>To make an exact replica of the source directory, you must delete files in the destination directory that do not exist in the source directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -vv --delete -a dir user@remote:</span><br></pre></td></tr></table></figure></p>
<p>Please use <code>-n</code> dry-run to see what will be deleted before performing command.</p>
<p>Be particular careful with tailing slash after dir:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -a dir/ user@remote:dest</span><br></pre></td></tr></table></figure></p>
<p>This will copy all files under dir to dest folder in remote instead of copy dir into dest.</p>
<p>You can also <code>--exclude=</code>, <code>--exclude-from=</code> and <code>--include=</code> in command.</p>
<p>To speed operation, <code>rsync</code> uses a quick check to determine whether any files on the transfer source are already on the destination. The quick check uses a combination of the file size and its last-modified date.</p>
<p>When the files on the source side are not identical to the files on the destination side, <code>rsync</code> transfers the source files and overwrites any files that exist on the remote side. The default behavior may be inadequate, though, because you may need additional reassurance that files are indeed the same before skipping over them in transfers, or you may want to put in some extra safeguards:</p>
<ul>
<li><p><code>--checksum</code>(abbreviation: <code>-c</code>) Compute checksums (mostly unique signatures) of the files to see if they’re the same. This consumes additional I/O and CPU resources during transfers, but if you’re dealing with sensitive data or files that often have uniform sizes, this option is a must. (This will focus on file content, not date stamp)</p>
</li>
<li><p><code>--ignore-existing</code> Doesn’t clobber files already on the target side.</p>
</li>
<li><p><code>--backup</code> (abbreviation: <code>-b</code>) Doesn’t clobber files already on the target but rather renames these existing files by adding a ~ suffix to their names before transferring the new files.</p>
</li>
<li><p><code>--suffix=s</code> Changes the suffix used with –backup from <code>~</code> to <code>s</code>.</p>
</li>
<li><p><code>--update</code> (abbreviation: <code>-u</code>) Doesn’t clobber any file on the target that has a later date than the corresponding file on the source.</p>
</li>
</ul>
<p>You can also compress the dir when transfer:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -az dir user@remote:</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>rsync</tag>
      </tags>
  </entry>
  <entry>
    <title>SELinux</title>
    <url>/2019/06/23/linux-selinux/</url>
    <content><![CDATA[<p>I have got chance to learn something about <code>SELinux</code> (Security-Enhanced Linux). This is a online training from O’REILLY.</p>
<p>The Linux operating system was never designed with overall security in mind, and that’s exactly where <code>SELinux</code> comes in. Using SELinux adds 21st century security to the Linux operating system. It is key to providing access control and is also an important topic in the Red Hat RHCSA, CompTIA Linux+ and Linux Foundation LFCS exams.</p>
<p><a href="https://en.wikipedia.org/wiki/Security-Enhanced_Linux" target="_blank" rel="noopener">Security-Enhanced Linux</a><br>I am using a <code>CentOS</code> machine in this training.</p>
<p>SELinux implements Mandatory Security. All syscalls are <strong>denied</strong> by default,<br>unless specifically enabled</p>
<ul>
<li>All objects (files, ports, processes) are provided with a security label (the<br>context)</li>
<li>User, role and type part in the context</li>
<li>Type part is the most important</li>
<li>The SELinux policy contains rules where you can see which source context<br>has access to which target context</li>
</ul>
<p>To check if SELinux status, dsiabled or enforcing<br><a href="https://howto.lintel.in/enable-disable-selinux-centos/" target="_blank" rel="noopener">Enable SELinux</a></p>
<p><code>Z</code> flag is the magic to show SELinux information<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -Z /boot</span><br><span class="line">netstat -Ztunlp</span><br><span class="line">ps auxZ</span><br></pre></td></tr></table></figure></p>
<p>看到22:00，没来得及看完😂，唉。。。这个topic对于目前的我，有点用不上，晦涩。不过这个配置有时会被特别提起，disable or permissive.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux PAM Module Configuration</title>
    <url>/2019/04/01/linux-pam/</url>
    <content><![CDATA[<p>When I was working on non-root set up worker containers or pods, in order to grant the non-root user su password-less privilege, I got into PAM module in RHEL. Let’s spend time to understand it.</p>
<p><strong>Pluggable authentication modules (PAMs)</strong> are a common framework for <strong>authentication</strong> and <strong>authorization</strong>. </p>
<p>There are many programs on your system that use PAM modules like su, passwd, ssh and login and other services. PAM main focus is to authenticate your users.</p>
<p>PAM or Pluggable Authentication Modules are the management layer that sits between Linux applications and the Linux native authentication system.</p>
<blockquote>
<p>For full details, please refer:<br><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system-level_authentication_guide/pluggable_authentication_modules" target="_blank" rel="noopener">USING PLUGGABLE AUTHENTICATION MODULES (PAM)</a><br><a href="https://www.cnblogs.com/kevingrace/p/8671964.html" target="_blank" rel="noopener">CHINESE VERSION</a></p>
</blockquote>
<p>Each PAM-aware application or service has a file in the <code>/etc/pam.d/</code> directory. Each file in this directory has the same name as the service to which it controls access. For example, the <code>login</code> program defines its service name as login and installs the <code>/etc/pam.d/login</code> PAM configuration file.</p>
<p>What I have done is add a non-root user, for example <code>demo</code>, to <code>wheel</code> group (usually <code>wheel</code> group is pre-existing), operate this as root user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usermod -a -G wheel demo</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Why <code>wheel</code> group? What is <code>wheel</code> stand for in computing?</p>
<p>In computing, the term <code>wheel</code> refers to a user account with a wheel bit, a system setting that provides additional special system privileges that empower a user to execute restricted commands that ordinary user accounts cannot access.</p>
<p>Modern Unix systems generally use user groups as a security protocol to control access privileges. The <code>wheel</code> group is a special user group used on some Unix systems to control access to the su or sudo command, which allows a user to masquerade as another user (usually the super user).</p>
<p>By default it permits root access to the system if the applicant user is a member of the <code>wheel</code> group.</p>
</blockquote>
<p>check <code>demo</code> group information:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">id demo</span><br><span class="line"></span><br><span class="line">uid=1010(demo) gid=1010(demo) groups=1010(demo),10(wheel)</span><br></pre></td></tr></table></figure></p>
<p>you can also go to <code>/etc/group</code> file to check group members of <code>wheel</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wheel:x:10:demo</span><br></pre></td></tr></table></figure></p>
<p>Then go to edit <code>/etc/pam.d/su</code> file to uncomment this directive:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Uncomment the following line to implicitly trust users in the &quot;wheel&quot; group.</span><br><span class="line">auth           sufficient      pam_wheel.so trust use_uid</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>What is <code>pam_wheel.so</code>?</p>
<p>The <code>pam_wheel</code> PAM module is used to enforce the so-called <code>wheel</code> group. By default it permits root access(su - ) to the system if the applicant user is a member of the wheel group. If no group with this name exist, the module is using the group with the group-ID 0.</p>
</blockquote>
<p>Now the user <code>demo</code> can su to other users (include root) without password. You can run command as another user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">su - &lt;another&gt; -c &quot;&lt;command&gt;&quot;</span><br></pre></td></tr></table></figure></p>
<p>If you also want to have <code>sudo</code> password-less privilege for <code>wheel</code> group user, you need to edit <code>/etc/sudoers</code> file by <code>visudo</code> as root like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## Allows people in group wheel to run all commands</span><br><span class="line">#%wheel  ALL=(ALL)       ALL</span><br><span class="line"></span><br><span class="line">## Same thing without a password</span><br><span class="line">%wheel        ALL=(ALL)       NOPASSWD: ALL</span><br></pre></td></tr></table></figure></p>
<h3 id="PAM-file-format"><a href="#PAM-file-format" class="headerlink" title="PAM file format"></a>PAM file format</h3><p>Each PAM configuration file, such as <code>/etc/pam.d/su</code> contains a group of directives that define the module (the authentication configuration area) and any controls or arguments with it.</p>
<p>The directives all have a simple syntax that identifies the module purpose (interface) and the configuration settings for the module.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">module_interface	control_flag	module_name module_arguments</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong>module_name</strong> — such as <code>pam_wheel.so</code></li>
<li><strong>auth</strong> — This module interface authenticates users. For example, it requests and verifies the validity of a password. Modules with this interface can also set credentials, such as group memberships.</li>
</ul>
<p>All PAM modules generate a success or failure result when called. <code>Control flags</code> tell PAM what to do with the result. Modules can be listed (stacked) in a particular order, and the control flags determine how important the success or failure of a particular module is to the overall goal of authenticating the user to the service.</p>
<ul>
<li><strong>sufficient</strong> — The module result is ignored if it fails. However, if the result of a module flagged sufficient is successful and no previous modules flagged required have failed, then no other results are required and the user is authenticated to the service.</li>
</ul>
<p>Let’s see an example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@MyServer ~]# cat /etc/pam.d/setup</span><br><span class="line"></span><br><span class="line">auth       sufficient	pam_rootok.so</span><br><span class="line">auth       include	system-auth</span><br><span class="line">account    required	pam_permit.so</span><br><span class="line">session	   required	pam_permit.so</span><br></pre></td></tr></table></figure></p>
<p>Here the modules are stacking, from up to bottom, verify each directive one by one,</p>
<ul>
<li><p><em>auth sufficient pam_rootok.so</em> — This line uses the <code>pam_rootok.so</code> module to check whether the current user is root, by verifying that their UID is 0. If this test succeeds, no other modules are consulted and the command is executed. If this test fails, the next module is consulted.</p>
</li>
<li><p><em>auth include system-auth</em> — This line includes the content of the /etc/pam.d/system-auth module and processes this content for authentication.</p>
</li>
</ul>
<p>PAM uses <code>arguments</code> to pass information to a pluggable module during authentication for some modules.</p>
<ul>
<li><p><strong>trust</strong>: The <code>pam_wheel</code> module will return PAM_SUCCESS instead of PAM_IGNORE if the user is a member of the wheel group</p>
</li>
<li><p><strong>use_uid</strong>: The check for wheel membership will be done against the current uid instead of the original one</p>
</li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>pam</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Signals and Trap</title>
    <url>/2019/08/13/linux-signal-trap/</url>
    <content><![CDATA[<p>Signals are software interrupts sent to a program to indicate that an important event has occurred. The events can vary from user requests to illegal memory access errors.</p>
<p>To list the signal supported in system:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kill -l</span><br></pre></td></tr></table></figure></p>
<p>Some common signals:<br><strong>SIGHUP</strong>: Hang up detected on controlling terminal or death of controlling process. Many daemons will <code>reload</code> their configuration files and reopen their logfiles instead of exiting when receiving this signal.<br><strong>SIGINT</strong>: Issued if the user sends an interrupt signal (Ctrl + C)<br><strong>SIGQUIT</strong>: Issued if the user sends a quit signal (Ctrl + D)<br><strong>SIGKILL</strong>: If a process gets this signal it must quit immediately and will not perform any clean-up operations<br><strong>SIGTERM</strong>: Software termination signal (sent by kill by default)<br><strong>SIGSTOP</strong>: Stop process<br><strong>SIGSTP</strong>: Stop typed at terminal<br><strong>SIGCONT</strong>: Continue if stopped</p>
<p>About trap the signals in script, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Set a Trap for Signals for graceful shutdown</span></span><br><span class="line"><span class="built_in">declare</span> -a SIGNALS_TRAPPED=(INT HUP QUIT TERM STOP)</span><br><span class="line"><span class="function"><span class="title">shudown_hook</span></span>() &#123;</span><br><span class="line">  ...</span><br><span class="line">  (/opt/servers/stop.sh)</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"Shutdown and Cleanup Successful..."</span></span><br><span class="line">  <span class="built_in">exit</span> 0</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">trap</span> <span class="string">'shudown_hook'</span> <span class="string">"<span class="variable">$&#123;SIGNALS_TRAPPED[@]&#125;</span>"</span></span><br><span class="line">`</span><br></pre></td></tr></table></figure></p>
<p>The general format is <code>trap command signals</code>, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">trap &quot;rm -rf /tmp/peek.txt; exit 0&quot; 1 2</span><br></pre></td></tr></table></figure></p>
<p>Ignore signal:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">trap &quot;&quot; 2 3 15</span><br></pre></td></tr></table></figure></p>
<p>If you ignore a signal, all subshells also ignore that signal. However, if you specify an action to be taken on the receipt of a signal, all subshells will still take the default action on receipt of that signal.</p>
<p>Reset the traps to default:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">trap 2 3 15</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>signal</tag>
      </tags>
  </entry>
  <entry>
    <title>sed Command Daily Work Summary</title>
    <url>/2019/05/30/linux-sed-summary/</url>
    <content><![CDATA[<p>Normally we use a interactive text editor, like <code>vim</code>. The command <code>sed</code> is one of the most commonly used <code>command line editor</code> in Linux world. <code>sed</code> stands for the <code>stream editor</code>, it uses the roles supplied to edit a stream of data on the fly.</p>
<p><strong>Note</strong>: Be careful that <code>sed</code> will break the softlink and create a file with the same name! for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ln -s /tmp/source.txt /tmp/link.txt</span><br><span class="line">sed -i -e <span class="string">"s#aaa#bbb#"</span> /tmp/link.txt</span><br></pre></td></tr></table></figure></p>
<p>then the softlink is gone, a new file named link.txt is created instead.<br>so use <code>readlink</code> first to get resolved symbolic links, then use <code>sed</code> on it.</p>
<p>First you need to understand how <code>sed</code> works with text:</p>
<ol>
<li>Reads <strong>one</strong> data line at a time from the input</li>
<li>Matches that data with the supplied editor commands</li>
<li>Changes data in the stream as specified in the commands</li>
<li>Outputs the new data to STDOUT</li>
</ol>
<h2 id="Substitution"><a href="#Substitution" class="headerlink" title="Substitution"></a>Substitution</h2><p>I have a text file <code>sedtxt</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hello world and hello tree.</span><br><span class="line">Using Java print hello world and hello tree.</span><br><span class="line">Using Java print hello world and hello tree.</span><br><span class="line">Using Java print hello world and hello tree.</span><br></pre></td></tr></table></figure></p>
<p>If I want to substite all <code>hello</code> with <code>hi</code> in-place:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -i -e <span class="string">'s/hello/hi/g'</span> sedtxt</span><br></pre></td></tr></table></figure></p>
<p><code>-i</code>: does in-place substitution in file <code>sedtxt</code>, create backup file automatically by using <code>-i.bak</code><br><code>-e</code>: followed by commands<br><code>s/x/y/flags</code>: substitute option, <code>/</code> is the delimiter, can be other chars; <code>g</code> represents that replace in all occurrences (global).</p>
<blockquote>
<p>Note that if not set <code>g</code>, it will only replace first occurrence in <strong>each</strong> line!</p>
</blockquote>
<blockquote>
<p>Note that <code>sed</code> can get input from STDIN or from pipe</p>
</blockquote>
<p>If I want to substitute the <strong>second</strong> <code>hello</code> with <code>goodbye</code> in each line:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'s/hello/goodbye/2'</span> sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hello world and goodbye tree.</span><br><span class="line">Using Java print hello world and goodbye tree.</span><br><span class="line">Using Java print hello world and goodbye tree.</span><br><span class="line">Using Java print hello world and goodbye tree.</span><br></pre></td></tr></table></figure>
<p>If I want to substitute <code>hello</code> with <code>hi</code> and <code>Java</code> with <code>Python</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -e &apos;s/hello/hi/g&apos; -e &apos;s/Java/Pyhton/g&apos; sedtxt</span><br><span class="line">sed -e &apos;s/hello/hi/g; s/Java/Python/g&apos; sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Pyhton print hi world and hi tree.</span><br><span class="line">Using Pyhton print hi world and hi tree.</span><br><span class="line">Using Pyhton print hi world and hi tree.</span><br><span class="line">Using Pyhton print hi world and hi tree.</span><br></pre></td></tr></table></figure>
<p>If I want to print only the matching lines, convenient for debugging:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -n -e &apos;s/hello/hi/gp&apos; sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br></pre></td></tr></table></figure>
<p><code>-n</code>: quiet output<br><code>p</code>: substitute flag to print matching line</p>
<blockquote>
<p>Note, combine with <code>grep</code> to debug is good</p>
</blockquote>
<h3 id="Using-Address"><a href="#Using-Address" class="headerlink" title="Using Address"></a>Using Address</h3><p>The <code>sed</code> editor assigns the first line in the text stream as line number 1 and continues sequentially for each new line.</p>
<p>only replace 2rd line:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -e &apos;2s/hello/hi/g&apos; sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hello world and hello tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hello world and hello tree.</span><br><span class="line">Using Java print hello world and hello tree.</span><br></pre></td></tr></table></figure>
<p>range substitution, <code>&#39;1,$s/hello/hi/g&#39;</code> means from top to bottom.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -e &apos;2,3s/hello/hi/g&apos; sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hello world and hello tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hi world and hi tree.</span><br><span class="line">Using Java print hello world and hello tree.</span><br></pre></td></tr></table></figure>
<p>can also use text pattern to filter lines, this will apply one line contains <code>print</code> word.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -e &apos;/print/s#and#or#&apos; sedtxt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Using Java print hello world or hello tree.</span><br><span class="line">Using Java print hello world or hello tree.</span><br><span class="line">Using Java print hello world or hello tree.</span><br><span class="line">Using Java print hello world or hello tree.</span><br></pre></td></tr></table></figure>
<h2 id="Deletion"><a href="#Deletion" class="headerlink" title="Deletion"></a>Deletion</h2><p>I have a text file <code>seddel</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure></p>
<p>Delete line 2 to end:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'2,$d'</span> seddel</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br></pre></td></tr></table></figure>
<p>can also use pattern matching, delete <code>3rd</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'/3rd/d'</span> seddel</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure>
<p>You can combine 2 address syntax, this will start from first line and until match <code>3rd</code>, replace <code>3rd</code> in the range with <code>NAN</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -e &apos;1,/3rd/&#123;s/3rd/NAN/g&#125;&apos; seddel</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The NAN line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure>
<p>Delete commented and empty line<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sed -e <span class="string">'/^#/d; /^$/d'</span> &lt;file&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Insertion-and-Appending"><a href="#Insertion-and-Appending" class="headerlink" title="Insertion and Appending"></a>Insertion and Appending</h2><p>The insert command (<code>i</code>) adds a new line <strong>before</strong> the specified line.<br>The append command (<code>a</code>) adds a new line <strong>after</strong> the specified line.</p>
<p>I have a text file <code>sedins</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure></p>
<p>Insert at first line:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -e &apos;1iNew line coming!&apos; sedins</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">New line coming!</span><br><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure>
<p>Append at 3rd line:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -e &apos;2aNew line coming!&apos; sedins</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">New line coming!</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure>
<h3 id="Insert-with-white-spaces"><a href="#Insert-with-white-spaces" class="headerlink" title="Insert with white spaces"></a>Insert with white spaces</h3><p>For example, When developing non-root, I want to add <code>runAsUser: 1000</code> right after <code>securityContext:</code> with correct alignment:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -i -e &apos;/securityContext/a\         runAsUser: 1000&apos; xxx.yml</span><br></pre></td></tr></table></figure></p>
<p>Only to escape the first space. <code>sed</code> can automatically recognize the rest of the spaces.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">       securityContext:</span><br><span class="line">         runAsUser: 1000</span><br><span class="line">         privileged: false</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h2 id="Changing"><a href="#Changing" class="headerlink" title="Changing"></a>Changing</h2><p>The change command allows you to change the contents of an entire line of text in the data stream.</p>
<p>I have a text file <code>sedch</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure></p>
<p>change the second line:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -e &apos;2cNONE&apos; sedch</span><br><span class="line">## or</span><br><span class="line">sed -e &apos;/2rd/cNONE&apos; sedch</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">NONE</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure>
<h2 id="Transforming-chars"><a href="#Transforming-chars" class="headerlink" title="Transforming chars"></a>Transforming chars</h2><p>The transform command (<code>y</code>) is the only sed editor command that operates on a single character. </p>
<p>I have a text file <code>sedtrans</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 1st line is 1</span><br><span class="line">The 2rd line is 2</span><br><span class="line">The 3rd line is 3</span><br><span class="line">The 4th line is 4</span><br></pre></td></tr></table></figure></p>
<p>The transform command performs a one-to-one mapping of the inchars and the outchars values.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -e &apos;y/1234/5678/&apos; sedtrans</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The 5st line is 5</span><br><span class="line">The 6rd line is 6</span><br><span class="line">The 7rd line is 7</span><br><span class="line">The 8th line is 8</span><br></pre></td></tr></table></figure>
<p>The transform command is a <strong>global</strong> command; that is, it performs the transformation on any character found in the text line automatically, without regard to the occurrence.<br>You can’t limit the transformation to a specific occurrence of the character.</p>
<h2 id="sed-files-in-directory-and-subdirectories-recursively"><a href="#sed-files-in-directory-and-subdirectories-recursively" class="headerlink" title="sed files in directory and subdirectories recursively"></a>sed files in directory and subdirectories recursively</h2><p>Actually we can find all files by <code>find</code> then exec <code>sed</code>, see this <a href="https://stackoverflow.com/questions/6758963/find-and-replace-with-sed-in-directory-and-sub-directories" target="_blank" rel="noopener">post</a>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find &lt;dir&gt; -<span class="built_in">type</span> f -name <span class="string">"*sh"</span> -<span class="built_in">exec</span> sed -i -e <span class="string">"s|<span class="variable">$&#123;old&#125;</span>|<span class="variable">$&#123;new&#125;</span>|g"</span> &#123;&#125; \;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>-type f</code> is necessary, otherwise will pass directory name to <code>sed</code>.</p>
</blockquote>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sed</tag>
      </tags>
  </entry>
  <entry>
    <title>Special Permission Bits</title>
    <url>/2019/05/11/linux-setuid-sticky-bit/</url>
    <content><![CDATA[<p>I haven’t seen something like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-r-sr-sr-x 1 root     db2iadm1   115555 Mar 21 03:19 db2start</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drwxrwsr-t 1 db2inst1 db2iadm1 212 May 10 17:16 sqllib</span><br><span class="line">drwxr-x--T 1 wasadmin dstage    21 Mar 21 03:56 usr</span><br></pre></td></tr></table></figure>
<p>What are these <code>s</code> (sometimes <code>S</code>) and <code>t/T</code> for? I only know <code>rwx</code> before (too young too simple T_T), these should be some basic things…</p>
<h3 id="Basic-Permissions"><a href="#Basic-Permissions" class="headerlink" title="Basic Permissions"></a>Basic Permissions</h3><ul>
<li><p><code>Read</code> - a readable permission allows the contents of the file to be viewed. A read permission on a directory allows you to list the contents of a directory.</p>
</li>
<li><p><code>Write</code> - a write permission on a file allows you to modify the contents of that file. For a directory, the write permission allows you to edit the contents of a directory (e.g. add/delete files).</p>
</li>
<li><p><code>Execute</code> - for a file, the executable permission allows you to run the file and execute a program or script. For a directory, the execute permission allows you to change to a different directory and make it your current working directory.</p>
</li>
</ul>
<h3 id="Setuid-and-Setgid-Bit"><a href="#Setuid-and-Setgid-Bit" class="headerlink" title="Setuid and Setgid Bit"></a>Setuid and Setgid Bit</h3><p>Assigning the <code>setuid</code> bit to binaries is a common way to give programs root permissions. <code>Linux capabilities</code> is a great alternative to reduce the usage of setuid.</p>
<blockquote>
<p>Capabilities break up root privileges in smaller units, so root access is no longer needed. Most of the binaries that have a setuid flag, can be changed to use capabilities instead.</p>
</blockquote>
<p><a href="https://linux-audit.com/linux-capabilities-hardening-linux-binaries-by-removing-setuid/" target="_blank" rel="noopener">Harden Linux Binaries by Removing setuid</a></p>
<h4 id="Apply-on-File"><a href="#Apply-on-File" class="headerlink" title="Apply on File"></a>Apply on File</h4><p>When the <code>setuid</code> or <code>setgid</code> attributes are set on an executable file, then any users able to execute the file will automatically execute the file with the privileges of the file’s owner (commonly root) and/or the file’s group, depending upon the flags set</p>
<p>This may pose potential security risks in some cases and executables should be properly evaluated before set.</p>
<p>For example the <code>passwd</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rwsr-xr-x. 1 root root 27832 Jan 29  2014 /usr/bin/passwd</span><br></pre></td></tr></table></figure></p>
<p>set setuid on file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod u+s script.sh</span><br></pre></td></tr></table></figure></p>
<p>remove setuid on file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod u-s script.sh</span><br></pre></td></tr></table></figure></p>
<h4 id="Apply-on-Directory"><a href="#Apply-on-Directory" class="headerlink" title="Apply on Directory"></a>Apply on Directory</h4><p>Setting the <code>setgid</code> permission on a directory causes new files and subdirectories created within it to inherit its <code>group ID</code>, rather than the primary group ID of the user who created the file (the owner ID is <strong>never</strong> affected, only the group ID).</p>
<p>set setgid on directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod g+s dir</span><br></pre></td></tr></table></figure></p>
<p>remove setgid on directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod g-s dir</span><br></pre></td></tr></table></figure></p>
<p>The <code>setuid</code> permission set on a directory is ignored on most UNIX and Linux systems.However FreeBSD can be configured to interpret <code>setuid</code> in a manner similar to setgid, in which case it forces all files and sub-directories created in a directory to be owned by that directory’s owner - a simple form of inheritance.</p>
<p>Note that both the <code>setuid</code> and <code>setgit</code> bits have <strong>no effect</strong> if the executable bit is not set. if executable bit is not set, <code>s</code> changes to <code>S</code>.</p>
<h4 id="Chown-Removes-Setuid"><a href="#Chown-Removes-Setuid" class="headerlink" title="Chown Removes Setuid"></a>Chown Removes Setuid</h4><p>If you run <code>chown</code> on a <code>setuid</code> script, you will find that the <code>s</code> is gone. This is a reasonable design, otherwise the <code>s</code> will apply to the new owner, a big security hole.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The `chown&apos; command sometimes clears the set-user-ID or set-group-ID</span><br><span class="line">permission bits.  This behavior depends on the policy and functionality</span><br><span class="line">of the underlying `chown&apos; system call, which may make system-dependent</span><br><span class="line">file mode modifications outside the control of the `chown&apos; command.</span><br><span class="line">For example, the `chown&apos; command might not affect those bits when</span><br><span class="line">invoked by a user with appropriate privileges, or when the bits signify</span><br><span class="line">some function other than executable permission (e.g., mandatory</span><br><span class="line">locking).  When in doubt, check the underlying system behavior.</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note that is you want to keep setuid and owner no change, for example last time deal with <code>sqllib</code>, please perserve when you do copy like: <code>/bin/cp -rfp /home/dfdcdc/sqllib /tmp</code></p>
</blockquote>
<h3 id="Sticky-Bit"><a href="#Sticky-Bit" class="headerlink" title="Sticky Bit"></a>Sticky Bit</h3><p>When set on a file or directory, the <code>sticky bit</code>, or <code>+t</code> mode, means that only the <code>owner</code> (or <code>root</code>) can delete the file (or files under the directory), <strong>regardless of</strong> which users have write access to this file or directory by way of group membership or ownership! </p>
<p>This is useful when a file or directory is owned by a group through which a number of users share write access to a given set of files.</p>
<p>set sticky bit:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod +t script.sh</span><br></pre></td></tr></table></figure></p>
<p>remove sticky bit, note that to change the sticky bit, you need to be either root or the file owner. The root user will be able to delete files regardless of the status of the sticky bit.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod -t script.sh</span><br></pre></td></tr></table></figure></p>
<p>Sometimes you see <code>T</code> instead of <code>t</code>, usually <code>t</code> sits with execute <code>x</code>, but if the execute bit is not set then the <code>t</code> is flagged up as a capital, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">touch file</span><br><span class="line">chmod u=rwx,go=rx file    # &quot;-rwxr-xr-x 1 roaima 0 Sep 10 23:13 file&quot;</span><br><span class="line">chmod +t file             # &quot;-rwxr-xr-t 1 roaima 0 Sep 10 23:13 file&quot;</span><br><span class="line">chmod o-x file            # &quot;-rwxr-xr-T 1 roaima 0 Sep 10 23:13 file&quot;</span><br><span class="line">chmod u=rwx,go=,+t file   # &quot;-rwx-----T 1 roaima 0 Sep 10 23:13 file&quot;</span><br></pre></td></tr></table></figure></p>
<p>Now if a user is not in that group, it cannot even enter the directory.</p>
<h3 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h3><p><a href="https://en.wikipedia.org/wiki/Setuid#SGID" target="_blank" rel="noopener">wiki setuid and setgid</a><br><a href="https://unix.stackexchange.com/questions/228925/how-do-you-set-the-t-bit" target="_blank" rel="noopener">how to set <code>T</code> bit</a><br><a href="https://unix.stackexchange.com/questions/53665/chown-removes-setuid-bit-bug-or-feature" target="_blank" rel="noopener">chown remove setuid</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>setuid</tag>
        <tag>setgid</tag>
        <tag>sticky</tag>
      </tags>
  </entry>
  <entry>
    <title>Solve Conflicts in RPM installation</title>
    <url>/2019/03/02/linux-solve-rpm-conflicts/</url>
    <content><![CDATA[<h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>I want to offline install some rpms for an application, I put all dependencies for that application in a dedicated directory. The problem is it will cause conflicts with the old installed ones, I also want to <strong>keep old existing</strong> rpms because they may needed by other packages. For example, I offline install <code>bind-utils</code> use command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum --disablerepo=* install -y ./<span class="built_in">bind</span>-utils/*.rpm</span><br></pre></td></tr></table></figure></p>
<p>Error output:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">Error: Package: 1:openssl-1.0.2k-12.el7.x86_64 (@anaconda/7.5)</span><br><span class="line">           Requires: openssl-libs(x86-64) = 1:1.0.2k-12.el7</span><br><span class="line">           Removing: 1:openssl-libs-1.0.2k-12.el7.x86_64 (@anaconda/7.5)</span><br><span class="line">               openssl-libs(x86-64) = 1:1.0.2k-12.el7</span><br><span class="line">           Updated By: 1:openssl-libs-1.0.2k-16.el7.x86_64 (/openssl-libs-1.0.2k-16.el7.x86_64)</span><br><span class="line">               openssl-libs(x86-64) = 1:1.0.2k-16.el7</span><br><span class="line">...</span><br><span class="line">You could try using --skip-broken to work around the problem</span><br><span class="line">** Found 1 pre-existing rpmdb problem(s), <span class="string">'yum check'</span> output follows:</span><br><span class="line">mokutil-15-1.el7.x86_64 is a duplicate with mokutil-12-1.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<p>This error shows that <code>yum</code> try to update old rpm with new one but this breaks the dependency chain. Option <code>--skip-broken</code> won’t work here, it will skip the dependency-problem rpm which include exactly what I need:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># skipped</span><br><span class="line">bind-utils.x86_64 32:9.9.4-73.el7_6</span><br></pre></td></tr></table></figure></p>
<p>Then I try to use:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ivh ./<span class="built_in">bind</span>-utils/*.rpm</span><br></pre></td></tr></table></figure></p>
<p>still bad with conflicts:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">file /usr/lib64/openssl/engines/libcapi.so from install of openssl-libs-1:1.0.2k-16.el7.x86_64 conflicts with file from package openssl-libs-1:1.0.2k-12.el7.x86_64</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>After doing research I find some <code>rpm</code> options may help:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm &#123;-i|--install&#125; [install-options] PACKAGE_FILE ...</span><br><span class="line"></span><br><span class="line">       This installs a new package.</span><br><span class="line"></span><br><span class="line">       The general form of an rpm upgrade command is</span><br><span class="line"></span><br><span class="line">rpm &#123;-U|--upgrade&#125; [install-options] PACKAGE_FILE ...</span><br><span class="line"></span><br><span class="line">       This upgrades or installs the package currently installed to a newer version.  This is the same as  install,</span><br><span class="line">       except all other version(s) of the package are removed after the new package is installed.</span><br><span class="line"></span><br><span class="line">rpm &#123;-F|--freshen&#125; [install-options] PACKAGE_FILE ...</span><br><span class="line"></span><br><span class="line">       This will upgrade packages, but only ones for which an earlier version is installed.</span><br><span class="line">...</span><br><span class="line">--force</span><br><span class="line">              Same as using --replacepkgs, --replacefiles, and --oldpackage.</span><br><span class="line">--replacepkgs</span><br><span class="line">              Install the packages even if some of them are already installed on this system.</span><br><span class="line">--replacefiles</span><br><span class="line">              Install the packages even if they replace files from other, already installed, packages.</span><br><span class="line">--oldpackage</span><br><span class="line">              Allow an upgrade to replace a newer package with an older one.</span><br></pre></td></tr></table></figure></p>
<p>Let’s add <code>--force</code> flag and try again, this works and the old rpms are still there:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm --force -ivh ./<span class="built_in">bind</span>-utils/*.rpm</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qa | grep openssl-libs</span><br><span class="line">openssl-libs-1.0.2k-12.el7.x86_64</span><br><span class="line">openssl-libs-1.0.2k-16.el7.x86_64</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>Grant User sudo Privilege</title>
    <url>/2019/07/15/linux-sudo-privilege/</url>
    <content><![CDATA[<p>Let’s see how to grant a regular user <code>sudo</code> privilege, this is summaried from non-root upgrade.</p>
<p>Say, there is a regular user named <code>guest</code>, the simplest way is to edit sudoers file solely, run as root user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">visudo</span><br></pre></td></tr></table></figure></p>
<p>Append this line at end of file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">guest ALL=(ALL) NOPASSWD:ALL</span><br></pre></td></tr></table></figure></p>
<p>Then when <code>su - guest</code>, you can run <code>sudo</code> free.</p>
<p>Another way is add this user to <code>wheel</code> group then give this special group password-less <code>sudo</code> privilege, why does this? because sometimes I also need grant <code>su</code> password-less to the user, <code>wheel</code> group is easy for both to operate on. See my blog <a href="https://chengdol.github.io/2019/04/01/linux-pam/" target="_blank" rel="noopener"><code>&lt;&lt;Linux PAM Module Configuration&gt;&gt;</code></a></p>
<p>Run as root user, add <code>guest</code> to <code>wheel</code> group:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usermod -a -G wheel guest</span><br></pre></td></tr></table></figure></p>
<p>then edit sudoers file<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">visudo</span><br></pre></td></tr></table></figure></p>
<p>Comment and uncomment like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## Allows people in group wheel to run all commands</span><br><span class="line">#%wheel ALL=(ALL)       ALL</span><br><span class="line"></span><br><span class="line">## Same thing without a password</span><br><span class="line">%wheel  ALL=(ALL)       NOPASSWD: ALL</span><br></pre></td></tr></table></figure></p>
<p>That’s it.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Setup SSH Passwordless</title>
    <url>/2019/10/30/linux-ssh-passwordless-setup/</url>
    <content><![CDATA[<p>We need to setup ssh passwordless in softlayer cluster, otherwise our Datastage installer wouldn’t work. Now the master node in cluster uses <code>/ibm/unicorn_rsa</code> as the key to ssh, we can generate a new key and utilize it to communicate.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## "yes" will overwrite existing rsa key</span></span><br><span class="line"><span class="comment">## -t specifies the type of key to create</span></span><br><span class="line"><span class="comment">## -N provides the new passphrase</span></span><br><span class="line"><span class="comment">## -f specifies the filename of the key file</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"yes"</span> | ssh-keygen -t rsa -N <span class="string">""</span> -f ~/.ssh/id_rsa</span><br><span class="line"></span><br><span class="line"><span class="comment">## then append the id_rsa.pub content to authorized_keys in each node</span></span><br><span class="line"><span class="built_in">declare</span> -a nodes=($(cat /etc/hosts | grep -i ibmcloud | awk &#123;<span class="string">'print $2'</span>&#125;))</span><br><span class="line">key=$(cat ~/.ssh/id_rsa.pub)</span><br><span class="line"><span class="keyword">for</span> node <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;nodes[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"[INFO] copy ssh public to <span class="variable">$&#123;node&#125;</span>"</span></span><br><span class="line">  ssh -i /ibm/unicorn_rsa -o StrictHostKeyChecking=no <span class="variable">$&#123;node&#125;</span> <span class="string">"echo <span class="variable">$&#123;key&#125;</span> &gt;&gt; ~/.ssh/authorized_keys"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>More information about ssh and scp can refer this <a href="https://chengdol.github.io/2019/02/21/linux-ssh-scp-summary/" target="_blank" rel="noopener">post</a>.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title>SSH and SCP Daily Work Summary</title>
    <url>/2019/02/21/linux-ssh-scp-summary/</url>
    <content><![CDATA[<p>This article used to walk you through some commonly <code>ssh</code> and <code>scp</code> usages, based on a real life scenario.</p>
<p>################################################################<br># &emsp; Insert latest update at the top of the logs<br>#<br># &emsp; Date &emsp; &emsp; &emsp; &emsp; &emsp; Description<br># &emsp; 03/12/2019 &emsp; &emsp; recover public key<br># &emsp; 03/11/2019 &emsp; &emsp; ssh -i option<br># &emsp; 02/21/2019 &emsp; &emsp; scp folder or files<br># &emsp; 01/23/2019 &emsp; &emsp; sshpass<br># &emsp; 01/22/2019 &emsp; &emsp; no prompt first time<br># &emsp; 01/08/2019 &emsp; &emsp; ECDSA host key changed<br># &emsp; 01/06/2019 &emsp; &emsp; ssh-kenscan<br># &emsp; 12/19/2018 &emsp; &emsp; ssh-copy-id<br># &emsp; 11/14/2018 &emsp; &emsp; ssh run shell script<br># &emsp; 10/01/2018 &emsp; &emsp; ssh send command<br>################################################################</p>
<h3 id="10-01-2018"><a href="#10-01-2018" class="headerlink" title="10/01/2018"></a>10/01/2018</h3><p>use <code>ssh</code> send commands to execute on remote machine:<br><img src="https://drive.google.com/uc?id=1OgNJ5NJpx6Kkr46oCxScylGhu1ShYaCV" alt=""><br><code>-t</code> flag allow you to interact with remote machine:<br><img src="https://drive.google.com/uc?id=1rgH7Eu7Qzw2icZQzroTT1_J7LH0G3EBP" alt=""></p>
<h3 id="11-14-2018"><a href="#11-14-2018" class="headerlink" title="11/14/2018"></a>11/14/2018</h3><p>use ssh run shell script in remote machine<br><img src="https://drive.google.com/uc?id=1FvvQTq-ujz1ETmharmWt9JsMBC1ipuUJ" alt=""></p>
<h3 id="12-19-2018"><a href="#12-19-2018" class="headerlink" title="12/19/2018"></a>12/19/2018</h3><p>use <code>ssh-copy-id</code> to copy local machine public key to remote machine’s <code>~/.ssh/authorized_keys</code> file, so next time when you <code>ssh</code> again, no prompt to require password:</p>
<p><img src="https://drive.google.com/uc?id=1HdAmGdDB1HxPtwFSzrTQcS-g7hw5r3o4" alt=""></p>
<p>Sometimes I see people use <code>~/.ssh/id_rsa</code> with <code>ssh-copy-id</code>, that confused me because that is private key, OK, <code>man</code> tell me why:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-i identity_file</span><br><span class="line">        ...If the filename does not end in .pub this is added.  If the filename is omitted, the default_ID_file is used.</span><br></pre></td></tr></table></figure></p>
<h3 id="01-06-2019"><a href="#01-06-2019" class="headerlink" title="01/06/2019"></a>01/06/2019</h3><p>use <code>ssh-keyscan</code> to get remote machine ecdsa identity, you can put this item into local known_hosts file, so when first time <code>ssh</code> login, there is no prompt to input <code>yes</code>:<br><img src="https://drive.google.com/uc?id=1C_IHZxToXYRN4iLabvmcW21x_5wbGcQp" alt=""><br>actually better to use <code>-o StrictHostKeyChecking=no</code> flag.</p>
<h3 id="01-08-2019"><a href="#01-08-2019" class="headerlink" title="01/08/2019"></a>01/08/2019</h3><p>I create a new cluster with the same master hostname as the deleted one, so when I try to ssh to it, interesting thing happens:<br><img src="https://drive.google.com/uc?id=1Fkc0M9_e0hufGmI2Es_qvFOBRaHLwPKd" alt=""><br>go to <code>~/.ssh/known_hosts</code> file and delete the corresponding <code>ECDSA</code> line<br><img src="https://drive.google.com/uc?id=159d02J98eKyz2jJMUpTgJ6kCuZtqVe10" alt=""></p>
<h3 id="01-22-2019"><a href="#01-22-2019" class="headerlink" title="01/22/2019"></a>01/22/2019</h3><p>when you first time ssh or scp to remote machine, it will prompt to add remote machine to <code>~/.ssh/known_hosts</code> file, this may interrupt <code>ansible</code> or shell script running, so I want to skip it. For example:<br><img src="https://drive.google.com/uc?id=1WfbdXCFeyg5k7tr9wS5JjMRIifJcdPaq" alt=""><br>use <code>-o StrictHostKeyChecking=no</code> option, it will silently add remote host name to <code>~/.ssh/known_host</code> file.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-copy-id -i .ssh/id_dsa.pub -o StrictHostKeyChecking=no root@example.com</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -o StrictHostKeyChecking=no -r ./<span class="built_in">source</span> root@example.com:~</span><br></pre></td></tr></table></figure>
<p>if you don’t want to add the host name, <code>-o UserKnownHostsFile=/dev/null</code> option can save you.</p>
<h3 id="01-23-2019"><a href="#01-23-2019" class="headerlink" title="01/23/2019"></a>01/23/2019</h3><p>scp or ssh without prompt input password<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y sshpass</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sshpass -p &lt;password&gt; scp/ssh ...</span><br></pre></td></tr></table></figure>
<p>It’s useful to set password-less at first time, combine all of these, no prompt will show up:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sshpass -p &lt;password&gt; ssh-copy-id -i ~/.ssh/id_rsa.pub -o StrictHostKeyChecking=no ...</span><br></pre></td></tr></table></figure></p>
<h3 id="02-21-2019"><a href="#02-21-2019" class="headerlink" title="02/21/2019"></a>02/21/2019</h3><p>scp <code>source</code> directory and it’s content recursively to <code>root</code> directory in <code>example.com</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -o StrictHostKeyChecking=no -r ~/<span class="built_in">source</span> root@example.com:~</span><br></pre></td></tr></table></figure></p>
<p>scp all files in <code>source</code> directory to <code>target</code> directory in <code>example.com</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -o StrictHostKeyChecking=no ./<span class="built_in">source</span>/* root@example.com:~/target</span><br></pre></td></tr></table></figure></p>
<h3 id="03-11-2019"><a href="#03-11-2019" class="headerlink" title="03/11/2019"></a>03/11/2019</h3><p>The <code>ssh</code> command has <code>-i</code> option, you associate private key with this flags:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -i ~/.ssh/id_rsa xxx</span><br></pre></td></tr></table></figure></p>
<p>Note that SSH never send private key over the network, <code>-i</code> merely used to answer challenge that is generated using the corresponding public key from target machine, you don’t need to explicitly use <code>-i</code> if you use default private key in right location.</p>
<h3 id="03-12-2019"><a href="#03-12-2019" class="headerlink" title="03/12/2019"></a>03/12/2019</h3><p>If public key is lost, you can use existing private key to generate one:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh-keygen -y -f ~/.ssh/id_rsa &gt; ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
        <tag>scp</tag>
      </tags>
  </entry>
  <entry>
    <title>Symbolic Link Operations</title>
    <url>/2019/04/13/linux-soft-link/</url>
    <content><![CDATA[<blockquote>
<p>Must use <code>absolute path</code> to do softlink!</p>
</blockquote>
<p>A symbolic link, also known as a <strong>symlink</strong> or a <strong>soft link</strong>, is a special kind of file (entry) that points to the actual file or directory on a disk (like a shortcut in Windows).</p>
<p>Symbolic links are used all the time to link libraries and often used to link files and folders on mounted NFS (Network File System) shares.</p>
<p>Generally, the <code>ln</code> syntax is similar to the <code>cp</code> or <code>mv</code> syntax, e.g. <source> <destination>.</destination></p>
<p>But if the path to the <link name=""> is an directory, link will be created inside that directory.</p>
<h3 id="Create-Soft-Link"><a href="#Create-Soft-Link" class="headerlink" title="Create Soft Link"></a>Create Soft Link</h3><p>For example, create a symbolic link to a file and directory<br><code>-f</code>: remove existing destination file, otherwise if the link is exist, get error like this:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## you need to remove the link first</span></span><br><span class="line"><span class="comment">## but with -f, no need</span></span><br><span class="line">ln: failed to create symbolic link ‘xxxx’: File exists</span><br></pre></td></tr></table></figure></p>
<p><code>-n</code>: treat LINK_NAME as a normal file if it is a symbolic link to a directory</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## link a file</span></span><br><span class="line">ln -nfs &lt;path to file&gt; &lt;path to link&gt;</span><br><span class="line"><span class="comment">## link a directory</span></span><br><span class="line">ln -nfs &lt;path to dir&gt; &lt;path to link&gt;</span><br></pre></td></tr></table></figure>
<h3 id="Delete-Soft-Link"><a href="#Delete-Soft-Link" class="headerlink" title="Delete Soft Link"></a>Delete Soft Link</h3><p>There are 2 ways to undo or delete the soft link:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">unlink &lt;link name&gt;</span><br><span class="line">rm [-rf] &lt;link name&gt;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that, the <code>rm</code> command just removes the link. It will not delete the target directory.</p>
</blockquote>
<h3 id="Broken-Soft-Link"><a href="#Broken-Soft-Link" class="headerlink" title="Broken Soft Link"></a>Broken Soft Link</h3><p>Find broken symbolic link:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -xtype l</span><br></pre></td></tr></table></figure></p>
<p>If you want to delete in one go:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -xtype l -delete</span><br></pre></td></tr></table></figure></p>
<p>A bit of explanation:<br><code>-xtype l</code> tests for links that are broken (it is the opposite of <code>-type</code>)<br><code>-delete</code> deletes the files directly, no need for further bothering with <code>xargs</code> or <code>-exec</code></p>
<h3 id="Resources"><a href="#Resources" class="headerlink" title="Resources:"></a>Resources:</h3><p><a href="https://www.shellhacks.com/symlink-create-symbolic-link-linux/" target="_blank" rel="noopener">SymLink – HowTo: Create a Symbolic Link – Linux</a><br><a href="https://unix.stackexchange.com/questions/34248/how-can-i-find-broken-symlinks" target="_blank" rel="noopener">How can I find broken symlinks</a><br><a href="https://unix.stackexchange.com/questions/314974/how-to-delete-broken-symlinks-in-one-go" target="_blank" rel="noopener">How to delete broken symlinks in one go?</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>soft link</tag>
      </tags>
  </entry>
  <entry>
    <title>Tar Command Daily Work Summary</title>
    <url>/2019/02/21/linux-tar-summary/</url>
    <content><![CDATA[<p>This article used to walk you through some commonly <code>tar</code> usages , based on a real life scenario.</p>
<p>################################################################<br>#  &emsp; Date &emsp; &emsp; &emsp; &emsp; &emsp; Description<br>#  &emsp; 05/29/2019 &emsp; &emsp; extract single file to another directory<br>#  &emsp; 05/28/2019 &emsp; &emsp; extract file to another directory<br>#  &emsp; 05/23/2019 &emsp; &emsp; extract single file from archive<br>#  &emsp; 04/21/2019 &emsp; &emsp; untar keep owner and permission<br>#  &emsp; 02/28/2019 &emsp; &emsp; dash or not<br>#  &emsp; 02/27/2019 &emsp; &emsp; untar to specified folder<br>#  &emsp; 02/22/2019 &emsp; &emsp; list tar content<br>#  &emsp; 02/21/2019 &emsp; &emsp; tar exclude<br>#  &emsp; 02/20/2019 &emsp; &emsp; untar multiple files<br>#  &emsp; 02/19/2019 &emsp; &emsp; tar multiple files<br>#<br>################################################################</p>
<h3 id="02-19-2019"><a href="#02-19-2019" class="headerlink" title="02/19/2019"></a>02/19/2019</h3><p>Basic operation: tar multiple files into <code>example.tar.gz</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## use -C to go to target directory</span></span><br><span class="line">tar czf example.tar.gz -C &lt;target directory&gt; file1 file2 file3</span><br><span class="line"></span><br><span class="line"><span class="comment">## tar a directory and its content in target directory</span></span><br><span class="line">tar czf example.tar.gz -C &lt;target directory&gt; &lt;folder name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## tar everything in target, note the dot at end!</span></span><br><span class="line">tar czf example.tar.gz -C &lt;target directory&gt; .</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>The file path matters! see my <a href="https://chengdol.github.io/2019/07/03/linux-tar-path/" target="_blank" rel="noopener">blog</a>.</p>
</blockquote>
<h3 id="02-20-2019"><a href="#02-20-2019" class="headerlink" title="02/20/2019"></a>02/20/2019</h3><p>When untar multiple files, you cannot do this, it will fail<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar zxf file1.tar.gz file2.tar.gz file3.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>The reason please see this <a href="https://stackoverflow.com/questions/583889/how-can-you-untar-more-than-one-file-at-a-time" target="_blank" rel="noopener">link</a>, the solution is to use <code>xargs</code> instead:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls *.tar.gz | xargs -i tar xzf &#123;&#125;</span><br></pre></td></tr></table></figure></p>
<p>Or you can use <code>find</code> with <code>-exec</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find . -maxdepth 1 -name <span class="string">"*.tar.gz"</span> -<span class="built_in">exec</span> tar zxf <span class="string">'&#123;&#125;'</span> \;</span><br></pre></td></tr></table></figure></p>
<h3 id="02-21-2019"><a href="#02-21-2019" class="headerlink" title="02/21/2019"></a>02/21/2019</h3><p>For example, if you want to tar things inside a folder but exclude some files<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar czf target.tar.gz -C &lt;target directory&gt; --exclude=<span class="string">'createInstallerTar.sh'</span> --exclude=<span class="string">"target.tar.gz"</span> --exclude=<span class="string">'pushBIPayload.sh'</span></span><br></pre></td></tr></table></figure></p>
<p>If you don’t exclude target.tar.gz, it will tar itself again.</p>
<h3 id="02-22-2019"><a href="#02-22-2019" class="headerlink" title="02/22/2019"></a>02/22/2019</h3><p>List tar.gz file content, flag <code>z</code>  is used to distinguish tar and tar.gz<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar ztvf target.tar.gz</span><br></pre></td></tr></table></figure></p>
<h3 id="02-27-2019"><a href="#02-27-2019" class="headerlink" title="02/27/2019"></a>02/27/2019</h3><p>If you don’t specify target folder, untar will put things in current directory, use <code>-C</code> option to specify it. For example, I want to untar source.tar.gz file to <code>/etc/yum.repos.d/</code> folder:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar zxf /tmp/source.tar.gz -C /etc/yum.repos.d/</span><br></pre></td></tr></table></figure></p>
<p>For <code>-C</code> option, in <code>c</code> and <code>r</code> mode, this changes the directory before adding the following files.  In <code>x</code> mode, change directories after opening the archive but before extracting entries from the archive.</p>
<h3 id="02-28-2019"><a href="#02-28-2019" class="headerlink" title="02/28/2019"></a>02/28/2019</h3><p>Sometimes I see people use <code>-czf</code> but sometimes <code>czf</code>, dash or not to pass flags?</p>
<p>Historical and compatible reason, <strong>no</strong> dash version is probably more portable.</p>
<p><code>tar</code> is one of those ancient commands from the days when option syntax hadn’t been standardized. Because all useful invocations of <code>tar</code> require specifying an operation before providing any file name, most <code>tar</code> implementations interpret their first argument as an option even if it doesn’t begin with a <code>-</code>. Most current implementations accept a <code>-</code>.</p>
<h3 id="04-21-2019"><a href="#04-21-2019" class="headerlink" title="04/21/2019"></a>04/21/2019</h3><p>When unpacking, consider using <code>p</code> option to perserve file permissions. Use this in extract mode to override your <code>umask</code> and get the exact permissions specified in the archive.. The <code>p</code> option is the default when working as the <strong>superuser</strong>, it will get what it has. If you are a <strong>regular user</strong>, add <code>p</code> to keep permissions.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxpf target.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>It seems umask ignores execute bit? When I untar the file with <code>rwxrwxrwx</code> permission inside by regular user with umask <code>0002</code>, the final permission is <code>rwxrwxr-x</code>.</p>
<p>if you want to keep owner as well:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar --same-owner -zxpf target.tar.gz</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that there is a <code>-</code> before <code>zxpf</code>.</p>
</blockquote>
<h3 id="05-23-2019"><a href="#05-23-2019" class="headerlink" title="05/23/2019"></a>05/23/2019</h3><p>Extract single file from tarball to current directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar xzf target.tar.gz installer/xxx.json</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that no leading <code>/</code> in the path (it uses relative path in tar file!), you can use <code>tar xtvf target.tar.gz</code> to check the path.</p>
</blockquote>
<p>Then you will see <code>&lt;current directory&gt;/installer/xxx.json</code> in current directory.</p>
<h3 id="05-28-2019"><a href="#05-28-2019" class="headerlink" title="05/28/2019"></a>05/28/2019</h3><p><code>tar</code> by default extracts file to current directory, if you want to place the untar files to another directory, run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar zxf target.tar.gz -C /target/directory</span><br></pre></td></tr></table></figure></p>
<p>Note that the target directory has to <strong>exist</strong> before running that command.</p>
<h3 id="05-29-2019"><a href="#05-29-2019" class="headerlink" title="05/29/2019"></a>05/29/2019</h3><p>If you want to extact single file to another directory, note the options order<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar xzf target.tar.gz -C /target/directory installer/xxx.json</span><br></pre></td></tr></table></figure></p>
<p>The single file must be in the command end.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tar</tag>
      </tags>
  </entry>
  <entry>
    <title>Tar Path Format Issue</title>
    <url>/2019/07/03/linux-tar-path/</url>
    <content><![CDATA[<p>I haven’t noticed the path format when I create tarball, this time the format issue plays as a major blocker in my project.</p>
<p>We use a module tar file to deploy <code>Zen</code> in ICP4D cluster, when I use my customized tar file, I get:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Loading images</span><br><span class="line">/ibm/InstallPackage/modules/./ibm-iisee-zen:1.0.0//images</span><br><span class="line">Loaded Images [==============================================================================] 7m29s (35/35) done</span><br><span class="line">Pushed Images [==============================================================================] 15m17s (35/35) done</span><br><span class="line">Deploying the chart as name ibm-iisee-zen100</span><br><span class="line">Running command: /ibm/InstallPackage/components/dpctl --config /ibm/InstallPackage/components/install.yaml helm rewriteChart -i /ibm/InstallPackage/modules/./ibm-iisee-zen:1.0.0//charts/*.tgz -o /ibm/InstallPackage/modules/./ibm-iisee-zen:1.0.0//charts/updated_ibm-iisee-zen100.tgz</span><br><span class="line">Running command: /ibm/InstallPackage/components/dpctl --config /ibm/InstallPackage/components/install.yaml helm installChart -f /ibm/InstallPackage/components/global.yaml   -r zen-ibm-iisee-zen100 -n zen -c /ibm/InstallPackage/modules/./ibm-iisee-zen:1.0.0//charts/updated_ibm-iisee-zen100.tgz</span><br><span class="line">Starting the installation ...</span><br><span class="line">There was a problem installing /ibm/InstallPackage/modules/ibm-iisee-zen:1.0.0/charts/updated_ibm-iisee-zen100.tgz chart. Reason: chart metadata (Chart.yaml) missing</span><br></pre></td></tr></table></figure></p>
<p>Let’s highlight the command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Running command: /ibm/InstallPackage/components/dpctl --config /ibm/InstallPackage/components/install.yaml helm rewriteChart -i /ibm/InstallPackage/modules/./ibm-iisee-zen:1.0.0//charts/*.tgz -o /ibm/InstallPackage/modules/./ibm-iisee-zen:1.0.0//charts/updated_ibm-iisee-zen100.tgz</span><br></pre></td></tr></table></figure></p>
<p>Look carefully there is a <code>./</code> in path <code>/ibm/InstallPackage/modules/./ibm-iisee-zen:1.0.0/....</code>, this is because I create tarball use:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar cf ibm-iisee-zen-1.0.0.tar ./ibm-iisee-zen:1.0.0</span><br></pre></td></tr></table></figure></p>
<p>the <code>./</code> will be put in the extract path! which is the trouble maker.</p>
<p>Instead I should first go to that directory, then tar or use <code>-C</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar cf ibm-iisee-zen-1.0.0.tar -C &lt;target directory&gt; ibm-iisee-zen:1.0.0</span><br></pre></td></tr></table></figure></p>
<p>If we list the tarball contents, no prefix in the file structure:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -tvf ibm-iisee-zen-1.0.0.tar</span><br><span class="line"></span><br><span class="line">drwxr-xr-x 1001/docker       0 1969-12-31 16:00 ibm-iisee-zen:1.0.0/</span><br><span class="line">drwxr-xr-x 1001/docker       0 2019-07-02 15:13 ibm-iisee-zen:1.0.0/charts/</span><br><span class="line">-rw-r--r-- root/root    245868 2019-07-02 15:12 ibm-iisee-zen:1.0.0/charts/ibm-iisee-zen-1.0.1.tgz</span><br><span class="line">-rw------- 1001/docker    4758 1969-12-31 16:00 ibm-iisee-zen:1.0.0/manifest.yaml</span><br><span class="line">drwxr-xr-x 1001/docker       0 1969-12-31 16:00 ibm-iisee-zen:1.0.0/LICENSES/</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>For more information about tar commands, I have a blob about it already <a href="https://chengdol.github.io/2019/02/21/linux-tar-summary/" target="_blank" rel="noopener"><code>&lt;&lt;Tar Command Daily Work Summary&gt;&gt;</code></a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tar</tag>
      </tags>
  </entry>
  <entry>
    <title>VNC Set up</title>
    <url>/2019/05/29/linux-vnc/</url>
    <content><![CDATA[<p><code>Virtual Network Computing (VNC)</code> is a graphical desktop-sharing system that uses the Remote Frame Buffer protocol (RFB) to remotely control another computer. It transmits the keyboard and mouse events from one computer to another, relaying the graphical-screen updates back in the other direction, over a network.</p>
<p>Popular uses for this technology include remote technical support and accessing files on one’s work computer from one’s home computer, or vice versa.</p>
<p>I usually use it to do remote development in Fyre, I have a central control machine with VNC set, after vnc to that machine then use it to SSH to others within the same internal network, you can also install IDE in VNC to do general programming work rather than developing locally.</p>
<blockquote>
<p>Note, there are other remote terminal tools like <code>Termius</code>. </p>
</blockquote>
<h2 id="Install-VNC-Server"><a href="#Install-VNC-Server" class="headerlink" title="Install VNC Server"></a>Install VNC Server</h2><p>Not sure if the configurations are the same, actually the settings are varies.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum update -y</span><br><span class="line"></span><br><span class="line">## seems no need this:</span><br><span class="line">yum install open-vm-tools</span><br><span class="line"></span><br><span class="line">## if you don’t have desktop installed, note linux has many different desktop system themes, only install core packages of KDE or GNOME, KDE is better</span><br><span class="line">yum groupinstall &apos;X Window System&apos; &apos;KDE&apos;</span><br><span class="line">yum groupinstall &apos;X Window System&apos; &apos;GNOME&apos;</span><br><span class="line"></span><br><span class="line">yum list |grep tiger</span><br><span class="line">yum -y install tigervnc-server </span><br><span class="line"></span><br><span class="line">## Fyre firewalld default is inactive, no need to deal with firewall here</span><br><span class="line">## if it’s enable, may need to config</span><br><span class="line">systemctl status firewalld</span><br><span class="line">firewall-cmd --permanent --zone=public --add-service vnc-server </span><br><span class="line">firewall-cmd --reload</span><br><span class="line"></span><br><span class="line">## start vnc</span><br><span class="line">## select yes then create password: 123456</span><br><span class="line">## first time it will open port 1</span><br><span class="line">## then you will get the address and port to login:</span><br><span class="line">## centctl1.fyre.ibm.com:1</span><br><span class="line">vncserver</span><br></pre></td></tr></table></figure></p>
<p>Note if you will get new vnc session everytime you run <code>vncserver</code>, check with<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep vnc</span><br><span class="line"></span><br><span class="line">root      2682  0.0  3.0 284860 116840 ?       Sl   May27   1:38 /usr/bin/Xvnc :1 -auth /root/.Xauthority -desktop mycentctl1.fyre.ibm.com:1 (root) -fp catalogue:/etc/X11/fontpath.d -geometry 1024x768 -pn -rfbauth /root/.vnc/passwd -rfbport 5901 -rfbwait 30000</span><br><span class="line">root      9199  1.4  1.6 231660 62388 pts/3    Sl   08:59   0:00 /usr/bin/Xvnc :2 -auth /root/.Xauthority -desktop mycentctl1.fyre.ibm.com:2 (root) -fp catalogue:/etc/X11/fontpath.d -geometry 1024x768 -pn -rfbauth /root/.vnc/passwd -rfbport 5902 -rfbwait 30000</span><br></pre></td></tr></table></figure></p>
<p>you can kill it by running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vncserver -kill :2</span><br></pre></td></tr></table></figure></p>
<p>If the VNC is broken due to maintenance, open a new session again by <code>vncserver</code>.</p>
<h2 id="Install-VNC-viewer"><a href="#Install-VNC-viewer" class="headerlink" title="Install VNC viewer"></a>Install VNC viewer</h2><p>Install VNC viewer on your local laptop, then connect by<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">centctl1.fyre.ibm.com:1</span><br></pre></td></tr></table></figure></p>
<h2 id="Copy-and-Paste"><a href="#Copy-and-Paste" class="headerlink" title="Copy and Paste"></a>Copy and Paste</h2><p>If you want to copy from local to viewer, sometimes it’s malfunction, kill the <code>klipper</code> process:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | grep klipper</span><br><span class="line">kill -9 &lt;PID of klipper&gt;</span><br></pre></td></tr></table></figure></p>
<p>You can adjust shortcuts in VNC viewer for copy and paste:<br>Settings -&gt; Configure Shortcuts -&gt; copy / paste</p>
<h2 id="Other-Settings"><a href="#Other-Settings" class="headerlink" title="Other Settings"></a>Other Settings</h2><p>Other settings useful:<br>Settings -&gt; Edit Current Profile -&gt; Mouse -&gt; copy on select / Trim trailing space</p>
<p>Adjust font size the themes:<br>Settings -&gt; Manage Profiles -&gt; Edit Profile -&gt; Appearabce -&gt; Black on Random Light<br>-&gt; check Vary the background color for each tab</p>
<p>Also change the text size under Appearance.</p>
<h2 id="Screen-resolution"><a href="#Screen-resolution" class="headerlink" title="Screen resolution"></a>Screen resolution</h2><p>If the screen open by VNC viewer is small, you can change the resolution, run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xrandr -s 1920x1080</span><br></pre></td></tr></table></figure></p>
<p>on the terminal in your remote machine.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>vnc</tag>
      </tags>
  </entry>
  <entry>
    <title>Set up and Use Local Yum Repository</title>
    <url>/2019/03/05/linux-yum-local-repo/</url>
    <content><![CDATA[<p>Just like the blogs I wrote before: <code>Offline Package Installation I</code> and <code>Solve Conflicts in RPM installation</code>, Use <code>rpm</code> or bare <code>yum</code> command to install downloaded rpm file works but I find somehow this will cause some maintenance problems, for example<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Warning: RPMDB altered outside of yum.</span><br><span class="line">** Found 51 pre-existing rpmdb problem(s), &apos;yum check&apos; output follows:</span><br><span class="line">bash-4.2.46-31.el7.x86_64 is a duplicate with bash-4.2.46-30.el7.x86_64</span><br><span class="line">binutils-2.27-34.base.el7.x86_64 is a duplicate with binutils-2.27-28.base.el7_5.1.x86_64</span><br><span class="line">coreutils-8.22-23.el7.x86_64 is a duplicate with coreutils-8.22-21.el7.x86_64</span><br><span class="line">cryptsetup-libs-2.0.3-3.el7.x86_64 is a duplicate with cryptsetup-libs-1.7.4-4.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<p>I need to find a way that can automatically figure out the dependency chain, install the rpm required from download pool.</p>
<h3 id="Create-a-yum-repository"><a href="#Create-a-yum-repository" class="headerlink" title="Create a yum repository"></a>Create a yum repository</h3><p>Install <code>createrepo</code> package:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y createrepo</span><br></pre></td></tr></table></figure></p>
<p>Next, creates the necessary metadata for your Yum repository, as well as the sqlite database for speeding up yum operations. For example, <code>/root/docker</code> directory contains all rpms that install docker needs:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">createrepo --database /root/docker</span><br></pre></td></tr></table></figure></p>
<p>you will find it generates a folder called <code>repodata</code> that contains:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">304457af78cd250275222993fa0da09256f64cc627c1e31fb3ec0848b28b28d8-primary.xml.gz</span><br><span class="line">3d5ab2f5b706e5750e0ebe5802a278525da9cac4b9700634c51c2bfdf04a0d0e-primary.sqlite.bz2</span><br><span class="line">421810a6b2d93e49bfe417404f937e17929f0d8c55953dbe8e96cbb19f40708d-filelists.sqlite.bz2</span><br><span class="line">62c33f23a9485d74076d3db77064a9bdf606ce68d6702cd84fc5c6f1bcb48f01-other.sqlite.bz2</span><br><span class="line">649e08cdba02219eb660f579b89e7a86cf805e4f989222cb1be556a8e0b82b5c-other.xml.gz</span><br><span class="line">6cd1c3a2d6f385b1cbb878a88f86b8ef7e32d6e5c2c32c41a81f51464c3785c7-filelists.xml.gz</span><br><span class="line">repomd.xml</span><br></pre></td></tr></table></figure></p>
<h3 id="Create-yum-repo-file"><a href="#Create-yum-repo-file" class="headerlink" title="Create yum repo file"></a>Create yum repo file</h3><p>To define a new repository, you can either add a <code>[repository]</code> section to the <code>/etc/yum.conf</code> file, or to a <code>.repo</code> file in the <code>/etc/yum.repos.d/</code> directory. All files with the <code>.repo</code> file extension in this directory are read by yum, and it is recommended to define your repositories here instead of in <code>/etc/yum.conf</code>.</p>
<p>For example, create a <code>docker-local.repo</code> file in <code>/etc/yum.repos.d/</code> directory, <code>baseurl</code> points to the folder that holds downloaded rpms:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[docker-local.repo]</span><br><span class="line">name=docker-local</span><br><span class="line">baseurl=file:///root/docker</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br></pre></td></tr></table></figure></p>
<p>Then if you run <code>yum repolist all</code>, you will see this new added yum repository:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum repolist all</span><br><span class="line"></span><br><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">repo id                 repo name                          status</span><br><span class="line">...</span><br><span class="line">docker-local.repo       docker-local                       enabled:    134</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>You can also list enabled and disabled repository:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum repolist enabled</span><br><span class="line">yum repolist disabled</span><br></pre></td></tr></table></figure></p>
<h3 id="Install-using-yum"><a href="#Install-using-yum" class="headerlink" title="Install using yum"></a>Install using yum</h3><p>Now you can install docker by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y docker-ce</span><br></pre></td></tr></table></figure></p>
<p>yum will check local repository and launch dependencies for you.</p>
<p>Sometimes it’s better to set <code>enabled=0</code> in <code>.repo</code> file to disable it by default, so you can run:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum --enablerepo=docker-local.repo install -y docker-ce</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title>Yum and Rpm Daily Work Summary</title>
    <url>/2019/03/02/linux-yum-rpm-summary/</url>
    <content><![CDATA[<p>This article used to walk you through some commonly <code>yum</code> and <code>rpm</code> usages , based on a real life scenario.</p>
<p>################################################################<br>#  &emsp; Date &emsp; &emsp; &emsp; &emsp; &emsp; Description<br>#  &emsp; 03/05/2019 &emsp; &emsp; yum autoremove<br>#  &emsp; 03/02/2019 &emsp; &emsp; upgrade rpm<br>#  &emsp; 03/01/2019 &emsp; &emsp; list rpm dependencies<br>#  &emsp; 02/27/2019 &emsp; &emsp; yum provides<br>#  &emsp; 02/25/2019 &emsp; &emsp; search rpm installed<br>#  &emsp; 02/24/2019 &emsp; &emsp; install rpm<br>#  &emsp; 01/19/2019 &emsp; &emsp; remove package<br>#<br>################################################################</p>
<p>Yum command <a href="https://access.redhat.com/sites/default/files/attachments/rh_yum_cheatsheet_1214_jcs_print-1.pdf" target="_blank" rel="noopener">cheat sheet</a><br><code>rpm</code> command is one of the package management command.</p>
<h3 id="01-19-2019"><a href="#01-19-2019" class="headerlink" title="01/19/2019"></a>01/19/2019</h3><p>Remove or erase a installed package with its dependencies:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ev &lt;package name&gt;</span><br><span class="line">yum erase &lt;package name&gt;</span><br></pre></td></tr></table></figure></p>
<p>if the rpm is part of other dependencies, <code>rpm -ev</code> will fail, or you can use <code>yum erase</code> to delete them all:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ev containerd.io</span><br><span class="line"></span><br><span class="line">error: Failed dependencies:</span><br><span class="line">        containerd.io &gt;= 1.2.2-3 is needed by (installed) docker-ce-3:18.09.2-3.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<p>Remove or erase a installed package <strong>without</strong> checking for dependencies<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ev --nodeps &lt;package name&gt;</span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ev --nodpes containerd.io</span><br><span class="line"></span><br><span class="line">Preparing packages...</span><br><span class="line">containerd.io-1.2.2-3.3.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<h3 id="02-24-2019"><a href="#02-24-2019" class="headerlink" title="02/24/2019"></a>02/24/2019</h3><p>This command will install a single rpm file if it meets all dependencies, otherwise install will fail and the output will show you the missig rpms.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ivh &lt;rpm name&gt;</span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ivh 416b2856f8dbb6f07a50a46018fee8596479ebc0eaeec069c26bedfa29033315-kubeadm-1.13.2-0.x86_64.rpm</span><br><span class="line"></span><br><span class="line">warning: 416b2856f8dbb6f07a50a46018fee8596479ebc0eaeec069c26bedfa29033315-kubeadm-1.13.2-0.x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID 3e1ba8d5: NOKEY</span><br><span class="line">error: Failed dependencies:</span><br><span class="line">        cri-tools &gt;= 1.11.0 is needed by kubeadm-1.13.2-0.x86_64</span><br><span class="line">        kubectl &gt;= 1.6.0 is needed by kubeadm-1.13.2-0.x86_64</span><br><span class="line">        kubelet &gt;= 1.6.0 is needed by kubeadm-1.13.2-0.x86_64</span><br><span class="line">        kubernetes-cni &gt;= 0.6.0 is needed by kubeadm-1.13.2-0.x86_64</span><br></pre></td></tr></table></figure></p>
<h3 id="02-25-2019"><a href="#02-25-2019" class="headerlink" title="02/25/2019"></a>02/25/2019</h3><p>These two both work:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## query package installed</span></span><br><span class="line">rpm -qa | grep &lt;package name&gt;</span><br><span class="line">yum list installed | grep &lt;package name&gt;</span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qa | grep docker</span><br><span class="line">docker-ce-18.06.1.ce-3.el7.x86_64</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum list installed | grep docker</span><br><span class="line">docker-ce.x86_64                18.06.1.ce-3.el7           installed</span><br></pre></td></tr></table></figure>
<h3 id="02-27-2019"><a href="#02-27-2019" class="headerlink" title="02/27/2019"></a>02/27/2019</h3><p>Find packages that provide the queried file, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum provides host</span><br><span class="line"></span><br><span class="line">32:<span class="built_in">bind</span>-utils-9.9.4-14.el7.x86_64 : Utilities <span class="keyword">for</span> querying DNS name servers</span><br><span class="line">Repo        : Local-Base</span><br><span class="line">Matched from:</span><br><span class="line">Filename    : /usr/bin/host</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>Next you can install it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y bind-utils</span><br></pre></td></tr></table></figure></p>
<h3 id="03-01-2019"><a href="#03-01-2019" class="headerlink" title="03/01/2019"></a>03/01/2019</h3><p>If you have a local rpm file, you can list its dependencies by running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qpR &lt;rpm name&gt;</span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qpR 416b2856f8dbb6f07a50a46018fee8596479ebc0eaeec069c26bedfa29033315-kubeadm-1.13.2-0.x86_64.rpm</span><br><span class="line"></span><br><span class="line">warning: 416b2856f8dbb6f07a50a46018fee8596479ebc0eaeec069c26bedfa29033315-kubeadm-1.13.2-0.x86_64.rpm: Header V4 RSA/SHA512 Signature, key ID 3e1ba8d5: NOKEY</span><br><span class="line">cri-tools &gt;= 1.11.0</span><br><span class="line">kubectl &gt;= 1.6.0</span><br><span class="line">kubelet &gt;= 1.6.0</span><br><span class="line">kubernetes-cni &gt;= 0.6.0</span><br><span class="line">rpmlib(CompressedFileNames) &lt;= 3.0.4-1</span><br><span class="line">rpmlib(FileDigests) &lt;= 4.6.0-1</span><br><span class="line">rpmlib(PayloadFilesHavePrefix) &lt;= 4.0-1</span><br><span class="line">rpmlib(PayloadIsXz) &lt;= 5.2-1</span><br></pre></td></tr></table></figure></p>
<h3 id="03-02-2019"><a href="#03-02-2019" class="headerlink" title="03/02/2019"></a>03/02/2019</h3><p>If you run <code>man rpm</code>, there are two similar statements:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The general form of an rpm upgrade command is</span><br><span class="line"></span><br><span class="line">rpm &#123;-U|--upgrade&#125; [install-options] PACKAGE_FILE ...</span><br><span class="line"></span><br><span class="line">       This upgrades or installs the package currently installed to a newer version.  This is the same as  install,</span><br><span class="line">       except all other version(s) of the package are removed after the new package is installed.</span><br><span class="line"></span><br><span class="line">rpm &#123;-F|--freshen&#125; [install-options] PACKAGE_FILE ...</span><br><span class="line"></span><br><span class="line">       This will upgrade packages, but only ones for which an earlier version is installed.</span><br></pre></td></tr></table></figure></p>
<p>Both <code>rpm -Fvh</code> and <code>rpm -Uvh</code> will perform the same task but the diff is <code>rpm -Uvh</code> is also same as <code>rpm -ivh</code>, you can use any of them I mean <code>rpm -ivh</code> or <code>rpm -Uvh</code> for installing the package.</p>
<p>But for upgrading installed package you can use any of <code>rpm -Fvh</code> or <code>rpm -Uvh</code>.</p>
<p><code>rpm -Fvh</code> is used for upgrading the existing package (installed package).<br><code>rpm -Uvh</code> is used for installing the package and upgrading the package both.</p>
<p>For example, upgrade <code>ansible</code> from <code>2.4.6.0</code> to <code>2.7.8</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -Fvh ansible-2.7.8-1.el7.ans.noarch.rpm</span><br><span class="line"></span><br><span class="line">warning: ansible-2.7.8-1.el7.ans.noarch.rpm: Header V4 RSA/SHA1 Signature, key ID 442667a9: NOKEY</span><br><span class="line">Preparing...                          ################################# [100%]</span><br><span class="line">Updating / installing...</span><br><span class="line">   1:ansible-2.7.8-1.el7.ans          ################################# [ 50%]</span><br><span class="line">Cleaning up / removing...</span><br><span class="line">   2:ansible-2.4.6.0-1.el7.ans        ################################# [100%]</span><br></pre></td></tr></table></figure></p>
<h3 id="03-05-2019"><a href="#03-05-2019" class="headerlink" title="03/05/2019"></a>03/05/2019</h3><p>Remove dependencies which are not in use, any unneeded dependencies from your system, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum autoremove docker-ce</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">=========================================================================================================================</span><br><span class="line"> Package                            Arch               Version                      Repository                      Size</span><br><span class="line">=========================================================================================================================</span><br><span class="line">Removing:</span><br><span class="line"> docker-ce                          x86_64             18.06.1.ce-3.el7             @docker-local.repo             168 M</span><br><span class="line">Removing for dependencies:</span><br><span class="line"> container-selinux                  noarch             2:2.68-1.el7                 @Local-Extras                   36 k</span><br><span class="line"> libcgroup                          x86_64             0.41-20.el7                  @Local-Base                    134 k</span><br><span class="line"> libseccomp                         x86_64             2.3.1-3.el7                  @Local-Base                    297 k</span><br><span class="line"> libtool-ltdl                       x86_64             2.4.2-22.el7_3               @Local-Base                     66 k</span><br><span class="line"> policycoreutils-python             x86_64             2.5-29.el7_6.1               @Local-Base                    1.2 M</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">=========================================================================================================================</span><br><span class="line">Remove  1 Package (+5 Dependent packages)</span><br></pre></td></tr></table></figure>
<p>You also can add <code>clean_requirements_on_remove=1</code> in <code>/etc/yum.conf</code> file, then run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum remove docker-ce</span><br></pre></td></tr></table></figure></p>
<p>the same effect as using <code>autoremove</code>.</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>Yum Pending Transaction</title>
    <url>/2019/02/28/linux-yum-pending/</url>
    <content><![CDATA[<p>I need to clean yum pending or unfinished transactions before our installer start to work, otherwise the <code>yum update</code> or <code>yum install</code> may fail. But where are these pending transactions from? Sometimes the machine is down or unexpected thing happens, the yum installation process failed.</p>
<h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>you may see error like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">There are unfinished transactions remaining. You might consider running yum-complete-transaction first to finish them.</span><br><span class="line">The program yum-complete-transaction is found in the yum-utils package.</span><br></pre></td></tr></table></figure></p>
<h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>According to the prompt, we need first install <code>yum-utils</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y yum-utils</span><br></pre></td></tr></table></figure></p>
<p><code>yum-complete-transaction</code> is a program which finds incomplete or aborted yum transactions on a system and attempts to complete them. It looks at the transaction-all<em> and transaction-done</em> files which can normally be found in /var/lib/yum if a yum transaction aborted in the middle of execution.</p>
<p>If it finds more than one unfinished transaction it will attempt to complete the most recent one first. You can run it more than once to clean up all unfinished transactions.</p>
<p>Then just issue the following command to do a cleanup:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum-complete-transaction --cleanup-only</span><br></pre></td></tr></table></figure></p>
<p>You can also check how many pending transactions exist:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find /var/lib/yum -maxdepth 1 -<span class="built_in">type</span> f -name <span class="string">'transaction-all*'</span> -not -name <span class="string">'*disabled'</span> -<span class="built_in">printf</span> . | wc -c</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title>Copy &amp; Paste in Terminal</title>
    <url>/2019/01/27/mac-copy-paste/</url>
    <content><![CDATA[<p>Mac provides the command line for copy and paste, useful for some tasks.</p>
<blockquote>
<p>refer link：<a href="http://osxdaily.com/2007/03/05/manipulating-the-clipboard-from-the-command-line/" target="_blank" rel="noopener">http://osxdaily.com/2007/03/05/manipulating-the-clipboard-from-the-command-line/</a></p>
</blockquote>
<h2 id="Copy"><a href="#Copy" class="headerlink" title="Copy"></a>Copy</h2><p>copy the content of the file<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pbcopy &lt; file.txt</span><br></pre></td></tr></table></figure></p>
<p>now the content is in clipboard, ready to be pasted</p>
<blockquote>
<p>you can use pipe to combine command such as <code>find</code>,<code>grep</code>, <code>awk</code> and <code>cut</code> to filter and aggregate data.</p>
</blockquote>
<p>for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker images | grep <span class="string">"iis-"</span> | pbcopy</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"this is a demo"</span> | pbcopy</span><br></pre></td></tr></table></figure>
<h2 id="Paste"><a href="#Paste" class="headerlink" title="Paste"></a>Paste</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pbpaste</span><br></pre></td></tr></table></figure>
<p>redirect content to a file<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pbpaste &gt; file.txt</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pbpaste | grep <span class="string">"xxx"</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac Backup to Google Drive</title>
    <url>/2019/12/11/mac-backup/</url>
    <content><![CDATA[<p>I want to automatically upload the copy tar of my blog folder to google drive when I deploy it. </p>
<blockquote>
<p>How to ssh/scp to <a href="https://support.apple.com/guide/mac-help/allow-a-remote-computer-to-access-your-mac-mchlp1066/mac" target="_blank" rel="noopener">Mac</a>? Notice that should be in the same network.</p>
</blockquote>
<p>Backup steps:</p>
<ol>
<li>hexo clean</li>
<li>tar</li>
<li>upload through Google drive API</li>
</ol>
<p>大概看了一下，文档很不直接，需要额外时间研究一下<br>我还没有create credenticals<br><a href="https://developers.google.com/drive/api/v3/about-sdk?authuser=1" target="_blank" rel="noopener">https://developers.google.com/drive/api/v3/about-sdk?authuser=1</a></p>
<p>google drive mimi-type:<br><a href="https://stackoverflow.com/questions/11894772/google-drive-mime-types-listing" target="_blank" rel="noopener">https://stackoverflow.com/questions/11894772/google-drive-mime-types-listing</a></p>
<p>python example:<br><a href="https://stackoverflow.com/questions/11472401/looking-for-example-using-mediafileupload" target="_blank" rel="noopener">https://stackoverflow.com/questions/11472401/looking-for-example-using-mediafileupload</a></p>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>google drive</tag>
      </tags>
  </entry>
  <entry>
    <title>User ID Valid Range</title>
    <url>/2019/07/26/linux-uid-range/</url>
    <content><![CDATA[<p>From the CloudPak certification requirments, the <code>uid</code> for non-root user in container should be set in a higher range. We change it from <code>1000</code> to <code>100321000</code> but the image build got stuck and failed.</p>
<p>The reason is there is a range for <code>uid</code> number, it’s described in <code>/etc/login.defs</code> file (you can edit this file).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /etc/login.defs | grep -i UID</span><br><span class="line"></span><br><span class="line">UID_MIN                  1000</span><br><span class="line">UID_MAX                 60000</span><br></pre></td></tr></table></figure></p>
<p>So if you create a user by <code>useradd</code> without specify user id explicitly, its <code>uid</code> will start from <code>1000</code>. Also when change the <code>uid</code> by <code>usermod -u &lt;new uid&gt; &lt;user name&gt;</code>, you need to follow the limitation.</p>
<p>The <code>gid</code> has the same restriction:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /etc/login.defs | grep -i GID</span><br><span class="line"></span><br><span class="line">GID_MIN                  1000</span><br><span class="line">GID_MAX                 60000</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Record Sounds in Mac</title>
    <url>/2019/12/28/mac-record-sounds/</url>
    <content><![CDATA[<p>How to capture the sounds coming from your Mac (with or without mixing the sounds from microphone):<br><a href="https://www.youtube.com/watch?v=dNYZOaf3Gvs" target="_blank" rel="noopener">https://www.youtube.com/watch?v=dNYZOaf3Gvs</a></p>
<p>Basically we need to install a plug-in <strong>Soundflower</strong>, download from <a href="https://www.youtube.com/redirect?q=http%3A%2F%2Fwww.fluxforge.com%2Fvector%2Fsoundflower_2.0b2.zip&amp;redir_token=FiOR4FxaoCa04ud_rckRAjoXlSd8MTU3NzY4OTE1N0AxNTc3NjAyNzU3&amp;v=dNYZOaf3Gvs&amp;event=video_description" target="_blank" rel="noopener">here</a>.</p>
<p>After downloading the zip folder, double click to install <code>Soundflower.pkg</code>(you may need to grant the privilege from system perference).</p>
<p>Open <strong>Audio MIDI Setup</strong>:</p>
<ol>
<li><p>Create a <code>Aggregate Device</code>, name it <code>Quicktime Player Input</code><br>Check <code>soundflower 2ch</code> and <code>Built-in Microphone</code>, clock source uses <code>Built-in Microphone</code>.</p>
</li>
<li><p>Create <code>Multi-Output Device</code>, name it <code>Screen Record w/ Audio</code><br>Check <code>soundflower 2ch</code> and <code>Built-in Output</code>, clock source uses <code>Built-in Output</code>.</p>
</li>
</ol>
<p>Before recording, go to system preference <code>Sound</code>, in <code>Output</code> section, select <code>Screen Record w/ Audio</code>. Then open <strong>Quicktime Player</strong> new audio or screen recording:</p>
<ol>
<li>If only wants to capture internal audio, in the drop-down menu select <code>soundflow (2ch)</code></li>
<li>If wants to capture internal/outside audio, select <code>Quicktime Player Input</code></li>
</ol>
<p>After recording is done, set back to <code>Headphones</code> in <code>Sound</code>.</p>
]]></content>
      <categories>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title>Miscellanea 2020</title>
    <url>/2020/01/22/mis-2020/</url>
    <content><![CDATA[<h3 id="01-22-2020"><a href="#01-22-2020" class="headerlink" title="01/22/2020"></a>01/22/2020</h3><ul>
<li><p>NFS network file system, list nfs port:<br><a href="https://serverfault.com/questions/377170/which-ports-do-i-need-to-open-in-the-firewall-to-use-nfs" target="_blank" rel="noopener">https://serverfault.com/questions/377170/which-ports-do-i-need-to-open-in-the-firewall-to-use-nfs</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpcinfo -p | grep nfs</span><br></pre></td></tr></table></figure>
<p>It depends on the version of the protocol you intent to use. NFS 4 only require <code>2049</code> while older versions require more.</p>
</li>
<li><p>setup nfs cluster to prevent single point of failure<br><a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/high_availability_add-on_administration/ch-nfsserver-haaa" target="_blank" rel="noopener">https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/high_availability_add-on_administration/ch-nfsserver-haaa</a></p>
</li>
</ul>
<h3 id="02-26-2020"><a href="#02-26-2020" class="headerlink" title="02/26/2020"></a>02/26/2020</h3><ul>
<li><p>如果不想让一个executable 执行多次，可以在每次run的时候在当前或固定文件夹create一个hidden file, for example: <code>.commad.lock</code>，然后写入当前正在run的command 参数等。通过检查这个file是否存在去决定是不是正在执行。</p>
</li>
<li><p>redhat 一个很不错的网站: <a href="https://www.redhat.com/sysadmin/" target="_blank" rel="noopener">https://www.redhat.com/sysadmin/</a></p>
</li>
<li><p>command <code>uuidgen</code> 可以用来generate random unique number.</p>
</li>
</ul>
<h3 id="04-07-2020"><a href="#04-07-2020" class="headerlink" title="04/07/2020"></a>04/07/2020</h3><ul>
<li><code>find</code> softlink file, use type <code>l</code>:<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -type l -name dsenv</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>or use <code>-L</code>, then the <code>-type</code> predicate will always match against the type of the file that  a  symbolic  link  points  to  rather  than  the link itself (unless the symbolic link is broken).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find -L / type f -name dsenv</span><br></pre></td></tr></table></figure></p>
<p>类似于<code>readlink</code>, 会去softlink directory里面寻找original file.</p>
<h3 id="04-09-2020"><a href="#04-09-2020" class="headerlink" title="04/09/2020"></a>04/09/2020</h3><ul>
<li><p><code>&gt; /dev/null 2&gt;&amp;1</code> can be written as <code>&amp;&gt; /dev/null</code></p>
</li>
<li><p><code>su</code> vs <code>su -</code>. 都是login to another user, <code>-</code> 表示normal login，login后会完全变成当前user的初始环境，比如在当前user的home dir且$PATH也是当前user的。没有<code>-</code>, 则会继承上个user的环境，比如dir还是上次的。2个login都会执行~/.bashrc.</p>
</li>
<li><p><code>!$</code> the last word from last command in history list:<br><a href="https://unix.stackexchange.com/questions/88642/what-does-mean" target="_blank" rel="noopener">https://unix.stackexchange.com/questions/88642/what-does-mean</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep -i joe /some/long/directory/structure/user-lists/list-15</span><br><span class="line"><span class="comment">## expand as /some/long/directory/structure/user-lists/list-15</span></span><br><span class="line">vi !$</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="04-18-2020"><a href="#04-18-2020" class="headerlink" title="04/18/2020"></a>04/18/2020</h3><ul>
<li>在pod container中，如果script process不是init process (pid 1)，那么script中的trap 内容不会被执行。 还不太清楚为什么。</li>
</ul>
<h3 id="04-26-2020"><a href="#04-26-2020" class="headerlink" title="04/26/2020"></a>04/26/2020</h3><ul>
<li><code>declare -F</code> show function name in current shell</li>
<li><code>declare -f</code> show function definition in current shell, <code>declare -f &lt;f name&gt;</code> get just that definition</li>
</ul>
]]></content>
      <categories>
        <category>Miscellanea</category>
      </categories>
      <tags>
        <tag>miscellanea</tag>
      </tags>
  </entry>
  <entry>
    <title>Elastic Stack Quick Start</title>
    <url>/2020/05/20/monitor-elasticsearch/</url>
    <content><![CDATA[<h1 id="Elastic-Stack"><a href="#Elastic-Stack" class="headerlink" title="Elastic Stack"></a>Elastic Stack</h1><p><a href="https://www.elastic.co/elastic-stack" target="_blank" rel="noopener">https://www.elastic.co/elastic-stack</a><br>The Elastic Stack is one of the most effective ways to leverage open source technology to build a central logging, monitoring, and alerting system for servers and applications.</p>
<p><code>Elasticsearch</code>: distributed, fast, highly scalable document database.<br><code>Logstash</code>: Aggregates, filters and supplyments log data, forwards them to Elasticsearch.<br><code>Kibana</code>: Web-based front-end to visualize data.<br><code>Beats</code>: lightweight utilities for reading logs from a varity of sources, sends data to Logstash or other backends.<br><code>Altering</code>: Send notifications to email, slack, pagerduty so on and so forth.</p>
<p><img src="https://drive.google.com/uc?id=1ch29tlydlCpFxh2RARV0EVxH_1AWSzRl" alt=""></p>
<p><a href="https://stackoverflow.com/questions/40793901/prometheus-vs-elasticsearch-which-is-better-for-container-and-server-monitoring" target="_blank" rel="noopener">Elastic stack vs Prometheus</a>:<br>ELK is general-purpose no-sql stack can be used for monitoring, aggregating all the logging and shipping to elastic search for ease of browsing all the logging and similar things.</p>
<p>Prometheus is dedicated monitoring system, alongside with service discovery consul and alert-manager, the right tool for the jobs.</p>
<h2 id="Install-Elasticsearch"><a href="#Install-Elasticsearch" class="headerlink" title="Install Elasticsearch"></a>Install Elasticsearch</h2><p>There are several ways to install: binary, rpm or on kubernetes<br><a href="https://www.elastic.co/downloads/elasticsearch" target="_blank" rel="noopener">https://www.elastic.co/downloads/elasticsearch</a></p>
<blockquote>
<p>Java runtime is required.</p>
</blockquote>
<p>I am here installing by yum repo with latest Elasticsearch version, before launching it go to <code>/etc/elasticsearch/elasticsearch.yml</code>, set the cluster name and node name, for example:<br><a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.7/rpm.html#rpm-configuring" target="_blank" rel="noopener">https://www.elastic.co/guide/en/elasticsearch/reference/7.7/rpm.html#rpm-configuring</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## cluster name</span></span><br><span class="line">cluster.name: chengdol-els</span><br><span class="line"><span class="comment">## node name</span></span><br><span class="line">node.name: master</span><br><span class="line"><span class="comment">## ip to access</span></span><br><span class="line">network.host: 9.30.94.85</span><br><span class="line"><span class="comment">## this is one of the must configuration</span></span><br><span class="line">discovery.seed_hosts: [<span class="string">"127.0.0.1"</span>, <span class="string">"[::1]"</span>]</span><br></pre></td></tr></table></figure></p>
<p>Then changing one system level setting (this is default, can skip):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## permenantly </span></span><br><span class="line">sysctl -w vm.max_map_count=262144</span><br></pre></td></tr></table></figure></p>
<p>The start by systemd<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start Elasticsearch</span><br></pre></td></tr></table></figure></p>
<p>Check the server is up and running:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 9200 is the defaul port</span></span><br><span class="line"><span class="comment">## or using postman</span></span><br><span class="line">curl http://9.30.94.85:9200</span><br><span class="line"></span><br><span class="line"><span class="comment">## response from Elasticsearch server</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"name"</span> : <span class="string">"master"</span>,</span><br><span class="line">  <span class="string">"cluster_name"</span> : <span class="string">"chengdol-els"</span>,</span><br><span class="line">  <span class="string">"cluster_uuid"</span> : <span class="string">"1fDfNniwR-uX3mXHQGItVw"</span>,</span><br><span class="line">  <span class="string">"version"</span> : &#123;</span><br><span class="line">    <span class="string">"number"</span> : <span class="string">"7.7.0"</span>,</span><br><span class="line">    <span class="string">"build_flavor"</span> : <span class="string">"default"</span>,</span><br><span class="line">    <span class="string">"build_type"</span> : <span class="string">"rpm"</span>,</span><br><span class="line">    <span class="string">"build_hash"</span> : <span class="string">"81a1e9eda8e6183f5237786246f6dced26a10eaf"</span>,</span><br><span class="line">    <span class="string">"build_date"</span> : <span class="string">"2020-05-12T02:01:37.602180Z"</span>,</span><br><span class="line">    <span class="string">"build_snapshot"</span> : <span class="literal">false</span>,</span><br><span class="line">    <span class="string">"lucene_version"</span> : <span class="string">"8.5.1"</span>,</span><br><span class="line">    <span class="string">"minimum_wire_compatibility_version"</span> : <span class="string">"6.8.0"</span>,</span><br><span class="line">    <span class="string">"minimum_index_compatibility_version"</span> : <span class="string">"6.0.0-beta1"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"tagline"</span> : <span class="string">"You Know, for Search"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Install-Logstash"><a href="#Install-Logstash" class="headerlink" title="Install Logstash"></a>Install Logstash</h2><p><a href="https://www.elastic.co/downloads/logstash" target="_blank" rel="noopener">https://www.elastic.co/downloads/logstash</a></p>
<blockquote>
<p>Java runtime is required.</p>
</blockquote>
<p>Installing by yum repos, by default the app location is in <code>/usr/share/logstash</code>, enable and start by systemd. A simple test to verify the correction:</p>
<p>Using systemd to start Logstash will load the configuration specified in <code>/etc/logstash/logstash.yml</code>. Using command to start Logstash is not recommended, usually for testing.</p>
<p>In <code>/etc/logstash/logstash.yml</code> file, you can set the value of <code>path.config</code> field so Logstash know where to pick the pipeline configurations.<br><a href="https://www.elastic.co/guide/en/logstash/current/logstash-settings-file.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/logstash/current/logstash-settings-file.html</a></p>
<p>A brief deviation, If you run <code>systemctl status logstash</code>, will see<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Loaded: loaded (/etc/systemd/system/logstash.service; disabled; vendor preset: disabled)</span><br></pre></td></tr></table></figure></p>
<p>Open and check <code>/etc/systemd/system/logstash.service</code>, you will find where the configuration files reside: <code>/etc/logstash</code>, also where is the executable <code>/usr/share/logstash</code>.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/share/logstash</span><br><span class="line"><span class="comment">## test running</span></span><br><span class="line">bin/logstash -e <span class="string">'input &#123; stdin &#123; &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; ["&lt;9.30.94.85&gt;:9200"] &#125; &#125;'</span></span><br><span class="line"><span class="comment">## then type something to send</span></span><br></pre></td></tr></table></figure>
<p>Then use curl or postman to fetch log from Elasticsearch:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## you will see what you typed in logstash</span></span><br><span class="line">curl http://9.30.94.85:9200/logstash-*/_search</span><br></pre></td></tr></table></figure></p>
<h3 id="Read-Beats-Data"><a href="#Read-Beats-Data" class="headerlink" title="Read Beats Data"></a>Read Beats Data</h3><p>To read data from Beats:</p>
<ol>
<li>Input: where is the data from? logs? beats?</li>
<li>Filter: how should we parse the data? grok filters, geoip filters, etc.</li>
<li>Output: where should we store the logs? backend? Elasticsearch?</li>
</ol>
<p>Go to <code>/etc/logstash/conf.d</code>, create new file for example, <code>beats.conf</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">input &#123;</span><br><span class="line">    <span class="comment">## in Beats side, listening on port 5043</span></span><br><span class="line">    beats &#123;</span><br><span class="line">        port =&gt; <span class="string">"5043"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">    <span class="keyword">if</span> [<span class="built_in">type</span>] == <span class="string">"syslog"</span> &#123;</span><br><span class="line">        <span class="comment">## grok filter</span></span><br><span class="line">        grok &#123;</span><br><span class="line">            match =&gt; &#123; <span class="string">"message"</span> =&gt; <span class="string">"%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\[%&#123;POSINT:syslog_pid&#125;\])?: %&#123;GREEDYDATA:syslog_message&#125;"</span> &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        date &#123;</span><br><span class="line">           match =&gt; [ <span class="string">"syslog_timestamp"</span>, <span class="string">"MMM  d HH:mm:ss"</span>, <span class="string">"MMM dd HH:mm:ss"</span> ]</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">    elasticsearch &#123;</span><br><span class="line">        <span class="comment">## Elasticsearch address</span></span><br><span class="line">        hosts =&gt; [ <span class="string">"9.30.94.85:9200"</span> ]</span><br><span class="line">        <span class="comment">## 这个对应Kibana中的Index Patterns</span></span><br><span class="line">        index =&gt; <span class="string">"%&#123;[@metadata][beat]&#125;-%&#123;+YYYY.MM.dd&#125;"</span></span><br><span class="line">        document_type =&gt; <span class="string">"%&#123;[@metadata][type]&#125;"</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Then run command to testing file validity:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## --config.test_and_exit: parses configuration file and reports any errors.</span></span><br><span class="line">bin/logstash -f beats.conf --config.test_and_exit</span><br><span class="line"></span><br><span class="line"><span class="comment">## The --config.reload.automatic: enables automatic config reloading so that don’t have to stop and restart Logstash every time modify the configuration file.</span></span><br><span class="line">bin/logstash -f beats.conf --config.reload.automatic</span><br></pre></td></tr></table></figure></p>
<h2 id="Install-Kibana"><a href="#Install-Kibana" class="headerlink" title="Install Kibana"></a>Install Kibana</h2><p><a href="https://www.elastic.co/downloads/kibana" target="_blank" rel="noopener">https://www.elastic.co/downloads/kibana</a><br>written in Node.js, no other dependencies needed.</p>
<p>Do a quick configuration, then start by systemd:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/kibana/kibana.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># To allow connections from remote users, set this parameter to a non-loopback address.</span></span><br><span class="line">server.host: <span class="string">"9.30.94.85"</span></span><br><span class="line"><span class="comment"># The Kibana server's name.  This is used for display purposes.</span></span><br><span class="line">server.name: <span class="string">"chengdol-kibana"</span></span><br><span class="line"><span class="comment"># The URLs of the Elasticsearch instances to use for all your queries.</span></span><br><span class="line">elasticsearch.hosts: [<span class="string">"http://9.30.94.85:9200"</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">## start</span></span><br><span class="line">systemctl start kibana</span><br><span class="line"><span class="comment">## to view the web interface</span></span><br><span class="line"><span class="comment">## default is 5601</span></span><br><span class="line">http://9.30.94.85:5601</span><br></pre></td></tr></table></figure></p>
<h3 id="Create-Dashboard"><a href="#Create-Dashboard" class="headerlink" title="Create Dashboard"></a>Create Dashboard</h3><p>Go to <code>Management</code>, create <code>Index Patterns</code> set format to poll data from Elasticsearch, then <code>Visualize</code> create graphs, add the graph to <code>Dashboard</code>.</p>
<h2 id="Beats"><a href="#Beats" class="headerlink" title="Beats"></a>Beats</h2><p><a href="https://www.elastic.co/beats/" target="_blank" rel="noopener">https://www.elastic.co/beats/</a><br>Beats can output data to Elasticsearch, Logstash and Redis. But usually we send data to Logstash (pre-processing) then forward to Elasticsearch.</p>
<p>Each Beat has configure yaml file with detailed configuration guideline. For example, in the configure yaml file, comment out Elasticsearch output, use Logstash output.</p>
<ul>
<li>Filebeat: text log files</li>
<li>Metricbeat: OS and applications</li>
<li>Packetbeat: network monitoring</li>
<li>Winlogbeat: windows event log</li>
<li>Libbeat: write your own</li>
</ul>
<h2 id="Alerting"><a href="#Alerting" class="headerlink" title="Alerting"></a>Alerting</h2><p>Not free feature.</p>
<p>Workflow:</p>
<ul>
<li>Schedule/trigger</li>
<li>Input/Query</li>
<li>Condition</li>
<li>Action</li>
</ul>
]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>monitor</tag>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Gain from People</title>
    <url>/2019/04/30/mis-gain-from-people/</url>
    <content><![CDATA[<p>入职IBM接近一年了，除了记录在博客中的东西，还有很多所学所得。目前觉得很实用的几个过来人的建议，一直贯彻落实在平时工作中。</p>
<ol>
<li><p>Document everything，能多详细多详细：时间，链接，上下文，切换原因，做了什么，目前得到了什么，接下来做什么, 能上图片上图片，能上语音上与语音, etc. 千万不要觉得记性好，那是幻觉。</p>
</li>
<li><p>Automate tedious work，如果你发现某一件事会重复发生至少3次以上，请立马想想能不能自动化一下，至少来点alias简化一下敲击键盘的数量。</p>
</li>
<li><p>At least half day. 以前太老实了，每次manager 问我how much time do you think you can finish it，我都给自己的buffer很少。有次我居然说20分钟可以解决，结果被大佬教育千万别这么说，万一半路去拉个屎20分钟就没了。</p>
</li>
<li><p>Back up daily work. 始于一次internal cloud maintenance后，自己的中控机文件系统受到损害无法修复壮烈牺牲（我总觉得可以修复，可能那人觉得没必要），后来又遇到laptop无故反复重启的险情，遂领悟高级备份技能。</p>
</li>
<li><p>Learning is an endless process. 以前还在想是不是经过一个陡峭的learning curve，工作将手到擒来（或者游刃有余），后来发现想多了T_T。我几乎每天都能遇到以前不会的新东西，honestly，我还是很高兴的，否则博客该写啥呢。也不是说领域完全没有尽头，只是它太大了，由点到面，融会贯通还需要时间。keep learning, all of these will pay off in the end.</p>
</li>
<li><p>Try, do try. 别太相信查找到解答，但其中很多内容已经失效，过时，并不是最佳方案（虽然能用），有的还是错的。一定要上手试一下，验证一下是否自己已经正确理解。几次遇到和2位组里大佬探讨时发现实际运行结果和期待的东西完全不一样。知其然，更知其所以然，否则心里不踏实。</p>
</li>
</ol>
]]></content>
      <categories>
        <category>Miscellanea</category>
      </categories>
  </entry>
  <entry>
    <title>Openshift Vs Kubernetes</title>
    <url>/2019/07/09/openshift-intro/</url>
    <content><![CDATA[<p>OpenShift version: <code>3.10</code></p>
<p>I have worked on Kubernetes and OpenShift for several months, both are good container management and schedule tools, they have many overlaps and the kubectl commands are compitable in OpenShift, so what the exactly differences between them are?</p>
<p>我大概是从2018年下半年开始接触OpenShift的，当时要求将部署移植到OpenShift平台上。推荐一本书:<code>&lt;&lt;开源容器云OpenShift 构建基于Kubernetes的企业应用云平台&gt;&gt;</code>，这本书基本上介绍清楚了OpenShift的一些基本操作和概念，也提到了和K8s不同的地方。</p>
<blockquote>
<p>A brief Digression: Today IBM officially close the acquisistion of Red Hat!</p>
</blockquote>
<h3 id="Resource"><a href="#Resource" class="headerlink" title="Resource"></a>Resource</h3><p><a href="https://en.wikipedia.org/wiki/OpenShift" target="_blank" rel="noopener">OpenShift-wikipedia</a></p>
<ol>
<li>OpenShift is a family of containerization software developed by Red Hat. Its flagship product is the <code>OpenShift Container Platform</code>, an on-premises platform as a service built around <code>Docker containers</code> orchestrated and managed by <code>Kubernetes</code> on a foundation of <code>Red Hat Enterprise Linux</code>. </li>
</ol>
<p><a href="https://www.redhat.com/en/blog/openshift-and-kubernetes-whats-difference" target="_blank" rel="noopener">The Differences Between Kubernetes and Openshift</a></p>
<ol>
<li>Kubernetes is the kernel</li>
<li>Openshift is the distribution</li>
</ol>
<p><a href="https://cloudowski.com/articles/10-differences-between-openshift-and-kubernetes/" target="_blank" rel="noopener">10 most important differences between OpenShift and Kubernetes</a></p>
<ol>
<li>OKD can install on rhel and centos</li>
<li>Kubernetes is an integral part of OpenShift with more features built around it.</li>
<li>OpenShift has more strict security policies than default Kubernetes, most of container images available on Docker Hub or we have built before won’t run on OpenShift, because it forbids to run a container as root. we need to relax this strict to give the workspace higher privileges to run container as root, or update our image to</li>
</ol>
<p><a href="https://medium.com/levvel-consulting/the-differences-between-kubernetes-and-openshift-ae778059a90e" target="_blank" rel="noopener">The Differences Between Kubernetes and Openshift</a></p>
]]></content>
      <categories>
        <category>OpenShift</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>openshift</tag>
      </tags>
  </entry>
  <entry>
    <title>Cluster Image Registry in OpenShift</title>
    <url>/2020/02/26/openshift-image-registry/</url>
    <content><![CDATA[<p>OpenShift version: <code>4.3</code></p>
<h2 id="Create-Internal-Image-Registry-Route"><a href="#Create-Internal-Image-Registry-Route" class="headerlink" title="Create Internal Image Registry Route"></a>Create Internal Image Registry Route</h2><p>From the Infra Node, run the following commands.<br>This will create a accessable path for you to push image to internal image registry.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc project openshift-image-registry</span><br><span class="line">oc patch configs.imageregistry.operator.openshift.io/cluster --<span class="built_in">type</span> merge -p <span class="string">'&#123;"spec":&#123;"defaultRoute":true&#125;&#125;'</span></span><br><span class="line"><span class="comment">## we need this output when tag and push image</span></span><br><span class="line">CLUSTER_IMAGE_REGISTRY_ROUTE=$(oc get route)</span><br></pre></td></tr></table></figure></p>
<h2 id="Pull-Tag-and-Push-Image"><a href="#Pull-Tag-and-Push-Image" class="headerlink" title="Pull, Tag and Push Image"></a>Pull, Tag and Push Image</h2><p>Here we use podman:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## pull original from other registry</span></span><br><span class="line"><span class="comment">## or use podman to load image archive</span></span><br><span class="line">podman login -u &lt;user&gt; -p &lt;password&gt; docker.io</span><br><span class="line">podman load -i &lt;image&gt;.tar.gz</span><br><span class="line"></span><br><span class="line">podman pull &lt;path&gt;/&lt;image&gt;:&lt;tag&gt;</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> PRIVATE_REGISTRY=<span class="variable">$&#123;CLUSTER_IMAGE_REGISTRY_ROUTE&#125;</span>/&lt;project&gt;</span><br><span class="line"><span class="comment">## kubeadmin is the default cluster admin</span></span><br><span class="line">podman login -u kubeadmin -p $(oc whoami -t)  <span class="variable">$PRIVATE_REGISTRY</span> --tls-verify=<span class="literal">false</span></span><br><span class="line"></span><br><span class="line">podman tag  &lt;path&gt;/&lt;image&gt;:&lt;tag&gt; <span class="variable">$PRIVATE_REGISTRY</span>/&lt;image&gt;:&lt;tag&gt;</span><br><span class="line">podman push <span class="variable">$PRIVATE_REGISTRY</span>/&lt;image&gt;:&lt;tag&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Create-Role-and-Binding"><a href="#Create-Role-and-Binding" class="headerlink" title="Create Role and Binding"></a>Create Role and Binding</h2><p>You need to get authenicated when pull image from cluster image registry, here we create a dedicated service account under the target project, then grant privileges to this service account and specify it to yaml file.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">oc</span> <span class="string">apply</span> <span class="bullet">-f</span> <span class="bullet">-</span> <span class="string">&lt;&lt;</span> <span class="string">EOF</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">&lt;service</span> <span class="string">account</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">&lt;projetc&gt;</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">&lt;cluster</span> <span class="string">role</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">["*"]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["*"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["*"]</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">&lt;couster</span> <span class="string">role</span> <span class="string">binding</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">  - kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">&lt;service</span> <span class="string">account</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">&lt;project&gt;</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">&lt;cluster</span> <span class="string">role</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br></pre></td></tr></table></figure>
<p>Example pod yaml file:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-pod</span></span><br><span class="line"><span class="attr">spec:</span> </span><br><span class="line">  <span class="comment">## specify the service accout</span></span><br><span class="line"><span class="attr">  serviceAccountName:</span> <span class="string">&lt;service</span> <span class="string">account</span> <span class="string">name&gt;</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">test-cotainer</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">image-registry.openshift-image-registry.svc:5000/&lt;project&gt;/&lt;image&gt;:&lt;tag&gt;</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'tail -f /dev/null'</span><span class="string">]</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that the default cluster registry path is <code>image-registry.openshift-image-registry.svc:5000</code>, consist of <code>&lt;svc name&gt;.&lt;project&gt;.svc:&lt;port&gt;</code>. don’t use that route path.</p>
</blockquote>
]]></content>
      <categories>
        <category>OpenShift</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>openshift</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell Arguments Format</title>
    <url>/2019/09/17/shell-argument-format/</url>
    <content><![CDATA[<p>When I check the <code>cmd</code> and <code>entrypoint</code> of one image, I see something like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cmd: zkServer.sh start-foreground</span><br><span class="line">entrypoint: /docker-entrypoint.sh</span><br></pre></td></tr></table></figure></p>
<p>That means <code>cmd</code> part will be passed into entrypoint as argument, let’s see what is inside <code>/docker-entrypoint.sh</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Generate Zookeeper configuration</span></span><br><span class="line">[ <span class="string">"<span class="variable">$1</span>"</span> = <span class="string">'zkServer.sh'</span> ] &amp;&amp; (zkGenConfig.sh || <span class="built_in">exit</span> 1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">exec</span> <span class="string">"<span class="variable">$@</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>It just like a wrapper and executes the passed parameters as a new command. This pattern gives me some inspirations.</p>
<p>About <code>$@</code>, reference from <a href="https://stackoverflow.com/questions/9994295/what-does-mean-in-a-shell-script" target="_blank" rel="noopener">https://stackoverflow.com/questions/9994295/what-does-mean-in-a-shell-script</a>:<br><code>$@</code> is nearly the same as <code>$*</code>, both meaning “all command line arguments”. They are often used to simply pass all arguments to another program (thus forming a wrapper around that other program).</p>
<p>The difference between the two syntaxes shows up when you have an argument with spaces in it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wrappedProgram <span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line"><span class="comment"># ^^^ this is correct and will hand over all arguments in the way</span></span><br><span class="line"><span class="comment">#     we received them, i. e. as several arguments, each of them</span></span><br><span class="line"><span class="comment">#     containing all the spaces and other uglinesses they have.</span></span><br><span class="line">wrappedProgram <span class="string">"$*"</span></span><br><span class="line"><span class="comment"># ^^^ this will hand over exactly one argument, containing all</span></span><br><span class="line"><span class="comment">#     original arguments, separated by single spaces.</span></span><br><span class="line">wrappedProgram $*</span><br><span class="line"><span class="comment"># ^^^ this will join all arguments by single spaces as well and</span></span><br><span class="line"><span class="comment">#     will then split the string as the shell does on the command</span></span><br><span class="line"><span class="comment">#     line, thus it will split an argument containing spaces into</span></span><br><span class="line"><span class="comment">#     several arguments.</span></span><br></pre></td></tr></table></figure></p>
<p>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wrapper &quot;one two    three&quot; four five &quot;six seven&quot;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;$@&quot;: wrappedProgram &quot;one two    three&quot; four five &quot;six seven&quot;</span><br><span class="line">&quot;$*&quot;: wrappedProgram &quot;one two    three four five six seven&quot;</span><br><span class="line">                             ^^^^ These spaces are part of the first</span><br><span class="line">                                  argument and are not changed.</span><br><span class="line">$*:   wrappedProgram one two three four five six seven</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenShift SCC Customized</title>
    <url>/2019/07/16/openshift-scc-customized/</url>
    <content><![CDATA[<p>OpenShift version: <code>3.10</code></p>
<p>There are by default 7 SCCs in OpenShift, but that may not satisfy the demands and it’s better to create a new dedicated one to use for non-root deployment.</p>
<blockquote>
<p>To get basic understand about <code>SCC</code>, see my blog <a href="https://chengdol.github.io/2019/06/21/openshift-scc/" target="_blank" rel="noopener"><code>&lt;&lt;OpenShift Security Context Constraint&gt;&gt;</code></a>.</p>
</blockquote>
<p>7 default existing SCCs are:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc get scc</span><br><span class="line"></span><br><span class="line">NAME               PRIV      CAPS      SELINUX     RUNASUSER          FSGROUP     SUPGROUP    PRIORITY   READONLYROOTFS   VOLUMES</span><br><span class="line">anyuid             <span class="literal">false</span>     []        MustRunAs   RunAsAny           RunAsAny    RunAsAny    10         <span class="literal">false</span>            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">hostaccess         <span class="literal">false</span>     []        MustRunAs   MustRunAsRange     MustRunAs   RunAsAny    &lt;none&gt;     <span class="literal">false</span>            [configMap downwardAPI emptyDir hostPath persistentVolumeClaim projected secret]</span><br><span class="line">hostmount-anyuid   <span class="literal">false</span>     []        MustRunAs   RunAsAny           RunAsAny    RunAsAny    &lt;none&gt;     <span class="literal">false</span>            [configMap downwardAPI emptyDir hostPath nfs persistentVolumeClaim projected secret]</span><br><span class="line">hostnetwork        <span class="literal">false</span>     []        MustRunAs   MustRunAsRange     MustRunAs   MustRunAs   &lt;none&gt;     <span class="literal">false</span>            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">nonroot            <span class="literal">false</span>     []        MustRunAs   MustRunAsNonRoot   RunAsAny    RunAsAny    &lt;none&gt;     <span class="literal">false</span>            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">privileged         <span class="literal">true</span>      [*]       RunAsAny    RunAsAny           RunAsAny    RunAsAny    &lt;none&gt;     <span class="literal">false</span>            [*]</span><br><span class="line">restricted         <span class="literal">false</span>     []        MustRunAs   MustRunAsRange     MustRunAs   RunAsAny    &lt;none&gt;     <span class="literal">false</span>            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br></pre></td></tr></table></figure></p>
<p>Don’t forget to examine SCC, such as <code>oc describe scc privileged</code>.</p>
<h2 id="SCC-Yaml-Demo"><a href="#SCC-Yaml-Demo" class="headerlink" title="SCC Yaml Demo"></a>SCC Yaml Demo</h2><blockquote>
<p>How to write SCC yaml and what does each field mean? <a href="https://docs.openshift.com/container-platform/3.9/architecture/additional_concepts/authorization.html#security-context-constraints" target="_blank" rel="noopener">OpenShift SCC official</a></p>
</blockquote>
<p>Create a file named as <code>scc-customized.yaml</code>, carefully fill the value to satisfy the demands<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">kind:</span> <span class="string">SecurityContextConstraints</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">scc-customized</span></span><br><span class="line"><span class="comment">## permission</span></span><br><span class="line"><span class="attr">allowPrivilegedContainer:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">allowHostIPC:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">allowHostNetwork:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">allowHostPID:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">allowHostPorts:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment">#allowedFlexVolumes: null</span></span><br><span class="line"><span class="comment">## linux capabilities, some pods require these</span></span><br><span class="line"><span class="attr">allowedCapabilities:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">SYS_NICE</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">IPC_OWNER</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">SYS_RESOURCE</span></span><br><span class="line"><span class="attr">requiredDropCapabilities:</span> <span class="string">[]</span></span><br><span class="line"><span class="attr">defaultAddCapabilities:</span> <span class="string">[]</span></span><br><span class="line"><span class="comment">## strategies</span></span><br><span class="line"><span class="attr">runAsUser:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">MustRunAsNonRoot</span></span><br><span class="line"><span class="attr">seLinuxContext:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">RunAsAny</span></span><br><span class="line"><span class="attr">fsGroup:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">RunAsAny</span></span><br><span class="line"><span class="attr">supplementalGroups:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">RunAsAny</span></span><br><span class="line"><span class="comment">## who can access this SCC</span></span><br><span class="line"><span class="attr">users:</span> <span class="string">[]</span></span><br><span class="line"><span class="attr">groups:</span></span><br><span class="line"><span class="attr">- system:</span><span class="string">authenticated</span></span><br><span class="line"><span class="comment">## may narrow down insteaf of `*`</span></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">'*'</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc create -f scc-customized.yaml</span><br></pre></td></tr></table></figure>
<p>Then, for example, you can bind <code>default</code> service account to this <code>SCC</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc adm policy add-scc-to-user scc-customized system:serviceaccount:&lt;project&gt;:default</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>A <code>default</code> service account is used by all other pods unless they specify a different service account.</p>
</blockquote>
]]></content>
      <categories>
        <category>OpenShift</category>
      </categories>
      <tags>
        <tag>openshift</tag>
        <tag>scc</tag>
      </tags>
  </entry>
  <entry>
    <title>Music in My Life</title>
    <url>/2019/05/27/music/</url>
    <content><![CDATA[<p>把这十几年间喜欢的音乐收集列出来，做个纪念😃😑😯😡😣😭😢绝不是随机排列…</p>
<h2 id="我弹奏的钢琴曲😃"><a href="#我弹奏的钢琴曲😃" class="headerlink" title="我弹奏的钢琴曲😃"></a>我弹奏的钢琴曲😃</h2><p>2019年6月17号我拿到了我买的YAMAHA P-125，从此开始了我钢琴自学之旅，记录一下自己的进步与快乐。</p>
<ul>
<li><p>Youtube:<br>🎹<a href="https://youtu.be/xReoYTG_0-4" target="_blank" rel="noopener">Because of You</a><br>🎹<a href="https://youtu.be/zatnaCmdDm4" target="_blank" rel="noopener">The Sound of Silence</a><br>🎹[stay tuned]</p>
</li>
<li><p>Blibli:<br>🎹<a href="https://www.bilibili.com/video/av65980280" target="_blank" rel="noopener">Because of You</a><br>🎹<a href="https://www.bilibili.com/video/av73571372" target="_blank" rel="noopener">The Sound of Silence</a><br>🎹[stay tuned]</p>
</li>
</ul>
<h2 id="最喜欢的😍"><a href="#最喜欢的😍" class="headerlink" title="最喜欢的😍"></a>最喜欢的😍</h2><ul>
<li><p><code>With an Orchid (与兰同馨)</code>(夜深人静戴耳机😝)<br>🎹🎻<a href="https://www.youtube.com/watch?v=rsNrpw2vPrA" target="_blank" rel="noopener">现场版</a><br>🎹<a href="https://www.youtube.com/watch?v=xCUjBPS9WTw" target="_blank" rel="noopener">原版</a><br>🎤<a href="https://www.youtube.com/watch?v=FRWgAV8i65o" target="_blank" rel="noopener">演唱版</a></p>
</li>
<li><p><code>Because of You</code>(夜深人静戴耳机😝)<br>🎻<a href="https://www.youtube.com/watch?v=3oYee5CEHRI" target="_blank" rel="noopener">小提琴版</a><br>🎹<a href="https://www.youtube.com/watch?v=PZIH_btEqFc" target="_blank" rel="noopener">钢琴版</a><br>🎤<a href="https://www.youtube.com/watch?v=atz_aZA3rf0" target="_blank" rel="noopener">原版MV</a></p>
</li>
</ul>
<h2 id="喜欢的🌹"><a href="#喜欢的🌹" class="headerlink" title="喜欢的🌹"></a>喜欢的🌹</h2><p>🎤<a href="https://www.youtube.com/watch?v=QN-N8jrinOM" target="_blank" rel="noopener">奔跑</a><br>🎤<a href="https://www.youtube.com/watch?v=R1i2kMxELJM" target="_blank" rel="noopener">嘻唰唰</a><br>🎤<a href="https://www.youtube.com/watch?v=hzzqzfPGrOQ" target="_blank" rel="noopener">浪漫满屋</a><br>🎤<a href="https://www.youtube.com/watch?v=qWV4gJIRRPY" target="_blank" rel="noopener">快乐崇拜</a><br>🎤<a href="https://www.youtube.com/watch?v=kqgYyfuGAag" target="_blank" rel="noopener">数码宝贝Brave Heart</a><br>🎤<a href="https://www.youtube.com/watch?v=RMFVuCURZIs" target="_blank" rel="noopener">数码宝贝Butterfly</a><br>🎤<a href="https://www.youtube.com/watch?v=5-2ednIJsa8" target="_blank" rel="noopener">你的微笑</a><br>🎹<a href="https://www.youtube.com/watch?v=KWdhcOtGtcE" target="_blank" rel="noopener">梦中的婚礼</a><br>🎤<a href="https://www.youtube.com/watch?v=h03_hs_QbEE" target="_blank" rel="noopener">不死之身</a><br>🎤<a href="https://www.youtube.com/watch?v=G97_rOdHcnY" target="_blank" rel="noopener">江南</a><br>🎹<a href="https://www.youtube.com/watch?v=WkM2Tqy-_OY" target="_blank" rel="noopener">星空</a><br>🎤<a href="https://www.youtube.com/watch?v=ZOHsd6Zk7DM" target="_blank" rel="noopener">Lydia</a><br>🎤<a href="https://www.youtube.com/watch?v=FQaid7WMr4g" target="_blank" rel="noopener">Soledad</a><br>🎤<a href="https://www.youtube.com/watch?v=8B3q6upO-Vw" target="_blank" rel="noopener">Evergreen</a><br>🎤<a href="https://www.youtube.com/watch?v=hqpDebYpP6w" target="_blank" rel="noopener">Black Black Heart</a><br>🎤<a href="https://www.youtube.com/watch?v=VNSgKDRndpQ" target="_blank" rel="noopener">7 Days</a><br>🎹<a href="https://www.youtube.com/watch?v=J7or0noYfMA" target="_blank" rel="noopener">Summer</a><br>🎤<a href="https://www.youtube.com/watch?v=E9a1W9hNkVo" target="_blank" rel="noopener">紫藤花</a><br>🎤<a href="https://www.youtube.com/watch?v=25rL-ooWICU" target="_blank" rel="noopener">I swear</a><br>🎹<a href="https://www.youtube.com/watch?v=7maJOI3QMu0" target="_blank" rel="noopener">River Flows in You</a><br>🎤<a href="https://www.youtube.com/watch?v=oXvYw-kgFz8" target="_blank" rel="noopener">Brave</a><br>🎹<a href="https://www.youtube.com/watch?v=MyziqLYNoNM" target="_blank" rel="noopener">忧伤还是快乐</a><br>🎤<a href="https://www.youtube.com/watch?v=Xp_EAKEWA-g" target="_blank" rel="noopener">留在我身边</a><br>🎤<a href="https://www.youtube.com/watch?v=CS-oP-XAzmU" target="_blank" rel="noopener">情非得已</a><br>🎹<a href="https://www.youtube.com/watch?v=cisd1_nUGkE" target="_blank" rel="noopener">The Sound of Silence</a><br>🎤<a href="https://www.youtube.com/watch?v=o6wtDPVkKqI" target="_blank" rel="noopener">残酷な天使のテーゼ</a><br>🎤<a href="https://www.youtube.com/watch?v=-7aY4tomcEE" target="_blank" rel="noopener">分开旅行</a><br>🎤<a href="https://www.youtube.com/watch?v=HwXIImlUFmY" target="_blank" rel="noopener">老男孩</a><br>🎹<a href="https://www.youtube.com/watch?v=ZrFQ88l2lAQ" target="_blank" rel="noopener">幽灵公主</a><br>🎤<a href="https://www.youtube.com/watch?v=w41gqTFYh08" target="_blank" rel="noopener">心跳</a><br>🎹🎻<a href="https://www.youtube.com/watch?v=E9kcNFpOavk" target="_blank" rel="noopener">Santorini</a><br>🎤<a href="https://www.youtube.com/watch?v=jofNR_WkoCE" target="_blank" rel="noopener">The Fox</a><br>🎤<a href="https://www.youtube.com/watch?v=hT_nvWreIhg" target="_blank" rel="noopener">Counting Stars</a><br>🎤<a href="https://www.youtube.com/watch?v=Xn676-fLq7I" target="_blank" rel="noopener">Stronger</a><br>🎤<a href="https://www.youtube.com/watch?v=EX_YWo1h-kQ&amp;list=PLRndcoWkF2_4Gv2QWYmI0pdToTYROsfQq&amp;index=16" target="_blank" rel="noopener">转动命运之轮</a><br>🎤<a href="https://www.youtube.com/watch?v=wJ61ENvN9e4" target="_blank" rel="noopener">下个，路口，见</a><br>🎹<a href="https://www.youtube.com/watch?v=LsrEEAFH0O8" target="_blank" rel="noopener">Run Away With Me</a><br>🎻<a href="https://www.youtube.com/watch?v=VZRVou4cyic" target="_blank" rel="noopener">Love Me Like You Do</a><br>🎤<a href="https://www.youtube.com/watch?v=W52V9a4iSEQ" target="_blank" rel="noopener">生来倔强</a><br>🎤<a href="https://www.youtube.com/watch?v=1Op8xDcgpUY" target="_blank" rel="noopener">飞-致我们的星辰大海</a><br>🎤<a href="https://www.youtube.com/watch?v=6GHJhhmVgdE" target="_blank" rel="noopener">追梦赤子心</a><br>🎤<a href="https://www.youtube.com/watch?v=Hpnub-uM6eo" target="_blank" rel="noopener">小苹果</a><br>🎤<a href="https://www.youtube.com/watch?v=TRgum7sGAXw" target="_blank" rel="noopener">荷塘月色</a><br>🎤<a href="https://www.youtube.com/watch?v=nWb_X3ZJQjw" target="_blank" rel="noopener">温柔</a><br>🎤<a href="https://www.youtube.com/watch?v=AQ-cLkZ7Pqw" target="_blank" rel="noopener">远走高飞</a><br>🎤<a href="https://www.youtube.com/watch?v=jdf3gxFP0F8" target="_blank" rel="noopener">美人鱼</a><br>🎤<a href="https://www.youtube.com/watch?v=TmIk61_Msgg" target="_blank" rel="noopener">杀破狼</a><br>🎤<a href="https://www.youtube.com/watch?v=GggTls8KznY" target="_blank" rel="noopener">三国恋</a><br>🎤<a href="https://www.youtube.com/watch?v=WWSxxV0KBaI" target="_blank" rel="noopener">时间飞了</a><br>🎤<a href="https://www.youtube.com/watch?v=OU3kSSMLNvE" target="_blank" rel="noopener">曾经的你</a><br>🎤<a href="https://www.youtube.com/watch?v=sHD_z90ZKV0" target="_blank" rel="noopener">稻香</a><br>🎤<a href="https://www.youtube.com/watch?v=k8IiCim0iW4" target="_blank" rel="noopener">偏爱</a><br>🎤<a href="https://www.youtube.com/watch?v=QtXby3twMmI" target="_blank" rel="noopener">Adventure Of A Lifetime</a></p>
<h2 id="随便记记😆"><a href="#随便记记😆" class="headerlink" title="随便记记😆"></a>随便记记😆</h2><p>🎤<a href="https://www.youtube.com/watch?v=rmPHuvQoh0g" target="_blank" rel="noopener">没那么简单</a><br>🎤<a href="https://www.youtube.com/watch?v=qnDlH_S4Fak" target="_blank" rel="noopener">王妃</a><br>🎤<a href="https://www.youtube.com/watch?v=Ynypvs5s75Y" target="_blank" rel="noopener">最炫民族风</a><br>🎤<a href="https://www.youtube.com/watch?v=a_Dmq21YoIc" target="_blank" rel="noopener">猪之歌</a><br>🎤<a href="https://www.youtube.com/watch?v=4GWH8q8BTtU" target="_blank" rel="noopener">我相信</a><br>🎤<a href="https://www.youtube.com/watch?v=C_91v3amKDw" target="_blank" rel="noopener">燃烧你的卡路里</a><br>🎤<a href="https://www.youtube.com/watch?v=rYEDA3JcQqw" target="_blank" rel="noopener">Rolling in the Deep</a><br>🎤<a href="https://www.youtube.com/watch?v=Nn9HqibQYCc" target="_blank" rel="noopener">幸福糊涂虫</a><br>🎤<a href="https://www.youtube.com/watch?v=jn40gqhxoSY" target="_blank" rel="noopener">No Promises</a><br>🎤<a href="https://www.youtube.com/watch?v=X1Fqn9du7xo" target="_blank" rel="noopener">Whataya Want from Me</a><br>🎤<a href="https://www.youtube.com/watch?v=ABvAbpusRbc" target="_blank" rel="noopener">默</a><br>🎤<a href="https://www.youtube.com/watch?v=pUTqs4c1mSA" target="_blank" rel="noopener">羅曼蒂克的愛情</a><br>🎤<a href="https://www.youtube.com/watch?v=TMBe2ulmNIA" target="_blank" rel="noopener">江湖笑</a><br>🎤<a href="https://www.youtube.com/watch?v=MP241noyop8" target="_blank" rel="noopener">你不是真正的快乐</a><br>🎤<a href="https://www.youtube.com/watch?v=-5YFaTrZiAg" target="_blank" rel="noopener">新贵妃醉酒</a><br>🎤<a href="https://www.youtube.com/watch?v=nfs8NYg7yQM" target="_blank" rel="noopener">Attention</a><br>🎤<a href="https://www.youtube.com/watch?v=wGAmgmZg-48" target="_blank" rel="noopener">最初的梦想</a><br>🎤<a href="https://www.youtube.com/watch?v=meruGj7Gxdw" target="_blank" rel="noopener">给我你的爱</a><br>🎤<a href="https://www.youtube.com/watch?v=F901ls8TVnY" target="_blank" rel="noopener">咱们结婚吧</a><br>🎤<a href="https://www.youtube.com/watch?v=Q0qD-EGNncs" target="_blank" rel="noopener">最好的舞台</a><br>🎤<a href="https://www.youtube.com/watch?v=PvWAApWoYmc" target="_blank" rel="noopener">最美情侣</a><br>🎹<a href="https://www.youtube.com/watch?v=bMPM3o0NYAU" target="_blank" rel="noopener">Horizon</a><br>🎤<a href="https://www.youtube.com/watch?v=b_goBPeiD7w" target="_blank" rel="noopener">空空如也</a><br>🎤<a href="https://youtu.be/ayaGw9un1wE" target="_blank" rel="noopener">渴望光荣</a><br>🎤<a href="https://www.youtube.com/watch?v=E8NC_MH7dok" target="_blank" rel="noopener">那么骄傲</a><br>🎤<a href="https://www.youtube.com/watch?v=ru0K8uYEZWw" target="_blank" rel="noopener">CAN’T STOP THE FEELING</a><br>🎤<a href="https://www.youtube.com/watch?v=lEDZyIUbSd0" target="_blank" rel="noopener">明天会更好</a><br>🎤<a href="https://www.youtube.com/watch?v=CfihYWRWRTQ" target="_blank" rel="noopener">Love Me Again</a><br>🎤<a href="https://www.youtube.com/watch?v=NjTT5_RSkw4" target="_blank" rel="noopener">平凡之路</a><br>🎤<a href="https://www.youtube.com/watch?v=ft-D_5OmsRY" target="_blank" rel="noopener">怒放的生命</a><br>🎤<a href="https://www.youtube.com/watch?v=k-9Q--LbPXU" target="_blank" rel="noopener">新的心跳</a><br>🎤<a href="https://www.youtube.com/watch?v=0sXxhp9Zcow" target="_blank" rel="noopener">Be what You Wanna Be</a><br>🎤<a href="https://www.youtube.com/watch?v=qySMxzayRcM" target="_blank" rel="noopener">回到过去</a><br>🎤<a href="https://www.youtube.com/watch?v=CZ78y__MIzM" target="_blank" rel="noopener">青花瓷</a><br>🎤<a href="https://www.youtube.com/watch?v=AdkkF6MT0R0" target="_blank" rel="noopener">夜的第七章</a><br>🎤<a href="https://www.youtube.com/watch?v=6j0riQjd7Sc" target="_blank" rel="noopener">不仅仅是喜欢</a><br>🎤<a href="https://www.youtube.com/watch?v=6Q0Pd53mojY" target="_blank" rel="noopener">夜曲</a><br>🎤<a href="https://www.youtube.com/watch?v=QpmygPPuUQ4" target="_blank" rel="noopener">只要有你</a><br>🎤<a href="https://www.youtube.com/watch?v=OtEJ6LGCW-U" target="_blank" rel="noopener">有點甜</a><br>🎤<a href="https://www.youtube.com/watch?v=AnMhdn0wJ4I" target="_blank" rel="noopener">Nevada</a><br>🎤<a href="https://www.youtube.com/watch?v=T4SimnaiktU" target="_blank" rel="noopener">光年之外</a><br>🎤<a href="https://www.youtube.com/watch?v=OgjFJKUh34I" target="_blank" rel="noopener">戰火榮耀</a></p>
]]></content>
      <categories>
        <category>Music</category>
      </categories>
  </entry>
  <entry>
    <title>Background Sign Caution</title>
    <url>/2019/09/09/shell-background-sign-caution/</url>
    <content><![CDATA[<p>I want to convert several commands into one line to put in <code>command</code>/<code>args</code> in yaml file for Kubernetes deployment. But always get syntax error with bad <code>;</code> mark like <code>-bash: syntax error near unexpected token ;&#39;</code>, finally realize the error is from <code>&amp;</code>.</p>
<p>Notice that here <code>&amp;</code> should not have <code>;</code> behind it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(echo 123)&amp;; sleep 5; echo 456</span><br></pre></td></tr></table></figure></p>
<p>instead the correct way is:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(echo 123)&amp; sleep 5; echo 456</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Array in Script</title>
    <url>/2019/08/13/shell-array/</url>
    <content><![CDATA[<p>The first thing to do is to distinguish between bash <code>indexed</code> array and bash <code>associative</code> array. The former are arrays in which the keys are ordered integers, while the latter are arrays in which the keys are represented by strings.</p>
<p>Although indexed arrays can be initialized in many ways, associative ones can <strong>only</strong> be created by using the <code>declare</code> command.</p>
<h1 id="Create-Indexed-Array"><a href="#Create-Indexed-Array" class="headerlink" title="Create Indexed Array"></a>Create Indexed Array</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create all at once</span></span><br><span class="line"><span class="built_in">declare</span> -a array=(x y z) </span><br><span class="line"><span class="comment">## create separately</span></span><br><span class="line"><span class="built_in">declare</span> -a array</span><br><span class="line">array[0]=xx</span><br><span class="line">array[1]=yy</span><br><span class="line">array[2]=zz</span><br></pre></td></tr></table></figure>
<p>you can also create on the fly<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">array=(xx yy zz)</span><br></pre></td></tr></table></figure></p>
<p>Add new element into array:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">array+=(<span class="string">'foo'</span>)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that in the context where an assignment statement is assigning a value to a <code>shell variable</code> or <code>array</code> index (see Arrays), the <code>+=</code> operator can be used to append to or add to the variable’s previous value.</p>
</blockquote>
<p>Using <code>&quot;${array[@]}&quot;</code>(have double quotes) in for loop to fetch array item.</p>
<h1 id="Create-Associated-Array"><a href="#Create-Associated-Array" class="headerlink" title="Create Associated Array"></a>Create Associated Array</h1><p><code>declare</code> is the only way to go, see reference for more details. Actually this is Map in shell script.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## create all at once</span></span><br><span class="line"><span class="built_in">declare</span> -A array=([a]=xx [b]=yy [c]=zz)</span><br><span class="line"><span class="comment">## create separately</span></span><br><span class="line"><span class="built_in">declare</span> -A array</span><br><span class="line">array[a]=xx</span><br><span class="line">array[b]=yy</span><br><span class="line">array[c]=zz</span><br></pre></td></tr></table></figure></p>
<p>iterate over the associated array:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## The keys are accessed using an exclamation point</span></span><br><span class="line"><span class="keyword">for</span> key <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;!array[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"key  : <span class="variable">$key</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"value: <span class="variable">$&#123;array[$key]&#125;</span>"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## assign all keys to other array</span></span><br><span class="line">array2=(<span class="string">"<span class="variable">$&#123;!array[@]&#125;</span>"</span>)</span><br></pre></td></tr></table></figure></p>
<h1 id="Caveat"><a href="#Caveat" class="headerlink" title="Caveat"></a>Caveat</h1><p>If you use <code>declare -a</code> or <code>declare -A</code> to create array in shell function, it by default is <strong>local scope</strong> in that function. You can move the <code>declare</code> out to make the array globally access, or use <code>declare -ga</code> and `declare -gA (<strong>only bash 4.2 and later support this</strong>).</p>
<p>Assign array to other variables:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">a=(<span class="string">'a'</span> <span class="string">'b'</span> <span class="string">'c'</span>)</span><br><span class="line"><span class="comment">## must have double qoutes to protect key that has whitespace</span></span><br><span class="line">b=(<span class="string">"<span class="variable">$&#123;a[@]&#125;</span>"</span>)</span><br></pre></td></tr></table></figure></p>
<p>Notice that you <strong>cannot</strong> <code>export</code> array directly. <code>Array variables may not (yet) be exported.</code> in some bash verions, but there are some workarounds.</p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p><a href="https://www.artificialworlds.net/blog/2012/10/17/bash-associative-array-examples/" target="_blank" rel="noopener">Bash associative array examples</a><br><a href="https://www.artificialworlds.net/blog/2013/09/18/bash-arrays/" target="_blank" rel="noopener">Bash indexed arrays</a><br><a href="https://linuxconfig.org/how-to-use-arrays-in-bash-script" target="_blank" rel="noopener">Indexed and associative array</a></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Asynchronous Processes</title>
    <url>/2019/05/29/shell-async-process/</url>
    <content><![CDATA[<p>I feel terrible today since I find a bug in the script I wrote several months ago! </p>
<p>Sometimes when I run some time-consuming tasks I want to make them execute parallelly to improve the CPU utilization and reduce execution time (if the machine is multi-core or multi-processing unit)</p>
<p>Let’s talk about different patterns to do that in shell script, for example, I have scripts:<br><code>back.sh</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">tail -f /dev/null</span><br></pre></td></tr></table></figure></p>
<p><code>hello.sh</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"====== hello"</span></span><br><span class="line"><span class="built_in">exit</span> 0</span><br></pre></td></tr></table></figure></p>
<h2 id="Wait-for-all-background-tasks"><a href="#Wait-for-all-background-tasks" class="headerlink" title="Wait for all background tasks"></a>Wait for all background tasks</h2><p>In <code>main.sh</code>, if:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">declare</span> -a nums=(1 2 3)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;nums[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  ./hello.sh &amp;</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"###### PID is $!"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">wait</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"done!"</span></span><br></pre></td></tr></table></figure></p>
<p>you will get the result like this, only get <code>done!</code> after all background processes finished:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">###### PID is 11649</span><br><span class="line">###### PID is 11650</span><br><span class="line">###### PID is 11651</span><br><span class="line">====== hello</span><br><span class="line">====== hello</span><br><span class="line">====== hello</span><br><span class="line">done!</span><br></pre></td></tr></table></figure></p>
<p>But if the <code>main.sh</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./back.sh &amp;</span><br><span class="line"><span class="built_in">declare</span> -a nums=(1 2 3)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;nums[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  ./hello.sh &amp;</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"###### PID is $!"</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">wait</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"done!"</span></span><br></pre></td></tr></table></figure></p>
<p>The <code>wait</code> will hold on until all background tasks complete, you will never see <code>done!</code> because back.sh will never exit. Have to use <code>kill</code> command to kill it.</p>
<p>The improved way is to only pass related PIDs to wait, so scheduler will not care unrelated background task <code>back.sh</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">declare</span> -a nums=(1 2 3)</span><br><span class="line"><span class="built_in">declare</span> -a pids</span><br><span class="line">./back.sh &amp;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;nums[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  ./hello.sh &amp;</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"###### PID is $!"</span></span><br><span class="line">  pids+=($!)</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">wait</span> <span class="variable">$&#123;pids[@]&#125;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"done!"</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Wait-background-task-in-arbitrary-order"><a href="#Wait-background-task-in-arbitrary-order" class="headerlink" title="Wait background task in arbitrary order"></a>Wait background task in arbitrary order</h2><p>This way is very similar to above example, but we wait individually.</p>
<p>In <code>main.sh</code>, write:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">declare</span> -a nums=(1 2 3)</span><br><span class="line"><span class="built_in">declare</span> -a pids</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;nums[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"> ./hello.sh &amp;</span><br><span class="line"> <span class="built_in">echo</span> <span class="string">"###### PID is $!"</span></span><br><span class="line"> pids[<span class="variable">$&#123;n&#125;</span>]=$! <span class="comment">## pids[n]=$! also works</span></span><br><span class="line"> <span class="built_in">let</span> n+=1</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pid <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;pids[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">wait</span> <span class="variable">$&#123;pid&#125;</span>; <span class="keyword">then</span></span><br><span class="line">    <span class="comment">## success</span></span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="comment">## fail</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"done!"</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that don’t forget the <code>let n+=1</code></p>
</blockquote>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>Acutally there is a <code>jobs</code> command can deal with the background processes:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ./back.sh  &amp;</span></span><br><span class="line">[1] 15405</span><br><span class="line"><span class="comment"># jobs</span></span><br><span class="line">[1]+  Running                 ./back.sh &amp;</span><br><span class="line"><span class="comment"># jobs -p</span></span><br><span class="line">15405</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenShift RBAC</title>
    <url>/2020/02/20/openshift-rbac/</url>
    <content><![CDATA[<p>OpenShift version: <code>4.3</code></p>
<p>OpenShift current is evolved to version <code>4.3</code> (last time when I was working on it, it was version <code>3.11</code>), I am assigned to try non-root install for DS assembly (a plugin) in CP4D cluster. what non-root means<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">No cluster admin privileges</span><br><span class="line">No root processes in containers</span><br><span class="line">No host access or ssh requirements</span><br><span class="line">No elevated SCCs (other than the cpd defaults)</span><br></pre></td></tr></table></figure></p>
<p>We have met last 3 requirements, so focus on first one.</p>
<p>After doing research, the steps are clear but not that straightforward (相比3.11目前版本的配置变化还挺大的，支持的内容更丰富了)</p>
<ol>
<li>Create regular user</li>
<li>Specify identity provider for OAuth</li>
<li>Bind necessary cluster role or local role</li>
<li>Run installation</li>
</ol>
<p>4.3版本的一大变化是kubeadmin是默认的cluster-admin user，如同之前的systemadmin, kubeadmin is treated as the root user for the cluster. The password is dynamically generated and unique to your OpenShift Container Platform environment.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc login -u kubeadmin -p IVfPS-FvJZI-Vagzw-nIpVA --server=https://api.dsocp43.os.fyre.ibm.com:6443</span><br></pre></td></tr></table></figure></p>
<p>password is provided in output when install is done，记下来就行，之前3.11 systemadmin是不需要password login的。</p>
<h2 id="Create-user-and-specify-identity-provider"><a href="#Create-user-and-specify-identity-provider" class="headerlink" title="Create user and specify identity provider"></a>Create user and specify identity provider</h2><p><a href="https://docs.openshift.com/container-platform/4.3/authentication/understanding-identity-provider.html" target="_blank" rel="noopener">Understanding identity provider configuration</a>。<br>By default, only a kubeadmin user exists on your cluster. To specify an identity provider, you must create a Custom Resource (CR) that describes that identity provider and add it to the cluster.</p>
<p>这里我选择htpasswd当作identity provider, <a href="https://docs.openshift.com/container-platform/4.3/authentication/identity_providers/configuring-htpasswd-identity-provider.html" target="_blank" rel="noopener">Configuring an HTPasswd identity provider</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## htpasswd -c -B -b &lt;/path/to/users.htpasswd&gt; &lt;user_name&gt; &lt;password&gt;</span></span><br><span class="line">htpasswd -c -B -b ~/.htpasswd demo demo</span><br></pre></td></tr></table></figure></p>
<p>Then create htpasswd secret:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc create secret generic htpass-secret --from-file=htpasswd=~/.htpasswd -n openshift-config</span><br></pre></td></tr></table></figure></p>
<p>Create Custom Resource and add it to cluster<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">config.openshift.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">OAuth</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  identityProviders:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">my_htpasswd_provider</span> </span><br><span class="line"><span class="attr">    mappingMethod:</span> <span class="string">claim</span> </span><br><span class="line"><span class="attr">    type:</span> <span class="string">HTPasswd</span></span><br><span class="line"><span class="attr">    htpasswd:</span></span><br><span class="line"><span class="attr">      fileData:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">htpass-secret</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc apply -f &lt;yaml file&gt;</span><br></pre></td></tr></table></figure>
<p>Verify:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc login -u demo -p demo</span><br><span class="line">oc whoami</span><br></pre></td></tr></table></figure></p>
<h2 id="Bind-cluster-role-or-local-role"><a href="#Bind-cluster-role-or-local-role" class="headerlink" title="Bind cluster role or local role"></a>Bind cluster role or local role</h2><p><a href="https://docs.openshift.com/container-platform/4.3/authentication/using-rbac.html" target="_blank" rel="noopener">Using RBAC to define and apply permissions</a>. Cluster administrators can use the cluster roles and bindings to control who has various access levels to the OpenShift Container Platform platform itself and all projects.</p>
<p>Use <code>kubeadmin</code> to create custom cluster role or local role and bind<br>目前为止<code>demo</code> user只能对自己创建的project都基本的project admin权限，如果要想操作其他project的内容，可以local bind一个project admin:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">oc adm policy add-role-to-user admin demo -n &lt;target project&gt;</span><br></pre></td></tr></table></figure></p>
<p>如果需要access其他resource，比如：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ERROR] [2020-02-19 15:19:21-0617] Error verifying current oauth token - Error from server (Forbidden): </span><br><span class="line">oauthaccesstokens.oauth.openshift.io &quot;XKRLOq8286U3YnRbf6lsv99Uk2rD1A6wanNVxgp5NNs&quot; is forbidden:</span><br><span class="line">User &quot;demo&quot; cannot get resource &quot;oauthaccesstokens&quot; in API group &quot;oauth.openshift.io&quot; at the cluster scope</span><br></pre></td></tr></table></figure></p>
<p>这里提示user <code>demo</code> cannot get resource <code>oauthaccesstokens</code> at the cluster scope, 我们可以先根据这个resource创建一个cluster role，然后bind it to user demo. 创建cluster role时可以指定操作，verb有get, list, create, delete, patch, watch, deletecollection。然后把创建好的cluster role 用cluster role binding 绑定到demo上:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## new custom custerrole oauthaccesstokens</span></span><br><span class="line">oc create clusterrole oauthaccesstoken_custom \</span><br><span class="line">  --verb=get,list,create,delete,patch,watch \</span><br><span class="line">  --resource=oauthaccesstokens</span><br><span class="line">oc adm policy add-cluster-role-to-user oauthaccesstoken_custom demo</span><br></pre></td></tr></table></figure></p>
<p>Check OpenShift Web can see what exactly bindings are there for user <code>demo</code>，这样就很方便了。</p>
]]></content>
      <categories>
        <category>OpenShift</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>openshift</tag>
      </tags>
  </entry>
  <entry>
    <title>BASH Pipeline Demo</title>
    <url>/2019/02/24/shell-pipeline/</url>
    <content><![CDATA[<p>This blog reformats and builds on top of this <em>stackoverflow</em> <a href="https://unix.stackexchange.com/questions/30759/whats-a-good-example-of-piping-commands-together" target="_blank" rel="noopener">topic</a>. Big thanks to <strong>rahmu</strong> and people contributed.</p>
<h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>Let’s say the command <code>conky</code> stopped responding on my desktop, and I want to kill it manually. I know a little bit of Unix, so I know that what I need to do is execute the command <code>kill &lt;PID&gt;</code>. In order to retrieve the PID, I can use <code>ps</code> or <code>top</code> or whatever tool my Unix distribution has given me. But how can I do this in one command?</p>
<h3 id="Answer"><a href="#Answer" class="headerlink" title="Answer"></a>Answer</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps aux | grep conky | grep -v grep | awk <span class="string">'&#123;print $2&#125;'</span> | xargs <span class="built_in">kill</span></span><br></pre></td></tr></table></figure>
<p><em>DISCLAIMER</em>: This command only works in certain cases. Don’t copy/paste it in your terminal and start using it, it could kill processes unsuspectingly. Rather learn <strong>how to build it</strong>.</p>
<h3 id="How-it-works"><a href="#How-it-works" class="headerlink" title="How it works"></a>How it works</h3><ul>
<li><strong><code>ps aux</code></strong></li>
</ul>
<p>This command will output the list of running processes and some info about them. The interesting info is that it’ll output the PID of each process in its 2nd column. Here’s an extract from the output of the command on my box:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ps aux</span><br><span class="line"> rahmu     1925  0.0  0.1 129328  6112 ?        S    11:55   0:06 tint2</span><br><span class="line"> rahmu     1931  0.0  0.3 154992 12108 ?        S    11:55   0:00 volumeicon</span><br><span class="line"> rahmu     1933  0.1  0.2 134716  9460 ?        S    11:55   0:24 parcellite</span><br><span class="line"> rahmu     1940  0.0  0.0  30416  3008 ?        S    11:55   0:10 xcompmgr -cC -t-5 -l-5 -r4.2 -o.55 -D6</span><br><span class="line"> rahmu     1941  0.0  0.2 160336  8928 ?        Ss   11:55   0:00 xfce4-power-manager</span><br><span class="line"> rahmu     1943  0.0  0.0  32792  1964 ?        S    11:55   0:00 /usr/lib/xfconf/xfconfd</span><br><span class="line"> rahmu     1945  0.0  0.0  17584  1292 ?        S    11:55   0:00 /usr/lib/gamin/gam_server</span><br><span class="line"> rahmu     1946  0.0  0.5 203016 19552 ?        S    11:55   0:00 python /usr/bin/system-config-printer-applet</span><br><span class="line"> rahmu     1947  0.0  0.3 171840 12872 ?        S    11:55   0:00 nm-applet --sm-disable</span><br><span class="line"> rahmu     1948  0.2  0.0 276000  3564 ?        Sl   11:55   0:38 conky -q</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong><code>grep conky</code></strong></li>
</ul>
<p>I’m only interested in one process, so I use <code>grep</code> to find the entry corresponding to my program <code>conky</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ps aux | grep conky</span><br><span class="line"> rahmu     1948  0.2  0.0 276000  3564 ?        Sl   11:55   0:39 conky -q</span><br><span class="line"> rahmu     3233  0.0  0.0   7592   840 pts/1    S+   16:55   0:00 grep conky</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong><code>grep -v grep</code></strong></li>
</ul>
<p>As you can see in step 2, the command ps outputs the <code>grep conky</code> process in its list (it’s a running process after all). In order to filter it, I can run <code>grep -v grep</code>. The option<code>-v</code> tells grep to match all the lines excluding the ones containing the pattern.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ps aux | grep conky | grep -v grep</span><br><span class="line"> rahmu     1948  0.2  0.0 276000  3564 ?        Sl   11:55   0:39 conky -q</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong><code>awk &#39;{print $2}&#39;</code></strong></li>
</ul>
<p>Now that I have isolated my target process. I want to retrieve its PID. In other words I want to retrieve the 2nd word of the output. Lucky for me, most (all?) modern unices will provide some version of <code>awk</code>, a scripting language that does wonders with tabular data. Our task becomes as easy as <code>print $2</code>.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ ps aux | grep conky | grep -v grep | awk <span class="string">'&#123;print $2&#125;'</span></span><br><span class="line"> 1948</span><br></pre></td></tr></table></figure></p>
<ul>
<li><strong><code>xargs kill</code></strong></li>
</ul>
<p>I have the PID. All I need is to pass it to <code>kill</code>. To do this, I will use <code>xargs</code>.</p>
<p><code>xargs kill</code> will read from the input (in our case from the pipe), form a command consisting of <code>kill &lt;items&gt;</code> (<code>&lt;items&gt;</code> are whatever it read from the input), and then execute the command created. In our case it will execute <code>kill 1948</code>. Mission accomplished.</p>
<h3 id="Final-words"><a href="#Final-words" class="headerlink" title="Final words"></a>Final words</h3><p>Note that depending on what version of unix you’re using, certain programs may behave a little differently (for example, <code>ps</code> might output the PID in column $3). If something seems wrong or different, read your vendor’s documentation (or better, the man pages). Also be careful as <strong>long pipes can be dangerous</strong>. Don’t make any assumptions especially when using commands like <code>kill</code> or <code>rm</code>. For example, if there was another user named ‘conky’ (or ‘Aconkyous’) my command may kill all his running processes too!</p>
<h3 id="Complement"><a href="#Complement" class="headerlink" title="Complement"></a>Complement</h3><p>actually you can simplify the pipeline further to<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pkill conky</span><br></pre></td></tr></table></figure></p>
<p>or<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">kill</span> $(pgrep conky)</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Login and Nonlogin Shell</title>
    <url>/2019/05/27/shell-login-nonlogin/</url>
    <content><![CDATA[<p>More information please see <code>man bash</code> (contains <code>if</code> condition syntax).</p>
<p>In the non-root development for DataStage, in order to launch applications as non-root user, I use <code>su - dsadm</code> with following commands. Later I occassionally notice that badal use <code>su dsadm</code>… So what are the differences?</p>
<p>There are two main shell instance types: <code>interactive</code> and <code>noninteractive</code>, but of those, only interactive shells are of interest because noninteractive shells (such as those that run shell scripts) usually don’t read any startup files. </p>
<p><code>Interactive shells</code> are the ones that you use to <strong>run commands from a terminal</strong>, they can be classified as <code>login</code> or <code>non-login</code>. I know there are lots of startup files under each user’s home directory, how do they be called and in what order?</p>
<h2 id="Login-Shell"><a href="#Login-Shell" class="headerlink" title="Login Shell"></a>Login Shell</h2><p>Logging in remotely with <code>SSH</code> will give you a login shell.</p>
<p>You can tell if a shell is a login shell by running <code>echo $0</code>; if the first character is a <code>-</code>, the shell’s a login shell.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## if not sure it's login or non-login, check it</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$0</span></span><br><span class="line">-bash</span><br></pre></td></tr></table></figure></p>
<p>When Bash is invoked as a <code>Login</code> shell:</p>
<ol>
<li>Login process calls <code>/etc/profile</code> (this is for all users)</li>
<li><code>/etc/profile</code> calls the scripts in <code>/etc/profile.d/</code></li>
<li>Login process calls <code>$HOME/.bash_profile</code>, <code>$HOME/.bash_login</code> and <code>$HOME/.profile</code> in order, the first found file is run and rest are ignored, most Linux distributions use only one or two of these four startup files. Notice that <code>$HOME/.bashrc</code> are not in the list, it typically run from one of these files.</li>
</ol>
<p>Login Shells created by explicitly telling to login, there is a <code>-</code> or <code>-l</code> flag:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su -</span><br><span class="line">su -l</span><br><span class="line">su --login</span><br><span class="line">su USERNAME - </span><br><span class="line">su -l USERNAME</span><br><span class="line">su --login USERNAME</span><br><span class="line">sudo -i</span><br></pre></td></tr></table></figure></p>
<h2 id="Non-login-Shell"><a href="#Non-login-Shell" class="headerlink" title="Non-login Shell"></a>Non-login Shell</h2><p>When bash is invoked as a <code>Non-login</code> shell (for example, you just run <code>bash</code> or <code>sh</code> without login):<br>如果先ssh进入系统，再运行<code>bash</code>，则就是non-login shell了。</p>
<ol>
<li>Non-login process(shell) calls <code>/etc/bashrc</code></li>
<li>then calls <code>$HOME/.bashrc</code> (remember!)</li>
</ol>
<p><code>Non-Login</code> shells created using the below commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su</span><br><span class="line">su USERNAME</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Of course you can source <code>$HOME/.bashrc</code> in <code>$HOME/.bash_profile</code> files to satisfy both login and non-login shell, for example: add <code>. $HOME/.bashrc</code> in <code>$HOME/.bash_profile</code> (it’s usually there by default setting).</p>
</blockquote>
<p>The reasoning behind the two different startup filesystems is that in the old days, users logged in through a traditional terminal with a <code>login shell</code>, then started <code>non-login</code> subshells with windowing systems or the screen program. For the <code>non-login</code> subshells, it was deemed a waste to repeatedly set the user environment and run a bunch of programs that had already been run. With login shells, you could run fancy startup commands in a file such as <code>.bash_profile</code>, leaving only aliases and other “lightweight” things to your <code>.bashrc</code>.</p>
<p>This can explain that if you use non-login like <code>su dsadm</code>, the parent exported environment variables are still there in <code>env</code> scope. But if you run <code>su - dsadm</code>, the parent exported environment variables are gone.</p>
<h2 id="Bash-Parameters"><a href="#Bash-Parameters" class="headerlink" title="Bash Parameters"></a>Bash Parameters</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Make bash act as if it had been invoked as a login shell</span></span><br><span class="line"><span class="comment">## 但实际上并不是真正的login shell, echo $0 可知</span></span><br><span class="line">bash --login</span><br><span class="line">bash -l</span><br><span class="line"></span><br><span class="line"><span class="comment">## -c: string If the -c option is present, then commands are read from string.</span></span><br><span class="line"><span class="comment">## If there are arguments after the string</span></span><br><span class="line"><span class="comment">## they are assigned to the positional parameters, starting with $0.</span></span><br><span class="line"><span class="comment">## 这就不是interactive shell了</span></span><br><span class="line">bash -c /tmp/test.sh hello world!</span><br><span class="line"></span><br><span class="line"><span class="comment">## do not run ~/.bashrc, by default same as `sh`</span></span><br><span class="line">bash --norc</span><br><span class="line"></span><br><span class="line"><span class="comment">## 这个只对login shell才有用，不进行任何初始化</span></span><br><span class="line">bash --noprofile</span><br><span class="line"></span><br><span class="line"><span class="comment">## specify other script to replace .bashrc</span></span><br><span class="line">bash --rcfile &lt;path to file&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## do syntax check only</span></span><br><span class="line">bash -n &lt;script&gt;</span><br></pre></td></tr></table></figure>
<p>Interesting question:<br><a href="https://stackoverflow.com/questions/9357464/how-to-start-a-shell-without-any-user-configuration" target="_blank" rel="noopener">How to start a shell in clean</a></p>
<p><code>~/.bash_logout</code> will be executed when exit login shell.</p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>shell-prompt-color</title>
    <url>/2019/07/23/shell-prompt-color/</url>
    <content><![CDATA[<p>PS1 customized<br><a href="https://www.youtube.com/watch?v=LXgXV7YmSiU" target="_blank" rel="noopener">https://www.youtube.com/watch?v=LXgXV7YmSiU</a></p>
<p>command prompt color<br>[time] user@host shell basedir: …<br>icon?</p>
<p>echo color..</p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Source vs Execute Script</title>
    <url>/2019/05/07/shell-source-vs-execute/</url>
    <content><![CDATA[<p>Understand the difference between <code>source</code> and execute a script is important, otherwise you will be confused why something doesn’t run as you expect.</p>
<h2 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h2><p>The file need <strong>not</strong> to be a executable but should be valid shell script. We usually use <code>source</code> to load shell functions and export environment variables into current shell process.</p>
<p>For example, both syntax are good:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">source</span> ./xx.env</span><br><span class="line">. ./xx.env</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>.</code> is not an alias for <code>source</code>, but rather the other way around. <code>source</code> is a bash extension, while <code>.</code> works in any POSIX compatible shell.</p>
</blockquote>
<p>You can also put the file path in <code>$PATH</code> so that you don’t need to specify the path in command.</p>
<h2 id="Execute"><a href="#Execute" class="headerlink" title="Execute"></a>Execute</h2><p>The file need to be <strong>executable</strong> and you are in right permission to run it. And you need to specify the path even in current directory, or put path in <code>$PATH</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./xx.sh</span><br></pre></td></tr></table></figure></p>
<p>The current shell spawned a new shell to run the script. The script is running in the new shell and all changes to the environment take effect only in the new shell. After the script is done all changes to the environment in the new shell are destroyed.</p>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Use execution will run the script as another process, so variables and functions in calling script will not be accessible in parent process. </p>
<p>The <code>source</code> method executes the script in the parent script’s process, and pulls in variables and functions from the other script so they are usable from the calling script.</p>
<p>If you are using <code>exit</code> in script, it will exit the parent script as well. Which will not happen in execution method.</p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell Script Template</title>
    <url>/2019/09/14/shell-script-template/</url>
    <content><![CDATA[<p>I think this is a good script template, it has exit hook, logs and json response. I will continuously update it if I find good patterns.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#########################################################################</span></span><br><span class="line"><span class="comment"># Please insert the update at top of the logs</span></span><br><span class="line"><span class="comment"># Date           Author           Description</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#########################################################################</span></span><br><span class="line"><span class="comment">#set -x</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## find canonical file path</span></span><br><span class="line"><span class="comment">## or you can restrict run script in it's current directory</span></span><br><span class="line">CUR_PATH=$(dirname $(readlink -f <span class="variable">$0</span>))</span><br><span class="line"><span class="built_in">source</span> <span class="variable">$CUR_PATH</span>/&lt;env file&gt;</span><br><span class="line">JQ=<span class="string">"<span class="variable">$CUR_PATH</span>/jq"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## create log file for this script</span></span><br><span class="line">OUT_FILE=$(mktemp /tmp/log.XXXX)</span><br><span class="line"><span class="comment">#OUT_FILE=/tmp/log</span></span><br><span class="line"></span><br><span class="line"><span class="comment">########################### function #########################</span></span><br><span class="line"><span class="keyword">function</span> exitHook &#123;</span><br><span class="line">  rm -f <span class="variable">$OUT_FILE</span></span><br><span class="line">  rm -f <span class="variable">$&#123;OUT_FILE&#125;</span>.out</span><br><span class="line">  rm -f <span class="variable">$&#123;OUT_FILE&#125;</span>.err</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">## clean job for log file, you can add other signals</span></span><br><span class="line"><span class="built_in">trap</span> exitHook EXIT</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">usage</span></span>() &#123;</span><br><span class="line"> <span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span>  xxx"</span></span><br><span class="line"> <span class="built_in">echo</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## this is for return json format messages</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">returnError</span></span>() &#123;</span><br><span class="line">  msg=<span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"&#123;\"result\": \"Failure\", \"message\": \"<span class="variable">$msg</span>\"&#125;"</span> |<span class="variable">$&#123;JQ&#125;</span> <span class="string">'.'</span></span><br><span class="line">  <span class="built_in">exit</span> 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">returnInfo</span></span>() &#123;</span><br><span class="line">  msg=<span class="string">"<span class="variable">$1</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"&#123;\"result\": \"Success\", \"message\": \"<span class="variable">$msg</span>\"&#125;"</span> |<span class="variable">$&#123;JQ&#125;</span> <span class="string">'.'</span></span><br><span class="line">  <span class="built_in">exit</span> 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">########################## main ##############################</span></span><br><span class="line"><span class="comment">## declare input parameters</span></span><br><span class="line">P1=<span class="string">""</span></span><br><span class="line">P2=<span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## check script parameters</span></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -eq 0 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">  msg=<span class="string">"No command-line arguments were specified..."</span></span><br><span class="line">  returnError <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> [ <span class="variable">$#</span> -gt 0 ]</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">    -p1)</span><br><span class="line">       <span class="built_in">shift</span></span><br><span class="line">       P1=<span class="variable">$1</span></span><br><span class="line">       <span class="built_in">shift</span>;;</span><br><span class="line"></span><br><span class="line">    -p2)</span><br><span class="line">       <span class="built_in">shift</span></span><br><span class="line">       P2=<span class="variable">$1</span></span><br><span class="line">       <span class="built_in">shift</span>;;</span><br><span class="line"></span><br><span class="line">    *) msg=<span class="string">"<span class="variable">$0</span>: Bad Usage..."</span></span><br><span class="line">       returnError <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line">  <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## double check or restrict parameters</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">"X<span class="variable">$&#123;P1&#125;</span>"</span> = <span class="string">"X"</span> ]]; <span class="keyword">then</span></span><br><span class="line">  msg=<span class="string">"-p1 was not specified"</span></span><br><span class="line">  returnError <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line"><span class="keyword">elif</span> [[ <span class="string">"X<span class="variable">$&#123;P2&#125;</span>"</span> = <span class="string">"X"</span> ]]; <span class="keyword">then</span></span><br><span class="line">  msg=<span class="string">"-p2 was not specified"</span></span><br><span class="line">  returnError <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## then do the job, when you run some commands in script </span></span><br><span class="line"><span class="comment">## you can redirect the normal output to $&#123;OUT_FILE&#125;.out</span></span><br><span class="line"><span class="comment">## and error output to $&#123;OUT_FILE&#125;.err</span></span><br><span class="line"><span class="built_in">command</span> 1&gt;&gt;<span class="variable">$&#123;OUT_FILE&#125;</span>.out 2&gt;&gt;<span class="variable">$&#123;OUT_FILE&#125;</span>.err</span><br><span class="line"><span class="keyword">if</span> [[ $? = 0 ]]; <span class="keyword">then</span></span><br><span class="line">    msg=<span class="string">"Run command successfully..."</span></span><br><span class="line">    returnInfo <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="comment">## parse err log file and return message</span></span><br><span class="line">    msg=$(cat <span class="variable">$&#123;OUT_FILE&#125;</span>.err|sed -e <span class="string">'s/"/\\"/g'</span>)</span><br><span class="line">    returnError <span class="string">"<span class="variable">$msg</span>"</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Daily Talk</title>
    <url>/2019/04/11/softskill-daily-talk/</url>
    <content><![CDATA[<blockquote>
<p>04/30/2020 目前来看，感受是我的职业发展一大障碍并不是技术，而是soft skills，比如如何高效直接又不失礼貌的<strong>沟通</strong> (not just what you say but how you say it!!!)，how to email, phone call effectively，如何协作多个团队以及个人，以及管理一个团队(interpersonal skill)。PluralSight上这方面的课程很不错，也有一些BQ相关的书籍需要阅读。总之，这非常重要！</p>
</blockquote>
<h1 id="Dialog"><a href="#Dialog" class="headerlink" title="Dialog"></a>Dialog</h1><h2 id="Dail-in"><a href="#Dail-in" class="headerlink" title="Dail in"></a>Dail in</h2><p>(not hear clearly) Sorry, I miss some points. I didn’t hear you.<br>Are your voice broken?</p>
<p>Who do we have on the call?<br>Do you want to go first?</p>
<p>This is from SVL, we have x1 x2 and myself, we are waiting for x3 to dail in.<br>only three of us here</p>
<p>go ahead badal…<br>we are waiting for more folks to join.</p>
<p>xx is on her way.<br>Even I saw her.</p>
<h2 id="Describe-Problem"><a href="#Describe-Problem" class="headerlink" title="Describe Problem"></a>Describe Problem</h2><p>obscure problems came up.</p>
<p>some of the files must have setuid bit set in order to function properly.<br>run something without killing my setuid bit?<br>Jaijeet can take the topic.</p>
<p>(别再说 I don’t know了😂)<br>it’s unknown to me.<br>It’s a complete black box to me.<br>I don’t have answer to this question.<br>I don’t have answer to all of these now.<br>I cannot make any promise now.<br>It’s hard to have a binary answer yes or no.</p>
<p>I ran into the same issue.<br>I don’t want to clutter/mess up the cluster…<br>Is there any workaround for this?</p>
<p>let us talk over on this on monday - seems convoluted (费解的).</p>
<p>not sure it’s possible or not</p>
<p>So what happends right now …<br>what happening is that …<br>How come the output file is missing ..</p>
<p>Let me know if any issues.<br>What is your opinion Badal?</p>
<p>Elaborate the reason, open the git issue if necessary. We need to understand the problem exactly.</p>
<p>I would say don’t do that.<br>we do have this fix.<br>I will take a look at it today.</p>
<p>They didn’t articulate what need to test.</p>
<p>I haven’t got time to stay with Deep to discuss…<br>That’s what I am discussing with you.<br>We don’t have anything to lose.</p>
<p>we are still facing the issue.<br>Something is failing intermittently, hard to figure it out what is the problem.</p>
<p>What am I supposed to conclude?</p>
<p>I take what I said back.<br>I am still struggleing myself for this issue.</p>
<p>Nothing is working, we need to engage UI team,  API team.<br>I am able to open the defect (ticket/issue) but not able to assign.</p>
<p>It is much easier said then done.<br>It is a big list <code>but by no means</code> it is a exhausted list</p>
<p>Make sure that it stays a useful tool and doesn’t become a maintenance headache/nightmare.</p>
<p>check out(pull)/in(push) the code (github).</p>
<p>Other things are more or less similar.</p>
<h2 id="Progress"><a href="#Progress" class="headerlink" title="Progress"></a>Progress</h2><p>Give me 1 hour please, in the middile of something.</p>
<p>I have some pending items.</p>
<p>It’s a overkill for me.</p>
<p>I was primarily working on …<br>I would suggest…</p>
<p>I did’t make much progress yesterday.</p>
<p>I am going to mimic what you did.<br>I will continue on the effort to …</p>
<p>we need to do that standalone..<br>I haven’t started, it will not take too long.</p>
<p>Kannu covered a lot we did last week.</p>
<p>This is a <code>ad hoc task</code>. (Ad hoc tasks are work items that can be created extemporaneously that are not initially part of a modeled process flow)</p>
<p>Anything else on your side?</p>
<p>That is my status.<br>That is all in my side.</p>
<p>(什么时候完成?)<br>When do you think you can put these in place?</p>
<p>This is our major block.<br>We plan to finish it by 8/28 or schedule need to be extended.<br>Please let me know ASAP as I have to report to …</p>
<p>I am done, can I go/drop?<br>The things left for me are …<br>it’s not <code>urgent</code>.</p>
<p>I will let someone know and ask .. so we get <code>immidiate attention</code>.<br>more or less the same<br>Is this still something that needs attention? It is unclear from the comments. Pl advise.<br>Also DM(direct message) me the cluster info if this still needs attention.</p>
<p>I need to go back and see all the notes.<br>go over your notes</p>
<p>There may be some potential issues we cannot see right now.<br>To be complete, let me mention …</p>
<h2 id="Office-Talk"><a href="#Office-Talk" class="headerlink" title="Office Talk"></a>Office Talk</h2><p>outline sth.<br>iterating over time 如此往复..</p>
<p>sth is discernable in .. 有迹可循</p>
<p>I will sync up/ set with you later…<br>We are on the same page now.<br>Hopefully we can walk through the doc and fill in the existing gaps and identify any others.</p>
<p>I’m not familiar with this.. I’ll have a look later today and will let you know if I figure out how it works.</p>
<p>强硬催人:<br>Sorry for the push. When you have some time - please do check and let us know.<br>Please let know.<br>Any luck with someone?</p>
<p>I just stop by.<br>can you come over?</p>
<p>Hi chengdol, can you come to my office for a sec?</p>
<p>My bad for not being clear, I was specifically asking about<br>Apologize for the long delay…</p>
<p>One query, …</p>
<p>if you have bandwidth you can start to work on ….</p>
<p>Can you give me a quick overview about …, share with us.</p>
<p>Distracted by the conversations…<br>will find comfort room to dail in</p>
<p>Thanks, this is a big call.<br>Appreciate someone’s services to something.</p>
<p>we have a hard stop at 11:00AM (for meeting)</p>
<p>you raise/give a bunch of information..</p>
<p>can I drop off（挂断） or stay here?<br>This issue sometime surfaces.</p>
<p>Is your system back on line?<br>Getting system up today.</p>
<p>users are allowed to elevate their privileges to root.<br>we don’t want to escalate this..</p>
<p>I get lost at this part.. I feel a little bit abstract on .<br>please don’t deviate my question.<br>I don’t know whether .. will fit in.</p>
<p>Make sense?<br>He can leverage me when thing is not going</p>
<p>Nevermind I got what I needed (问了问题别人还没回答自己找到答案了)</p>
<p>who may know better on this.</p>
<p>(别人说了sorry什么的)<br>That’s OK.</p>
<h2 id="Issue"><a href="#Issue" class="headerlink" title="Issue"></a>Issue</h2><p>This issue doesn’t appear to be related to xxx,  but an underlying xxx issue with networking..</p>
<p>We should <code>investigate</code> why the network performance is so bad.</p>
<p>This likely also explains some of the poor performance seen for the NFS mounts.</p>
<p>I’m going to remove my name from this one as the software appears to be functioning as designed, but is limited by the underlying infrastructure. </p>
<p>If addition information comes up and anything else you want me to look at let me know.<br>Per previous discussion, assigning this to you for now.</p>
<p>Not mission critical.<br>incurs/introduces overhead.</p>
<p>provide context and a shared language to describe …</p>
<h2 id="Leaving"><a href="#Leaving" class="headerlink" title="Leaving"></a>Leaving</h2><p>We will be having farewell lunch for xx at xx on Monday, Febr 3rd. Let’s meet and wish him all the best in his new role and Thank him for all the GREAT work he did for our team.Please RSVP by Thursday.</p>
<p>Dear colleagues and friends, this Friday, Jan 24th will be my last day at xx, but this Is not a note to say good bye. This is a note to say thank you.<br>I am so thankful for my time here at xxx and for all of the wonderful people who have I have had the privilege to work with.<br>I have learned so much and been inspired by many of you over the years. I am so grateful for all the gifts the people of xx have given me and I can only hope in some way I have inspired some of you as well.<br>I take my leave from xx because of a unique opportunity to leverage all I have learned, and build some really cool xx solutions right here in my beloved Chicago. Leaving IBM and all the people I love here was the hard part, even with the exciting opportunity ahead of me.</p>
<p>All the best and was nice working with you.<br>whom can I reach to now, I mean your replacement.<br>please carry on the good work!</p>
]]></content>
      <categories>
        <category>Soft Skill</category>
      </categories>
      <tags>
        <tag>soft skill</tag>
        <tag>daily talk</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell timeout Command</title>
    <url>/2019/09/04/shell-timeout/</url>
    <content><![CDATA[<p><code>timeout</code> command used to run command with a time limit. One case is when you know exactly how long you want a process to run for. A common use-case is to have timeout control a logging or data-capture program so that the log files don’t relentlessly devour your hard drive space.</p>
<p>Another case is when you don’t know how long you want a process to run for, but you do know you don’t want it to run indefinitely. You might have a habit of setting processes running, minimizing the terminal window, and forgetting about them. For example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">timeout 12 ping 127.0.0.1</span><br></pre></td></tr></table></figure></p>
<p>By default 12 is second unit, to use a time value measured in minutes, hours or days add an <code>m</code>, <code>h</code> or a <code>d</code>.</p>
<h2 id="Send-Right-Signal"><a href="#Send-Right-Signal" class="headerlink" title="Send Right Signal"></a>Send Right Signal</h2><p>When <code>timeout</code> wants to stop a program it sends the <code>SIGTERM</code> signal. This politely asks the program to terminate. Some programs may choose to ignore the <code>SIGTERM</code> signal. When that happens, we need to tell timeout to be a little more forceful.</p>
<p>Send <code>KILL</code> signal if program is still running:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">timeout -s SIGKILL 10 sudo tcpdump &gt; capture.txt</span><br></pre></td></tr></table></figure></p>
<p>We can use the <code>-s (signal)</code> option to tell timeout to send the <code>SIGKILL</code> signal.</p>
<p>Or give it a buffer:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">timeout -k 20 10 sudo tcpdump &gt; capture.txt</span><br></pre></td></tr></table></figure></p>
<p>we use the <code>-k (kill after)</code> option. The <code>-k</code> option requires a time value as a parameter. If tcpdump is still running after 20 seconds, it means the <code>SIGTERM</code> was ignored and timeout should send in <code>SIGKILL</code> to finish the job.</p>
<h2 id="Retrieving-the-Program’s-Exit-Code"><a href="#Retrieving-the-Program’s-Exit-Code" class="headerlink" title="Retrieving the Program’s Exit Code"></a>Retrieving the Program’s Exit Code</h2><p><code>timeout</code> provides its own exit code, The exit code is <code>124</code>. This is the value timeout uses to indicate the program was terminated using SIGTERM.</p>
<p>But we may not care about that. We are probably more interested in the exit code from the process that timeout is controlling.</p>
<p>If the execution of the program ends <strong>before</strong> timeout terminates it, timeout <strong>can</strong> pass the exit code from the program back to the shell. (no need <code>--preserve-status</code>)</p>
<p>we must use the <code>--preserve-status</code> option if the program timeout but we still want to get its status exit code! For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">timeout --preserve-status 10 &lt;program&gt;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">##Start Engine Conductor</span></span><br><span class="line">LogMsg <span class="string">"Starting Engine Conductor Pod..."</span></span><br><span class="line">(<span class="built_in">cd</span> <span class="variable">$BASE</span>/Engine/engine-conductor; <span class="built_in">pwd</span>; ./createConductorDepAndSvc.sh <span class="variable">$NAME_SPACE</span> <span class="variable">$ENGINE_HOST</span>)</span><br><span class="line">check_return_code $?</span><br><span class="line">conductor_pod=$(kubectl get pods -n <span class="variable">$NAME_SPACE</span> | grep -i -E <span class="variable">$POD_STATES</span> | grep -v NAME|awk <span class="string">'&#123;print $1&#125;'</span>|grep <span class="variable">$ENGINE_HOST</span>)</span><br><span class="line"><span class="comment">##Check for Engine  background processes to complete</span></span><br><span class="line">timeout --preserve-status 3.0m cat &lt;(check_k8s_start_loop <span class="variable">$conductor_pod</span> 7 <span class="variable">$NAME_SPACE</span>)</span><br><span class="line">check_timeout_return $? <span class="variable">$conductor_pod</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>what is <code>cat &lt;()</code>?<br><code>a &lt;(b)</code> replaces the argument to <code>a</code> with an named pipe. <code>a</code> and <code>b</code> run in parallel. </p>
</blockquote>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Shell Process Demystify</title>
    <url>/2019/06/02/shell-subshell/</url>
    <content><![CDATA[<p>Understanding how <code>SHELL</code> works under the hood is a must for me, I have encountered several interesting and confusing issues in my daily work about <code>SHELL</code>. Let’s dive deeply into shell process and its relationships to explore how subshells are created and their relationship to the parent shell; The varied commands that create child processes are explored as well as built-in commands.</p>
<h2 id="Shell-Type"><a href="#Shell-Type" class="headerlink" title="Shell Type"></a>Shell Type</h2><p>Due to the <code>bash</code> shell’s popularity, it’s rare to use any other shell as a default shell.</p>
<p>The <code>default interactive shell</code> starts whenever a user logs into a virtual console terminal or starts a terminal emulator in the GUI. Another default shell, <code>/bin/sh</code>, is the <code>default system shell</code>. The <code>default system shell</code> is used for system shell scripts, such as those needed at startup.</p>
<p>In my Redhat and CentOS system, actually they are the same:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lrwxrwxrwx. 1 root root 4 Apr 13  2018 /bin/sh -&gt; bash</span><br></pre></td></tr></table></figure></p>
<p>To see the default user login shell, go to see <code>/etc/passwd</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fyre:x:1000:1000::/home/fyre:/bin/bash</span><br><span class="line">demo:x:1001:1001::/home/demo:/bin/bash</span><br></pre></td></tr></table></figure></p>
<h2 id="Shell-Relationships"><a href="#Shell-Relationships" class="headerlink" title="Shell Relationships"></a>Shell Relationships</h2><p>You can use <code>ps -f</code> to see difference before you run <code>bash</code>(child) in a shell(parent):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root      7762  7758  0 Jun03 pts/0    00:00:00 -bash</span><br><span class="line">root     14957  7762  0 17:12 pts/0    00:00:00 bash</span><br><span class="line">root     15028 14957  0 17:13 pts/0    00:00:00 ps -f</span><br></pre></td></tr></table></figure></p>
<p>Here PID <code>14957</code> has parent <code>7762</code>.</p>
<p>A child shell is also called a <strong>subshell</strong>. A subshell can be created from a parent shell, and a subshell can be created from another subshell:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps --forest</span><br></pre></td></tr></table></figure></p>
<p>can be used to show the nesting of the subshells. For example, run <code>bash</code> 3 times:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps --forest -f</span><br><span class="line"></span><br><span class="line">UID        PID  PPID  C STIME TTY          TIME CMD</span><br><span class="line">root      7762  7758  0 Jun03 pts/0    00:00:00 -bash</span><br><span class="line">root      2264  7762  0 23:52 pts/0    00:00:00  \_ bash</span><br><span class="line">root      2467  2264  0 23:55 pts/0    00:00:00      \_ bash</span><br><span class="line">root      2487  2467  0 23:55 pts/0    00:00:00          \_ bash</span><br><span class="line">root      2510  2487  0 23:55 pts/0    00:00:00              \_ ps --forest -f</span><br></pre></td></tr></table></figure></p>
<h2 id="Constructs-Create-SubShell"><a href="#Constructs-Create-SubShell" class="headerlink" title="Constructs Create SubShell"></a>Constructs Create SubShell</h2><p>Refer to this <a href="https://unix.stackexchange.com/questions/442692/is-a-subshell" target="_blank" rel="noopener">what is a subshell</a></p>
<blockquote>
<p>Note subshells are often used for multi-processing in shell scripts. However, entering into a subshell is an expensive method and can significantly slow down processing.</p>
</blockquote>
<p>A subshell is typically implemented by <code>forking</code> a new process (but some shells may optimize this in some cases).</p>
<ul>
<li><p>Subshell for grouping: <code>(...)</code> does nothing but create a subshell and <strong>wait</strong> for it to terminate. Contrast with <code>{...}</code> which groups commands purely for syntactic purposes and does not create a subshell.</p>
</li>
<li><p>Background <code>&amp;</code>: creates a subshell and does not wait for it to terminate.</p>
</li>
<li><p>Pipeline: <code>|</code> creates two subshells, one for the left-hand side and one for the right-hand side, and waits for both to terminate. The shell creates a pipe and connects the left-hand side’s standard output to the write end of the pipe and the right-hand side’s standard input to the read end. In some shells (ksh88, ksh93, zsh, bash with the lastpipe option set and effective), the right-hand side runs in the original shell, so the pipeline construct only creates one subshell.</p>
</li>
<li><p>Command substitution: <code>$()</code> creates a subshell with its standard output set to a pipe, collects the output in the parent and expands to that output, minus its trailing newlines. (And the output may be further subject to splitting and globbing, but that’s another story.)</p>
</li>
<li><p>Process substitution: <code>&lt;()</code> creates a subshell with its standard output set to a pipe and expands to the name of the pipe. The parent (or some other process) may open the pipe to communicate with the subshell. <code>&gt;()</code> does the same but with the pipe on standard input.</p>
</li>
<li><p>Coprocess: <code>coproc</code> creates a subshell and does not wait for it to terminate. The subshell’s standard input and output are each set to a pipe with the parent being connected to the other end of each pipe.</p>
</li>
</ul>
<h3 id="Process-List"><a href="#Process-List" class="headerlink" title="Process List"></a>Process List</h3><p>For a command list to be considered a <code>process list</code> (a grouping), the commands must be encased in parentheses <code>()</code>. Adding parentheses and turning the command list into a process list created a subshell to execute the commands.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># echo $BASH_SUBSHELL</span><br><span class="line">0</span><br><span class="line"></span><br><span class="line"># (echo $BASH_SUBSHELL)</span><br><span class="line">1</span><br><span class="line"></span><br><span class="line"># ( (echo $BASH_SUBSHELL) ) </span><br><span class="line">2</span><br></pre></td></tr></table></figure></p>
<p>For parent variables act in subshell <code>()</code>, from <a href="https://stackoverflow.com/questions/26079488/bash-subshell-mystery" target="_blank" rel="noopener">this</a>, <a href="https://unix.stackexchange.com/questions/157957/why-is-a-variable-visible-in-a-subshell?noredirect=1&amp;lq=1" target="_blank" rel="noopener">this</a> and <a href="https://unix.stackexchange.com/questions/138463/do-parentheses-really-put-the-command-in-a-subshell?noredirect=1&amp;lq=1" target="_blank" rel="noopener">this</a> posts, long story short: Subshell <code>()</code> inherit all variables. Even <code>$$</code> (the PID of the original shell) is kept. The reason is that for a subshell, the shell just <strong>forks</strong> and doesn’t execute a new shell (such as run a script <code>./xx</code>)</p>
<blockquote>
<p>Note, usually use subshell <code>()</code> with <code>&amp;</code>.</p>
</blockquote>
<h3 id="Background-mode"><a href="#Background-mode" class="headerlink" title="Background mode"></a>Background mode</h3><p>Background mode is very handy. And it provides a method for creating useful subshells at the CLI.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># jobs -l</span><br><span class="line"></span><br><span class="line">[1]+  7552 Running                 sleep 40 &amp;</span><br></pre></td></tr></table></figure></p>
<p><code>[1]</code> is job number, <code>7552</code> is PID, then <code>Running</code> is job status. The <code>jobs</code> command displays <strong>any</strong> user’s processes (jobs) currently running in background mode:</p>
<p>Using a <code>process list</code> in background mode is one creative method for using subshells at the CLI. Remember we start Jetty in conductor container? <code>docker load</code> and <code>scp</code> are also suitable for background execution sometimes.</p>
<h3 id="Co-processing"><a href="#Co-processing" class="headerlink" title="Co-processing"></a>Co-processing</h3><p>Co-processing performs almost identically to putting a command in background mode, <strong>except</strong> for the fact that it creates a subshell.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coproc sleep 2</span><br><span class="line">[1] 8174</span><br><span class="line"></span><br><span class="line">[1]+  Done                    coproc COPROC sleep 2</span><br></pre></td></tr></table></figure></p>
<p>it the same as:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># (sleep2) &amp;</span><br></pre></td></tr></table></figure></p>
<p>The <code>COPROC</code> is a name given to the porcess, you can change it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coproc My_Job &#123; sleep 10; &#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>The only time you need to name a co-process is when you have multiple co-processes running, and you need to communicate with them all. Otherwise, just let the coproc command set the name to the default, <code>COPROC</code>.</p>
</blockquote>
<p>This will create a nested subshell:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># coproc ( sleep 10; sleep 2 )</span><br></pre></td></tr></table></figure></p>
<h3 id="My-question"><a href="#My-question" class="headerlink" title="My question"></a>My question</h3><p>Remember in conductor container we start Jetty using the <code>(...) &amp;</code>. We want to run it in a separate process in background. Why not just <code>&amp;</code>? So If I want to run something in background, should I use <code>&amp;</code> to put command in background or <code>()&amp;</code> to put subshell in background?</p>
<p>I haven’t fully understaned it, refer to my <a href="https://unix.stackexchange.com/questions/523675/run-script-in-background-using-or" target="_blank" rel="noopener">post</a>.</p>
<h2 id="Shell-Build-in-Commands"><a href="#Shell-Build-in-Commands" class="headerlink" title="Shell Build-in Commands"></a>Shell Build-in Commands</h2><p>An external command, sometimes called a filesystem command, is a program that exists outside of the bash shell. They are not built into the shell program. An external command program is typically located in <code>/bin</code>, <code>/usr/bin</code>, <code>/sbin</code>, or <code>/usr/sbin</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># which ps</span><br><span class="line">/usr/bin/ps</span><br><span class="line"></span><br><span class="line"># type -a ps</span><br><span class="line">ps is /usr/bin/ps</span><br></pre></td></tr></table></figure></p>
<p>Whenever an external command is executed, a child process is created. This action is termed <code>forking</code>. It takes time and effort to set up the new child process’s environment. Thus, external commands can be a little expensive.</p>
<p>When using a built-in command, no forking is required. Therefore, built-in commands are less expensive.</p>
<p>Built-in commands are different in that they do not need a child process to execute. They were compiled into the shell and thus are part of the shell’s toolkit.</p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Variables in Shell</title>
    <url>/2019/06/02/shell-variables/</url>
    <content><![CDATA[<p>The article mainly talks about the <code>variable scope</code> in shell. especially how to access variables in one scrpt from another.</p>
<h2 id="ENV-Variables"><a href="#ENV-Variables" class="headerlink" title="ENV Variables"></a>ENV Variables</h2><p>The <code>set</code> command displays all variables defined for a specific process, including both <code>local</code> and <code>global</code> environment variables and user-defined variables:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">set</span></span><br></pre></td></tr></table></figure></p>
<p>It also sorts the display alphabetically.</p>
<h3 id="Global-ENV-Variables"><a href="#Global-ENV-Variables" class="headerlink" title="Global ENV Variables"></a>Global ENV Variables</h3><p>Global environment variables are visible from the shell session and from <strong>any</strong> spawned child subshells. This makes global environment variables useful in applications that create child subshells, which require parent shell information.</p>
<p>To view global environment variables, use the <code>env</code> or the <code>printenv</code> command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># printenv HOME</span></span><br><span class="line"></span><br><span class="line">/root</span><br></pre></td></tr></table></figure></p>
<p>You can use <code>export</code> to create global environment variable.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> demo=<span class="string">'hello world'</span></span><br></pre></td></tr></table></figure></p>
<p>You can use <code>unset</code> to remove an existing environment variable.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">unset</span> demo</span><br></pre></td></tr></table></figure></p>
<p>A common trick for programmers is to include the <code>single dot</code> symbol in their <code>PATH</code> environment variable. The single dot symbol represents the current directory:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PATH=<span class="variable">$PATH</span>:.</span><br></pre></td></tr></table></figure></p>
<h3 id="Local-ENV-Variables"><a href="#Local-ENV-Variables" class="headerlink" title="Local ENV Variables"></a>Local ENV Variables</h3><p>Local variables are available <strong>only</strong> in the shell that creates them. In fact, the Linux system also defines standard local environment variables for you by default. </p>
<p>How to define a local environment variable:<br><strong>No</strong> space can appear between the variable, the equal sign, and the value:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var1=value</span><br></pre></td></tr></table></figure></p>
<p>Variables defined within the shell script maintain their values throughtout the life of the shell script but are delted when the shell script completes.</p>
<p>If you want to assign the value of one variable to another, must use <code>$</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">var2=<span class="variable">$&#123;var1&#125;</span></span><br></pre></td></tr></table></figure></p>
<p>otherwise, <code>var1</code> will be interpreted as text string.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">var2=var1</span><br></pre></td></tr></table></figure></p>
<h2 id="Variable-Scope"><a href="#Variable-Scope" class="headerlink" title="Variable Scope"></a>Variable Scope</h2><p>My question is how to pass variables from one script to another?<br>Basically there are 2 options:</p>
<ol>
<li><p>Make the variable an environment variable (<code>export</code> it) before executing the 2nd script (<code>./script2</code>).</p>
</li>
<li><p><code>source</code> the second script and it will run in the same shell, This would let you share more complex variables like arrays easily, but also means that the other script could modify variables in the caller shell.</p>
</li>
</ol>
<h2 id="Preserve-ENV-variables"><a href="#Preserve-ENV-variables" class="headerlink" title="Preserve ENV variables"></a>Preserve ENV variables</h2><p>Refer to <a href="https://unix.stackexchange.com/questions/188144/why-is-a-variable-passed-to-the-su-command-but-not-an-array-from-the-same-scope" target="_blank" rel="noopener">this</a> question. This is interesting and easy to make mistake, if I want to preserve ENV variable with switch user from parent shell, use <code>su xxx</code> instead of <code>su - xxx</code>, <code>-</code> option will do:</p>
<ol>
<li>clears all environment variables except for TERM</li>
<li>initializes the environment variables HOME, SHELL, USER, LOGNAME, PATH</li>
<li>changes to the target user’s home directory</li>
<li>sets argv[0] of the shell to ‘-‘ in order to make the shell a login shell</li>
</ol>
<p>But be very careful not let shell do variable expanding in command option:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su xxx -c <span class="string">"... echo <span class="variable">$a</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>Here <code>$a</code> will be expanded before executing, use single quote or escape the <code>$</code> sign:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su xxx -c <span class="string">'... echo $a'</span></span><br><span class="line">su xxx -c <span class="string">"... echo \$a"</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Double-substitution"><a href="#Double-substitution" class="headerlink" title="Double substitution"></a>Double substitution</h2><p>For example, it not <code>${${first2}}</code>!<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">first=<span class="string">"real value"</span></span><br><span class="line">first2=<span class="string">"first"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$&#123;!first2&#125;</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Visual Studio Code Setup</title>
    <url>/2020/05/28/vsc-setup/</url>
    <content><![CDATA[<p>There is a Settings Sync plugin:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;Sync Update/upload settings or Download</span><br></pre></td></tr></table></figure></p>
<ol>
<li>Theme setting: command + P: &gt;theme, then select the theme you like</li>
<li>Material Icon plugin</li>
<li>Fira Code: <a href="https://github.com/tonsky/FiraCode" target="_blank" rel="noopener">https://github.com/tonsky/FiraCode</a></li>
<li>Still hold picture on google drive, refer by <code>![](https://drive.google.com/uc?id=xxx)</code></li>
<li>Open settings: &gt;settings, &gt;default settings<ul>
<li>autoSave afterdelay</li>
</ul>
</li>
</ol>
]]></content>
      <categories>
        <category>Visual Studio Code</category>
      </categories>
      <tags>
        <tag>vsc</tag>
      </tags>
  </entry>
  <entry>
    <title>Leadership Principle</title>
    <url>/2020/05/23/softskill-leadership/</url>
    <content><![CDATA[<p>今天决定把Soft Skill相关的总结单独分出来。除了日常工作对话，后续重要的技能包括email, phone, technical writing 以及 negotiation, management等.</p>
<p>关注并接触Leadership 是始于Amazon的面试准备，虽然我很烦在面试中考察这种形式化的东西，但我不得不说它非常重要，特别是在英文背景中我这方面欠缺挺大的，必须要系统性的总结一下。</p>
<h1 id="Leadership-view"><a href="#Leadership-view" class="headerlink" title="Leadership view"></a>Leadership view</h1><p>I think you have been doing a nice job.</p>
<p>figure out customer requirements<br>hold meetings<br>write agendas<br>status reports</p>
<p>Critical skill of being a leader:</p>
<ul>
<li>Communication</li>
<li>Effective management skill</li>
<li>Emotional intelligence (情商) and Empathy</li>
</ul>
<p>Communicate in clear, credible and authentic way.<br>Use passion and confidence to enhance the message.(口音，表情，肢体语言)<br>Inspire, motivate others<br>Informs, persuades, guides, assures</p>
<p>when you be a leader in your new team:</p>
<ul>
<li>devote time and energy to establishing how you want your team to work</li>
<li>first few weeks are critical</li>
<li>get to know your team members</li>
<li>showcase your values</li>
<li>explain how you want the team to work</li>
<li>set and clarify goals, walk the talk</li>
<li>don’t be afraid to over communicate</li>
</ul>
<p>Don’t:</p>
<ul>
<li>不要认为没建立关系也能完成工作</li>
<li>不要假设成员理解你的工作模式和期望</li>
<li>不要担心在开始阶段过多的重复谈话</li>
</ul>
<p>What does leadership mean to you?<br>connection:</p>
<ul>
<li>focus on the person</li>
<li>influence</li>
<li>words</li>
</ul>
<p>changes:</p>
<ul>
<li>vision</li>
<li>action</li>
<li>drive change</li>
</ul>
<p>motivate:</p>
<ul>
<li>inspire motivation</li>
<li>long-lasting motivation</li>
</ul>
<p>Why they will follow you?<br>make them feel comfortable, configent and satisfied:</p>
<ul>
<li>trust<ul>
<li>be open, fair and listen</li>
<li>admit mistake</li>
<li>be decisive</li>
<li>respect the opinions of others</li>
</ul>
</li>
<li>compassion</li>
<li>stability</li>
<li>hope</li>
</ul>
]]></content>
      <categories>
        <category>Soft Skill</category>
      </categories>
      <tags>
        <tag>soft skill</tag>
        <tag>leadership</tag>
      </tags>
  </entry>
  <entry>
    <title>Effective Email</title>
    <url>/2020/05/24/softskill-email/</url>
    <content><![CDATA[<h2 id="Purpose"><a href="#Purpose" class="headerlink" title="Purpose"></a>Purpose</h2><p>Understand the purpose of every email, for example:</p>
<ul>
<li>to educate or inform</li>
<li>make a request</li>
<li>introduction</li>
<li>respond</li>
</ul>
<p>Before sending, review for purpose alignment. If not, adjust the message.</p>
<p>Key elements for good email:</p>
<ul>
<li>Subject line: keep email from getting deleted</li>
<li>Introduction: create context, build trust, remind who you are</li>
<li>Message: bulk of the email</li>
<li>Call to action: request, the last part of the body</li>
<li>Signature: provide contact information, your brand</li>
</ul>
<p>Adjust the <code>From</code> name and email address, for example <code>chengdol &lt;email address&gt;</code>, this can be done through <code>Send email as</code> in Gmail.</p>
<p>The <code>Signature</code> helps people understand your skill set, value proposition, may include:</p>
<ul>
<li>your name</li>
<li>tagline: directly under your name, a few words, can be your title (senior software engineer) or pluralsight skills IQ</li>
<li>phone, address, links</li>
</ul>
<p><strong>To, CC and BCC</strong><br><code>To</code>: directly talk to a person.<br><code>CC</code>: who can hear the conversation, don’t have to act on it.<br><code>BCC</code>: blind from others, only the person put you in BCC feild knows you are listening, no one else know you are on recipient list, fine to reply to sender but not reply all.</p>
<p><strong>Time</strong><br>Email complements other communications, when there is a lot of information, highly visual. Usually not time urgent.</p>
<h2 id="Communicating-Better"><a href="#Communicating-Better" class="headerlink" title="Communicating Better"></a>Communicating Better</h2><p>Visuals may help, but not make it distracting, <code>bold or highlighting</code> is good to make response stand out.</p>
<p>When many people involved, use <code>Reply All</code>, unless you intend to start a side conversation. Move to <code>Reply</code>, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Thank again for the introduction, I&apos;ll move this conversation with xx to another thread so we don&apos;t clutter your inbox.</span><br></pre></td></tr></table></figure></p>
<p>Set <code>out-of-office auto reply</code>, for example, at a conference, on leave. A good example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">I’m currently consumed with a project that is taking almost all of my time. If you are emailing me with a product or support question, please email Liz. Otherwise, I will try to respond within 24 hours.</span><br></pre></td></tr></table></figure></p>
<p><code>Proofread</code> before sending it:</p>
<ul>
<li>purpose aligned</li>
<li>body</li>
<li>distraction</li>
<li>call to action is clear</li>
<li>spelling and grammar</li>
<li>proper audience</li>
<li>any attachment</li>
</ul>
<p>When the stakes are high, and your email can have a major impact on the outcome, it can pay to invest your time in proper proofreading.</p>
<h2 id="Demos"><a href="#Demos" class="headerlink" title="Demos"></a>Demos</h2><p><code>The first communication</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## subject</span></span><br><span class="line">Reaching out from Twitter</span><br><span class="line"></span><br><span class="line"><span class="comment">## introduction</span></span><br><span class="line">Hi Chris, I have been following you on Twitter <span class="keyword">for</span> a <span class="keyword">while</span>, and have interacted a little with you over the last few weeks. I wanted to bring the conversation over to email.</span><br><span class="line"></span><br><span class="line"><span class="comment">## message</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## call to action</span></span><br><span class="line">Can we get on a call <span class="keyword">in</span> the next week or so? I am open all day Thursday, just <span class="built_in">let</span> me know what works <span class="keyword">for</span> you.</span><br><span class="line"></span><br><span class="line"><span class="comment">## signature</span></span><br></pre></td></tr></table></figure></p>
<p><code>Vitual introduction</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## subject</span></span><br><span class="line">Virtual introduction: Matt and Jesse</span><br><span class="line"></span><br><span class="line"><span class="comment">## introduction</span></span><br><span class="line">Hi Matt and Jesse, as per our previous conversations I wanted to introduce you to one another.</span><br><span class="line"></span><br><span class="line"><span class="comment">## message</span></span><br><span class="line">Matt, I’ve known Jesse <span class="keyword">for</span> a few years and know him to be a very clever developer, and a loyal friend. I know he can <span class="built_in">help</span> you with some of the coding challenges you are facing right now.</span><br><span class="line"></span><br><span class="line">Jesse, Matt is my friend and colleague, and can better explain his challenges than I can, but I think you are the right person <span class="keyword">for</span> him to talk to.</span><br><span class="line"></span><br><span class="line"><span class="comment">## call to action</span></span><br><span class="line">I hope you two can get together soon. I’ll <span class="built_in">let</span> you take it from here.</span><br><span class="line"></span><br><span class="line"><span class="comment">## signature</span></span><br></pre></td></tr></table></figure></p>
<p><code>Information heavy</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Follow-up on job search information</span><br><span class="line"></span><br><span class="line">Hi Laurie, you had asked <span class="keyword">for</span> information to <span class="built_in">help</span> you with your job search Thursday morning when we spoke.</span><br><span class="line"></span><br><span class="line">Below are a few of my favorite blog posts <span class="built_in">which</span> I think are relevant to <span class="built_in">where</span> you are, based on our conversation. I am happy to talk about any of this with you, over email or on a call. Just <span class="built_in">let</span> me know what works best <span class="keyword">for</span> you.</span><br><span class="line"></span><br><span class="line"><span class="comment">## some links here</span></span><br><span class="line"></span><br><span class="line">I have been blogging <span class="keyword">for</span> over 14 years, and have plenty to share, but I thought these would be the most interesting and meaningful to you.</span><br><span class="line"></span><br><span class="line">I would love to jump on a call this week to talk about your next steps. Are you available <span class="keyword">for</span> a call Friday before 2?</span><br><span class="line"></span><br><span class="line"><span class="comment">## signature</span></span><br></pre></td></tr></table></figure></p>
<p><code>Respond to questions</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Hi Jim, thank you <span class="keyword">for</span> your thoughtful email. You have a lot of questions and ideas <span class="keyword">in</span> there. Please scroll down and see my comments <span class="keyword">in</span> `yellow`</span><br><span class="line"><span class="comment">## copy the original email and answer right after each question and highlight with yellow</span></span><br></pre></td></tr></table></figure></p>
<p><code>Negative situation</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Team performance</span><br><span class="line"></span><br><span class="line">Mike, I promised you an email follow-up from our conversation this morning. I know this is an uncomfortable conversation and I appreciate your willingness to address this with me.</span><br><span class="line"></span><br><span class="line">There are two issues we need to address.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Project Foo meeting this morning</span><br><span class="line"></span><br><span class="line">Hi Carlos, <span class="built_in">let</span> me first apologize <span class="keyword">for</span> how the meeting went this afternoon. I could tell that you were uncomfortable. I wanted to share my perspective on what was happening.</span><br><span class="line"></span><br><span class="line">While I knew there was a chance your Project Foo was going to be killed, I was not aware of the reasons stated <span class="keyword">in</span> the meeting. I have seen what you and your team have <span class="keyword">done</span> with Project Foo and I have been very impressed.</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Soft Skill</category>
      </categories>
      <tags>
        <tag>soft skill</tag>
        <tag>email</tag>
      </tags>
  </entry>
  <entry>
    <title>Zookeeper Introduction</title>
    <url>/2019/08/29/zookeeper-introd/</url>
    <content><![CDATA[<p><a href="https://zookeeper.apache.org/" target="_blank" rel="noopener">Apach Zookeeper</a></p>
]]></content>
      <categories>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Module Reference</title>
    <url>/2019/03/22/ansible-module-refer/</url>
    <content><![CDATA[<p>There are some commonly used Ansible modules that I will refer frequently. More specific detail please see Ansible document.</p>
<p>How to organize the ansible files structure, see best <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_best_practices.html" target="_blank" rel="noopener">practice</a>.</p>
<h2 id="pause"><a href="#pause" class="headerlink" title="pause"></a>pause</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/pause_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/pause_module.html</a><br>Pauses playbook execution for a set amount of time, or until a prompt is acknowledged. All parameters are optional. The default behavior is to pause with a prompt.</p>
<p>The pause module integrates into async/parallelized playbooks without any special considerations (see Rolling Updates). When using pauses with the serial playbook parameter (as in rolling updates) you are only prompted once for the current group of hosts.</p>
<p>Useful when debug certain task to see the execution result:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># just pause </span></span><br><span class="line"><span class="attr">- pause:</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># a helpful reminder of what to look out for post-update.</span></span><br><span class="line"><span class="attr">- pause:</span></span><br><span class="line"><span class="attr">    prompt:</span> <span class="string">"Make sure org.foo.FooOverload exception is not present"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># pause to get some sensitive input.</span></span><br><span class="line"><span class="attr">- pause:</span></span><br><span class="line"><span class="attr">    prompt:</span> <span class="string">"Enter a secret"</span></span><br><span class="line"><span class="attr">    echo:</span> <span class="literal">no</span></span><br></pre></td></tr></table></figure></p>
<h2 id="skip"><a href="#skip" class="headerlink" title="skip"></a>skip</h2><p>Sometimes I need to skip some tasks promptly, how to do this?<br>It seems there is no <code>skip</code> module in ansible, but we have workaroud:<br><a href="https://unix.stackexchange.com/questions/424151/skip-some-task-with-prompt-in-ansible" target="_blank" rel="noopener">https://unix.stackexchange.com/questions/424151/skip-some-task-with-prompt-in-ansible</a></p>
<p>You can also apply <code>tag</code> or conditionals<br><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html</a><br><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html#conditionals" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/user_guide/playbooks_conditionals.html#conditionals</a></p>
<h2 id="debug"><a href="#debug" class="headerlink" title="debug"></a>debug</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/debug_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/debug_module.html</a><br>This module prints statements during execution and can be useful for debugging variables or expressions without necessarily halting the playbook.</p>
<p>Useful for debugging together with the ‘when:’ directive.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Example that prints return information from the previous task</span></span><br><span class="line"><span class="attr">- shell:</span> <span class="string">/usr/bin/uptime</span></span><br><span class="line"><span class="attr">  register:</span> <span class="string">result</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## var option already runs in Jinja2 context and has an implicit &#123;&#123; &#125;&#125; wrapping</span></span><br><span class="line"><span class="attr">- debug:</span></span><br><span class="line"><span class="attr">    var:</span> <span class="string">result</span></span><br><span class="line">    <span class="comment">## this verbosity is associated with `-vv` parameter</span></span><br><span class="line"><span class="attr">    verbosity:</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## prints the loopback address and gateway for each host</span></span><br><span class="line"><span class="attr">- debug:</span></span><br><span class="line"><span class="attr">    msg:</span> <span class="string">System</span> <span class="string">&#123;&#123;</span> <span class="string">inventory_hostname</span> <span class="string">&#125;&#125;</span> <span class="string">has</span> <span class="string">gateway</span> <span class="string">&#123;&#123;</span> <span class="string">ansible_default_ipv4.gateway</span> <span class="string">&#125;&#125;</span></span><br><span class="line"><span class="attr">  when:</span> <span class="string">ansible_default_ipv4.gateway</span> <span class="string">is</span> <span class="string">defined</span></span><br></pre></td></tr></table></figure></p>
<h2 id="fail"><a href="#fail" class="headerlink" title="fail"></a>fail</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/fail_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/fail_module.html</a><br>This module fails the progress with a custom message.<br>It can be useful for bailing out when a certain condition is met using when.</p>
<p>More error handling see:<br><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_error_handling.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/user_guide/playbooks_error_handling.html</a></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">check</span> <span class="string">async</span> <span class="string">task</span> <span class="string">status</span></span><br><span class="line"><span class="attr">  ignore_errors:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment">## check async task status</span></span><br><span class="line"><span class="attr">  async_status:</span></span><br><span class="line"><span class="attr">    jid:</span> <span class="string">"<span class="template-variable">&#123;&#123; sleepTask.ansible_job_id &#125;&#125;</span>"</span></span><br><span class="line"><span class="attr">  register:</span> <span class="string">job_result</span></span><br><span class="line"><span class="attr">  until:</span> <span class="string">job_result.finished</span></span><br><span class="line"><span class="attr">  when:</span> <span class="string">"inventory_hostname == groups.master[0]"</span></span><br><span class="line"><span class="attr">  retries:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">  delay:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## other things to do</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## fail the process if the retry failed</span></span><br><span class="line"><span class="attr">- fail:</span></span><br><span class="line"><span class="attr">    msg:</span> <span class="string">The</span> <span class="string">time</span> <span class="string">limit</span> <span class="string">hit,</span> <span class="string">the</span> <span class="string">cluster</span> <span class="string">may</span> <span class="string">not</span> <span class="string">be</span> <span class="string">in</span> <span class="string">ready</span> <span class="string">status!</span></span><br><span class="line">  <span class="comment">## it depends what output is in the register variable</span></span><br><span class="line"><span class="attr">  when:</span> <span class="string">job_result.failed</span> <span class="string">==</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>
<h2 id="copy"><a href="#copy" class="headerlink" title="copy"></a>copy</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/copy_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/copy_module.html</a><br>The copy module copies a file from the local or remote machine to a location on the remote machine (depends on the condition). 和template类似, 如果task下面有files文件夹, 在不指定src路径的时候, eg: <code>src: xxx.txt</code>, 会从files文件夹里copy.</p>
<p>Use the <code>fetch</code> module to copy files from remote locations to the local box.</p>
<p>If you need variable interpolation in copied files, use the <code>template</code> module. Using a variable in the content field will result in unpredictable output.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## &#123;&#123; baseDir &#125;&#125;/registry-certs/tls.crt is in control machine</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Copy</span> <span class="string">secure</span> <span class="string">docker</span> <span class="string">registry</span> <span class="string">ssl/tls</span> <span class="string">certs</span> <span class="string">to</span> <span class="string">all</span> <span class="string">worker</span> <span class="string">nodes</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  copy:</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">"<span class="template-variable">&#123;&#123; baseDir &#125;&#125;</span>/registry-certs/tls.crt"</span></span><br><span class="line"><span class="attr">    dest:</span> <span class="string">"/etc/docker/certs.d/<span class="template-variable">&#123;&#123; service name &#125;&#125;</span>:5000/tls.crt"</span></span><br><span class="line"><span class="attr">    owner:</span> <span class="string">root</span></span><br><span class="line"><span class="attr">    group:</span> <span class="string">root</span></span><br><span class="line"><span class="attr">    mode:</span> <span class="string">'0644'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## remote_src: yes means copy is happening on remote machine</span></span><br><span class="line"><span class="comment">## remote_src supports recursive copying as of version 2.8</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Copy</span> <span class="string">a</span> <span class="string">"sudoers"</span> <span class="string">file</span> <span class="string">on</span> <span class="string">the</span> <span class="string">remote</span> <span class="string">machine</span> <span class="string">for</span> <span class="string">editing</span></span><br><span class="line"><span class="attr">  copy:</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">/etc/sudoers</span></span><br><span class="line"><span class="attr">    dest:</span> <span class="string">/etc/sudoers.edit</span></span><br><span class="line"><span class="attr">    remote_src:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure></p>
<h2 id="fetch"><a href="#fetch" class="headerlink" title="fetch"></a>fetch</h2><p>This module works like copy, but in reverse.</p>
<p>It is used for fetching files from remote machines and storing them locally in a file tree, organized by hostname.</p>
<p>Files that already exist at dest will be overwritten if they are different than the src.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## fetched file is marked by the remote hostname </span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Store</span> <span class="string">file</span> <span class="string">into</span> <span class="string">/tmp/fetched/host.example.com/tmp/somefile</span></span><br><span class="line"><span class="attr">  fetch:</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">/tmp/somefile</span></span><br><span class="line"><span class="attr">    dest:</span> <span class="string">/tmp/fetched</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## If dest ends with '/', it will use the basename of the source file, similar to the copy module.</span></span><br><span class="line"><span class="comment">## This can be useful if working with a single host, or if retrieving files that are uniquely named per host.</span></span><br><span class="line"><span class="comment">## If using multiple hosts with the same filename, the file will be overwritten for each host.</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Specifying</span> <span class="string">a</span> <span class="string">destination</span> <span class="string">path</span></span><br><span class="line"><span class="attr">  fetch:</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">/tmp/uniquefile</span></span><br><span class="line"><span class="attr">    dest:</span> <span class="string">/tmp/special/</span></span><br><span class="line"><span class="attr">    flat:</span> <span class="literal">yes</span></span><br></pre></td></tr></table></figure></p>
<h2 id="template"><a href="#template" class="headerlink" title="template"></a>template</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/template_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/template_module.html</a><br>这个module在统一设置配置文件时很常用, 或者可以用来初始化script template中的参数, 然后传递到各个host去运行.<br>Templates are processed by the <code>Jinja2</code> templating language.<br>Documentation on the template formatting can be found in the <a href="https://jinja.palletsprojects.com/en/2.10.x/templates/" target="_blank" rel="noopener">Template Designer Documentation</a>.</p>
<p>Usually we have the ansible role structure:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">roles/</span><br><span class="line">  install.components/</span><br><span class="line">      defaults/</span><br><span class="line">        main.yml</span><br><span class="line">      tasks/</span><br><span class="line">        main.yml</span><br><span class="line">      templates/</span><br><span class="line">        example.conf.j2</span><br><span class="line">        example.sh.j2</span><br><span class="line">      files/</span><br><span class="line">        bar.txt</span><br><span class="line">        foo.sh</span><br></pre></td></tr></table></figure></p>
<p>When template works it picks source file from role’s <code>templates/</code> folder.<br>If the template file contains jinja2 placeholder, it will be interpolated.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## from control machine to other nodes</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Template</span> <span class="string">a</span> <span class="string">file</span> <span class="string">to</span> <span class="string">/etc/files.conf</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">/mytemplates/foo.j2</span></span><br><span class="line"><span class="attr">    dest:</span> <span class="string">/etc/file.conf</span></span><br><span class="line"><span class="attr">    owner:</span> <span class="string">bin</span></span><br><span class="line"><span class="attr">    group:</span> <span class="string">wheel</span></span><br><span class="line"><span class="attr">    mode:</span> <span class="string">'0644'</span></span><br></pre></td></tr></table></figure>
<h2 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/shell_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/shell_module.html</a><br>这个太常用了, 可以做几乎所有其他module的工作.</p>
<p>It is almost exactly like the <code>command</code> module but runs the command through a shell (<code>/bin/sh</code>) on the remote node.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Copy</span> <span class="string">IIS</span> <span class="string">docker</span> <span class="string">images</span> <span class="string">to</span> <span class="string">specified</span> <span class="string">worker</span> <span class="string">nodes</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  shell:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    /tmp/copyIISDockers.sh <span class="template-variable">&#123;&#123; iisDockers &#125;&#125;</span> <span class="template-variable">&#123;&#123; imageTag &#125;&#125;</span></span></span><br><span class="line"><span class="string">    if [[ $? -eq 0 ]]; then</span></span><br><span class="line"><span class="string">      touch /tmp/copyIISImageToWorker.done</span></span><br><span class="line"><span class="string">    fi</span></span><br><span class="line"><span class="string"></span><span class="attr">  when:</span> <span class="string">"inventory_hostname == groups.master[0]"</span></span><br><span class="line"><span class="attr">  args:</span></span><br><span class="line">    <span class="comment">## A filename, when it already exists, this step will not be run.</span></span><br><span class="line"><span class="attr">    creates:</span> <span class="string">/tmp/copyIISImageToWorker.done</span></span><br><span class="line">    <span class="comment">## A filename, when it does not exist, this step will not be run.</span></span><br><span class="line"><span class="attr">    removes:</span> <span class="string">/tmp/preTaskOk.done</span></span><br><span class="line">    <span class="comment">## disable task warning</span></span><br><span class="line"><span class="attr">    warn:</span> <span class="literal">no</span></span><br><span class="line">    <span class="comment">## change the shell</span></span><br><span class="line"><span class="attr">    executable:</span> <span class="string">/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Change</span> <span class="string">the</span> <span class="string">working</span> <span class="string">directory</span> <span class="string">to</span> <span class="string">somedir/</span> <span class="string">before</span> <span class="string">executing</span> <span class="string">the</span> <span class="string">command.</span></span><br><span class="line"><span class="attr">  shell:</span> <span class="string">somescript.sh</span> <span class="string">&gt;&gt;</span> <span class="string">somelog.txt</span></span><br><span class="line"><span class="attr">  args:</span></span><br><span class="line"><span class="attr">    chdir:</span> <span class="string">somedir/</span></span><br></pre></td></tr></table></figure>
<h2 id="command"><a href="#command" class="headerlink" title="command"></a>command</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/command_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/command_module.html</a><br>The <code>command</code> module takes the command name followed by a list of space-delimited arguments.<br>The given command will be executed on all selected nodes.<br>The command(s) will <strong>not</strong> be processed through the <code>shell</code>, so variables like $HOME and operations like “&lt;”, “&gt;”, “|”, “;” and “&amp;” will not work. Use the shell module if you need these features.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">return</span> <span class="string">motd</span> <span class="string">to</span> <span class="string">registered</span> <span class="string">var</span></span><br><span class="line"><span class="attr">  command:</span> <span class="string">cat</span> <span class="string">/etc/motd</span></span><br><span class="line"><span class="attr">  register:</span> <span class="string">mymotd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 'args' is a task keyword, passed at the same level as the module</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Run</span> <span class="string">command</span> <span class="string">if</span> <span class="string">/path/to/database</span> <span class="string">does</span> <span class="string">not</span> <span class="string">exist</span> <span class="string">(with</span> <span class="string">'args'</span> <span class="string">keyword).</span></span><br><span class="line"><span class="attr">  command:</span> <span class="string">/usr/bin/make_database.sh</span> <span class="string">db_user</span> <span class="string">db_name</span></span><br><span class="line"><span class="attr">  args:</span></span><br><span class="line"><span class="attr">    creates:</span> <span class="string">/path/to/database</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 'cmd' is module parameter</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Run</span> <span class="string">command</span> <span class="string">if</span> <span class="string">/path/to/database</span> <span class="string">does</span> <span class="string">not</span> <span class="string">exist</span> <span class="string">(with</span> <span class="string">'cmd'</span> <span class="string">parameter).</span></span><br><span class="line"><span class="attr">  command:</span></span><br><span class="line"><span class="attr">    cmd:</span> <span class="string">/usr/bin/make_database.sh</span> <span class="string">db_user</span> <span class="string">db_name</span></span><br><span class="line"><span class="attr">    creates:</span> <span class="string">/path/to/database</span></span><br></pre></td></tr></table></figure>
<h2 id="service"><a href="#service" class="headerlink" title="service"></a>service</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/service_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/service_module.html</a><br>Controls services on remote hosts. Supported init systems include BSD init, OpenRC, SysV, Solaris SMF, systemd, upstart.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Start</span> <span class="string">service</span> <span class="string">httpd,</span> <span class="string">if</span> <span class="string">not</span> <span class="string">started</span></span><br><span class="line"><span class="attr">  service:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">httpd</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">started</span></span><br></pre></td></tr></table></figure>
<h2 id="systemd"><a href="#systemd" class="headerlink" title="systemd"></a>systemd</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/systemd_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/systemd_module.html</a><br>more dedicated then service module, controls systemd services on remote hosts.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Enable</span> <span class="string">and</span> <span class="string">start</span> <span class="string">docker</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  systemd:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">docker</span></span><br><span class="line"><span class="attr">    enabled:</span> <span class="literal">yes</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">started</span></span><br></pre></td></tr></table></figure>
<h2 id="file"><a href="#file" class="headerlink" title="file"></a>file</h2><p>Set attributes of files, symlinks or directories.<br>Alternatively, remove files, symlinks or directories.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Create</span> <span class="string">a</span> <span class="string">directory</span> <span class="string">if</span> <span class="string">it</span> <span class="string">does</span> <span class="string">not</span> <span class="string">exist</span></span><br><span class="line"><span class="attr">  file:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/some_directory</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">directory</span></span><br><span class="line"><span class="attr">    mode:</span> <span class="string">'0755'</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Touch</span> <span class="string">a</span> <span class="string">file,</span> <span class="string">using</span> <span class="string">symbolic</span> <span class="string">modes</span> <span class="string">to</span> <span class="string">set</span> <span class="string">the</span> <span class="string">permissions</span> <span class="string">(equivalent</span> <span class="string">to</span> <span class="number">0644</span><span class="string">)</span></span><br><span class="line"><span class="attr">  file:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/foo.conf</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">touch</span></span><br><span class="line"><span class="attr">    mode:</span> <span class="string">u=rw,g=r,o=r</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Remove</span> <span class="string">file</span> <span class="string">(delete</span> <span class="string">file)</span></span><br><span class="line"><span class="attr">  file:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/foo.txt</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">absent</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Recursively</span> <span class="string">remove</span> <span class="string">directory</span></span><br><span class="line"><span class="attr">  file:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/foo</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">absent</span></span><br></pre></td></tr></table></figure>
<h2 id="lineinfile"><a href="#lineinfile" class="headerlink" title="lineinfile"></a>lineinfile</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/lineinfile_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/lineinfile_module.html</a><br>If you use <code>sed</code> in command module, you will get warning, you can disable the warning by add <code>warn: false</code> or use lineinfile module.</p>
<p>This module ensures a particular line is in a file, or replace an existing line using a back-referenced regular expression.</p>
<p>This is primarily useful when you want to change a single line in a file only.</p>
<p>See the <code>replace</code> module if you want to change multiple, similar lines or check <code>blockinfile</code> if you want to insert/update/remove a block of lines in a file. For other cases, see the copy or template modules.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Make</span> <span class="string">sure</span> <span class="string">group</span> <span class="string">wheel</span> <span class="string">is</span> <span class="string">not</span> <span class="string">in</span> <span class="string">the</span> <span class="string">sudoers</span> <span class="string">configuration</span></span><br><span class="line"><span class="attr">  lineinfile:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/sudoers</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">absent</span></span><br><span class="line"><span class="attr">    regexp:</span> <span class="string">'^%wheel'</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Ensure</span> <span class="string">we</span> <span class="string">have</span> <span class="string">our</span> <span class="string">own</span> <span class="string">comment</span> <span class="string">added</span> <span class="string">to</span> <span class="string">/etc/services</span></span><br><span class="line"><span class="attr">  lineinfile:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/etc/services</span></span><br><span class="line"><span class="attr">    regexp:</span> <span class="string">'^# port for http'</span></span><br><span class="line"><span class="attr">    insertbefore:</span> <span class="string">'^www.*80/tcp'</span></span><br><span class="line"><span class="attr">    line:</span> <span class="string">'# port for http by default'</span></span><br></pre></td></tr></table></figure>
<h2 id="mount"><a href="#mount" class="headerlink" title="mount"></a>mount</h2><p><a href="https://docs.ansible.com/ansible/latest/modules/mount_module.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/modules/mount_module.html</a><br>This module controls active and configured mount points in <code>/etc/fstab</code></p>
<p>For <code>/etc/exports</code>, no dedicated module for it.</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">- name:</span> <span class="string">Edit</span> <span class="string">/etc/fstab</span> <span class="string">file</span> <span class="string">to</span> <span class="string">mount</span> <span class="string">share</span> <span class="string">directory</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  mount:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">"/mnt"</span></span><br><span class="line"><span class="attr">    src:</span> <span class="string">"<span class="template-variable">&#123;&#123; dfsFileServer &#125;&#125;</span>:<span class="template-variable">&#123;&#123; dfsDataDir &#125;&#125;</span>"</span></span><br><span class="line"><span class="attr">    fstype:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">    opts:</span> <span class="string">"defaults,timeo=10,retrans=3,rsize=1048576,wsize=1048576"</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">mounted</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">Edit</span> <span class="string">/etc/fstab</span> <span class="string">file</span> <span class="string">to</span> <span class="string">unmout</span> <span class="string">share</span> <span class="string">directory</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  mount:</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">"/mnt"</span></span><br><span class="line"><span class="attr">    fstype:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">    opts:</span> <span class="string">"defaults,timeo=10,retrans=3,rsize=1048576,wsize=1048576"</span></span><br><span class="line"><span class="attr">    state:</span> <span class="string">absent</span></span><br></pre></td></tr></table></figure>
<h2 id="asynchronous"><a href="#asynchronous" class="headerlink" title="asynchronous"></a>asynchronous</h2><p><a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/latest/user_guide/playbooks_async.html</a><br>By default task in playbook blocks, this may not always be desirable, or you may be running operations that take longer than the SSH timeout.</p>
<p>This module can be use to create progress bar for long time task.</p>
<blockquote>
<p>Notice that async task can only be accessed in the same playbook.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">async</span> <span class="string">task</span> <span class="string">in</span> <span class="string">background</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">  shell:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    echo "start first task"</span></span><br><span class="line"><span class="string">    sleep 20</span></span><br><span class="line"><span class="string">    touch /tmp/sleep.done</span></span><br><span class="line"><span class="string">  ## when poll &gt; 0, task still blocks</span></span><br><span class="line"><span class="string">  ## when poll = 0, task run in background</span></span><br><span class="line"><span class="string"></span><span class="attr">  poll:</span> <span class="number">0</span></span><br><span class="line">  <span class="comment">## explicitly sets the timeout 1000 seconds</span></span><br><span class="line"><span class="attr">  async:</span> <span class="number">1000</span> </span><br><span class="line">  <span class="comment">## register for later check</span></span><br><span class="line"><span class="attr">  register:</span> <span class="string">sleepTask</span></span><br><span class="line"><span class="attr">  when:</span> <span class="string">"inventory_hostname == groups.master[0]"</span></span><br><span class="line"><span class="attr">  args:</span></span><br><span class="line"><span class="attr">    creates:</span> <span class="string">/tmp/sleep.done</span></span><br><span class="line"></span><br><span class="line"><span class="attr">- name:</span> <span class="string">check</span> <span class="string">async</span> <span class="string">task</span> <span class="string">status</span></span><br><span class="line"><span class="attr">  any_errors_fatal:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment">## check async task status</span></span><br><span class="line"><span class="attr">  async_status:</span></span><br><span class="line"><span class="attr">    jid:</span> <span class="string">"<span class="template-variable">&#123;&#123; sleepTask.ansible_job_id &#125;&#125;</span>"</span></span><br><span class="line"><span class="attr">  register:</span> <span class="string">job_result</span></span><br><span class="line"><span class="attr">  until:</span> <span class="string">job_result.finished</span></span><br><span class="line"><span class="attr">  when:</span> <span class="string">"inventory_hostname == groups.master[0]"</span></span><br><span class="line"><span class="attr">  retries:</span> <span class="number">30</span></span><br><span class="line"><span class="attr">  delay:</span> <span class="number">3</span></span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="synchronize"><a href="#synchronize" class="headerlink" title="synchronize"></a>synchronize</h2><p>rsync wrapper</p>
<h2 id="loop"><a href="#loop" class="headerlink" title="loop"></a>loop</h2><p><a href="https://docs.ansible.com/ansible/2.4/playbooks_loops.html" target="_blank" rel="noopener">https://docs.ansible.com/ansible/2.4/playbooks_loops.html</a><br>items</p>
<h2 id="variables"><a href="#variables" class="headerlink" title="variables"></a>variables</h2><p>inventory_hostname<br>groups<br>jinjia2 template <figure class="highlight plain"><figcaption><span>&#125;&#125;```</span></figcaption><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">operator: in</span><br><span class="line"></span><br><span class="line">## conditional</span><br><span class="line">when clause</span><br><span class="line"></span><br><span class="line">```yaml</span><br><span class="line">## 不是每个module都支持creates的</span><br><span class="line">args:</span><br><span class="line">  creates: xxx</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Practical Vim, 2nd Edition</title>
    <url>/2019/08/06/book-vim/</url>
    <content><![CDATA[<p>看这种书挺枯燥，还是learn by doing 比较好，使用一段时间就很明确自己需要什么功能了。</p>
<blockquote>
<p>By default <code>oc/kubectl edit</code> will use <code>vi</code> in Linux if environment variable <code>OC _EDITOR</code> is empty, if you have <code>.vimrc</code> that is not compatible with <code>vi</code>, will get error message, to use <code>vim</code> set <code>export OC_EDITOR=vim</code> or <code>export KUBE_EDITOR=vim</code>.</p>
</blockquote>
<h1 id="Other-resources"><a href="#Other-resources" class="headerlink" title="Other resources"></a>Other resources</h1><p><a href="https://nvie.com/posts/how-i-boosted-my-vim/" target="_blank" rel="noopener">How I booted my Vim</a><br>Informative!! I grab lots of configurations from it, go and poke around the author’s vimrc file.</p>
<p><a href="http://derekwyatt.org/vim/tutorials/index.html" target="_blank" rel="noopener">Vim Tutorial Videos</a><br>There are a lot, see O`Reilly.</p>
<p>Actually you can learn <code>Vim</code> by running command <code>vimtutor</code> in your terminal, it is a simple and quick tutorial. For a quick review, just see summary after each lesson.</p>
<h1 id="Daily-Foundation"><a href="#Daily-Foundation" class="headerlink" title="Daily Foundation"></a>Daily Foundation</h1><p>掌握好这些操作基本上就满足日常需求了。</p>
<h2 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h2><p><code>.vimrc</code> is just like <code>.bashrc</code>. you create a <code>.vimrc</code> (even it’s empty) to tell vim use vim not vi-compatiable mode!</p>
<p>关于vimrc的配置，参考my github repo:<br><a href="https://github.com/chengdol/vim-configuration" target="_blank" rel="noopener">https://github.com/chengdol/vim-configuration</a></p>
<ol>
<li>Basic configuration</li>
<li>Custom key mapping</li>
<li>Vimscript plugin</li>
</ol>
<p>About mapping:</p>
<ul>
<li>nmap: normal mode</li>
<li>vmap: visual mode</li>
<li>imap: insert mode</li>
<li>map: normal, visual and operating-pending mode</li>
<li>map!: command and insert mode</li>
</ul>
<p>To list mapping: <code>:map</code> or more specific <code>:vmap</code></p>
<p>Which mode is currently use should be clear:  <code>Normal</code> mode, <code>Insert</code> mode and <code>Visual</code> mode, <code>Command-Line</code> mode, <code>Replace</code> mode, etc. <code>Visual</code> mode lets us select text in the <code>buffer</code> and then operate on the selection.</p>
<p>If you suspect that your customizations are causing interference, here’s a quick test. Try quitting Vim and then launching it with these options:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim -u NONE -N</span><br></pre></td></tr></table></figure></p>
<p>The <code>-u NONE</code> flag tells Vim not to source your <code>vimrc</code> on startup. That way, your customizations won’t be applied and plugins will be disabled. In older versions of Vim, not loading a <code>vimrc</code> file activates <code>vi</code> compatible mode, which causes many useful features to be disabled. The <code>-N</code> flag prevents this by setting the <code>nocompatible</code> option. Since version 8.0 of Vim, the <code>nocompatible</code> option is set by default, making the <code>-N</code> flag unnecessary.</p>
<p><code>vim -N file</code>: <code>-N</code> not using vi compatible mode, use newer vim mode. or can configuring in <code>.vimrc</code> file.</p>
<p><code>:set list</code>, <code>:set nolist</code>, <code>:set list?</code>, <code>:set list&amp;</code>: set, unset, check value, set as default. 以此类推.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set autochdir &quot;auto set current dir as working dir</span><br><span class="line">set wildmode=list:longest &quot;activate TAB auto-complete file path</span><br></pre></td></tr></table></figure></p>
<p><strong>Reload .vimrc</strong><br>Reload .vimrc without restarting vim: <code>:source ~/.vimrc</code>. 已经加入vimrc了。</p>
<h2 id="Plugin"><a href="#Plugin" class="headerlink" title="Plugin"></a>Plugin</h2><p>Vim 8.0 has its own built-in package manager. For Vim version less than 8.0, I use <code>vim-plug</code> as the plugin manager:<br><a href="https://github.com/junegunn/vim-plug" target="_blank" rel="noopener">https://github.com/junegunn/vim-plug</a><br>You can even specify git address of the plugin, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Plug &apos;https://github.com/tfnico/vim-gradle.git&apos;</span><br></pre></td></tr></table></figure></p>
<p>If the plugin does not get auto installed, run <code>:PlugInstall</code>, check the plug status by <code>:PlugStatus</code>. 这些在<code>vim-plug</code> README中都有说明。</p>
<blockquote>
<p>Please see my <a href="https://github.com/chengdol/vim-configuration" target="_blank" rel="noopener">vim-configuration git repo</a>, download the vimrc file.</p>
</blockquote>
<ul>
<li>nerdtree: file system explorer for vim editor</li>
<li>fuzzyfinder: fzf</li>
<li>buffer explorer: 比默认的buffer要好看</li>
<li>taglist: source code browser</li>
</ul>
<p>NERDTree，在目录界面中通过<code>m</code>启动常规文件/文件夹操作。<code>C</code>回车 进入子文件夹。</p>
<h2 id="Display-Management"><a href="#Display-Management" class="headerlink" title="Display Management"></a>Display Management</h2><p>Vim中切换编辑多个文件：<br><code>:cd /tmp</code> change vim working directory<br><code>:pwd</code> show current working directory<br><code>:set hidden</code> (put it in <code>.vimrc</code>): <a href="https://medium.com/usevim/vim-101-set-hidden-f78800142855" target="_blank" rel="noopener">https://medium.com/usevim/vim-101-set-hidden-f78800142855</a><br><code>:e .</code> browse current directory, select file to edit</p>
<p><code>:ls</code> list buffer (open files)</p>
<ul>
<li>%: buffer in current window</li>
<li>+: unsave changes</li>
<li>=: read-only</li>
</ul>
<p><code>:bn</code> go to next buffer<br><code>:bp</code> go to previous buffer<br><code>:bd</code> delete buffer, such as <code>:bd5</code><br><code>:bf</code> go to first buffer<br><code>:bl</code> go to last buffer<br><code>:b3</code> go to 3rd buffer<br><code>gf</code> jump to the file under the cursor, use <code>ctrl+o</code> jump back</p>
<p>可以在vim <code>:e &lt;path&gt;</code> 中直接创建，删除文件或者文件夹，显示long format, sort等</p>
<blockquote>
<p>在使用<code>vim-plug</code>加载插件后，这部分功能失效了, 不过可以使用command mode去做查看。</p>
<ul>
<li>i: long, thin, tree format</li>
<li>s: sort by name, time, file size</li>
<li>r: reverse sort order</li>
<li>gh: hide or unhide dotfiles</li>
<li>d: make a directory</li>
<li>D: delete file or directory</li>
<li>R: rename file or dir</li>
<li>-: go up a directory</li>
</ul>
</blockquote>
<h3 id="windows-amp-splits"><a href="#windows-amp-splits" class="headerlink" title="windows &amp; splits"></a>windows &amp; splits</h3><p>All start with <code>ctrl+w</code>:</p>
<ul>
<li>s: split horizontally </li>
<li>h: move focus left</li>
<li><p>l: move focus right</p>
</li>
<li><p>v: split vertically</p>
</li>
<li>j: move focus down</li>
<li><p>k: move focus up</p>
</li>
<li><p>w: cycle focus</p>
</li>
<li><p>p: focus previous win</p>
</li>
<li><p>c: close win current focus</p>
</li>
<li>o: close all win except current focus</li>
</ul>
<p><code>:h window-resize</code>, check for window resize.</p>
<ul>
<li>+: enlarge windows, <code>5+</code></li>
<li>-: reduce windows, <code>3-</code></li>
</ul>
<h3 id="Tab"><a href="#Tab" class="headerlink" title="Tab"></a>Tab</h3><p>各个文件单独的tab，不用划分window了, 这个部分是放在vimrc中的:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot; Tab mappings</span><br><span class="line">&quot; The default leader key is \</span><br><span class="line">let mapleader=&quot;,&quot;                        &quot; remap leader key to ,</span><br><span class="line">&quot; invoke for example: ,tt</span><br><span class="line">map &lt;leader&gt;tt :tabnew&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;te :tabedit</span><br><span class="line">map &lt;leader&gt;tc :tabclose&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;to :tabonly&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;tn :tabnext&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;tp :tabprevious&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;tf :tabfirst&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;tl :tablast&lt;cr&gt;</span><br><span class="line">map &lt;leader&gt;tm :tabmove</span><br></pre></td></tr></table></figure></p>
<p>What is <code>Leader key</code> in Vim?<br><a href="https://stackoverflow.com/questions/1764263/what-is-the-leader-in-a-vimrc-file" target="_blank" rel="noopener">https://stackoverflow.com/questions/1764263/what-is-the-leader-in-a-vimrc-file</a><br>The <code>Leader key</code> is a way of extending the power of VIM’s shortcuts by using sequences of keys to perform a command.</p>
<h2 id="Operation"><a href="#Operation" class="headerlink" title="Operation"></a>Operation</h2><p>Using <code>hjkl</code> (在后续许多命令中都有涉及) or <code>arrow</code> keys to move around, can have number ahead to indicate how many line to move.</p>
<p><code>:q!</code> quit without saving.<br><code>:wq</code> quit with saving, always retouch the timestamp.<br>sometimes using <code>:q!</code> and <code>:wq!</code>: <a href="https://unix.stackexchange.com/questions/88247/use-of-in-vim" target="_blank" rel="noopener">https://unix.stackexchange.com/questions/88247/use-of-in-vim</a></p>
<p><code>:x</code> the same as <code>:wq</code>, but write only when changes have been made.<br><code>:w filename</code> used to save file to <code>filename</code>.<br><code>:w !sudo tee %</code> write to sudo with current file name, <code>%</code> represent current file name. (用在保存更改read-only文件的内容)</p>
<p><a href="https://medium.com/usevim/vim-101-quick-movement-c12889e759e0" target="_blank" rel="noopener">Quick Movement</a><br><code>A</code> append at end of the line, <code>a</code> appends after cursor.<br><code>I</code> insert ata head of the line, <code>i</code> insert at cursor.<br><code>W</code> jump contiguous words, <code>w</code> jump one word.<br><code>o</code> will open a line below cursor, <code>O</code> open above.<br><code>3w</code> move 3 words forward, <code>0</code> move to the start of the line.<br><code>^</code> go to first non-empty char in line<br><code>3fn</code> find 3rd <code>n</code> char at this line. repeat by <code>;</code></p>
<h3 id="Screen-line-movement"><a href="#Screen-line-movement" class="headerlink" title="Screen line movement"></a>Screen line movement</h3><p>screen line指被terminal因宽度限制产生的行，并不是指原始的很长的那一行。<br><code>g0</code>, <code>gm</code>, <code>g$</code>: start, middle, end of a line.<br><code>gk</code>, <code>gj</code>: move up/down in screan line (can use arrow instead k/j ).</p>
<h3 id="Scrolling"><a href="#Scrolling" class="headerlink" title="Scrolling"></a>Scrolling</h3><p>Press <code>G</code> to move you to the bottom of the file.<br>Type <code>gg</code> to move you to the start of the file.<br><code>line number + G</code> or <code>line number + gg</code> will go to the line specified.<br>To go back to where you came from press <code>Ctrl-o</code> (Keep <code>Ctrl</code> down while pressing the letter <code>o</code>). To go forward <code>Ctrl-i</code><br><code>H</code>, <code>M</code> and <code>L</code> move the cursor to top, medium and bottom of current page<br><code>zt</code>, <code>zz</code>, <code>zb</code>: move cursor line to top, middle, bottom of screen</p>
<h3 id="Make-Mark"><a href="#Make-Mark" class="headerlink" title="Make Mark"></a>Make Mark</h3><p>For example, jump back and forth spots:<br><a href="https://www.linux.com/news/vim-tips-moving-around-using-marks-and-jumps/" target="_blank" rel="noopener">https://www.linux.com/news/vim-tips-moving-around-using-marks-and-jumps/</a><br><code>:marks</code></p>
<h3 id="Shift"><a href="#Shift" class="headerlink" title="Shift"></a>Shift</h3><p>Shift configuration is in <code>.vimrc</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot; shift with tab</span><br><span class="line">set tabstop=2                    &quot; Global tab width.</span><br><span class="line">set shiftwidth=2                 &quot; And again, related.</span><br><span class="line">set expandtab                    &quot; Use spaces instead of tabs</span><br><span class="line">&quot; extremely useful to edit yaml file</span><br><span class="line">set autoindent                   &quot; always set autoindenting on</span><br><span class="line">set copyindent                   &quot; copy the previous indentation on autoindentin</span><br></pre></td></tr></table></figure></p>
<p><code>:retab</code>: replace all tabs with spaces in current buffer.</p>
<p><code>&gt;&gt;</code>, <code>&lt;&lt;</code> shift current line, <code>4&gt;&gt;</code>, <code>4&lt;&lt;</code> block shift with 4 lines together.<br>In insert mode, can use tab itself to shift (now override by auto-complete in my vimrc file), or using <code>ctrl+t</code>, <code>ctrl+d</code>: shift right and left.</p>
<p>对于code block indention，我在.vimrc 中设置了vmap, 用visual mode选中后shift就很方便了。</p>
<h3 id="Search-and-Replace"><a href="#Search-and-Replace" class="headerlink" title="Search and Replace"></a>Search and Replace</h3><p><code>/</code> search forward, <code>?</code> search backword. when hit the search, <code>n</code> go forward, <code>N</code> go backword. If the cursor is at search word, use <code>*</code> to search forward, <code>#</code> search back, use <code>g*</code>, <code>g#</code> do partial match search.</p>
<p><code>/case\c</code> search case-insensitive, <code>/CaSe\C</code> search case-sensitive. <code>\c</code> and <code>\C</code> can be anywhere in pattern.</p>
<p><code>:s/old/new/g</code> to substitute <code>old</code> by <code>new</code> in a line for all occrurences. you must place the cursor in that line.<br>To change every occurrence of a character string between two lines,<br><code>:#,#s/old/new/g</code> where <code>#,#</code> are the line numbers of the range of lines where the substitution is to be done.<br><code>:%s/old/new/g</code>  to change every occurrence in the whole file.<br><code>:%s/old/new/gc</code> to find every occurrence in the whole file, with a prompt whether to substitute or not, <code>c</code> is confirmation.</p>
<p>For case-sensitive: <code>:%s/old/new/Igc</code>, but actually can be <code>:%s/old\C/new/gc</code>.</p>
<h3 id="Copy-and-Paste"><a href="#Copy-and-Paste" class="headerlink" title="Copy and Paste"></a>Copy and Paste</h3><p>这里和vim 的 register有关. Default is unnamed register, delete, change, substitute, search and yank all use registers.</p>
<blockquote>
<p>Pasting text into a terminal running Vim with automatic indentation enabled can destroy the indentation of the pasted text: <a href="https://vim.fandom.com/wiki/Toggle_auto-indenting_for_code_paste" target="_blank" rel="noopener">https://vim.fandom.com/wiki/Toggle_auto-indenting_for_code_paste</a>, use <code>vim-bracketed-paste</code> can fix this.</p>
</blockquote>
<p>Show register contents: <code>:registers</code></p>
<p><code>y</code> is copy operator, for example, <code>yw</code> copy one word, <code>y$</code> copy to end of the line and <code>yy</code> used to copy a line, then you can paste through <code>p</code>. you can use <code>v</code> to select and copy. By default it uses unnamed register. Register <code>0</code> always stores the yank content, so you can use <code>&quot;0p</code> to paste.</p>
<p><code>&quot;ayy</code>, <code>&quot;ap</code> use register <code>a</code> to yank and paste. Usually we use <code>a~z</code> and <code>A~Z</code> register, the uppercase register can append text to current content.</p>
<p>使用上不同文件之间copy/paste没啥问题，但如果需要copy到system clipboard，需要设置:<br><a href="https://stackoverflow.com/questions/3961859/how-to-copy-to-clipboard-in-vim" target="_blank" rel="noopener">https://stackoverflow.com/questions/3961859/how-to-copy-to-clipboard-in-vim</a><br>vim has to be compiled with clipboard support for any of the suggestions mentioned here to work. Mine wasn’t configured that way on Mac OS X by default and I had to rebuild vim. Use this the command to find out whether you have it or not:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim --version | grep &apos;clipboard&apos;</span><br></pre></td></tr></table></figure></p>
<p><code>+clipboard</code> means you’re good and the suggestions here will work for you, while <code>-clipboard</code> means you have to recompile and rebuild vim.</p>
<p><code>d</code> is the <strong>delete operator</strong>, use <strong>motion</strong> to specify the action, for example <code>dw</code>, <code>de</code>, <code>d$</code>. Without <code>d</code>, vim just move the cursor: <code>w</code>, <code>e</code>, <code>$</code><br><code>2dw</code> delete 2 words ahead<br><code>4dd</code> delete 4 lines in a row<br>Type <code>p</code> to put previously <code>deleted</code> text after the cursor. for example, you delete a line and replace it in another place</p>
<p><code>v</code> and then you move the cursor to select the text you want, if you want to delete them next, type <code>d</code>, if you want to save the selected text to another file, press <code>:</code>, then type <code>w filename</code>. <code>V</code> is moved linewise.</p>
<h3 id="Folding"><a href="#Folding" class="headerlink" title="Folding"></a>Folding</h3><p>这个非常有用，比如编辑yaml 文件。<br>Fold by syntax or indent (yaml). <code>:sed foldmethod=indent/syntax</code><br><code>zM</code>, <code>zR</code>: fold and unfold all<br><code>zi</code>: toggle fold all<br><code>zc</code>, <code>zo</code>: close, open fold block<br><code>za</code>: toggle fold block<br><code>zk</code>, <code>zj</code>: move fold focus up and down</p>
<p>还可以根据file type去设定, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot; Automatic fold settings for specific files. Uncomment to use.</span><br><span class="line">&quot; autocmd FileType ruby setlocal foldmethod=syntax</span><br><span class="line">&quot; autocmd FileType css  setlocal foldmethod=indent shiftwidth=2 tabstop=2</span><br></pre></td></tr></table></figure></p>
<h3 id="Recording"><a href="#Recording" class="headerlink" title="Recording"></a>Recording</h3><p>暂时没用到，对重复的复杂操作有用。</p>
<h3 id="others"><a href="#others" class="headerlink" title="others"></a>others</h3><p>Press <code>u</code> to undo the last commands, <code>U</code> to undo all the changes in a line.<br><code>crtl+r</code> to undo undo.</p>
<p>Type <code>rx</code> to replace the one character at the cursor with  <code>x</code>. <code>R</code> is used to replace more then one chars, type <code>R</code> then get into insert mode.</p>
<p><code>ce</code> deletes the word and places you in Insert mode, so you can type new word, it will replace old ones. <code>c</code> is <strong>change operator</strong>, just like <code>d</code>.<br>比如要更改3个连续的words 在某行中: <code>c3w</code>, then type.</p>
<p><code>Ctrl+g</code> will show cursor location in the file and the file status, also the file name.</p>
<p><code>%</code> is used tp match another part of <code>(, [ or {</code>. This is very useful in debugging a program with unmatched parentheses. 也可以用来match其他block语句，比如if-end。</p>
<p><code>:!&lt;commands&gt;</code> is used to execute external commands, for example <code>:!ls -ltr /tmp</code>. (the same as IPython)</p>
<p><code>:r filename</code> will retrive the file placed under the cursor. you can also read the output of an external command, <code>:r !ls -ltr</code>.</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title>Kubernetes Operators</title>
    <url>/2020/06/03/book-k8s-operator/</url>
    <content><![CDATA[<p>这段时间开始研究Operator了，刚好有这本书，计划快速过一遍，recap quick start.<br>Git repository:<br><a href="https://github.com/kubernetes-operators-book/chapters" target="_blank" rel="noopener">https://github.com/kubernetes-operators-book/chapters</a></p>
<p>首先，从K8s官网上粗略地了解一下什么是:</p>
<ul>
<li><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/" target="_blank" rel="noopener">Operator pattern</a></li>
<li><a href="https://github.com/operator-framework" target="_blank" rel="noopener">Operator framework</a></li>
<li><a href="https://coreos.com/blog/introducing-operators.html" target="_blank" rel="noopener">Introducing Operators: Putting Operational Knowledge into Software</a></li>
<li><a href="https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-building-kubernetes-operators-and-stateful-apps" target="_blank" rel="noopener">Best practices for building Kubernetes Operators and stateful apps</a></li>
</ul>
<h1 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1 Introduction"></a>Chapter 1 Introduction</h1><p>An Operator continues to monitor its application as it runs, and can back up data, recover from failures, and upgrade the application over time, automatically.</p>
<p>An Operator is a custom Kubernetes controller watching a CR type and taking application-specific actions to make reality match the spec in that resource.</p>
<p>Making an Operator means creating a CRD and providing a program that runs in a loop watching CRs of that kind. </p>
<p>The Operator pattern arose in response to infrastructure engineers and developers wanting to extend Kubernetes to provide features specific to their sites and software.</p>
<p>看到这里产生了一个疑问: Helm and Operator.</p>
<ul>
<li><a href="https://medium.com/@cloudark/kubernetes-operators-and-helm-it-takes-two-to-tango-3ff6dcf65619" target="_blank" rel="noopener">Kubernetes Operators and Helm — It takes Two to Tango</a></li>
<li><a href="https://www.openshift.com/blog/make-a-kubernetes-operator-in-15-minutes-with-helm" target="_blank" rel="noopener">Make a Kubernetes Operator in 15 minutes with Helm</a></li>
</ul>
<h1 id="Chapter-2-Running-Operators"><a href="#Chapter-2-Running-Operators" class="headerlink" title="Chapter 2 Running Operators"></a>Chapter 2 Running Operators</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## need cluster wide privilege</span></span><br><span class="line">kubectl describe clusterrole cluster-admin</span><br><span class="line"></span><br><span class="line"><span class="comment">## good</span></span><br><span class="line">Name:         cluster-admin</span><br><span class="line">Labels:       kubernetes.io/bootstrapping=rbac-defaults</span><br><span class="line">Annotations:  rbac.authorization.kubernetes.io/autoupdate: <span class="literal">true</span></span><br><span class="line">PolicyRule:</span><br><span class="line">  Resources  Non-Resource URLs  Resource Names  Verbs</span><br><span class="line">  ---------  -----------------  --------------  -----</span><br><span class="line">  *.*        []                 []              [*]</span><br><span class="line">             [*]                []              [*]</span><br></pre></td></tr></table></figure>
<p>Start with <code>etcd</code> as ‘hello world’ example. Deviation:</p>
<ul>
<li>Raft protocol: <a href="https://raft.github.io/" target="_blank" rel="noopener">https://raft.github.io/</a></li>
</ul>
<p>you’ll deploy the etcd Operator, then have it create an etcd cluster according to your specifications. You will have the Operator recover from failures and perform a version upgrade while the etcd API continues to service read and write requests, showing how an Operator automates the lifecycle of a piece of foundation software.</p>
<p>A <code>CRD</code> is akin to a schema for a <code>CR</code>, defining the <code>CR</code>’s fields and the types of values those fields contain:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apiextensions.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CustomResourceDefinition</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcdclusters.etcd.database.coreos.com</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  group:</span> <span class="string">etcd.database.coreos.com</span></span><br><span class="line"><span class="attr">  names:</span></span><br><span class="line"><span class="attr">    kind:</span> <span class="string">EtcdCluster</span></span><br><span class="line"><span class="attr">    listKind:</span> <span class="string">EtcdClusterList</span></span><br><span class="line"><span class="attr">    plural:</span> <span class="string">etcdclusters</span></span><br><span class="line"><span class="attr">    shortNames:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">etcdclus</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">etcd</span></span><br><span class="line"><span class="attr">    singular:</span> <span class="string">etcdcluster</span></span><br><span class="line"><span class="attr">  scope:</span> <span class="string">Namespaced</span></span><br><span class="line"><span class="attr">  version:</span> <span class="string">v1beta2</span></span><br><span class="line"><span class="attr">  versions:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">v1beta2</span></span><br><span class="line"><span class="attr">    served:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p>
<p>The <code>CR</code>’s group, version, and kind together form the fully qualified name of a Kubernetes resource type. That canonical name must be unique across a cluster.</p>
<p>Defining an Operator Service Account:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator-sa</span></span><br></pre></td></tr></table></figure></p>
<p>Defining role:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator-role</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">etcd.database.coreos.com</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">etcdclusters</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">etcdbackups</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">etcdrestores</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">'*'</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">pods</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">services</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">endpoints</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">persistentvolumeclaims</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">events</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">'*'</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">apps</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">deployments</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">'*'</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">secrets</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">get</span></span><br></pre></td></tr></table></figure></p>
<p>Defining rolebinding, assigns the role to the service account for the etcd Operator:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">RoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator-rolebinding</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">Role</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator-role</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator-sa</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">default</span></span><br></pre></td></tr></table></figure></p>
<p>The Operator is a custom controller running in a pod, and it watches the EtcdCluster CR you defined earlier.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">etcd-operator</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">etcd-operator</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">etcd-operator</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">etcd-operator</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">quay.io/coreos/etcd-operator:v0.9.4</span></span><br><span class="line"><span class="attr">        command:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">etcd-operator</span></span><br><span class="line"><span class="bullet">        -</span> <span class="bullet">--create-crd=false</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_POD_NAMESPACE</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">MY_POD_NAME</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">metadata.name</span></span><br><span class="line"><span class="attr">        imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">etcd-operator-sa</span></span><br></pre></td></tr></table></figure></p>
<p>Declaring an etcd cluster:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">etcd.database.coreos.com/v1beta2</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">EtcdCluster</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">example-etcd-cluster</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  size:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  version:</span> <span class="number">3.1</span><span class="number">.10</span></span><br></pre></td></tr></table></figure></p>
<p>After create <code>CR</code> resource, operator will generate 3 replicas pod (the pod definition is written by operator logic).</p>
<p>This example etcd cluster is a first-class citizen, an <code>EtcdCluster</code> in your cluster’s API. Since it’s an API resource, you can get the etcd cluster spec and status directly from Kubernetes.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## etcdcluster is a resource just like pod/deploy/sts</span></span><br><span class="line">kubectl describe etcdcluster example-etcd-cluster</span><br></pre></td></tr></table></figure></p>
<p>The etcd Operator creates a Kubernetes service in the etcd cluster’s namespace:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get services --selector etcd_cluster=example-etcd-cluster</span><br></pre></td></tr></table></figure></p>
<p>Run the etcd client on the cluster and use it to connect to the client service and interact with the etcd API.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl run --rm -i --tty etcdctl --image quay.io/coreos/etcd --restart=Never -- /bin/sh</span><br></pre></td></tr></table></figure></p>
<p>From the etcd container’s shell, create and read a key-value pair in etcd with etcdctl’s put and get verbs:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> ETCDCTL_API=3</span><br><span class="line"><span class="built_in">export</span> ETCDCSVC=http://example-etcd-cluster-client:2379</span><br><span class="line">etcdctl --endpoints <span class="variable">$ETCDCSVC</span> put foo bar</span><br><span class="line">etcdctl --endpoints <span class="variable">$ETCDCSVC</span> get foo</span><br><span class="line"></span><br><span class="line"><span class="comment">## check etcd cluster general health</span></span><br><span class="line">etcdctl --endpoints http://example-etcd-cluster-client:2379 cluster-health</span><br></pre></td></tr></table></figure></p>
<p>You can try to delete etcd pod or upgrade the version (edit cr file then apply) and watching the operator recover the health.</p>
<p>kubectl tricks for upgrade:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl patch etcdcluster example-etcd-cluster --<span class="built_in">type</span>=<span class="string">'json'</span> \</span><br><span class="line">  -p <span class="string">'[&#123;"op": "replace", "path": "/spec/version", "value":3.3.12&#125;]'</span></span><br></pre></td></tr></table></figure></p>
<h1 id="Chapter-3-Operators-at-the-Kubernetes-Interface"><a href="#Chapter-3-Operators-at-the-Kubernetes-Interface" class="headerlink" title="Chapter 3 Operators at the Kubernetes Interface"></a>Chapter 3 Operators at the Kubernetes Interface</h1><p>Operators extend two key Kubernetes concepts: <code>resources</code> and <code>controllers</code>. The Kubernetes API includes a mechanism, the CRD, for defining new resources.</p>
<p>这2段话把一般通用控制器和operator的区别讲清楚了:</p>
<blockquote>
<p>The actions the ReplicaSet controller takes are intentionally general and application agnostic. It does not, should not, and truly cannot know the particulars of startup and shutdown sequences for every application that might run on a Kubernetes cluster.</p>
</blockquote>
<blockquote>
<p>An Operator is the application-specific combination of CRs and a custom controller that does know all the details about starting, scaling, recovering, and managing its application.</p>
</blockquote>
<p>Every Operator has one or more custom controllers implementing its application-specific management logic.</p>
<p>An Operator, in turn, can be limited to a namespace, or it can maintain its operand across an entire cluster.</p>
<p>For example, cluster-scoped operator:</p>
<blockquote>
<p>Istio operator: <a href="https://github.com/istio/operator" target="_blank" rel="noopener">https://github.com/istio/operator</a><br>cert-manager: <a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">https://github.com/jetstack/cert-manager</a></p>
</blockquote>
<p>A <code>service account</code> is a special type of cluster user for authorizing programs instead of people. An Operator is a program that uses the Kubernetes API, and most Operators should derive their access rights from a service account. </p>
<h1 id="Chapter-4-The-Operator-Framework"><a href="#Chapter-4-The-Operator-Framework" class="headerlink" title="Chapter 4 The Operator Framework"></a>Chapter 4 The Operator Framework</h1><p>This chapter introduced the three pillars of the Operator Framework: the Operator SDK for building and developing Operators; Operator Lifecycle Manager for distributing, installing, and upgrading them; and Operator Metering for measuring Operator performance and resource consumption.</p>
<p>The <code>Red Hat Operator Framework</code> makes it simpler to create and distribute Operators. It makes building Operators easier with a <code>software development kit (SDK)</code> that automates much of the repetitive implementation work. The Framework also provides mechanisms for deploying and managing Operators. <code>Operator Lifecycle Manager (OLM)</code> is an Operator that installs, manages, and upgrades other Operators. <code>Operator Metering</code> is a metrics system that accounts for Operators’ use of cluster resources.</p>
<p><code>Operator SDK</code>: <a href="https://github.com/operator-framework/operator-sdk" target="_blank" rel="noopener">https://github.com/operator-framework/operator-sdk</a><br>The SDK currently includes first-class support for constructing Operators in the <code>Go</code> programming language, with support for other languages planned. The SDK also offers what might be described as an adapter architecture for <code>Helm</code> charts or <code>Ansible</code> playbooks. </p>
<p><code>Operator Lifecycle Manager</code> takes the Operator pattern one level up the stack: it’s an Operator that acquires, deploys, and manages Operators on a Kubernetes cluster.</p>
<p><code>Operator Metering</code> is a system for analyzing the resource usage of the Operators running on Kubernetes clusters.</p>
<h1 id="Chapter-5"><a href="#Chapter-5" class="headerlink" title="Chapter 5"></a>Chapter 5</h1>]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>kubernetes</tag>
        <tag>operator</tag>
      </tags>
  </entry>
  <entry>
    <title>System Design</title>
    <url>/2019/11/29/design-system/</url>
    <content><![CDATA[<p>This blog is for system design, please revisit frequently to refresh. The notes are mainly from <code>https://www.educative.io/</code> and Youtube channel.</p>
<p>有的系统设计主要是各功能部件合理组合:</p>
<ol>
<li>Design Instagarm</li>
<li>Design Dropbox</li>
<li>Design Twitter<br>post tweets(photos, videos), follow others, favorite tweets<br>generate timeline of top tweets<br>low latancy<br>highly available<br>consistency can take a hit</li>
</ol>
<p>storage: text + photo + video<br>ingress (write): new generated storage / sec<br>egress (read): read volume / sec</p>
<p>read heavy system<br>data sharding: user id -&gt; tweet id -&gt; (creation time + tweet id, sort by time)<br>query all servers and aggregate</p>
<p>cache for hot users and tweets</p>
<ol start="4">
<li>Designing Twitter Search</li>
<li><p>Designing a Web Crawler (BFS, modular, url frontier, DNS, fetcher, DIS, content filter, extractor, url filter)</p>
</li>
<li><p>Designing Facebook Messenger<br>each chat server serves a bunch of users, LB maps user to it’s chat server, chat server commuicate with each other to send/receive message<br>message handling: long polling to receive message<br>hashtable keep track of online user, if offline, notify delivery failure to sender<br>handle message order: 单独靠timestamp不行，use sequence number with every message for each user</p>
</li>
</ol>
<p>database: support high frequence write/read row, quick small updates, range based search: HBase, column-oriented key-value NoSQL database<br>partition by UserID, low latency</p>
<p>有的主要涉及到了数据结构和算法:</p>
<ol>
<li>Typeahead suggestion (trie, reference)</li>
<li>API rate limiter (dynamic sliding window)</li>
<li><p>Designing Facebook’s Newsfeed (offline feed generation)<br>contain updates, posts, video, photos from all people user follows<br>user average has 200 followers, 300M DAU, fetch 5 times a day, 1KB each post, so can get traffic.<br>cache each users’ news feed in mem for quick fetch.<br>feed generation:<br>retrieve, rank, store<br>offline generate by dedicated servers, <code>Map&lt;UserID, LikedHashMap/TreeMap&lt;PostID, PostItem&gt;&gt; + LastGenerateTime</code> in memory, LRU cache for user or find user’s activity pattern to help generate newsfeed<br>feed publishing:<br>push to notify, pull for serving</p>
</li>
<li><p>Designing Yelp (querying, objects don’t change often, QuadTree)<br>解释一下我的理解，这里partition讲的是partition quadtree.<br>从DB中读location id, 通过hashing map to different quadtree server (这个mapping其实就是quadtree index，可以在quadtree server fail后用来重新构造它的数据)，然后各自构造自己的quadtree.这些quadtree servers有一个aggregator server（它有自己的copies）。于是每次request要去所有quadtree server查询，然后聚合返回的数据。对于每个quadtree server，它所包含的location id也有一个本地的mapping, to know which DB servers contains this locatio id info. 这个mapping也使用的hashing实现。</p>
</li>
<li><p>Designing Uber backend (requirements, objects do change often, QuadTree)</p>
</li>
<li>Design Ticketmaster (first come first serve, highly concurrent, financial transactions ACID)</li>
</ol>
<h1 id="CAP-Theorem"><a href="#CAP-Theorem" class="headerlink" title="CAP Theorem"></a>CAP Theorem</h1><p>CAP theorem states that it is impossible for a distributed software system to simultaneously provide more than two out of three of the following guarantees (CAP): <code>Consistency</code>, <code>Availability</code>, and <code>Partition tolerance</code>.</p>
<p>When we design a distributed system, trading off among <code>CAP</code> is almost the first thing we want to consider.</p>
<h1 id="Thinking-process"><a href="#Thinking-process" class="headerlink" title="Thinking process"></a>Thinking process</h1><ol>
<li>requirements clarification</li>
<li>back of the envelope estimation: scale, storate, bandwidth.</li>
<li>system interface definition</li>
<li>defining data model</li>
<li>high level design</li>
<li>detailed design</li>
<li>identifying and resolving bottlenecks</li>
</ol>
<h1 id="Crucial-Components"><a href="#Crucial-Components" class="headerlink" title="Crucial Components"></a>Crucial Components</h1><p>这里的笔记主要根据以下几点展开:</p>
<ol>
<li>Database (book: 7 weeks 7 databases)</li>
<li>Cache system (redis, memcache)</li>
<li>Message queue (kafka &amp;&amp; zookeeper or others)</li>
<li>Load balancer (nginx, Round Robin approach)</li>
<li>Log systems</li>
<li>monitor system</li>
<li>My domain of knowledge k8s, docker, micro-services</li>
</ol>
<h1 id="Key-Characteristics-of-Distributed-Systems"><a href="#Key-Characteristics-of-Distributed-Systems" class="headerlink" title="Key Characteristics of Distributed Systems"></a>Key Characteristics of Distributed Systems</h1><p>Scalability: scaling without performance loss (but actually will).<br>Reliability: keep delivering services when some components fail.<br>Availability: reliable means available, but not vice versa<br>Efficiency: latency and (throughput)bandwidth.<br>Manageability: ease of diagnosing and understanding problems when they occur.</p>
<h1 id="常用技术知识"><a href="#常用技术知识" class="headerlink" title="常用技术知识"></a>常用技术知识</h1><h2 id="备份的说法"><a href="#备份的说法" class="headerlink" title="备份的说法:"></a>备份的说法:</h2><p>Standby replicas<br>Failover to other healthy copies<br>Duplicates<br>Backup (spare)<br>Redundancy (redundant secondary copy)</p>
<h2 id="NoSQL-Database"><a href="#NoSQL-Database" class="headerlink" title="NoSQL Database:"></a>NoSQL Database:</h2><p><a href="https://www.youtube.com/watch?v=uD3p_rZPBUQ" target="_blank" rel="noopener">An Introduction To NoSQL Databases</a><br><strong>Big Data</strong>: social network, search engine, traditional methods of processing and storage are inadequate.</p>
<ol>
<li>Key-value stores: Redis, Dynamo (redis can also be cache)</li>
<li>Document database: MongoDB, Couchbase</li>
<li><a href="https://www.youtube.com/watch?v=8KGVFB3kVHQ" target="_blank" rel="noopener">Wide-column database</a>: Cassandra, HBase</li>
<li>Graph database: Neo4J</li>
</ol>
<p>Advantage of NOSQL database：<br>no data models(no pre-defind schema), unstructed , easy to scale up and down (horizontal data sharding), high performance with big data.</p>
<p>Advantage of SQL database:<br>relational data, normalization (eliminate redundancy), SQL, data integrity, ACID compliance.</p>
<h2 id="Consistent-Hashing-with-virtual-replicas"><a href="#Consistent-Hashing-with-virtual-replicas" class="headerlink" title="Consistent Hashing (with virtual replicas)"></a>Consistent Hashing (with virtual replicas)</h2><p><a href="https://www.youtube.com/watch?v=ffE1mQWxyKM" target="_blank" rel="noopener">https://www.youtube.com/watch?v=ffE1mQWxyKM</a><br>Using hash <code>mod</code> strategy is not efficient, think about that add a new server, then original 20 % 3 = 2 now is 20 % 4 = 0. We have to <strong>re-organize</strong> all the existing mappings.</p>
<p><a href="https://www.youtube.com/watch?v=zaRkONvyGr8" target="_blank" rel="noopener">https://www.youtube.com/watch?v=zaRkONvyGr8</a><br>Consistent hashing can be used in many situations, like distributed cache, load balancing, database, etc.</p>
<p>For example, we have <code>n</code> servers.<br>Hash the request and get the location of it in the <code>ring</code>, find the server with hash value equal or larger than it and send this request to that server (clockwise move). But server may not distributed in ring evenly or the requests is not uniformly (thus server load factor is not <code>1/n</code>), so we can use <strong>virtual replicas</strong>, this can implement by other hash function.</p>
<p>With contsistent hashing, add or remove servers will not cause much overhead. The new added server will grab objects from its near servers and removed server, all original objects will move to next server after the removed one.</p>
<h2 id="Long-Polling-轮询"><a href="#Long-Polling-轮询" class="headerlink" title="Long Polling (轮询)"></a>Long Polling (轮询)</h2><p><a href="https://www.jianshu.com/p/d3f66b1eb748?from=timeline&amp;isappinstalled=0" target="_blank" rel="noopener">https://www.jianshu.com/p/d3f66b1eb748?from=timeline&amp;isappinstalled=0</a><br>和一般的polling都属于pull(拉模式)。</p>
<blockquote>
<p>题外话: push模式其实也是建立了一个持久的connection，但server一旦有新的信息就会push给client，而不会去在乎client的处理能力，这是一个缺点, long polling对于client要更灵活一些（因为client会request first）。</p>
</blockquote>
<p>This is a variation of the traditional polling technique that allows the server to push information to a client whenever the data is available. With Long-Polling, the client requests information from the server exactly as in normal polling, but with the expectation that the server may not respond immediately (keep the connection connected). That’s why this technique is sometimes referred to as a <code>Hanging GET</code>.</p>
<p>Each Long-Poll request has a <code>timeout</code>. The client has to reconnect periodically after the connection is closed due to timeouts or receive the disconnect from server.</p>
<p>如果client突然unavailable了，如何检测呢？这个connection是如何保持的？我猜想的是connection保持期间，并不需要额外的sync查看server client是否健在(我记得TCP有一个机制会检测这个connection是否健康？)。如果server 发送了message未收到acknowledge则说明client不在了，则connection中断。</p>
<h2 id="Data-Sharding"><a href="#Data-Sharding" class="headerlink" title="Data Sharding"></a>Data Sharding</h2><p><a href="https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6" target="_blank" rel="noopener">https://medium.com/@jeeyoungk/how-sharding-works-b4dec46b3f6</a><br><code>Horizontal partitioning</code> is also called as Data Sharding</p>
<h2 id="Web-Server-vs-Application-Server"><a href="#Web-Server-vs-Application-Server" class="headerlink" title="Web Server vs Application Server"></a>Web Server vs Application Server</h2><p><a href="https://stackoverflow.com/questions/936197/what-is-the-difference-between-application-server-and-web-server" target="_blank" rel="noopener">https://stackoverflow.com/questions/936197/what-is-the-difference-between-application-server-and-web-server</a></p>
<h2 id="proxy-server"><a href="#proxy-server" class="headerlink" title="proxy server"></a>proxy server</h2><p><a href="https://www.educative.io/courses/grokking-the-system-design-interview/N8G9MvM4OR2" target="_blank" rel="noopener">https://www.educative.io/courses/grokking-the-system-design-interview/N8G9MvM4OR2</a><br>A proxy server is an intermediate server between the client and the back-end server.</p>
<p>Typically, proxies are used to filter requests, log requests, or sometimes transform requests (by adding/removing headers, encrypting/decrypting, or compressing a resource). Another advantage of a proxy server is that its cache can serve a lot of requests.</p>
<ol>
<li>open (forwarding) proxy: hide clients</li>
<li>reverse proxy: hide servers</li>
</ol>
<h2 id="Map-Reduce"><a href="#Map-Reduce" class="headerlink" title="Map Reduce"></a>Map Reduce</h2><p>We can have a Map-Reduce (MR) set-up These MR jobs will calculate frequencies of all searched terms in the past hour.</p>
<h2 id="Exponential-Moving-Average-EMA"><a href="#Exponential-Moving-Average-EMA" class="headerlink" title="Exponential Moving Average (EMA)"></a>Exponential Moving Average (EMA)</h2><p>In EMA, we give more weight to the latest data. It’s also known as the exponentially weighted moving average.</p>
<h1 id="Some-Design-Bottlenecks"><a href="#Some-Design-Bottlenecks" class="headerlink" title="Some Design Bottlenecks"></a>Some Design Bottlenecks</h1><ol>
<li><p>data compression 需要吗, 如何选择？</p>
</li>
<li><p>capacity estimation: metadata + content 两方面都要考虑，high level estimations 主要包括: storage for each day, storage for years, incoming bandwidth, outgoing bandwidth. 这些主要来自于: Total user, Daily active user (DAU), size of each request, how many entries each user produce, data growth, 有时对某个量单独估计比较好。</p>
</li>
<li><p>read heavy or wirte heavy? bandwidth, ingress: 每日新增数据总量/秒; egress: 用户浏览或下载总量/秒.</p>
</li>
<li>database需要有哪些符合场景的特点? 比如quick small updates, ACID, range based search, etc.</li>
<li>how about consider the peak time read and wirte throughput.</li>
<li><p>hot user in database handle, 怎么设计database去减轻这个问题.</p>
</li>
<li><p>we may need aggregator server for fetching and process data from different DB or caches.</p>
</li>
<li><p>monitoring system, collect metrics: daily peak, latency.  we will realize if we need more replication, load balancing, or caching.</p>
</li>
<li><p>load balancer can sit: between client and web server, web server and application server (or cahce), application server and database. load balancer can be single point of failure, need redundancy to take over when main is down.</p>
</li>
<li><p>load balancer: Round Robin approach, or more intelligent.</p>
</li>
<li><p>cache policy, LRU, 80-20 rule.</p>
</li>
</ol>
<h1 id="Other-System-Design-Videos"><a href="#Other-System-Design-Videos" class="headerlink" title="Other System Design Videos:"></a>Other System Design Videos:</h1><h2 id="Introduce-to-System-Design"><a href="#Introduce-to-System-Design" class="headerlink" title="Introduce to System Design"></a>Introduce to System Design</h2><p><a href="https://www.youtube.com/watch?v=UzLMhqg3_Wc&amp;list=PLrmLmBdmIlps7GJJWW9I7N0P0rB0C3eY2" target="_blank" rel="noopener">Introduce to System Design</a><br>同样推荐了这本书<code>&lt;&lt;Designing Data Intensive Applications&gt;&gt;</code>, 会对这些topics有更深入的讲解。</p>
<ol>
<li>ask good question:<br>which features care about, which not?<br>how much to scale (data, request, latency)</li>
<li>don’t use buzzword (be clear about the tech you use)</li>
<li>clear and organized thinking</li>
<li>drive discussion (80% I talk)</li>
</ol>
<p><strong>Things to consider</strong>:</p>
<ol>
<li>Features</li>
<li>API</li>
<li>Availability</li>
<li>Latency</li>
<li>Scalability</li>
<li>Durability</li>
<li>Class Diagram</li>
<li>Security and Privacy</li>
<li>Cost-effective</li>
</ol>
<p><strong>Concepts to know</strong>:</p>
<ol>
<li>Vertical vs horizontal scaling</li>
<li>CAP theorem</li>
<li>ACID vs BASE</li>
<li>Partitioning/Sharding </li>
<li>Consistent Hashing</li>
<li>Optimistic vs pessimistic locking</li>
<li>Strong vs eventual consistency</li>
<li>RelationalDB vs NoSQL</li>
<li>Types of NoSQL<br>  Key value<br>  Wide column<br>  Document-based<br>  Graph-based</li>
<li>Caching</li>
<li>Data center/racks/hosts</li>
<li>CPU/memory/Hard drives/Network bandwidth</li>
<li>Random vs sequential read/writes to disk</li>
<li>HTTP vs http2 vs WebSocket</li>
<li>TCP/IP model</li>
<li>ipv4 vs ipv6</li>
<li>TCP vs UDP</li>
<li>DNS lookup</li>
<li>Http &amp; TLS</li>
<li>Public key infrastructure and certificate authority(CA)</li>
<li>Symmetric vs asymmetric encryption</li>
<li>Load Balancer</li>
<li>CDNs &amp; Edges</li>
<li>Bloom filters and Count-Min sketch</li>
<li>Paxos </li>
<li>Leader election</li>
<li>Design patterns and Object-oriented design</li>
<li>Virtual machines and containers</li>
<li>Pub-sub architecture </li>
<li>MapReduce</li>
<li>Multithreading, locks, synchronization, CAS(compare and set)</li>
</ol>
<p><strong>Tools</strong>:</p>
<ol>
<li>Cassandra</li>
<li>MongoDB/Couchbase</li>
<li>Mysql</li>
<li>Memcached</li>
<li>Redis</li>
<li>Zookeeper</li>
<li>Kafka</li>
<li>NGINX</li>
<li>HAProxy</li>
<li>Solr, Elastic search</li>
<li>Amazon S3</li>
<li>Docker, Kubernetes, Mesos</li>
<li>Hadoop/Spark and HDFS</li>
</ol>
<h2 id="Design-Spotify-Apple-Muisc-Youtube-Music"><a href="#Design-Spotify-Apple-Muisc-Youtube-Music" class="headerlink" title="Design Spotify| Apple Muisc | Youtube Music"></a>Design Spotify| Apple Muisc | Youtube Music</h2><p><a href="https://www.youtube.com/watch?v=ks-CS41AiQs" target="_blank" rel="noopener">Design Spotify| Apple Muisc | Youtube Music</a></p>
<ol>
<li>scope: cover and what else you are not going to cover</li>
<li>key components (具体分析了一下spotify工作的过程，比如存储，传输protocol转换，low latency, CDN)</li>
<li>data model</li>
<li>scaling</li>
</ol>
<p>if data size is high, consider compress audio data<br>quality, user use different device and network condition<br>distribution CDN</p>
<p>scaling group 比如一些stateless servers可以使用k8s, containers去管理。</p>
]]></content>
      <categories>
        <category>System Design</category>
      </categories>
      <tags>
        <tag>system design</tag>
      </tags>
  </entry>
  <entry>
    <title>OOP Design</title>
    <url>/2020/03/29/design-OOD/</url>
    <content><![CDATA[<p>OOD 可以看成是 High Level System Design 后的具体实现。</p>
<p>This blog is for <code>Object Oriented Design</code>, please revisit frequently to refresh. The notes are mainly from <code>https://www.educative.io/</code>.</p>
<p><a href="https://www.youtube.com/watch?v=fJW65Wo7IHI&amp;list=PLGLfVvz_LVvS5P7khyR4xDp7T9lCk9PgE" target="_blank" rel="noopener">OOP Design video</a><br><code>OOP</code>: <code>Object-oriented programming</code><br><code>Design pattern</code>: singleton, factory, etc<br><code>Concurrency</code></p>
<p>The four principles of object-oriented programming are encapsulation, abstraction, inheritance, and polymorphism.</p>
<p>The process of OO analysis and design can be described as:</p>
<ol>
<li>Identifying the objects in a system;</li>
<li>Defining relationships between objects;</li>
<li>Establishing the interface of each object;</li>
<li>Making a design, which can be converted to executables using OO languages.</li>
</ol>
<p>要清楚如何定义enum, constants abstract class, interface. 如何选择他们.</p>
<p><code>UML</code> stands for <code>Unified Modeling Language</code> and is used to model the Object-Oriented Analysis of a software system. UML is a way of visualizing and documenting a software system by using a collection of diagrams.</p>
<p>Be familiar with:</p>
<ol>
<li>use case diagram (actors， 不是指所有的object: admin, customer, system…)</li>
<li>class diagram (relationships)</li>
<li>sequence diagram (emphasize on interaction between objects, time series)</li>
<li>activity diagram (emphasize on control of flow)</li>
</ol>
<p><strong>Summary</strong>:<br>总的来看，通过class diagram，设计好基本的abstract class, interface, base class，然后再延伸，实例化。实例化的class中设计好attributes, method的实现。</p>
<ul>
<li><p>定义好enum, constants.</p>
</li>
<li><p>把不同的系统分开设计，比如notifiation, payment…</p>
</li>
<li><p>对于actor people，有一个account class, 被包含在person abstract class中，然后这个person被实例化为其他诸如guest, admin, member等class. (有类似关系的以此类推)</p>
</li>
<li><p>对于有查询需求的任务, search interface中声明search方法，然后被search的对象类implements, 在这个对象内部实现search的各种method, 通常需要与database连接。</p>
</li>
<li><p>可能会用到设计模式</p>
</li>
</ul>
<h3 id="Design-a-Library-Management-System"><a href="#Design-a-Library-Management-System" class="headerlink" title="Design a Library Management System"></a>Design a Library Management System</h3><p>Library management systems help libraries keep track of the books and their checkouts, as well as members’ subscriptions and profiles.</p>
<ol>
<li>get clarity of the requirements, Be sure to ask questions to find the exact scope of the system that the interviewer has in mind</li>
</ol>
<p>找到actors之后，围绕actors就可以提出具体要求，可以做什么事情:<br>member can search book by title, name, date, category, author.<br>book has unique id, rack number, etc.<br>member can checkout, reserve book copies.<br>days a member can keep the book.<br>numbers a member can checkout.<br>collect fine if after due date.<br>system can send notification to user.<br>…</p>
<p>最后确认需具体要实现什么的功能？</p>
<ol start="2">
<li><p>use case diagram, define top use cases<br>从object角度, 看看各自可以有什么操作, 对具体的实现功能，画出具体的use case diagram。</p>
</li>
<li><p>class diagram<br>有几个问题:<br>要从high level考虑有哪些abstract class, enum, constant, interface等。<br>然后各自的依赖关系画一下。</p>
</li>
</ol>
<p>interface vs inheritace，什么时候谁合适?</p>
<p>在实现代码的时候，class diagram可以作为指导原则</p>
<ol start="4">
<li><p>activity diagram<br>画出具体实现<strong>某一</strong>功能的状态图</p>
</li>
<li><p>code<br>Since you are not required to write a fully executable code in an interview, you can assume parts of the code to interact with the database, payment system, etc..</p>
</li>
</ol>
<p>主要写出基本的部分:<br>Enums and Constants:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// enums</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> BookStatus</span><br><span class="line">&#123;</span><br><span class="line">  AVAILABLE,</span><br><span class="line">  RESERVED,</span><br><span class="line">  LOANED,</span><br><span class="line">  LOST</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> ReservationStatus</span><br><span class="line">&#123;</span><br><span class="line">  WAITING,</span><br><span class="line">  PENDING,</span><br><span class="line">  CANCELED,</span><br><span class="line">  NONE</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// constants</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Constants</span> </span>&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_BOOKS_ISSUED_TO_A_USER = <span class="number">5</span>;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAX_LENDING_DAYS = <span class="number">10</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后是abstrace class, interface 和其他继承，实现的类，根据class diagram去实现，举几个例子:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// For simplicity, we are not defining getter and setter functions. The reader can</span></span><br><span class="line"><span class="comment">// assume that all class attributes are private and accessed through their respective</span></span><br><span class="line"><span class="comment">// public getter methods and modified only through their public methods function.</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Book</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String ISBN;</span><br><span class="line">  <span class="keyword">private</span> String title;</span><br><span class="line">  <span class="keyword">private</span> String subject;</span><br><span class="line">  <span class="keyword">private</span> String publisher;</span><br><span class="line">  <span class="keyword">private</span> String language;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> numberOfPages;</span><br><span class="line">  <span class="keyword">private</span> List&lt;Author&gt; authors;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BookItem</span> <span class="keyword">extends</span> <span class="title">Book</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> String barcode;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">boolean</span> isReferenceOnly;</span><br><span class="line">  <span class="keyword">private</span> Date borrowed;</span><br><span class="line">  <span class="keyword">private</span> Date dueDate;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">double</span> price;</span><br><span class="line">  <span class="keyword">private</span> BookFormat format;</span><br><span class="line">  <span class="keyword">private</span> BookStatus status;</span><br><span class="line">  <span class="keyword">private</span> Date dateOfPurchase;</span><br><span class="line">  <span class="keyword">private</span> Date publicationDate;</span><br><span class="line">  <span class="keyword">private</span> Rack placedAt;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">checkout</span><span class="params">(String memberId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(bookItem.getIsReferenceOnly()) &#123;</span><br><span class="line">      ShowError(<span class="string">"This book is Reference only and can't be issued"</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(!BookLending.lendBook(<span class="keyword">this</span>.getBarCode(), memberId))&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">this</span>.updateBookItemStatus(BookStatus.LOANED);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Rack</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">int</span> number;</span><br><span class="line">  <span class="keyword">private</span> String locationIdentifier;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// interface</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Search</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchByTitle</span><span class="params">(String title)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchByAuthor</span><span class="params">(String author)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchBySubject</span><span class="params">(String subject)</span></span>;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchByPubDate</span><span class="params">(Date publishDate)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Catalog</span> <span class="keyword">implements</span> <span class="title">Search</span> </span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">  <span class="keyword">private</span> HashMap&lt;String, List&lt;Book&gt;&gt; bookTitles;</span><br><span class="line">  <span class="keyword">private</span> HashMap&lt;String, List&lt;Book&gt;&gt; bookAuthors;</span><br><span class="line">  <span class="keyword">private</span> HashMap&lt;String, List&lt;Book&gt;&gt; bookSubjects;</span><br><span class="line">  <span class="keyword">private</span> HashMap&lt;String, List&lt;Book&gt;&gt; bookPublicationDates;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchByTitle</span><span class="params">(String query)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// return all books containing the string query in their title.</span></span><br><span class="line">    <span class="keyword">return</span> bookTitles.get(query);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> List&lt;Book&gt; <span class="title">searchByAuthor</span><span class="params">(String query)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// return all books containing the string query in their author's name.</span></span><br><span class="line">    <span class="keyword">return</span> bookAuthors.get(query);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Design-parking-lot"><a href="#Design-parking-lot" class="headerlink" title="Design parking lot"></a>Design parking lot</h3><p><a href="https://www.youtube.com/watch?v=DSGsa0pu8-k&amp;t=814s" target="_blank" rel="noopener">https://www.youtube.com/watch?v=DSGsa0pu8-k&amp;t=814s</a><br>评论里有一些批评意见，可以参考。</p>
<ul>
<li><p>Identify the problem scope:<br>do you want me to come up a system design, or class hierarchy?<br>or should we get into certain specific question and wirte some methods?</p>
</li>
<li><p>How you approach the problem:<br>show a clear and systematic approach how you tackle this problem<br>how is the parking lot designed? building? open space? free or pay?<br>how many spots are we talking about? floors?<br>are there mutliple entrances or exits?<br>should we first fill out floor from top?<br>prices strategy? premium, general customer?</p>
</li>
</ul>
<p>进口的识别系统会识别plate number + vehicle type，然后再ticket上标明应该停放到哪个building，哪一层的哪个位置。(如果有多个entrance, 则有concurrency问题需要解决)</p>
<p>code some part of the design? which part do you want me to implement?<br>We have database backend but here for Simplicity can we assume we store the data in memory?</p>
<p>算法去实现spot -&gt; vehicle的分配。</p>
<ol>
<li><p>system requirements<br>multi-floors<br>multi-entries or exits<br>parking ticket<br>pay cash or credit card<br>pay at info panel or at exit<br>display message when full<br>different parking spots for different type car<br>electric car spots, charge station support<br>step price hourly</p>
</li>
<li><p>use case diagram<br>get clarity what functions we need to implement.</p>
</li>
<li><p>class diagram<br>ParkingLot<br>ParkingFloor<br>ParkingSpot<br>Account: admin and parking attendant<br>ParkingTicket<br>Vehicle: many types<br>Payment: credit card or cash<br>ParkingRate<br>ParkingDisplayBoard<br>ParkingAttendantPortal<br>CustomerInfoPortal<br>ElectricPanel</p>
</li>
<li><p>code<br>see: <a href="https://www.educative.io/courses/grokking-the-object-oriented-design-interview/gxM3gRxmr8Z" target="_blank" rel="noopener">https://www.educative.io/courses/grokking-the-object-oriented-design-interview/gxM3gRxmr8Z</a></p>
</li>
</ol>
<h3 id="Design-Amazon-online-shopping-system"><a href="#Design-Amazon-online-shopping-system" class="headerlink" title="Design Amazon online shopping system"></a>Design Amazon online shopping system</h3><ol>
<li>get clarity</li>
</ol>
<ul>
<li>what scope do you want me to focus on?</li>
<li>high level design or dive into a specific function component, wirte class and method.</li>
</ul>
<p><code>Objects</code>: guest, member, admin and system<br>分别讨论一下各自可以做什么操作。</p>
<p>几个主要的system:<br>register, search, review, order, shipment, payment, notification.</p>
<ol start="2">
<li>use case diagram</li>
<li>activity diagram</li>
<li>sequence diagram</li>
</ol>
<h4 id="Design-shopify"><a href="#Design-shopify" class="headerlink" title="Design shopify"></a>Design shopify</h4><p><a href="https://www.youtube.com/watch?v=lEL4F_0J3l8" target="_blank" rel="noopener">shopify eCommerce platform</a><br>类似于淘宝, 有自己的网店portal.</p>
<h3 id="Design-stack-overflow"><a href="#Design-stack-overflow" class="headerlink" title="Design stack overflow"></a>Design stack overflow</h3><p>Stack Overflow is one of the largest online communities for developers to learn and share their knowledge.</p>
<p>Users of Stack Overflow can earn reputation points and badges. For example, a person is awarded ten reputation points for receiving an “up” vote on an answer and five points for the “up” vote of a question. The can also receive badges for their valued contributions. A higher reputation lets users unlock new privileges like the ability to vote, comment on, and even edit other people’s posts.</p>
<p><code>Actors</code>: admin, guest, member, system, moderator(close,delete,undelete question)</p>
<h3 id="Design-a-Movie-Ticket-Booking-System"><a href="#Design-a-Movie-Ticket-Booking-System" class="headerlink" title="Design a Movie Ticket Booking System"></a>Design a Movie Ticket Booking System</h3><ol>
<li><p>high level overview<br>movie theater -&gt; halls -&gt; moive -&gt; shows<br>search movie<br>select show and boot ticket<br>select seat<br>notification<br>payment<br><strong>concurrency</strong> issue when booking:<br>在数据库层面实现的，没有使用Java的concurrency package<br>We can use transactions in SQL databases to avoid any clashes.<br>lock the rows before we update them<br>discount/coupon apply</p>
</li>
<li><p>use case diagram</p>
</li>
<li>class diagram</li>
<li>activity diagram</li>
</ol>
<h3 id="Design-ATM"><a href="#Design-ATM" class="headerlink" title="Design ATM"></a>Design ATM</h3><p>Automated teller machine (ATM)<br>withdraw and deposit money</p>
<p>components of ATM:<br>card reader<br>kaypad<br>screen<br>Cash dispenser<br>Deposit slot<br>printer<br>network</p>
<p>checking and saving account of user<br>都放在<strong>transaction中，保证原子性</strong>:<br>Balance inquiry<br>Deposit cash<br>Deposit check<br>Withdraw cash<br>Transfer funds</p>
<p>The ATM will maintain an internal log of transactions that contains information about hardware failures; this log will be used by the ATM operator to resolve any issues.</p>
<p><code>actors:</code><br>operator<br>customer<br>bank manager<br>system</p>
<h3 id="Design-an-Airline-Management-System"><a href="#Design-an-Airline-Management-System" class="headerlink" title="Design an Airline Management System"></a>Design an Airline Management System</h3><p>This system involves the scheduling of flights, air ticket reservations, flight cancellations, customer support, and staff management. Daily flights updates can also be retrieved by using the system.</p>
<p>roundtrip<br>one way<br>mutli-city</p>
<p>回忆一下预定的界面<br>departing<br>returning</p>
<h3 id="Design-a-Hotel-Management-System"><a href="#Design-a-Hotel-Management-System" class="headerlink" title="Design a Hotel Management System"></a>Design a Hotel Management System</h3><p>和ticket booking类似<br>a online portal, keep track of available rooms, book rooms and generate bill.<br>booking of different room types like standard, deluxe, family suite, etc<br>housekeeping log to keep track of all housekeeping tasks</p>
<ol>
<li><p>use case diagram<br>guest<br>manager<br>system<br>housekeeper<br>Receptionist</p>
</li>
<li><p>class diagram</p>
</li>
<li>activity diagram</li>
</ol>
<h3 id="Restaurant-Management-system"><a href="#Restaurant-Management-system" class="headerlink" title="Restaurant Management system"></a>Restaurant Management system</h3><p>同上，补充几个特点:<br>The system allows the manager to keep track of available tables in the system as well as the reservation of tables and bill generation.<br>这里是西餐的形式，没人一个座位，单独点餐。</p>
<p>menu -&gt; menu sections -&gt; items<br>rooms -&gt; tables (reservation or walk-in)</p>
<h3 id="Design-Facebook"><a href="#Design-Facebook" class="headerlink" title="Design Facebook"></a>Design Facebook</h3><p>Facebook is an online social networking service where users can connect with other users to post and read messages. Users access Facebook through their website interface or mobile apps.</p>
<h3 id="Design-LinkedIn"><a href="#Design-LinkedIn" class="headerlink" title="Design LinkedIn"></a>Design LinkedIn</h3><p>Similar to Facebook design but carter to professionals. 各种功能几乎就一样。</p>
<p>A LinkedIn member’s profile page, which emphasizes their skills, employment history, and education, has professional network news feeds with customizable modules.</p>
<ol>
<li><p>use case diagram<br>member<br>admin<br>system</p>
</li>
<li><p>class diagram</p>
</li>
<li>activity diagram</li>
</ol>
]]></content>
      <categories>
        <category>OOP Design</category>
      </categories>
      <tags>
        <tag>OOP design</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker Registry API</title>
    <url>/2019/06/10/docker-registry-api/</url>
    <content><![CDATA[<p>How to list images and tags in the docker registory? How to delete image(layers) in docker registory? These are general demands in my daily work, let’s figure them out.</p>
<p>A brife digression: The <code>OpenShift</code> platform has web UI to deal with images in integrated docker registry (it is called <code>imagestream</code> in OpenShift), usually after you login to terminal, run <code>oc version</code> will show you the web address. You can list and delete imagestream there.</p>
<p>For example, I use <code>OpenShift</code> integrated docker registry and push my docker images to a project called <code>datastage</code> (I configuring the setting so other project can pull images from this project):<br><img src="https://drive.google.com/uc?id=1T55Gro5-_WZDTkP3lNuIrDUk6C7f8qWl" alt=""></p>
<h2 id="Resurces"><a href="#Resurces" class="headerlink" title="Resurces"></a>Resurces</h2><p><a href="https://docs.docker.com/registry/spec/api/" target="_blank" rel="noopener">Docker Registry HTTP API V2</a><br><a href="https://blog.csdn.net/qq_35904833/article/details/80807592" target="_blank" rel="noopener">Registry 清理镜像</a><br><a href="https://github.com/docker/distribution/blob/master/docs/spec/auth/token.md" target="_blank" rel="noopener">v2 Docker registry authentication</a><br><a href="https://github.com/byrnedo/docker-reg-tool" target="_blank" rel="noopener">Registry tool Git project</a><br><a href="https://medium.com/@mcvidanagama/cleanup-your-docker-registry-ef0527673e3a" target="_blank" rel="noopener">Cleanup Your Docker Registry</a></p>
<h2 id="Quick-Set-up"><a href="#Quick-Set-up" class="headerlink" title="Quick Set up"></a>Quick Set up</h2><p>After installing docker, get and run docker registry from <a href="https://hub.docker.com/_/registry" target="_blank" rel="noopener">Docker Offical Images - registry</a>.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull registry</span><br></pre></td></tr></table></figure>
<p>you will get:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker images</span><br><span class="line"></span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">registry            latest              f32a97de94e1        3 months ago        25.8MB</span><br></pre></td></tr></table></figure></p>
<p>then run it locally with image deletion enabled:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d -p 5000:5000 -e REGISTRY_STORAGE_DELETE_ENABLED=true --restart always --name registry registry</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>To remove images, you need to setup docker registry with <strong>delete enabled</strong>(by default it’s off), see my blog <a href="https://chengdol.github.io/2019/06/16/docker-registry-config/" target="_blank" rel="noopener">Docker Registry Configure</a></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker ps</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES</span><br><span class="line">3021266dca1f        registry            &quot;/entrypoint.sh /etc...&quot;   2 seconds ago       Up 1 second         0.0.0.0:5000-&gt;5000/tcp   registry</span><br></pre></td></tr></table></figure>
<p>Next, let’s use busybox to illustrate:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull busybox</span><br><span class="line">docker tag busybox localhost:5000/busybox:v1</span><br><span class="line">docker push localhost:5000/busybox:v1</span><br></pre></td></tr></table></figure></p>
<h2 id="Insecure-Docker-Registry"><a href="#Insecure-Docker-Registry" class="headerlink" title="Insecure Docker Registry"></a>Insecure Docker Registry</h2><p>Quick set up will give you a insecure private docker registry (means no <code>docker login</code> and use <code>http</code> to access API).</p>
<blockquote>
<p>Note that you can use <code>-v</code> option in <code>curl</code> command to get verbose message such as HEADER information.</p>
</blockquote>
<h3 id="Check-Availability"><a href="#Check-Availability" class="headerlink" title="Check Availability"></a>Check Availability</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k --head -X GET http://localhost:5000/v2/</span><br><span class="line"></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Length: 2</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Docker-Distribution-Api-Version: registry/2.0</span><br><span class="line">X-Content-Type-Options: nosniff</span><br><span class="line">Date: Sun, 23 Jun 2019 05:20:01 GMT</span><br></pre></td></tr></table></figure>
<p>This means registry is accessable and user has permission.</p>
<h3 id="List-Images"><a href="#List-Images" class="headerlink" title="List Images"></a>List Images</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k -X GET http://localhost:5000/v2/_catalog</span><br><span class="line"></span><br><span class="line">&#123;&quot;repositories&quot;:[&quot;busybox&quot;]&#125;</span><br></pre></td></tr></table></figure>
<h3 id="List-Image-Tags"><a href="#List-Image-Tags" class="headerlink" title="List Image Tags"></a>List Image Tags</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k -X GET http://localhost:5000/v2/busybox/tags/list</span><br><span class="line"></span><br><span class="line">&#123;&quot;name&quot;:&quot;busybox&quot;,&quot;tags&quot;:[&quot;v1&quot;]&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Delete-Images"><a href="#Delete-Images" class="headerlink" title="Delete Images"></a>Delete Images</h3><p>Deletion of unused digests of docker images to avoid unnecessary space growth in a private docker registry</p>
<p>Deletion is more complicated than list, from <a href="https://docs.docker.com/registry/spec/api/#deleting-an-image" target="_blank" rel="noopener">Deleting an Image API</a>, there are 2 main steps:</p>
<h4 id="Delete-through-API"><a href="#Delete-through-API" class="headerlink" title="Delete through API"></a>Delete through API</h4><ol>
<li>Get the <code>digest</code> of the image with tag <code>v1</code><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k --head -H &quot;Accept: application/vnd.docker.distribution.manifest.v2+json&quot; -X GET http://localhost:5000/v2/busybox/manifests/v1</span><br><span class="line"></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Content-Length: 527</span><br><span class="line">Content-Type: application/vnd.docker.distribution.manifest.v2+json</span><br><span class="line">Docker-Content-Digest: sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff</span><br><span class="line">Docker-Distribution-Api-Version: registry/2.0</span><br><span class="line">Etag: &quot;sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff&quot;</span><br><span class="line">X-Content-Type-Options: nosniff</span><br><span class="line">Date: Sun, 16 Jun 2019 20:12:07 GMT</span><br></pre></td></tr></table></figure>
</li>
</ol>
<blockquote>
<p>Note when deleting a manifest from a registry version 2.3 or later, the following header must be used when HEAD or GET-ing the manifest to obtain the correct digest to delete: <code>Accept: application/vnd.docker.distribution.manifest.v2+json</code>.</p>
<p>You can refer this <a href="https://docs.docker.com/registry/spec/manifest-v2-2/" target="_blank" rel="noopener">Image Manifest V 2, Schema 2</a> to get more header details.</p>
</blockquote>
<p>Here, we use the digest from <code>Docker-Content-Digest</code> field in the header, the vaule is <code>sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff</code>.</p>
<p>Actually, if the docker image is loaded, you can inspect it by:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect localhost:5000/busybox:v1 | less</span><br></pre></td></tr></table></figure></p>
<p>There is a <code>RepoDigests</code> field that also contains the same digest:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">        &quot;RepoDigests&quot;: [</span><br><span class="line">            &quot;busybox@sha256:7a4d4ed96e15d6a3fe8bfedb88e95b153b93e230a96906910d57fc4a13210160&quot;,</span><br><span class="line">            &quot;localhost:5000/busybox@sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff&quot;</span><br><span class="line">        ],</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<ol start="2">
<li>Issue delete command<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k -v -X DELETE http://localhost:5000/v2/busybox/manifests/sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff</span><br><span class="line"></span><br><span class="line">* About to connect() to localhost port 5000 (#0)</span><br><span class="line">*   Trying 127.0.0.1...</span><br><span class="line">* Connected to localhost (127.0.0.1) port 5000 (#0)</span><br><span class="line">&gt; DELETE /v2/busybox/manifests/sha256:bf510723d2cd2d4e3f5ce7e93bf1e52c8fd76831995ac3bd3f90ecc866643aff HTTP/1.1</span><br><span class="line">&gt; User-Agent: curl/7.29.0</span><br><span class="line">&gt; Host: localhost:5000</span><br><span class="line">&gt; Accept: */*</span><br><span class="line">&gt;</span><br><span class="line">&lt; HTTP/1.1 202 Accepted</span><br><span class="line">&lt; Docker-Distribution-Api-Version: registry/2.0</span><br><span class="line">&lt; X-Content-Type-Options: nosniff</span><br><span class="line">&lt; Date: Sun, 16 Jun 2019 20:27:05 GMT</span><br><span class="line">&lt; Content-Length: 0</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>The response <code>HTTP/1.1 202 Accepted</code> means the deletion succeeds, let’s check the tag again:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k -X GET http://localhost:5000/v2/busybox/tags/list</span><br><span class="line"></span><br><span class="line">&#123;&quot;name&quot;:&quot;busybox&quot;,&quot;tags&quot;:null&#125;</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that if the docker registry deletion is not enabled, you will get response<br><code>{&quot;errors&quot;:[{&quot;code&quot;:&quot;UNSUPPORTED&quot;,&quot;message&quot;:&quot;The operation is unsupported.&quot;}]}</code>.</p>
</blockquote>
<h4 id="Delete-in-File-System"><a href="#Delete-in-File-System" class="headerlink" title="Delete in File System"></a>Delete in File System</h4><blockquote>
<p>Note this way doesn’t required docker registry is deletion enabled!</p>
</blockquote>
<p>Actually, docker registry stores image in <code>/var/lib/registry/docker/registry/v2/</code>, there are <code>blobs</code> and <code>repositories</code> directories. <code>blobs</code> directory is where images reside and <code>repositories</code> is where metadata and reference locate.</p>
<p>You need to delete two dirs if you mount docker registry storage in host:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rm -rf &lt;mount path&gt;/registry/v2/repositories/busybox/_manifests/tags/v1/index/sha256/&lt;hash dir&gt;</span><br><span class="line"></span><br><span class="line">rm -rf &lt;mount path&gt;/registry/v2/repositories/busybox/_manifests/revisions/sha256/&lt;hash dir&gt;</span><br></pre></td></tr></table></figure></p>
<p>At the time of deleting those dirs; the docker registry should be in read only mode. Nobody should push to registry.</p>
<h4 id="Garbage-Collection"><a href="#Garbage-Collection" class="headerlink" title="Garbage Collection"></a>Garbage Collection</h4><p>However, the API and file system deletions above only remove the <strong>metadata</strong> or dereference the connection between manifest with layers data in disk, we need to run <strong>garbage collection</strong> in docker registry to remove layers:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker exec -it registry sh</span><br></pre></td></tr></table></figure></p>
<p>check space used before clean:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">du -sch /var/lib/registry/docker/</span><br><span class="line"></span><br><span class="line">764.0K  /var/lib/registry/docker/</span><br><span class="line">764.0K  total</span><br></pre></td></tr></table></figure></p>
<p>then run garbage collection:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bin/registry garbage-collect /etc/docker/registry/config.yml</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>/etc/docker/registry/config.yml</code> is the configuration file for docker registry.</p>
</blockquote>
<p>then if you check space used again<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">du -sch /var/lib/registry/docker/</span><br><span class="line"></span><br><span class="line">8.0K    /var/lib/registry/docker/</span><br><span class="line">8.0K    total</span><br></pre></td></tr></table></figure></p>
<h3 id="Other-Notice"><a href="#Other-Notice" class="headerlink" title="Other Notice"></a>Other Notice</h3><p>If you have one image with multiple tags and the digests are the same, delete one of them will remove them all.</p>
<p>If you have one image with multiple tags and the digests are different for each tag, deletion is tag-separate.</p>
<h2 id="Secure-Docker-Registry"><a href="#Secure-Docker-Registry" class="headerlink" title="Secure Docker Registry"></a>Secure Docker Registry</h2><p>In ICP4D cluster, we use secure docker registry with <code>https</code> and login credentials. But first let’s understand how to set up secure docker registry, see my blog <a href="https://chengdol.github.io/2019/06/16/docker-secure-registry/" target="_blank" rel="noopener"><code>&lt;&lt;Secure Docker Registry&gt;&gt;</code></a>.</p>
<p>login, see .docker/config<br>curl works?</p>
<h3 id="Check-Availability-1"><a href="#Check-Availability-1" class="headerlink" title="Check Availability"></a>Check Availability</h3><p>If you don’t have authentication, you will get <code>401</code> Unauthorized status, for example, here <code>https://mycluster.icp:8500</code> is the private secure docker registry location:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl --head -k -X GET https://mycluster.icp:8500/v2/</span><br><span class="line"></span><br><span class="line">HTTP/1.1 401 Unauthorized</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Docker-Distribution-Api-Version: registry/2.0</span><br><span class="line">Www-Authenticate: Bearer realm=&quot;https://mycluster.icp:8600/image-manager/api/v1/auth/token&quot;,service=&quot;token-service&quot;</span><br><span class="line">Date: Mon, 24 Jun 2019 16:14:10 GMT</span><br><span class="line">Content-Length: 87</span><br></pre></td></tr></table></figure></p>
<p>Here <code>Www-Authenticate</code> tells you Auth Server address.</p>
<p>In my <code>OpenShift</code> cluster:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -k --head -X GET https://172.30.159.11:5000/v2/</span><br><span class="line"></span><br><span class="line">HTTP/1.1 401 Unauthorized</span><br><span class="line">Content-Type: application/json; charset=utf-8</span><br><span class="line">Docker-Distribution-Api-Version: registry/2.0</span><br><span class="line">Www-Authenticate: Bearer realm=&quot;https://172.30.159.11:5000/openshift/token&quot;</span><br><span class="line">X-Registry-Supports-Signatures: 1</span><br><span class="line">Date: Mon, 24 Jun 2019 16:37:40 GMT</span><br><span class="line">Content-Length: 87</span><br><span class="line"></span><br><span class="line">&#123;&quot;errors&quot;:[&#123;&quot;code&quot;:&quot;UNAUTHORIZED&quot;,&quot;message&quot;:&quot;authentication required&quot;,&quot;detail&quot;:null&#125;]&#125;</span><br></pre></td></tr></table></figure></p>
<p>Need to apply token from Auth Server.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">======================================================================================</span><br><span class="line">I think I get stuck here...</span><br><span class="line">the situation is:</span><br><span class="line">1. I have docker login ability</span><br><span class="line">2. where can I get the token to do API access? auth server, where, how?</span><br><span class="line">3. the platform use what to secure docker registry?</span><br><span class="line"></span><br><span class="line">icp4d cluster is more transparent the Openshfit</span><br><span class="line">======================================================================================</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -u openshift:NOyEoOrA0FDm2IgYqlHCDkDepQ7I0vw-7Sx8RzPUmzw -X GET &quot;https://172.30.159.11:5000/openshift/token?service=172.30.159.11:5000&amp;scope=repository:demo1-ds/busybox:pull,push&quot;</span><br></pre></td></tr></table></figure>
<p><a href="https://docs.docker.com/registry/spec/auth/token/" target="_blank" rel="noopener">https://docs.docker.com/registry/spec/auth/token/</a></p>
<h3 id="List-Images-1"><a href="#List-Images-1" class="headerlink" title="List Images"></a>List Images</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="List-Tags"><a href="#List-Tags" class="headerlink" title="List Tags"></a>List Tags</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="Remove-Images"><a href="#Remove-Images" class="headerlink" title="Remove Images"></a>Remove Images</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>docker registry</tag>
      </tags>
  </entry>
  <entry>
    <title>Completely Delete K8s Cluster</title>
    <url>/2019/03/02/k8s-delete-cluster/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>Today I spend some time to investigate how to remove nodes from the k8s cluster that built by <code>kubeadm</code>.</p>
<p>For example, I have a 3 nodes cluster called <code>k8stest</code>, I deploy the application in <code>namespace</code> <code>test-1</code>, each worker node (<code>k8stest2</code> and <code>k8stest3</code>) holds some pods:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods -n <span class="built_in">test</span>-1 -o wide</span><br><span class="line"></span><br><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE     IP            NODE                    NOMINATED NODE   READINESS GATES</span><br><span class="line">is-en-conductor-0                        1/1     Running   0          5h40m   192.168.1.2   k8stest3.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-engine-compute-0                      1/1     Running   0          5h39m   192.168.1.3   k8stest3.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-engine-compute-1                      1/1     Running   0          5h38m   192.168.2.4   k8stest2.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-servicesdocker-pod-7b4d9d5c48-vvfn6   1/1     Running   0          5h41m   192.168.2.3   k8stest2.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-xmetadocker-pod-5ff59fff46-tkmqn      1/1     Running   0          5h42m   192.168.2.2   k8stest2.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="Drain-and-delete-worker-nodes"><a href="#Drain-and-delete-worker-nodes" class="headerlink" title="Drain and delete worker nodes"></a>Drain and delete worker nodes</h3><p>You can use <code>kubectl drain</code> to safely evict all of your pods from a node before you perform maintenance on the node (e.g. kernel upgrade, hardware maintenance, etc.). Safe evictions allow the pod’s containers to <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods" target="_blank" rel="noopener">gracefully terminate</a> and will respect the <code>PodDisruptionBudgets</code> you have specified.</p>
<p>The <code>drain</code> evicts or deletes all pods except mirror pods (which cannot be deleted through the API server). If there are DaemonSet-managed pods, drain will not proceed without <code>--ignore-daemonsets</code>, and regardless it will not delete any DaemonSet-managed pods, because those pods would be immediately replaced by the DaemonSet controller, which ignores unschedulable markings. If there are any pods that are neither mirror pods nor managed by <code>ReplicationController</code>, <code>ReplicaSet</code>, <code>DaemonSet</code>, <code>StatefulSet</code> or <code>Job</code>, then drain will not delete any pods unless you use <code>--force</code>. <code>--force</code> will also allow deletion to proceed if the managing resource of one or more pods is missing.</p>
<p>Let’s first drain <code>k8stest2</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl drain k8stest2.fyre.ibm.com --delete-local-data --force --ignore-daemonsets</span><br><span class="line"></span><br><span class="line">node/k8stest2.fyre.ibm.com cordoned</span><br><span class="line">WARNING: Ignoring DaemonSet-managed pods: calico-node-txjpn, kube-proxy-52njn</span><br><span class="line">pod/is-engine-compute-1 evicted</span><br><span class="line">pod/is-xmetadocker-pod-5ff59fff46-tkmqn evicted</span><br><span class="line">pod/is-servicesdocker-pod-7b4d9d5c48-vvfn6 evicted</span><br><span class="line">node/k8stest2.fyre.ibm.com evicted</span><br></pre></td></tr></table></figure></p>
<p>When <code>kubectl drain</code> returns successfully, that indicates that all of the pods (except the ones excluded as described in the previous paragraph) have been safely evicted (respecting the desired graceful termination period, and without violating any application-level disruption SLOs). It is then safe to bring down the node by powering down its physical machine or, if running on a cloud platform, deleting its virtual machine.</p>
<p>Let’s ssh to <code>k8stest2</code> node and see what happens here, the payloads were gone:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh k8stest2.fyre.ibm.com</span><br><span class="line">docker ps</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE                  COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">0fbbb64d93d0        fa6f35a1c14d           <span class="string">"/install-cni.sh"</span>        6 hours ago         Up 6 hours                              k8s_install-cni_calico-node-txjpn_kube-system_4b916269-3d49-11e9-b6b3-00163e01eecc_0</span><br><span class="line">b78013d4f454        427a0694c75c           <span class="string">"start_runit"</span>            6 hours ago         Up 6 hours                              k8s_calico-node_calico-node-txjpn_kube-system_4b916269-3d49-11e9-b6b3-00163e01eecc_0</span><br><span class="line">c6aaf7cbf713        01cfa56edcfc           <span class="string">"/usr/local/bin/kube..."</span>   6 hours ago         Up 6 hours                              k8s_kube-proxy_kube-proxy-52njn_kube-system_4b944a11-3d49-11e9-b6b3-00163e01eecc_0</span><br><span class="line">542bc4662ee4        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 6 hours ago         Up 6 hours                              k8s_POD_calico-node-txjpn_kube-system_4b916269-3d49-11e9-b6b3-00163e01eecc_0</span><br><span class="line">86ee508f0aa1        k8s.gcr.io/pause:3.1   <span class="string">"/pause"</span>                 6 hours ago         Up 6 hours                              k8s_POD_kube-proxy-52njn_kube-system_4b944a11-3d49-11e9-b6b3-00163e01eecc_0</span><br></pre></td></tr></table></figure></p>
<p>The given node will be marked <code>unschedulable</code> to prevent new pods from arriving.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">NAME                    STATUS                     ROLES    AGE     VERSION</span><br><span class="line">k8stest1.fyre.ibm.com   Ready                      master   6h11m   v1.13.2</span><br><span class="line">k8stest2.fyre.ibm.com   Ready,SchedulingDisabled   &lt;none&gt;   5h57m   v1.13.2</span><br><span class="line">k8stest3.fyre.ibm.com   Ready                      &lt;none&gt;   5h57m   v1.13.2</span><br></pre></td></tr></table></figure></p>
<p>Because the dedicated node <code>k8stest2</code> was drained, so <code>is-servicesdocker</code> and <code>is-xmetadocker</code> keep pending:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">NAME                                     READY   STATUS    RESTARTS   AGE     IP            NODE                    NOMINATED NODE   READINESS GATES</span><br><span class="line">is-en-conductor-0                        1/1     Running   0          6h3m    192.168.1.2   k8stest3.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-engine-compute-0                      1/1     Running   0          6h2m    192.168.1.3   k8stest3.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-engine-compute-1                      1/1     Running   0          9m26s   192.168.1.4   k8stest3.fyre.ibm.com   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-servicesdocker-pod-7b4d9d5c48-vz7x4   0/1     Pending   0          9m39s   &lt;none&gt;        &lt;none&gt;                  &lt;none&gt;           &lt;none&gt;</span><br><span class="line">is-xmetadocker-pod-5ff59fff46-m4xj2      0/1     Pending   0          9m39s   &lt;none&gt;        &lt;none&gt;                  &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure></p>
<p>Now it’s safe to delete node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl delete node k8stest2.fyre.ibm.com</span><br><span class="line"></span><br><span class="line">node <span class="string">"k8stest2.fyre.ibm.com"</span> deleted</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">NAME                    STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8stest1.fyre.ibm.com   Ready    master   6h22m   v1.13.2</span><br><span class="line">k8stest3.fyre.ibm.com   Ready    &lt;none&gt;   6h8m    v1.13.2</span><br></pre></td></tr></table></figure>
<p>Repeat the steps above for worker node <code>k8stest3</code> then only master node survives:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">NAME                    STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8stest1.fyre.ibm.com   Ready    master   6h25m   v1.13.2</span><br></pre></td></tr></table></figure></p>
<h3 id="Drain-master-node"><a href="#Drain-master-node" class="headerlink" title="Drain master node"></a>Drain master node</h3><p>It’s time to deal with master node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl drain k8stest1.fyre.ibm.com --delete-local-data --force --ignore-daemonsets</span><br><span class="line"></span><br><span class="line">node/k8stest1.fyre.ibm.com cordoned</span><br><span class="line">WARNING: Ignoring DaemonSet-managed pods: calico-node-vlqh5, kube-proxy-5tfgr</span><br><span class="line">pod/docker-registry-85577757d5-952wq evicted</span><br><span class="line">pod/coredns-86c58d9df4-kwjr8 evicted</span><br><span class="line">pod/coredns-86c58d9df4-4p7g2 evicted</span><br><span class="line">node/k8stest1.fyre.ibm.com evicted</span><br></pre></td></tr></table></figure></p>
<p>Let’s see what happens for infrastructure pods, some of them were gone:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get pods -n kube-system</span><br><span class="line"></span><br><span class="line">NAME                                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">calico-node-vlqh5                               2/2     Running   0          6h31m</span><br><span class="line">coredns-86c58d9df4-5ctw2                        0/1     Pending   0          2m15s</span><br><span class="line">coredns-86c58d9df4-mg8rf                        0/1     Pending   0          2m15s</span><br><span class="line">etcd-k8stest1.fyre.ibm.com                      1/1     Running   0          6h31m</span><br><span class="line">kube-apiserver-k8stest1.fyre.ibm.com            1/1     Running   0          6h31m</span><br><span class="line">kube-controller-manager-k8stest1.fyre.ibm.com   1/1     Running   0          6h30m</span><br><span class="line">kube-proxy-5tfgr                                1/1     Running   0          6h31m</span><br><span class="line">kube-scheduler-k8stest1.fyre.ibm.com            1/1     Running   0          6h31m</span><br></pre></td></tr></table></figure></p>
<p>Note that don’t do delete for master node.</p>
<h3 id="Reset-cluster"><a href="#Reset-cluster" class="headerlink" title="Reset cluster"></a>Reset cluster</h3><p>Run this in every node to revert any changes made  by <code>kubeadm init</code> or <code>kubeadm join</code>:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubeadm reset -f</span><br></pre></td></tr></table></figure></p>
<p>All container were gone and also check if <code>kubectl</code> still works?<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker ps</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">The connection to the server 9.30.219.224:6443 was refused - did you specify the right host or port?</span><br></pre></td></tr></table></figure>
<h3 id="Delete-rpm-and-files"><a href="#Delete-rpm-and-files" class="headerlink" title="Delete rpm and files"></a>Delete rpm and files</h3><p>Finally, we need to delete rpms and remove residue in every node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum erase -y kubeadm.x86_64 kubectl.x86_64 kubelet.x86_64 kubernetes-cni.x86_64 cri-tools socat</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## calico</span></span><br><span class="line">/bin/rm -rf /opt/cni/bin/*</span><br><span class="line">/bin/rm -rf /var/lib/calico</span><br><span class="line">/bin/rm -rf /run/calico</span><br><span class="line"><span class="comment">## config</span></span><br><span class="line">/bin/rm -rf /root/.kube</span><br><span class="line"><span class="comment">## etcd</span></span><br><span class="line">/bin/rm -rf /var/lib/etcd/*</span><br><span class="line"><span class="comment">## kubernetes</span></span><br><span class="line">/bin/rm -rf /etc/kubernetes/</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>kubeadm</tag>
        <tag>drain</tag>
      </tags>
  </entry>
  <entry>
    <title>Helm Quick Start</title>
    <url>/2020/04/30/k8s-helm-quick-start/</url>
    <content><![CDATA[<p><a href="https://helm.sh/docs/" target="_blank" rel="noopener">Official Document</a><br>To install helm in the control node, download the corresponding binary and untar to execution path.</p>
<p>Package manager analogy:</p>
<ul>
<li>apt (deb)</li>
<li>yum (rpm)</li>
<li>maven (Jar)</li>
<li>npm (node modules)</li>
<li>pip (python packages)</li>
<li>helm (charts)</li>
</ul>
<p><strong>Helm v3.2.0</strong></p>
<blockquote>
<p>Helm3 does not have Tiller server, see <a href="https://developer.ibm.com/technologies/containers/blogs/kubernetes-helm-3/" target="_blank" rel="noopener">what’s new in Helm 3</a></p>
</blockquote>
<h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><p>Now, let’s understand the basic concepts of Helm:<br><a href="https://helm.sh/docs/intro/using_helm/" target="_blank" rel="noopener">https://helm.sh/docs/intro/using_helm/</a></p>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>helm3 does not have default repo, usually we use <code>https://kubernetes-charts.storage.googleapis.com/</code> as our stable repo. helm2 can skip this it has default stable repo.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## add stable repo to local repo</span></span><br><span class="line"><span class="comment">## 'stable' is your custom repo name</span></span><br><span class="line">helm repo add stable https://kubernetes-charts.storage.googleapis.com/</span><br><span class="line"><span class="comment">## display local repo list</span></span><br><span class="line">helm repo list</span><br><span class="line"><span class="comment">## remove repo 'stable'</span></span><br><span class="line">helm repo remove stable</span><br><span class="line"></span><br><span class="line"><span class="comment">## install charts</span></span><br><span class="line"><span class="comment">## Make sure we get the latest list of charts</span></span><br><span class="line">helm repo update </span><br><span class="line">helm install stable/mysql --generate-name</span><br><span class="line">helm install &lt;release name&gt; stable/mysql -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## show status of your release</span></span><br><span class="line">helm status &lt;release name&gt;</span><br></pre></td></tr></table></figure></p>
<p>Whenever you install a chart, a new release is created. So one chart can be installed multiple times into the same cluster. Each can be independently managed and upgraded.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show deployed release</span></span><br><span class="line">helm ls -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## uninstall</span></span><br><span class="line"><span class="comment">## with --keep-history, you can check the status of release</span></span><br><span class="line"><span class="comment">## or even undelete it</span></span><br><span class="line">helm uninstall &lt;release name&gt; [--keep-history] -n &lt;namespace&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="Chart-template-guide"><a href="#Chart-template-guide" class="headerlink" title="Chart template guide"></a>Chart template guide</h2><p><a href="https://helm.sh/docs/chart_template_guide/getting_started/" target="_blank" rel="noopener">https://helm.sh/docs/chart_template_guide/getting_started/</a><br>Helm Chart templates are written in the <code>Go template language</code>, with the addition of 50 or so add-on template functions from the <code>Sprig library</code> and a few other specialized functions.</p>
<h3 id="Template-and-values"><a href="#Template-and-values" class="headerlink" title="Template and values"></a>Template and values</h3><p><a href="https://helm.sh/docs/topics/charts/#templates-and-values" target="_blank" rel="noopener">https://helm.sh/docs/topics/charts/#templates-and-values</a></p>
<p>Where are the configuration values from, precdence low to high from top to bottom:</p>
<ol>
<li>values.yaml</li>
<li>other-file.yaml: <code>helm install -f &lt;other-file.yaml&gt; ...</code></li>
<li>command: <code>helm install --set key=val ...</code></li>
</ol>
<p>Helm template built-in objects:</p>
<ol>
<li>Chart.yaml: <code>.Chart.Name</code> (use upper case)</li>
<li>Release data: <code>.Release.Name</code></li>
<li>K8s data: <code>.Capabilities.KubeVersion</code></li>
<li>File data: <code>.Files.Get. conf.ini</code></li>
<li>Template data: <code>.Template.Name</code></li>
</ol>
<p>In <code>values.yaml</code>:</p>
<ol>
<li>use <code>_</code> instead of <code>-</code></li>
<li>decimal number wrapped by <code>&quot;&quot;</code>, <code>&quot;2.0&quot;</code>, integer number no need</li>
</ol>
<p>使用placeholder 是最基本的操作，let’s see functions and logic.</p>
<ol>
<li><p>use functions and pipelines, they are interchangeable<br><a href="https://helm.sh/docs/chart_template_guide/functions_and_pipelines/" target="_blank" rel="noopener">https://helm.sh/docs/chart_template_guide/functions_and_pipelines/</a><br>commonly used functions and correspinding pipelines</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">      <span class="keyword">function</span> usage         --       pipeline usage</span><br><span class="line">================================================================</span><br><span class="line">default default_value value  -- value | default default_value</span><br><span class="line">quote value                  -- value | quote</span><br><span class="line">upper value                  -- value | upper</span><br><span class="line">trunc value 20               -- value | trunc 20</span><br><span class="line">trimSuffix <span class="string">"-"</span> value         -- value | trimSuffix <span class="string">"-"</span></span><br><span class="line">b64enc value                 -- value | b64enc</span><br><span class="line">randAlphaNum 10              -- value | randAlphaNum 10 </span><br><span class="line">toYaml value                 -- value | toYaml</span><br><span class="line"><span class="built_in">printf</span> format value          -- list value | join <span class="string">"-"</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>modify scope using <code>with</code> to simpify the directives，就不用写一长串引用了</p>
</li>
<li><p>control whitespaces and indent<br>use <code>-</code> to remove whitespace (newline is treated as white space!)</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&#123;&#123;-</span> <span class="string">with</span> <span class="string">...</span> <span class="bullet">-&#125;&#125;</span></span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="string">&#123;&#123;-</span> <span class="string">end&#125;&#125;</span></span><br><span class="line"><span class="comment">## indent 6 space ahead</span></span><br><span class="line"><span class="string">&#123;&#123;</span> <span class="string">indent</span> <span class="number">6</span> <span class="string">.Value.tcp</span> <span class="string">&#125;&#125;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>logical operators and flow control<br>if-else and loop</p>
</li>
<li><p>use variables<br>define the variable</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;&#123;- <span class="variable">$defaultPortNum</span> := .Values.defaultPortNum -&#125;&#125;</span><br><span class="line">&#123;&#123; <span class="variable">$defaultPortNum</span> &#125;&#125;</span><br><span class="line"><span class="comment">## . means global scope</span></span><br><span class="line">&#123;&#123; $.Release.Name&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>use sub-template<br>define function in <code>_helper.tpl</code> file then use <code>include</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;&#123; include <span class="string">"fun_name"</span> . | indent 4&#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="Debug-template"><a href="#Debug-template" class="headerlink" title="Debug template"></a>Debug template</h2><p>Locally rendering template:<br><a href="https://helm.sh/docs/helm/helm_template/" target="_blank" rel="noopener">https://helm.sh/docs/helm/helm_template/</a><br><a href="https://helm.sh/docs/chart_template_guide/debugging/" target="_blank" rel="noopener">https://helm.sh/docs/chart_template_guide/debugging/</a></p>
<blockquote>
<p>Usually first use the static check then dynamic check.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## static</span></span><br><span class="line"><span class="comment">## works without k8s cluster</span></span><br><span class="line"><span class="comment">## use `REALEASE-NAME`</span></span><br><span class="line">helm template &lt;chart dir or archive file&gt; [--debug] | less</span><br><span class="line"></span><br><span class="line"><span class="comment">## dynamic</span></span><br><span class="line"><span class="comment">## real helm install but without commit</span></span><br><span class="line"><span class="comment">## can generate a release name as [release]</span></span><br><span class="line">helm install [release] &lt;chart&gt; --dry-run --debug 2&gt;&amp;1 | less</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h2 id="Chart-file-structure"><a href="#Chart-file-structure" class="headerlink" title="Chart file structure"></a>Chart file structure</h2><p><a href="https://helm.sh/docs/topics/charts/#the-chart-file-structure" target="_blank" rel="noopener">https://helm.sh/docs/topics/charts/#the-chart-file-structure</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&lt;chart name&gt;/</span><br><span class="line">  Chart.yaml          <span class="comment"># A YAML file containing information about the chart</span></span><br><span class="line">  LICENSE             <span class="comment"># OPTIONAL: A plain text file containing the license for the chart</span></span><br><span class="line">  README.md           <span class="comment"># OPTIONAL: A human-readable README file</span></span><br><span class="line">  values.yaml         <span class="comment"># The default configuration values for this chart</span></span><br><span class="line">  values.schema.json  <span class="comment"># OPTIONAL: A JSON Schema for imposing a structure on the values.yaml file, values.yaml 必须遵守这个结构, 否则不会通过</span></span><br><span class="line">  charts/             <span class="comment"># other dependent</span></span><br><span class="line">  requirements.yaml   <span class="comment"># other dependent (for helm2)</span></span><br><span class="line">  crds/               <span class="comment"># Custom Resource Definitions</span></span><br><span class="line">  templates/          <span class="comment"># A directory of templates that, when combined with values,</span></span><br><span class="line">                      <span class="comment"># will generate valid Kubernetes manifest files.</span></span><br><span class="line">     xxx.yaml</span><br><span class="line">     _xx.tpl          <span class="comment"># functions</span></span><br><span class="line">     NOTES.txt        <span class="comment"># show description after run helm install </span></span><br><span class="line">  templates/NOTES.txt <span class="comment"># OPTIONAL: A plain text file containing short usage notes</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>To drop a dependency into your <code>charts/</code> directory, use the <code>helm pull</code> command</p>
</blockquote>
<ol>
<li>Chart.yaml<br><code>apiVersion</code>, helm3 is <code>v2</code>, helm2 is <code>v1</code><br><code>appVersion</code>, application verion<br><code>version</code>, charts version, for example, chart file/structure changed<br><code>keywords</code> field is used for helm search<br><code>type</code>, we have application and library chart</li>
</ol>
<h2 id="Managing-dependencies"><a href="#Managing-dependencies" class="headerlink" title="Managing dependencies"></a>Managing dependencies</h2><p>Package the charts to archive, you can use <code>tar</code> but helm has special command for this purpose:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## it will create .tgz suffix</span></span><br><span class="line"><span class="comment">## and append chart verion to archive name</span></span><br><span class="line"><span class="comment">## chart version is from Chart.yaml</span></span><br><span class="line">helm package &lt;chart_name&gt;</span><br></pre></td></tr></table></figure></p>
<p>Publishing chart in repos, chartmuseum (like docker hub..), just like private docker registry, you can create a private chartmuseum in your host (有专门的安装包).<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## go to the dir that contains chart archive</span></span><br><span class="line"><span class="comment">## this will generate a index.yaml file</span></span><br><span class="line">helm repo index .</span><br><span class="line"><span class="comment">## for security can be signed and verified</span></span><br><span class="line"><span class="comment">## for verification, we need provenance file</span></span><br><span class="line">helm package --sign</span><br><span class="line">helm verify &lt;chart&gt;</span><br><span class="line"><span class="comment">## verify when install</span></span><br><span class="line">helm install --verify ...</span><br></pre></td></tr></table></figure></p>
<p>关于dependency，甚至可以只有charts文件夹，里面放所有的chart archive，外面也不需要templates了。<br>但这样不好管理版本，还是在Chart.yaml中定义依赖比较好。<br>在定义中还可以指定版本的范围，用的是semver语法: <code>~1.2.3</code>, <code>^0.3.4</code>, <code>1.2-3.4.5</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## will download dependency charts archive to your charts folder</span></span><br><span class="line"><span class="comment">## according to the definition in Chart.yaml</span></span><br><span class="line">helm dependency update &lt;chart name&gt;</span><br><span class="line"><span class="comment">## list dependency, their version, repo and status</span></span><br><span class="line">helm dependency list &lt;chart name&gt;</span><br></pre></td></tr></table></figure></p>
<p>You can also use <code>conditions and tags</code> to control which dependency is needed or not, for example, in <code>Chart.yaml</code> file<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v2</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">guestbook</span></span><br><span class="line"><span class="attr">appVersion:</span> <span class="string">"2.0"</span></span><br><span class="line"><span class="attr">description:</span> <span class="string">A</span> <span class="string">Helm</span> <span class="string">chart</span> <span class="string">for</span> <span class="string">Guestbook</span> <span class="number">2.0</span> </span><br><span class="line"><span class="attr">version:</span> <span class="number">1.2</span><span class="number">.2</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">application</span></span><br><span class="line"><span class="attr">dependencies:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">backend</span></span><br><span class="line"><span class="attr">    version:</span> <span class="string">~1.2.2</span></span><br><span class="line"><span class="attr">    repository:</span> <span class="attr">http://localhost:8080</span></span><br><span class="line"><span class="attr">    condition:</span> <span class="string">backend.enabled</span></span><br><span class="line"><span class="attr">    tags:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">api</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">frontend</span></span><br><span class="line"><span class="attr">    version:</span> <span class="string">^1.2.0</span></span><br><span class="line"><span class="attr">    repository:</span> <span class="attr">http://localhost:8080</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">database</span></span><br><span class="line"><span class="attr">    version:</span> <span class="string">~1.2.2</span></span><br><span class="line"><span class="attr">    repository:</span> <span class="attr">http://localhost:8080</span></span><br><span class="line"><span class="attr">    condition:</span> <span class="string">database.enabled</span></span><br><span class="line"><span class="attr">    tags:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">api</span></span><br></pre></td></tr></table></figure></p>
<p>Then in <code>values.yaml</code> file:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## can be true or false</span></span><br><span class="line"><span class="attr">backend:</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">database:</span></span><br><span class="line"><span class="attr">  enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">tags:</span></span><br><span class="line"><span class="attr">  api:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Using-existing-charts"><a href="#Using-existing-charts" class="headerlink" title="Using existing charts"></a>Using existing charts</h2><p>Helm web: <a href="https://hub.helm.sh/" target="_blank" rel="noopener">https://hub.helm.sh/</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## add and remove repo</span></span><br><span class="line">helm add repo ...</span><br><span class="line">helm remove repo ...</span><br><span class="line"><span class="comment">## list repo's name and URL</span></span><br><span class="line">helm repo list</span><br><span class="line"></span><br><span class="line"><span class="comment">## search chart you want,for example</span></span><br><span class="line"><span class="comment">## mysql, nfs, mongodb, prometheus, redis, dashboard, wordpress</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## for mysql, you need to specify storage provisioner</span></span><br><span class="line"><span class="comment">## see inspect readme or values</span></span><br><span class="line">helm search [hub | repo] &lt;keyword&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## inspect the chart, like docker inspect</span></span><br><span class="line"><span class="comment">## readme: usage 去网上看更清晰</span></span><br><span class="line"><span class="comment">## values: default config</span></span><br><span class="line"><span class="comment">## chart: Chart.yaml</span></span><br><span class="line">helm inspect [all | readme | values | chart] &lt;chart name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same as 'helm inspect values'</span></span><br><span class="line">helm show values</span><br><span class="line"></span><br><span class="line"><span class="comment">## download chart without dependencies</span></span><br><span class="line"><span class="comment">## for example, looking into the source code</span></span><br><span class="line">helm fetch &lt;chart name&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## download dependencies specified in Chart.yaml</span></span><br><span class="line"><span class="comment">## specify char name unpacked</span></span><br><span class="line">helm dependency update &lt;chart name&gt;</span><br></pre></td></tr></table></figure>
<h2 id="Customizig-existing-charts"><a href="#Customizig-existing-charts" class="headerlink" title="Customizig existing charts"></a>Customizig existing charts</h2><p>if you want to override <code>child</code> chart’s values.yaml, then in your <code>partent</code> chart values.yaml, 这是常用的，比如你有个dependency 是 mongodb chart, 要改它的默认配置:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 'mongodb' is child chart name</span></span><br><span class="line"><span class="attr">mongodb:</span></span><br><span class="line"><span class="attr">  persistence:</span></span><br><span class="line"><span class="attr">    size:</span> <span class="number">100</span><span class="string">Mi</span></span><br></pre></td></tr></table></figure></p>
<p>还可以child chart中的values.yaml override parent的，但很少这样用，用法很tricky.</p>
<h2 id="Helm-command"><a href="#Helm-command" class="headerlink" title="Helm command"></a>Helm command</h2><p><a href="https://helm.sh/docs/helm/" target="_blank" rel="noopener">https://helm.sh/docs/helm/</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## install with specified release name</span></span><br><span class="line">helm install [release name] [chart] -n &lt;namespace&gt;</span><br><span class="line"><span class="comment">## check release status</span></span><br><span class="line">helm list -n &lt;namespace&gt;</span><br><span class="line"><span class="comment">## display yaml files</span></span><br><span class="line">helm get manifest [release] -n &lt;namespace&gt; | less</span><br><span class="line"></span><br><span class="line"><span class="comment">## check release specification and revision numbers</span></span><br><span class="line">helm status [release] -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## get all info</span></span><br><span class="line"><span class="comment">## helm2: helm get [release]</span></span><br><span class="line">helm get all [release] -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## upgrade</span></span><br><span class="line">helm upgrade [release] [chart] -n &lt;namespace&gt;</span><br><span class="line"><span class="comment">## check revision</span></span><br><span class="line">helm <span class="built_in">history</span> [release] -n &lt;namespace&gt;</span><br><span class="line"><span class="comment">## rollback</span></span><br><span class="line"><span class="comment">## revision number can get from helm history</span></span><br><span class="line">helm rollback [release] [revision] -n &lt;namespace&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment">## helm2: helm delete --purge [release] </span></span><br><span class="line">helm uninstall [release] -n &lt;namespace&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="PluralSight-Complement"><a href="#PluralSight-Complement" class="headerlink" title="PluralSight Complement"></a>PluralSight Complement</h1><p>github: <a href="https://github.com/phcollignon/helm3" target="_blank" rel="noopener">https://github.com/phcollignon/helm3</a></p>
<h2 id="Helm-context"><a href="#Helm-context" class="headerlink" title="Helm context"></a>Helm context</h2><p>Helm use the same configuration as kubectl<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## helm env, repos, config, cache info</span></span><br><span class="line">helm env</span><br><span class="line"><span class="comment">## check helm version</span></span><br><span class="line">helm version --short</span><br><span class="line"><span class="comment">## helm uses the same current context</span></span><br><span class="line">kubectl config view</span><br></pre></td></tr></table></figure></p>
<p>Helm stores release configuration and history in k8s as secrets. In helm3, it is stored in each corresponding namepsace.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## in your working namespace</span></span><br><span class="line">kubectl get secret -n &lt;ns&gt;</span><br><span class="line"><span class="comment">## helm secret is something like:</span></span><br><span class="line">sh.helm.release.v1.demomysql.v1      helm.sh/release.v1                    1      110s</span><br></pre></td></tr></table></figure></p>
<p><a href="https://helm.sh/docs/faq/#improved-upgrade-strategy-3-way-strategic-merge-patches" target="_blank" rel="noopener">Improved Upgrade Strategy: 3-way Strategic Merge Patches</a><br>In Helm3, Helm considers the <code>old manifest</code>, its <code>live state</code>, and the <code>new manifest</code> when generating a patch.</p>
<p>In helm2, helm client uses <code>gRPC</code> protocol to access Tiller server (in production secure connection is required, set TLS/SSL), then Tiller (need service account with privilege) will call K8s API to instantiate the charts. In helm3, no Tiller no security issue.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>helm</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux LPIC-1 Training</title>
    <url>/2020/04/15/linux-LPIC1-training/</url>
    <content><![CDATA[<p>这篇总结是来自PluralSight上的<code>LPIC-1</code>课程的Essential章节。</p>
<p>备注:2020年4月份pluralsight在搞活动，免费注册学习！这次lock down是个机会补补课。</p>
<p>Environment: <code>CentOS 7 Enterprise Linux</code> or <code>RedHat</code></p>
<h2 id="Essentials"><a href="#Essentials" class="headerlink" title="Essentials"></a>Essentials</h2><p>Reading OS data<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## system version</span></span><br><span class="line"><span class="comment">## softlink actually</span></span><br><span class="line">cat /etc/os-release</span><br><span class="line">cat /etc/system-release</span><br><span class="line">cat /etc/redhat-release</span><br><span class="line"></span><br><span class="line"><span class="comment">## kernel number</span></span><br><span class="line">uname -r</span><br><span class="line">cat /proc/version</span><br></pre></td></tr></table></figure></p>
<h3 id="Shutdown"><a href="#Shutdown" class="headerlink" title="Shutdown"></a>Shutdown</h3><p>Send message to others<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## send to individual user terminal</span></span><br><span class="line">write dsadm</span><br><span class="line">&gt; xxx</span><br><span class="line"></span><br><span class="line"><span class="comment">## send to all user in terminals</span></span><br><span class="line">wall &lt; message.txt</span><br></pre></td></tr></table></figure></p>
<p>Shutdown system and prompt<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## reboot now</span></span><br><span class="line">shutdown -r now</span><br><span class="line"><span class="comment">## halt/poweroff in 10 mins and use wall send message to login users</span></span><br><span class="line">shutdown -h 10 <span class="string">"The system is going down in 10 min"</span></span><br><span class="line"><span class="comment">## cancel shutdown</span></span><br><span class="line">shutdown -c</span><br></pre></td></tr></table></figure></p>
<p>Changing runlevels<br>what is <code>runlevel</code> in linux?<br><a href="https://www.liquidweb.com/kb/linux-runlevels-explained/" target="_blank" rel="noopener">https://www.liquidweb.com/kb/linux-runlevels-explained/</a><br>比如<br>runlevel 1 就只能root user且没有network enabled，也叫作rescue.target，可以做一些需要隔离的操作。<br>runlevel 3 是默认的multi-user + network enabled。<br>runlevel 5 是Desktop interface + runlevel 3的组合。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show current runlevel</span></span><br><span class="line">who -r</span><br><span class="line">runlevel</span><br><span class="line"></span><br><span class="line"><span class="comment">## default runlevel</span></span><br><span class="line">systemctl get-default</span><br><span class="line"><span class="comment">## set defailt runlevel</span></span><br><span class="line">systemctl <span class="built_in">set</span>-default multi-user.target</span><br></pre></td></tr></table></figure></p>
<h3 id="Manage-processes"><a href="#Manage-processes" class="headerlink" title="Manage processes"></a>Manage processes</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show process on current shell</span></span><br><span class="line"><span class="comment">## use dash is UNIX options</span></span><br><span class="line">ps -f</span><br><span class="line"><span class="comment">## -e means all processes</span></span><br><span class="line">ps -ef --forest</span><br><span class="line"><span class="comment">## -F show full format column</span></span><br><span class="line">ps -F -p $(pgrep sshd)</span><br><span class="line"><span class="comment">## kill all sleep processes</span></span><br><span class="line">pkill sleep</span><br><span class="line"><span class="comment">## BSD options</span></span><br><span class="line">ps aux</span><br></pre></td></tr></table></figure>
<p><code>$$</code> the PID of current running process<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /proc/$$</span><br><span class="line"><span class="comment">## we can interrogate this directory</span></span><br><span class="line"><span class="comment">## current dir</span></span><br><span class="line">ls -l cwd</span><br><span class="line"><span class="comment">## current exe</span></span><br><span class="line">ls -l exe</span><br></pre></td></tr></table></figure></p>
<p><code>top</code> 命令的options还记得吗? 比如切换memory显示单位，选择排序的依据CPU/MEM occupied..</p>
<h3 id="Process-priority"><a href="#Process-priority" class="headerlink" title="Process priority"></a>Process priority</h3><p>if something runs in foreground and prevent you from doing anything, use <code>ctrl + z</code> to suspend it (still in memory, not takeing CPU time), then put it in background.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sleep 10000</span><br><span class="line">^Z</span><br><span class="line">[1]+  Stopped                 sleep 10000</span><br><span class="line"></span><br><span class="line"><span class="comment">## use job command, `+` means current focus</span></span><br><span class="line"><span class="built_in">jobs</span></span><br><span class="line">[1]+  Stopped                 sleep 10000</span><br><span class="line"></span><br><span class="line"><span class="comment">## use bg command to put current focus in background</span></span><br><span class="line"><span class="built_in">bg</span></span><br><span class="line">[1]+ sleep 10000 &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment">## check is running in background</span></span><br><span class="line"><span class="built_in">jobs</span></span><br><span class="line">[1]+  Running                 sleep 10000 &amp;</span><br><span class="line"></span><br><span class="line"><span class="comment">## use fg will bring current focus to foreground again</span></span><br></pre></td></tr></table></figure></p>
<p>如果你在一个bash shell中sleep 1000&amp; 然后exit bash shell，则这个sleep process will hand over to init process. can check via <code>ps -F -p $(pgrep sleep)</code>, 会发现PPID是<code>1</code>了。进入另一个bash shell <code>jobs</code> 并不会显示之前bash shell的background process.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show PRI(priority) and NI(nice) number</span></span><br><span class="line">ps -l</span><br><span class="line"></span><br><span class="line">F S   UID   PID  PPID  C PRI  NI ADDR SZ WCHAN  TTY          TIME CMD</span><br><span class="line">4 S     0 23785 23781  0  80   0 - 28891 do_wai pts/1    00:00:00 bash</span><br><span class="line">0 S     0 24859 23785  0  80   0 - 26987 hrtime pts/1    00:00:00 sleep</span><br><span class="line">0 S     0 24861 23785  0  80   0 - 26987 hrtime pts/1    00:00:00 sleep</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>NI value is from [-20,19], higher the nicer so less CPU time to take.<br>PRI value is from [60,99], 60 is the highest.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## set nice value to 19</span></span><br><span class="line">nice -n 19 sleep 1000 &amp;</span><br><span class="line"><span class="comment">## reset nice value</span></span><br><span class="line">renice -n 10 -p &lt;pid&gt;</span><br></pre></td></tr></table></figure></p>
<p>要注意的是只有root可以设置负数nice value和降低nice value. root可以去<code>vim /etc/security/limits.conf</code>设置对不同user/group的nice value。</p>
<h3 id="Monitor-linux-performance"><a href="#Monitor-linux-performance" class="headerlink" title="Monitor linux performance"></a>Monitor linux performance</h3><p>这个很重要，一般关注网络，硬盘，CPU</p>
<p>List content of the package <code>procps-ng</code>, <code>procps</code> is the package that has a bunch of small useful utilities that give information about processes using the <code>/proc</code> filesystem. The package includes the programs ps, top, vmstat, w, kill, free, slabtop, and skill.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## see executable files under procps package via rpm</span></span><br><span class="line">rpm -ql procps-ng | grep <span class="string">"^/usr/bin/"</span></span><br><span class="line"></span><br><span class="line">/usr/bin/free</span><br><span class="line">/usr/bin/pgrep</span><br><span class="line">/usr/bin/pkill</span><br><span class="line">/usr/bin/pmap</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment">## check the source package of top command</span></span><br><span class="line">rpm -qf $(<span class="built_in">which</span> top)</span><br><span class="line"></span><br><span class="line">procps-ng-3.3.10-17.el7_5.2.x86_64</span><br></pre></td></tr></table></figure></p>
<p>Introduce 2 new commands: <code>pmap</code> and <code>pwdx</code><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## pmap, show memory map of a process</span></span><br><span class="line"><span class="comment">## for example, current running process</span></span><br><span class="line">pmap $$</span><br><span class="line"><span class="comment">## you can also see shared libary been used by the process</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## show current working directory of process</span></span><br><span class="line">pwdx $$</span><br><span class="line">pwdx $(pgrep sshd)</span><br><span class="line"><span class="comment">## actually the output is from /proc/&lt;pid&gt;/cwd, it is a softlink</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## check how long the system has been running</span></span><br><span class="line"><span class="comment">## load average is not normalized for cpu number 如果你知道CPU有多少个</span></span><br><span class="line"><span class="comment">## 根据load average就能看出是不是很忙, 如果load average的值超出了CPU个数</span></span><br><span class="line"><span class="comment">## 则说明需要queue or wait</span></span><br><span class="line"><span class="comment">## 这个命令其实是从/proc/uptime, /proc/loadavg 来的数据 </span></span><br><span class="line">uptime</span><br><span class="line">18:53:14 up 39 days,  3:50,  1 user,  load average: 0.00, 0.01, 0.05</span><br><span class="line"></span><br><span class="line"><span class="comment">## check how many cpu</span></span><br><span class="line">lscpu</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same as w</span></span><br><span class="line">w</span><br><span class="line"> 18:59:29 up 12 days, 23:40,  3 users,  load average: 0.04, 0.26, 0.26</span><br><span class="line">USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT</span><br><span class="line">root     pts/0    9.160.1.111      08:47    6:46m  0.03s  0.03s -bash</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>监控load or output<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## execute a program periodically, showing output fullscreen</span></span><br><span class="line"><span class="comment">## 这里的例子是每隔4秒 运行 uptime</span></span><br><span class="line">watch -n 4 uptime</span><br><span class="line"></span><br><span class="line"><span class="comment">## graphic representation of system load average</span></span><br><span class="line"><span class="comment">## 如果此时运行一个tar，会看到loadavg显著变化</span></span><br><span class="line">tload</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -b 使用batch mode 输出所有process情况</span></span><br><span class="line"><span class="comment">## -n2 运行2回合</span></span><br><span class="line">top -b -n2 &gt; file.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">## run 3 time, gap 5 seconds</span></span><br><span class="line"><span class="comment">## reports information about processes, memory, paging, block IO, traps, disks and cpu activity</span></span><br><span class="line">vmstat 5 3</span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   <span class="keyword">in</span>   cs us sy id wa st</span><br><span class="line"> 1  0    520  90576   4176 1601932    0    0     4   188   18   19  0  1 93  4  2</span><br><span class="line"> 0  0    520  90460   4176 1601956    0    0     0    46  514  348  0  0 98  2  1</span><br><span class="line"> 0  0    520  88972   4176 1603692    0    0     0   542  707  589  0  1 97  2  1</span><br></pre></td></tr></table></figure>
<h3 id="sysstat-toolkit"><a href="#sysstat-toolkit" class="headerlink" title="sysstat toolkit"></a>sysstat toolkit</h3><p>Install <code>sysstat</code> (this is a series of command: <code>iostat</code>, <code>netstat</code>, etc).<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y sysstat</span><br><span class="line"></span><br><span class="line"><span class="comment">## then check executable</span></span><br><span class="line">rpm -ql | grep <span class="string">"^/usr/bin"</span></span><br><span class="line"></span><br><span class="line">/usr/bin/cifsiostat</span><br><span class="line">/usr/bin/iostat</span><br><span class="line">/usr/bin/mpstat</span><br><span class="line">/usr/bin/nfsiostat-sysstat</span><br><span class="line">/usr/bin/pidstat</span><br><span class="line">/usr/bin/sadf</span><br><span class="line">/usr/bin/sar</span><br><span class="line">/usr/bin/tapestat</span><br></pre></td></tr></table></figure></p>
<p>在安装后，其实用的cron在背后操作收集数据, configuration is in file <code>cat /etc/sysconfig/sysstat</code>，这里面可以设置记录的周期，默认是28天。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## cron config for sysstat</span></span><br><span class="line">cat /etc/cron.d/sysstat </span><br><span class="line"></span><br><span class="line"><span class="comment"># Run system activity accounting tool every 10 minutes</span></span><br><span class="line">*/10 * * * * root /usr/lib64/sa/sa1 1 1</span><br><span class="line"><span class="comment"># 0 * * * * root /usr/lib64/sa/sa1 600 6 &amp;</span></span><br><span class="line"><span class="comment"># Generate a daily summary of process accounting at 23:53</span></span><br><span class="line">53 23 * * * root /usr/lib64/sa/sa2 -A</span><br></pre></td></tr></table></figure></p>
<p>start and enable:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start sysstat</span><br><span class="line">systemctl <span class="built_in">enable</span> sysstat</span><br></pre></td></tr></table></figure></p>
<p>来看看sysstat下的工具命令:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show in mega byte</span></span><br><span class="line"><span class="comment">## run 3 times 5 seconds in between</span></span><br><span class="line">iostat -m 5 3</span><br><span class="line"><span class="comment">## others</span></span><br><span class="line">pidstat</span><br><span class="line">mpstat</span><br></pre></td></tr></table></figure></p>
<p>Let’s see <code>sar</code> report, 通过分析一天的bottleneck(cpu/memory/disk/network/loadavg)可以更好的schedule任务。这里并没有深入讲解怎么解读这些数据，并且你需要了解各个部分数据的含义，以及什么样的数据可能是异常。<br><code>sar</code>的数据在<code>/var/log/sa</code>里面，每天一个文件，周期性覆盖。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## default show CPU utilization</span></span><br><span class="line">sar -u</span><br><span class="line"><span class="comment">## show memory utilization</span></span><br><span class="line">sar -r</span><br><span class="line"><span class="comment">## show disk utilization</span></span><br><span class="line">sar -b</span><br><span class="line"><span class="comment">## network activity</span></span><br><span class="line">sar -n DEV</span><br><span class="line"><span class="comment">## load average</span></span><br><span class="line">sar -q</span><br><span class="line"><span class="comment">## 显示sa23这天的文件，从18:00:00到19:00:00 </span></span><br><span class="line">sar -n DEV -s 18:00:00 -e 19:00:00 -f /var/<span class="built_in">log</span>/sa/sa23</span><br></pre></td></tr></table></figure></p>
<p>图形化sar数据，可以用ksar:<a href="https://www.cyberciti.biz/tips/identifying-linux-bottlenecks-sar-graphs-with-ksar.html" target="_blank" rel="noopener">https://www.cyberciti.biz/tips/identifying-linux-bottlenecks-sar-graphs-with-ksar.html</a></p>
<h3 id="Log-and-logrotate"><a href="#Log-and-logrotate" class="headerlink" title="Log and logrotate"></a>Log and logrotate</h3><p>Auditing login events，这个还挺有用的，看哪个user什么时候login了, <code>w</code>是查看当前哪些user正在使用中。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## see user login info</span></span><br><span class="line">lastlog | grep -v <span class="string">"Never"</span></span><br><span class="line"></span><br><span class="line">Username         Port     From             Latest</span><br><span class="line">root             pts/0    9.65.239.28      Fri Apr 24 17:51:48 -0700 2020</span><br><span class="line">fyre             pts/0                     Fri Apr 24 17:52:00 -0700 2020</span><br><span class="line"></span><br><span class="line"><span class="comment">## check system reboot info</span></span><br><span class="line"><span class="comment">## The last command reads data from the wtmp log and displays it in a terminal window.</span></span><br><span class="line">last reboot</span><br><span class="line"><span class="comment">## check still login user</span></span><br><span class="line">last | grep still</span><br></pre></td></tr></table></figure></p>
<p>Auditing root access，看su/sudo的使用情况，在<code>/var/log/secure</code>文件中，这里其实有多个secure文件，有日期区分。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## there are some secure and auditing files</span></span><br><span class="line"><span class="built_in">cd</span> /var/<span class="built_in">log</span></span><br><span class="line"><span class="comment">## secure file</span></span><br><span class="line"><span class="comment">## 当然有grep也行，把用sudo的事件找出来</span></span><br><span class="line">awk <span class="string">'/sudo/ &#123; print $5, $6, $14&#125;'</span> secure</span><br></pre></td></tr></table></figure></p>
<p>我会专门总结一下awk的笔记，这个挺有用的。</p>
<p><code>journalctl</code>是一个常用的system log查询工具。当时查看一些docker的log在里面也能看到。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show last 10 lines</span></span><br><span class="line">journalctl -n 10</span><br><span class="line"><span class="comment">## ses real time appending</span></span><br><span class="line">journalctl -f</span><br><span class="line"><span class="comment">## -u: systemd unit</span></span><br><span class="line">journalctl -u sshd</span><br><span class="line"><span class="comment">## timestamp</span></span><br><span class="line">journalctl --since <span class="string">"10 minutes ago"</span></span><br><span class="line">journalctl --since <span class="string">"2020-04-26 13:00:00"</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Selinux"><a href="#Selinux" class="headerlink" title="Selinux"></a>Selinux</h3><p>O’Reilly有过相关的课程，在我工作邮件中连接还在。目前只需要知道什么是selinux，如何打开，关闭它即可。<br>SELINUX= can take one of these three values:<br><code>enforcing</code> - SELinux security policy is enforced.<br><code>permissive</code> - SELinux prints warnings instead of enforcing.<br><code>disabled</code> - No SELinux policy is loaded.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## see if selinux is permissive, enforcing or disabled</span></span><br><span class="line">getenforce</span><br><span class="line"><span class="comment">## more clear</span></span><br><span class="line">sestatus</span><br></pre></td></tr></table></figure></p>
<p>如果最开始是disabled的，则要去config file <code>/etc/selinux/config</code> 设置permissive，然后重启。<br>不能setenforce 去disable，也只能在config文件中disable然后重启机器。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## setenforce [ Enforcing | Permissive | 1 | 0 ]</span></span><br><span class="line"><span class="comment">## 成为permissive后就可以用setenforce切换了，但都不是永久的</span></span><br><span class="line">setenforce 0</span><br><span class="line">setenforce 1</span><br></pre></td></tr></table></figure></p>
<p>显示selinux的labels, <code>Z</code>对于其他命令也有用。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ps -Zp $(pgrep sshd)</span><br><span class="line"></span><br><span class="line">LABEL                             PID TTY      STAT   TIME COMMAND</span><br><span class="line">system_u:system_r:kernel_t:s0     968 ?        Ss     0:00 /usr/sbin/sshd -D</span><br><span class="line">unconfined_u:unconfined_r:unconfined_t:s0 1196 ? Ss   0:00 sshd: root@pts/0</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>LPIC-1</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Capability</title>
    <url>/2019/05/13/linux-capability/</url>
    <content><![CDATA[<p>In my post <a href="https://chengdol.github.io/2019/05/01/linux-ipcs/" target="_blank" rel="noopener"><code>&lt;&lt;Linux IPC&gt;&gt;</code></a>, I mentioned <code>Linux Capability</code>, so what is it? Why we use it? How and when to use this feature?</p>
<p>For the purpose of performing permission checks, traditional UNIX implementations distinguish two categories of processes: <code>privileged</code> processes (whose effective user ID is 0, referred to as superuser or root), and <code>unprivileged</code> processes (whose effective UID is nonzero).</p>
<p>Privileged processes bypass all kernel permission checks, while unprivileged processes are subject to full permission checking based on the process’s credentials (usually: effective UID, effective GID, and supplementary group list).</p>
<blockquote>
<p>Note again, privilege process (root user) bypass all kernel permission checks, but in K8s or docker container, it depends on the configuration you made.</p>
</blockquote>
<p>Starting with kernel 2.2, Linux divides the privileges traditionally associated with superuser into distinct units, known as <code>capabilities</code>, which can be independently enabled and disabled. This way the full set of privileges is reduced and decreasing the risks of exploitation.</p>
<h2 id="Basic-Capability-Thing"><a href="#Basic-Capability-Thing" class="headerlink" title="Basic Capability Thing"></a>Basic Capability Thing</h2><h3 id="Header-File"><a href="#Header-File" class="headerlink" title="Header File"></a>Header File</h3><p>Linux capabilities are defined in a header file with the non-surprising name <code>capability.h</code>, in <code>/usr/include/linux/capability.h</code>. They’re pretty self-explanatory and well commented</p>
<h3 id="Capability-Number"><a href="#Capability-Number" class="headerlink" title="Capability Number"></a>Capability Number</h3><p>To see the highest capability number for your kernel, use the data from the <code>/proc</code> file system.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat /proc/sys/kernel/cap_last_cap</span><br><span class="line"></span><br><span class="line">36</span><br></pre></td></tr></table></figure></p>
<h3 id="Current-Capabilities"><a href="#Current-Capabilities" class="headerlink" title="Current Capabilities"></a>Current Capabilities</h3><p>To see the current capabilities list, run <code>capsh --print</code>, for example, normal user <code>dsadm</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ capsh --print</span><br><span class="line"></span><br><span class="line">Current: =</span><br><span class="line">Bounding set =cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,</span><br><span class="line">cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,</span><br><span class="line">cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,</span><br><span class="line">cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,</span><br><span class="line">cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,</span><br><span class="line">cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,</span><br><span class="line">35,36</span><br><span class="line">Securebits: 00/0x0/1&apos;b0</span><br><span class="line"> secure-noroot: no (unlocked)</span><br><span class="line"> secure-no-suid-fixup: no (unlocked)</span><br><span class="line"> secure-keep-caps: no (unlocked)</span><br><span class="line">uid=1002(dsadm)</span><br><span class="line">gid=1002(dsadm)</span><br><span class="line">groups=1002(dsadm)</span><br></pre></td></tr></table></figure></p>
<p>you see the <code>Current: =</code> is empty, but if you run as root user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ capsh --print</span><br><span class="line"></span><br><span class="line">Current: = cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,</span><br><span class="line">cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,</span><br><span class="line">cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,</span><br><span class="line">cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,</span><br><span class="line">cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,</span><br><span class="line">cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,</span><br><span class="line">35,36+ep</span><br><span class="line">Bounding set =cap_chown,cap_dac_override,cap_dac_read_search,cap_fowner,cap_fsetid,</span><br><span class="line">cap_kill,cap_setgid,cap_setuid,cap_setpcap,cap_linux_immutable,cap_net_bind_service,</span><br><span class="line">cap_net_broadcast,cap_net_admin,cap_net_raw,cap_ipc_lock,cap_ipc_owner,cap_sys_module,</span><br><span class="line">cap_sys_rawio,cap_sys_chroot,cap_sys_ptrace,cap_sys_pacct,cap_sys_admin,cap_sys_boot,</span><br><span class="line">cap_sys_nice,cap_sys_resource,cap_sys_time,cap_sys_tty_config,cap_mknod,cap_lease,</span><br><span class="line">cap_audit_write,cap_audit_control,cap_setfcap,cap_mac_override,cap_mac_admin,cap_syslog,</span><br><span class="line">35,36</span><br><span class="line">Securebits: 00/0x0/1&apos;b0</span><br><span class="line"> secure-noroot: no (unlocked)</span><br><span class="line"> secure-no-suid-fixup: no (unlocked)</span><br><span class="line"> secure-keep-caps: no (unlocked)</span><br><span class="line">uid=0(root)</span><br><span class="line">gid=0(root)</span><br><span class="line">groups=0(root)</span><br></pre></td></tr></table></figure></p>
<p>To see the capabilities for a particular process, run <code>cat /proc/&lt;PID&gt;/status | grep -i cap</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># cat /proc/1/status | grep -i cap</span><br><span class="line"></span><br><span class="line">CapInh: 00000000a884a5fb</span><br><span class="line">CapPrm: 00000000a884a5fb</span><br><span class="line">CapEff: 00000000a884a5fb</span><br><span class="line">CapBnd: 00000000a884a5fb</span><br><span class="line">CapAmb: 0000000000000000</span><br></pre></td></tr></table></figure></p>
<p>This is the bit map for capabilities, the meaning for each is:</p>
<ul>
<li>CapInh = Inherited capabilities</li>
<li>CapPrm – Permitted capabilities</li>
<li>CapEff = Effective capabilities</li>
<li>CapBnd = Bounding set</li>
<li>CapAmb = Ambient capabilities set</li>
</ul>
<blockquote>
<p>The <code>CapBnd</code> defines the upper level of available capabilities. During the time a process runs, no capabilities can be added to this list. Only the capabilities in the bounding set can be added to the inheritable set, which uses the capset() system call. If a capability is dropped from the boundary set, that process or its children can no longer have access to it.</p>
</blockquote>
<p>Using the <code>capsh</code> utility we can decode them into the capabilities name:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># capsh --decode=00000000a884a5fb</span><br><span class="line"></span><br><span class="line">0x00000000a884a5fb=cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,cap_setgid,</span><br><span class="line">cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,cap_sys_chroot,</span><br><span class="line">cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap</span><br></pre></td></tr></table></figure></p>
<p>The another easy way is use <code>getpcaps</code> utility:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># getpcaps 1965</span><br><span class="line"></span><br><span class="line">Capabilities for `1965&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+eip</span><br></pre></td></tr></table></figure></p>
<p>It is also interesting to see the capabilities of a set of processes that have a relationship.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># getpcaps $(pgrep db2)</span><br><span class="line"></span><br><span class="line">Capabilities for `1965&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+eip</span><br><span class="line">Capabilities for `2151&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+i</span><br><span class="line">Capabilities for `2245&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+eip</span><br><span class="line">Capabilities for `2246&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+eip</span><br><span class="line">Capabilities for `2247&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+eip</span><br><span class="line">Capabilities for `2249&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+i</span><br><span class="line">Capabilities for `2614&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+i</span><br><span class="line">Capabilities for `4213&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+i</span><br><span class="line">Capabilities for `4238&apos;: = cap_chown,cap_dac_override,cap_fowner,cap_fsetid,cap_kill,</span><br><span class="line">cap_setgid,cap_setuid,cap_setpcap,cap_net_bind_service,cap_net_raw,cap_ipc_owner,</span><br><span class="line">cap_sys_chroot,cap_sys_nice,cap_mknod,cap_audit_write,cap_setfcap+i</span><br></pre></td></tr></table></figure></p>
<h3 id="Limit-Capability"><a href="#Limit-Capability" class="headerlink" title="Limit Capability"></a>Limit Capability</h3><p>You can test what happens when a particular capability is dropped by using the <code>capsh</code> utility. This is a way to see what capabilities a particular program may need to function correctly. The <code>capsh</code> command can run a particular process and restrict the set of available capabilities.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">capsh --print -- -c &quot;/bin/ping -c 1 localhost&quot;</span><br></pre></td></tr></table></figure></p>
<p>After dropping <code>cap_net_raw</code>, <code>ping</code> not permitted.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">capsh --drop=cap_net_raw --print -- -c &quot;/bin/ping -c 1 localhost&quot;</span><br></pre></td></tr></table></figure></p>
<h3 id="Capability-Meet"><a href="#Capability-Meet" class="headerlink" title="Capability Meet"></a>Capability Meet</h3><p>List the capabilities I have seen so far:</p>
<ul>
<li><p>CAP_SYS_ADMIN<br>Without it, I cannot perform <code>hostname</code> command for docker container in K8s.</p>
</li>
<li><p>CAP_SYS_RESOURCE<br>This is for adjust <a href="https://www.ibm.com/support/knowledgecenter/en/SSEPGG_11.1.0/com.ibm.db2.luw.qb.server.doc/doc/c0057140.html" target="_blank" rel="noopener">Db2 kernel parameters</a></p>
</li>
</ul>
<p>These 3 are for Db2:</p>
<ul>
<li><p>CAP_SETFCAP<br>Set arbitrary capabilities on a file. (actually this is default in unprivileged docker container)</p>
</li>
<li><p>CAP_SYS_NICE</p>
</li>
<li><p>CAP_IPC_OWNER<br>Bypass permission checks for operations on System V IPC objects.</p>
</li>
</ul>
<h3 id="My-Questions"><a href="#My-Questions" class="headerlink" title="My Questions"></a>My Questions</h3><ol>
<li><p>Privileges grant to user or process?<br>I think for the process run by normal user.</p>
</li>
<li><p>Privilege process bypass all kernel permission check? Does that mean linux capabilities are only for non-privilege user or process?<br>I think there is a global or default capability set in system to determine what ever processes on system is allowed to do. Then you can fine-tune for unprivileged process.</p>
</li>
<li><p>If we have root and normal user both in docker container, so capabilities are applied on root or normal user or both?<br>After testing and comparing by <code>capsh --print</code> with different user in xmeta container, I think capabilities are applied on all users in K8s environment.</p>
</li>
</ol>
<p>Later I post blogs to talk about <code>&lt;&lt;Capability in Docker&gt;&gt;</code> and <code>&lt;&lt;Capability in K8s&gt;&gt;</code>.</p>
<h2 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h2><p><a href="http://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">Linux Programmer’s Manual</a><br><a href="https://linux-audit.com/linux-capabilities-101/" target="_blank" rel="noopener">Linux capabilities 101</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>capability</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux IPC</title>
    <url>/2019/05/01/linux-ipc/</url>
    <content><![CDATA[<h2 id="Prequel"><a href="#Prequel" class="headerlink" title="Prequel"></a>Prequel</h2><p>Recently I was dealing with Linux kernel parameters, which are new to me and in my case they are the key to performance of the Database (DB2). This story is about removing <code>SYS_ADMIN</code> and <code>SYS_RESOURCE</code> Linux capabilities for K8s container </p>
<blockquote>
<p>Forget what is Linux capability? See my blog <a href="https://chengdol.github.io/2019/05/13/linux-capability/" target="_blank" rel="noopener"><code>&lt;&lt;Linux Capability</code>&gt;&gt;</a></p>
</blockquote>
<p>In <a href="https://www.ibm.com/support/knowledgecenter/en/SSEPGG_11.1.0/com.ibm.db2.luw.qb.server.doc/doc/c0057140.html" target="_blank" rel="noopener">Db2 IPC kernel parameters doc</a>, the database manager uses a formula to automatically adjust kernel parameter settings and eliminate the need for manual updates to these settings.</p>
<p>When instances are started, if an <code>interprocess communication (IPC)</code> kernel parameter is below the enforced minimum value, the database manager updates it to the enforced minimum value. The IPC kernel parameter values change when a Db2 instance is started.</p>
<p>There are severl Linux interprocess communication kernel parameters need to be adjusted for Db2:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kernel.shmmni (SHMMNI)</span><br><span class="line">kernel.shmmax (SHMMAX)</span><br><span class="line">kernel.shmall (SHMALL)</span><br><span class="line">kernel.sem (SEMMNI)</span><br><span class="line">kernel.sem (SEMMSL)</span><br><span class="line">kernel.sem (SEMMNS)</span><br><span class="line">kernel.sem (SEMOPM)</span><br><span class="line">kernel.msgmni (MSGMNI)</span><br><span class="line">kernel.msgmax (MSGMAX)</span><br><span class="line">kernel.msgmnb (MSGMNB)</span><br></pre></td></tr></table></figure></p>
<p>If you check <code>SYS_RESOURCE</code> <a href="http://man7.org/linux/man-pages/man7/capabilities.7.html" target="_blank" rel="noopener">manual</a>, you can see:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CAP_SYS_RESOURCE</span><br><span class="line">...</span><br><span class="line">  * raise msg_qbytes limit for a System V message queue above</span><br><span class="line">    the limit in /proc/sys/kernel/msgmnb (see msgop(2) and</span><br><span class="line">    msgctl(2));</span><br><span class="line">  * use F_SETPIPE_SZ to increase the capacity of a pipe above</span><br><span class="line">    the limit specified by /proc/sys/fs/pipe-max-size;</span><br><span class="line">  * override /proc/sys/fs/mqueue/queues_max limit when creating</span><br><span class="line">    POSIX message queues (see mq_overview(7));</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>Without granting <code>SYS_RESOURCE</code>, <code>msgmnb</code> (maybe also other kernel parameters) cannot be changed properly (actually I doubt this after checking having and not having <code>SYS_RESOURCE</code> result).</p>
<p>If there is no <code>SYS_RESOURCE</code>, one workaround is to use <code>sysctl</code> in K8s (I will talk this later…), but in my case I cannot modify kubelet configuration thus this method doesn’t work.</p>
<p>Now what we did was just removing the Linux capabilities and ran test suite to expose failures and errors with xmeta pods.</p>
<h2 id="IPC-thing"><a href="#IPC-thing" class="headerlink" title="IPC thing"></a>IPC thing</h2><p>Let’s first understand what is IPC? </p>
<p><a href="http://en.tldp.org/LDP/tlk/ipc/ipc.html" target="_blank" rel="noopener">IPC Mechanisms</a><br><a href="http://www.chandrashekar.info/articles/linux-system-programming/introduction-to-linux-ipc-mechanims.html" target="_blank" rel="noopener">IPC Mechanisms on Linux - Introduction</a></p>
<p>This post website seems going to die, just forward it here (after I go through it, I can still remember some tech words from 402 Operating System, but I forget the detail):</p>
<p><code>Inter-Process-Communication</code> (or IPC for short) are mechanisms provided by the kernel to allow processes to communicate with each other. On modern systems, IPCs form the web that bind together each process within a large scale software architecture.</p>
<p>The Linux kernel provides the following IPC mechanisms:</p>
<ol>
<li>Signals</li>
<li>Anonymous Pipes</li>
<li>Named Pipes or FIFOs</li>
<li>SysV Message Queues</li>
<li>POSIX Message Queues</li>
<li>SysV Shared memory</li>
<li>POSIX Shared memory</li>
<li>SysV semaphores</li>
<li>POSIX semaphores</li>
<li>FUTEX locks</li>
<li>File-backed and anonymous shared memory using mmap</li>
<li>UNIX Domain Sockets</li>
<li>Netlink Sockets</li>
<li>Network Sockets</li>
<li>Inotify mechanisms</li>
<li>FUSE subsystem</li>
<li>D-Bus subsystem</li>
</ol>
<p>While the above list seems quite a lot, each IPC mechanism from the list describe above , is tailored to work better for a particular use-case scenario.</p>
<ul>
<li><p>SIGNALS<br>Signals are the cheapest forms of IPC provided by Linux. Their primary use is to notify processes of change in states or events that occur within the kernel or other processes. We use signals in real world to convey messages with least overhead - think of hand and body gestures. For example, in a crowded gathering, we raise a hand to gain attention, wave hand at a friend to greet and so on.</p>
<p>On Linux, the kernel notifies a process when an event or state change occurs by interrupting the process’s normal flow of execution and invoking one of the signal handler functinos registered by the process or by the invoking one of the default signal dispositions supplied by the kernel, for the said event.</p>
</li>
<li><p>ANONYMOUS PIPES<br>Anonymous pipes (or simply pipes, for short) provide a mechanism for one process to stream data to another. A pipe has two ends associated with a pair of file descriptors - making it a one-to-one messaging or communication mechanism. One end of the pipe is the read-end which is associated with a file-descriptor that can only be read, and the other end is the write-end which is associated with a file descriptor that can only be written. This design means that pipes are essentially half-duplex.</p>
<p>Anonymous pipes can be setup and used only between processes that share parent-child relationship. Generally the parent process creates a pipe and then forks child processes. Each child process gets access to the pipe created by the parent process via the file descriptors that get duplicated into their address space. This allows the parent to communicate with its children, or the children to communicate with each other using the shared pipe.</p>
<p>Pipes are generally used to implement Producer-Consumer design amongst processes - where one or more processes would produce data and stream them on one end of the pipe, while other processes would consume the data stream from the other end of the pipe.</p>
</li>
<li><p>NAMED PIPES OR FIFO<br>Named pipes (or FIFO) are variants of pipe that allow communication between processes that are not related to each other. The processes communicate using named pipes by opening a special file known as a FIFO file. One process opens the FIFO file from writing while the other process opens the same file for reading. Thus any data written by the former process gets streamed through a pipe to the latter process. The FIFO file on disk acts as the contract between the two processes that wish to communicate.</p>
</li>
<li><p>MESSAGE QUEUES<br>Message Queues are synonymous to mailboxes. One process writes a message packet on the message queue and exits. Another process can access the message packet from the same message queue at a latter point in time. The advantage of message queues over pipes/FIFOs are that the sender (or writer) processes do not have to wait for the receiver (or reader) processes to connect. Think of communication using pipes as similar to two people communicating over phone, while message queues are similar to two people communicating using mail or other messaging services.</p>
<p>There are two standard specifications for message queues.</p>
<ul>
<li><p>SysV message queues.<br>The AT&amp;T SysV message queues support message channeling. Each message packet sent by senders carry a message number. The receivers can either choose to receive message that match a particular message number, or receive all other messages excluding a particular message number or all messages.</p>
</li>
<li><p>POSIX message queues.<br>The POSIX message queues support message priorities. Each message packet sent by the senders carry a priority number along with the message payload. The messages get ordered based on the priority number in the message queue. When the receiver tries to read a message at a later point in time, the messages with higher priority numbers get delivered first. POSIX message queues also support asynchronous message delivery using threads or signal based notification.</p>
</li>
</ul>
<p>Linux support both of the above standards for message queues.</p>
</li>
<li><p>SHARED MEMORY<br>As the name implies, this IPC mechanism allows one process to share a region of memory in its address space with another. This allows two or more processes to communicate data more efficiently amongst themselves with minimal kernel intervention.</p>
<p>There are two standard specifications for Shared memory.</p>
<ul>
<li><p>SysV Shared memory. Many applications even today use this mechanism for historical reasons. It follows some of the artifacts of SysV IPC semantics.</p>
</li>
<li><p>POSIX Shared memory. The POSIX specifications provide a more elegant approach towards implementing shared memory interface. On Linux, POSIX Shared memory is actually implemented by using files backed by RAM-based filesystem. I recommend using this mechanism over the SysV semantics due to a more elegant file based semantics.</p>
</li>
</ul>
</li>
<li><p>SEMAPHORES<br>Semaphores are locking and synchronization mechanism used most widely when processes share resources. Linux supports both SysV semaphores and POSIX semaphores. POSIX semaphores provide a more simpler and elegant implementation and thus is most widely used when compared to SysV semaphores on Linux.</p>
</li>
<li><p>FUTEXES<br>Futexes are high-performance low-overhead locking mechanisms provided by the kernel. Direct use of futexes is highly discouraged in system programs. Futexes are used internally by POSIX threading API for condition variables and its mutex implementations.</p>
</li>
<li><p>UNIX DOMAIN SOCKETS<br>UNIX Domain Sockets provide a mechanism for implementing applications that communicate using the Client-Server architecture. They support both stream and datagram oriented communication, are full-duplex and support a variety of options. They are very widely used for developing many large-scale frameworks.</p>
</li>
<li><p>NETLINK SOCKETS<br>Netlink sockets are similar to UNIX Domain Sockets in its API semantics - but used mainly for two purposes:</p>
<p>For communication between a process in user-space to a thread in kernel-space<br>For communication amongst processes in user-space using broadcast mode.</p>
</li>
<li><p>NETWORK SOCKETS<br>Based on the same API semantics like UNIX Domain Sockets, Network Sockets API provide mechanisms for communication between processes that run on different hosts on a network. Linux has rich support for features and various protocol stacks for using network sockets API. For all kinds of network programming and distributed programming - network socket APIs form the core interface.</p>
</li>
</ul>
<ul>
<li><p>INOTIFY MECHANISMS<br>The Inotify API on Linux provides a method for processes to know of any changes on a monitored file or a directory asynchronously. By adding a file to inotify watch-list, a process will be notified by the kernel on any changes to the file like open, read, write, changes to file stat, deleting a file and so on.</p>
</li>
<li><p>FUSE SUBSYSTEM<br>FUSE provides a method to implement a fully functional filesystem in user-space. Various operations on the mounted FUSE filesystem would trigger functions registered by the user-space filesystem handler process. This technique can also be used as an IPC mechanism to implement Client-Server architecture without using socket API semantics.</p>
</li>
<li><p>D-BUS SUBSYSTEM<br>D-Bus is a high-level IPC mechanism built generally on top of socket API that provides a mechanism for multiple processes to communicate with each other using various messaging patterns. D-Bus is a standards specification for processes communicating with each other and very widely used today by GUI implementations on Linux following Freedesktop.org specifications.</p>
</li>
</ul>
<h2 id="IPC-Related-Commands"><a href="#IPC-Related-Commands" class="headerlink" title="IPC Related Commands"></a>IPC Related Commands</h2><p>you can use <code>ipcs</code> command to show IPC facilities information: shared memory segments, message queues, and semaphore arrays.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ipcs -l</span><br><span class="line"></span><br><span class="line">------ Shared Memory Limits --------</span><br><span class="line">max number of segments = 4096               // SHMMNI	</span><br><span class="line">max seg size (kbytes) = 32768               // SHMMAX</span><br><span class="line">max total shared memory (kbytes) = 8388608  // SHMALL</span><br><span class="line">min seg size (bytes) = 1</span><br><span class="line"></span><br><span class="line">------ Semaphore Limits --------</span><br><span class="line">max number of arrays = 1024                 // SEMMNI</span><br><span class="line">max semaphores per array = 250              // SEMMSL</span><br><span class="line">max semaphores system wide = 256000         // SEMMNS</span><br><span class="line">max ops per semop call = 32                 // SEMOPM</span><br><span class="line">semaphore max value = 32767</span><br><span class="line"></span><br><span class="line">------ Messages: Limits --------</span><br><span class="line">max queues system wide = 1024               // MSGMNI</span><br><span class="line">max size of message (bytes) = 65536         // MSGMAX</span><br><span class="line">default max size of queue (bytes) = 65536   // MSGMNB</span><br></pre></td></tr></table></figure>
<p>Also, you can use <code>sysctl</code> command to view kernel parameters:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#sysctl -a | grep -i shmmni</span></span><br><span class="line"><span class="string">kernel.shmmni</span> <span class="string">=</span> <span class="number">4096</span></span><br></pre></td></tr></table></figure></p>
<p>or<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment">#sysctl kernel.shmmni</span></span><br><span class="line"><span class="string">kernel.shmmni</span> <span class="string">=</span> <span class="number">4096</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Modify-Kernel-Parameters"><a href="#Modify-Kernel-Parameters" class="headerlink" title="Modify Kernel Parameters"></a>Modify Kernel Parameters</h2><p>From this post <a href="https://www.ibm.com/support/knowledgecenter/en/SSEPGG_11.1.0/com.ibm.db2.luw.qb.server.doc/doc/t0008238.html" target="_blank" rel="noopener">Db2 Modify Kernel Parameters</a>.</p>
<p>Modify the kernel parameters that you have to adjust by editing the <code>/etc/sysctl.conf</code> file. If this file does not exist, create it. The following lines are examples of what must be placed into the file:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">kernel.shmmni=4096</span></span><br><span class="line"><span class="string">kernel.shmmax=17179869184</span></span><br><span class="line"><span class="string">kernel.shmall=8388608</span></span><br><span class="line"><span class="comment">#kernel.sem=&lt;SEMMSL&gt; &lt;SEMMNS&gt; &lt;SEMOPM&gt; &lt;SEMMNI&gt;</span></span><br><span class="line"><span class="string">kernel.sem=4096</span> <span class="number">1024000</span> <span class="number">250</span> <span class="number">4096</span></span><br><span class="line"><span class="string">kernel.msgmni=16384</span></span><br><span class="line"><span class="string">kernel.msgmax=65536</span></span><br><span class="line"><span class="string">kernel.msgmnb=65536</span></span><br></pre></td></tr></table></figure></p>
<p>Reload settings from the default file <code>/etc/sysctl.conf</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl -p</span><br></pre></td></tr></table></figure></p>
<p>For RedHat The rc.sysinit initialization script reads the <code>/etc/sysctl.conf</code> file automatically after every reboot.</p>
<p>You can also make the change not persistently, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl -w kernel.shmmni=4096</span><br><span class="line">sysctl -w kernel.sem=&quot;4096 1024000 250 4096&quot;</span><br></pre></td></tr></table></figure></p>
<p>or directly wirte into <code>procfs</code> files:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;4096 1024000 250 4096&quot; &gt; /proc/sys/kernel/sem</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ipc</tag>
      </tags>
  </entry>
  <entry>
    <title>Prometheus Quick Start</title>
    <url>/2020/05/18/monitor-prometheus/</url>
    <content><![CDATA[<h1 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h1><p>A basic introduction:<br><a href="https://github.com/yolossn/Prometheus-Basics" target="_blank" rel="noopener">https://github.com/yolossn/Prometheus-Basics</a></p>
<p>Architecture<br><img src="https://drive.google.com/uc?id=1WrobLras0BsfiVB_RphmprnA6-6Dm83U" alt=""></p>
<p>To recap:</p>
<ul>
<li>Know how to setup</li>
<li>Know how to configure</li>
<li>Know how to export different kind of metrics</li>
<li>Know how to PromQL</li>
<li>Know how to integrate Grafana</li>
</ul>
<p>Open-source monitoring and alerting toolkit: <a href="https://prometheus.io/" target="_blank" rel="noopener">https://prometheus.io/</a></p>
<ul>
<li>PromQL</li>
<li>Grafana integration</li>
<li>written in Go</li>
</ul>
<p>Type of metrics want to collect, get full view of the health of the system:<br>Runtime metrics</p>
<ul>
<li>memory usage</li>
<li>cpu load</li>
<li>other requests</li>
</ul>
<p>Application metrics, custom statistics<br>Docker metrics: 监控docker自身的状况也很重要</p>
<h2 id="Architecting"><a href="#Architecting" class="headerlink" title="Architecting"></a>Architecting</h2><ol>
<li>Metrics provider (spend more time analyzing app to see which states to be collected)<br>Docker container/server expose metrics API</li>
<li>Metrics server (polling server)<br>Prometheus container reads and store time-series data from metrics API</li>
<li>Metrics visualizer<br>Query and visualize data by Grafana running in another container to build the dashboard, we can add security access(https) of Grafana from outsdie the cluster.</li>
</ol>
<p>On prometheus side, using different configuration to different environment, for example: dev, test, prod have different polling interval seconds.</p>
<h2 id="Collecting-Metrics"><a href="#Collecting-Metrics" class="headerlink" title="Collecting Metrics"></a>Collecting Metrics</h2><p>Prometheus is driven by simple configuration file.</p>
<p>Prometheus image under <code>prom</code> org in Docker Hub:<br><a href="https://hub.docker.com/r/prom/prometheus" target="_blank" rel="noopener">https://hub.docker.com/r/prom/prometheus</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker pull prom/prometheus:v2.18.1</span><br><span class="line"><span class="comment">## --publish-all: publish all ports</span></span><br><span class="line"><span class="comment">## after run check which port is mapping to 9090</span></span><br><span class="line">docker run --detach --name=prom --publish-all prom/prometheus:v2.18.1</span><br></pre></td></tr></table></figure></p>
<p>Then access the interface via<code>&lt;public&gt;:&lt;port&gt;</code>. Per specified in prometheus Docker file, the configure file by default is <code>--config.file=/etc/prometheus/prometheus.yml</code> in container. You can customize as you need, for example, wrap the original image:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">FROM prom/prometheus:v2.18.1</span><br><span class="line"><span class="comment">## copy your config file to default place</span></span><br><span class="line">COPY prometheus.yml /etc/prometheus/prometheus.yml</span><br></pre></td></tr></table></figure></p>
<p>Other userful image in <code>prom</code>:<br><a href="https://hub.docker.com/u/prom" target="_blank" rel="noopener">https://hub.docker.com/u/prom</a><br>Key components for monitoring:</p>
<ul>
<li>node-exporter</li>
<li>alertmanager</li>
<li>pushgateway </li>
</ul>
<h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><p><a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/" target="_blank" rel="noopener">https://prometheus.io/docs/prometheus/latest/configuration/configuration/</a><br>Set other containers as scrape targets, in the prometheus UI, you can check the configuration file from <code>Status</code> -&gt; <code>Configuration</code>, for example:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line"><span class="attr">  scrape_interval:</span> <span class="number">10</span><span class="string">s</span></span><br><span class="line"></span><br><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'netfx-app'</span></span><br><span class="line">    <span class="comment">## metrics point http</span></span><br><span class="line"><span class="attr">    metrics_path:</span> <span class="string">/metrics/</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line">    <span class="comment">## netfx is the container name</span></span><br><span class="line">    <span class="comment">## 50506 is port number</span></span><br><span class="line"><span class="attr">      - targets:</span> <span class="string">['netfx:50506']</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'java-app'</span></span><br><span class="line"><span class="attr">    metrics_path:</span> <span class="string">/app-metrics/</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line"><span class="attr">      - targets:</span> <span class="string">['java:8080']</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'java-tomcat'</span></span><br><span class="line"><span class="attr">    metrics_path:</span> <span class="string">/metrics/</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line"><span class="attr">      - targets:</span> <span class="string">['java:8080']</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">## monitor docker</span></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'docker-managers'</span></span><br><span class="line">    <span class="comment">## override global setting</span></span><br><span class="line"><span class="attr">    scrape_interval:</span> <span class="number">15</span><span class="string">s</span></span><br><span class="line"><span class="attr">    metrics_path:</span> <span class="string">/metrics</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line"><span class="attr">      - targets:</span> <span class="string">['host.docker.internal:50501']</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'docker-workers'</span></span><br><span class="line"><span class="attr">    scrape_interval:</span> <span class="number">15</span><span class="string">s</span></span><br><span class="line"><span class="attr">    metrics_path:</span> <span class="string">/metrics</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line"><span class="attr">      - targets:</span> <span class="string">['host.docker.internal:50501']</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Here the configuration is <code>static_configs</code>, Prometheus supports service discovery so is able to scrape all containers, good for dynamical and self-healing environment.</p>
</blockquote>
<h3 id="Metrics-data-type"><a href="#Metrics-data-type" class="headerlink" title="Metrics data type"></a>Metrics data type</h3><p><a href="https://prometheus.io/docs/concepts/metric_types/" target="_blank" rel="noopener">https://prometheus.io/docs/concepts/metric_types/</a></p>
<ul>
<li>counter (monotonic increasing)</li>
<li>gauge (up and down)</li>
<li>histogram</li>
<li>summary<br>目前就这几种类型的metrics type，prometheus server收集这些数据并且存在数据库中，可以使用promQL去查询。自带的graph UI比较简单，后面会有Grafana去帮忙显示。</li>
</ul>
<h2 id="Exposing-Metrics"><a href="#Exposing-Metrics" class="headerlink" title="Exposing Metrics"></a>Exposing Metrics</h2><p>Let’s see how to export metrics for prometheus to scrape.</p>
<h3 id="Runtime-metrics"><a href="#Runtime-metrics" class="headerlink" title="Runtime metrics"></a>Runtime metrics</h3><p>Runtime (operating system or application host data) has metrics by its own, for example, Tomcat has web server metrics, Java has JVM metrics, we just need to expose them from container as <code>/metrics</code>.</p>
<ul>
<li>Using exporting utility<br>For app which don’t have their own metrics API</li>
<li>Running in app container</li>
<li>Reading runtime metrics</li>
<li>Exporting in prometheus format</li>
</ul>
<p>Exporter的好处是显而易见的，比如legacy app没有metrics的接口，这时候可以使用exporter去处理。如此一来Container hosts both app and exportor，要注意exportor不要占用太多资源。</p>
<p>Exporter integration:<br><a href="https://prometheus.io/docs/instrumenting/exporters/" target="_blank" rel="noopener">https://prometheus.io/docs/instrumenting/exporters/</a></p>
<p>This Dockerfile has integrated Tomcat exporter:<br><a href="https://github.com/nlighten/tomcat_exporter" target="_blank" rel="noopener">https://github.com/nlighten/tomcat_exporter</a><br>Just several extra line added:<br><figure class="highlight dockerfile"><table><tr><td class="code"><pre><span class="line"><span class="comment">## build source code</span></span><br><span class="line"><span class="keyword">FROM</span> maven:<span class="number">3.5</span>.<span class="number">4</span>-jdk-<span class="number">8</span>-slim AS builder</span><br><span class="line"><span class="keyword">WORKDIR</span><span class="bash"> /usr/src/jsfapp </span></span><br><span class="line"><span class="bash">COPY src/java/jsfapp/pom.xml .</span></span><br><span class="line"><span class="bash">RUN mvn -B -f pom.xml -s /usr/share/maven/ref/settings-docker.xml dependency:resolve</span></span><br><span class="line"><span class="bash">COPY src/java/jsfapp .</span></span><br><span class="line"><span class="bash">RUN mvn -B -s /usr/share/maven/ref/settings-docker.xml package -DskipTests</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash"><span class="comment"># app image</span></span></span><br><span class="line"><span class="bash">FROM tomcat:8.5-jre8-alpine</span></span><br><span class="line"><span class="bash">ENV WEBAPP_HOME=<span class="variable">$&#123;CATALINA_HOME&#125;</span>/webapps</span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">RUN rm -r -f <span class="variable">$&#123;WEBAPP_HOME&#125;</span></span></span><br><span class="line"><span class="bash"><span class="comment">#############################</span></span></span><br><span class="line"><span class="bash"><span class="comment">## add exporter utility</span></span></span><br><span class="line"><span class="bash">WORKDIR <span class="variable">$&#123;WEBAPP_HOME&#125;</span></span></span><br><span class="line"><span class="bash"><span class="comment">## copy exporter jar and war files</span></span></span><br><span class="line"><span class="bash">COPY --from=psmonitoring/tomcat-exporter:0.0.6 /exporter/*.jar <span class="variable">$&#123;CATALINA_HOME&#125;</span>/lib/</span></span><br><span class="line"><span class="bash">COPY --from=psmonitoring/tomcat-exporter:0.0.6 /exporter/tomcat_exporter_servlet-0.0.6.war ./metrics.war</span></span><br><span class="line"><span class="bash"><span class="comment">#############################</span></span></span><br><span class="line"><span class="bash"></span></span><br><span class="line"><span class="bash">WORKDIR <span class="variable">$&#123;WEBAPP_HOME&#125;</span>/ROOT </span></span><br><span class="line"><span class="bash"><span class="comment">## copy from builder (see first line)</span></span></span><br><span class="line"><span class="bash">COPY --from=builder /usr/src/jsfapp/target/jsfapp/ .</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Application-metrics"><a href="#Application-metrics" class="headerlink" title="Application metrics"></a>Application metrics</h3><p><a href="https://prometheus.io/docs/instrumenting/clientlibs/" target="_blank" rel="noopener">https://prometheus.io/docs/instrumenting/clientlibs/</a><br>Using prometheus client libraries, 选择匹配你开发语言的库，然后加入依赖调用即可。</p>
<p>Also see best practice:<br><a href="https://prometheus.io/docs/practices/naming/" target="_blank" rel="noopener">https://prometheus.io/docs/practices/naming/</a><br><code>Label</code> is useful, for example, you want to metrics the http response, there are several kinds: 200 OK, 500 Internal Server Error, 401 Unauthroized, 403 Forbidden. Don;t separate them to different metrics, too complicated, just put them as http_response_total with different label, easy to graph and filter. </p>
<p>Some guidelines:</p>
<ul>
<li>Any external interactions with other systems should be instrumented, so you know how often your app is communicating, whether the communication succeeds, and how long it takes. </li>
<li>Any workflows that involve multiple processes should be instrumented at each stage with a correlation ID label, so you can track progress through the system. </li>
<li>Any business facing metrics, which need reporting on, should be instrumented, so you can build a live dashboard rather than sending out historical reports. </li>
<li>Look at all the logging that you currently have in your app. Try to instrument total counts for each type of log entry, info, warn, error and so on. Then you can compare the numbers between environments or between releases.</li>
</ul>
<p>For example, use <code>/app-metrics</code> as endpoint to expose. For example, adding metrics to Java App:</p>
<ol>
<li>maven prometheus client library</li>
<li>create and register custom metrics</li>
<li>increment counters and gauges</li>
<li>servlet hosting metrics endpoint </li>
</ol>
<h3 id="Docker-metrics"><a href="#Docker-metrics" class="headerlink" title="Docker metrics"></a>Docker metrics</h3><p>Experimental mode in docker but safe to use, docker metrics includes:</p>
<ul>
<li>Engine details</li>
<li>Image builds</li>
<li>Containers<br>The metrics endpoint is in standard prometheus text format.</li>
</ul>
<h3 id="Grafana-Integration"><a href="#Grafana-Integration" class="headerlink" title="Grafana Integration"></a>Grafana Integration</h3><p>Grafana image in Docker Hub:<br><a href="https://hub.docker.com/r/grafana/grafana" target="_blank" rel="noopener">https://hub.docker.com/r/grafana/grafana</a></p>
<ul>
<li>Running in container</li>
<li>Connecting to Prometheus</li>
<li>Visualizing query results</li>
<li>Packaging the dashboard</li>
</ul>
<p>Grafana support querying time-series database like <strong>prometheus</strong> and influxdb, also support <strong>Elasticsearch</strong> logging &amp; analytics database.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## pull image</span></span><br><span class="line">docker pull grafana/grafana:7.0.0</span><br><span class="line">docker run --detach --name=grafana --publish-all grafana/grafana:7.0.0</span><br></pre></td></tr></table></figure>
<p>The default login is <code>admin/admin</code>. After login, go to set <code>Data Sources</code>, select prometheus and specify the url, then import data in dashboard.</p>
<p>You can also create new dashboard with different graph, import and query data from data sources.</p>
<p>更深入的话比如如何设置alerting等。</p>
<h1 id="Pair-with-Kubernetes"><a href="#Pair-with-Kubernetes" class="headerlink" title="Pair with Kubernetes"></a>Pair with Kubernetes</h1><p><a href="https://www.youtube.com/watch?v=bErGEHf6GCc&amp;list=PLpbcUe4chE7-HuslXKj1MB10ncorfzEGa" target="_blank" rel="noopener">https://www.youtube.com/watch?v=bErGEHf6GCc&amp;list=PLpbcUe4chE7-HuslXKj1MB10ncorfzEGa</a><br><a href="https://www.youtube.com/watch?v=CmPdyvgmw-A" target="_blank" rel="noopener">https://www.youtube.com/watch?v=CmPdyvgmw-A</a><br><a href="https://www.youtube.com/watch?v=h4Sl21AKiDg" target="_blank" rel="noopener">https://www.youtube.com/watch?v=h4Sl21AKiDg</a></p>
<p><a href="https://www.youtube.com/watch?v=5o37CGlNLr8" target="_blank" rel="noopener">https://www.youtube.com/watch?v=5o37CGlNLr8</a><br><a href="https://www.youtube.com/watch?v=LQpmeb7idt8" target="_blank" rel="noopener">https://www.youtube.com/watch?v=LQpmeb7idt8</a></p>
<p>articles:<br><a href="https://www.metricfire.com/blog/prometheus-vs-elk" target="_blank" rel="noopener">https://www.metricfire.com/blog/prometheus-vs-elk</a><br><a href="https://logz.io/blog/grafana-vs-kibana/" target="_blank" rel="noopener">https://logz.io/blog/grafana-vs-kibana/</a></p>
]]></content>
      <categories>
        <category>Monitor</category>
      </categories>
      <tags>
        <tag>monitor</tag>
        <tag>prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenShift Security Context Constraint</title>
    <url>/2019/06/21/openshift-scc/</url>
    <content><![CDATA[<p>OpenShift version: <code>3.10</code></p>
<p>I have some doubts about <code>Security Context Constraint (SCC)</code> in OpenShift, for example, I give <code>privileged</code> SCC to service account, but some containers are still running as non-root user.</p>
<p>First what is <code>SCC</code> used for: control the actions that a pod can perform and what it has the ability to access, also very useful for managing access to persistent storage.</p>
<h2 id="Prerequisite"><a href="#Prerequisite" class="headerlink" title="Prerequisite"></a>Prerequisite</h2><p>Spin up a fresh OpenShift Enterprise cluster with version:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openshift v3.9.31</span><br><span class="line">kubernetes v1.9.1+a0ce1bc657</span><br></pre></td></tr></table></figure></p>
<p>Create regular user <code>demo1</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">htpasswd -b /etc/origin/master/htpasswd demo1 demo1</span><br></pre></td></tr></table></figure></p>
<p>After login as <code>demo1</code>, you have its records in cluster, if run as <code>system:admin</code> user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc get user</span><br><span class="line">oc get identity</span><br></pre></td></tr></table></figure></p>
<p>You will get demo1 information.</p>
<p>Fetch integrated docker registry address and port from <code>system:admin</code> user:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc get svc -n default | grep -E &quot;^docker-registry&quot;</span><br><span class="line"></span><br><span class="line">docker-registry                     ClusterIP   172.30.159.11    &lt;none&gt;        5000/TCP                  1h</span><br></pre></td></tr></table></figure></p>
<h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p>This experiment will show you:</p>
<ol>
<li>How to enable pulling image from other project.</li>
<li>How to run container as root user.</li>
</ol>
<p>Start with <code>demo1</code>, login by <code>oc login -u demo1</code> and create 2 projects:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc new-project demo1-proj ## this one is for deploying app</span><br><span class="line">oc new-project demo1-ds   ## this one is for storing imagestream</span><br></pre></td></tr></table></figure></p>
<p>Pull <code>busybox</code> and update <code>entrypoint</code> to tail <code>/dev/null</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull busybox</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name mybb \</span><br><span class="line">  --entrypoint=/bin/sh \</span><br><span class="line">  busybox \</span><br><span class="line">  -c &apos;tail -f /dev/null&apos;</span><br></pre></td></tr></table></figure>
<p>Then commit:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker commit &lt;container id&gt; busybox</span><br></pre></td></tr></table></figure></p>
<p>Then docker tag to add docker registry address prefix:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker tag docker.io/busybox 172.30.159.11:5000/demo1-ds/busybox:v1</span><br></pre></td></tr></table></figure></p>
<p>Docker login to integrated docker registry and push:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker login -u openshift -p `oc whoami -t` 172.30.159.11:5000</span><br><span class="line">docker push 172.30.159.11:5000/demo1-ds/busybox:v1</span><br></pre></td></tr></table></figure></p>
<p>Go back to <code>demo1-proj</code> project by <code>oc project demo1-proj</code>, write a simple deployment yaml <code>bb-deploy.yml</code>:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">bb-deployment</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">        image:</span> <span class="number">172.30</span><span class="number">.159</span><span class="number">.11</span><span class="string">:5000/demo1-ds/busybox:v1</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Enable-Pull-from-Other-Projects"><a href="#Enable-Pull-from-Other-Projects" class="headerlink" title="Enable Pull from Other Projects"></a>Enable Pull from Other Projects</h3><p>If now run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc apply -f bb-deploy.yml</span><br></pre></td></tr></table></figure></p>
<p>It will fail to pull the image from <code>demo1-ds</code> (describe pod can see) because we deploy objects on project <code>demo1-proj</code>, it doesn’t have the permission to pull image from other project, let’s enable it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc policy add-role-to-user \</span><br><span class="line">    system:image-puller system:serviceaccount:demo1-proj:default \</span><br><span class="line">    --namespace=demo1-ds</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that if you run this several times, it will create severl duplicate <code>system:image-puller</code>.</p>
</blockquote>
<p>Then if you check <code>rolebindings</code> in <code>demo1-ds</code>, you see there is a new binding <code>system:image-puller</code> with service account <code>demo1-proj/default</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc get rolebindings -n demo1-ds</span><br><span class="line"></span><br><span class="line">NAME                    ROLE                    USERS     GROUPS                            SERVICE ACCOUNTS     SUBJECTS</span><br><span class="line">admin                   /admin                  demo1</span><br><span class="line">system:deployers        /system:deployer                                                    deployer</span><br><span class="line">system:image-builders   /system:image-builder                                               builder</span><br><span class="line">system:image-puller     /system:image-puller                                                demo1-proj/default</span><br><span class="line">system:image-pullers    /system:image-puller              system:serviceaccounts:demo1-ds</span><br></pre></td></tr></table></figure></p>
<p>Ok, then we can deploy the busubox in <code>demo1-proj</code> project:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NAME                            READY     STATUS    RESTARTS   AGE</span><br><span class="line">bb-deployment-78bdb8c4f-lzqfj   1/1       Running   0          6s</span><br></pre></td></tr></table></figure></p>
<p>Let’s next see the container UID:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kbc exec -it bb-deployment-78bdb8c4f-lzqfj sh</span><br><span class="line"></span><br><span class="line">/ $ id</span><br><span class="line">uid=1000130000 gid=0(root) groups=1000130000</span><br></pre></td></tr></table></figure></p>
<h3 id="Set-Security-Context-Constraint"><a href="#Set-Security-Context-Constraint" class="headerlink" title="Set Security Context Constraint"></a>Set Security Context Constraint</h3><p>Correct, OpenShift by default doesn’t spin up container run as root user due to security issue. Acutally this is about <code>SCC</code>, let’s dig deeper:</p>
<p>These 2 articles cover lots of things for SCC and service account:<br><a href="https://docs.openshift.com/container-platform/3.9/admin_guide/manage_scc.html#enable-images-to-run-with-user-in-the-dockerfile" target="_blank" rel="noopener">Managing Security Context Constraints</a><br><a href="https://docs.openshift.com/container-platform/3.9/architecture/additional_concepts/authorization.html#security-context-constraints" target="_blank" rel="noopener">Security Context Constraints official</a><br><a href="https://docs.openshift.com/container-platform/3.9/admin_guide/service_accounts.html" target="_blank" rel="noopener">Configuring Service Accounts</a></p>
<p>you must have <code>cluster-admin</code> privilege to manage SCCs (you can grant <code>cluster-admin</code> privilege to regular user), there are 7 SCCs:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc get scc</span><br><span class="line"></span><br><span class="line">NAME               PRIV      CAPS      SELINUX     RUNASUSER          FSGROUP     SUPGROUP    PRIORITY   READONLYROOTFS   VOLUMES</span><br><span class="line">anyuid             false     []        MustRunAs   RunAsAny           RunAsAny    RunAsAny    10         false            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">hostaccess         false     []        MustRunAs   MustRunAsRange     MustRunAs   RunAsAny    &lt;none&gt;     false            [configMap downwardAPI emptyDir hostPath persistentVolumeClaim projected secret]</span><br><span class="line">hostmount-anyuid   false     []        MustRunAs   RunAsAny           RunAsAny    RunAsAny    &lt;none&gt;     false            [configMap downwardAPI emptyDir hostPath nfs persistentVolumeClaim projected secret]</span><br><span class="line">hostnetwork        false     []        MustRunAs   MustRunAsRange     MustRunAs   MustRunAs   &lt;none&gt;     false            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">nonroot            false     []        MustRunAs   MustRunAsNonRoot   RunAsAny    RunAsAny    &lt;none&gt;     false            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br><span class="line">privileged         true      [*]       RunAsAny    RunAsAny           RunAsAny    RunAsAny    &lt;none&gt;     false            [*]</span><br><span class="line">restricted         false     []        MustRunAs   MustRunAsRange     MustRunAs   RunAsAny    &lt;none&gt;     false            [configMap downwardAPI emptyDir persistentVolumeClaim projected secret]</span><br></pre></td></tr></table></figure></p>
<p>By default, when a container or pod does not request a user ID under which it should be run, the effective UID depends on the SCC that emits this pod. Because <code>restricted</code> SCC is granted to all authenticated users by default, it will be available to all users and service accounts and used in most cases.<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">oc</span> <span class="string">describe</span> <span class="string">scc</span> <span class="string">restricted</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Name:</span>                                           <span class="string">restricted</span></span><br><span class="line"><span class="attr">Priority:</span>                                       <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Access:</span></span><br><span class="line"><span class="attr">  Users:</span>                                        <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">  Groups:</span>                                       <span class="attr">system:authenticated</span></span><br><span class="line"><span class="attr">Settings:</span></span><br><span class="line">  <span class="string">Allow</span> <span class="attr">Privileged:</span>                             <span class="literal">false</span></span><br><span class="line">  <span class="string">Default</span> <span class="string">Add</span> <span class="attr">Capabilities:</span>                     <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">Required</span> <span class="string">Drop</span> <span class="attr">Capabilities:</span>                   <span class="string">KILL,MKNOD,SETUID,SETGID</span></span><br><span class="line">  <span class="string">Allowed</span> <span class="attr">Capabilities:</span>                         <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">Allowed</span> <span class="string">Seccomp</span> <span class="attr">Profiles:</span>                     <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">Allowed</span> <span class="string">Volume</span> <span class="attr">Types:</span>                         <span class="string">configMap,downwardAPI,emptyDir,persistentVolumeClaim,projected,secret</span></span><br><span class="line">  <span class="string">Allowed</span> <span class="attr">Flexvolumes:</span>                          <span class="string">&lt;all&gt;</span></span><br><span class="line">  <span class="string">Allow</span> <span class="string">Host</span> <span class="attr">Network:</span>                           <span class="literal">false</span></span><br><span class="line">  <span class="string">Allow</span> <span class="string">Host</span> <span class="attr">Ports:</span>                             <span class="literal">false</span></span><br><span class="line">  <span class="string">Allow</span> <span class="string">Host</span> <span class="attr">PID:</span>                               <span class="literal">false</span></span><br><span class="line">  <span class="string">Allow</span> <span class="string">Host</span> <span class="attr">IPC:</span>                               <span class="literal">false</span></span><br><span class="line">  <span class="string">Read</span> <span class="string">Only</span> <span class="string">Root</span> <span class="attr">Filesystem:</span>                    <span class="literal">false</span></span><br><span class="line">  <span class="string">Run</span> <span class="string">As</span> <span class="string">User</span> <span class="attr">Strategy:</span> <span class="string">MustRunAsRange</span></span><br><span class="line"><span class="attr">    UID:</span>                                        <span class="string">&lt;none&gt;</span></span><br><span class="line">    <span class="string">UID</span> <span class="string">Range</span> <span class="attr">Min:</span>                              <span class="string">&lt;none&gt;</span></span><br><span class="line">    <span class="string">UID</span> <span class="string">Range</span> <span class="attr">Max:</span>                              <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">SELinux</span> <span class="string">Context</span> <span class="attr">Strategy:</span> <span class="string">MustRunAs</span></span><br><span class="line"><span class="attr">    User:</span>                                       <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">    Role:</span>                                       <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">    Type:</span>                                       <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">    Level:</span>                                      <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">FSGroup</span> <span class="attr">Strategy:</span> <span class="string">MustRunAs</span></span><br><span class="line"><span class="attr">    Ranges:</span>                                     <span class="string">&lt;none&gt;</span></span><br><span class="line">  <span class="string">Supplemental</span> <span class="string">Groups</span> <span class="attr">Strategy:</span> <span class="string">RunAsAny</span></span><br><span class="line"><span class="attr">    Ranges:</span>                                     <span class="string">&lt;none&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>The <code>restricted</code> SCC uses <code>MustRunAsRange</code> strategy for constraining and defaulting the possible values of the securityContext.runAsUser field. The admission plug-in will look for the <code>openshift.io/sa.scc.uid-range</code> annotation on the current project to populate range fields, as it does not provide this range. In the end, a container will have runAsUser equal to the first value of the range that is hard to predict because every project has different ranges. </p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">oc</span> <span class="string">describe</span> <span class="string">project</span> <span class="string">demo1-proj</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Name:</span>                   <span class="string">demo1-proj</span></span><br><span class="line"><span class="attr">Created:</span>                <span class="number">3</span> <span class="string">hours</span> <span class="string">ago</span></span><br><span class="line"><span class="attr">Labels:</span>                 <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Annotations:</span>            <span class="string">openshift.io/description=</span></span><br><span class="line">                        <span class="string">openshift.io/display-name=</span></span><br><span class="line">                        <span class="string">openshift.io/requester=demo1</span></span><br><span class="line">                        <span class="string">openshift.io/sa.scc.mcs=s0:c11,c10</span></span><br><span class="line">                        <span class="string">openshift.io/sa.scc.supplemental-groups=1000130000/10000</span></span><br><span class="line">                        <span class="string">openshift.io/sa.scc.uid-range=1000130000/10000</span></span><br><span class="line"><span class="string">Display</span> <span class="attr">Name:</span>           <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Description:</span>            <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Status:</span>                 <span class="string">Active</span></span><br><span class="line"><span class="string">Node</span> <span class="attr">Selector:</span>          <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Quota:</span>                  <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="string">Resource</span> <span class="attr">limits:</span>        <span class="string">&lt;none&gt;</span></span><br></pre></td></tr></table></figure>
<p>You see, here <code>openshift.io/sa.scc.uid-range</code> start from <code>1000130000</code>, is the UID of our <code>busybox</code> container.</p>
<p>SCCs are not granted directly to a project. Instead, you add a service account to an SCC and either specify the service account name on your pod or, when unspecified, run as the <code>default</code> service account.</p>
<h4 id="Add-and-Remove-SCC"><a href="#Add-and-Remove-SCC" class="headerlink" title="Add and Remove SCC"></a>Add and Remove SCC</h4><p>Add service account <code>default</code> in project <code>demo1-proj</code> to SCC <code>privileged</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc adm policy add-scc-to-user privileged system:serviceaccount:demo1-proj:default</span><br><span class="line"></span><br><span class="line">scc &quot;privileged&quot; added to: [&quot;system:serviceaccount:demo1-proj:default&quot;]</span><br></pre></td></tr></table></figure></p>
<p>Where to examine the result:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">oc</span> <span class="string">describe</span> <span class="string">scc</span> <span class="string">privileged</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Name:</span>                                           <span class="string">privileged</span></span><br><span class="line"><span class="attr">Priority:</span>                                       <span class="string">&lt;none&gt;</span></span><br><span class="line"><span class="attr">Access:</span></span><br><span class="line"><span class="attr">  Users:</span>                                        <span class="attr">system:admin,system:serviceaccount:openshift-infra:build-controller,system:serviceaccount:management-infra:management-admin,system:serviceaccount:management-infra:inspector-admin,system:serviceaccount:glusterfs:default,system:serviceaccount:glusterfs:router,system:serviceaccount:glusterfs:heketi-storage-service-account,system:serviceaccount:demo1-proj:default</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></p>
<p>In the <code>Users</code> field, we now have <code>system:serviceaccount:demo1-proj:default</code>.</p>
<p>How to remove the SCC from a service account?<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc adm policy remove-scc-from-user privileged system:serviceaccount:demo1-proj:default</span><br><span class="line"></span><br><span class="line">scc &quot;privileged&quot; removed from: [&quot;system:serviceaccount:demo1-proj:default&quot;]</span><br></pre></td></tr></table></figure></p>
<h3 id="Deploy-Again"><a href="#Deploy-Again" class="headerlink" title="Deploy Again"></a>Deploy Again</h3><p>Then login as <code>demo1</code>, go to <code>demo1-proj</code>, deploy again:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc apply -f bb-deploy.yml</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc exec -it bb-deployment-78bdb8c4f-rgj88 sh</span><br><span class="line"></span><br><span class="line">/ $ id</span><br><span class="line">uid=1000130000 gid=0(root) groups=1000130000</span><br></pre></td></tr></table></figure>
<p>Why the UID is still <code>1000130000</code>? We have applied <code>privileged</code> right?<br>Because <code>privileged</code> is just a constraint, you need to <strong>Ensure</strong> that at least one of the pod’s containers is requesting a privileged mode in the security context.</p>
<p>So update the yaml file, add <code>securityContext</code>, and deploy again:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">bb-deployment</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">bb</span></span><br><span class="line"><span class="attr">        image:</span> <span class="number">172.30</span><span class="number">.159</span><span class="number">.11</span><span class="string">:5000/demo1-ds/busybox:v1</span></span><br><span class="line"><span class="attr">      securityContext:</span></span><br><span class="line"><span class="attr">        runAsUser:</span> <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>Now if you check the UID, it’s <code>0</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">oc rsh bb-deployment-58cb44b56b-zmdcw</span><br><span class="line"></span><br><span class="line">/ # id</span><br><span class="line">uid=0(root) gid=0(root) groups=10(wheel)</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>oc rsh</code> is the same as <code>kubectl exec -it ... sh</code></p>
</blockquote>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Add <code>privileged</code> SCC to service account is not enough, need to specify <code>runAsUser: 0</code> in yaml file.</p>
]]></content>
      <categories>
        <category>OpenShift</category>
      </categories>
      <tags>
        <tag>openshift</tag>
        <tag>scc</tag>
      </tags>
  </entry>
  <entry>
    <title>Common Code Snippets</title>
    <url>/2019/02/24/shell-common-code/</url>
    <content><![CDATA[<p>This blog collects the commonly used code snippets based on my daily work, also do summary from related <em>stackoverflow</em> topics.</p>
<h2 id="set-builtin"><a href="#set-builtin" class="headerlink" title="set builtin"></a>set builtin</h2><p>Usually I use <code>set -x</code> for debugging purpose, today I see a new statement <code>set -ex</code>. What is this and what is set in Bash? </p>
<p><a href="https://www.gnu.org/software/bash//manual/html_node/The-Set-Builtin.html" target="_blank" rel="noopener">The Set Builtin</a>, in short, <code>set</code> allows you to change the values of shell options and set the positional parameters, or to display the names and values of shell variables.</p>
<p><code>set -e</code>, causes the shell to exit if any subcommand or pipeline returns a non-zero status. This tells bash that it should exit the script if any statement returns a non-true return value. The benefit of using <code>-e</code> is that it prevents errors snowballing into serious issues when they could have been caught earlier. </p>
<p>But sometimes <code>set -e</code> may not be good, see these two posts:<br><a href="https://serverfault.com/questions/143445/what-does-set-e-do-and-why-might-it-be-considered-dangerous" target="_blank" rel="noopener">What does ‘set -e’ do, and why might it be considered dangerous?</a><br><a href="https://www.cnblogs.com/YatHo/p/7682344.html" target="_blank" rel="noopener">“set -e” usage</a></p>
<h2 id="get-path-of-running-script"><a href="#get-path-of-running-script" class="headerlink" title="get path of running script"></a>get path of running script</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curpath=$(dirname $(readlink -f $0))</span><br></pre></td></tr></table></figure>
<p><code>readlink -f $0</code> will follow every symlink in every component of the given name recursively and get the <code>canonical</code> path. For example <code>/tmp/script.sh</code>. A single file existing on a system can have <strong>many</strong> different paths that refer to it, but only one <code>canonical</code> path, <code>canonical</code> gives a unique <strong>absolute</strong> path for a given file. That means even though you call a script in it’s current directory, <code>readlink -f $0</code> will give you the absolute path!.</p>
<p><code>dirname $0</code> cut the script name to get the calling path, for example <code>/tmp</code></p>
<h2 id="run-script-in-it’s-driectory"><a href="#run-script-in-it’s-driectory" class="headerlink" title="run script in it’s driectory"></a>run script in it’s driectory</h2><p>Sometimes we want to run script in it’s folder by <code>./xxx.sh</code>. we can check that:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SCRIPT_PATH=$(dirname <span class="variable">$0</span>)</span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">"X"</span><span class="string">"<span class="variable">$&#123;SCRIPT_PATH&#125;</span>"</span> != <span class="string">"X."</span> ]]; <span class="keyword">then</span></span><br><span class="line">  LogMsg <span class="string">"###### ERROR: Please run this script in it's directory!"</span></span><br><span class="line">  <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<h2 id="create-tmp-file-to-store-log"><a href="#create-tmp-file-to-store-log" class="headerlink" title="create tmp file to store log"></a>create tmp file to store log</h2><p>create a temporary file or directory<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">OUT_FILE=$(mktemp /tmp/dfd-replication-db.XXXX)</span><br></pre></td></tr></table></figure></p>
<p>it will randomly substitute <code>XXXX</code>. You may need to delete the tmp file when script finish, for example, use hook and signal trap<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">function</span> exitHook &#123;</span><br><span class="line">  rm -f <span class="variable">$OUT_FILE</span></span><br><span class="line">  rm -f <span class="variable">$&#123;OUT_FILE&#125;</span>.yml</span><br><span class="line">  rm -f <span class="variable">$&#123;OUT_FILE&#125;</span>.out</span><br><span class="line">  rm -f <span class="variable">$&#123;OUT_FILE&#125;</span>.err</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">trap</span> exitHook EXIT</span><br></pre></td></tr></table></figure></p>
<p>Actually, you can get random number from<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo $RANDOM</span><br></pre></td></tr></table></figure></p>
<p>you can also seed it to generate reproducible sequence:<br><a href="https://stackoverflow.com/questions/42004870/seed-for-random-environment-variable-in-bash" target="_blank" rel="noopener">https://stackoverflow.com/questions/42004870/seed-for-random-environment-variable-in-bash</a></p>
<h2 id="if-condition"><a href="#if-condition" class="headerlink" title="if condition"></a>if condition</h2><p>List of <a href="http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html" target="_blank" rel="noopener">bash condition statements</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># sth does not exist?</span></span><br><span class="line"><span class="keyword">if</span> [[ <span class="string">"<span class="variable">$&#123;sth&#125;</span>"</span><span class="string">"X"</span> == <span class="string">"X"</span> ]]; <span class="keyword">then</span></span><br><span class="line">  LogMsg <span class="string">"###### INFO: ..."</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<p>or<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># True if the length of "STRING" is non-zero.</span></span><br><span class="line"><span class="keyword">if</span> [[ -z <span class="string">"<span class="variable">$&#123;sth&#125;</span>"</span> ]]; <span class="keyword">then</span></span><br><span class="line">  LogMsg <span class="string">"###### INFO: ..."</span></span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># directory does not exist?</span></span><br><span class="line"><span class="keyword">if</span> [[ ! -d <span class="string">"<span class="variable">$&#123;folder_path&#125;</span>"</span> ]]; <span class="keyword">then</span></span><br><span class="line">   LogMsg <span class="string">"###### ERROR: <span class="variable">$&#123;folder_path&#125;</span> directory doesn't exist!"</span></span><br><span class="line">   <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<p>Acutally the key is the test command <code>[]</code> or <code>[[ ]]</code>.</p>
<h2 id="select-loop"><a href="#select-loop" class="headerlink" title="select loop"></a>select loop</h2><p>The select loop provides an easy way to create a numbered menu from which users can select options. It is useful when you need to ask the user to choose one or more items from a list of choices.</p>
<blockquote>
<p>Note that this loop was introduced in ksh and has been adapted into bash. It is not available in sh.</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">PS3=<span class="string">"Enter your choice (must be a number): "</span></span><br><span class="line">select DRINK <span class="keyword">in</span> tea cofee water juice appe all none</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">   <span class="keyword">case</span> <span class="variable">$DRINK</span> <span class="keyword">in</span></span><br><span class="line">      tea | cofee | water | all) </span><br><span class="line">         <span class="built_in">echo</span> <span class="string">"Go to canteen"</span></span><br><span class="line">         <span class="built_in">break</span></span><br><span class="line">         ;;</span><br><span class="line">      juice|appe)</span><br><span class="line">         <span class="built_in">echo</span> <span class="string">"Available at home"</span></span><br><span class="line">         <span class="built_in">break</span></span><br><span class="line">      ;;</span><br><span class="line">      none) </span><br><span class="line">         <span class="built_in">break</span> </span><br><span class="line">      ;;</span><br><span class="line">      *) </span><br><span class="line">         <span class="built_in">echo</span> <span class="string">"ERROR: Invalid selection"</span> </span><br><span class="line">      ;;</span><br><span class="line">   <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>When select you can use index number or literal, if no <code>break</code>, it will loop forever.<br><code>PS3</code> is used to show the prompt for input.</p>
<h2 id="input-password-and-confirm"><a href="#input-password-and-confirm" class="headerlink" title="input password and confirm"></a>input password and confirm</h2><p>Must not show password user input:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"****************************************************************"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Please input the password:"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"****************************************************************"</span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span>; <span class="keyword">do</span></span><br><span class="line">  <span class="built_in">read</span> -s -p <span class="string">"PASSWORD: "</span> PASSWORD</span><br><span class="line">  <span class="built_in">echo</span></span><br><span class="line">  <span class="built_in">read</span> -s -p <span class="string">"CONFIRM:  "</span> PASSWORD_CONFIRM</span><br><span class="line">  <span class="built_in">echo</span></span><br><span class="line">  [ <span class="variable">$&#123;#PASSWORD&#125;</span> -lt 6 ] &amp;&amp; <span class="built_in">echo</span> <span class="string">"The length of password at least 6, please try again"</span> &amp;&amp; <span class="built_in">continue</span></span><br><span class="line">  [ <span class="string">"<span class="variable">$&#123;PASSWORD&#125;</span>"</span> = <span class="string">"<span class="variable">$&#123;PASSWORD_CONFIRM&#125;</span>"</span> ] &amp;&amp; <span class="built_in">break</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"Passwords do not match please try again..."</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<h2 id="script-input-parameters"><a href="#script-input-parameters" class="headerlink" title="script input parameters"></a>script input parameters</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> [ <span class="variable">$#</span> -eq 0 ]</span><br><span class="line"><span class="keyword">then</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"No command-line arguments were specified..."</span></span><br><span class="line">  <span class="comment"># Usage</span></span><br><span class="line">  <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> [ <span class="variable">$#</span> -gt 0 ]</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">    -p1)</span><br><span class="line">       <span class="built_in">shift</span></span><br><span class="line">       P1=<span class="variable">$&#123;1&#125;</span></span><br><span class="line">       <span class="built_in">shift</span>;;</span><br><span class="line"></span><br><span class="line">    -p2)</span><br><span class="line">       <span class="built_in">shift</span></span><br><span class="line">       P2=<span class="variable">$&#123;1&#125;</span></span><br><span class="line">       <span class="built_in">shift</span>;;</span><br><span class="line"></span><br><span class="line">    *) <span class="comment"># Usage</span></span><br><span class="line">       <span class="built_in">exit</span> 1;;</span><br><span class="line">  <span class="keyword">esac</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">[[ <span class="string">"X<span class="variable">$P1</span>"</span> = <span class="string">"X"</span> ]] &amp;&amp;  <span class="built_in">exit</span> 1</span><br><span class="line">[[ <span class="string">"X<span class="variable">$P2</span>"</span> = <span class="string">"X"</span> ]] &amp;&amp;  <span class="built_in">exit</span> 1</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note there are 2 shift in one case, after each <code>shift</code>, <code>$#</code> minus 1.</p>
</blockquote>
<h2 id="bash-function-inputs"><a href="#bash-function-inputs" class="headerlink" title="bash function inputs"></a>bash function inputs</h2><p>The function refers to passed arguments by their position (not by name), that is <code>$1</code>, <code>$2</code>, and so forth. <code>$0</code> is the name of the script itself.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">example()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"args #0 is <span class="variable">$0</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"args #1 is <span class="variable">$1</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"args #s is <span class="variable">$2</span>"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Need to call your function after it is declared.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">example <span class="string">"p1"</span> <span class="string">"p2"</span></span><br><span class="line"></span><br><span class="line">args <span class="comment">#0 is &lt;absolute path to script itself&gt;</span></span><br><span class="line">args <span class="comment">#1 is p1</span></span><br><span class="line">args <span class="comment">#2 is p2</span></span><br></pre></td></tr></table></figure></p>
<h2 id="log-message"><a href="#log-message" class="headerlink" title="log message"></a>log message</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">LogMsg()</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment"># parse input and reformat</span></span><br><span class="line">  logMsg=<span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"["</span>`date +<span class="string">"%Y/%m/%d %r"</span>`<span class="string">"] "</span> <span class="variable">$&#123;logMsg&#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">LogMsg <span class="string">"[INFO] ..."</span></span><br><span class="line">LogMsg <span class="string">"[WARNING] ..."</span></span><br><span class="line">LogMsg <span class="string">"[ERROR]..."</span></span><br></pre></td></tr></table></figure>
<p>Actually, this style <code>[INFO] [2019-10-11 15:59:26-0081] ...</code> it better.</p>
<h2 id="check-last-command-result"><a href="#check-last-command-result" class="headerlink" title="check last command result"></a>check last command result</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="title">echo_success_failure</span></span>() &#123;</span><br><span class="line">  <span class="keyword">if</span> [ $? -eq 0 ]; <span class="keyword">then</span> </span><br><span class="line">    LogMsg <span class="string">"###### INFO: Success..."</span></span><br><span class="line">  <span class="keyword">else</span> </span><br><span class="line">    LogMsg <span class="string">"###### INFO: Failure..."</span></span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="run-as-root"><a href="#run-as-root" class="headerlink" title="run as root"></a>run as root</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">effective_uid=`id -u` 2&gt;/dev/null</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$effective_uid</span> -ne 0 ]; <span class="keyword">then</span></span><br><span class="line"> LogMsg <span class="string">"###### ERROR: Please run this script as root or sudo"</span>  </span><br><span class="line"> <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>
<h2 id="delimited-string-to-array"><a href="#delimited-string-to-array" class="headerlink" title="delimited string to array"></a>delimited string to array</h2><p>Convert delimited string to array, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">string=<span class="string">"item1 item2 item3"</span></span><br><span class="line">IFS=<span class="string">' '</span> <span class="built_in">read</span> -a array &lt;&lt;&lt; <span class="string">"<span class="variable">$&#123;string&#125;</span>"</span></span><br></pre></td></tr></table></figure></p>
<p>This version has no globbing problem, the split character is set in <code>$IFS</code> (here is space), variables quoted. Don’t forget to do sanity check after converting.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$&#123;array[0]&#125;</span>  ===&gt; item1</span><br><span class="line"><span class="variable">$&#123;array[1]&#125;</span>  ===&gt; item2</span><br><span class="line"><span class="variable">$&#123;array[2]&#125;</span>  ===&gt; item3</span><br></pre></td></tr></table></figure></p>
<p>Actually if the string use spaces as delimiter, we can loop items directly:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">string=<span class="string">"item1 item2 item3"</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;string&#125;</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$&#123;i&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<h2 id="loop-array"><a href="#loop-array" class="headerlink" title="loop array"></a>loop array</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">declare</span> -a array=(<span class="string">"element1"</span> <span class="string">"element2"</span> <span class="string">"element3"</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="string">"<span class="variable">$&#123;array[@]&#125;</span>"</span></span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">   <span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;i&#125;</span>"</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p><code>declare</code> or <code>typeset</code> are an explicit way of declaring variable in shell scripts.</p>
<p>In BASH it is safer to quote the variable using <code>&quot;&quot;</code> for the cases when <code>$i</code> may contain white spaces or shell expandable characters.</p>
<p>If you want to use index of array element<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># get length of an array</span></span><br><span class="line">arraylength=<span class="variable">$&#123;#array[@]&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># use for loop to read all values and indexes</span></span><br><span class="line"><span class="keyword">for</span> (( i=0; i&lt;<span class="variable">$&#123;arraylength&#125;</span>; i++ ));</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="variable">$i</span> <span class="string">" / "</span> <span class="variable">$&#123;arraylength&#125;</span> <span class="string">" : "</span> <span class="variable">$&#123;array[$i]&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure></p>
<h2 id="chmod"><a href="#chmod" class="headerlink" title="chmod"></a>chmod</h2><p><code>chmod</code> recursively for directory and it’s content<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod -R 0755 &lt;target directory&gt;</span><br></pre></td></tr></table></figure></p>
<p>Or only add executable for file<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find . -name <span class="string">'&lt;file name&gt;'</span> -<span class="built_in">type</span> f | xargs chmod +x</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">-rwxr-xr-x ...</span><br></pre></td></tr></table></figure>
<h2 id="pass-parameters-to-script"><a href="#pass-parameters-to-script" class="headerlink" title="pass parameters to script"></a>pass parameters to script</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># invoke, must stick to this format</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"admin</span></span><br><span class="line"><span class="string">admin"</span> | ./script.sh</span><br><span class="line"><span class="comment"># receive code snippet in script.sh</span></span><br><span class="line">MsgLog <span class="string">"###### Please enter args1  ..."</span></span><br><span class="line"><span class="built_in">read</span> args1</span><br><span class="line">LogMsg <span class="string">"###### Please enter password ..."</span></span><br><span class="line"><span class="built_in">read</span> -s password</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="variable">$&#123;args1&#125;</span>     ===&gt; admin</span><br><span class="line"><span class="variable">$&#123;password&#125;</span>  ===&gt; admin</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: <code>read</code> <code>-s</code> flag: do not echo input coming from a terminal, used for password</p>
</blockquote>
<h2 id="setup-ssh-password-less"><a href="#setup-ssh-password-less" class="headerlink" title="setup ssh password-less"></a>setup ssh password-less</h2><p>Idempotence：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh-keyscan -H <span class="variable">$&#123;remote&#125;</span> &gt;&gt; ~/.ssh/known_hosts</span><br><span class="line">sshpass -p <span class="string">"&lt;password&gt;"</span> ssh-copy-id -i ~/.ssh/id_rsa.pub root@<span class="variable">$&#123;remote&#125;</span></span><br><span class="line"><span class="keyword">if</span> [[ $? -ne 0 ]]; <span class="keyword">then</span></span><br><span class="line">  LogMsg <span class="string">"######ERROR: Something went wrong with ssh-copy-id. Check for incorrect credentials ... "</span></span><br><span class="line">  <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure></p>
<h2 id="recursive-call"><a href="#recursive-call" class="headerlink" title="recursive call"></a>recursive call</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">example()</span><br><span class="line">&#123;</span><br><span class="line">  &lt;execute sth&gt;</span><br><span class="line">  <span class="keyword">if</span> [[ $? -ne 0 ]]; <span class="keyword">then</span></span><br><span class="line">       LogMsg <span class="string">"######ERROR: Something went wrong… "</span></span><br><span class="line">       example</span><br><span class="line">  <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="tee-command"><a href="#tee-command" class="headerlink" title="tee command"></a>tee command</h2><p><code>tee</code> command reads the standard input and writes it to both the standard output and one or more files, <code>-a</code> flag used to append output to existing file, if no <code>-a</code>, tee will create the file if not exist.<br>  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">LogMsg()</span><br><span class="line">&#123;</span><br><span class="line">  logMsg=<span class="string">"<span class="variable">$@</span>"</span></span><br><span class="line">  <span class="built_in">echo</span> <span class="string">"["</span>`date +<span class="string">"%Y/%m/%d %r"</span>`<span class="string">"]"</span> <span class="variable">$&#123;logMsg&#125;</span> | tee -a logs/ds_<span class="variable">$&#123;stage&#125;</span>_<span class="variable">$&#123;timeStamp&#125;</span>.<span class="built_in">log</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------------+     +-------+    +--------------+</span><br><span class="line">|  command    |     | tee   |    |   stdout     |</span><br><span class="line">|   output    +----&gt;+       +---&gt;+              |</span><br><span class="line">+-------------+     +---+---+    +--------------+</span><br><span class="line">                        |</span><br><span class="line">                    +---v---+</span><br><span class="line">                    |  file |</span><br><span class="line">                    |       |</span><br><span class="line">                    +-------+</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>SSL Demystify</title>
    <url>/2019/11/29/ssl-demystify/</url>
    <content><![CDATA[<p>This is all about securing servers with <code>SSL/TLS certificates</code> from udemy course <em>SSL complete guide</em>.</p>
<p><a href="https://www.ssllabs.com/index.html" target="_blank" rel="noopener">https://www.ssllabs.com/index.html</a>:<br>The quality of SSL varies, you have SSL setup doesn’t mean your site is good secured. The HTTPS may not work correctly, sub-optimal.</p>
<p>If you click the <code>lock</code> icon at left of the website address, it will show you if the connection is secured or not, it’s certificates, cookies and so on. further click the certificate icon, you will see <code>root CA</code>, <code>intermediate CA</code> and <code>certificate</code>.</p>
<blockquote>
<p>Install wireshark on Mac, go to download the <code>stable</code> version dmg package and double click to install.</p>
</blockquote>
<blockquote>
<p>You can use chrome inspect -&gt; Network to see traffic details or use wireshark</p>
</blockquote>
<p>for example, from <code>Network</code> section, check HEADER information you can get IP address of source website, or just use <code>host</code>, <code>nslookup</code> commands to get IP address.</p>
<blockquote>
<p>Interesting, from <code>Network</code> I see the the chrome browser actually uses IPV6 address talk to server, for example facebook and some other sites. see this <a href="https://superuser.com/questions/1199129/how-web-browser-determines-when-to-use-ipv4-or-ipv6-to-connect-to-the-destinatio" target="_blank" rel="noopener">question</a></p>
</blockquote>
<h1 id="Encryption"><a href="#Encryption" class="headerlink" title="Encryption"></a>Encryption</h1><ul>
<li><p>symmetric encryption, the same key is used by both sides, for example: <code>AES</code>. This algorithm is embedded in SSL with HTTPS protocol.</p>
</li>
<li><p>asymmetric encryption, for example: <code>RSA</code>.</p>
</li>
</ul>
<h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><p>How does hash work to verify data integrity:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data + hash(data)  ---------&gt; data + hash(data)</span><br><span class="line">                                |         |</span><br><span class="line">                                |--hash--&gt;| (compare if they are the same)</span><br></pre></td></tr></table></figure></p>
<p>Notice that in database the password is hashed, not plain text.</p>
<p>Hash algorithms: <code>MD5</code>, <code>SHA</code>…</p>
<ul>
<li>MD5: 128 bits, <code>echo 123 | md5</code></li>
</ul>
<p>for <code>SHA</code>, use <code>shasum</code> command in linux or use inline tool.</p>
<ul>
<li>SHA-1: 160 bits</li>
<li>SHA-256: 256 bits</li>
<li><p>SHA-512: 512 bits</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">shasum -a 256 -t test.txt</span><br></pre></td></tr></table></figure>
</li>
<li><p>HMAC: can be used with md5 or sha. In cryptography, an HMAC (sometimes expanded as either keyed-hash message authentication code or hash-based message authentication code) is a specific type of message authentication code (MAC) involving a cryptographic hash function and a secret cryptographic <code>key</code>. It may be used to simultaneously verify <code>both</code> the data integrity and the authenticity of a message, as with any MAC. Any cryptographic hash function, such as SHA-256 or SHA-3, may be used in the calculation of an HMAC.</p>
</li>
</ul>
<h2 id="Asymmetric-Keys"><a href="#Asymmetric-Keys" class="headerlink" title="Asymmetric Keys"></a>Asymmetric Keys</h2><ul>
<li>encryption<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">data -------------&gt; code =========&gt;  code -------------&gt; data  (owner side)</span><br><span class="line">      public key                          private key</span><br><span class="line">      encryption                          decryption</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Usually(but not necessarily), the keys are <code>interchangeable</code>, in the sense that if key A encrypts a message, then B can decrypt it, and if key B encrypts a message, then key A can decrypt it. While common, this property is not essential to asymmetric encryption.</p>
<ul>
<li>signing<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">           data                          |----------&gt; hash value</span><br><span class="line">            | (hash)     ==========&gt;     |  compare       |</span><br><span class="line">            |                            |                |</span><br><span class="line">        private key encrypt              |           public key decrypte</span><br><span class="line">            |                            | (hash)         |</span><br><span class="line">data   +   encrypted hash              data    +   encrypted hash</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>Signing ensures the data is sent by the <code>owner of private key</code> and not has been modified inbetween.</p>
<p>What is the difference of digest and signature?<br><a href="https://www.ibm.com/support/knowledgecenter/en/SSFKSJ_7.1.0/com.ibm.mq.doc/sy10510_.htm" target="_blank" rel="noopener">https://www.ibm.com/support/knowledgecenter/en/SSFKSJ_7.1.0/com.ibm.mq.doc/sy10510_.htm</a><br>A message digest is a fixed size numeric representation of the contents of a message, computed by a hash function. A message digest can be encrypted, forming a digital signature.</p>
<h2 id="PKI"><a href="#PKI" class="headerlink" title="PKI"></a>PKI</h2><p><code>public key infrastructure</code> is a set of roles, policies, hardware, software and procedures needed to create, manage, distribute, use, store and revoke digital certificates and manage public-key encryption. The purpose of a PKI is to facilitate the secure electronic transfer of information for a range of network activities such as e-commerce, internet banking and confidential email.</p>
<h2 id="Certificate"><a href="#Certificate" class="headerlink" title="Certificate"></a>Certificate</h2><p>A file with some contents:</p>
<ol>
<li>certificate owner</li>
<li>certificate issuer</li>
<li>signature (RSA created, made by issuer)</li>
<li>public key (from owner, we then use this public key to HTTPS)</li>
</ol>
<p>The basic rule is we trust the CA (the issuer) so on the certificate owner.</p>
<blockquote>
<p>Self-signed certificate: issued and signed by the owner.</p>
</blockquote>
<p>More readings:<br><a href="https://stackoverflow.com/questions/18257185/how-does-a-public-key-verify-a-signature" target="_blank" rel="noopener">How does a public key verify a signature?</a></p>
<h2 id="Why-we-need-intermediary-CAs"><a href="#Why-we-need-intermediary-CAs" class="headerlink" title="Why we need intermediary CAs?"></a>Why we need intermediary CAs?</h2><p>There are not so much public root CAs because of problem of trust. Actually anybody can create own root CA but nobody will trust it. That’s why there is limited set of global root CAs that are trusted worldwide by operating systems and browsers. You can view list of such global CAs with their root certificates in any browser or OS.</p>
<p>Such root CAs have certificates with long period of validity and their main responsibility is simple create “source of trust”. That’s why they don’t issue certificates to end users to avoid additional work and minimize risk that their private keys will be compromised. Intermediate CAs certificates don’t necessarily need to be in the list of trusted certificates in the OS or browser. They need simply be issued by trusted root CA.</p>
<h1 id="Chain-of-Trust"><a href="#Chain-of-Trust" class="headerlink" title="Chain of Trust"></a>Chain of Trust</h1><p><code>openssl</code> command:</p>
<p>Generate RSA private key:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## check help for sub-command genrsa</span></span><br><span class="line">openssl genrsa -h</span><br><span class="line"></span><br><span class="line"><span class="comment">## generate private.pem file private key with aes256 encryption method</span></span><br><span class="line"><span class="comment">## will ask you input pass phrase </span></span><br><span class="line">openssl genrsa -aes256 -out private.pem</span><br><span class="line"></span><br><span class="line"><span class="comment">## generate public key from above private key</span></span><br><span class="line"><span class="comment">## will ask you pass phrase from private key</span></span><br><span class="line">openssopenssl rsa -<span class="keyword">in</span> private.pem -outform PEM -pubout -out public.pem</span><br></pre></td></tr></table></figure></p>
<h2 id="Root-CAs-in-OS"><a href="#Root-CAs-in-OS" class="headerlink" title="Root CAs in OS"></a>Root CAs in OS</h2><ul>
<li>How does web browser trust the root CAs and certificates?<br>The OS ships a list of trusted certificates, in Mac search <code>Keychain Access</code>. </li>
</ul>
<p>In Linux, see this <a href="https://blog.confirm.ch/adding-a-new-trusted-certificate-authority/" target="_blank" rel="noopener">link</a>: On Red Hat/Centos, It includes all trusted certificate authorities under <code>/etc/pki/ca-trust/extracted/openssl/ca-bundle.trust.crt</code>. Just add your new certificate authority file(s) to the directory <code>/etc/pki/ca-trust/source/anchors</code>, then run <code>/bin/update-ca-trust</code> for update the certificate authority file.</p>
<h2 id="Verify-chain-of-trust"><a href="#Verify-chain-of-trust" class="headerlink" title="Verify chain of trust"></a>Verify chain of trust</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">           root CA         |     intermediate CA       |        end user</span><br><span class="line">----------------------------------------------------------------------------------------</span><br><span class="line">  self-singed certificate  |     signed by root CA     |   signed by intermediate CA</span><br><span class="line">----------------------------------------------------------------------------------------</span><br><span class="line">   signature: encrpty      |    signature: encrpty     |       signature: encrpty</span><br><span class="line"> by private key of root CA | by private key of root CA |  by private key of intermediate</span><br><span class="line">                           |                           |  CA</span><br></pre></td></tr></table></figure>
<p><code>CSR</code>: certificate signing request (the root CA receive CSR from intermediate CA, the signature of intermediate CA is signed by root CA, the root CA also provide issuer info for intermediate CA. Similarly, end user is signed by intermediate CA)</p>
<p>Web server sends you its certificate and all intermediate certificates. Then on your side start the verification process from end user certificates back to top intermediate certificate then root certificate.</p>
<p>There is a online tool to check the certificates chain: <a href="https://www.geocerts.com/ssl-checker" target="_blank" rel="noopener">https://www.geocerts.com/ssl-checker</a>.</p>
<h1 id="Create-Self-signed-Certificate"><a href="#Create-Self-signed-Certificate" class="headerlink" title="Create Self-signed Certificate"></a>Create Self-signed Certificate</h1><p>Before creating certificate, you need <code>CSR</code>, and before <code>CSR</code>, you need first generate asymmetric keys. (Becuase certificate needs to include signature from upstream and also your public key)</p>
<blockquote>
<p>Choose common name (CN) according to the main domain where certificate will be used. (for example, in secure docker registry, CN is the registry address)</p>
</blockquote>
<blockquote>
<p>What is <code>/etc/ssl/certs</code> directory? Actually this is a softlink to <code>/etc/pki/tls/certs</code>.</p>
</blockquote>
<p>Generate self-signed certificate, see this <a href="https://stackoverflow.com/questions/10175812/how-to-create-a-self-signed-certificate-with-openssl" target="_blank" rel="noopener">post</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">openssl req \</span><br><span class="line">        -newkey rsa:4096 -nodes -x509 -sha256\</span><br><span class="line">        -keyout key.pem -out cert.pem -days 365 \</span><br><span class="line">        -subj &quot;/C=US/ST=CA/L=San Jose/O=Company Name/OU=Org/CN=&lt;domain&gt;&quot;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>-nodes: short for No DES, if you don’t want to protect your private key with a passphrase.</li>
<li>Add <code>-subj &#39;/CN=localhost&#39;</code> to suppress questions about the contents of the certificate (replace localhost with your desired domain).</li>
<li>For anyone else using this in automation, here’s all of the common parameters for the subject: <code>-subj &quot;/C=US/ST=CA/L=San Jose/O=Company Name/OU=Org/CN=&lt;domain&gt;&quot;</code></li>
<li>Remember to use <code>-sha256</code> to generate SHA-256-based certificate.</li>
</ul>
<h1 id="SSL-TLS-and-HTTPS"><a href="#SSL-TLS-and-HTTPS" class="headerlink" title="SSL/TLS and HTTPS"></a>SSL/TLS and HTTPS</h1><p><code>SSL</code>: Secure Socket Layer<br><code>TLS</code>: Transport Layer Security.<br>Both are cryptographic protocols used in HTTPS.</p>
<p>Difference between <code>SSL</code> vs <code>TLS</code>:  TLS is an update and secure version of SSL.<br><a href="https://www.globalsign.com/en/blog/ssl-vs-tls-difference/" target="_blank" rel="noopener">https://www.globalsign.com/en/blog/ssl-vs-tls-difference/</a><br>It’s important to note that certificates are not dependent on protocols. Sometimes you hear <code>SSL/TLS certificate</code>, it may be more accurate to call them <code>Certificates for use with SSL and TLS</code>, since the protocols are determined by your server configuration, not the certificates themselves.</p>
<p>Go to <a href="https://www.ssllabs.com/ssltest/" target="_blank" rel="noopener"><code>ssllab</code></a>, you can check which version of TLS the web server use, input the web server address and scan, then click IP icon.</p>
<p>Why <code>RSA</code> is not used in data encryption?</p>
<ol>
<li>too slow</li>
<li>bi-directional data encryption requires RSA key pairs on both sides<br>We encrypt data use symmetic key after setup secure connection.</li>
</ol>
<blockquote>
<p>Why need rsa key pairs on both sides? If the key is interchangeable, everyone has public key can decrypt data encrypted by private key!</p>
</blockquote>
<h2 id="Establish-TLS-Session"><a href="#Establish-TLS-Session" class="headerlink" title="Establish TLS Session"></a>Establish TLS Session</h2><ol>
<li>establish tcp session</li>
<li>establish tls session (negotiate protocol)</li>
<li>web server sends its certifiate (intermediate and others) to browser</li>
<li>browser generate symmetic key secured by public key from server and send to server. Or use <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange" target="_blank" rel="noopener"><code>Diffie–Hellman key exchange</code></a>.</li>
</ol>
<p>Let’s see wireshark for wikipedia connection:<br>The top 3 are TCP handshakes, then you see TLS client hello, then TLS server hello.<br><img src="https://drive.google.com/uc?id=1BqEQwaHXUIBIJguBGifnGIc_AnHJtoBB" alt=""></p>
<p>In client hello, there are lots of information to negoitate with server, here you see some supported version of TLS, also cipher suites.<br><img src="https://drive.google.com/uc?id=1eLDoipLHyJ72aXeUPv5ERcSLHlAYNU1N" alt=""></p>
<p>In server hello, you see the the server has selected one of cipher suites. The <code>TLS_ECDHE.._SHA256</code> means it uses Diffie–Hellman key exchange and sha256 as hash.<br><img src="https://drive.google.com/uc?id=1lC9yZ5vy1T-geCDnJoN1aq--QZIe3eOm" alt=""></p>
<h2 id="Diffie–Hellman"><a href="#Diffie–Hellman" class="headerlink" title="Diffie–Hellman"></a>Diffie–Hellman</h2><p>Diffie–Hellman uses one-way function, for example, mod operation.<br><img src="https://drive.google.com/uc?id=1lXCys7VAEXJxZ-sytIWUVQGXgxxRTCTi" alt=""><br>See, here <code>a</code>, <code>b</code> are priviate keys on both side, <code>g</code>, <code>p</code> are public key. <code>A</code>, <code>B</code> are mod result, <code>K</code> is the final result that both side can get use to encrypt the data.</p>
<p>Elliptic-curve cryptography is used in Diffie–Hellman.</p>
<h1 id="Custom-Domain"><a href="#Custom-Domain" class="headerlink" title="Custom Domain"></a>Custom Domain</h1><p>Purchase custom domain and use free hosting to setup our website.</p>
]]></content>
      <categories>
        <category>SSL/TLS</category>
      </categories>
      <tags>
        <tag>ssl</tag>
        <tag>tls</tag>
      </tags>
  </entry>
  <entry>
    <title>Python for Devops</title>
    <url>/2019/10/01/book-python-for-devops/</url>
    <content><![CDATA[<p>Good description for daily use:</p>
<p>One time I was in the ocean and a wave crashed on top of me and took my breath away as it pulled me deeper into the ocean. Just as I started to recover my breath, another wave dropped on top of me and extracted much of my remaining energy and pulled me even deeper into the ocean. Just as I started to recover, yet another wave crashed down on top of me. The more I would fight the waves and the ocean, the more energy I drained. I seriously wondered if I would die at that moment. I couldn’t breath, my body ached and I was terrified I was going to drown.</p>
<p>Being close to death helped me focus on the only thing that could save me, which was conserving my energy and using the waves not fighting them.</p>
<h1 id="Install-and-Configure"><a href="#Install-and-Configure" class="headerlink" title="Install and Configure"></a>Install and Configure</h1><p>Usually python2 is pre-installed, need to install <code>python3</code>, can refer this blog<br><a href="https://www.osradar.com/install-python-3-7-on-centos-7-and-fedora-27-28/" target="_blank" rel="noopener">Install Python 3.7 on centos 7</a><br>This installation will not disturb original <code>python2</code> pre-installed (it is the dependency of some other packages).</p>
<p><a href="https://pip.pypa.io/en/stable/installing/" target="_blank" rel="noopener">install pip3</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py</span><br><span class="line"><span class="comment">## install pip3</span></span><br><span class="line">python3 get-pip.py</span><br><span class="line"><span class="comment">## or install pip</span></span><br><span class="line">python get-pip.py</span><br></pre></td></tr></table></figure></p>
<p>then you can use <code>pip3</code> to install other packages, otherwise <code>pip</code> is still use <code>python2</code>.</p>
<p>Make <a href="https://askubuntu.com/questions/320996/how-to-make-python-program-command-execute-python-3" target="_blank" rel="noopener">python command execute python3</a>, you can use alias.</p>
<p><a href="https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/" target="_blank" rel="noopener">Installing packages using pip and virtual environments</a></p>
<h1 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1 Introduction"></a>Chapter 1 Introduction</h1><p>Install <code>ipython</code> or <code>ipython3</code>, powerful mixed interactive shell:<br><a href="https://ipython.org/index.html#" target="_blank" rel="noopener">https://ipython.org/index.html#</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install ipython</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">pip3 install ipython</span><br></pre></td></tr></table></figure></p>
<p>then run it as<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ipython</span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">ipython3</span><br></pre></td></tr></table></figure></p>
<p>Python variables use dynamic typing. In practice, this means reassigned to values of different types or classes</p>
<h2 id="Built-in-Functions"><a href="#Built-in-Functions" class="headerlink" title="Built-in Functions"></a>Built-in Functions</h2><ul>
<li>print</li>
<li>range<br>Use spaces instead of tabs to indent.</li>
</ul>
<h2 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h2><p>functions can be object, can put it in the list.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>functions = [double, triple]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> function <span class="keyword">in</span> functions:</span><br><span class="line"><span class="meta">... </span>    print(function(<span class="number">3</span>))</span><br></pre></td></tr></table></figure></p>
<p>Wrapping Functions with Decorators, there are some other python command line build tools. <a href="https://click.palletsprojects.com" target="_blank" rel="noopener"><code>click</code> package</a>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install click</span><br></pre></td></tr></table></figure></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="string">'''A example of using the click package to develop a command line tool'''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> click</span><br><span class="line"></span><br><span class="line"><span class="meta">@click.command()</span></span><br><span class="line"><span class="meta">@click.argument('name')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hello</span><span class="params">(name)</span>:</span></span><br><span class="line">    <span class="string">'''Say hello to name'''</span>    </span><br><span class="line">    print(<span class="string">f"Hello <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    hello()</span><br></pre></td></tr></table></figure>
<p>call it:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ python simple_cli.py Sue</span><br><span class="line">Hello Sue</span><br></pre></td></tr></table></figure></p>
<p>lambda function, just like <code>java</code> use lambda to create comparator for priority queue.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">sorted(items, key=<span class="keyword">lambda</span> item: item[<span class="number">1</span>])</span><br></pre></td></tr></table></figure></p>
<h2 id="RE-package"><a href="#RE-package" class="headerlink" title="RE package"></a>RE package</h2><p>The <code>re</code> module uses <code>\</code> to delineate special character for matching, for example <code>\.</code>, <code>\n</code>, etc. To avoid confusion with regular string escape sequences, <code>raw</code> strings are recommended in defining regular expressions. Raw strings are prepended with a <code>r</code> before the first quotation mark.</p>
<p>Similar as <code>grep</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">re.search(<span class="string">r'Rostam'</span>, cc_list)</span><br><span class="line">re.search(<span class="string">r'Chr[a-z][a-z]'</span>, cc_list)</span><br><span class="line">re.search(<span class="string">r'[A-Za-z]&#123;6&#125;'</span>, cc_list)</span><br><span class="line">re.search(<span class="string">r'[A-Za-z]+@[a-z]+\.[a-z]+'</span>, cc_list)</span><br></pre></td></tr></table></figure></p>
<h2 id="Lazy-Evaluation"><a href="#Lazy-Evaluation" class="headerlink" title="Lazy Evaluation"></a>Lazy Evaluation</h2><p>This will have footprint in memory, generate values as needed, will not take much memory.</p>
<p>Create generator, using <code>()</code> instead of <code>[]</code>(list comprehension)<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">gen_o_nums = (x <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">100</span>))</span><br></pre></td></tr></table></figure></p>
<h2 id="More-IPYTHON-features"><a href="#More-IPYTHON-features" class="headerlink" title="More IPYTHON features"></a>More IPYTHON features</h2><p>Using IPython To Run Unix Shell Commands, add <code>!</code> before command, but sometime does not need (default setting):<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">In [2]: !ls -l</span><br></pre></td></tr></table></figure></p>
<p>can assign to a variable:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">In [6]: res = !df -h | head -n 7</span><br><span class="line"></span><br><span class="line"><span class="comment">## list format</span></span><br><span class="line">In [7]: res</span><br><span class="line">Out[7]:</span><br><span class="line">[<span class="string">'Filesystem                 Size  Used Avail Use% Mounted on'</span>,</span><br><span class="line"> <span class="string">'/dev/mapper/rhel-root      241G   73G  169G  31% /'</span>,</span><br><span class="line"> <span class="string">'devtmpfs                   3.9G     0  3.9G   0% /dev'</span>,</span><br><span class="line"> <span class="string">'tmpfs                      3.9G     0  3.9G   0% /dev/shm'</span>,</span><br><span class="line"> <span class="string">'tmpfs                      3.9G  403M  3.5G  11% /run'</span>,</span><br><span class="line"> <span class="string">'tmpfs                      3.9G     0  3.9G   0% /sys/fs/cgroup'</span>,</span><br><span class="line"> <span class="string">'/dev/vda1                 1014M  208M  807M  21% /boot'</span>]</span><br><span class="line"></span><br><span class="line">In [8]: res.grep(<span class="string">"dev"</span>)</span><br><span class="line">Out[8]:</span><br><span class="line">[<span class="string">'/dev/mapper/rhel-root      241G   73G  169G  31% /'</span>,</span><br><span class="line"> <span class="string">'devtmpfs                   3.9G     0  3.9G   0% /dev'</span>,</span><br><span class="line"> <span class="string">'tmpfs                      3.9G     0  3.9G   0% /dev/shm'</span>,</span><br><span class="line"> <span class="string">'/dev/vda1                 1014M  208M  807M  21% /boot'</span>]</span><br></pre></td></tr></table></figure></p>
<p>magic commands:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## enter bash </span></span><br><span class="line">In [13]: %%bash</span><br><span class="line"><span class="comment">## write into a file</span></span><br><span class="line">In [14]: %%writefile test.sh</span><br></pre></td></tr></table></figure></p>
<p><a href="https://www.quora.com/How-can-I-make-IPython-import-the-aliases-defined-in-my-bash-profile-upon-startup" target="_blank" rel="noopener">Make IPython import shell alias</a><br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line">c = get_config()</span><br><span class="line"><span class="keyword">with</span> open(os.path.expanduser(<span class="string">'~/.bashrc'</span>)) <span class="keyword">as</span> bashrc:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> bashrc:</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> line.startswith(<span class="string">'alias'</span>):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        parts = re.match(<span class="string">r'^alias (\w+)=([\'"]?)(.+)\2$'</span>, line.strip())</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> parts:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        source, _, target = parts.groups()</span><br><span class="line">        c.AliasManager.user_aliases.append((source, target))</span><br></pre></td></tr></table></figure></p>
<p>Drop this code in <code>~/.ipython/profile_default/ipython_config.py</code>, just like <code>.bashrc</code> and <code>.vimrc</code>, the configuration file for ipython.</p>
<p>How to import shell functions in <code>.bashrc</code>? Or wirte python function instead.</p>
<h1 id="Chapter-2-Automating-Text-and-Files"><a href="#Chapter-2-Automating-Text-and-Files" class="headerlink" title="Chapter 2 Automating Text and Files"></a>Chapter 2 Automating Text and Files</h1><p>In the DevOps world, you are continually parsing, searching, and changing the text in files, whether it’s searching application logs or propagating configuration files.</p>
<p>read regular file:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## don't need to close explicitly</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"/root/DS/tmp.txt"</span>, <span class="string">"r"</span>) <span class="keyword">as</span> handler:</span><br><span class="line">  data = handler.read()</span><br><span class="line"></span><br><span class="line"><span class="comment">## one char</span></span><br><span class="line">data[<span class="number">0</span>]</span><br><span class="line"><span class="comment">## file size</span></span><br><span class="line">len(data)</span><br></pre></td></tr></table></figure></p>
<p>or use<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">## this will parse lines by `\n`</span></span><br><span class="line">data = readlines()</span><br><span class="line"><span class="comment">## i-th line</span></span><br><span class="line">data[i]</span><br></pre></td></tr></table></figure></p>
<p>Different operating systems use different escaped characters to represent line-endings. Unix systems use <code>\n</code> and Windows systems use <code>\r\n</code>. Python converts these to <code>\n</code> when you open a file as text. If you are opening a binary file, such as a jpeg image, you are likely to corrupt the data by this conversion if you open it as text. You can, however, read binary files by appending a <code>b</code> to mode:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">file_path = <span class="string">'bookofdreamsghos00lang.pdf'</span></span><br><span class="line"><span class="keyword">with</span> open(file_path, <span class="string">'rb'</span>) <span class="keyword">as</span> open_file:</span><br><span class="line">  btext = open_file.read()</span><br></pre></td></tr></table></figure></p>
<p>write file:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">content=<span class="string">'''export a=123</span></span><br><span class="line"><span class="string">export b=456</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"/root/DS/.envrc"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> handler:</span><br><span class="line">  handler.write(content)</span><br></pre></td></tr></table></figure></p>
<p>The <code>open</code> function creates the file if it does not already exist and overwrites if it does. if want to append, use <code>a</code> mode instead of <code>w</code>. For binary file use <code>bw</code> or <code>ba</code>.</p>
<h2 id="JSON"><a href="#JSON" class="headerlink" title="JSON"></a>JSON</h2><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'xx.json'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> handler:</span><br><span class="line">  data = json.load(handler)</span><br><span class="line"></span><br><span class="line">json.load() <span class="keyword">is</span> used to load file</span><br><span class="line"><span class="comment">## Deserialize fp (a .read()-supporting text file or binary file containing a JSON document) to a Python object using this conversion table.</span></span><br><span class="line"></span><br><span class="line">json.loads() <span class="keyword">is</span> used to load other object</span><br><span class="line"><span class="comment">##Deserialize s (a str, bytes or bytearray instance containing a JSON document) to a Python object using this conversion table.</span></span><br><span class="line"></span><br><span class="line">pprint</span><br><span class="line">Pretty printing has been turned ON</span><br><span class="line"><span class="comment">## then print data is good</span></span><br><span class="line"><span class="comment">## or</span></span><br><span class="line">print(json.dumps(data, indent=<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">## update</span></span><br><span class="line">data[<span class="string">"workerNodeHosts"</span>][<span class="number">0</span>][<span class="string">"name"</span>] = <span class="string">"localhost"</span></span><br><span class="line"><span class="comment">## write file</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'xx.json'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> handler:</span><br><span class="line">  json.dump(data, handler, indent=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## the same as load() and loads()</span></span><br><span class="line">json.dump() <span class="keyword">is</span> <span class="keyword">for</span> file</span><br><span class="line">json.dumps() <span class="keyword">is</span> <span class="keyword">for</span> general object</span><br></pre></td></tr></table></figure>
<p>actually you can use data pretty printer:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> pprint</span><br><span class="line"></span><br><span class="line">pprint.pprint(data)</span><br></pre></td></tr></table></figure></p>
<h2 id="YAML"><a href="#YAML" class="headerlink" title="YAML"></a>YAML</h2><p>The most commonly used library for parsing YAML files in Python is <code>PyYAML</code>. It is not in the Python Standard Library, but you can install it using pip:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">pip install pyyaml</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"><span class="comment">## read</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"xx.yml"</span>, <span class="string">"r"</span>) <span class="keyword">as</span> handler: </span><br><span class="line">  data = yaml.safe_load(handler) </span><br><span class="line"></span><br><span class="line"><span class="comment">## python convert data as a dict, so you can edit it</span></span><br><span class="line"></span><br><span class="line">print(yaml.dump(data, indent=<span class="number">2</span>))</span><br><span class="line"><span class="comment">## write</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"xx.yml"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> handler:</span><br><span class="line">  yaml.dump(data, handler, indent=<span class="number">2</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="XML"><a href="#XML" class="headerlink" title="XML"></a>XML</h2><p>Historically, many web systems used XML to transport data. One use is for <code>RSS</code> feeds. <code>RSS (Really Simple Syndication)</code> feeds are used to track and notify users of updates to websites. These feeds have been used to track the publication of articles from various sources. RSS uses XML formatted pages. Python offers the xml library for dealing with XML documents. It maps the XML documents hierarchical structure to a tree-like data structure.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line">tree = ET.parse(<span class="string">'/tmp/test.xml'</span>)</span><br><span class="line">root = tree.getroot()</span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> root:</span><br><span class="line">  print(child.tag, child.attrib)</span><br></pre></td></tr></table></figure></p>
<h2 id="CSV"><a href="#CSV" class="headerlink" title="CSV"></a>CSV</h2><p>data stored as comma-separated values.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">16</span>]: <span class="keyword">import</span> csv</span><br><span class="line">In [<span class="number">17</span>]: file_path = <span class="string">'/tmp/user.csv'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">18</span>]: <span class="keyword">with</span> open(file_path, newline=<span class="string">''</span>) <span class="keyword">as</span> handler:</span><br><span class="line">    ...:     off_reader = csv.reader(handler, delimiter=<span class="string">','</span>)</span><br><span class="line">    ...:     <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">    ...:         print(next(off_reader))</span><br><span class="line">    ..</span><br></pre></td></tr></table></figure></p>
<p><code>pandas</code> packages is mainstay to do data science work.<br>Pandas has many more methods for analyzing and manipulating table like data, and there are many books on its use. You should be aware that it is available if you need to do data analysis.</p>
<h2 id="Search-Text"><a href="#Search-Text" class="headerlink" title="Search Text"></a>Search Text</h2><p>One widely used format is the <code>Common Log Format (CLF)</code>. A variety of log analysis tools can understand this format:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;IP Address&gt; &lt;Client Id&gt; &lt;User Id&gt; &lt;Time&gt; &lt;Request&gt; &lt;Status&gt; &lt;Size&gt;</span><br><span class="line">127.0.0.1 - swills [13/Nov/2019:14:43:30 -0800] &quot;GET /assets/234 HTTP</span><br></pre></td></tr></table></figure></p>
<p>Just give some examples:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">line = <span class="string">'127.0.0.1 - swills [13/Nov/2019:14:43:30 -0800] "GET /assets/234 HTTP/1.0" 200 2326'</span></span><br><span class="line"><span class="comment">## use name groups</span></span><br><span class="line">r = <span class="string">r'(?P&lt;IP&gt;\d+\.\d+\.\d+\.\d+) - (?P&lt;User&gt;\w+) \[(?P&lt;Time&gt;\d\d/\w&#123;3&#125;/\d&#123;4&#125;:\d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125; [-+]\d&#123;4&#125;)\] (?P&lt;Request&gt;".+")'</span></span><br><span class="line">m = re.search(r, line)</span><br><span class="line"></span><br><span class="line">In [<span class="number">11</span>]: m.group(<span class="string">'IP'</span>)</span><br><span class="line">Out[<span class="number">11</span>]: <span class="string">'129.0.0.1'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">12</span>]: m.group(<span class="string">'Time'</span>)</span><br><span class="line">Out[<span class="number">12</span>]: <span class="string">'13/Nov/2019:14:43:30 -0800'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">13</span>]: m.group(<span class="string">'User'</span>)</span><br><span class="line">Out[<span class="number">13</span>]: <span class="string">'swills'</span></span><br><span class="line"></span><br><span class="line">In [<span class="number">14</span>]: m.group(<span class="string">'Request'</span>)</span><br><span class="line">Out[<span class="number">14</span>]: <span class="string">'"GET /assets/234 HTTP/1.0"'</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: Python automatically allocates and frees memory.The Python garbage collector can be controlled using the <code>gc</code> package, though this is rarely needed.</p>
</blockquote>
<p>For large files. If the files contain data that can be processed one line at a time, the task is easy with Python. You can read one line at a time, process the line, and then move to the next. The lines are removed from memory automatically by Python’s garbage collector, freeing up memory.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">In [<span class="number">23</span>]: <span class="keyword">with</span> open(<span class="string">'big-data.txt'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> source_file:</span><br><span class="line">    ...:     <span class="keyword">with</span> open(<span class="string">'big-data-corrected.txt'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> target_file:</span><br><span class="line">    ...:         <span class="keyword">for</span> line <span class="keyword">in</span> source_file:</span><br><span class="line">    ...:             target_file.write(line)</span><br></pre></td></tr></table></figure>
<h1 id="Chapter-3-Command-Line"><a href="#Chapter-3-Command-Line" class="headerlink" title="Chapter 3 Command Line"></a>Chapter 3 Command Line</h1><p>Python offers tools for interacting with systems and shells. You should become familiar with the <code>sys</code>, <code>os</code>, and <code>subprocess</code> modules, as are all essential tools.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment">## little or big endian</span></span><br><span class="line">sys.byteorder</span><br><span class="line"><span class="comment">## python object size</span></span><br><span class="line">sys.getsizeof(<span class="number">1</span>)</span><br><span class="line"><span class="comment">## platform</span></span><br><span class="line">sys.platform</span><br><span class="line"><span class="comment">## python version</span></span><br><span class="line">sys.version_info.major</span><br><span class="line">sys.version_info.minor</span><br></pre></td></tr></table></figure>
<p>The most common usage of the os module is to get settings from environment variables.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment">## pwd and cd</span></span><br><span class="line">os.getcwd()</span><br><span class="line">os.chdir(<span class="string">'/tmp'</span>)</span><br><span class="line"><span class="comment">## get and set env var</span></span><br><span class="line">os.environ.get(<span class="string">'HOME'</span>)</span><br><span class="line">os.environ[<span class="string">'HOME'</span>] = <span class="string">'/tmp'</span></span><br><span class="line"><span class="comment">## login user</span></span><br><span class="line">os.getlogin()</span><br></pre></td></tr></table></figure></p>
<p>With <code>subprocess</code> you can run your favorite shell command or other command line software and collect its output from within Python. For the majority of use-cases, you should use the <code>subprocess.run</code> function to spawn processes<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> subprocess</span><br><span class="line"></span><br><span class="line">sub = subprocess.run([<span class="string">'ls'</span>, <span class="string">'-ltr'</span>], capture_output=<span class="keyword">True</span>, universal_newlines=<span class="keyword">True</span>)</span><br><span class="line">sub.stdout</span><br><span class="line">sub.stderr</span><br><span class="line"><span class="comment">## exception will be raised when use</span></span><br><span class="line">sub = subprocess.run([<span class="string">'ls'</span>, <span class="string">'/non'</span>], capture_output=<span class="keyword">True</span>, universal_newlines=<span class="keyword">True</span>, check=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="Creating-Command-Line-Tools"><a href="#Creating-Command-Line-Tools" class="headerlink" title="Creating Command Line Tools"></a>Creating Command Line Tools</h2><p>Invoke python script usually by:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python xx.py</span><br></pre></td></tr></table></figure></p>
<p>or you can eliminate python by adding <code>#!/usr/bin/env python</code>(or <code>python3</code>) at first line of the script, then <code>chmod</code> the script to executable:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./xx.py</span><br></pre></td></tr></table></figure></p>
<p>The simplest and most basic way to process arguments from the command line is to use the argv attribute of the <code>sys module</code>:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Simple command line tool using sys.argv</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">  <span class="comment">## sys.argv is a list</span></span><br><span class="line">  sys.argv[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> <span class="string">'--help'</span> <span class="keyword">in</span> sys.argv:</span><br><span class="line">    help_message = <span class="string">f"Usage: <span class="subst">&#123;sys.argv[<span class="number">0</span>]&#125;</span> ..."</span></span><br><span class="line">    print(help_message)</span><br><span class="line">    sys.exit()</span><br><span class="line"><span class="comment">## can get index</span></span><br><span class="line">idx = sys.argv.index(<span class="string">'--namespace'</span>)</span><br><span class="line">namespace = sys.argv[idx]</span><br></pre></td></tr></table></figure></p>
<p>This is not enough, we need argument parser! Luckily there are modules and packages designed for the creation of command line tools. These packages provide frameworks to design the user interface for your module when running in a shell. Three popular solutions <code>argparse</code>, <code>click</code>, and <code>fire</code>. All three include ways to design required arguments, optional flags, and means to display help documentation. The first, argparse, is part of the Python standard library, and the other two are third-party packages that need to be installed separately (using pip).</p>
<h3 id="argparse"><a href="#argparse" class="headerlink" title="argparse"></a>argparse</h3><p>这个有专门的tutorial，大概看了一下，it does take much work on your part but you get lots of control.</p>
<p>Automatically generates help and usage messages and issues errors when users give the program invalid arguments.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Command line tool using argparse</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line">parser = argparse.ArgumentParser(description=<span class="string">'Process some integers.'</span>)</span><br><span class="line">parser.add_argument(<span class="string">'integers'</span>, metavar=<span class="string">'N'</span>, type=int, nargs=<span class="string">'+'</span>,</span><br><span class="line">                    help=<span class="string">'an integer for the accumulator'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">## If the name begins with a dash, it is treated as an optional, flag, argument, otherwise as a position-dependent command. </span></span><br><span class="line">parser.add_argument(<span class="string">'--sum'</span>, dest=<span class="string">'accumulate'</span>, action=<span class="string">'store_const'</span>,</span><br><span class="line">                    const=sum, default=max,</span><br><span class="line">                    help=<span class="string">'sum the integers (default: find the max)'</span>)</span><br><span class="line"></span><br><span class="line">args = parser.parse_args()</span><br><span class="line">print(args.accumulate(args.integers))</span><br></pre></td></tr></table></figure></p>
<p>You can also define sub-commands, like <code>git stash ...</code>.</p>
<h3 id="click"><a href="#click" class="headerlink" title="click"></a>click</h3><p>It uses Python <code>Function Decorators</code> to bind the command line interface directly with your functions. </p>
<p>Python decorators are a special syntax for functions <strong>take other functions as arguments</strong>. Python functions are objects, so any function can take a function as an argument. The decorator syntax provides a clean and easy way to do this.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Simple Click example</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> click</span><br><span class="line"></span><br><span class="line"><span class="meta">@click.command()</span></span><br><span class="line"><span class="meta">@click.option('--greeting', default='Hiya', help='How do you want to greet?')</span></span><br><span class="line"><span class="meta">@click.option('--name', default='Tammy', help='Who do you want to greet?')</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(greeting, name)</span>:</span></span><br><span class="line">    print(<span class="string">f"<span class="subst">&#123;greeting&#125;</span> <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    greet()</span><br></pre></td></tr></table></figure>
<p>Please refer to <a href="https://click.palletsprojects.com/en/7.x/" target="_blank" rel="noopener">click documents</a>.</p>
<h3 id="fire"><a href="#fire" class="headerlink" title="fire"></a>fire</h3><p><a href="https://github.com/google/python-fire" target="_blank" rel="noopener">fire document</a>.</p>
<p>for example:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Simple Fire example</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> fire</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">greet</span><span class="params">(greeting=<span class="string">'Hiya'</span>, name=<span class="string">'Tammy'</span>)</span>:</span></span><br><span class="line">    print(<span class="string">f"<span class="subst">&#123;greeting&#125;</span> <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">goodbye</span><span class="params">(goodbye=<span class="string">'Bye'</span>, name=<span class="string">'Tammy'</span>)</span>:</span></span><br><span class="line">    print(<span class="string">f"<span class="subst">&#123;goodbye&#125;</span> <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    fire.Fire()</span><br></pre></td></tr></table></figure></p>
<p>An exciting feature of fire is the ability to enter an interactive mode easily. By using the <code>--interactive</code> flag, fire opens an IPython shell with the object and functions of your script available:<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">./fire_example.py &lt;command&gt; &lt;args&gt; -- --interactive</span><br></pre></td></tr></table></figure></p>
<p>Overall, We recommend <code>click</code> for most use cases. It balances ease and control. In the case of complex interfaces where you want to separate the UI code from business logic, <code>argparse</code> is the way to go. Moreover, if you need to access code that does not have a command line interface quickly, <code>fire</code> is right for you.</p>
<h2 id="Implementing-plugins"><a href="#Implementing-plugins" class="headerlink" title="Implementing plugins"></a>Implementing plugins</h2><p>Once you’ve implemented your applications command line user interface you might want to consider a plugin system. Plugins are pieces of code supplied by the user of your program to extend functionality. </p>
<p>A key part of any plugin system is plugin discover. Your program needs to know what plugins are available to load and run. Create a file named <code>add_plugins.py</code><br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="keyword">import</span> fire</span><br><span class="line"><span class="keyword">import</span> pkgutil</span><br><span class="line"><span class="keyword">import</span> importlib</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_and_run_plugins</span><span class="params">(plugin_prefix)</span>:</span></span><br><span class="line">    plugins = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Discover and Load Plugins</span></span><br><span class="line">    print(<span class="string">f"Discovering plugins with prefix: <span class="subst">&#123;plugin_prefix&#125;</span>"</span>)</span><br><span class="line">    <span class="comment"># pkgutil.iter_modules returns all modules available in the current sys.path</span></span><br><span class="line">    <span class="keyword">for</span> _, name, _ <span class="keyword">in</span>  pkgutil.iter_modules():</span><br><span class="line">        <span class="comment"># Check if the module uses our plugin prefix</span></span><br><span class="line">        <span class="keyword">if</span> name.startswith(plugin_prefix):</span><br><span class="line">            <span class="comment"># Use importlib to load the module, saving it in a dict for later use.</span></span><br><span class="line">            module = importlib.import_module(name)</span><br><span class="line">            plugins[name] = module</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run Plugins</span></span><br><span class="line">    <span class="keyword">for</span> name, module <span class="keyword">in</span> plugins.items():</span><br><span class="line">        print(<span class="string">f"Running plugin <span class="subst">&#123;name&#125;</span>"</span>)</span><br><span class="line">        <span class="comment"># Call the run method on the plugin.</span></span><br><span class="line">        module.run()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    fire.Fire()</span><br></pre></td></tr></table></figure></p>
<p>then you can wirte modules for example: <code>module1.py</code> and put it in <code>sys.path</code> directory. If you run <code>./add_plugins.py find_and_run_plugins module</code>, then it will search, load and run the <code>module1.py</code> module.</p>
<h2 id="Turbocharging-Python-with-Command-Line-Tools"><a href="#Turbocharging-Python-with-Command-Line-Tools" class="headerlink" title="Turbocharging Python with Command Line Tools"></a>Turbocharging Python with Command Line Tools</h2><p>Here are the raw ingredients that will be used to make several solutions:</p>
<ul>
<li>Click Framework</li>
<li>Python CUDA Framework</li>
<li>Numba Framework</li>
<li>Scikit-learn Machine Learning Framework</li>
</ul>
<p>These are tools to speed up the performance.</p>
<h1 id="Chapter-4-Useful-Linux-Utilities"><a href="#Chapter-4-Useful-Linux-Utilities" class="headerlink" title="Chapter 4 Useful Linux Utilities"></a>Chapter 4 Useful Linux Utilities</h1><p>This chapter will go through some common patterns in the shell and will include some useful Python commands that should enhance the ability to interact with a machine.</p>
<p>As a seasoned performance engineer once said, it depends on what is measured and how.</p>
<h2 id="disk-utility"><a href="#disk-utility" class="headerlink" title="disk utility"></a>disk utility</h2><p>If we had to work in an isolated environment with a server that doesn’t have access to the internet or that we don’t control and therefore can’t install packages, we would have to say that the <code>dd</code> tool can provide help.</p>
<p>This will get thoughput of the new device, for example, the throughput is 1.4GB/s<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dd if=/dev/zero of=&lt;new device&gt; count=10 bs=100M</span><br><span class="line"></span><br><span class="line">10+0 records in</span><br><span class="line">10+0 records out</span><br><span class="line">10506731520 bytes (11 GB) copied, 3.12099 s, 1.4 GB/s</span><br></pre></td></tr></table></figure></p>
<p>how to get IOPS, update every 1 second:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iostat -d &lt;device&gt; 1</span><br></pre></td></tr></table></figure></p>
<p>Other common test tool is <code>fio</code>, you may need to install this package. It can help clarify the performance behavior of a device in a read-heavy or write-heavy environment (and even adjust the percentages of reads vs. writes).</p>
<h2 id="network-utility"><a href="#network-utility" class="headerlink" title="network utility"></a>network utility</h2><ul>
<li>ssh tunneling (ssh port forwarding)</li>
</ul>
<p>For example, the server hello.com can only access by ssh with port 3345 and not exposed,let’s forward hello.com:3345 to a local port in my machine:<br><a href="https://www.youtube.com/watch?v=AtuAdk4MwWw" target="_blank" rel="noopener">https://www.youtube.com/watch?v=AtuAdk4MwWw</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -f -L 12333:hello.com:3345 root@hello.com -N</span><br></pre></td></tr></table></figure></p>
<p><code>-f</code> means run in bachground<br><code>-L</code> is forwarding rule<br><code>-N</code> means don’t get into remote shell<br><a href="mailto:`root@hello.com" target="_blank" rel="noopener">`root@hello.com</a>` is the username and address of that server</p>
<p>This tech can also be used to bypass firewall for some ports. Then we can access localhost:12333 to access the server.<br>疑问：如果port已经被firewall block了，ssh是怎么连接上的呢？</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins Quick Start</title>
    <url>/2020/05/12/jenkins-learn/</url>
    <content><![CDATA[<h1 id="Certified-Jenkins-Enginee"><a href="#Certified-Jenkins-Enginee" class="headerlink" title="Certified Jenkins Enginee"></a>Certified Jenkins Enginee</h1><p>Certified Jenkins Engineer (CJE):<br><a href="https://github.com/bmuschko/cje-crash-course" target="_blank" rel="noopener">https://github.com/bmuschko/cje-crash-course</a></p>
<h1 id="Jenkins"><a href="#Jenkins" class="headerlink" title="Jenkins"></a>Jenkins</h1><p>Jenkins is not a build system, it is a structured model.<br>Other interesting project: <code>Tekton</code>, <code>Jenkinx</code> (k8s involved)</p>
<p>Installing Jenkins, must have compatible <code>openjdk</code> installed.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## can use war file:</span></span><br><span class="line">java -jar jenkins.war</span><br></pre></td></tr></table></figure></p>
<p>or using rpm install for centos/redhat, then using systemctl to start/enable Jenkins<br><a href="https://www.jenkins.io/doc/book/installing/#red-hat-centos" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/installing/#red-hat-centos</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## you will see the default jenkins port is 8080</span></span><br><span class="line">ps aux | grep jenkinx</span><br></pre></td></tr></table></figure></p>
<p>then you can open the web interface by <code>&lt;node ip&gt;:8080</code>.</p>
<p>If wizard install failed with some plugins, you can fix this later in <code>Manage Plugins</code>.</p>
<p>Jenkins use file system to store everything, if using systemd, the configuration is in <code>/var/lib/jenkins</code>. You can backup this folder, or if you want to wipe it out, then run <code>systemctl restart jenkins</code>, then jenkins goes back to init state.</p>
<p>Even Jenkins UI to create project is not needed, you can mkdir and files in the Jenkins working directory, then go to <code>Manage Jenkins</code> -&gt; <code>Reload Configuration from Disk</code>.</p>
<blockquote>
<p>遇到一件很神奇的事情，有次Jenkins的Credentials配置消失了。。。重启也不见恢复，后来我直接stop daemon, 清空workspace下所有文件，再次重启初始化，就恢复了。后来想想我应该是在配置Credentials时把配置改错了，可以通过<code>Manage Jenkins</code> -&gt; <code>Configure Credentials</code> 改回去。</p>
</blockquote>
<h2 id="Creating-app-build"><a href="#Creating-app-build" class="headerlink" title="Creating app build"></a>Creating app build</h2><p>freestyle project -&gt; pipeline (series of freestyle project), freestyle project is not recommended.</p>
<p>Jenkins <strong>Workspace</strong>, you can see it in console output or click <code>Workspace</code> icon in your project dashboard. Everything running is in project workspace. Every build will override the previous one. You can use tar command to backup and restore this workspace, or clean workspace.</p>
<blockquote>
<p>注意, 如果在Jenkins configuration中直接使用pipeline script 而不是 SCM, 是不会创建workspace的。</p>
</blockquote>
<p>To store the build artifact, use <code>Post-build Action</code> in configure. for example, you want to archive some jar or zip files. then after build is done, these archives will show in the build page.</p>
<h3 id="Build-trend"><a href="#Build-trend" class="headerlink" title="Build trend"></a>Build trend</h3><p>Right to <code>Build History</code> list, there is a <code>trend</code> button, click it will see the build time history statistics and distribution.</p>
<h2 id="Testing-and-Continuous-integration"><a href="#Testing-and-Continuous-integration" class="headerlink" title="Testing and Continuous integration"></a>Testing and Continuous integration</h2><p>Now start the <code>pipeline</code> job type. After creating a pipeline job, you will see <code>pipeline syntax</code> button in the page bottom, it contains necessary resources to start. You can also use <code>Copy from</code> to copy a pipeline configure from another, for quick start.</p>
<h3 id="Add-slave-nodes"><a href="#Add-slave-nodes" class="headerlink" title="Add slave nodes"></a>Add slave nodes</h3><p><code>Manage Jenkins</code> -&gt; <code>Manage Nodes and Clouds</code><br>To add slaves, usually use SSH to launch agent nodes. (如果node没有被发现，会显示错误，根据错误指示排查问题即可)</p>
<h3 id="Pipeline-steps"><a href="#Pipeline-steps" class="headerlink" title="Pipeline steps"></a>Pipeline steps</h3><blockquote>
<p>This is scripted pipeline syntax, not recommended! Please use declarative pipeline directives! what are the differences between them: <a href="https://www.jenkins.io/doc/book/pipeline/#pipeline-syntax-overview" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/#pipeline-syntax-overview</a></p>
</blockquote>
<p>如果直接在Jenkins configure UI中设置Jenkins file，则常用的Steps (in snippet generator):</p>
<ul>
<li><p>node: Allocate node<br>Jenkins use <code>master &lt;-&gt; agent model</code>, you can configure tasks to be executed in agent node.</p>
</li>
<li><p>stage: stage</p>
</li>
<li>stash: stash some files to be used later in build</li>
<li>unstash: restore files previous stashed</li>
<li>parallel: execute in parallel (如果注册了多个slave nodes，则parallel会在上面执行并行的任务， 一般用在测试的时候，比如测试不同的环境和配置, see declarative pipeline demo code below)</li>
<li>git: Git</li>
<li>dir: Change Current Directory</li>
<li>sh: Shell Script</li>
<li>step: General Build Step</li>
<li>emailext: Extended Email</li>
</ul>
<h3 id="Triggering-auto-build"><a href="#Triggering-auto-build" class="headerlink" title="Triggering auto build"></a>Triggering auto build</h3><p>在pipeline configure中有<code>Builder Triggers</code>可以选择:</p>
<ul>
<li>Build after other projects are built</li>
<li>Build periodically</li>
<li>Poll SCM</li>
<li>Disable this project</li>
<li>Quiet period</li>
<li>Trigger builds remotely</li>
</ul>
<h3 id="Email-Notification"><a href="#Email-Notification" class="headerlink" title="Email Notification"></a>Email Notification</h3><p>Using <code>emailext: Extended Email</code>，可以用groovy函数包装，传入email的subject以及内容再调用。</p>
<h2 id="Managing-plugins"><a href="#Managing-plugins" class="headerlink" title="Managing plugins"></a>Managing plugins</h2><p><code>Manage Jenkins</code> -&gt; <code>Manage Plugins</code>, then you can select and install plugin in <code>Available</code> section. For example:</p>
<ul>
<li>Pipeline (如果这个没安装，则不会在UI中显示pipeline的动态流程图)</li>
<li><p>Html publisher (常用于发布unit test后的html report，这些html文件其实是被相关test生成好的, publisher then renders it)</p>
<figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">publishHTML([<span class="string">allowMissing:</span> <span class="literal">true</span>,</span><br><span class="line"><span class="symbol">            alwaysLinkToLastBuild:</span> <span class="literal">true</span>,</span><br><span class="line"><span class="symbol">                keepAll:</span> <span class="literal">true</span>,</span><br><span class="line"><span class="symbol">                reportDir:</span> <span class="string">"$WORKSPACE/cognitive-designer-api/DSJsonApiServletJUnitTests/build/reports/tests/payloadtests"</span>,</span><br><span class="line"><span class="symbol">                reportFiles:</span> <span class="string">'index.html'</span>,</span><br><span class="line"><span class="symbol">                reportName:</span> <span class="string">'Payload Test'</span>,</span><br><span class="line"><span class="symbol">                reportTitles:</span> <span class="string">''</span>])</span><br></pre></td></tr></table></figure>
</li>
<li><p>Green Balls (show green color for success)</p>
</li>
<li>Blue Ocean (embedded site with new Jenkins UI)</li>
<li>Job DSL: Allowing jobs to be defined in a programmatic form in a human readable file.</li>
</ul>
<blockquote>
<p>Pipeline compatible plugins: <a href="https://github.com/jenkinsci/pipeline-plugin/blob/master/COMPATIBILITY.md" target="_blank" rel="noopener">https://github.com/jenkinsci/pipeline-plugin/blob/master/COMPATIBILITY.md</a></p>
</blockquote>
<p>在初始化设置Jenkins的时候，有可能有plugins安装失败，可以自己在<code>Manage plugin</code>中安装，然后restart Jenkins (关于restart Jenkins请在没有job运行的情况下进行，不同的安装方式restart的方法不同，或者在安装plugin的时候选择restart jenkins after install), for example: <code>systemctl restart jenkins</code>, 这可以消除控制面板上的plugin failure警告。。</p>
<h2 id="Continuous-delivery"><a href="#Continuous-delivery" class="headerlink" title="Continuous delivery"></a>Continuous delivery</h2><p>In <code>Blue Ocean</code>, you can run multiple builds in parallel. if more than one builds run in the same agent, the workplace path is distinguished by suffix (@count number). 但是能不能run multiple builds in one agent depends on how you design your pipeline and tasks.</p>
<p><code>Blue Ocean</code>中的UI对parallel的显示也很直观，方便查看。</p>
<h3 id="Trigger-builds-remotely"><a href="#Trigger-builds-remotely" class="headerlink" title="Trigger builds remotely"></a>Trigger builds remotely</h3><p>Setup token in pipeline configure interface. Then in the upstream pipeline, for example, perform:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## unsecured connection</span></span><br><span class="line">curl POST http://&lt;url&gt;/job/<span class="variable">$&#123;PIPELINE_NAME&#125;</span>/buildWithParameters?token=<span class="variable">$&#123;PIPELINE_TOKEN&#125;</span>\\&amp;para1=val1\\&amp;para2=val2\\&amp;para3=val3</span><br><span class="line"><span class="comment">## secured connection</span></span><br><span class="line">curl --user <span class="variable">$&#123;BUILD_USER&#125;</span>:<span class="variable">$&#123;JENKINS_TOKEN&#125;</span> --request POST https://&lt;url&gt;/job/<span class="variable">$&#123;PIPELINE_NAME&#125;</span>/buildWithParameters?para1=val1\\&amp;para2=val2\\&amp;para3=val3</span><br></pre></td></tr></table></figure></p>
<h3 id="Flyweight-executor"><a href="#Flyweight-executor" class="headerlink" title="Flyweight executor"></a>Flyweight executor</h3><p>Flyweight executor reside in Jenkins master, used to execute code outside of node allocation. Others are heavyweight executors. Flyweight exxcutor will not be counted into executor capacity.</p>
<p>For example, we use flyweight executor for pause, in Jenkins script:<br><a href="https://stackoverflow.com/questions/44737036/jenkins-pipeline-with-code-pause-for-input" target="_blank" rel="noopener">https://stackoverflow.com/questions/44737036/jenkins-pipeline-with-code-pause-for-input</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## see below declarative pipeline demo code</span></span><br><span class="line">input <span class="string">"waiting for approval, move to staging stage..."</span></span><br></pre></td></tr></table></figure></p>
<p>The job will be paused, you can go to <code>Paused for Input</code> to decide what to do next: proceed or abort. (In <code>Blue Ocean</code>, the pause interface is more clear)</p>
<h1 id="Declarative-pipeline"><a href="#Declarative-pipeline" class="headerlink" title="Declarative pipeline"></a>Declarative pipeline</h1><p>github demo:<br><a href="https://github.com/sixeyed/jenkins-pipeline-demos" target="_blank" rel="noopener">https://github.com/sixeyed/jenkins-pipeline-demos</a></p>
<p>Declarative Pipelines:<br><a href="https://www.jenkins.io/doc/book/pipeline/syntax/" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/syntax/</a></p>
<p>这里有关于declarative pipeline的介绍视频, Jenkins file lives in source control!<br><a href="https://www.jenkins.io/solutions/pipeline/" target="_blank" rel="noopener">https://www.jenkins.io/solutions/pipeline/</a>, </p>
<p>Using <code>blue ocean</code> to setup pipeline from github need personal access token (must check out repo and user options):<br><a href="https://www.youtube.com/watch?v=FhDomw6BaHU" target="_blank" rel="noopener">https://www.youtube.com/watch?v=FhDomw6BaHU</a></p>
<p>In Jenkins UI, go to pipeline syntax then <code>declarative directive generator</code>, it will help you generate pipeline code for declarative pipeline:<br><a href="https://www.jenkins.io/doc/book/pipeline/getting-started/#directive-generator" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/getting-started/#directive-generator</a></p>
<p>This is just a basic structure demo:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">  <span class="comment">// default agent specify</span></span><br><span class="line">  agent any</span><br><span class="line">  <span class="comment">// pipeline level env var</span></span><br><span class="line">  environment &#123;</span><br><span class="line">    <span class="comment">// you can put release number here</span></span><br><span class="line">    RELEASE = <span class="string">'1.1.3'</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// can have multiple stages</span></span><br><span class="line">  stages &#123;</span><br><span class="line">    <span class="comment">// list tool version</span></span><br><span class="line">    stage(<span class="string">'Audit tools'</span>) &#123;</span><br><span class="line">      steps &#123;</span><br><span class="line">          sh <span class="string">'''</span></span><br><span class="line"><span class="string">            git version</span></span><br><span class="line"><span class="string">            docker version</span></span><br><span class="line"><span class="string">          '''</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(<span class="string">'Build'</span>) &#123;</span><br><span class="line">      <span class="comment">// agent specify</span></span><br><span class="line">      agent any</span><br><span class="line">      <span class="comment">// stage level env var</span></span><br><span class="line">      environment &#123;</span><br><span class="line">        USER = <span class="string">'root'</span></span><br><span class="line">      &#125;</span><br><span class="line">      steps &#123;</span><br><span class="line">        echo <span class="string">"this is Build stage"</span></span><br><span class="line">        <span class="comment">// executable in your repo</span></span><br><span class="line">        sh <span class="string">'chmod +x ./build.sh'</span></span><br><span class="line">        <span class="comment">// 把jenkins中一个名为api-key的密匙的值 放入 API_KEY这个环境变量中</span></span><br><span class="line">        <span class="comment">// 且这个API_KEY在block中可见</span></span><br><span class="line">        withCredentials([string(<span class="string">credentialsId:</span> <span class="string">'api-key'</span>, <span class="string">variable:</span> <span class="string">'API_KEY'</span>)]) &#123;</span><br><span class="line">          sh <span class="string">'''</span></span><br><span class="line"><span class="string">              ./build.sh</span></span><br><span class="line"><span class="string">          '''</span></span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="comment">// can have different type</span></span><br><span class="line">    stage(<span class="string">'Test'</span>) &#123;</span><br><span class="line">      environment &#123;</span><br><span class="line">        LOG_LEVEL = <span class="string">"INFO"</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// parallel tasks</span></span><br><span class="line">      parallel &#123;</span><br><span class="line">        <span class="comment">// they can be running on different agent</span></span><br><span class="line">        <span class="comment">// depends on you agent setting</span></span><br><span class="line">        stage(<span class="string">'test1'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">          steps &#123;</span><br><span class="line">            <span class="comment">// show current stage name test1</span></span><br><span class="line">            echo <span class="string">"parallel $&#123;STAGE_NAME&#125;"</span></span><br><span class="line">            <span class="comment">// switch to ./src directory</span></span><br><span class="line">            dir(<span class="string">'./gradle'</span>) &#123;</span><br><span class="line">              sh <span class="string">'''</span></span><br><span class="line"><span class="string">              ./gradlew -p xxx test1</span></span><br><span class="line"><span class="string">              '''</span></span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'test2'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">          steps &#123;</span><br><span class="line">            echo <span class="string">"parallel $&#123;STAGE_NAME&#125;"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'test3'</span>)</span><br><span class="line">        &#123;</span><br><span class="line">          steps &#123;</span><br><span class="line">            echo <span class="string">"parallel $&#123;STAGE_NAME&#125;"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    stage(<span class="string">'Deploy'</span>) &#123;</span><br><span class="line">      <span class="comment">// waiting for user input before deploying</span></span><br><span class="line">      input &#123;</span><br><span class="line">        message <span class="string">"Continue Deploy?"</span></span><br><span class="line">        ok <span class="string">"Do it!"</span></span><br><span class="line">        parameters &#123;</span><br><span class="line">          string(<span class="string">name:</span> <span class="string">'TARGET'</span>, <span class="string">defaultValue:</span> <span class="string">'PROD'</span>, <span class="string">description:</span> <span class="string">'target environment'</span>)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      steps &#123;</span><br><span class="line">        echo <span class="string">"this is Deploy with $&#123;RELEASE&#125;"</span></span><br><span class="line">        <span class="comment">// groovy code block</span></span><br><span class="line">        <span class="comment">// potential security hole, jenkins will not make it easy for you</span></span><br><span class="line">        script &#123;</span><br><span class="line">          <span class="comment">// you need to approve use of these class/method</span></span><br><span class="line">          <span class="keyword">if</span> (Math.random() &gt; <span class="number">0.5</span>) &#123;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> Exception()</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// if fail, this wouldn't get executed</span></span><br><span class="line">        <span class="comment">// write passed into file test-results.txt</span></span><br><span class="line">        writeFile <span class="string">file:</span> <span class="string">'test-results.txt'</span>, <span class="string">text:</span> <span class="string">'passed'</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125; </span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  post &#123;</span><br><span class="line">    <span class="comment">// will always be executed</span></span><br><span class="line">    always &#123;</span><br><span class="line">      echo <span class="string">"prints whether deploy happened or not, success or failure."</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// others like: success, failure, cleanup, etc</span></span><br><span class="line">    success &#123;</span><br><span class="line">      <span class="comment">// archive files</span></span><br><span class="line">      archiveArtifacts <span class="string">'test-results.txt'</span></span><br><span class="line">      <span class="comment">// slack notifation</span></span><br><span class="line">      slackSend <span class="string">channel:</span> <span class="string">'#chengdol-private'</span>,</span><br><span class="line"><span class="symbol">                   message:</span> <span class="string">"Release $&#123;env.RELEASE&#125;, success: $&#123;currentBuild.fullDisplayName&#125;."</span></span><br><span class="line">    &#125;</span><br><span class="line">    failure &#123;</span><br><span class="line">         slackSend <span class="string">channel:</span> <span class="string">'#chengdol-private'</span>,</span><br><span class="line"><span class="symbol">                   color:</span> <span class="string">'danger'</span>,</span><br><span class="line"><span class="symbol">                   message:</span> <span class="string">"Release $&#123;env.RELEASE&#125;, FAILED: $&#123;currentBuild.fullDisplayName&#125;."</span></span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>if you don’t want to checkout SCM in stages that run in same agent, you can use this option:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">options &#123;</span><br><span class="line">  skipDefaultCheckout <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Configure-slack"><a href="#Configure-slack" class="headerlink" title="Configure slack"></a>Configure slack</h2><p>This is a slightly out-of-date video, 其实在各自pipeline中可以自己单独配置token以及选择channel。<br><a href="https://www.youtube.com/watch?v=TWwvxn2-J7E" target="_blank" rel="noopener">https://www.youtube.com/watch?v=TWwvxn2-J7E</a></p>
<p>First install <code>slack notifaction</code> plugin. Then go to <code>Manage Jenkins</code> -&gt; <code>Configure System</code>, scroll down to bottom you will see slack section, see question mark for explanation.</p>
<p>Then go to your target slack channel, select <code>Add an app</code>, search <code>Jenkins CI</code>, then add it to slack, follow the instructions to get the secret token, add this token to Jenkins credentials and use it in above slack configuration.</p>
<p>After all set, try <code>Test connection</code>, you will see message in your slack channel.</p>
<h2 id="Reusable"><a href="#Reusable" class="headerlink" title="Reusable"></a>Reusable</h2><p>Reusable functions and libraries are written in <code>Groovy</code>.</p>
<p>Let’s see some demos:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    <span class="comment">// options</span></span><br><span class="line">    parameters &#123;</span><br><span class="line">        booleanParam(<span class="string">name:</span> <span class="string">'RC'</span>, <span class="string">defaultValue:</span> <span class="literal">false</span>, <span class="string">description:</span> <span class="string">'Is this a Release Candidate?'</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    environment &#123;</span><br><span class="line">        VERSION = <span class="string">"0.1.0"</span>        </span><br><span class="line">        VERSION_RC = <span class="string">"rc.2"</span></span><br><span class="line">    &#125;</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(<span class="string">'Audit tools'</span>) &#123;                        </span><br><span class="line">            steps &#123;</span><br><span class="line">                <span class="comment">// call function</span></span><br><span class="line">                auditTools()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'Build'</span>) &#123;</span><br><span class="line">            environment &#123;</span><br><span class="line">                <span class="comment">// call function</span></span><br><span class="line">                VERSION_SUFFIX = getVersionSuffix()</span><br><span class="line">            &#125;</span><br><span class="line">            steps &#123;</span><br><span class="line">              echo <span class="string">"Building version: $&#123;VERSION&#125; with suffix: $&#123;VERSION_SUFFIX&#125;"</span></span><br><span class="line">              sh <span class="string">'dotnet build -p:VersionPrefix="$&#123;VERSION&#125;" --version-suffix "$&#123;VERSION_SUFFIX&#125;" ./m3/src/Pi.Web/Pi.Web.csproj'</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'Unit Test'</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">              <span class="comment">// switch directory</span></span><br><span class="line">              dir(<span class="string">'./m3/src'</span>) &#123;</span><br><span class="line">                sh <span class="string">'''</span></span><br><span class="line"><span class="string">                    dotnet test --logger "trx;LogFileName=Pi.Math.trx" Pi.Math.Tests/Pi.Math.Tests.csproj</span></span><br><span class="line"><span class="string">                    dotnet test --logger "trx;LogFileName=Pi.Runtime.trx" Pi.Runtime.Tests/Pi.Runtime.Tests.csproj</span></span><br><span class="line"><span class="string">                '''</span></span><br><span class="line">                mstest <span class="string">testResultsFile:</span><span class="string">"**/*.trx"</span>, <span class="string">keepLongStdio:</span> <span class="literal">true</span></span><br><span class="line">              &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'Smoke Test'</span>) &#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">              sh <span class="string">'dotnet ./m3/src/Pi.Web/bin/Debug/netcoreapp3.1/Pi.Web.dll'</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(<span class="string">'Publish'</span>) &#123;</span><br><span class="line">            <span class="comment">// condition</span></span><br><span class="line">            when &#123;</span><br><span class="line">                expression &#123; <span class="keyword">return</span> params.RC &#125;</span><br><span class="line">            &#125; </span><br><span class="line">            steps &#123;</span><br><span class="line">                sh <span class="string">'dotnet publish -p:VersionPrefix="$&#123;VERSION&#125;" --version-suffix "$&#123;VERSION_RC&#125;" ./m3/src/Pi.Web/Pi.Web.csproj -o ./out'</span></span><br><span class="line">                archiveArtifacts(<span class="string">'out/'</span>)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// groovy methods, can run straight groovy code</span></span><br><span class="line">String getVersionSuffix() &#123;</span><br><span class="line">    <span class="keyword">if</span> (params.RC) &#123;</span><br><span class="line">        <span class="keyword">return</span> env.VERSION_RC</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> env.VERSION_RC + <span class="string">'+ci.'</span> + env.BUILD_NUMBER</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">void</span> auditTools() &#123;</span><br><span class="line">    sh <span class="string">'''</span></span><br><span class="line"><span class="string">        git version</span></span><br><span class="line"><span class="string">        docker version</span></span><br><span class="line"><span class="string">        dotnet --list-sdks</span></span><br><span class="line"><span class="string">        dotnet --list-runtimes</span></span><br><span class="line"><span class="string">    '''</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="Shared-library"><a href="#Shared-library" class="headerlink" title="Shared library"></a>Shared library</h2><p>Demo structure and code:<br><a href="https://github.com/sixeyed/jenkins-pipeline-demo-library" target="_blank" rel="noopener">https://github.com/sixeyed/jenkins-pipeline-demo-library</a><br>Invoking shared library at head of jenkins file:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line"><span class="comment">// this is dynamic reference, explicitly specify the library in jenkins file</span></span><br><span class="line">library <span class="string">identifier:</span> <span class="string">'jenkins-pipeline-demo-library@master'</span>, <span class="string">retriever:</span> modernSCM(</span><br><span class="line">        [<span class="string">$class:</span> <span class="string">'GitSCMSource'</span>,</span><br><span class="line"><span class="symbol">        remote:</span> <span class="string">'https://github.com/sixeyed/jenkins-pipeline-demo-library.git'</span>,</span><br><span class="line">        <span class="comment">// if the repo is private, you can have credential here</span></span><br><span class="line"><span class="symbol">        credentialsId:</span> <span class="string">'&lt;credential id&gt;'</span>])</span><br><span class="line"></span><br><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(<span class="string">'Audit tools'</span>) &#123; </span><br><span class="line">            environment &#123;</span><br><span class="line">                <span class="comment">// pass parameters as map</span></span><br><span class="line">                VERSION_SUFFIX = getVersionSuffix <span class="string">rcNumber:</span> env.VERSION_RC, <span class="string">isReleaseCandidate:</span> params.RC</span><br><span class="line">            &#125;</span><br><span class="line">            steps &#123;</span><br><span class="line">                auditTools()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>You can add <code>Global Pipeline Libraries</code> in <code>Configure Jenkins</code> for any pipeline use.<br>这种情况下，可以设置默认的shared library，然后在jenkins file中直接调用相关函数。</p>
<h3 id="Shared-pipelines"><a href="#Shared-pipelines" class="headerlink" title="Shared pipelines"></a>Shared pipelines</h3><p>You can put the shared pipeline into a shared library, for example:<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">library <span class="string">identifier:</span> <span class="string">'jenkins-pipeline-demo-library@master'</span>, </span><br><span class="line"><span class="symbol">        retriever:</span> modernSCM([<span class="string">$class:</span> <span class="string">'GitSCMSource'</span>, <span class="string">remote:</span> <span class="string">'https://github.com/sixeyed/jenkins-pipeline-demo-library.git'</span>])</span><br><span class="line"></span><br><span class="line">crossPlatformBuild <span class="string">repoName:</span> <span class="string">'sixeyed/pi-psod-pipelines'</span>,</span><br><span class="line"><span class="symbol">                   linuxContext:</span> <span class="string">'m4'</span>, </span><br><span class="line"><span class="symbol">                   windowsContext:</span> <span class="string">'m4'</span></span><br></pre></td></tr></table></figure></p>
<p>Shared library is under <code>vars</code> folder. In Groovy, we can add a method named call to a class and then invoke the method without using the name <code>call</code>, crossPlatformBuild is actually the file name, inside file there is a call method.</p>
<h2 id="Multi-branch-pipeline"><a href="#Multi-branch-pipeline" class="headerlink" title="Multi-branch pipeline"></a>Multi-branch pipeline</h2><p><a href="https://www.jenkins.io/doc/book/pipeline/multibranch/" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/multibranch/</a><br>Jenkins automatically discovers, manages and executes Pipelines for branches which contain a Jenkinsfile in source control.</p>
<p>Orphaned item strategy, for deleted branch, you can discard or reserve it.</p>
<h1 id="Pipeline-development-tools"><a href="#Pipeline-development-tools" class="headerlink" title="Pipeline development tools"></a>Pipeline development tools</h1><h2 id="Validating-pipeline-syntax"><a href="#Validating-pipeline-syntax" class="headerlink" title="Validating pipeline syntax"></a>Validating pipeline syntax</h2><p>First enable <code>anonymous read access</code> in <code>Configure Global Security</code>:<br><a href="https://www.jenkins.io/doc/book/pipeline/development/#linter" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/development/#linter</a></p>
<p>Issue curl command:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## if not success, it will show you the overall problems with your jenkins file</span></span><br><span class="line">curl -X POST -F <span class="string">"jenkinsfile=&lt;[jenkins file path]"</span> http://&lt;IP&gt;:8080/pipeline-model-converter/validate</span><br></pre></td></tr></table></figure></p>
<p>Visual Studio code has Jenkins linter plugin, you need to configure it with linter url.</p>
<h2 id="Restart-or-replay"><a href="#Restart-or-replay" class="headerlink" title="Restart or replay"></a>Restart or replay</h2><p>In every build interface, <code>restart from stage</code>, you can select which stage to restart (sometimes stage may fail due to external reason), <code>replay</code>, you can edit your jenkins file and library then rerun, the changes only live in current build (after succeed, check in your updates to source control).</p>
<h2 id="Unit-test"><a href="#Unit-test" class="headerlink" title="Unit test"></a>Unit test</h2><blockquote>
<p><a href="https://github.com/jenkinsci/JenkinsPipelineUnit" target="_blank" rel="noopener">https://github.com/jenkinsci/JenkinsPipelineUnit</a></p>
</blockquote>
<ul>
<li>Supports running pipelines and library methods</li>
<li>Can mock steps and validate calls</li>
</ul>
<h1 id="Jenkins-with-Docker"><a href="#Jenkins-with-Docker" class="headerlink" title="Jenkins with Docker"></a>Jenkins with Docker</h1><p>学习步骤:<br>首先是agent 使用docker，然后master + agent 都使用docker, 最后交由K8s去管理。</p>
<p>这块很有意思，加入容器后就太灵活了，只要有build agent支持docker且已安装，则jenkins就可以把container运行在之上。<br><a href="https://www.jenkins.io/doc/book/pipeline/docker/" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/docker/</a></p>
<p><a href="https://hub.docker.com/r/jenkins/jenkins" target="_blank" rel="noopener">https://hub.docker.com/r/jenkins/jenkins</a><br>you can parallelly run several jenkins version in one machine, for purposes like testing new features, testing upgrade, so on and so forth. But you may need to customize the jenkins docker image and expose to different port.</p>
<ul>
<li>containers as build agents</li>
<li>customizing the build container</li>
<li>using the docker pipeline plugin</li>
</ul>
<p>Jenkins master and slave with docker:<br><a href="https://medium.com/@prashant.vats/jenkins-master-and-slave-with-docker-b993dd031cbd" target="_blank" rel="noopener">https://medium.com/@prashant.vats/jenkins-master-and-slave-with-docker-b993dd031cbd</a></p>
<p>From agent syntax:<br><a href="https://www.jenkins.io/doc/book/pipeline/syntax/#agent" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/syntax/#agent</a><br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">agent &#123;</span><br><span class="line">    docker &#123;</span><br><span class="line">        image <span class="string">'myregistry.com/node'</span></span><br><span class="line">        <span class="comment">// can pass argument to docker run</span></span><br><span class="line">        args  <span class="string">'-v /tmp:/tmp'</span></span><br><span class="line">        <span class="comment">// the node must pre-configured to have docker</span></span><br><span class="line">        label <span class="string">'my-defined-label'</span></span><br><span class="line">        <span class="comment">// optional set the registry to pull image</span></span><br><span class="line">        registryUrl <span class="string">'https://myregistry.com/'</span></span><br><span class="line">        registryCredentialsId <span class="string">'myPredefinedCredentialsInJenkins'</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>If there is no <code>label</code> option, Jenkins will dynamically provisioned on a node and it will fail if no docker installed, you can set docker label to filter:<br><a href="https://www.jenkins.io/doc/book/pipeline/docker/#specifying-a-docker-label" target="_blank" rel="noopener">https://www.jenkins.io/doc/book/pipeline/docker/#specifying-a-docker-label</a></p>
<p>I got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock:<br><a href="https://stackoverflow.com/questions/47854463/docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socke" target="_blank" rel="noopener">https://stackoverflow.com/questions/47854463/docker-got-permission-denied-while-trying-to-connect-to-the-docker-daemon-socke</a></p>
<p>还解决了一个权限的问题，在实验中container默认用户是<code>jenkins</code>，没有root权限无线运行container内部的程序，解决办法是 <code>args  &#39;-u root&#39;</code>在上面的配置中。</p>
<p>此外jenkins会把workspace注入到container中，通过环境变量查找:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sh <span class="string">'printenv'</span></span><br><span class="line">sh <span class="string">'ls -l "$WORKSPACE"</span></span><br></pre></td></tr></table></figure></p>
<p>Additionally, you can use agent with <code>Dockerfile</code> and install Docker Pipeline plugin.</p>
]]></content>
      <categories>
        <category>Jenkins</category>
      </categories>
      <tags>
        <tag>infra</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Set Up K8s Cluster by Kubeadm</title>
    <url>/2018/12/17/k8s-kubeadm-setup/</url>
    <content><![CDATA[<p><strong>Kubernetes version 1.13.2</strong></p>
<p>This article mainly talks about setting up k8s cluster by <code>kubeadm</code> manually. As far as I know there are no coming changes that will significantly impact the validity of these steps.</p>
<h2 id="Cluster-Info"><a href="#Cluster-Info" class="headerlink" title="Cluster Info"></a>Cluster Info</h2><p>I have a 3 nodes bare-metal cluster called <code>myk8s</code> with <strong>CentOS</strong> version 7.5, the <code>/etc/hosts</code> file in each node:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">172.16.158.44    myk8s1.fyre.ibm.com myk8s1</span><br><span class="line">172.16.171.110   myk8s2.fyre.ibm.com myk8s2</span><br><span class="line">172.16.171.227   myk8s3.fyre.ibm.com myk8s3</span><br></pre></td></tr></table></figure></p>
<p>Let’ see the network interface on master node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## ifconfig -a</span></span><br><span class="line"></span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.16.158.44  netmask 255.255.0.0  broadcast 172.16.255.255</span><br><span class="line">        ether 00:16:3e:01:9e:2c  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 1617615790  bytes 203050237209 (189.1 GiB)</span><br><span class="line">        RX errors 0  dropped 1  overruns 0  frame 0</span><br><span class="line">        TX packets 436  bytes 50037 (48.8 KiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line"></span><br><span class="line">eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 9.30.97.218  netmask 255.255.254.0  broadcast 9.30.97.255</span><br><span class="line">        ether 00:20:09:1e:61:da  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 13350021  bytes 1424223654 (1.3 GiB)</span><br><span class="line">        RX errors 0  dropped 5  overruns 0  frame 0</span><br><span class="line">        TX packets 246436  bytes 45433438 (43.3 MiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h2 id="Configure"><a href="#Configure" class="headerlink" title="Configure"></a>Configure</h2><blockquote>
<p>For <strong>every</strong> node in cluster, following instruction below</p>
</blockquote>
<h3 id="Install-utilities"><a href="#Install-utilities" class="headerlink" title="Install utilities"></a>Install utilities</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum update -y</span><br><span class="line">yum install -y vim</span><br><span class="line">yum install -y git</span><br></pre></td></tr></table></figure>
<h3 id="Disable-firewall"><a href="#Disable-firewall" class="headerlink" title="Disable firewall"></a>Disable firewall</h3><p>Check firewall status and disable it if active<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl status firewalld</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line">systemctl stop firewalld</span><br></pre></td></tr></table></figure>
<h3 id="Install-kubeadm-kubectl-and-kubelet"><a href="#Install-kubeadm-kubectl-and-kubelet" class="headerlink" title="Install kubeadm kubectl and kubelet"></a>Install kubeadm kubectl and kubelet</h3><blockquote>
<p><a href="https://kubernetes.io/docs/setup/independent/install-kubeadm/" target="_blank" rel="noopener">Install kubeadm</a> </p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span><br><span class="line">exclude=kube*</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set SELinux in permissive mode (effectively disabling it)</span></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">'s/^SELINUX=enforcing$/SELINUX=permissive/'</span> /etc/selinux/config</span><br><span class="line"></span><br><span class="line">yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> --now kubelet</span><br></pre></td></tr></table></figure>
<p>Setting SELinux in permissive mode by running <code>setenforce 0</code> and <code>sed ...</code> effectively disables it. This is required to allow containers to access the host filesystem, which is needed by pod networks for example. You have to do this until SELinux support is improved in the kubelet.</p>
<p>Currently installed:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Installed:</span><br><span class="line">  kubeadm.x86_64 0:1.13.3-0               kubectl.x86_64 0:1.13.3-0               kubelet.x86_64 0:1.13.3-0</span><br></pre></td></tr></table></figure></p>
<p>check <code>/etc/sysctl.conf</code> file, for example:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">net.ipv6.conf.all.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.default.disable_ipv6 = 1</span><br><span class="line">net.ipv6.conf.lo.disable_ipv6 = 1</span><br><span class="line">net.ipv4.ip_forward = 0</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>ensure that these 3 options exist and set to 1, because some users on RHEL/CentOS 7 have reported issues with traffic being routed incorrectly due to iptables being bypassed<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure></p>
<p>if these 3 items not set, edit <code>net.ipv4.ip_forward = 1</code> and append <code>net.bridge.bridge-nf-call-ip6tables = 1</code> and <code>net.bridge.bridge-nf-call-iptables = 1</code> in <code>sysctl.conf</code> file</p>
<p>then make sure that the <code>net.bridge.bridge-nf-call</code> is enabled, check if <code>br_netfilter</code> module is loaded. This can be done by running<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">lsmod | grep br_netfilter</span><br></pre></td></tr></table></figure></p>
<p>if not, to load it explicitly call<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">modprobe br_netfilter</span><br></pre></td></tr></table></figure></p>
<p>next run this command to reload setting<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sysctl --system</span><br></pre></td></tr></table></figure></p>
<p>then you can check the final setting:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sysctl -a | grep -E <span class="string">"net.bridge|net.ipv4.ip_forward"</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Install-docker"><a href="#Install-docker" class="headerlink" title="Install docker"></a>Install docker</h3><blockquote>
<p><a href="https://kubernetes.io/docs/setup/cri/#docker" target="_blank" rel="noopener">CRI installation in Kubernetes</a></p>
</blockquote>
<h4 id="Uninstall-old-versions"><a href="#Uninstall-old-versions" class="headerlink" title="Uninstall old versions"></a>Uninstall old versions</h4><p>Older versions of Docker were called docker or docker-engine. If these are installed, uninstall them, along with associated dependencies.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum remove docker \</span><br><span class="line">                  docker-client \</span><br><span class="line">                  docker-client-latest \</span><br><span class="line">                  docker-common \</span><br><span class="line">                  docker-latest \</span><br><span class="line">                  docker-latest-logrotate \</span><br><span class="line">                  docker-logrotate \</span><br><span class="line">                  docker-engine</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p><a href="https://docs.docker.com/install/linux/docker-ce/centos/" target="_blank" rel="noopener">Official Docker installation guides</a></p>
</blockquote>
<h4 id="Install-Docker-CE"><a href="#Install-Docker-CE" class="headerlink" title="Install Docker CE"></a>Install Docker CE</h4><p>currently Docker version <code>18.06.2</code> is recommended, but 1.11, 1.12, 1.13 and 17.03 are known to work as well. Keep track of the latest verified Docker version in the Kubernetes release notes<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## Set up the repository</span></span><br><span class="line">yum install yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"></span><br><span class="line"><span class="comment">## Add docker repository.</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line"><span class="comment">## Install docker ce.</span></span><br><span class="line">yum update &amp;&amp; yum install docker-ce-18.06.2.ce</span><br><span class="line"></span><br><span class="line"><span class="comment">## Create /etc/docker directory.</span></span><br><span class="line">mkdir /etc/docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># Setup daemon.</span></span><br><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line">  <span class="string">"log-driver"</span>: <span class="string">"json-file"</span>,</span><br><span class="line">  <span class="string">"log-opts"</span>: &#123;</span><br><span class="line">    <span class="string">"max-size"</span>: <span class="string">"100m"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"storage-driver"</span>: <span class="string">"overlay2"</span>,</span><br><span class="line">  <span class="string">"storage-opts"</span>: [</span><br><span class="line">    <span class="string">"overlay2.override_kernel_check=true"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">mkdir -p /etc/systemd/system/docker.service.d</span><br><span class="line"></span><br><span class="line"><span class="comment"># Restart docker.</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure></p>
<p>check result<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] docker version</span><br><span class="line">Client:</span><br><span class="line"> Version:           18.06.2-ce</span><br><span class="line"> API version:       1.38</span><br><span class="line"> Go version:        go1.10.3</span><br><span class="line"> Git commit:        6d37f41</span><br><span class="line"> Built:             Sun Feb 10 03:46:03 2019</span><br><span class="line"> OS/Arch:           linux/amd64</span><br><span class="line"> Experimental:      false</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          18.06.2-ce</span><br><span class="line">  API version:      1.38 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.10.3</span><br><span class="line">  Git commit:       6d37f41</span><br><span class="line">  Built:            Sun Feb 10 03:48:29 2019</span><br><span class="line">  OS/Arch:          linux/amd64</span><br><span class="line">  Experimental:     false</span><br></pre></td></tr></table></figure></p>
<h3 id="Disable-swap"><a href="#Disable-swap" class="headerlink" title="Disable swap"></a>Disable swap</h3><p><a href="https://serverfault.com/questions/881517/why-disable-swap-on-kubernetes" target="_blank" rel="noopener"><strong>why we need to disable swap?</strong> </a><br>The idea of Kubernetes is to tightly pack instances to as close to 100% utilized as possible. All deployments should be pinned with CPU/memory limits. So if the scheduler sends a pod to a machine it should never use swap at all. You don’t want to swap since it’ll slow things down. It’s mainly for performance.</p>
<p>in <code>/etc/fstab</code> file, comment out swap setting<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/dev/mapper/centos-swap swap                    swap    defaults        0 0</span><br></pre></td></tr></table></figure></p>
<p>activate new configuration and check<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">swapoff -a</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s3 ~] free -h</span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:           7.6G        189M        5.7G        136M        1.8G        7.0G</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure>
<blockquote>
<p> for <code>worker</code> nodes in cluster, stop here. Continue steps in <code>master</code> node:</p>
</blockquote>
<h2 id="Initialize-kubernetes-cluster"><a href="#Initialize-kubernetes-cluster" class="headerlink" title="Initialize kubernetes cluster"></a>Initialize kubernetes cluster</h2><p>I will use <code>Calico</code> as the container network solution, in master node, run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm init --pod-network-cidr=192.168.0.0/16</span><br></pre></td></tr></table></figure></p>
<p>you can specify the version by using <code>--kubernetes-version v1.13.3</code>, otherwise it will pull latest version from Internet.</p>
<p>you can see the output like this<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">[kubeconfig] Using kubeconfig folder <span class="string">"/etc/kubernetes"</span></span><br><span class="line">[kubeconfig] Writing <span class="string">"admin.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"kubelet.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"controller-manager.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"scheduler.conf"</span> kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-apiserver"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-controller-manager"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-scheduler"</span></span><br><span class="line">[etcd] Creating static Pod manifest <span class="keyword">for</span> <span class="built_in">local</span> etcd <span class="keyword">in</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line"></span><br><span class="line">...</span><br><span class="line">Your Kubernetes master has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of machines by running the following on each node</span><br><span class="line">as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join 9.30.97.218:6443 --token jjkiw2.n478eree0wrr3bmc --discovery-token-ca-cert-hash sha256:79659fb0b3fb0044f382ab5a5e317d4f775e821a61d0df4a401a4cbd8d8c5a7f</span><br></pre></td></tr></table></figure></p>
<p>keep the last command for joining worker node later<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubeadm join 9.30.97.218:6443 --token jjkiw2.n478eree0wrr3bmc --discovery-token-ca-cert-hash sha256:79659fb0b3fb0044f382ab5a5e317d4f775e821a61d0df4a401a4cbd8d8c5a7f</span><br></pre></td></tr></table></figure></p>
<p>then run following command in master node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure></p>
<p>now if you run <code>kubectl version</code>, you will get something like below:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] kubectl version</span><br><span class="line">Client Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;13&quot;, GitVersion:&quot;v1.13.3&quot;, GitCommit:&quot;721bfa751924da8d1680787490c54b9179b1fed0&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2019-02-01T20:08:12Z&quot;, GoVersion:&quot;go1.11.5&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;</span><br><span class="line">Server Version: version.Info&#123;Major:&quot;1&quot;, Minor:&quot;13&quot;, GitVersion:&quot;v1.13.3&quot;, GitCommit:&quot;721bfa751924da8d1680787490c54b9179b1fed0&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2019-02-01T20:00:57Z&quot;, GoVersion:&quot;go1.11.5&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;&#125;</span><br></pre></td></tr></table></figure></p>
<p>let’s check what kind of docker images pulled from network to create the cluster in master<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] docker images</span><br><span class="line">REPOSITORY                           TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">k8s.gcr.io/kube-apiserver            v1.13.3             fe242e556a99        2 weeks ago         181MB</span><br><span class="line">k8s.gcr.io/kube-controller-manager   v1.13.3             0482f6400933        2 weeks ago         146MB</span><br><span class="line">k8s.gcr.io/kube-proxy                v1.13.3             98db19758ad4        2 weeks ago         80.3MB</span><br><span class="line">k8s.gcr.io/kube-scheduler            v1.13.3             3a6f709e97a0        2 weeks ago         79.6MB</span><br><span class="line">k8s.gcr.io/coredns                   1.2.6               f59dcacceff4        3 months ago        40MB</span><br><span class="line">k8s.gcr.io/etcd                      3.2.24              3cab8e1b9802        4 months ago        220MB</span><br><span class="line">k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        14 months ago       742kB</span><br></pre></td></tr></table></figure></p>
<h2 id="Launch-cluster-network"><a href="#Launch-cluster-network" class="headerlink" title="Launch cluster network"></a>Launch cluster network</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## kubectl get pods --all-namespaces</span></span><br><span class="line">NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-86c58d9df4-5dfh9                      0/1     Pending   0          9m30s</span><br><span class="line">kube-system   coredns-86c58d9df4-d9bfm                      0/1     Pending   0          9m30s</span><br><span class="line">kube-system   etcd-myk8s1.fyre.ibm.com                      1/1     Running   0          8m52s</span><br><span class="line">kube-system   kube-apiserver-myk8s1.fyre.ibm.com            1/1     Running   0          8m37s</span><br><span class="line">kube-system   kube-controller-manager-myk8s1.fyre.ibm.com   1/1     Running   0          8m34s</span><br><span class="line">kube-system   kube-proxy-wxjx8                              1/1     Running   0          9m31s</span><br><span class="line">kube-system   kube-scheduler-myk8s1.fyre.ibm.com            1/1     Running   0          8m46s</span><br></pre></td></tr></table></figure>
<p>you can find some pods are not ready, for example <code>coredns-86c58d9df4-5dfh9</code> and <code>coredns-86c58d9df4-d9bfm</code>, also the master node<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] kubectl get nodes</span><br><span class="line">NAME                  STATUS     ROLES    AGE   VERSION</span><br><span class="line">myk8s1.fyre.ibm.com   NotReady   master   11m   v1.13.3</span><br></pre></td></tr></table></figure></p>
<p>it’s time to set up network, you should first figure out which <code>Calico</code> version you need, check kubernetes <a href="https://kubernetes.io/docs/setup/release/notes/" target="_blank" rel="noopener">release note</a>, we see currently it support <code>Calico</code> version 3.3.1:</p>
<p><img src="https://drive.google.com/uc?id=1pl6EV9YwD604U1ItoMKnqlAp0cjwEOAd" alt=""></p>
<p> you can also refer this <a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/#pod-network" target="_blank" rel="noopener">link</a> to install, it’s the same setting as below:<br><img src="https://drive.google.com/uc?id=11R3h2G2oknDcN3sY1cTdwUHQCnxwRysn" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/rbac-kdd.yaml</span><br><span class="line">kubectl apply -f https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml</span><br></pre></td></tr></table></figure>
<p>after applying <code>rbac-kdd.yaml</code> and <code>calico.yaml</code>, now you can see<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## kubectl get pods --all-namespaces</span></span><br><span class="line">NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-node-4vm2c                             2/2     Running   0          45s</span><br><span class="line">kube-system   coredns-86c58d9df4-5dfh9                      1/1     Running   0          37m</span><br><span class="line">kube-system   coredns-86c58d9df4-d9bfm                      1/1     Running   0          37m</span><br><span class="line">kube-system   etcd-myk8s1.fyre.ibm.com                      1/1     Running   0          36m</span><br><span class="line">kube-system   kube-apiserver-myk8s1.fyre.ibm.com            1/1     Running   0          36m</span><br><span class="line">kube-system   kube-controller-manager-myk8s1.fyre.ibm.com   1/1     Running   0          36m</span><br><span class="line">kube-system   kube-proxy-wxjx8                              1/1     Running   0          37m</span><br><span class="line">kube-system   kube-scheduler-myk8s1.fyre.ibm.com            1/1     Running   0          36m</span><br></pre></td></tr></table></figure></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## kubectl get nodes</span></span><br><span class="line">NAME                  STATUS   ROLES    AGE   VERSION</span><br><span class="line">myk8s1.fyre.ibm.com   Ready    master   38m   v1.13.3</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note that I encountered the problem that when join the worker nodes, the <code>calico-node</code> becomes not ready<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## kubectl get pods --all-namespaces</span></span><br><span class="line">NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-node-4vm2c                             1/2     Running   0          11m</span><br><span class="line">kube-system   calico-node-zsbjj                             1/2     Running   0          96s</span><br><span class="line">kube-system   coredns-86c58d9df4-5dfh9                      1/1     Running   0          48m</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>The reason is my master node has multiple <code>eth</code>, I need to specify which one to use in order to be consistent among all nodes.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml</span><br></pre></td></tr></table></figure></p>
<p>delete the previous <code>Calico</code> deployment and then edit and apply yaml file again:</p>
<p><img src="https://drive.google.com/uc?id=1bPLxrrlLLyFvNn6cBdSIJbWpANy-ht4h" alt=""></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@myk8s1 ~] kubectl get pods --all-namespaces</span><br><span class="line">NAMESPACE     NAME                                          READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   calico-node-dpcsp                             2/2     Running   0          6m15s</span><br><span class="line">kube-system   calico-node-gc5hs                             2/2     Running   0          6m15s</span><br><span class="line">kube-system   coredns-86c58d9df4-5dfh9                      1/1     Running   0          81m</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h2 id="Join-worker-nodes"><a href="#Join-worker-nodes" class="headerlink" title="Join worker nodes"></a>Join worker nodes</h2><p>Join worker nodes is pretty easy, run this command on all worker nodes:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">kubeadm join 9.30.97.218:6443 --token jjkiw2.n478eree0wrr3bmc --discovery-token-ca-cert-hash sha256:79659fb0b3fb0044f382ab5a5e317d4f775e821a61d0df4a401a4cbd8d8c5a7f</span><br></pre></td></tr></table></figure></p>
<p>Check node status<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## kubectl get nodes</span></span><br><span class="line">NAME                  STATUS   ROLES    AGE   VERSION</span><br><span class="line">myk8s1.fyre.ibm.com   Ready    master   83m   v1.13.3</span><br><span class="line">myk8s2.fyre.ibm.com   Ready    &lt;none&gt;   36m   v1.13.3</span><br><span class="line">myk8s3.fyre.ibm.com   Ready    &lt;none&gt;   33s   v1.13.3</span><br></pre></td></tr></table></figure></p>
<p>By default, tokens expire after 24 hours. If you are joining a node to the cluster after the current token has expired, you can create a new token by running the following command on the master node<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kubeadm token create</span><br></pre></td></tr></table></figure></p>
<p>If you don’t have the value of <code>--discovery-token-ca-cert-hash</code>, you can get it by running the following command chain on the master node:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openssl x509 -pubkey -<span class="keyword">in</span> /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2&gt;/dev/null | \</span><br><span class="line">   openssl dgst -sha256 -hex | sed <span class="string">'s/^.* //'</span></span><br></pre></td></tr></table></figure></p>
<p>Now a fresh kubernetes cluster with 1 master and 2 worker nodes is created.</p>
]]></content>
      <categories>
        <category>Kubernetes</category>
      </categories>
      <tags>
        <tag>kubernetes</tag>
        <tag>calico</tag>
        <tag>kubeadm</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux Networking PluralSight</title>
    <url>/2019/11/29/linux-networking-pluralsight/</url>
    <content><![CDATA[<p>这篇总结是来自PluralSight上的<code>LPIC-1</code>课程的Network chapter，以及<code>LFCE</code> Advanced Networking training.</p>
<p><strong>Frequently asked Question:</strong><br>What is going on when you hit URL in browser?<br><a href="https://medium.com/@maneesha.wijesinghe1/what-happens-when-you-type-an-url-in-the-browser-and-press-enter-bb0aa2449c1a" target="_blank" rel="noopener">from medium</a><br><a href="https://www.quora.com/What-are-the-series-of-steps-that-happen-when-a-URL-is-requested-from-the-address-field-of-a-browser" target="_blank" rel="noopener">from Quora</a></p>
<p>备注:2020年4月份pluralsight在搞活动，免费注册学习！这次lock down是个机会补补课。</p>
<p>Environment: <code>CentOS 7 Enterprise Linux</code> or <code>RedHat</code></p>
<h2 id="Ip-vs-Ifconfig"><a href="#Ip-vs-Ifconfig" class="headerlink" title="Ip vs Ifconfig"></a>Ip vs Ifconfig</h2><p><code>ifconfig</code> is obsolete, use <code>ip</code> instead.<br>我专门有一篇写的ip command.</p>
<p><code>ipv4</code>: <code>32</code>  bits long, dotted decimal<br><code>ipv6</code>: <code>128</code> bits long, quad hex</p>
<h2 id="Hostname"><a href="#Hostname" class="headerlink" title="Hostname"></a>Hostname</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show full hostname</span></span><br><span class="line">hostname -f</span><br><span class="line"><span class="comment">## node hostname</span></span><br><span class="line">uname -n</span><br><span class="line"></span><br><span class="line"><span class="comment">## query and change the system hostname and related settings</span></span><br><span class="line">hostnamectl</span><br><span class="line"></span><br><span class="line">   Static hostname: halos1.fyre.ibm.com</span><br><span class="line">         Icon name: computer-vm</span><br><span class="line">           Chassis: vm</span><br><span class="line">        Machine ID: f7bbe4af93974cbfa5c55b68c011d41c</span><br><span class="line">           Boot ID: 4e30e7107fa441a9b3ad70d0b784782d</span><br><span class="line">    Virtualization: kvm</span><br><span class="line">  Operating System: Red Hat Enterprise Linux Server 7.6 (Maipo)</span><br><span class="line">       CPE OS Name: cpe:/o:redhat:enterprise_linux:7.6:GA:server</span><br><span class="line">            Kernel: Linux 3.10.0-957.10.1.el7.x86_64</span><br><span class="line">      Architecture: x86-64</span><br><span class="line"></span><br><span class="line"><span class="comment">## show domain name</span></span><br><span class="line">dnsdomainname</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## this will not be persistent</span></span><br><span class="line"><span class="comment">## the static hostname is still unchanged but transient hostname is xxx.example.com</span></span><br><span class="line"><span class="comment">## you can see transient name by hostnamectl</span></span><br><span class="line">hostname xxx.examplel.com</span><br><span class="line"></span><br><span class="line"><span class="comment">## this will be persistent in</span></span><br><span class="line"><span class="comment">## /etc/hostname file</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname xxx.example.com</span><br><span class="line"></span><br><span class="line"><span class="comment">## set pretty hostname which includes '</span></span><br><span class="line"><span class="comment">## /etc/machine-info</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname <span class="string">"xxx'ok.example.com"</span></span><br></pre></td></tr></table></figure>
<p>Notice that the order we add in <code>/etc/hosts</code> file is important!<br>把fully qualified hostname放第一个，然后aliases，否则在一些场景会出问题！<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## /etc/hosts</span></span><br><span class="line">&lt;ip&gt; &lt;fully qualified hostname: FQDN&gt; &lt;aliases&gt;</span><br></pre></td></tr></table></figure></p>
<p>除了local hosts file, 来看看DNS设置, 我有一篇blog讲到了这个。<br><code>dig</code> command (DNS lookup utility)，用来check response and checking hostname from DNS server.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## use default dns server</span></span><br><span class="line">dig www.pluralsight.com </span><br><span class="line"><span class="comment">## use specified dns server, for example, google dns server 8.8.8.8</span></span><br><span class="line">dig www.pluralsight.com @8.8.8.8</span><br></pre></td></tr></table></figure></p>
<p>output:<br><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">&lt;&lt;&gt;&gt;</span> <span class="string">DiG</span> <span class="number">9.9</span><span class="number">.4</span><span class="bullet">-RedHat-9.9.4-61.el7_5.1</span> <span class="string">&lt;&lt;&gt;&gt;</span> <span class="string">www.pluralsight.com</span> <span class="string">@8.8.8.8</span></span><br><span class="line"><span class="string">;;</span> <span class="string">global</span> <span class="attr">options:</span> <span class="string">+cmd</span></span><br><span class="line"><span class="string">;;</span> <span class="string">Got</span> <span class="attr">answer:</span></span><br><span class="line"><span class="string">;;</span> <span class="bullet">-&gt;&gt;HEADER&lt;&lt;-</span> <span class="attr">opcode:</span> <span class="string">QUERY,</span> <span class="attr">status:</span> <span class="string">NOERROR,</span> <span class="attr">id:</span> <span class="number">14726</span></span><br><span class="line"><span class="string">;;</span> <span class="attr">flags:</span> <span class="string">qr</span> <span class="string">rd</span> <span class="string">ra;</span> <span class="attr">QUERY:</span> <span class="number">1</span><span class="string">,</span> <span class="attr">ANSWER:</span> <span class="number">3</span><span class="string">,</span> <span class="attr">AUTHORITY:</span> <span class="number">0</span><span class="string">,</span> <span class="attr">ADDITIONAL:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="string">;;</span> <span class="string">OPT</span> <span class="attr">PSEUDOSECTION:</span></span><br><span class="line"><span class="string">;</span> <span class="attr">EDNS:</span> <span class="attr">version:</span> <span class="number">0</span><span class="string">,</span> <span class="attr">flags:;</span> <span class="attr">udp:</span> <span class="number">512</span></span><br><span class="line"><span class="string">;;</span> <span class="string">QUESTION</span> <span class="attr">SECTION:</span></span><br><span class="line"><span class="string">;www.pluralsight.com.</span>           <span class="string">IN</span>      <span class="string">A</span></span><br><span class="line"></span><br><span class="line"><span class="string">;;</span> <span class="string">ANSWER</span> <span class="attr">SECTION:</span></span><br><span class="line"><span class="string">www.pluralsight.com.</span>    <span class="number">59</span>      <span class="string">IN</span>      <span class="string">CNAME</span>   <span class="string">www.pluralsight.com.cdn.cloudflare.net.</span></span><br><span class="line"><span class="string">www.pluralsight.com.cdn.cloudflare.net.</span> <span class="number">186</span> <span class="string">IN</span> <span class="string">A</span> <span class="number">104.19</span><span class="number">.162</span><span class="number">.127</span></span><br><span class="line"><span class="string">www.pluralsight.com.cdn.cloudflare.net.</span> <span class="number">186</span> <span class="string">IN</span> <span class="string">A</span> <span class="number">104.19</span><span class="number">.161</span><span class="number">.127</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## server now is 8.8.8.8</span></span><br><span class="line"><span class="string">;;</span> <span class="string">Query</span> <span class="attr">time:</span> <span class="number">60</span> <span class="string">msec</span></span><br><span class="line"><span class="string">;;</span> <span class="attr">SERVER:</span> <span class="number">8.8</span><span class="number">.8</span><span class="number">.8</span><span class="comment">#53(8.8.8.8)</span></span><br><span class="line"><span class="string">;;</span> <span class="attr">WHEN:</span> <span class="string">Sun</span> <span class="string">Apr</span> <span class="number">12</span> <span class="number">13</span><span class="string">:03:48</span> <span class="string">PDT</span> <span class="number">2020</span></span><br><span class="line"><span class="string">;;</span> <span class="string">MSG</span> <span class="string">SIZE</span>  <span class="attr">rcvd:</span> <span class="number">132</span></span><br></pre></td></tr></table></figure></p>
<p>Add short format <code>+short</code> to return the IP address only:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">dig +short www.pluralsight.com @8.8.8.8</span><br><span class="line"></span><br><span class="line">www.pluralsight.com.cdn.cloudflare.net.</span><br><span class="line">104.19.161.127</span><br><span class="line">104.19.162.127</span><br></pre></td></tr></table></figure></p>
<h2 id="Network-services"><a href="#Network-services" class="headerlink" title="Network services"></a>Network services</h2><p>04/12/2020 目前我只是查看配置，没有去设置过。</p>
<p>Display and set IP address<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip -4 addr</span><br><span class="line">ip addr show eth0</span><br><span class="line"><span class="comment">## not persist</span></span><br><span class="line">ip addr add 192.168.1.50/24 dev eth0</span><br></pre></td></tr></table></figure></p>
<p>没太明白这些配置的具体用法。<br>Network Manager tool, 这个tool也不是万能的，有的地方不适用, can be used to set persistent change so we will not lost it.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## check status</span></span><br><span class="line">systemctl status NetworkManager</span><br><span class="line"><span class="comment">## if not active, start it</span></span><br><span class="line">systemctl start NetworkManager</span><br><span class="line"></span><br><span class="line"><span class="comment">## nmcli command</span></span><br><span class="line"><span class="comment">## command-line tool for controlling NetworkManager</span></span><br><span class="line"><span class="comment">## show all connections</span></span><br><span class="line">nmcli connection show</span><br><span class="line"><span class="comment">## pretty format</span></span><br><span class="line">nmcli -p connection show eth0</span><br><span class="line"></span><br><span class="line"><span class="comment">## terminal graph interface</span></span><br><span class="line">nmtui</span><br><span class="line"><span class="comment">## then edit a connection, select network interface</span></span><br><span class="line"><span class="comment">## config ipv4 ip address/gateway.</span></span><br><span class="line">systemctl restart network</span><br></pre></td></tr></table></figure></p>
<p>Traditional network service, more flexible and common.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl status network</span><br></pre></td></tr></table></figure></p>
<p>The network configuration is read from scripts under <code>/etc/sysconfig/network-scripts/</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ifcfg-eth0  ifcfg-eth1  ifcfg-lo ...</span><br></pre></td></tr></table></figure></p>
<p>这些文件里面都写好了配置，more details see this link:<br><a href="https://www.computernetworkingnotes.com/rhce-study-guide/network-configuration-files-in-linux-explained.html" target="_blank" rel="noopener">https://www.computernetworkingnotes.com/rhce-study-guide/network-configuration-files-in-linux-explained.html</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TYPE=Ethernet</span><br><span class="line">BOOTPROTO=dhcp</span><br><span class="line">NAME=eth0</span><br><span class="line">DEVICE=eth0</span><br><span class="line">ONBOOT=yes</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>After editing the ifcfg-xx file, bring down and up that interface:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ifdown eth0</span><br><span class="line">ifup eth0</span><br></pre></td></tr></table></figure></p>
<h2 id="Routing"><a href="#Routing" class="headerlink" title="Routing"></a>Routing</h2><p>Display route tables<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ip r</span><br><span class="line"><span class="comment">## route and netstat 每个column的意思更清楚一些</span></span><br><span class="line">netstat -r</span><br><span class="line">route</span><br><span class="line"></span><br><span class="line"><span class="comment">## destination 表示一个ip range, 要出去的packet IP 和 mask 作用之后</span></span><br><span class="line"><span class="comment">## 据destination送去不同的interface</span></span><br><span class="line"><span class="comment">## 如果和mask作用后有多个match, 则去mask最长的那个</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">default         gateway         0.0.0.0         UG    0      0        0 eth1</span><br><span class="line">9.30.94.0       0.0.0.0         255.255.254.0   U     0      0        0 eth1</span><br><span class="line">172.16.0.0      0.0.0.0         255.255.0.0     U     0      0        0 eth0</span><br></pre></td></tr></table></figure></p>
<p>Adding routes, 把所有的找不到routing的traffic全部转到192.168.56.104上去，通过eth0, 比如当前的machine无法访问外网，而192.168.56.104却可以, 但之后192.168.56.104也需要配置成router。</p>
<p>当时在做项目的时候需要去ds ops console查看performance, 但Openshift worker node外界无法直接访问，只能通过infra node的routing才行，于是先用nodePort expose service, 再设置infra node到对应worker node port的映射，最后对外用MASQUERADE。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## this command is not persistent</span></span><br><span class="line"><span class="comment">## default can be format like 192.168.1.0/24</span></span><br><span class="line">ip route add default via 192.168.56.104 dev eth0</span><br></pre></td></tr></table></figure></p>
<p>如果需要make it persist, need to edit <code>/etc/sysconfig/network-scripts/</code> corresponding file eth0, 或者自己添加script，然后重启network <code>systemctl restart network</code>.</p>
<p>Configuring a linux system as router:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## now let's configure machine 192.168.56.104 as a router</span></span><br><span class="line">vim /etc/sysctl.conf</span><br><span class="line"><span class="comment">## add this line to enable ipv4 forward</span></span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line"><span class="comment">## reload</span></span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure></p>
<p>Allowing access to the internet via NAT, so traffic can get back to private network.</p>
<blockquote>
<p>注意routing这部分还没有涉及到firewall, firewall is inactive</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -t nat: working on nat table</span></span><br><span class="line"><span class="comment">## -A POSTROUTING: appending to post routing chain</span></span><br><span class="line"><span class="comment">## -o eth0: outbound via eth0, eth0 connects to internet</span></span><br><span class="line"><span class="comment">## -j MASQUERADE: jump to MASQUERADE rule</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## not persistent, see iptables section below</span></span><br><span class="line">iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</span><br></pre></td></tr></table></figure>
<p>then if you check <code>iptables -t nat -nvL</code> will see the postrouting rule with new line added.</p>
<h2 id="Firewall"><a href="#Firewall" class="headerlink" title="Firewall"></a>Firewall</h2><p>其实很多linux是靠iptables去实现firewall的功能的，见下一节，firewalld service背后改动的也是iptables.</p>
<p>Implement packet filtering (iptables and firewalld both can do this)<br>firewall <code>zone</code>: represent a concept to manage incoming traffic more transparently. The zones are connected to networking interfaces or assigned a range of source addresses. You manage firewall rules for each zone independently.</p>
<p>配置命令类似于kubectl/oc的形式。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment">## show default zone</span></span><br><span class="line">firewall-cmd --get-default-zone</span><br><span class="line"><span class="comment">## show active zones, will see interfaces apply to it</span></span><br><span class="line">firewall-cmd --get-active-zones</span><br><span class="line"><span class="comment">## show available zones</span></span><br><span class="line">firewall-cmd --get-zones</span><br><span class="line"></span><br><span class="line"><span class="comment">## permanently remove interface eth0 from public zone</span></span><br><span class="line">firewall-cmd --permanent --zone=public --remove-interface=eth0</span><br><span class="line"><span class="comment">## permanently add eth0 to external zone</span></span><br><span class="line">firewall-cmd --permanent --zone=external --add-interface=eth0</span><br><span class="line"><span class="comment">## permanently add eth1 to internal zone</span></span><br><span class="line">firewall-cmd --permanent --zone=internal --add-interface=eth1</span><br><span class="line"></span><br><span class="line"><span class="comment">## change default zone</span></span><br><span class="line">firewall-cmd --<span class="built_in">set</span>-default-zone=external</span><br><span class="line"><span class="comment">## after updating, restart to take effect</span></span><br><span class="line">systemctl restart firewalld</span><br></pre></td></tr></table></figure></p>
<p>后面主要讲了firewall的配置，可以对不同的zone添加或删除services, ports等，service的默认配置文件在<code>/usr/lib/firewalld/services</code>目录，但是自己创建的service文件在<code>/etc/firewalld/services/</code>。</p>
<h2 id="Iptables"><a href="#Iptables" class="headerlink" title="Iptables"></a>Iptables</h2><p>用iptables也可以实现firewall的功能, packet filtering</p>
<p>Using iptables toolset<br>注意， 可以自己添加rules去加功能，但不要去更改default policy ACCEPT。否则出了意外都不能连接上了。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## list 3 basic chain: INPUT, FORWARD, OUTPUT</span></span><br><span class="line"><span class="comment">## forward is routing function</span></span><br><span class="line">iptables -L</span><br><span class="line"><span class="comment">## v: verbose, </span></span><br><span class="line"><span class="comment">## n: numberic data</span></span><br><span class="line">iptables -nvL</span><br><span class="line"></span><br><span class="line"><span class="comment">## save current config</span></span><br><span class="line"><span class="comment">## can edit in this output file</span></span><br><span class="line">iptables-save &gt; orgset</span><br><span class="line">iptables-restore &lt; orgset</span><br><span class="line"></span><br><span class="line"><span class="comment">## rules 类似于switch中的case，从上到下match，顺序很重要！</span></span><br><span class="line"><span class="comment">## -A: append</span></span><br><span class="line"><span class="comment">## accept any traffic to local interface</span></span><br><span class="line">iptables -A INPUT -i lo -j ACCEPT</span><br><span class="line"><span class="comment">## allow ssh in through destination port 22</span></span><br><span class="line"><span class="comment">## -dport: destination port</span></span><br><span class="line">iptables -A INPUT -p tcp --dport 22 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment">## drop if not match </span></span><br><span class="line"><span class="comment">## 这个放最后，否则一来就drop了</span></span><br><span class="line">iptables -A INPUT -j DROP</span><br><span class="line"><span class="comment">## not acting as a router</span></span><br><span class="line">iptables -A FORWARD -j DROP</span><br><span class="line"></span><br><span class="line"><span class="comment">## -I: insert</span></span><br><span class="line"><span class="comment">## 把这个rule加到INPUT chain的第一行</span></span><br><span class="line">iptables -I INPUT 1 -p tcp --dport 80 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment">## clear rules in all chains</span></span><br><span class="line">iptables -F [chain name]</span><br></pre></td></tr></table></figure></p>
<p>来看看iptables service的使用，变成systemctl service的形式了，使用上更正规一些。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y iptables-services</span><br></pre></td></tr></table></figure></p>
<p>在<code>/etc/sysconfig</code>目录下，有<code>iptables</code> and <code>iptables-config</code> files, If set these two values as <code>yes</code>, then iptables will save the config automatically in <code>iptables</code> file, easy to maintain.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Save current firewall rules on stop.</span></span><br><span class="line"><span class="comment">#   Value: yes|no,  default: no</span></span><br><span class="line"><span class="comment"># Saves all firewall rules to /etc/sysconfig/iptables if firewall gets stopped</span></span><br><span class="line"><span class="comment"># (e.g. on system shutdown).</span></span><br><span class="line">IPTABLES_SAVE_ON_STOP=<span class="string">"yes"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save current firewall rules on restart.</span></span><br><span class="line"><span class="comment">#   Value: yes|no,  default: no</span></span><br><span class="line"><span class="comment"># Saves all firewall rules to /etc/sysconfig/iptables if firewall gets</span></span><br><span class="line"><span class="comment"># restarted.</span></span><br><span class="line">IPTABLES_SAVE_ON_RESTART=<span class="string">"yes"</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Monitoring-Network"><a href="#Monitoring-Network" class="headerlink" title="Monitoring Network"></a>Monitoring Network</h2><p>Measure network performance, bottleneck<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 可以查看途径的IP，比如VPN看路径是不是正确的</span></span><br><span class="line">tracepath www.google.com</span><br></pre></td></tr></table></figure></p>
<p><code>traceroute</code> vs <code>tracepath</code>:<br><a href="https://askubuntu.com/questions/114264/what-are-the-significant-differences-between-tracepath-and-traceroute" target="_blank" rel="noopener">https://askubuntu.com/questions/114264/what-are-the-significant-differences-between-tracepath-and-traceroute</a><br>some option of <code>traceroute</code> need root privilege, and has more features then <code>tracepath</code>.</p>
<p>Display network status<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## 显示有多少error, drop packets来看是不是网络有问题</span></span><br><span class="line">ip -s -h link</span><br><span class="line">ip -s -h link show eth0</span><br></pre></td></tr></table></figure></p>
<p><code>netstat</code> command can also do the same thing.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -i</span><br><span class="line"></span><br><span class="line">Kernel Interface table</span><br><span class="line">Iface             MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg</span><br><span class="line">eth0             1500 16008695      0      5 0       8446165      0      0      0 BMRU</span><br><span class="line">eth1             1500   461914      0     12 0         35082      0      0      0 BMRU</span><br><span class="line">lo              65536   277761      0      0 0        277761      0      0      0 LRU</span><br></pre></td></tr></table></figure></p>
<p>还介绍了一下<code>sysstat</code> command，需要yum安装，安装之后它会收集每日的系统历史数据供查看。这也是一个很重要的系统监控工具。<br>还有一个command <code>nmap</code>, 用来scan ports:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y nmap</span><br><span class="line"><span class="comment">## check what ports in your system is opening</span></span><br><span class="line">nmap scanme.nmap.org</span><br><span class="line"><span class="comment">## list interface and routes information</span></span><br><span class="line">nmap -iflist</span><br></pre></td></tr></table></figure></p>
<p>Can use <code>ss</code> command (similar to <code>netstat</code>) to show listening tcp ports:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## show listening ipv4 tcp sockets in numeric format</span></span><br><span class="line">ss -ltn -4</span><br><span class="line"></span><br><span class="line"><span class="comment">## *:* means listening from any address and any port</span></span><br><span class="line">State      Recv-Q Send-Q                  Local Address:Port                                 Peer Address:Port              </span><br><span class="line">LISTEN     0      64                                  *:2049                                            *:*                  </span><br><span class="line">LISTEN     0      128                                 *:36168                                           *:*                  </span><br><span class="line">LISTEN     0      128                                 *:111                                             *:* </span><br><span class="line"></span><br><span class="line"><span class="comment">## list current active connections</span></span><br><span class="line">ss -t</span><br><span class="line"></span><br><span class="line"><span class="comment">## 9.30.166.179:ssh is my Mac IP, it ssh to current host</span></span><br><span class="line"><span class="comment">## 这里State is ESTAB, 如果握手没回应，则会显示SYN-SENT</span></span><br><span class="line">State      Recv-Q Send-Q                Local Address:Port                                 Peer Address:Port                </span><br><span class="line">ESTAB      0      128                    9.30.166.179:ssh                                  9.160.91.147:62991                </span><br><span class="line">ESTAB      0      0                      9.30.166.179:54556                               54.183.140.32:https</span><br></pre></td></tr></table></figure></p>
<h1 id="Network-Basic"><a href="#Network-Basic" class="headerlink" title="Network Basic"></a>Network Basic</h1><p>这里主要是通过做实验，把基本概念过了一遍。用Vitual Box 设置实验环境，在虚拟机中安装使用wireshark, tcpdump很清晰，没有其他干扰信息。设置实验环境时，可以有1主2从，主机可以访问外界(Adapter1 设置NAT, Adapter2/3 设置Internal Network)，从机可以访问主机，间接实现外部访问(各自的Adapter1 设置Internal Network连接主机的Internal Network). 然后可以进行各种ip, route, iptables的实验了。</p>
<p><code>Network topology</code>: LAN, WAN (bus, star, ring, full mesh)<br><code>Network devices</code>: adapter, switch, router, firewall<br><code>OSI</code> model</p>
<p>subnetting: a logically grouped collection of devices on the same network<br>subnet mask: network portion / host portion<br>special address:<br>  network address (all 0 in host portion)<br>  broadcast (all 1 in host portion)<br>  loopback 127.0.0.1<br>classful subnet: class A/B/C, they are inefficient</p>
<p><code>VLSM</code>: variable length subet mask, for example x.x.x/25<br><code>NAT</code>: one to one, many to one map<br><code>ARP</code>: address resolution protocol (IP -&gt; MAC), broadcast on bus to see who has MAC for a particular IP<br><code>DNS</code>: map hostname to IP, UDP protocol</p>
<p><code>IP packet</code>: can be fragmented and reassembled by router and host. fragments其实很影响throughput，因为每个IP packet都有header。还要注意有的IP加密 (VPN)会额外增加IP packet的长度，造成fragments.<br><code>TTL</code>: time to live in IP header, this is how <code>traceroute</code> works</p>
<p><code>Routing Table</code>:<br>static: path defined by admin<br>dynamic: path programmatically defined, routing protocol <a href="https://en.wikipedia.org/wiki/Quagga_(software" target="_blank" rel="noopener">software Quagga on Linux</a>)</p>
<p><code>TCP</code>:<br>  connection oriented: three way handshake<br>  connection establishment/termination<br>  data transfer<br>  ports: system can have more than one IP, ports are only unique per IP<br>         well know port: 0-1024<br>  flow control: maintained by receiver<br>  congestion control: the sender slow down<br>  error detection and retransmission</p>
<p><code>UDP</code>:<br>  send it and forget it<br>  DNS (dig, host commands)<br>  VoIP</p>
<ol>
<li><p>setup http service on server host</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y httpd</span><br><span class="line"><span class="comment">## if firewall is on</span></span><br><span class="line">firewall-cmd --permanent --add-port=80/tcp</span><br><span class="line">firewall-cmd --reload</span><br><span class="line"><span class="comment">## set page content</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"hello world"</span> &gt; /var/www/html/index.html</span><br><span class="line">systemctl <span class="built_in">enable</span> httpd</span><br><span class="line">systemctl start httpd</span><br></pre></td></tr></table></figure>
</li>
<li><p>get the web page from other host</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget http://&lt;ip or hostname&gt;/index.html</span><br></pre></td></tr></table></figure>
</li>
<li><p>install <a href="https://danielmiessler.com/study/tcpdump/" target="_blank" rel="noopener">tcpdump</a> wireshark on other host</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y tcpdump wireshark wireshark-gnome</span><br><span class="line"><span class="comment">## if you have desktop in linux, start wireshark</span></span><br><span class="line">wireshark &amp;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>Check the arp cache<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## '?' means stale</span></span><br><span class="line">arp -a</span><br><span class="line">ip neighbor</span><br><span class="line"><span class="comment">## delete arp cache</span></span><br><span class="line">arp -d 192.168.1.1</span><br></pre></td></tr></table></figure></p>
<p>specify size of the data and ping total number:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## -c 1: ping once</span></span><br><span class="line"><span class="comment">## -s 1472: 1472 bytes long (this is not total length of IP, it will append header)</span></span><br><span class="line"><span class="comment">## so maybe exceed 1500 MTU and then packet will be fragmented</span></span><br><span class="line">ping -c 1 -s 1472 192.168.1.1</span><br><span class="line"><span class="comment">## -t set TTL</span></span><br><span class="line">ping -c 2 -t 5 192.168.0.1</span><br></pre></td></tr></table></figure></p>
<p>Create a large file to transfer:<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## fast allocate file</span></span><br><span class="line"><span class="comment">## -l5G: length of file is 5G</span></span><br><span class="line">fallocate -l5G test.bin</span><br><span class="line"><span class="comment">## then using scp to copy from network</span></span><br><span class="line">scp ...</span><br><span class="line"><span class="comment">## you can check wireshark to see the tcp window scaling graph</span></span><br><span class="line"><span class="comment">## will see slow start and speed up</span></span><br></pre></td></tr></table></figure></p>
<p>Traffic control setting<br>用来模拟网络不好的情况, 如用scp在传输文件，设置tc bad performance，然后恢复，会发现transmission rate提高了。可以查看wireshark window scaling graph 和 IO graph.<br><a href="https://blog.csdn.net/pansaky/article/details/88801249" target="_blank" rel="noopener">Linux 下 TC 命令原理及详解</a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tc qdisc add dev eth1 root netem delay 3000m loss 5%</span><br><span class="line"><span class="comment">## remove the above policy</span></span><br><span class="line">tc qdisc del dev eth1 root</span><br></pre></td></tr></table></figure></p>
<p>let’s see the statistic:<br>After performance recover, TCP congestion window size enlarge quickly:<br><img src="https://drive.google.com/uc?id=1DqpLc4_K5ZSjSSSBKIqUEYuSOrXWdra_" alt=""></p>
<p>This is IO graph, shows TCP window size and update points:<br><img src="https://drive.google.com/uc?id=1soVs4XwDeH6A6D9CG6ZK4WS_jSAnVxPI" alt=""><br><img src="https://drive.google.com/uc?id=1QRlirLbMDaA2p_XgEPnvA1fZn98qLJ_M" alt=""></p>
<h1 id="Network-Troubleshooting"><a href="#Network-Troubleshooting" class="headerlink" title="Network Troubleshooting"></a>Network Troubleshooting</h1><p><code>Network is not reachable</code>. For example, cannot ping through.<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">## check subnet and gateway, then</span></span><br><span class="line">ip route</span><br><span class="line"><span class="comment">## check interface, state DOWN? NO-CARRIER? then</span></span><br><span class="line">ip addr</span><br><span class="line"><span class="comment">## check MAC mapping in layer 2, then</span></span><br><span class="line">arp -a</span><br><span class="line"><span class="comment">## layer1 is ok? link detected no?</span></span><br><span class="line"><span class="comment">## 注意虚拟机是没有这个统计的！真实网卡才有，之前遇到过这个情景了</span></span><br><span class="line"><span class="comment">## port speed 也可以查看</span></span><br><span class="line">ethtool eth0</span><br></pre></td></tr></table></figure></p>
<p><code>No route to host</code>，比如在scp的时候，这时去host server上看一下port是不是打开的<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ss -lnt4</span><br></pre></td></tr></table></figure></p>
<p>wireshark看一下client端的情况，发现可能是firewall issue! 端口被屏蔽了。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title>Yum and Rpm Management 101</title>
    <url>/2019/03/26/linux-yum-rpm-management/</url>
    <content><![CDATA[<p>OK, This article is a summary from IBM developer <a href="https://developer.ibm.com/tutorials/l-lpic1-102-5/" target="_blank" rel="noopener">Linux series</a> that contains something I haven’t realized and history information about YUM and RPM.</p>
<h3 id="Introducing-package-management"><a href="#Introducing-package-management" class="headerlink" title="Introducing package management"></a>Introducing package management</h3><p>In the past, many Linux programs were distributed as source code, which a user would build into the required program or set of programs, along with the required man pages, configuration files, and so on. Nowadays, most Linux distributors use prebuilt programs or sets of programs called <em>packages</em>, which ship ready for installation on that distribution. In this tutorial, you will learn about <em>package management tools</em> that help you install, update, and remove packages. This tutorial focuses on the <strong>Red Hat Package Manager (RPM)</strong>, which was developed by Red Hat, as well as the <strong>Yellowdog Updater Modified (YUM)</strong>, which was originally developed to manage Red Hat Linux systems at Duke University’s Physics department. Another tutorial in this series, “<a href="https://developer.ibm.com/tutorials/l-lpic1-102-4/" target="_blank" rel="noopener">Learn Linux 101: Debian package management</a>,” covers the package management tools used on Debian systems.</p>
<h3 id="Package-managers"><a href="#Package-managers" class="headerlink" title="Package managers"></a>Package managers</h3><p>RPM, YUM, and APT (for Debian systems) have many similarities. All can install and remove packages. Information about installed packages is kept in a database. All have basic command-line functionality, while additional tools can provide more user-friendly interfaces. All can retrieve packages from the Internet.</p>
<p>When you install a Linux system, you typically install a large selection of packages. The set may be customized to the intended use of the system, such as a server, desktop, or developer workstation. And at some time you will probably need to install new packages for added functionality, update the packages you have, or even remove packages that you no longer need or that have been made obsolete by newer packages. Let’s look at how you do these tasks, and at some of the related challenges such as finding which package might contain a particular command.</p>
<h4 id="RPM"><a href="#RPM" class="headerlink" title="RPM"></a>RPM</h4><p>Red Hat introduced RPM in 1995. RPM is now the package management system used for packaging in the Linux Standard Base (LSB). The rpm command options are grouped into three subgroups for:</p>
<ul>
<li>Querying and verifying packages</li>
<li>Installing, upgrading, and removing packages</li>
<li>Performing miscellaneous functions</li>
</ul>
<h4 id="YUM"><a href="#YUM" class="headerlink" title="YUM"></a>YUM</h4><p>YUM adds automatic updates and package management, including dependency management, to RPM systems. In addition to understanding the installed packages on a system, YUM is like the Debian Advanced Packaging Tool (APT) in that it works with repositories, which are collections of packages and are typically accessible over a network connection.</p>
<h3 id="Install-RPM-packages"><a href="#Install-RPM-packages" class="headerlink" title="Install RPM packages"></a>Install RPM packages</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@attic‑f21 ~rpm ‑i  gcc‑gfortran‑4.9.2‑6.fc21.x86_64.rpm </span><br><span class="line">error: Failed dependencies:</span><br><span class="line">    libquadmath‑devel = 4.9.2‑6.fc21 is needed by gcc‑gfortran‑4.9.2‑6.fc21.x86_64</span><br></pre></td></tr></table></figure>
<p>One good thing is that you can give the rpm command a list of packages to install and it will install them all in the right order if all dependencies are satisfied. So you at least don’t have to manually install each piece in the right order.</p>
<p><a href="https://unix.stackexchange.com/questions/158244/what-is-the-difference-between-i686-and-x86-64-packages" target="_blank" rel="noopener">What is the difference between i686 and x86_64 packages?</a><br>Technically, i686 is actually a 32-bit instruction set (part of the x86 family line), while x86_64 is a 64-bit instruction set (also referred to as amd64).</p>
<p>let’s see the yum install output in my machine:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">Local-Base                                                                                | 2.0 kB  00:00:00     </span><br><span class="line">Local-Extras                                                                              | 2.9 kB  00:00:00     </span><br><span class="line">Local-Optional                                                                            | 2.0 kB  00:00:00     </span><br><span class="line">Local-Supplementary                                                                       | 2.0 kB  00:00:00     </span><br><span class="line">(1/6): Local-Base/updateinfo                                                              | 3.2 MB  00:00:00     </span><br><span class="line">(2/6): Local-Supplementary/primary                                                        |  99 kB  00:00:00     </span><br><span class="line">(3/6): Local-Optional/updateinfo                                                          | 2.3 MB  00:00:00     </span><br><span class="line">(4/6): Local-Optional/primary                                                             | 5.0 MB  00:00:00     </span><br><span class="line">(5/6): Local-Supplementary/updateinfo                                                     |  69 kB  00:00:00     </span><br><span class="line">(6/6): Local-Base/primary                                                                 |  34 MB  00:00:00     </span><br><span class="line">Local-Base                                                                                           23907/23907</span><br><span class="line">Local-Optional                                                                                       17526/17526</span><br><span class="line">Local-Supplementary                                                                                      310/310</span><br><span class="line">Resolving Dependencies</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package vim-enhanced.x86_64 2:7.4.160-5.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: vim-common = 2:7.4.160-5.el7 for package: 2:vim-enhanced-7.4.160-5.el7.x86_64</span><br><span class="line">--&gt; Processing Dependency: libgpm.so.2()(64bit) for package: 2:vim-enhanced-7.4.160-5.el7.x86_64</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package gpm-libs.x86_64 0:1.20.7-5.el7 will be installed</span><br><span class="line">---&gt; Package vim-common.x86_64 2:7.4.160-5.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: vim-filesystem for package: 2:vim-common-7.4.160-5.el7.x86_64</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package vim-filesystem.x86_64 2:7.4.160-5.el7 will be installed</span><br><span class="line">--&gt; Finished Dependency Resolution</span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">=================================================================================================================</span><br><span class="line"> Package                      Arch                 Version                        Repository                Size</span><br><span class="line">=================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> vim-enhanced                 x86_64               2:7.4.160-5.el7                Local-Base               1.0 M</span><br><span class="line">Installing for dependencies:</span><br><span class="line"> gpm-libs                     x86_64               1.20.7-5.el7                   Local-Base                32 k</span><br><span class="line"> vim-common                   x86_64               2:7.4.160-5.el7                Local-Base               5.9 M</span><br><span class="line"> vim-filesystem               x86_64               2:7.4.160-5.el7                Local-Base                10 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">=================================================================================================================</span><br><span class="line">Install  1 Package (+3 Dependent packages)</span><br><span class="line"></span><br><span class="line">Total download size: 7.0 M</span><br><span class="line">Installed size: 23 M</span><br><span class="line"></span><br><span class="line">Is this ok [y/d/N]: y</span><br><span class="line">Downloading packages:</span><br><span class="line">(1/4): gpm-libs-1.20.7-5.el7.x86_64.rpm                                                   |  32 kB  00:00:00     </span><br><span class="line">(2/4): vim-enhanced-7.4.160-5.el7.x86_64.rpm                                              | 1.0 MB  00:00:00</span><br><span class="line">(3/4): vim-filesystem-7.4.160-5.el7.x86_64.rpm                                            |  10 kB  00:00:00</span><br><span class="line">(4/4): vim-common-7.4.160-5.el7.x86_64.rpm                                                | 5.9 MB  00:00:00</span><br><span class="line">-----------------------------------------------------------------------------------------------------------------</span><br><span class="line">Total                                                                             55 MB/s | 7.0 MB  00:00:00</span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">Warning: RPMDB altered outside of yum.</span><br><span class="line">** Found 1 pre-existing rpmdb problem(s), &apos;yum check&apos; output follows:</span><br><span class="line">mokutil-15-1.el7.x86_64 is a duplicate with mokutil-12-1.el7.x86_64</span><br><span class="line">  Installing : gpm-libs-1.20.7-5.el7.x86_64                                                                  1/4</span><br><span class="line">  Installing : 2:vim-filesystem-7.4.160-5.el7.x86_64                                                         2/4</span><br><span class="line">  Installing : 2:vim-common-7.4.160-5.el7.x86_64                                                             3/4</span><br><span class="line">  Installing : 2:vim-enhanced-7.4.160-5.el7.x86_64                                                           4/4</span><br><span class="line">Local-Base/productid                                                                      | 2.1 kB  00:00:00</span><br><span class="line">Local-Supplementary/productid                                                             | 2.1 kB  00:00:00</span><br><span class="line">  Verifying  : 2:vim-enhanced-7.4.160-5.el7.x86_64                                                           1/4</span><br><span class="line">  Verifying  : 2:vim-common-7.4.160-5.el7.x86_64                                                             2/4</span><br><span class="line">  Verifying  : 2:vim-filesystem-7.4.160-5.el7.x86_64                                                         3/4</span><br><span class="line">  Verifying  : gpm-libs-1.20.7-5.el7.x86_64                                                                  4/4</span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  vim-enhanced.x86_64 2:7.4.160-5.el7</span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  gpm-libs.x86_64 0:1.20.7-5.el7    vim-common.x86_64 2:7.4.160-5.el7    vim-filesystem.x86_64 2:7.4.160-5.el7</span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure></p>
<p>Here we see yum find <code>x86_64</code> version of vim in <code>Local-Base</code> repository. Sometimes you will usually want the latest version of a package, but you can provide additional qualifications if you need an earlier version, or the <code>i686</code> version instead of the <code>x86_64</code> version. See the section on specifying package names in the man pages for the yum command.</p>
<h3 id="Package-locations"><a href="#Package-locations" class="headerlink" title="Package locations"></a>Package locations</h3><p>Where do the packages come from? How does yum know where to download packages from? The starting point is the <code>/etc/yum.repos.d/</code> directory, which usually contains several repo files. This is the default location for repository information, but other locations may be specified in the YUM configuration file, normally <code>/etc/yum.conf</code>. </p>
<p>In the Fyre machine, there is a <code>devit-rh7-x86_64.repo</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Base OS packages</span><br><span class="line">[Local-Base]</span><br><span class="line">name=Fyre Local OS repository</span><br><span class="line">baseurl=http://fyreyum1.fyre.ibm.com/redhat/yum/server/7/7Server/x86_64/os</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line"></span><br><span class="line">[Local-Supplementary]</span><br><span class="line">name=Fyre Local Supplementary repository</span><br><span class="line">baseurl=http://fyreyum1.fyre.ibm.com/redhat/yum/server/7/7Server/x86_64/supplementary/os</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line"></span><br><span class="line">[Local-Optional]</span><br><span class="line">name=Fyre Local Optional repository</span><br><span class="line">baseurl=http://fyreyum1.fyre.ibm.com/redhat/yum/server/7/7Server/x86_64/optional/os</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line"></span><br><span class="line">[Local-Extras]</span><br><span class="line">name=Fyre Local Extras repository</span><br><span class="line">baseurl=http://fyreyum1.fyre.ibm.com/redhat/yum/server/7/7Server/x86_64/extras/os</span><br><span class="line">gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br></pre></td></tr></table></figure></p>
<p>YUM and RPM use a local database to determine what packages are installed. The metadata about packages that is stored in the local database is retrieved from the enabled repositories. Although you will seldom need to worry about the local database, you use the command <code>yum clean all</code> to clean out various parts of the locally stored information and <code>yum makecache</code> to create the information in your local database for the enabled repos. You might do this if you change your repo configuration, for example.</p>
<h3 id="Removing-RPM-packages"><a href="#Removing-RPM-packages" class="headerlink" title="Removing RPM packages"></a>Removing RPM packages</h3><p>The RPM system does not maintain information on packages that were automatically added, so there is no trivial way to find out which dependencies might also be removed. </p>
<p>If you use YUM and if the package you are trying to remove is a <em>dependent package</em> for some other installed packages, then YUM will offer to remove those as well as the dependent package. (This is different from <code>yum autoremove</code>)</p>
<h3 id="Upgrading-RPM-packages"><a href="#Upgrading-RPM-packages" class="headerlink" title="Upgrading RPM packages"></a>Upgrading RPM packages</h3><p>You can use <code>yum update</code> to update your entire system, or you can specify a single package or a wildcard specification. Listing 8 shows how to update all the packages whose names start with “pop”. Note the use of apostrophes to prevent shell expansion of the “*”.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum update &apos;pop*&apos;</span><br></pre></td></tr></table></figure></p>
<p><a href="[https://unix.stackexchange.com/questions/55777/in-centos-what-is-the-difference-between-yum-update-and-yum-upgrade](https://unix.stackexchange.com/questions/55777/in-centos-what-is-the-difference-between-yum-update-and-yum-upgrade">what is the difference between yum update and yum upgrade?</a><br>)<br><code>yum upgrade</code> forces the removal of obsolete packages, while <code>yum update</code> may or may not also do this. The removal of obsolete packages can be risky, as it may remove packages that you use.<br>This makes <code>yum update</code> the safer option.</p>
<h3 id="Querying-RPM-packages"><a href="#Querying-RPM-packages" class="headerlink" title="Querying RPM packages"></a>Querying RPM packages</h3><p>In our examples you saw that installing an rpm with the <code>rpm</code> command requires the full name of the package file (or URL), such as <code>gcc-gfortran-4.9.2-6.fc21.x8664.rpm</code>. On the other hand, installing with <code>yum</code>, or removing an rpm with either command requires only the package name, such as <code>gcc-gfortran</code>. As with APT, YUM maintains an internal database of your installed packages, allowing you to manipulate installed packages using the package name.</p>
<p>Note that you need to have root authority to install, upgrade, or remove packages, but non-root users can perform queries against the rpm database.</p>
<p>Basic query asks if package is installed, if so, show version number:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mycentctl1 ~]# rpm -q bind-utils</span><br><span class="line">bind-utils-9.9.4-73.el7_6.x86_64</span><br><span class="line"></span><br><span class="line">[root@mycentctl1 ~]# rpm -q ansible</span><br><span class="line">package ansible is not installed</span><br><span class="line"></span><br><span class="line">[root@mycentctl1 ~]# yum list bind-utils</span><br><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">Installed Packages</span><br><span class="line">bind-utils.x86_64                                    32:9.9.4-73.el7_6                                    @Local-Base</span><br><span class="line"></span><br><span class="line">[root@mycentctl1 ~]# yum list ansible</span><br><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">Available Packages</span><br><span class="line">ansible.noarch                                       2.4.2.0-2.el7                                       Local-Extras</span><br></pre></td></tr></table></figure></p>
<p>Display info about a package:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mycentctl1 ~]# yum info bind-utils</span><br><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">Installed Packages</span><br><span class="line">Name        : bind-utils</span><br><span class="line">Arch        : x86_64</span><br><span class="line">Epoch       : 32</span><br><span class="line">Version     : 9.9.4</span><br><span class="line">Release     : 73.el7_6</span><br><span class="line">Size        : 431 k</span><br><span class="line">Repo        : installed</span><br><span class="line">From repo   : Local-Base</span><br><span class="line">Summary     : Utilities for querying DNS name servers</span><br><span class="line">URL         : http://www.isc.org/products/BIND/</span><br><span class="line">License     : ISC</span><br><span class="line">Description : Bind-utils contains a collection of utilities for querying DNS (Domain</span><br><span class="line">            : Name System) name servers to find out information about Internet</span><br><span class="line">            : hosts. These tools will provide you with the IP addresses for given</span><br><span class="line">            : host names, as well as other information about registered domains and</span><br><span class="line">            : network addresses.</span><br><span class="line">            :</span><br><span class="line">            : You should install bind-utils if you need to get information from DNS name</span><br><span class="line">            : servers.</span><br></pre></td></tr></table></figure></p>
<p>Search package names and descriptions for a term<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mycentctl1 ~]# yum search vim</span><br><span class="line">Loaded plugins: product-id, search-disabled-repos</span><br><span class="line">================================================= N/S matched: vim ==================================================</span><br><span class="line">golang-vim.noarch : Vim plugins for Go</span><br><span class="line">protobuf-vim.x86_64 : Vim syntax highlighting for Google Protocol Buffers descriptions</span><br><span class="line">vim-X11.x86_64 : The VIM version of the vi editor for the X Window System</span><br><span class="line">vim-common.x86_64 : The common files needed by any version of the VIM editor</span><br><span class="line">vim-enhanced.x86_64 : A version of the VIM editor which includes recent enhancements</span><br><span class="line">vim-filesystem.x86_64 : VIM filesystem layout</span><br><span class="line">vim-minimal.x86_64 : A minimal version of the VIM editor</span><br><span class="line"></span><br><span class="line">  Name and summary matches only, use &quot;search all&quot; for everything.</span><br></pre></td></tr></table></figure></p>
<h3 id="RPM-packages-and-files-in-them"><a href="#RPM-packages-and-files-in-them" class="headerlink" title="RPM packages and files in them"></a>RPM packages and files in them</h3><p>List the files inside the package, you will see <code>host</code> command is here:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mycentctl1 ~]# rpm -ql bind-utils</span><br><span class="line">/etc/trusted-key.key</span><br><span class="line">/usr/bin/dig</span><br><span class="line">/usr/bin/host</span><br><span class="line">/usr/bin/nslookup</span><br><span class="line">/usr/bin/nsupdate</span><br><span class="line">/usr/share/man/man1/dig.1.gz</span><br><span class="line">/usr/share/man/man1/host.1.gz</span><br><span class="line">/usr/share/man/man1/nslookup.1.gz</span><br><span class="line">/usr/share/man/man1/nsupdate.1.gz</span><br></pre></td></tr></table></figure></p>
<p>if you have a download package and want to know the files in it, <code>-p</code> means package:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@mycentctl1 ~]# rpm -qlp jq-1.5-1.el7.x86_64.rpm</span><br><span class="line">warning: jq-1.5-1.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 352c64e5: NOKEY</span><br><span class="line">/usr/bin/jq</span><br><span class="line">/usr/lib64/libjq.so.1</span><br><span class="line">/usr/lib64/libjq.so.1.0.4</span><br><span class="line">/usr/share/doc/jq/AUTHORS</span><br><span class="line">/usr/share/doc/jq/COPYING</span><br><span class="line">/usr/share/doc/jq/README</span><br><span class="line">/usr/share/doc/jq/README.md</span><br><span class="line">/usr/share/man/man1/jq.1.gz</span><br></pre></td></tr></table></figure></p>
<h3 id="Which-package-owns-a-file"><a href="#Which-package-owns-a-file" class="headerlink" title="Which package owns a file?"></a>Which package owns a file?</h3><p>For YUM:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum provides vim</span><br></pre></td></tr></table></figure></p>
<p>For RPM:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -qf `which vim`</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
        <tag>rpm</tag>
      </tags>
  </entry>
  <entry>
    <title>Miscellanea 2019</title>
    <url>/2019/03/03/mis-2019/</url>
    <content><![CDATA[<p>This series contains something that is too short to be a blog, so put them all here, chronologically.</p>
<h3 id="02-25-2019"><a href="#02-25-2019" class="headerlink" title="02/25/2019"></a>02/25/2019</h3><ul>
<li><code>hostPath</code> in <code>PersistentVolume</code> is the mount path in host machine. <code>mountPath</code> in <code>containers</code> field is the mount path inside the container.</li>
</ul>
<h3 id="02-27-2019"><a href="#02-27-2019" class="headerlink" title="02/27/2019"></a>02/27/2019</h3><ul>
<li><p>Docker uses <code>/var/lib/docker</code> to store your images, containers, and local named volumes. Deleting this can result in data loss and possibly stop the engine from running. The <code>overlay2</code> subdirectory specifically contains the various <a href="https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers" target="_blank" rel="noopener">filesystem layers</a> for images and containers.</p>
</li>
<li><p><strong>Vim</strong> readonly mode, can open the same file in multiple windows:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim -R file</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="02-28-2019"><a href="#02-28-2019" class="headerlink" title="02/28/2019"></a>02/28/2019</h3><ul>
<li><p>reboot machine rightnow, <code>-r</code> means reboot, for example:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">shutdown -r now</span><br></pre></td></tr></table></figure>
<p>If you execute remotely, use <code>ssh example.com</code> to test if it bring up.</p>
</li>
<li><p><strong>Jenkins</strong>: the exit code of last command of the Jenkin’s Execute Shell build step is what determines the success/failure, now it’s better to wrap the code snippet as a script and execute it. Need to do more search on it.</p>
</li>
</ul>
<h3 id="03-02-2019"><a href="#03-02-2019" class="headerlink" title="03/02/2019"></a>03/02/2019</h3><ul>
<li><p>For <code>ls</code> command: If no operands are given, the contents of the current directory are displayed.  If more than one operand is given, non-directory operands are displayed first; directory and non-directory operands are sorted separately and in <strong>lexicographical order</strong>.</p>
<p> I use this feature with <code>tail</code> command to pick latest package, for example:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls | grep ansible-* | tail -1</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>ansible</code> has <code>log_path</code> setting in <code>~/.ansible.cfg</code> file, for example:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">log_path = /ibm-test/DS-Kube-Installer/logs/ds_installer_20190301_1645.log</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="03-04-2019"><a href="#03-04-2019" class="headerlink" title="03/04/2019"></a>03/04/2019</h3><ul>
<li><p><a href="https://www.gluster.org/" target="_blank" rel="noopener">Gluster file system</a> with RedHat?</p>
</li>
<li><p>when run <code>systemctl start docker</code>, these directories are created: <code>/var/lib/docker</code>, <code>/run/docker</code>, <code>etc/docker</code>.</p>
</li>
</ul>
<h3 id="03-05-2019"><a href="#03-05-2019" class="headerlink" title="03/05/2019"></a>03/05/2019</h3><ul>
<li>Find Red Hat or CentOS version:<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /etc/os-release</span><br><span class="line"></span><br><span class="line">Red Hat Enterprise Linux Server release 7.6 (Maipo)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="03-13-2019"><a href="#03-13-2019" class="headerlink" title="03/13/2019"></a>03/13/2019</h3><ul>
<li><p>I see people sometimes use <code>/bin/cp</code>, <code>/bin/rm</code> in script, why they don’t use <code>cp</code> or <code>rm</code> directly? The answer is <code>cp</code> or <code>rm</code> may be an alias in target machine! For example:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alias cp=&apos;cp -i&apos;</span><br><span class="line">alias mv=&apos;mv -i&apos;</span><br><span class="line">alias rm=&apos;rm -i&apos;</span><br></pre></td></tr></table></figure>
<p>So when use <code>cp -f source target</code> it will still prompt you the overwrite confirm if target and source are the same. <code>/bin/cp -f source target</code> is correct way to go.</p>
</li>
</ul>
<h3 id="03-16-2019"><a href="#03-16-2019" class="headerlink" title="03/16/2019"></a>03/16/2019</h3><p>These are from <code>Ansible: Up and Running, 2nd Edition</code> book:</p>
<ul>
<li><p><a href="https://gunicorn.org/" target="_blank" rel="noopener">Gunicorn</a>: a Python WSGI HTTP Server for UNIX.</p>
</li>
<li><p><a href="https://www.tablesgenerator.com/markdown_tables" target="_blank" rel="noopener">Markdown table generator</a></p>
</li>
<li><p><a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s Encrypt</a>: a free, automated, and open Certificate Authority.</p>
</li>
<li><p><a href="http://www.celeryproject.org/" target="_blank" rel="noopener">Celery</a>: a distributed task queue.</p>
</li>
<li><p><a href="https://www.rabbitmq.com/" target="_blank" rel="noopener">RabbitMQ</a>: open source message broker</p>
</li>
<li><p>A <strong>staging environment</strong> (stage) is a nearly exact replica of a production environment for software testing. Staging environments are made to test codes, builds, and updates to ensure quality under a production-like environment before application deployment.</p>
</li>
</ul>
<h3 id="03-17-2019"><a href="#03-17-2019" class="headerlink" title="03/17/2019"></a>03/17/2019</h3><p>These are from <code>Ansible: Up and Running, 2nd Edition</code> book:</p>
<ul>
<li><p><a href="http://mezzanine.jupo.org/" target="_blank" rel="noopener">Mezzanine</a>: similar in spirit to WordPress. Mezzanine is built on top of Django, the free Python-based framework for writing web applications.</p>
</li>
<li><p><a href="http://www.fabfile.org/" target="_blank" rel="noopener">Fabric</a>: a Python-based tool that helps automate running tasks via SSH.</p>
</li>
<li><p><a href="https://www.sqlite.org/serverless.html" target="_blank" rel="noopener">SQLite is serveless database</a>: Most SQL database engines are implemented as a separate server process. Programs that want to access the database communicate with the server using some kind of interprocess communication (typically TCP/IP) to send requests to the server and to receive back results. SQLite does not work this way. With SQLite, the process that wants to access the database reads and writes directly from the database files on disk. There is no intermediary server process.</p>
</li>
</ul>
<h3 id="03-18-2019"><a href="#03-18-2019" class="headerlink" title="03/18/2019"></a>03/18/2019</h3><ul>
<li><p>Today after Fyre maintenance, one of my VM cannot resolve hostname, when I run</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ping google.com</span><br></pre></td></tr></table></figure>
<p>it hangs, also <code>nslookup</code> doesn’t work as well.<br>Let’s check <code>/etc/resolv.conf</code> file, it is good:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">; generated by /usr/sbin/dhclient-script</span><br><span class="line">search fyre.ibm.com. svl.ibm.com.</span><br><span class="line">nameserver 172.16.200.52</span><br><span class="line">nameserver 172.16.200.50</span><br></pre></td></tr></table></figure>
<p>Then reboot VM again it works, sometimes Fyre generates weird problem.</p>
</li>
</ul>
<h3 id="03-22-2019"><a href="#03-22-2019" class="headerlink" title="03/22/2019"></a>03/22/2019</h3><ul>
<li><a href="https://kb.iu.edu/d/afiz" target="_blank" rel="noopener">Corn job</a></li>
</ul>
<h3 id="03-23-2019"><a href="#03-23-2019" class="headerlink" title="03/23/2019"></a>03/23/2019</h3><ul>
<li>From IBM developer website, <a href="https://developer.ibm.com/tutorials/l-lpic1-102-5/" target="_blank" rel="noopener">RPM and YUM package management</a></li>
</ul>
<h3 id="03-25-2019"><a href="#03-25-2019" class="headerlink" title="03/25/2019"></a>03/25/2019</h3><ul>
<li><a href="https://electronjs.org/" target="_blank" rel="noopener">ELECTRON</a>: Build cross platform desktop apps with JavaScript, HTML, and CSS</li>
</ul>
<h3 id="03-27-2019"><a href="#03-27-2019" class="headerlink" title="03/27/2019"></a>03/27/2019</h3><ul>
<li><p>This is from a issue I encountered: when we setup a NFS server as storage in K8s cluster with the <code>/etc/exports</code> file, we need to  restrict the clients who is able to access the NFS mount instead of something like:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/data *(rw,insecure,async,no_root_squash)</span><br></pre></td></tr></table></figure>
<p>Correct way is to specify which NFS client can access:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/data example1.com(rw,insecure,async,no_root_squash)</span><br><span class="line">/data example1.com(rw,insecure,async,no_root_squash)</span><br><span class="line">/data example1.com(rw,insecure,async,no_root_squash)</span><br></pre></td></tr></table></figure>
<p>Here in ansible template, it uses <code>lookup</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for host in &#123;&#123; lookup(&apos;env&apos;,&apos;nfsclienthosts&apos;) &#125;&#125;; do</span><br><span class="line">  echo &quot;&#123;&#123; dfsDataDir &#125;&#125; &quot;$host&quot;(rw,insecure,async,no_root_squash)&quot; &gt;&gt; /etc/exports</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>I want to say be careful with the space in exports file, from <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/nfs-serverconfig" target="_blank" rel="noopener">RHEL NFS exports</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Important</span><br><span class="line"></span><br><span class="line">The format of the /etc/exports file is very precise, particularly in </span><br><span class="line">regards to use of the space character. Remember to always separate exported</span><br><span class="line">file systems from hosts and hosts from one another with a space character. </span><br><span class="line">However, there should be no other space characters in the file except on </span><br><span class="line">comment lines.</span><br><span class="line"></span><br><span class="line">For example, the following two lines do not mean the same thing:</span><br><span class="line"></span><br><span class="line">/home bob.example.com(rw)</span><br><span class="line">/home bob.example.com (rw)</span><br><span class="line"></span><br><span class="line">The first line allows only users from bob.example.com read and write access </span><br><span class="line">to the /home directory. The second line allows users from bob.example.com </span><br><span class="line">to mount the directory as read-only (the default), while the rest of the </span><br><span class="line">world can mount it read/write.</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="03-28-2019"><a href="#03-28-2019" class="headerlink" title="03/28/2019"></a>03/28/2019</h3><ul>
<li><p><code>ps aux</code> command will not show full outputs and the lines are truncated, if you are in a lightweight Linux distributions like <code>BusyBox</code>, you can try:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps aux | cat</span><br></pre></td></tr></table></figure>
<p>otherwise try:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps auxw</span><br><span class="line">ps auxww</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="03-29-2019"><a href="#03-29-2019" class="headerlink" title="03/29/2019"></a>03/29/2019</h3><ul>
<li>open terminal run <code>vimtutor</code>, haha.</li>
</ul>
<h3 id="03-30-2019"><a href="#03-30-2019" class="headerlink" title="03/30/2019"></a>03/30/2019</h3><ul>
<li><p>see memory usage</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">free -h</span><br></pre></td></tr></table></figure>
</li>
<li><p>clean swap space</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">swapoff -a &amp;&amp; swapon -a</span><br></pre></td></tr></table></figure>
</li>
<li><p><a href="https://www.nagios.org/about/overview/" target="_blank" rel="noopener">Nagios</a>: open source Industry Standard In IT Infrastructure Monitoring</p>
</li>
<li><p><a href="http://www.haproxy.org/" target="_blank" rel="noopener">HAProxy</a>:The Reliable, High Performance TCP/HTTP Load Balancer</p>
</li>
<li><p><code>/bin/false</code> is a system command that is used anytime you need to pass a command to a program that should do nothing more than exit with an error. It’s the companion to <code>/bin/true</code>. Both of these are very old and standard POSIX utilities and neither produce any output by definition. <code>true</code> is sometimes used for a shell script that should loop indefinitely, like:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">while true; do</span><br><span class="line">    ...</span><br><span class="line">    # Waste time</span><br><span class="line">    if [ $wasted_time -gt 100000 ]; then</span><br><span class="line">        exit 0</span><br><span class="line">    fi</span><br><span class="line">    ...</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p><code>/usr/sbin/nologin</code> is specifically designed to replace a shell and produces output complaining you can’t log-in. Before it existed, it was common to use <code>/bin/false</code> for dummy users, but could be confusing since the user doesn’t know why they’re kicked off.</p>
</li>
</ul>
<h3 id="04-01-2019"><a href="#04-01-2019" class="headerlink" title="04/01/2019"></a>04/01/2019</h3><ul>
<li><p>Sometimes when I login to a user home, the prompt is like:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bash-4.2$</span><br></pre></td></tr></table></figure>
<p>instead of </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[demo@myk8s1 ~]$</span><br></pre></td></tr></table></figure>
<p>the reason is <code>.bash_history  .bash_logout  .bash_profile  .bashrc</code> under <code>/home/demo</code> are missing!</p>
</li>
</ul>
<h3 id="04-02-2019"><a href="#04-02-2019" class="headerlink" title="04/02/2019"></a>04/02/2019</h3><ul>
<li><p>docker <a href="https://docs.docker.com/storage/bind-mounts/" target="_blank" rel="noopener">bind mounts</a> and <a href="https://docs.docker.com/storage/volumes/" target="_blank" rel="noopener">volume</a>, in our application, we use mount type in docker run command:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker inspect &lt;container name&gt;</span><br><span class="line"></span><br><span class="line">&quot;Mounts&quot;: [</span><br><span class="line">          &#123;</span><br><span class="line">              &quot;Type&quot;: &quot;bind&quot;,</span><br><span class="line">              &quot;Source&quot;: &quot;/opt/builds&quot;,</span><br><span class="line">              &quot;Destination&quot;: &quot;/opt/builds&quot;,</span><br><span class="line">              &quot;Mode&quot;: &quot;&quot;,</span><br><span class="line">              &quot;RW&quot;: true,</span><br><span class="line">              &quot;Propagation&quot;: &quot;rprivate&quot;</span><br><span class="line">          &#125;,</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>I use <code>busybox</code> does a bind mount test, in the Dockerfile, I create a <code>/tmp/bb</code> folder and put <code>test.txt</code> file in it</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM busybox</span><br><span class="line">MAINTAINER chengdol@ibm.com</span><br><span class="line"></span><br><span class="line">COPY ./hello.txt /</span><br><span class="line">RUN sh -c &quot;mkdir /tmp/bb&quot; &amp;&amp; \</span><br><span class="line">  touch /tmp/bb/test.txt &amp;&amp; \</span><br><span class="line">  sh -c &quot;echo &apos;123&apos; &gt; /tmp/bb/test.txt&quot;</span><br><span class="line"></span><br><span class="line">CMD tail -f /hello.txt</span><br></pre></td></tr></table></figure>
<p>After build image and run as:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run -d --name mybb -v /tmp/bb:/tmp/bb mybb:v1</span><br></pre></td></tr></table></figure>
<p>Then I get into the container, the <code>test.txt</code> is missing. But if we first put something in the host <code>/tmp/bb</code> folder, it will show up inside container.</p>
</li>
<li><p>occasionally find a online drawing tool, <a href="https://www.draw.io/" target="_blank" rel="noopener">draw.io</a>, but this cloud service may not approved by company use.</p>
</li>
</ul>
<h3 id="04-03-2019"><a href="#04-03-2019" class="headerlink" title="04/03/2019"></a>04/03/2019</h3><ul>
<li><p><code>echo -n</code> will disable the newline, <code>echo -e</code> will enable the escape, so if you run</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo -e &quot;\n&quot;</span><br></pre></td></tr></table></figure>
<p>it will output a newline</p>
</li>
</ul>
<h3 id="04-04-2019"><a href="#04-04-2019" class="headerlink" title="04/04/2019"></a>04/04/2019</h3><ul>
<li><p>Linux capability, how to know what capabilities a process required to work properly?</p>
</li>
<li><p>Linux user and group with permission problem</p>
</li>
<li><p><code>docker commit</code>, commit what</p>
</li>
<li><p><code>docker save</code>, <code>docker export</code> difference</p>
</li>
<li><p>suid <code>rws</code> bit field for file and <code>t</code> sometimes, <a href="https://www.linode.com/docs/tools-reference/linux-users-and-groups/#additional-file-permissions" target="_blank" rel="noopener">link</a></p>
</li>
<li><p><code>usermod</code>, specify or change home directory</p>
</li>
<li><p><code>useradd</code>/<code>userdel</code>, <code>groupadd</code>/<code>groupdel</code> usage, <code>passwd</code> add password for user</p>
</li>
<li><p>sudo run process will be root USER</p>
</li>
<li><p><code>cp -p</code>, don’t change permission, owner and timestamps of the file</p>
</li>
</ul>
<h3 id="04-09-2019"><a href="#04-09-2019" class="headerlink" title="04/09/2019"></a>04/09/2019</h3><ul>
<li>find files owned by particular user<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -user &quot;xxx&quot;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>###04/10/2019</p>
<ul>
<li><p>check the parent of the process, show <code>PPID</code> (parent id) in ps command:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -efj</span><br></pre></td></tr></table></figure>
</li>
<li><p>setuid <strong>only</strong> set when owner is <strong>root</strong>, and other user with permission to run the file will be the owner of that process:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rwsr-xr-x 1 root  root  62 Apr 10 15:40 hang.sh</span><br></pre></td></tr></table></figure>
<p>if I’m <code>demo</code> user to run it, the process is owned by demo</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">demo     32403  0.0  0.0 113176  1388 pts/1    S+   10:13   0:00 /bin/bash ./hang.sh</span><br></pre></td></tr></table></figure>
<p>There is also <code>setgid</code> concept.</p>
</li>
</ul>
<h3 id="04-11-2019"><a href="#04-11-2019" class="headerlink" title="04/11/2019"></a>04/11/2019</h3><ul>
<li>copy with hidden files and directories</li>
</ul>
<h3 id="04-21-2019"><a href="#04-21-2019" class="headerlink" title="04/21/2019"></a>04/21/2019</h3><ul>
<li><p>global user start file: <code>/etc/bashrc</code>, the <code>umask</code> is inside it. </p>
<blockquote>
<p>Note that <code>umask</code> uses subtraction.</p>
</blockquote>
</li>
<li><p>tools which preserve permissions apply the appropriate mode and ignore umask: <code>cp -p</code>, <code>tar -p</code>.</p>
</li>
</ul>
<h3 id="04-24-2019"><a href="#04-24-2019" class="headerlink" title="04/24/2019"></a>04/24/2019</h3><ul>
<li><p>I find sometimes I use <code>grep -r XXX .</code> cannot find the pattern in files in current and subdirectories. The reason is <code>-r</code> flag will not process symbolic link except it’s on the command link. you can use:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep -Rn XXX .</span><br></pre></td></tr></table></figure>
<p><code>-R</code> will follow symbolic links<br><code>-n</code> will show line number for each matched result<br><code>-i</code> make it case-insensitive<br><code>-F</code> used looking for fixed string to save time</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep -Rn --include &quot;*.txt&quot; XXX .</span><br></pre></td></tr></table></figure>
<p>if you know the pattern of the file, you can specify that using <code>--include</code>, you can also mention using <code>--exclude</code> option.</p>
</li>
</ul>
<h3 id="05-10-2019"><a href="#05-10-2019" class="headerlink" title="05/10/2019"></a>05/10/2019</h3><ul>
<li><p>scp from linux to windows machine</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">scp ~/Downloads/PXSmokeTest_outputs.dsx Administrator@indraniwindows1.fyre.ibm.com:</span><br></pre></td></tr></table></figure>
<p>the file will be put in <code>C:\Users\Administrator&gt;</code> folder in windows.</p>
</li>
<li><p>How to scp files from remote host to container in k8s?<br>inside the container, install <code>openssh-clients</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo yum install openssh-clients</span><br></pre></td></tr></table></figure>
<p>then just like normal:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo scp root@mycentctl1:/GitRepos/cognitive-designer-api/DSNexus_Build/Docker_Scripts/Kubernetes_11.7.DS/buildengine/opt/IBM/InformationServer/initScripts/* .</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="05-20-2019"><a href="#05-20-2019" class="headerlink" title="05/20/2019"></a>05/20/2019</h3><ul>
<li><code>Coordinated Universal Time (UTC)</code> is 7 hours ahead of <code>Pacific Time</code>.</li>
</ul>
<h3 id="06-12-2019"><a href="#06-12-2019" class="headerlink" title="06/12/2019"></a>06/12/2019</h3><ul>
<li><p>grep exclude pattern use <code>-v</code>:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker images | grep -E <span class="string">"xmeta|services|engine|compute"</span> | grep -v <span class="string">"mycluster"</span> | awk <span class="string">'&#123;print $1&#125;'</span></span><br></pre></td></tr></table></figure>
<p>this will exclude results have <code>mycluster</code>.</p>
</li>
</ul>
<h3 id="06-19-2019"><a href="#06-19-2019" class="headerlink" title="06/19/2019"></a>06/19/2019</h3><ul>
<li>workaround when you cannot find rpm or package to install in linux, download the    binary and put it in working PATH, for example, to use <code>jq</code>, download binaries form<br><a href="https://stedolan.github.io/jq/download/" target="_blank" rel="noopener">here</a>.<br>add executable bit and move to <code>/usr/bin</code>.</li>
</ul>
<h3 id="07-01-2019"><a href="#07-01-2019" class="headerlink" title="07/01/2019"></a>07/01/2019</h3><ul>
<li><p>check directory current used size:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">du -sh &lt;path to directory&gt;</span><br></pre></td></tr></table></figure>
<p>if you want to know the partition size associated with this directory, for example <code>/var/lib/docker</code>, use</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -h /var</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="07-02-2019"><a href="#07-02-2019" class="headerlink" title="07/02/2019"></a>07/02/2019</h3><ul>
<li><p>change file or directory time stamp to <code>1969-12-31 16:00</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">touch -a -m -t 196912311600 xx.txt</span><br></pre></td></tr></table></figure>
<p><code>-a</code>: change the access time of a file. By default it will take the current system time and update the atime field.<br><code>-m</code>: change the modification time of a file.<br><code>-t</code>: explicitly specify the time</p>
<p>Check status by <code>stat</code> command:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">stat xx.txt</span><br><span class="line"></span><br><span class="line">File: `xx.txt&apos;</span><br><span class="line">Size: 3         	Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: 801h/2049d	Inode: 394283      Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: ( 1000/lakshmanan)   Gid: ( 1000/lakshmanan)</span><br><span class="line">Access: 2038-01-18 12:05:09.000000000 +0530</span><br><span class="line">Modify: 2038-01-18 12:05:09.000000000 +0530</span><br><span class="line">Change: 2012-10-19 00:40:58.763514502 +0530</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>  reference and update the time stamp of file a.txt from the time stamp of b.txt file<br>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">touch a.txt -r b.txt</span><br></pre></td></tr></table></figure></p>
<p>  Change time stamp recursively<br>  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -type f -exec touch -a -m -t 196912311600 &#123;&#125; +</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>Convert format from <code>DOS</code> to <code>UNIX</code>:<br>If you open a file via <code>vim</code> and see there are many <code>^M</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NOTICE^M</span><br><span class="line">^M</span><br><span class="line">This document includes License Information documents below for multiple Programs. Each License Information document identifies the Program(s) to which it applies. Only those License Information documents for the Program(s) for which Licensee has acquired entitlements apply.^M</span><br><span class="line">^M</span><br><span class="line">^M</span><br></pre></td></tr></table></figure>
<p>This is because it’s <code>DOS</code> format:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">file LA_en.ORIG</span><br><span class="line"></span><br><span class="line">LA_en.ORIG: ASCII text, with very long lines, with CRLF, LF line terminators</span><br></pre></td></tr></table></figure>
<p>how to convert to <code>UNIX</code>?</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y dos2unix</span><br><span class="line">dos2unix &lt;file name&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="07-12-2019"><a href="#07-12-2019" class="headerlink" title="07/12/2019"></a>07/12/2019</h3><ul>
<li>Previously I use<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -ltr --block-size=M</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>to see the human readable size for each file, actually use<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -ltrh</span><br></pre></td></tr></table></figure></p>
<p>is enough!</p>
<h3 id="07-15-2019"><a href="#07-15-2019" class="headerlink" title="07/15/2019"></a>07/15/2019</h3><ul>
<li>new tech word <code>linting</code>: the process of running a program that will analyse code for potential errors. For example, <code>PHPLint</code>, <code>JSLint</code>.</li>
</ul>
<h3 id="07-24-2019"><a href="#07-24-2019" class="headerlink" title="07/24/2019"></a>07/24/2019</h3><ul>
<li><p>if run script using <code>sudo</code>, for example:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo script.sh</span><br></pre></td></tr></table></figure>
<p>then every command in scipt is executed with sudo.</p>
</li>
</ul>
<h3 id="08-05-2019"><a href="#08-05-2019" class="headerlink" title="08/05/2019"></a>08/05/2019</h3><ul>
<li><p>find file owned by a particular user or group</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find &lt;path&gt; -user &lt;dsadm&gt; -group &lt;dstage&gt;</span><br></pre></td></tr></table></figure>
<p>find file by case-insensitive name and use <code>-ls</code> format</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find &lt;path&gt; -iname &lt;name&gt; -type f -ls</span><br></pre></td></tr></table></figure>
</li>
<li><p>find particular files and change the chown or chmod</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find &lt;path&gt; -user &lt;dsadm&gt; -group &lt;dstage&gt; -exec chmod 755 &#123;&#125; /;</span><br></pre></td></tr></table></figure>
<p>explain:<br><code>chmod 755 {} \;</code> specifies the command that will be executed by find for each file. <code>{}</code> is replaced by the file path, and the <code>semicolon(;)</code> denotes the end of the command (escaped, otherwise it would be interpreted by the shell instead of find).</p>
</li>
</ul>
<h3 id="08-09-2019"><a href="#08-09-2019" class="headerlink" title="08/09/2019"></a>08/09/2019</h3><ul>
<li>if var is not set, use default value <code>123456</code>:<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var=$&#123;var:-&quot;123456&quot;&#125;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="08-28-2019"><a href="#08-28-2019" class="headerlink" title="08/28/2019"></a>08/28/2019</h3><ul>
<li>docker commit will not apply <code>chmod 777 /</code> in new image, the permission mode of <code>/</code> directory is still original. Not sure why.</li>
</ul>
<h3 id="09-05-2019"><a href="#09-05-2019" class="headerlink" title="09/05/2019"></a>09/05/2019</h3><ul>
<li><code>curl</code> can be used to verbose request in detail, to check the RESTful API content.</li>
</ul>
<h3 id="11-13-2019"><a href="#11-13-2019" class="headerlink" title="11/13/2019"></a>11/13/2019</h3><ul>
<li><code>uniq</code> <a href="https://www.geeksforgeeks.org/uniq-command-in-linux-with-examples/" target="_blank" rel="noopener">command</a>, used to deduplicates </li>
</ul>
<h3 id="11-30-2019"><a href="#11-30-2019" class="headerlink" title="11/30/2019"></a>11/30/2019</h3><ul>
<li><code>https://distrowatch.com/</code> linux forum, contains lots of different linux distribtions and release informations.</li>
</ul>
]]></content>
      <categories>
        <category>Miscellanea</category>
      </categories>
      <tags>
        <tag>miscellanea</tag>
      </tags>
  </entry>
  <entry>
    <title>Leetcode Summary</title>
    <url>/2019/07/10/leetcode-recall/</url>
    <content><![CDATA[<h2 id="TO-DO"><a href="#TO-DO" class="headerlink" title="TO-DO"></a>TO-DO</h2><ol start="0">
<li>hiring season, internal reference</li>
<li>position: backend developer, DevOps, Infra</li>
<li>system design from x code in my laptop? baidu cloud?</li>
<li>company series, buy x code or leetcode?</li>
<li>resume project chat</li>
<li>blog review</li>
</ol>
<h1 id="Data-Structure"><a href="#Data-Structure" class="headerlink" title="Data Structure"></a>Data Structure</h1><p>java Integer notation, see this <a href="https://stackoverflow.com/questions/17636749/java-why-cant-i-declare-integer-types-using-scientific-notation" target="_blank" rel="noopener">post</a>:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 10^9</span></span><br><span class="line"><span class="keyword">int</span> a = (<span class="keyword">int</span>)<span class="number">1e9</span>;</span><br><span class="line"><span class="keyword">int</span> a = (<span class="keyword">int</span>)Math.pow(<span class="number">10</span>, <span class="number">9</span>);</span><br><span class="line"><span class="keyword">int</span> b = <span class="number">2_000_000_000</span>;</span><br></pre></td></tr></table></figure></p>
<h2 id="Class-features"><a href="#Class-features" class="headerlink" title="Class features"></a>Class features</h2><p>basic structure and syntax<br>nested class, inner class<br>static class<br>private<br>public<br>protected</p>
<h2 id="LRU"><a href="#LRU" class="headerlink" title="LRU"></a>LRU</h2><p>LRU除了可以使用自定义的double linked list去实现，也可以用Java API <code>LinkedHashMap</code>，在constructor中指定参数:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 设置capacity</span></span><br><span class="line"><span class="keyword">int</span> CAPACITY = <span class="number">10</span>;</span><br><span class="line"><span class="comment">// true表示自动实现LRU功能</span></span><br><span class="line">LinkedHashMap&lt;String, Integer&gt; lru = <span class="keyword">new</span> LinkedHashMap&lt;&gt;(CAPACITY, <span class="number">0.75f</span>, <span class="keyword">true</span>)&#123;</span><br><span class="line">  <span class="comment">// override</span></span><br><span class="line">  <span class="keyword">protected</span> <span class="keyword">boolean</span> removeEldestEntry​(Map.Entry&lt;String, Integer&gt; eldest)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">return</span> size() &gt; CAPACITY;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如此一来，可以直接使用put(), get()即可，其他不用操心，当达新增的量超过capacity时会自动删除least recently used item.</p>
<p>此外，如果不使用这个special constructor <code>new LinkedHashMap&lt;&gt;(CAPACITY, 0.75f, true)</code>，则linked list中的顺序是insertion order，即最先insert的在前面，最近的在后面，如果用keySet() iterator是按照linked list的顺序出来的，即最先insert的先出来。</p>
<p>经过试验发现，LRU声称的access order，都是insertion order的顺序，只不过LRU实现每次会自动把最新活动的元素重新放到linked list最后， 然后超出capacity时，把least recently used one删除了.</p>
<h2 id="Pair-class"><a href="#Pair-class" class="headerlink" title="Pair class"></a>Pair class</h2><p><a href="https://docs.oracle.com/javase/8/javafx/api/javafx/util/Pair.html" target="_blank" rel="noopener">https://docs.oracle.com/javase/8/javafx/api/javafx/util/Pair.html</a><br><a href="https://www.baeldung.com/java-pairs" target="_blank" rel="noopener">https://www.baeldung.com/java-pairs</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> javafx.util.Pair;</span><br></pre></td></tr></table></figure></p>
<p><a href="https://www.geeksforgeeks.org/pair-class-in-java/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/pair-class-in-java/</a></p>
<h2 id="input-method"><a href="#input-method" class="headerlink" title="input method"></a>input method</h2><h2 id="Deque"><a href="#Deque" class="headerlink" title="Deque"></a>Deque</h2><p>如果把Deque既当stack又当queue, 不要使用他们的native method，用能明确指出操作位置的method:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">addLast(x)</span><br><span class="line">removeLast()</span><br><span class="line">peekLast()</span><br><span class="line"></span><br><span class="line">addFirst()</span><br><span class="line">removeFirst()</span><br><span class="line">peekFirst()</span><br></pre></td></tr></table></figure></p>
<p>如果只充当stack or queue之一，则可以用native method:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">stack: push, pop</span><br><span class="line">queue: add, poll</span><br></pre></td></tr></table></figure></p>
<h2 id="Segment-Tree"><a href="#Segment-Tree" class="headerlink" title="Segment Tree"></a>Segment Tree</h2><p><a href="https://www.geeksforgeeks.org/segment-tree-set-1-sum-of-given-range/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/segment-tree-set-1-sum-of-given-range/</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// get min value &gt;= x</span></span><br><span class="line"><span class="comment">// 返回的都是整数，但是是double type</span></span><br><span class="line">Math.ceil(<span class="keyword">double</span> x)</span><br><span class="line"><span class="comment">// get max value &lt;= x</span></span><br><span class="line"><span class="comment">// 返回的都是整数，但是是double type</span></span><br><span class="line">Math.floor(<span class="keyword">double</span> x)</span><br><span class="line"><span class="comment">// log e of x</span></span><br><span class="line">Math.log(<span class="keyword">double</span> x)</span><br><span class="line"><span class="comment">// calculate log2</span></span><br><span class="line">Math.log(x) / Math.log(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<p>Complete binary tree number of nodes: <code>2^height - 1</code> (height start from <code>1</code>)<br>For segment tree, number of nodes:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// n is the length of array</span></span><br><span class="line"><span class="keyword">int</span> h = (<span class="keyword">int</span>)Math.ceil(Math.log(n) / Math.log(<span class="number">2</span>));</span><br><span class="line"><span class="keyword">int</span> maxSTSize = <span class="number">2</span> * (<span class="keyword">int</span>)Math.pow(<span class="number">2</span>, h) - <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span>[] st</span><br></pre></td></tr></table></figure></p>
<p>Or you can define <code>class Node</code> to build segment tree.</p>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><ul>
<li>LinkedList is doubly-linked!</li>
<li>change array to list<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; list = Arrays.&lt;Integer&gt;asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, ...);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>but this is fixed size list backed by array, you can create a new one:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; list = <span class="keyword">new</span> ArrayList&lt;Integer&gt;(Arrays.&lt;Integer&gt;asList(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>, ...));</span><br></pre></td></tr></table></figure></p>
<p>use slow-fast pointer to find middle of linkedlist or find cycle<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">ListNode slow = head, fast = head;</span><br><span class="line"><span class="keyword">while</span> (fast.next != <span class="keyword">null</span> &amp;&amp; fast.next.next != <span class="keyword">null</span>) &#123;</span><br><span class="line">    slow = slow.next;</span><br><span class="line">    fast = fast.next.next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// when loop break, slow is in middle</span></span><br></pre></td></tr></table></figure></p>
<p>reverse the linked list:<br><a href="https://leetcode.com/problems/reorder-list/submissions/" target="_blank" rel="noopener">https://leetcode.com/problems/reorder-list/submissions/</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1-&gt;2-&gt;3-&gt;4</span></span><br><span class="line"><span class="comment">// 1&lt;-2&lt;-3&lt;-4</span></span><br><span class="line">ListNode pre = <span class="keyword">null</span>;</span><br><span class="line">ListNode cur = &lt;node <span class="number">1</span>&gt;;</span><br><span class="line"><span class="keyword">while</span> (cur != <span class="keyword">null</span>)</span><br><span class="line">&#123;</span><br><span class="line">    ListNode next = cur.next;</span><br><span class="line">    cur.next = pre;</span><br><span class="line">    pre = cur;</span><br><span class="line">    cur = next;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 注意这里不要弄错了</span></span><br><span class="line">ListNode newHead = pre;</span><br></pre></td></tr></table></figure></p>
<h2 id="PriorityQueue"><a href="#PriorityQueue" class="headerlink" title="PriorityQueue"></a>PriorityQueue</h2><p>Priority queue has <code>contains(object)</code> and <code>remove(object)</code> method, but that will take <code>O(n)</code> time.</p>
<p>如果要构造比较整数大小的priority queue<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// if use (a, b) -&gt; a - b, this may overflow when encounter MAX MIN</span></span><br><span class="line">Queue&lt;Integer&gt; pq = <span class="keyword">new</span> PriorityQueue&lt;&gt;((a, b) -&gt; Integer.compare(a, b));</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>注意priorityQueue iterator返回的是random order!</p>
</blockquote>
<h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><p>String: immutable<br>StringBuilder: mutable, not thread safe<br>StringBuffer: mutable, thread safe</p>
<p>注意<code>&quot;\t&quot;, &quot;\n&quot;</code>在string中只相当于一个长度！！！</p>
<p>“abcdefg”<br>substring 是连续的: “cdef”<br>subsequence可以不连续，但顺序要一致: “abdf”</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str = <span class="keyword">new</span> String(<span class="string">"123"</span>);</span><br><span class="line">String str = <span class="string">"123"</span>;</span><br><span class="line"><span class="comment">// convert number 123456 to string "123"</span></span><br><span class="line">String str = String.valueOf(<span class="number">123456</span>);</span><br><span class="line">str.length();</span><br><span class="line"><span class="comment">// use + to concatenate</span></span><br><span class="line">str1 + str2</span><br><span class="line"><span class="comment">// string compare</span></span><br><span class="line">str1.compareTo(str2);</span><br></pre></td></tr></table></figure>
<p>when do replace<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str = <span class="string">"a.b.c.d"</span>;</span><br><span class="line">str.replace(<span class="string">"."</span>, <span class="string">""</span>); <span class="comment">// get "abcd"</span></span><br><span class="line"><span class="comment">// don't use str.replace('.',''), cannot be empty char</span></span><br><span class="line"><span class="comment">// there is no regex, just CharSequence type</span></span><br></pre></td></tr></table></figure></p>
<p>if just want to create a string using other type:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="string">""</span> + other type</span><br></pre></td></tr></table></figure></p>
<p>caution:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String a = <span class="string">"1.2.3."</span>;</span><br><span class="line"><span class="comment">// a.split("\\.") will get length of 3, it will ignore last '.'</span></span><br><span class="line">String a = <span class="string">".1.2.3"</span>;</span><br><span class="line"><span class="comment">// a.split("\\.") will get length of 4, it will not ignore first '.'</span></span><br><span class="line">String b = <span class="string">"1..2.3"</span>;</span><br><span class="line"><span class="comment">// b.split("\\.") will get length of 4, it will not ignore consecutive '.'</span></span><br></pre></td></tr></table></figure></p>
<p>Notice the parameters format<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">indexOf(<span class="keyword">int</span> ch, <span class="keyword">int</span> startIndex)</span><br><span class="line">split(String reg)</span><br><span class="line"></span><br><span class="line"><span class="comment">// returns the index within this string of</span></span><br><span class="line"><span class="comment">// the last occurrence of the specified character.</span></span><br><span class="line"><span class="keyword">int</span> lastIndexOf​(<span class="keyword">int</span> ch)</span><br></pre></td></tr></table></figure></p>
<h2 id="StringBuilder"><a href="#StringBuilder" class="headerlink" title="StringBuilder"></a>StringBuilder</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">StringBuilder sb = <span class="keyword">new</span> StringBuilder(String);</span><br><span class="line">sb.append(x);</span><br><span class="line"><span class="comment">// insert in head</span></span><br><span class="line">sb.insert(<span class="number">0</span>, x);</span><br><span class="line">sb.toString();</span><br><span class="line"><span class="comment">// return stringbuilder</span></span><br><span class="line">sb.reverse();</span><br><span class="line"><span class="comment">// stringbuilder does not implement equals method!!</span></span><br><span class="line">sb.equals(another stringbuilder object); <span class="comment">// wrong!!</span></span><br></pre></td></tr></table></figure>
<p>more methods:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// return String</span></span><br><span class="line"><span class="comment">// 这里只有一个参数的时候是start index!</span></span><br><span class="line">substring(<span class="keyword">int</span> startidx)</span><br><span class="line"><span class="comment">// [start end)</span></span><br><span class="line">substring(<span class="keyword">int</span> startidx, <span class="keyword">int</span> endidx) </span><br><span class="line">append(lot of types)</span><br><span class="line">setLength(<span class="keyword">int</span> len)</span><br></pre></td></tr></table></figure></p>
<h2 id="Character"><a href="#Character" class="headerlink" title="Character"></a>Character</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// return Character</span></span><br><span class="line">Character.valueOf(<span class="keyword">char</span>)</span><br><span class="line"><span class="comment">//return char</span></span><br><span class="line">c.charValue()</span><br><span class="line"></span><br><span class="line"><span class="comment">// actually the convert is auto like int and Integer!</span></span><br><span class="line"><span class="keyword">char</span> c1 = <span class="keyword">new</span> Character(<span class="string">'a'</span>);</span><br><span class="line">Character c1 = <span class="string">'b'</span>;</span><br></pre></td></tr></table></figure>
<p>char compare in <code>if</code> use <code>==</code><br>if use +- with char, such as <code>ch - &#39;a&#39;</code>, don’t forget <code>(char)(ch)</code></p>
<p>check letter:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Character.isDigit(ch);</span><br><span class="line">Character.toLowerCase(ch);</span><br><span class="line">Character.isLetterOrDigit(ch);</span><br></pre></td></tr></table></figure></p>
<p>Non-ASCII character (&gt; 256):<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Character.toString((<span class="keyword">char</span>)<span class="number">342</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="3-items-if-expression"><a href="#3-items-if-expression" class="headerlink" title="3 items if expression"></a>3 items if expression</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// I forget the precedence</span></span><br><span class="line"><span class="comment">// this will first 1 + 2 + 3 then compare with 3!</span></span><br><span class="line"><span class="number">1</span> + <span class="number">2</span> + <span class="number">3</span> == <span class="number">3</span>? <span class="keyword">true</span>: <span class="keyword">false</span></span><br></pre></td></tr></table></figure>
<h2 id="Enhenced-for-Loop"><a href="#Enhenced-for-Loop" class="headerlink" title="Enhenced for Loop"></a>Enhenced for Loop</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// enhanced for loop</span></span><br><span class="line"><span class="keyword">for</span> (Character ch : str.toCharArray())</span><br><span class="line">&#123;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Collection"><a href="#Collection" class="headerlink" title="Collection"></a>Collection</h2><p>convert list to array<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// result is List&lt;int[]&gt; type</span></span><br><span class="line"><span class="comment">// think about it</span></span><br><span class="line">result.toArray(<span class="keyword">new</span> <span class="keyword">int</span>[result.size()][]);</span><br></pre></td></tr></table></figure></p>
<p>convert Integer list to int array (from Java8):<br><a href="https://stackoverflow.com/questions/718554/how-to-convert-an-arraylist-containing-integers-to-primitive-int-array" target="_blank" rel="noopener">https://stackoverflow.com/questions/718554/how-to-convert-an-arraylist-containing-integers-to-primitive-int-array</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] arr = list.stream().mapToInt(i -&gt; i).toArray();</span><br></pre></td></tr></table></figure></p>
<p>also from int array to Integer list<br><a href="https://stackoverflow.com/questions/1073919/how-to-convert-int-into-listinteger-in-java" target="_blank" rel="noopener">https://stackoverflow.com/questions/1073919/how-to-convert-int-into-listinteger-in-java</a><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; list = Arrays.stream(ints).boxed().collect(Collectors.toList());</span><br></pre></td></tr></table></figure></p>
<p>这个是Java stream的知识点</p>
<h2 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// one dimension</span></span><br><span class="line"><span class="keyword">int</span>[] arr = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;</span><br><span class="line"><span class="keyword">int</span>[] arr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">4</span>]; <span class="comment">// default value is 0</span></span><br><span class="line"><span class="comment">// two dimensions</span></span><br><span class="line"><span class="keyword">int</span>[][] arr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">3</span>][<span class="number">4</span>]; <span class="comment">// 3 rows 4 columns</span></span><br><span class="line"><span class="keyword">int</span>[][] arr = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">3</span>][]; <span class="comment">// still ok, you can init one dimension array later</span></span><br><span class="line"><span class="keyword">int</span>[][] arr = <span class="keyword">new</span> <span class="keyword">int</span>[][]&#123;&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;, &#123;<span class="number">4</span>,<span class="number">5</span>&#125;, &#123;<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>&#125;&#125;; <span class="comment">// each one dimension array can have different length!</span></span><br></pre></td></tr></table></figure>
<p>Let’s see char array<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">char</span>[] arr = str.toCharArray();</span><br></pre></td></tr></table></figure></p>
<p>Use sort static method, if you want to use comparator, see my <strong>lambda</strong> section<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Arrays.sort(E[] e);</span><br><span class="line"><span class="comment">// also for collections</span></span><br><span class="line">Collections.sort(List&lt;xx&gt; l);</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Arrays.sort(int[]) primitive type是不能自己写comparator的！</p>
</blockquote>
<p>数组内容字符串化用:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[] a = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line"><span class="comment">// correct!</span></span><br><span class="line">Arrays.toString(a);</span><br><span class="line"><span class="comment">// wrong! 这个返回id string</span></span><br><span class="line">a.toString()</span><br></pre></td></tr></table></figure></p>
<p>Shuffle arrays:<br>Every permutation of array element should equally likely:<br><a href="https://www.geeksforgeeks.org/shuffle-a-given-array-using-fisher-yates-shuffle-algorithm/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/shuffle-a-given-array-using-fisher-yates-shuffle-algorithm/</a><br><a href="https://introcs.cs.princeton.edu/java/stdlib/StdRandom.java.html" target="_blank" rel="noopener">https://introcs.cs.princeton.edu/java/stdlib/StdRandom.java.html</a></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// nums[0] swap with element in range [0, n)</span></span><br><span class="line"><span class="comment">// nums[1] swap with element in range [1, n)</span></span><br><span class="line"><span class="comment">// nums[2] swap with element in range [2, n)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] shuffle(<span class="keyword">int</span>[] nums)</span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nums.length; i++)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="keyword">int</span> j = i + rand.nextInt(nums.length - i);</span><br><span class="line">    <span class="comment">// swap</span></span><br><span class="line">    <span class="keyword">int</span> tmp = nums[i];</span><br><span class="line">    nums[i] = nums[j];</span><br><span class="line">    nums[j] = tmp;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> nums;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>TreeSet operation time complexity, from java TreeSet doc:<br><strong>This implementation provides guaranteed log(n) time cost for the basic operations (add, remove and contains).</strong></p>
<h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.*;</span><br></pre></td></tr></table></figure>
<p>HashMap&lt;&gt;() not thread safe<br>HashTable&lt;&gt;(), thread safe but ConcurrentHash…</p>
<p>有时用char[26]（<code>c - &#39;a&#39;</code>） 或者 int[256] (直接用c即可) 可以用来代替hashmap</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">map.containsKey()</span><br><span class="line"><span class="comment">// also has contains value method!</span></span><br><span class="line">map.containsValue()</span><br><span class="line"><span class="comment">// return set</span></span><br><span class="line">map.keySet()</span><br><span class="line">map.entrySet()</span><br><span class="line"><span class="comment">// return collection</span></span><br><span class="line">map.values()</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// provide value for new key which is absent </span></span><br><span class="line">map.put(key, map.getOrDefault(key, <span class="number">0</span>) + <span class="number">1</span>);</span><br><span class="line"><span class="comment">// if value is a collection object can use:</span></span><br><span class="line">map.computeIfAbsent(key, k -&gt; <span class="keyword">new</span> ArrayList&lt;Stone&gt;()).add(<span class="keyword">new</span> Stone(x,y));</span><br><span class="line"><span class="comment">// remove current key if it's value is val</span></span><br><span class="line">map.remove(key, val)</span><br></pre></td></tr></table></figure>
<p>Treemap/TreeSet (sorted map) perform <strong>all operation</strong> based on it’s default/custom comparator! if two key are equal in comparator, should be treated as equal in equals() method! 但如果没有一致，还是按照comparator去做. treemap/treeset.remove(object) 用的是comparator去比较相等！！</p>
<p>range query API:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// treemap</span></span><br><span class="line">tm.ceilingKey(K key)</span><br><span class="line">tm.ceilingEntry(K key)</span><br><span class="line">tm.floorEntry(K key)</span><br><span class="line">tm.floorKey(K key)</span><br><span class="line"></span><br><span class="line">tm.firstKey()</span><br><span class="line">tm.firstEntry()</span><br><span class="line">tm.lastKey()</span><br><span class="line">tm.lastEntry()</span><br><span class="line"></span><br><span class="line">tm.pollFirstEntry()</span><br><span class="line">tm.pollLastEntry()</span><br><span class="line"><span class="comment">// treeset</span></span><br><span class="line">ts.ceiling(K key)</span><br><span class="line">ts.floor(K key)</span><br><span class="line"></span><br><span class="line">ts.first()</span><br><span class="line">ts.last()</span><br><span class="line"><span class="comment">// 可以用来模拟pq</span></span><br><span class="line">ts.pollFirst()</span><br><span class="line">ts.pollLast()</span><br></pre></td></tr></table></figure></p>
<p>如果要返回map中的任意一个key，比如key是string类型<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">return</span> (String)map.keySet().iterator().next();</span><br></pre></td></tr></table></figure></p>
<p>this is java <strong>syntax</strong>, I see it in leetcode<br><a href="https://stackoverflow.com/questions/1958636/what-is-double-brace-initialization-in-java" target="_blank" rel="noopener">https://stackoverflow.com/questions/1958636/what-is-double-brace-initialization-in-java</a></p>
<h2 id="Exception-Handling"><a href="#Exception-Handling" class="headerlink" title="Exception Handling"></a>Exception Handling</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"xxx"</span>);</span><br></pre></td></tr></table></figure>
<h2 id="Random-Number-Generation"><a href="#Random-Number-Generation" class="headerlink" title="Random Number Generation"></a>Random Number Generation</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Random;</span><br><span class="line">Random rand = <span class="keyword">new</span> Random();</span><br><span class="line"><span class="keyword">int</span> randomNum = rand.nextInt((max - min) + <span class="number">1</span>) + min;</span><br><span class="line"><span class="comment">// simply can use this:</span></span><br><span class="line"><span class="comment">// return double, need to force convert to int maybe</span></span><br><span class="line">Math.random(): [<span class="number">0.00</span>,<span class="number">1.00</span>)</span><br></pre></td></tr></table></figure>
<h2 id="Lambda-Expression"><a href="#Lambda-Expression" class="headerlink" title="Lambda Expression"></a>Lambda Expression</h2><p>for comparator and comparable, let’s see how to wirte it, <a href="https://www.mkyong.com/java8/java-8-lambda-comparator-example/" target="_blank" rel="noopener">this post</a></p>
<p>原来的方法，在constructor中定义comparator:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Queue&lt;Integer&gt; que = <span class="keyword">new</span> PriorityQueue&lt;&gt;(<span class="keyword">new</span> Comparator&lt;Integer&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Integer n1, Integer n2)</span> </span>&#123;</span><br><span class="line">				<span class="keyword">return</span> Integer.compare(n1, n2);</span><br><span class="line">			&#125; </span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span>[] arr = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">5</span>, <span class="number">3</span>, <span class="number">56</span>, <span class="number">78</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">5</span>&#125;;</span><br><span class="line"><span class="comment">// anonymous class to implement comparator</span></span><br><span class="line">Arrays.sort(arr, <span class="keyword">new</span> Comparator&lt;Integer&gt;()&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Integer n1, Integer n2)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> Integer.compare(n1, n2);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span>[][] arr = &#123;&#123;<span class="number">5</span>,<span class="number">1</span>&#125;, &#123;<span class="number">2</span>,<span class="number">3</span>&#125;&#125;;</span><br><span class="line"><span class="comment">// sort by the first element of one dimenstional array</span></span><br><span class="line">Arrays.sort(arr, (<span class="keyword">int</span>[] a, <span class="keyword">int</span>[]b) -&gt; a[<span class="number">0</span>] - b[<span class="number">0</span>]);</span><br><span class="line">System.out.println(<span class="string">"result= "</span> + Arrays.deepToString(arr));</span><br></pre></td></tr></table></figure>
<p>用lambda构造comparator 时可以用到外部的数据结构？<br><a href="https://leetcode.com/problems/top-k-frequent-elements/solution/" target="_blank" rel="noopener">https://leetcode.com/problems/top-k-frequent-elements/solution/</a><br>比如这个的官方solution<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// init heap 'the less frequent element first'</span></span><br><span class="line">    PriorityQueue&lt;Integer&gt; heap =</span><br><span class="line">            <span class="keyword">new</span> PriorityQueue&lt;Integer&gt;((n1, n2) -&gt; count.get(n1) - count.get(n2))</span><br></pre></td></tr></table></figure></p>
<p>其实这里可以使用Map.Entry&lt;&gt; 放入pq中。<br>count是一个外部定义的hashmap. 这个到底是怎么回事？</p>
<h2 id="Java-Memory-Management"><a href="#Java-Memory-Management" class="headerlink" title="Java Memory Management"></a>Java Memory Management</h2><p>java heap space, java stack memory<br><a href="https://www.journaldev.com/4098/java-heap-space-vs-stack-memory" target="_blank" rel="noopener">Memory Allocation in Java</a><br><a href="https://www.baeldung.com/java-stack-heap" target="_blank" rel="noopener">Stack Memory and Heap Space in Java</a></p>
<h2 id="Java-Garbage-Collection"><a href="#Java-Garbage-Collection" class="headerlink" title="Java Garbage Collection"></a>Java Garbage Collection</h2><p>you can watch the operting system course video<br>implemented by DFS with marked bit in each object, scan from stack</p>
<h3 id="Why-use-Deque-instead-of-stack"><a href="#Why-use-Deque-instead-of-stack" class="headerlink" title="Why use Deque instead of stack"></a>Why use Deque instead of stack</h3><p>check this post <a href="https://leetcode.com/problems/flatten-nested-list-iterator/discuss/80147/Simple-Java-solution-using-a-stack-with-explanation/165585" target="_blank" rel="noopener">https://leetcode.com/problems/flatten-nested-list-iterator/discuss/80147/Simple-Java-solution-using-a-stack-with-explanation/165585</a></p>
<p>I just recently interviewed with 16 different companies in the silicon valley (including FAANG except Netflix) for senior software engineering positions. Here’s my opinion, based on my experience:</p>
<p>Some interviewers will expect you to know why Deque is better than Stack.</p>
<p>Showing mastery of at least one programming language (in this case, Java) can, at worst, score you extra points in the interview, and at best get you the job and even help you get higher compensation or leveling. Getting the optimal solution is the basic requirement to pass an interview. Additionally, you are being benchmarked against other candidates being asked exactly the same question. Lastly, for those targeting senior level positions, the interviewer will also evaluate your seniority. This is one case where I think most interviewers will expect to see that you’ve mastered the Java programming language (if you chose to use it in your interview).</p>
<p>Here are a few reasons why Deque is better than Stack:</p>
<p>Object oriented design - Inheritance, abstraction, classes and interfaces: Stack is a class, Deque is an interface. Only one class can be extended, whereas any number of interfaces can be implemented by a single class in Java (multiple inheritance of type). Using the Deque interface removes the dependency on the concrete Stack class and its ancestors and gives you more flexibility, e.g. the freedom to extend a different class or swap out different implementations of Deque (like LinkedList, ArrayDeque).</p>
<p>Inconsistency: Stack extends the Vector class, which allows you to access element by index. This is inconsistent with what a Stack should actually do, which is why the Deque interface is preferred (it does not allow such operations)–its allowed operations are consistent with what a FIFO or LIFO data structure should allow.</p>
<p>Performance: The Vector class that Stack extends is basically the “thread-safe” version of an ArrayList. The synchronizations can potentially cause a significant performance hit to your application. Also, extending other classes with unneeded functionality (as mentioned in #2) bloat your objects, potentially costing a lot of extra memory and performance overhead.</p>
<h2 id="Tries"><a href="#Tries" class="headerlink" title="Tries"></a>Tries</h2><p><code>string symbol table</code>: specialized to string key. Faster than hashing, flexible then BST<br>recall the structure of tries, very simple! put value in last node (character).<br>put and search method for tries can be recursion implementations.<br>一般都用的这个。</p>
<p><code>3-way tries</code>: 这里注意，当前char的值和node char比较，less then go left, larger then go right, then compare, if not match, miss hit. Using recursion to do put and search operation. <code>TST</code> is as fast as hashing (for string key) and space efficient. support in-order traverse (obey BST rule)</p>
<p>Implementation: prefix matching, wildcard match, longest prefix.</p>
<h1 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h1><p><a href="https://www.youtube.com/user/tusharroy2525/playlists" target="_blank" rel="noopener">Tushar Roy youtube channel</a><br>princeton algorithms，在youtube or coursera上都有</p>
<p>Time complexity:<br><a href="https://en.wikipedia.org/wiki/Time_complexity" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Time_complexity</a><br>usually:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">constant O(1)</span><br><span class="line">logarithmic O(logn)</span><br><span class="line">linear O(n)</span><br><span class="line">quasilinear O(nlogn)</span><br><span class="line">quadratic O(n^2), n to the power of 2</span><br><span class="line">cubic O(n^3), n to the power of 3</span><br><span class="line">polynomial O(n^x + n^y + ..)</span><br><span class="line">exponential O(2^n)</span><br><span class="line">factorial O(n!)</span><br></pre></td></tr></table></figure></p>
<p><code>Tilde notation</code>: ignore lower order terms, negligible<br>best case, lower bound<br>worst case, upper bound, <code>Big O</code> does this<br>average case, cost for random input, expected cost<br>when upper bound equals lower bound, we get optimal algorithms</p>
<p><a href="https://cs.stackexchange.com/questions/52776/difference-between-the-tilde-and-big-o-notations" target="_blank" rel="noopener">tilde notation vs big-O</a></p>
<h2 id="Prime"><a href="#Prime" class="headerlink" title="Prime"></a>Prime</h2><p>LC 886 <a href="https://leetcode.com/problems/prime-palindrome/" target="_blank" rel="noopener">https://leetcode.com/problems/prime-palindrome/</a><br>isPrime是如何检查的，函数记住, 并不是检查每个递增+1的除数是否整除！<br>检查特殊的值就可以了<br><a href="https://en.wikipedia.org/wiki/Primality_test" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Primality_test</a></p>
<h2 id="Monotonic-Stack"><a href="#Monotonic-Stack" class="headerlink" title="Monotonic Stack"></a>Monotonic Stack</h2><p>LC 496 Next Greater Element I<br>LC 503 Next Greater Element II<br>还有LC 31 next permutation 也是属于monotonic problem, 见这题我的note</p>
<p>Monotonic stack practice:<br><a href="https://medium.com/@vishnuvardhan623/monotonic-stack-e9dcc4fa8c3e" target="_blank" rel="noopener">https://medium.com/@vishnuvardhan623/monotonic-stack-e9dcc4fa8c3e</a></p>
<p>increasing monotonic stack: from stack top to stack bottom is increasing<br>decreasing monotonoc stack: reverse order</p>
<h2 id="General"><a href="#General" class="headerlink" title="General"></a>General</h2><p>bit and boolean can use XOR ^ operator!</p>
<h2 id="Sliding-Window"><a href="#Sliding-Window" class="headerlink" title="Sliding Window"></a>Sliding Window</h2><p>相关window问题的<a href="https://leetcode.com/problems/minimum-window-substring/discuss/26808" target="_blank" rel="noopener">template</a> and <a href="https://leetcode.com/problems/find-all-anagrams-in-a-string/discuss/92007" target="_blank" rel="noopener">summary</a>, good sliding window <a href="https://www.geeksforgeeks.org/window-sliding-technique/" target="_blank" rel="noopener">demo</a></p>
<p><a href="https://www.geeksforgeeks.org/window-sliding-technique/" target="_blank" rel="noopener">basic sliding window problem</a><br>leetcode 904<br>find the longest sequence with at most 2 integers</p>
<h2 id="Quick-select"><a href="#Quick-select" class="headerlink" title="Quick select"></a>Quick select</h2><p>Average <code>O(n)</code>, worst case <code>O(n^2)</code>, need to shuffle.<br>if quick select Kth element, then in the range [0, K] is guarantee the K smallest elemets in unsorted array.</p>
<p>Summary of top k problem:<br><a href="https://leetcode.com/problems/k-closest-points-to-origin/discuss/220235/" target="_blank" rel="noopener">https://leetcode.com/problems/k-closest-points-to-origin/discuss/220235/</a></p>
<h2 id="Binary-search"><a href="#Binary-search" class="headerlink" title="Binary search"></a>Binary search</h2><p>how to decide the condition?<br>lo &lt; hi or lo &lt;= hi?<br>hi = mid - 1 or hi = mid?<br>lo = mid + 1 or lo = mid?</p>
<p>when target exists, use<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (lo &lt;= hi)</span><br></pre></td></tr></table></figure></p>
<p>because it will finally concentrate. lo == hi will be the result:<br>hi = mid - 1 or hi = mid?<br>or<br>lo = mid + 1 or lo = mid?<br>does not matter.<br>对于可能不存在的也用lo &lt;= hi，但要保证hi = mid - 1 和 lo = mid + 1</p>
<p>You use while (start &lt;= end) if you are returning the match from inside the loop.<br>You use while (start &lt; end) if you want to exit out of the loop first, and then use the result of start or end to return the match.</p>
<h2 id="Backtracking"><a href="#Backtracking" class="headerlink" title="Backtracking"></a>Backtracking</h2><p><a href="https://www.geeksforgeeks.org/backtracking-algorithms/#standard" target="_blank" rel="noopener"><code>Backtracking</code></a> is an algorithmic-technique for solving problems <code>recursively</code> by trying to build a solution <code>incrementally</code>, one piece at a time, abandons those solutions that fail to satisfy the constraints of the problem at any point of time.</p>
<p>for example:<br>SudoKo<br><a href="https://www.youtube.com/watch?v=xouin83ebxE" target="_blank" rel="noopener">N Queens problem</a>, smart at process diagonal row-col and row + col. think recursion as a tree, back and forth.</p>
<p>leetcode <a href="https://leetcode.com/problems/permutations/discuss/18239" target="_blank" rel="noopener">summary</a> backtracking about <code>Subsets</code>, <code>Permutations</code>, and <code>Combination Sum</code></p>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>x^y how to describe: x to the power of y<br>x^2: x squard<br>x^3: x cubed</p>
<h2 id="Find-rectangle"><a href="#Find-rectangle" class="headerlink" title="Find rectangle"></a>Find rectangle</h2><p>p1[x,y], p2[x,y]<br>if p1 and p2 are diagonal, check if other 2 points exist, can use hashmap or hashset</p>
<h2 id="Toggle-1-and-0"><a href="#Toggle-1-and-0" class="headerlink" title="Toggle 1 and 0"></a>Toggle 1 and 0</h2><p>use xor 1 to toggle 1 and 0<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span></span><br><span class="line">a ^= <span class="number">1</span>; <span class="comment">// a is 0</span></span><br><span class="line">a ^= <span class="number">1</span>; <span class="comment">// a is 1</span></span><br></pre></td></tr></table></figure></p>
<p>calculate power of 2:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Math.pow(<span class="number">2</span>, n); <span class="comment">// slow</span></span><br><span class="line"><span class="comment">// or can use shift</span></span><br><span class="line"><span class="number">1</span> &lt;&lt; n <span class="comment">// fast</span></span><br></pre></td></tr></table></figure></p>
<h2 id="Union-Find"><a href="#Union-Find" class="headerlink" title="Union Find"></a>Union Find</h2><p>for quick find, all sites in a component must have the same value in id[], directly check <code>id[p] == id[q]</code><br>for quick union, set the root of pool p to the root of q<br>then improve quick union, compress the path when seach the root:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span>[] uf, <span class="keyword">int</span> i)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (uf[i] != i)</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="comment">// path compression</span></span><br><span class="line">    uf[i] = uf[uf[i]];</span><br><span class="line">    i = uf[i];</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="sort"><a href="#sort" class="headerlink" title="sort"></a>sort</h2><p>in-place:<br>  bobble sort     stable<br>  selection sort  not stable<br>  insertion sort  stable<br>  quick sort      not stable<br>  heap sort       not stable<br>need space:<br>  merge sort      stable</p>
<p>insertion sort对于partial sorted的数组排序很快。<br>merge sort O(nlogn) 很稳定，可以用merge sort的思路去divide and conquer解决其他问题<br>quick sort 最坏O(n^2)，比如排好序的数组，所以需要shuffle: <code>Collections.shuffle(list)</code></p>
<p>radix sort不是通过comparison机制实现的, leetcode 164</p>
<p>sort one array based on another array<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// sort a based on b</span></span><br><span class="line"><span class="keyword">int</span>[] a = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">2</span>,<span class="number">5</span>,<span class="number">78</span>,<span class="number">4</span>,<span class="number">2</span>&#125;;</span><br><span class="line"><span class="keyword">int</span>[] b = <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">7</span>,<span class="number">45</span>,<span class="number">2</span>,<span class="number">4</span>,<span class="number">7</span>,<span class="number">78</span>,<span class="number">2</span>,<span class="number">4</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// pair[i][0] = a[i];</span></span><br><span class="line"><span class="comment">// pair[i][1] = b[i];</span></span><br><span class="line"><span class="keyword">int</span>[][] pair = <span class="keyword">new</span> <span class="keyword">int</span>[a.length][a.length];</span><br><span class="line">Arrays.sort(pair, (a, b) -&gt; a[<span class="number">1</span>] - b[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line"><span class="comment">// or use map &lt;b value: b index&gt;</span></span><br><span class="line"><span class="comment">// the sort b, recreate a using the map mapping</span></span><br></pre></td></tr></table></figure></p>
<h2 id="0-1-knapsack"><a href="#0-1-knapsack" class="headerlink" title="0/1 knapsack"></a>0/1 knapsack</h2><h2 id="Binary-Search-Tree"><a href="#Binary-Search-Tree" class="headerlink" title="Binary Search Tree"></a>Binary Search Tree</h2><p>need to know different traverse orders:</p>
<ul>
<li><em>pre-order</em>: current -&gt; display -&gt; left -&gt; right</li>
<li><em>post-order</em>: current -&gt; left -&gt; right -&gt; display</li>
<li><em>in-order</em>: current -&gt; left -&gt; display -&gt; right, this will get ascending order if traverse a BST.</li>
<li><em>out-order</em>: current -&gt; right -&gt; display -&gt; left, this will get descending order if traverse a BST</li>
</ul>
<p>pre order list can build BST uniquely.<br>(post)pre order + in order can build BT uniquely</p>
<h3 id="threaded-binary-search-tree"><a href="#threaded-binary-search-tree" class="headerlink" title="threaded binary search tree"></a>threaded binary search tree</h3><p>LC 99:<br><a href="https://leetcode.com/problems/recover-binary-search-tree/submissions/" target="_blank" rel="noopener">https://leetcode.com/problems/recover-binary-search-tree/submissions/</a><br>video:<br>morris traversal inorder to binary tree: 不用递归的方式，实现constant space的一种traverse<br><a href="https://www.youtube.com/watch?v=wGXB9OWhPTg" target="_blank" rel="noopener">https://www.youtube.com/watch?v=wGXB9OWhPTg</a><br><a href="https://www.geeksforgeeks.org/inorder-tree-traversal-without-recursion-and-without-stack/" target="_blank" rel="noopener">https://www.geeksforgeeks.org/inorder-tree-traversal-without-recursion-and-without-stack/</a></p>
<h2 id="Undirected-graph"><a href="#Undirected-graph" class="headerlink" title="Undirected graph"></a>Undirected graph</h2><p>vertex and edge matters<br>degree: num of edge connect to a vertex<br>graph API design:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">addEdge()</span><br><span class="line">Iterable adjacent nodes</span><br><span class="line">numEdge()</span><br><span class="line">numVertex()</span><br></pre></td></tr></table></figure></p>
<p>How to repesent vertex and it’s edge, here use <code>adjacency list</code><br>如果发现graph的node是连续的，比如<code>0 ~ n-1</code>则用adjacency list比较好，否则用<code>Map&lt;Integer, List&lt;Integer&gt;&gt;</code><br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// generic array</span></span><br><span class="line">List&lt;Integer&gt;[] adj = (List&lt;Integer&gt;[]) <span class="keyword">new</span> List[n];</span><br><span class="line"><span class="comment">// it seems we can do now:</span></span><br><span class="line">List&lt;Integer&gt;[] adj =  <span class="keyword">new</span> List[n];</span><br><span class="line">TreeMap&lt;Integer, Integer&gt;[] tmap = <span class="keyword">new</span> TreeMap[n];</span><br><span class="line"><span class="comment">// init</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">&#123;</span><br><span class="line">  adj[i] = <span class="keyword">new</span> ArrayList&lt;Integer&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>actually we can use list of list instead of this format, but array is faster.<br><a href="https://stackoverflow.com/questions/8559092/create-an-array-of-arraylists" target="_blank" rel="noopener">how to create an array of list</a></p>
<p>may contains:<br>self-loop<br>parallel edges</p>
<h3 id="BFS"><a href="#BFS" class="headerlink" title="BFS"></a>BFS</h3><p>use <code>queue</code> to hold the vertices<br>add all unmarked vertices to queue adjacent to v and mark them<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">boolean</span>[] marked;</span><br><span class="line"><span class="keyword">int</span>[] edgeTo;</span><br><span class="line"><span class="keyword">int</span>[] distTo;</span><br></pre></td></tr></table></figure></p>
<p>time complexity: O(E + V)</p>
<h3 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h3><p>for example, find exit for maze graph<br>mark vertex has visited<br>recursive (or use <code>stack</code> )visit all unmarked vertices w adjancent to v<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">boolean</span>[] marked;</span><br><span class="line"><span class="keyword">int</span>[] edgeTo;</span><br></pre></td></tr></table></figure></p>
<p>time complexity: O(E + V)</p>
<h3 id="Bridge"><a href="#Bridge" class="headerlink" title="Bridge"></a>Bridge</h3><p>leetcode: <a href="https://leetcode.com/problems/critical-connections-in-a-network/" target="_blank" rel="noopener">1192</a><br>这是一种找bridge的算法: Tarjan algorithm<br>可以看看这个频道的graph theory playlist:<br><a href="https://www.youtube.com/watch?v=aZXi1unBdJA" target="_blank" rel="noopener">https://www.youtube.com/watch?v=aZXi1unBdJA</a><br><a href="https://www.youtube.com/watch?v=TyWtx7q2D7Y" target="_blank" rel="noopener">https://www.youtube.com/watch?v=TyWtx7q2D7Y</a></p>
<h3 id="Connected-components"><a href="#Connected-components" class="headerlink" title="Connected components"></a>Connected components</h3><p>a connected component is a max pool of connected vertices<br>answer the question: is v and w connected in contact time.</p>
<p>DFS? yes, run DFS for each unvisited vertex, verteice in same connected component has the same id (this can represent component number!), so, check vertex id will get result.</p>
<h2 id="Directed-graph"><a href="#Directed-graph" class="headerlink" title="Directed graph"></a>Directed graph</h2><p>also called <code>digraph</code><br>outdegree, indegree<br>directed cycle</p>
<p><code>DAG</code>: directed acyclic graph</p>
<h3 id="Unweighted"><a href="#Unweighted" class="headerlink" title="Unweighted"></a>Unweighted</h3><p><strong>without</strong> weight on edge, the same for DFS and BFS<br>we use <code>adjacency list</code> the same as undirected graph<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt;[] adj;</span><br></pre></td></tr></table></figure></p>
<h4 id="topological-sorting"><a href="#topological-sorting" class="headerlink" title="topological sorting"></a>topological sorting</h4><p>for example, <code>precedence scheduling</code><br>at least one vertex has 0 indegree and should be <code>directed acyclic graph (DAG)</code></p>
<p><code>BFS</code>: 从indegree为0的node开始，压入队列中，每次下一个node的indegree减1，再把下一批indegree为0的node压入队列中，最后如果没有cycle，所有node都应该被explored.</p>
<p><code>DFS</code>也可以，但要注意visited用2种记号表示, 0:没有访问，1:当前访问, 2:完全访问。如果在一次DFS中再次遇到了1，则说明有cycle.当完全访问后，再设置成2.</p>
<h4 id="strongly-connected-component"><a href="#strongly-connected-component" class="headerlink" title="strongly connected component"></a>strongly connected component</h4><p>Strongly connected: there is a path from v to w and w to v as well.<br>skip this topic</p>
<h3 id="Weighted"><a href="#Weighted" class="headerlink" title="Weighted"></a>Weighted</h3><p>API design:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">class DirectedEdge: weight, from, to</span><br><span class="line">class EdgeWeightedDigraph: addEdge(new DirectedEdge(from, to, weight));</span><br><span class="line">distTo(<span class="keyword">int</span> w);</span><br><span class="line">pathTo(<span class="keyword">int</span> w);</span><br></pre></td></tr></table></figure></p>
<p>we still use adjacency list representation:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;DirectedEdge&gt;[] adj = (List&lt;DirectedEdge&gt;[]) <span class="keyword">new</span> List[n];</span><br><span class="line"><span class="comment">// new init array</span></span><br><span class="line">List&lt;DirectedEdge&gt;[] adj = <span class="keyword">new</span> List[n];</span><br></pre></td></tr></table></figure></p>
<h4 id="Dijkstra"><a href="#Dijkstra" class="headerlink" title="Dijkstra"></a>Dijkstra</h4><p><code>non-negative weight</code><br><code>SPT</code>: shortest path tree exist in graph from the source vertex</p>
<p><strong>remember</strong>:<br>Use minium priority queue, to choose the next vertex cloest to the source vertex!<br>Then update the path accordingly if it’s shorter than before (如何实现这个degrade呢?)<br><a href="https://www.geeksforgeeks.org/dijkstras-shortest-path-algorithm-in-java-using-priorityqueue/" target="_blank" rel="noopener">implementation</a></p>
<p>有几点需要注意：</p>
<ol>
<li>它没有实现degrade操作，只是又加入了新的元素在pq中，这样旧的就沉到底部了</li>
<li>有一个visited set去控制结束</li>
<li>注意comparator interface是怎么实现的，override了compare method，其实也用不着，在pq初始化的时候可以用lambda去实现。</li>
</ol>
<p>time complexity of the construct computation: O(ElogV)</p>
<h4 id="Bellman-Ford"><a href="#Bellman-Ford" class="headerlink" title="Bellman-Ford"></a>Bellman-Ford</h4><p><code>no negative cycle</code></p>
<h3 id="A"><a href="#A" class="headerlink" title="A*"></a>A*</h3><p>A graph traversal and path search algorithm<br>leetcode 1263</p>
<h3 id="regular-expression"><a href="#regular-expression" class="headerlink" title="regular expression"></a>regular expression</h3><p>leetcode 819<br>去掉所有非字典字母，然后split每个word组成数组:<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String[] words = p.replaceAll(<span class="string">"\\W+"</span> , <span class="string">" "</span>).toLowerCase().split(<span class="string">"\\s+"</span>);</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Leetcode</category>
      </categories>
      <tags>
        <tag>leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title>Ansible Up and Running, 2nd Edition</title>
    <url>/2019/03/13/book-ansible-up-and-running/</url>
    <content><![CDATA[<blockquote>
<p>Note: This is a fat summary of the book <code>Ansible: Up and Running, 2nd Edition</code>, just for quick revisit and review.</p>
</blockquote>
<p>这本书其实挺不错的，我还总结了在工作中ansible的常用模块在另一个blog里面，然后有一个测试框架，主要用来验证和熟悉新模块的作用。</p>
<p>Could we remove major architectural components from the IT automation stack? Eliminating management daemons and relying instead on OpenSSH meant the system could start managing a computer fleet immediately, without having to set up anything on the managed machines.</p>
<p>the “Making Ansible Go Even Faster” chapter now covers asynchronous tasks, and the “Debugging Ansible Playbooks” chapter now covers the debugger that was introduced in version 2.1.</p>
<p>we are all slowly turning into system engineers.</p>
<h3 id="Chapter-1-Introduction"><a href="#Chapter-1-Introduction" class="headerlink" title="Chapter 1. Introduction"></a>Chapter 1. Introduction</h3><p>When we talk about configuration management, we are typically talking about writing some kind of state description for our servers, and then using a tool to enforce that the servers are, indeed, in that state: the right packages are installed, configuration files contain the expected values and have the expected permissions, the right services are running, and so on.</p>
<p>Ansible is a great tool for deployment as well as configuration management. Using a single tool for both configuration management and deployment makes life simpler for the folks responsible for operations.</p>
<p>Some people talk about the need for <em>orchestration</em> of deployment. This is where multiple remote servers are involved, and things have to happen in a specific order.</p>
<h4 id="How-Ansible-works"><a href="#How-Ansible-works" class="headerlink" title="How Ansible works"></a>How Ansible works</h4><p>In Ansible, a script is called a playbook. A playbook describes which hosts (what Ansible calls remote servers) to configure, and an ordered list of tasks to perform on those hosts.</p>
<p>Ansible will make SSH connections in parallel to web1, web2, and web3. It will execute the first task on the list on all three hosts simultaneously</p>
<p>To manage a remote server with Ansible, the server needs to have SSH and Python 2.5 or later installed, or Python 2.4 with the Python <code>simplejsonlibrary</code> installed. There’s no need to preinstall an agent or anyother software on the host.</p>
<p>The control machine (the one that you use to control remote machines) needs to have Python 2.6 or later installed.</p>
<p>Ansible is <strong>push based</strong>, and has been used successfully in production with thousands of nodes, and has excellent support for environments where servers are dynamically added and removed.</p>
<p>Ansible modules are declarative; you use them to describe the state you want the server to be in. Modules are also idempotent.</p>
<p>Ansible has excellent support for templating, as well as defining variables at different scopes. Anybody who thinks Ansible is equivalent to working with shell scripts has never had to maintain a nontrivial program written in shell. I’ll always choose Ansible over shell scripts for config management tasks if given a choice.</p>
<p>To be productive with Ansible, you need to be familiar with basic Linux system administration tasks. Ansible makes it easy to automate your tasks, but it’s not the kind of tool that “automagically” does things that you otherwise wouldn’t know how to do.</p>
<p>Ansible uses the YAML file format and the Jinja2 templating languages, so you’ll need to learn some YAML and Jinja2 to use Ansible, but both technologies are easy to pick up.</p>
<p>If you prefer not to spend the money on a public cloud, I recommend you install Vagrant on your machine. Vagrant is an excellent open source tool for managing virtual machines. You can use Vagrant to boot a Linux virtual machine inside your laptop, and you can use that as a test server.</p>
<p>Vagrant needs the VirtualBox virtualizer to be installed on your machine. Download <a href="http://www.virtualbox.org/" target="_blank" rel="noopener">VirtualBox</a> and then download <a href="http://www.vagrantup.com/" target="_blank" rel="noopener">Vagrant</a>.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir playbooks</span><br><span class="line">cd playbooks</span><br><span class="line">vagrant init ubuntu/trusty64</span><br><span class="line">vagrant up</span><br></pre></td></tr></table></figure>
<p>The first time you use vagrant up, it will download the virtual machine image file, which might take a while, depending on your internet connection.</p>
<p>You should be able to SSH into your new Ubuntu 14.04 virtual machine by running the following:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant ssh</span><br></pre></td></tr></table></figure></p>
<p>This approach lets us interact with the shell, but Ansible needs to connect to the virtual machine by using the regular SSH client, not the vagrant ssh command.</p>
<p>Tell Vagrant to output the SSH connection details by typing the following:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant ssh-config</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh vagrant@127.0.0.1 -p 2222 -i /Users/lorin/dev/ansiblebook/ch01/</span><br><span class="line">playbooks/.vagrant/machines/default/virtualbox/private_key</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">testserver ansible_host=127.0.0.1 ansible_port=2222 ansible_user=vagrant ansible_private_key_file=.vagrant/machines/default/virtualbox/private_key</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">~/.ansible.cfg</span><br></pre></td></tr></table></figure>
<p>Ansible supports the ssh-agent program, so you don’t need to explicitly specify SSH key files in your inventory files. See <a href="https://learning.oreilly.com/library/view/Ansible:+Up+and+Running,+2nd+Edition/9781491979792/app01.html#SSH_AGENT" target="_blank" rel="noopener">“SSH Agent”</a> for more details if you haven’t used ssh-agent before</p>
<p>If Ansible did not succeed, add the <code>-vvvv</code> flag to see more details about the error:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible testserver -i hosts -m ping -vvvv</span><br></pre></td></tr></table></figure></p>
<h4 id="Simplify-by-ansible-cfg-file"><a href="#Simplify-by-ansible-cfg-file" class="headerlink" title="Simplify by ansible.cfg file"></a>Simplify by <em>ansible.cfg</em> file</h4><p>we’ll use one such mechanism, the <code>ansible.cfg</code> file, to set some defaults so we don’t need to type as much.</p>
<p>Ansible looks for an <code>ansible.cfg</code> file in the following places, in this order:</p>
<ul>
<li>File specified by the ANSIBLE_CONFIG environment variable</li>
<li>./ansible.cfg (ansible.cfg in the current directory)</li>
<li>~/.ansible.cfg (.ansible.cfg in your home directory)</li>
<li>/etc/ansible/ansible.cfg</li>
</ul>
<p>I typically put <em>ansible.cfg</em> in the current directory, alongside my playbooks. That way, I can check it into the same version-control repository that my playbooks are in.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">inventory = hosts</span><br><span class="line">remote_user = vagrant</span><br><span class="line">private_key_file = .vagrant/machines/default/virtualbox/private_key</span><br><span class="line">host_key_checking = False</span><br></pre></td></tr></table></figure>
<p>Disables SSH host-key checking. Otherwise, we need to edit our <em>~/.ssh/known_hosts</em> file every time we destroy and re-create a nodes.</p>
<p>Ansible uses <code>/etc/ansible/hosts</code> as the default location for the inventory file. However, I never use this because I like to keep my inventory files version-controlled alongside my playbooks.</p>
<p>The <code>command</code> module is so commonly used that it’s the default module, so we can omit it<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible testserver -a uptime</span><br><span class="line">## spaces in command use quotes</span><br><span class="line">ansible testserver -a &quot;tail /var/log/dmesg&quot;</span><br><span class="line">## -b becomes root user</span><br><span class="line">ansible testserver -b -a &quot;tail /var/log/syslog&quot;</span><br></pre></td></tr></table></figure></p>
<h3 id="Chapter-2-Playbooks-A-Beginning"><a href="#Chapter-2-Playbooks-A-Beginning" class="headerlink" title="Chapter 2. Playbooks: A Beginning"></a>Chapter 2. Playbooks: A Beginning</h3><p>Most of your time in Ansible will be spent writing <em>playbooks</em>. A playbook is the term that Ansible uses for a configuration management script.</p>
<p>vargant virtual machine ports mapping in <em>vagrantfile</em>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">VAGRANTFILE_API_VERSION = &quot;2&quot;</span><br><span class="line"></span><br><span class="line">Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|</span><br><span class="line">  config.vm.box = &quot;ubuntu/trusty64&quot;</span><br><span class="line">  config.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8080</span><br><span class="line">  config.vm.network &quot;forwarded_port&quot;, guest: 443, host: 8443</span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant reload</span><br><span class="line"></span><br><span class="line">==&gt; default: Forwarding ports...</span><br><span class="line">    default: 80 =&gt; 8080 (adapter 1)</span><br><span class="line">    default: 443 =&gt; 8443 (adapter 1)</span><br><span class="line">    default: 22 =&gt; 2222 (adapter 1)</span><br></pre></td></tr></table></figure>
<h4 id="TLS-VERSUS-SSL"><a href="#TLS-VERSUS-SSL" class="headerlink" title="TLS VERSUS SSL"></a>TLS VERSUS SSL</h4><p>You might be familiar with the term <em>SSL</em> rather than <em>TLS</em>(Transport Layer Security) in the context of secure web servers. SSL is an older protocol that was used to secure communications between browsers and web servers, and it has been superseded by a newer protocol named TLS. Although many continue to use the term <em>SSL</em> to refer to the current secure protocol, in this book, I use the more accurate <em>TLS</em>.</p>
<h4 id="WHY-DO-YOU-USE-TRUE-IN-ONE-PLACE-AND-YES-IN-ANOTHER"><a href="#WHY-DO-YOU-USE-TRUE-IN-ONE-PLACE-AND-YES-IN-ANOTHER" class="headerlink" title="WHY DO YOU USE TRUE IN ONE PLACE AND YES IN ANOTHER?"></a>WHY DO YOU USE TRUE IN ONE PLACE AND YES IN ANOTHER?</h4><p>Strictly speaking, module arguments (for example, update_cache=yes) are treated differently from values elsewhere in playbooks (for example, sudo: True). Values elsewhere are handled by the YAML parser and so use the YAML conventions of truthiness:</p>
<p>YAML truthy</p>
<blockquote>
<p>true, True, TRUE, yes, Yes, YES, on, On, ON, y, Y</p>
</blockquote>
<p>YAML falsey</p>
<blockquote>
<p>false, False, FALSE, no, No, NO, off, Off, OFF, n, N</p>
</blockquote>
<p>Module arguments are passed as strings and use Ansible’s internal conventions:</p>
<p>module arg truthy</p>
<blockquote>
<p>yes, on, 1, true</p>
</blockquote>
<p>module arg falsey</p>
<blockquote>
<p>no, off, 0, false</p>
</blockquote>
<p>I tend to follow the examples in the official Ansible documentation. These typically use yes and no when passing arguments to modules (since that’s consistent with the module documentation), and True and False elsewhere in playbooks.</p>
<h4 id="NOTE"><a href="#NOTE" class="headerlink" title="NOTE"></a>NOTE</h4><p>An Ansible convention is to keep files in a subdirectory named <em>files</em>, and Jinja2 templates in a subdirectory named <em>templates</em>. I follow this convention throughout the book.</p>
<p>For <code>.j2</code> file, when Ansible renders this template, it will replace this variable with the real value.</p>
<p>Inventory files are in the <code>.ini</code> file format.</p>
<h4 id="COWSAY"><a href="#COWSAY" class="headerlink" title="COWSAY"></a><a href="https://michaelheap.com/cowsay-and-ansible/" target="_blank" rel="noopener">COWSAY</a></h4><p>If you have the <em>cowsay</em> program installed on your local machine, Ansible output will look like this instead:</p>
<p>you can download <em>cowsay</em> rpm and install it:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cowsay -l</span><br><span class="line"></span><br><span class="line">Cow files in /usr/share/cowsay:</span><br><span class="line">beavis.zen blowfish bong bud-frogs bunny cheese cower default dragon</span><br><span class="line">dragon-and-cow elephant elephant-in-snake eyes flaming-sheep ghostbusters</span><br><span class="line">head-in hellokitty kiss kitty koala kosh luke-koala mech-and-cow meow milk</span><br><span class="line">moofasa moose mutilated ren satanic sheep skeleton small sodomized</span><br><span class="line">stegosaurus stimpy supermilker surgery telebears three-eyes turkey turtle</span><br><span class="line">tux udder vader vader-koala www</span><br></pre></td></tr></table></figure></p>
<p>set what animal you like:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export ANSIBLE_COW_SELECTION=tux</span><br></pre></td></tr></table></figure></p>
<p>enable cowsay:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export ANSIBLE_NOCOWS=0</span><br></pre></td></tr></table></figure></p>
<p>then if you run playbook:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt; PLAY [Configure webserver with nginx] &gt;</span><br><span class="line"> ---------------------------------------</span><br><span class="line">        \   ^__^</span><br><span class="line">         \  (oo)\_______</span><br><span class="line">            (__)\       )\/\</span><br><span class="line">                ||----w |</span><br><span class="line">                ||     ||</span><br></pre></td></tr></table></figure></p>
<p>If you don’t want to see the cows, you can disable cowsay by setting the <code>ANSIBLE_NOCOWS</code> environment variable like this:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export ANSIBLE_NOCOWS=1</span><br></pre></td></tr></table></figure>
<p>You can also disable cowsay by adding the following to your <em>ansible.cfg</em> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">nocows = 1</span><br></pre></td></tr></table></figure></p>
<h4 id="TIP"><a href="#TIP" class="headerlink" title="TIP"></a>TIP</h4><p>If your playbook file is marked as executable and starts with a line that looks like this<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/usr/bin/env ansible-playbook</span><br></pre></td></tr></table></figure></p>
<p>then you can execute it by invoking it directly, like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./playbook-file.yml</span><br></pre></td></tr></table></figure></p>
<h4 id="YAML-syntax"><a href="#YAML-syntax" class="headerlink" title="YAML syntax"></a>YAML syntax</h4><h5 id="Start-of-file"><a href="#Start-of-file" class="headerlink" title="Start of file"></a>Start of file</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br></pre></td></tr></table></figure>
<p>However, if you forget to put those three dashes at the top of your playbook files, Ansible won’t complain.</p>
<h5 id="String"><a href="#String" class="headerlink" title="String"></a>String</h5><p>In general, YAML strings don’t have to be quoted, although you can quote them if you prefer. Even if there are spaces, you don’t need to quote them.</p>
<p>In some scenarios in Ansible, you will need to quote strings. These typically involve the use of  for variable substitution. </p>
<h5 id="Boolean"><a href="#Boolean" class="headerlink" title="Boolean"></a>Boolean</h5><p>YAML has a native Boolean type, and provides you with a wide variety of strings that can be interpreted as true or false.</p>
<h5 id="List"><a href="#List" class="headerlink" title="List"></a>List</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- My Fair Lady</span><br><span class="line">- Oklahoma</span><br><span class="line">- The Pirates of Penzance</span><br></pre></td></tr></table></figure>
<h5 id="Dictionary"><a href="#Dictionary" class="headerlink" title="Dictionary"></a>Dictionary</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">address: 742 Evergreen Terrace</span><br><span class="line">city: Springfield</span><br><span class="line">state: North Takoma</span><br></pre></td></tr></table></figure>
<h5 id="Line-folding"><a href="#Line-folding" class="headerlink" title="Line folding"></a>Line folding</h5><p>When writing playbooks, you’ll often encounter situations where you’re passing many arguments to a module. For aesthetics, you might want to break this up across multiple lines in your file, but you want Ansible to treat the string as if it were a single line.</p>
<p>You can do this with YAML by using line folding with the greater than (<code>&gt;</code>) character. The YAML parser will replace line breaks with spaces. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">address: &gt;</span><br><span class="line">    Department of Computer Science,</span><br><span class="line">    A.V. Williams Building,</span><br><span class="line">    University of Maryland</span><br><span class="line">city: College Park</span><br><span class="line">state: Maryland</span><br></pre></td></tr></table></figure></p>
<h4 id="Anatomy-of-a-Playbook"><a href="#Anatomy-of-a-Playbook" class="headerlink" title="Anatomy of a Playbook"></a><a href="https://learning.oreilly.com/library/view/ansible-up-and/9781491979792/ch02.html#playbooks_a_beginning" target="_blank" rel="noopener">Anatomy of a Playbook</a></h4><p>A playbook is a list of plays:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">- name: Configure webserver with nginx</span><br><span class="line">  hosts: webservers</span><br><span class="line">  become: True</span><br><span class="line">  tasks:</span><br><span class="line">  - name: install nginx</span><br><span class="line">      apt: name=nginx update_cache=yes</span><br><span class="line"></span><br><span class="line">  - name: copy nginx config file</span><br><span class="line">    copy: src=files/nginx.conf dest=/etc/nginx/sites-available/default</span><br><span class="line"></span><br><span class="line">  - name: enable configuration</span><br><span class="line">    file: &gt;</span><br><span class="line">      dest=/etc/nginx/sites-enabled/default</span><br><span class="line">      src=/etc/nginx/sites-available/default</span><br><span class="line">      state=link</span><br><span class="line"></span><br><span class="line">  - name: copy index.html</span><br><span class="line">    template: src=templates/index.html.j2  dest=/usr/share/nginx/html/index.html mode=0644</span><br><span class="line"></span><br><span class="line">  - name: restart nginx</span><br><span class="line">    service: name=nginx state=restarted</span><br></pre></td></tr></table></figure></p>
<p>you’ll see in <a href="https://learning.oreilly.com/library/view/ansible-up-and/9781491979792/ch16.html#DEBUGGING" target="_blank" rel="noopener">Chapter 16</a>, you can use the <code>--start-at-task &lt;task name&gt;</code> flag to tell <code>ansible-playbook</code> to start a playbook in the middle of a play, but you need to reference the task by name.</p>
<p>Every task must contain a key with the name of a module and a value with the arguments to that module. In the preceding example, the module name is <code>apt</code> and the arguments are <code>name=nginx update_cache=yes</code>.</p>
<p>The arguments are treated as a string, not as a dictionary. This means that if you want to break arguments into multiple lines, you need to use the YAML folding syntax, like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: install nginx</span><br><span class="line">  apt: &gt;</span><br><span class="line">      name=nginx</span><br><span class="line">      update_cache=yes</span><br></pre></td></tr></table></figure></p>
<p>Ansible also supports a task syntax that will let you specify module arguments as a YAML dictionary, which is helpful when using modules that support complex arguments. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Install docker</span><br><span class="line">  any_errors_fatal: true</span><br><span class="line">  yum:</span><br><span class="line">    name: docker-ce</span><br><span class="line">    state: present</span><br><span class="line">    enablerepo: docker-local</span><br></pre></td></tr></table></figure></p>
<h4 id="Modules"><a href="#Modules" class="headerlink" title="Modules"></a>Modules</h4><p>Modules are scripts that come packaged with Ansible and perform some kind of action on a host.</p>
<p>commonly used modules:</p>
<ul>
<li>yum</li>
<li>copy</li>
<li>file</li>
<li>service</li>
<li>template</li>
</ul>
<h5 id="VIEWING-ANSIBLE-MODULE-DOCUMENTATION"><a href="#VIEWING-ANSIBLE-MODULE-DOCUMENTATION" class="headerlink" title="VIEWING ANSIBLE MODULE DOCUMENTATION"></a>VIEWING ANSIBLE MODULE DOCUMENTATION</h5><p>Ansible ships with the <code>ansible-doc</code> command-line tool, which shows documentation about modules. Think of it as man pages for Ansible modules.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-doc yum</span><br></pre></td></tr></table></figure></p>
<p>Recall from the first chapter that Ansible executes a task on a host by generating a custom script based on the module name and arguments, and then copies this script to the host and runs it.</p>
<p>More than 200 modules ship with Ansible, and this number grows with every release. You can also find third-party Ansible modules out there, or write your own.</p>
<h4 id="Putting-It-All-Together"><a href="#Putting-It-All-Together" class="headerlink" title="Putting It All Together"></a>Putting It All Together</h4><p>To sum up, a playbook contains one or more plays. A play associates an unordered set of hosts with an ordered list of tasks. Each task is associated with exactly one module.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------------+         +------------+          +-------------+</span><br><span class="line">|             |     +---&gt;            |      +---&gt;             |</span><br><span class="line">|  playbook   +---------&gt;    play    +----------&gt;    hosts    |</span><br><span class="line">|             |     +---&gt;            |      +---&gt;             |</span><br><span class="line">+-------------+         +------+-----+          +-------------+</span><br><span class="line">                               |</span><br><span class="line">                               |</span><br><span class="line">                               |</span><br><span class="line">                             +---+</span><br><span class="line">                             | | |</span><br><span class="line">                        +----v-v-v----+         +-------------+</span><br><span class="line">                        |             |         |             |</span><br><span class="line">                        |   task      +--------&gt;+   module    |</span><br><span class="line">                        |             |         |             |</span><br><span class="line">                        +-------------+         +-------------+</span><br><span class="line">`</span><br></pre></td></tr></table></figure></p>
<h4 id="Did-Anything-Change-Tracking-Host-State"><a href="#Did-Anything-Change-Tracking-Host-State" class="headerlink" title="Did Anything Change? Tracking Host State"></a>Did Anything Change? Tracking Host State</h4><p>Ansible modules will first check to see whether the state of the host needs to be changed before taking any action. If the state of the host matches the arguments of the module, Ansible takes no action on the host and responds with a state of <code>ok</code>.</p>
<p>Ansible’s detection of state change can be used to trigger additional actions through the use of <em>handlers</em>. But, even without using handlers, it is still a useful form of feedback to see whether your hosts are changing state as the playbook runs.</p>
<h4 id="Variables-and-Handlers"><a href="#Variables-and-Handlers" class="headerlink" title="Variables and Handlers"></a>Variables and Handlers</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Configure webserver with nginx and tls</span><br><span class="line">  hosts: webservers</span><br><span class="line">  become: True</span><br><span class="line">  vars:</span><br><span class="line">    key_file: /etc/nginx/ssl/nginx.key</span><br><span class="line">    cert_file: /etc/nginx/ssl/nginx.crt</span><br><span class="line">    conf_file: /etc/nginx/sites-available/default</span><br><span class="line">    server_name: localhost</span><br><span class="line">  tasks:</span><br><span class="line">    - name: Install nginx</span><br><span class="line">      apt: name=nginx update_cache=yes cache_valid_time=3600</span><br><span class="line"></span><br><span class="line">    - name: create directories for ssl certificates</span><br><span class="line">      file: path=/etc/nginx/ssl state=directory</span><br><span class="line"></span><br><span class="line">    - name: copy TLS key</span><br><span class="line">      copy: src=files/nginx.key dest=&#123;&#123; key_file &#125;&#125; owner=root mode=0600</span><br><span class="line">      notify: restart nginx</span><br><span class="line"></span><br><span class="line">    - name: copy TLS certificate</span><br><span class="line">      copy: src=files/nginx.crt dest=&#123;&#123; cert_file &#125;&#125;</span><br><span class="line">      notify: restart nginx</span><br><span class="line"></span><br><span class="line">    - name: copy nginx config file</span><br><span class="line">      template: src=templates/nginx.conf.j2 dest=&#123;&#123; conf_file &#125;&#125;</span><br><span class="line">      notify: restart nginx</span><br><span class="line"></span><br><span class="line">    - name: enable configuration</span><br><span class="line">      file: dest=/etc/nginx/sites-enabled/default src=&#123;&#123; conf_file &#125;&#125; state=link</span><br><span class="line">      notify: restart nginx</span><br><span class="line"></span><br><span class="line">    - name: copy index.html</span><br><span class="line">      template: src=templates/index.html.j2 dest=/usr/share/nginx/html/index.html</span><br><span class="line">             mode=0644</span><br><span class="line"></span><br><span class="line">  handlers:</span><br><span class="line">    - name: restart nginx</span><br><span class="line">      service: name=nginx state=restarted</span><br></pre></td></tr></table></figure>
<h5 id="Generating-a-TLS-Certificate"><a href="#Generating-a-TLS-Certificate" class="headerlink" title="Generating a TLS Certificate"></a>Generating a TLS Certificate</h5><p>In a production environment, you’d purchase your TLS certificate from a certificate authority, or use a free service such as <a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let’s Encrypt</a>, which Ansible supports via the letsencrypt module.</p>
<p>Here we use self-signed certificate generated free of charge:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir files</span><br><span class="line">openssl req -x509 -nodes -days 3650 -newkey rsa:2048 \</span><br><span class="line">    -subj /CN=localhost \</span><br><span class="line">    -keyout files/nginx.key -out files/nginx.crt</span><br></pre></td></tr></table></figure></p>
<p>Any valid YAML can be used as the value of a variable. You can use lists and dictionaries in addition to strings and Booleans.</p>
<h5 id="Variables"><a href="#Variables" class="headerlink" title="Variables"></a>Variables</h5><p>Variables can be used in tasks, as well as in template files. You reference variables by using the <code></code> notation. Ansible replaces these braces with the value of the variable.</p>
<h5 id="WHEN-QUOTING-IS-NECESSARY"><a href="#WHEN-QUOTING-IS-NECESSARY" class="headerlink" title="WHEN QUOTING IS NECESSARY"></a>WHEN QUOTING IS NECESSARY</h5><p>bad:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: perform some task</span><br><span class="line">  command: &#123;&#123; myapp &#125;&#125; -a foo</span><br></pre></td></tr></table></figure></p>
<p>good:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: perform some task</span><br><span class="line">  command: &quot;&#123;&#123; myapp &#125;&#125; -a foo&quot;</span><br></pre></td></tr></table></figure></p>
<p>A similar problem arises if your argument contains a colon. For example, bad:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: show a debug message</span><br><span class="line">  debug: msg=&quot;The debug module will print a message: neat, eh?&quot;</span><br></pre></td></tr></table></figure></p>
<p>good:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: show a debug message</span><br><span class="line">  debug: &quot;msg=&apos;The debug module will print a message: neat, eh?&apos;&quot;</span><br></pre></td></tr></table></figure></p>
<h4 id="Generating-the-Template"><a href="#Generating-the-Template" class="headerlink" title="Generating the Template"></a>Generating the Template</h4><p>We put templates in <code>templates</code> folder, we use the <code>.j2</code> extension to indicate that the file is a Jinja2 template. However, you can use a different extension if you like; Ansible doesn’t care.</p>
<p>You can use all of the Jinja2 features in your templates, you probably won’t need to use those advanced templating features, though. One Jinja2 feature you probably will use with Ansible is filters: <a href="http://jinja.pocoo.org/docs/dev/templates/" target="_blank" rel="noopener">Jinja2 Template Designer Documentation</a>.</p>
<h5 id="Handlers"><a href="#Handlers" class="headerlink" title="Handlers"></a>Handlers</h5><p>Handlers are one of the conditional forms that Ansible supports. A handler is similar to a task, but it runs only if it has been notified by a task. A task will fire the notification if Ansible recognizes that the task has changed the state of the system. A task notifies a handler by passing the handler’s name as the argument. </p>
<h5 id="A-FEW-THINGS-TO-KEEP-IN-MIND-ABOUT-HANDLERS"><a href="#A-FEW-THINGS-TO-KEEP-IN-MIND-ABOUT-HANDLERS" class="headerlink" title="A FEW THINGS TO KEEP IN MIND ABOUT HANDLERS"></a>A FEW THINGS TO KEEP IN MIND ABOUT HANDLERS</h5><p>Handlers usually run after all of the tasks are run at the end of the <em>play</em>. They run only <em>once</em>, even if they are notified multiple times. If a play contains multiple handlers, the handlers always run in the order that they are <em>defined</em> in the handlers section, not the notification order.</p>
<p>The official Ansible docs mention that the only common uses for handlers are for restarting services and for reboots. Personally, I’ve always used them only for restarting services.Even then, it’s a pretty small optimization, since we can always just unconditionally restart the service at the end of the playbook instead of notifying it on change, and restarting a service doesn’t usually take very long.</p>
<h3 id="Chapter-3-Inventory-Describing-Your-Servers"><a href="#Chapter-3-Inventory-Describing-Your-Servers" class="headerlink" title="Chapter 3. Inventory: Describing Your Servers"></a>Chapter 3. Inventory: Describing Your Servers</h3><p>The collection of hosts that Ansible knows about is called the inventory. In this chapter, you will learn how to describe a set of hosts as an Ansible inventory.</p>
<p>Ansible automatically adds one host to the inventory by default: <em>localhost</em>. Ansible understands that localhost refers to your local machine, so it will interact with it directly rather than connecting by SSH.</p>
<h4 id="Preliminaries-Multiple-Vagrant-Machines"><a href="#Preliminaries-Multiple-Vagrant-Machines" class="headerlink" title="Preliminaries: Multiple Vagrant Machines"></a>Preliminaries: Multiple Vagrant Machines</h4><p>Before you modify your existing Vagrantfile, make sure you destroy your existing virtual machine by running the following:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant destroy --force</span><br></pre></td></tr></table></figure></p>
<p><em>vagrantfile</em> for three servers:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">VAGRANTFILE_API_VERSION = &quot;2&quot;</span><br><span class="line"></span><br><span class="line">Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|</span><br><span class="line">  # Use the same key for each machine</span><br><span class="line">  config.ssh.insert_key = false</span><br><span class="line"></span><br><span class="line">  config.vm.define &quot;vagrant1&quot; do |vagrant1|</span><br><span class="line">    vagrant1.vm.box = &quot;ubuntu/trusty64&quot;</span><br><span class="line">    vagrant1.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8080</span><br><span class="line">    vagrant1.vm.network &quot;forwarded_port&quot;, guest: 443, host: 8443</span><br><span class="line">  end</span><br><span class="line">  config.vm.define &quot;vagrant2&quot; do |vagrant2|</span><br><span class="line">    vagrant2.vm.box = &quot;ubuntu/trusty64&quot;</span><br><span class="line">    vagrant2.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8081</span><br><span class="line">    vagrant2.vm.network &quot;forwarded_port&quot;, guest: 443, host: 8444</span><br><span class="line">  end</span><br><span class="line">  config.vm.define &quot;vagrant3&quot; do |vagrant3|</span><br><span class="line">    vagrant3.vm.box = &quot;ubuntu/trusty64&quot;</span><br><span class="line">    vagrant3.vm.network &quot;forwarded_port&quot;, guest: 80, host: 8082</span><br><span class="line">    vagrant3.vm.network &quot;forwarded_port&quot;, guest: 443, host: 8445</span><br><span class="line">  end</span><br><span class="line">end</span><br></pre></td></tr></table></figure></p>
<p>Using the same key on each host simplifies our Ansible setup because we can specify a single SSH key in the <em>ansible.cfg</em> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">inventory = inventory</span><br><span class="line">remote_user = vagrant</span><br><span class="line">private_key_file = ~/.vagrant.d/insecure_private_key</span><br><span class="line">host_key_checking = False</span><br></pre></td></tr></table></figure></p>
<p>In the inventory file, you can use <code>ansible_host</code> to explicitly specify IP and <code>ansible_port</code> indicates SSH port number:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vagrant1 ansible_host=127.0.0.1 ansible_port=2222</span><br><span class="line">vagrant2 ansible_host=127.0.0.1 ansible_port=2200</span><br><span class="line">vagrant3 ansible_host=127.0.0.1 ansible_port=2201</span><br></pre></td></tr></table></figure></p>
<h4 id="Behavioral-Inventory-Parameters"><a href="#Behavioral-Inventory-Parameters" class="headerlink" title="Behavioral Inventory Parameters"></a>Behavioral Inventory Parameters</h4><p><a href="https://www.tablesgenerator.com/markdown_tables" target="_blank" rel="noopener">Markdown table generator</a><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">|            Name            	|     Default     	|                                   Description                                   	|</span><br><span class="line">|:--------------------------:	|:---------------:	|:-------------------------------------------------------------------------------:	|</span><br><span class="line">| ansible_host               	| Name of host    	| Hostname or IP address to SSH to                                                	|</span><br><span class="line">| ansible_port               	| 22              	| Port to SSH to                                                                  	|</span><br><span class="line">| ansible_user               	| Root            	| User to SSH as                                                                  	|</span><br><span class="line">| ansible_password           	| (None)          	| Password to use for SSH authentication                                          	|</span><br><span class="line">| ansible_connection         	| smart           	| How Ansible will connect to host (see the following section)                    	|</span><br><span class="line">| ansible_private_key_file   	| (None)          	| SSH private key to use for SSH authenticatio                                    	|</span><br><span class="line">| ansible_shell_type         	| sh              	| Shell to use for commands (see the following section)                           	|</span><br><span class="line">| ansible_python_interpreter 	| /usr/bin/python 	| Python interpreter on host (see the following section)                          	|</span><br><span class="line">| ansible_*_interpreter      	| (None)          	| Like ansible_python_interpreter for other languages (see the following section) 	|</span><br></pre></td></tr></table></figure></p>
<p>Explanation:</p>
<ul>
<li><p>ansible_connection<br>Ansible supports multiple <em>transports</em>, which are mechanisms that Ansible uses to connect to the host. The default transport, <code>smart</code>, will check whether the locally installed SSH client supports a feature called <em>ControlPersist</em>. If the SSH client supports ControlPersist, Ansible will use the local SSH client. If the SSH client doesn’t support ControlPersist, the smart transport will fall back to using a Python-based SSH client library called <em>Paramiko</em>.</p>
</li>
<li><p>ansible_shell_type<br>Ansible works by making SSH connections to remote machines and then invoking scripts.By default, Ansible assumes that the remote shell is the Bourne shell located at <em>/bin/sh</em>, and will generate the appropriate command-line parameters that work with Bourne shell.</p>
<p>Ansible also accepts <code>csh</code>, <code>fish</code>, and (on Windows) <code>powershell</code> as valid values for<br>this parameter. I’ve never encountered a need for changing the shell type.</p>
</li>
<li><p>ansible_python_interpreter<br>Because the modules that ship with Ansible are implemented in Python 2, Ansible needs to know the location of the Python interpreter on the remote machine. You might need to change this if your remote host does not have a Python 2 interpreter at <em>/usr/bin/python</em>. For example, if you are managing hosts that run Arch Linux, you will need to change this to <em>/usr/bin/python2</em>, because Arch Linux installs Python 3 at <em>/usr/bin/python</em>, and Ansible modules are not (yet) compatible with Python 3.</p>
</li>
<li><p>ansible_*_interpreter<br>If you are using a custom module that is not written in Python, you can use this parameter to specify the location of the interpreter (e.g., /usr/bin/ruby).</p>
</li>
</ul>
<p><strong>Note</strong>: You can override some of the behavioral parameter default values in the defaults section of the <code>ansible.cfg</code> file<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Behavioral inventory parameter 	| ansible.cfg option 	|</span><br><span class="line">|:------------------------------:	|:------------------:	|</span><br><span class="line">| ansible_port                   	| remote_port        	|</span><br><span class="line">| ansible_user                   	| remote_user        	|</span><br><span class="line">| ansible_private_key_file       	| private_key_file   	|</span><br><span class="line">| ansible_shell_type             	| executable         	|</span><br></pre></td></tr></table></figure></p>
<h4 id="Groups"><a href="#Groups" class="headerlink" title="Groups"></a>Groups</h4><p>Ansible automatically defines a group called <code>all</code> (or <code>*</code>), which includes all of the hosts in the inventory. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible all -a &quot;date&quot;</span><br><span class="line">ansible &apos;*&apos; -a &quot;date&quot;</span><br></pre></td></tr></table></figure></p>
<p>We can define our own groups in the inventory file. Ansible uses the <em>.ini</em> file format for inventory files. In the <em>.ini</em> format, configuration values are grouped together into sections. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[master]</span><br><span class="line"></span><br><span class="line">[workers]</span><br><span class="line"></span><br><span class="line">[nodes]</span><br><span class="line"></span><br><span class="line">[all:vars]</span><br><span class="line">ansible_connection=ssh</span><br><span class="line">ansible_user=root</span><br><span class="line">ansible_ssh_private_key_file=null</span><br><span class="line">gather_facts=True</span><br><span class="line">gathering=smart</span><br><span class="line">host_key_checking=False</span><br></pre></td></tr></table></figure></p>
<h4 id="Alias-and-Ports"><a href="#Alias-and-Ports" class="headerlink" title="Alias and Ports:"></a>Alias and Ports:</h4><p>In inventory file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[master]</span><br><span class="line">&lt;hostname&gt;</span><br><span class="line">&lt;hostname&gt;:&lt;port number&gt;</span><br><span class="line">&lt;alias&gt; ansible_host=&lt;IP&gt; ansible_port=&lt;port number&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="Groups-of-groups"><a href="#Groups-of-groups" class="headerlink" title="Groups of groups"></a>Groups of groups</h4><p>Ansible also allows you to define groups that are made up of other groups. Here web and task are groups, diango subgroup wrap them up.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[django:children]</span><br><span class="line">web</span><br><span class="line">task</span><br></pre></td></tr></table></figure></p>
<h4 id="Numbered-hosts"><a href="#Numbered-hosts" class="headerlink" title="Numbered hosts"></a>Numbered hosts</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[host]</span><br><span class="line">web[1:20].example.com</span><br><span class="line">## leading 0</span><br><span class="line">web[01:20].example.com</span><br><span class="line">web-[a-t].example.com</span><br></pre></td></tr></table></figure>
<h4 id="Host-and-Group-Variables"><a href="#Host-and-Group-Variables" class="headerlink" title="Host and Group Variables"></a>Host and Group Variables</h4><p>Format: [<group name="">:vars]<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[all:vars]</span><br><span class="line"></span><br><span class="line">[production:vars]</span><br><span class="line"></span><br><span class="line">[staging:vars]</span><br></pre></td></tr></table></figure></group></p>
<p>Additionally, though Ansible variables can hold Booleans, strings, lists, and dictionaries, in an inventory file, you can specify only Booleans and strings.</p>
<p>Ansible offers a more scalable approach to keep track of host and group variables: you can create a separate variable file for each host and each group. Ansible expects these variable files to be in YAML format.</p>
<p>Ansible looks for host variable files in a directory called <code>host_vars</code> and group variable files in a directory called <code>group_vars</code>. Ansible expects these directories to be either in the directory that contains your playbooks or in the directory adjacent to your inventory file. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">playbooks folder:</span><br><span class="line">  - playbook.yml</span><br><span class="line">  - group_vars folder</span><br><span class="line">    - production</span><br></pre></td></tr></table></figure></p>
<p>If we use YAML dictionary format in group variable file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">db:</span><br><span class="line">    user: widgetuser</span><br><span class="line">    password: pFmMxcyD;Fc6)6</span><br><span class="line">    name: widget_production</span><br><span class="line">    primary:</span><br><span class="line">        host: rhodeisland.example.com</span><br><span class="line">        port: 5432</span><br><span class="line">    replica:</span><br><span class="line">        host: virginia.example.com</span><br><span class="line">        port: 5432</span><br><span class="line"></span><br><span class="line">rabbitmq:</span><br><span class="line">    host: pennsylvania.example.com</span><br><span class="line">    port: 5672</span><br></pre></td></tr></table></figure></p>
<p>when reference in playbook:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123; db.primary.host &#125;&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="Dynamic-Inventory"><a href="#Dynamic-Inventory" class="headerlink" title="Dynamic Inventory"></a>Dynamic Inventory</h4><p>If the inventory file is marked executable, Ansible will assume it is a dynamic inventory script and will execute the file instead of reading it.</p>
<p>If some other system, such as AWS EC2, will keep track of the virtual machine information for us, we don’t necessarily need to write the inventory file manually, we can use dynamic inventory script to query about which machines are running and use them.</p>
<p><a href="https://github.com/ansible/ansible/blob/devel/contrib/inventory/vagrant.py" target="_blank" rel="noopener">preexisting inventory scripts</a></p>
<h4 id="Adding-Entries-at-Runtime-with-add-host-and-group-by"><a href="#Adding-Entries-at-Runtime-with-add-host-and-group-by" class="headerlink" title="Adding Entries at Runtime with add_host and group_by"></a>Adding Entries at Runtime with add_host and group_by</h4><p>Ansible will let you add hosts and groups to the inventory during the execution of a playbook.<br><strong>not use yet</strong></p>
<h3 id="Chapter-4-Variables-and-Facts"><a href="#Chapter-4-Variables-and-Facts" class="headerlink" title="Chapter 4. Variables and Facts"></a>Chapter 4. Variables and Facts</h3><p>Ansible is not a full-fledged programming language, but it does have several programming language features, and one of the most important of these is <strong>variable substitution</strong>. This chapter presents Ansible’s support for variables in more detail, including a certain type of variable that Ansible calls a <em>fact</em>.</p>
<h4 id="Defining-Variables-in-Playbooks"><a href="#Defining-Variables-in-Playbooks" class="headerlink" title="Defining Variables in Playbooks"></a>Defining Variables in Playbooks</h4><p>There are two scenarios, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Configure Kubeadm</span><br><span class="line">  hosts: master</span><br><span class="line">  become: true</span><br><span class="line">  any_errors_fatal: true</span><br><span class="line">  vars:</span><br><span class="line">    NODE_COUNT: &quot;&#123;&#123; groups[&apos;nodes&apos;] | length &#125;&#125;&quot;</span><br><span class="line">  roles:</span><br><span class="line">    - setup.master</span><br><span class="line"></span><br><span class="line">## or</span><br><span class="line">- name: Configure Kubeadm</span><br><span class="line">  hosts: master</span><br><span class="line">  become: true</span><br><span class="line">  any_errors_fatal: true</span><br><span class="line">  vars_files:</span><br><span class="line">    - config.yml</span><br><span class="line">  roles:</span><br><span class="line">    - setup.master</span><br></pre></td></tr></table></figure></p>
<h4 id="Viewing-the-Values-of-Variables"><a href="#Viewing-the-Values-of-Variables" class="headerlink" title="Viewing the Values of Variables"></a>Viewing the Values of Variables</h4><p>We use the <code>debug</code> module to print out an arbitrary message. We can also use it to output the value of the variable.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- debug: var=&lt;myvarname&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="Registering-Variables"><a href="#Registering-Variables" class="headerlink" title="Registering Variables"></a>Registering Variables</h4><p>Often, you’ll find that you need to set the value of a variable based on the result of a task.To do so, we create a <em>registered variable</em> using the <code>register</code> clause when invoking a module. Below shows how to capture the output of the <code>whoami</code> command to a variable named <code>login</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: capture output of whoami command</span><br><span class="line">  command: whoami</span><br><span class="line">  register: login</span><br></pre></td></tr></table></figure></p>
<p><strong>Note</strong>, if you want to use <code>login</code> variable registered here, it’s not like that you can call it as <code></code></p>
<p>In order to use the login variable later, we need to know the type of value to expect. The value of a variable set using the register clause is always a dictionary, but the specific keys of the dictionary are different, depending on the module that was invoked.</p>
<p>Unfortunately, the official Ansible module documentation doesn’t contain information about what the return values look like for each module. The module docs do often contain examples that use the register clause, which can be helpful. I’ve found the simplest way to find out what a module returns is to register a variable and then output that variable with the debug module.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: show return value of command module</span><br><span class="line">  hosts: server1</span><br><span class="line">  tasks:</span><br><span class="line">    - name: capture output of id command</span><br><span class="line">      command: id -un</span><br><span class="line">      register: login</span><br><span class="line">    - debug: var=login</span><br></pre></td></tr></table></figure></p>
<p>The <code>shell</code> module has the same output structure as the <code>command</code> module, but other modules contain different keys, the output here is:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK: [debug var=login] *******************************************************</span><br><span class="line">ok: [server1] =&gt; &#123;</span><br><span class="line">    &quot;login&quot;: &#123;</span><br><span class="line">        &quot;changed&quot;: true, 1</span><br><span class="line">        &quot;cmd&quot;: [ 2</span><br><span class="line">            &quot;id&quot;,</span><br><span class="line">            &quot;-un&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;delta&quot;: &quot;0:00:00.002180&quot;,</span><br><span class="line">        &quot;end&quot;: &quot;2015-01-11 15:57:19.193699&quot;,</span><br><span class="line">        &quot;invocation&quot;: &#123;</span><br><span class="line">            &quot;module_args&quot;: &quot;id -un&quot;,</span><br><span class="line">            &quot;module_name&quot;: &quot;command&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;rc&quot;: 0, 3</span><br><span class="line">        &quot;start&quot;: &quot;2015-01-11 15:57:19.191519&quot;,</span><br><span class="line">        &quot;stderr&quot;: &quot;&quot;, 4</span><br><span class="line">        &quot;stdout&quot;: &quot;vagrant&quot;, 5</span><br><span class="line">        &quot;stdout_lines&quot;: [ 6</span><br><span class="line">            &quot;vagrant&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;warnings&quot;: []</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>The <code>changed</code> key is present in the return value of all Ansible modules, and Ansible uses it to determine whether a state change has occurred. For the <code>command</code> and <code>shell</code>module, this will always be set to <code>true</code> unless overridden with the <code>changed_when</code>clause.</p>
</li>
<li><p>The <code>cmd</code> key contains the invoked command as a list of strings.</p>
</li>
<li><p>The <code>rc</code> key contains the return code. If it is nonzero, Ansible will assume the task failed to execute.</p>
</li>
<li><p>The <code>stdout</code> key contains any text written to standard out, as a single string.</p>
</li>
<li><p>The <code>stdout_lines</code> key contains any text written to split by newline. It is a list, and each element of the list is a line of output.</p>
</li>
</ul>
<p>So now you can access <code>login</code> with:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: capture output of id command</span><br><span class="line">  command: id -un</span><br><span class="line">  register: login</span><br><span class="line">- debug: msg=&quot;Logged in as user &#123;&#123; login.stdout &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<h5 id="ACCESSING-DICTIONARY-KEYS-IN-A-VARIABLE"><a href="#ACCESSING-DICTIONARY-KEYS-IN-A-VARIABLE" class="headerlink" title="ACCESSING DICTIONARY KEYS IN A VARIABLE"></a>ACCESSING DICTIONARY KEYS IN A VARIABLE</h5><p>If a variable contains a dictionary, you can access the keys of the dictionary by using either a dot (.) or a subscript ([]).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123; login.stdout &#125;&#125;</span><br><span class="line">&#123;&#123; login[&apos;stdout&apos;] &#125;&#125;</span><br><span class="line"></span><br><span class="line">ansible_eth1[&apos;ipv4&apos;][&apos;address&apos;]</span><br><span class="line">ansible_eth1[&apos;ipv4&apos;].address</span><br><span class="line">ansible_eth1.ipv4[&apos;address&apos;]</span><br><span class="line">ansible_eth1.ipv4.address</span><br></pre></td></tr></table></figure></p>
<h5 id="CAUTION"><a href="#CAUTION" class="headerlink" title="CAUTION"></a>CAUTION</h5><p>If your playbooks use registered variables, make sure you know the content of those variables, both for cases where the module changes the host’s state and for when the module doesn’t change the host’s state. Otherwise, your playbook might fail when it tries to access a key in a registered variable that doesn’t exist.</p>
<h4 id="Facts"><a href="#Facts" class="headerlink" title="Facts"></a>Facts</h4><p>As you’ve already seen, when Ansible runs a playbook, before the first task runs, this happens:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GATHERING FACTS **************************************************</span><br><span class="line">ok: [servername]</span><br></pre></td></tr></table></figure></p>
<p>When Ansible gathers facts, it connects to the host and queries it for all kinds of details about the host: CPU architecture, operating system, IP addresses, memory info, disk info, and more. This information is stored in variables that are called <em>facts</em>, and they behave just like any other variable. For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: print out operating system</span><br><span class="line">  hosts: all</span><br><span class="line">  gather_facts: True</span><br><span class="line">  tasks:</span><br><span class="line">  - debug: var=ansible_distribution</span><br></pre></td></tr></table></figure></p>
<p>List of facts variable can be found <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_variables.html#information-discovered-from-systems-facts" target="_blank" rel="noopener">here</a></p>
<h5 id="Viewing-All-Facts-Associated-with-a-Server"><a href="#Viewing-All-Facts-Associated-with-a-Server" class="headerlink" title="Viewing All Facts Associated with a Server"></a>Viewing All Facts Associated with a Server</h5><p>Ansible implements fact collecting through the use of a special module called the <code>setup</code>module. You don’t need to call this module in your playbooks because Ansible does that automatically when it gathers facts.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible server1 -m setup</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server1 | success &gt;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;ansible_all_ipv4_addresses&quot;: [</span><br><span class="line">            &quot;10.0.2.15&quot;,</span><br><span class="line">            &quot;192.168.4.10&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;ansible_all_ipv6_addresses&quot;: [</span><br><span class="line">            &quot;fe80::a00:27ff:fefe:1e4d&quot;,</span><br><span class="line">            &quot;fe80::a00:27ff:fe67:bbf3&quot;</span><br><span class="line">        ],</span><br><span class="line">(many more facts)</span><br></pre></td></tr></table></figure>
<p>Note that the returned value is a dictionary whose key is <code>ansible_facts</code> and whose value is a dictionary that contains the name and value of the actual facts.</p>
<h5 id="Viewing-a-Subset-of-Facts"><a href="#Viewing-a-Subset-of-Facts" class="headerlink" title="Viewing a Subset of Facts"></a>Viewing a Subset of Facts</h5><p>The <code>setup</code> module supports a <code>filter</code> parameter that lets you filter by fact name by specifying a glob.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible web -m setup -a &apos;filter=ansible_eth*&apos;</span><br></pre></td></tr></table></figure></p>
<h5 id="Any-Module-Can-Return-Facts"><a href="#Any-Module-Can-Return-Facts" class="headerlink" title="Any Module Can Return Facts"></a>Any Module Can Return Facts</h5><p>The use of <code>ansible_facts</code> in the return value is an Ansible idiom. If a module returns a dictionary that contains <code>ansible_facts</code> as a key, Ansible will create variable names in the environment with those values and associate them with the active host.</p>
<p>For modules that return facts, there’s no need to register variables, since Ansible creates these variables for you automatically.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: get ec2 facts</span><br><span class="line">  ec2_facts:</span><br><span class="line"></span><br><span class="line">- debug: var=ansible_ec2_instance_id</span><br></pre></td></tr></table></figure></p>
<p>Several modules ship with Ansible that return facts. You’ll see another one of them, the <code>docker</code> module.</p>
<h5 id="Local-Facts"><a href="#Local-Facts" class="headerlink" title="Local Facts"></a>Local Facts</h5><p>Ansible provides an additional mechanism for associating facts with a host. You can place one or more files on the remote host machine in the <code>/etc/ansible/facts.d</code> directory.<br><strong>not used yet</strong></p>
<h5 id="Using-set-fact-to-Define-a-New-Variable"><a href="#Using-set-fact-to-Define-a-New-Variable" class="headerlink" title="Using set_fact to Define a New Variable"></a>Using set_fact to Define a New Variable</h5><p>Ansible also allows you to set a fact (effectively the same as defining a new variable) in a task by using the <code>set_fact</code> module. I often like to use <code>set_fact</code> immediately after <code>register</code> to make it simpler to refer to a variable.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: get snapshot id</span><br><span class="line">  shell: &gt;</span><br><span class="line">    aws ec2 describe-snapshots --filters</span><br><span class="line">    Name=tag:Name,Values=my-snapshot</span><br><span class="line">    | jq --raw-output &quot;.Snapshots[].SnapshotId&quot;</span><br><span class="line">  register: snap_result</span><br><span class="line"></span><br><span class="line">- set_fact: snap=&#123;&#123; snap_result.stdout &#125;&#125;</span><br><span class="line"></span><br><span class="line">- name: delete old snapshot</span><br><span class="line">  command: aws ec2 delete-snapshot --snapshot-id &quot;&#123;&#123; snap &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<h4 id="Built-in-Variables"><a href="#Built-in-Variables" class="headerlink" title="Built-in Variables"></a>Built-in Variables</h4><p>Ansible defines several variables that are always available in a playbook<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Parameter                	| Description                                                                                                                                                                                 	|</span><br><span class="line">|--------------------------	|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------	|</span><br><span class="line">| hostvars                 	| A dict whose keys are Ansible hostnames and values are dicts  that map variable names to values                                                                                             	|</span><br><span class="line">| inventory_hostname       	| Fully qualified domain name of the current host as known by Ansible  (e.g., myhost.example.com)                                                                                             	|</span><br><span class="line">| inventory_hostname_short 	| Name of the current host as known by Ansible, without the domain name  (e.g., myhost)                                                                                                       	|</span><br><span class="line">| group_names              	| A list of all groups that the current host is a member of                                                                                                                                   	|</span><br><span class="line">| groups                   	| A dict whose keys are Ansible group names and values are a list of  hostnames that are members of the group. Includes all and ungrouped groups:  &#123;&quot;all&quot;: […], &quot;web&quot;: […], &quot;ungrouped&quot;: […]&#125; 	|</span><br><span class="line">| ansible_check_mode       	| A boolean that is true when running in check mode                                                                                                                                           	|</span><br><span class="line">| ansible_play_batch       	| A list of the inventory hostnames that are active in the current batch                                                                                                                      	|</span><br><span class="line">| ansible_play_hosts       	| A list of all of the inventory hostnames that are active in the current  play                                                                                                               	|</span><br><span class="line">| ansible_version          	| A dict with Ansible version info:  &#123;&quot;full&quot;: 2.3.1.0&quot;, &quot;major&quot;: 2, &quot;minor&quot;: 3, &quot;revision&quot;: 1, &quot;string&quot;: &quot;2.3.1.0&quot;&#125;                                                                           	|</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p><strong>hostvars</strong><br>This is a dictionary that contains all of the variables defined on all of the hosts, keyed by the hostname as known to Ansible. If Ansible has not yet gathered facts on a host, you will not be able to access its facts by using the hostvars variable, unless fact caching is enabled.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;&#123; hostvars[&apos;db.example.com&apos;].ansible_eth1.ipv4.address &#125;&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>inventory_hostname</strong><br>The inventory_hostname is the hostname of the current host, as known by Ansible.</p>
</li>
<li><p><strong>groups</strong><br>The groups variable can be useful when you need to access variables for a group of hosts.</p>
</li>
</ul>
<p>I encounter this in playbook vars section:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: xxx</span><br><span class="line">  hosts: master</span><br><span class="line">  become: true</span><br><span class="line">  any_errors_fatal: true</span><br><span class="line">  vars:</span><br><span class="line">    NODE_COUNT: &quot;&#123;&#123; groups[&apos;nodes&apos;] | length &#125;&#125;&quot;</span><br><span class="line">  roles:</span><br><span class="line">    - ...</span><br><span class="line"></span><br><span class="line">- name: xxx</span><br><span class="line">  any_errors_fatal: true</span><br><span class="line">  shell: &quot;...&quot;</span><br><span class="line">  when: &quot;inventory_hostname == groups.master[0]&quot;</span><br></pre></td></tr></table></figure></p>
<h4 id="Setting-Variables-on-the-Command-Line"><a href="#Setting-Variables-on-the-Command-Line" class="headerlink" title="Setting Variables on the Command Line"></a>Setting Variables on the Command Line</h4><p>Variables set by passing <code>-e var=value</code> to <code>ansible-playbook</code> have the highest precedence, which means you can use this to override variables that are already defined.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook greet.yml -e &apos;greeting=&quot;hi there&quot;&apos;</span><br></pre></td></tr></table></figure></p>
<p>Ansible also allows you to pass a file containing the variables instead of passing them directly on the command line by passing @filename.yml as the argument to <code>-e</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook greet.yml -e @greetvars.yml</span><br></pre></td></tr></table></figure></p>
<p>content in <code>greetvars.yml</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">greeting: hiya</span><br></pre></td></tr></table></figure></p>
<h4 id="Precedence"><a href="#Precedence" class="headerlink" title="Precedence"></a>Precedence</h4><p>We’ve covered several ways of defining variables, and it can happen that you define the same variable multiple times for a host, using different values. Avoid this when you can, but if you can’t, then keep in mind Ansible’s precedence rules.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. (Highest) ansible-playbook -e var=value</span><br><span class="line">2. Task variables</span><br><span class="line">3. Block variables</span><br><span class="line">4. Role and include variables</span><br><span class="line">5. set_fact</span><br><span class="line">6. Registered variables</span><br><span class="line">7. vars_files</span><br><span class="line">8. vars_prompt</span><br><span class="line">9. Play variables</span><br><span class="line">10. Host facts</span><br><span class="line">11. host_vars set on a playbook</span><br><span class="line">12. group_vars set on a playbook</span><br><span class="line">13. host_vars set in the inventory</span><br><span class="line">14. group_vars set in the inventory</span><br><span class="line">15. Inventory variables</span><br><span class="line">16. In defaults/main.yml of a role</span><br></pre></td></tr></table></figure></p>
<h3 id="Chapter-5-Introducing-Mezzanine-Our-Test-Application"><a href="#Chapter-5-Introducing-Mezzanine-Our-Test-Application" class="headerlink" title="Chapter 5. Introducing Mezzanine: Our Test Application"></a>Chapter 5. Introducing Mezzanine: Our Test Application</h3><p>Let’s take a little detour and talk about the differences between running software in development mode on your laptop versus running the software in production. Mezzanine is a great example of an application that is much easier to run in development mode than it is to deploy.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">virtualenv venv</span><br><span class="line">source venv/bin/activate</span><br><span class="line">pip install mezzanine</span><br><span class="line">mezzanine-project myproject</span><br><span class="line">cd myproject</span><br><span class="line">sed -i &apos;s/ALLOWED_HOSTS = \[\]/ALLOWED_HOSTS = [&quot;127.0.0.1&quot;]/&apos; settings.py</span><br><span class="line">python manage.py createdb</span><br><span class="line">python manage.py runserver</span><br></pre></td></tr></table></figure></p>
<p>You’ll be prompted to answer several questions. I answered “yes” to each yes/no question, and accepted the default answer whenever one was available.</p>
<p>Now, let’s look at what happens when you deploy to production.</p>
<ul>
<li><p><strong>PostgreSQL: The Database</strong><br>In production, we want to run a server-based database, because those have better support for multiple, concurrent requests, and server-based databases allow us to run multiple HTTP servers for load balancing. This means we need to deploy a database management system such as MySQL or PostgreSQL (aka Postgres). </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Install the database software.</span><br><span class="line">Ensure the database service is running.</span><br><span class="line">Create the database inside the database management system.</span><br><span class="line">Create a database user who has the appropriate permissions for the database system.</span><br><span class="line">Configure our Mezzanine application with the database user credentials and </span><br><span class="line">connection information.</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>Gunicorn: The Application Server</strong></p>
</li>
<li><p><strong>Nginx: The Web Server</strong></p>
</li>
</ul>
<blockquote>
<p>Note: Application server and Web server, their usage is different. Here Nginx is like a <a href="https://www.cnblogs.com/Anker/p/6056540.html" target="_blank" rel="noopener">reverse proxy</a> for Gunicorn.</p>
</blockquote>
<ul>
<li><strong>Supervisor: The Process Manager</strong></li>
</ul>
<h3 id="Chapter-7-Roles-Scaling-Up-Your-Playbooks"><a href="#Chapter-7-Roles-Scaling-Up-Your-Playbooks" class="headerlink" title="Chapter 7. Roles: Scaling Up Your Playbooks"></a>Chapter 7. Roles: Scaling Up Your Playbooks</h3><p>Ansible scales down well because simple tasks are easy to implement. It scales up well because it provides mechanisms for decomposing complex jobs into smaller pieces.</p>
<p>In Ansible, the <code>role</code> is the primary mechanism for breaking a playbook into multiple files. This simplifies writing complex playbooks, and it makes them easier to reuse.</p>
<h4 id="Basic-Structure-of-a-Role"><a href="#Basic-Structure-of-a-Role" class="headerlink" title="Basic Structure of a Role"></a>Basic Structure of a Role</h4><p>An Ansible role has a name, such as <code>database</code>. Files associated with the <code>database</code> role go in the <em>roles/database</em> directory, which contains the following files and directories:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| roles/database/tasks/main.yml    	| Tasks                                    	|</span><br><span class="line">| roles/database/files/            	| Holds files to be uploaded to hosts      	|</span><br><span class="line">| roles/database/templates/        	| Holds Jinja2 template files              	|</span><br><span class="line">| roles/database/handlers/main.yml 	| Handlers                                 	|</span><br><span class="line">| roles/database/vars/main.yml     	| Variables that shouldn’t be overridden   	|</span><br><span class="line">| roles/database/defaults/main.yml 	| Default variables that can be overridden 	|</span><br><span class="line">| roles/database/meta/main.yml     	| Dependency information about a role      	|</span><br></pre></td></tr></table></figure></p>
<p>Each individual file is optional; if your role doesn’t have any handlers, there’s no need to have an empty handlers/main.yml file.</p>
<h4 id="WHERE-DOES-ANSIBLE-LOOK-FOR-MY-ROLES"><a href="#WHERE-DOES-ANSIBLE-LOOK-FOR-MY-ROLES" class="headerlink" title="WHERE DOES ANSIBLE LOOK FOR MY ROLES?"></a>WHERE DOES ANSIBLE LOOK FOR MY ROLES?</h4><p>Ansible looks for roles in the <em>roles</em> directory alongside your playbooks. It also looks for systemwide roles in <em>/etc/ansible/roles</em>. You can customize the systemwide location of roles by setting the <code>roles_path</code> setting in the <code>defaults</code> section of your <em>ansible.cfg</em> file.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">roles_path = ~/ansible_roles</span><br></pre></td></tr></table></figure></p>
<h4 id="Using-Roles-in-Your-Playbooks"><a href="#Using-Roles-in-Your-Playbooks" class="headerlink" title="Using Roles in Your Playbooks"></a>Using Roles in Your Playbooks</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: deploy mezzanine on vagrant</span><br><span class="line">  ## target hosts</span><br><span class="line">  hosts: web</span><br><span class="line">  vars_files:</span><br><span class="line">    - secrets.yml</span><br><span class="line">  ## role section</span><br><span class="line">  roles:</span><br><span class="line">    - role: database</span><br><span class="line">       ## pass variables into role task</span><br><span class="line">      database_name: &quot;&#123;&#123; mezzanine_proj_name &#125;&#125;&quot;</span><br><span class="line">      database_user: &quot;&#123;&#123; mezzanine_proj_name &#125;&#125;&quot;</span><br><span class="line"></span><br><span class="line">    - role: mezzanine</span><br><span class="line">      live_hostname: 192.168.33.10.xip.io</span><br><span class="line">      domains:</span><br><span class="line">        - 192.168.33.10.xip.io</span><br><span class="line">        - www.192.168.33.10.xip.io</span><br></pre></td></tr></table></figure>
<p>Note that we can pass in variables when invoking the roles. If these variables have already been defined in the role (either in vars/main.yml or defaults/main.yml), then the values will be overridden with the variables that were passed in.</p>
<h4 id="Pre-Tasks-and-Post-Tasks"><a href="#Pre-Tasks-and-Post-Tasks" class="headerlink" title="Pre-Tasks and Post-Tasks"></a>Pre-Tasks and Post-Tasks</h4><p>Sometimes you want to run tasks before or after you invoke your roles. Let’s say you want to update the apt cache before you deploy Mezzanine, and you want to send a notification to a Slack channel after you deploy.</p>
<p>Ansible allows you to define a list of tasks that execute before the roles with a <code>pre_tasks</code> section, and a list of tasks that execute after the roles with a <code>post_tasks</code>section.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: deploy mezzanine on vagrant</span><br><span class="line">  hosts: web</span><br><span class="line">  vars_files:</span><br><span class="line">    - secrets.yml</span><br><span class="line">  pre_tasks:</span><br><span class="line">    - name: update the apt cache</span><br><span class="line">      apt: update_cache=yes</span><br><span class="line">  roles:</span><br><span class="line">    - role: mezzanine</span><br><span class="line">  post_tasks:</span><br><span class="line">    - name: notify Slack that the servers have been updated</span><br><span class="line">      local_action: &gt;</span><br><span class="line">        slack</span><br><span class="line">        domain=acme.slack.com</span><br><span class="line">        token=&#123;&#123; slack_token &#125;&#125;</span><br><span class="line">        msg=&quot;web server &#123;&#123; inventory_hostname &#125;&#125; configured&quot;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: you need to define and put variables in right place, for example, the variables that would be used by multiple roles or playbooks should be put in <code>group_vars/all</code> file.</p>
</blockquote>
<h4 id="WHY-ARE-THERE-TWO-WAYS-TO-DEFINE-VARIABLES-IN-ROLES"><a href="#WHY-ARE-THERE-TWO-WAYS-TO-DEFINE-VARIABLES-IN-ROLES" class="headerlink" title="WHY ARE THERE TWO WAYS TO DEFINE VARIABLES IN ROLES?"></a>WHY ARE THERE TWO WAYS TO DEFINE VARIABLES IN ROLES?</h4><p>When Ansible first introduced support for roles, there was only one place to define role variables, in <em>vars/main.yml</em>. Variables defined in this location have a higher precedence than those defined in the <code>vars</code> section of a play, which meant you couldn’t override the variable unless you explicitly passed it as an argument to the role.</p>
<p>Ansible later introduced the notion of default role variables that go in <em>defaults/main.yml</em>.This type of variable is defined in a role, but has a low precedence, so it will be overridden if another variable with the same name is defined in the playbook.</p>
<p>If you think you might want to change the value of a variable in a role, use a default variable. If you don’t want it to change, use a regular variable.</p>
<h4 id="Some-role-practices"><a href="#Some-role-practices" class="headerlink" title="Some role practices"></a>Some role practices</h4><p><strong>Note</strong> that if for role variables, it’s better to add prefix like <code>&lt;role name&gt;_&lt;var name&gt;</code>. It’s good practice to do this with role variables because Ansible doesn’t have any notion of namespace across roles. This means that variables that are defined in other roles, or elsewhere in a playbook, will be accessible everywhere. This can cause some unexpected behavior if you accidentally use the same variable name in two different roles. For example, for the role called <code>mezzanine</code>, in <code>roles/mezzanine/vars/main.yml</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mezzanine_user: &quot;&#123;&#123; ansible_user &#125;&#125;&quot;</span><br><span class="line">mezzanine_venv_home: &quot;&#123;&#123; ansible_env.HOME &#125;&#125;&quot;</span><br><span class="line">mezzanine_venv_path: &quot;&#123;&#123; mezzanine_venv_home &#125;&#125;/&#123;&#123; mezzanine_proj_name &#125;&#125;&quot;</span><br><span class="line">mezzanine_repo_url: git@github.com:lorin/mezzanine-example.git</span><br><span class="line">mezzanine_proj_dirname: project</span><br></pre></td></tr></table></figure></p>
<p>For role variables in <em>default/main.yml</em>, no need to add prefix because we may intentionally override them elsewhere.</p>
<p>If the role task is very long, you can break it into several task files, for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">roles/mezzanine/tasks/django.yml</span><br><span class="line">roles/mezzanine/tasks/main.yml</span><br><span class="line">roles/mezzanine/tasks/nginx.yml</span><br></pre></td></tr></table></figure></p>
<p>In the <code>main.yml</code> task file you can invoke other tasks by using <code>include</code> statement:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: install apt packages</span><br><span class="line">  apt: pkg=&#123;&#123; item &#125;&#125; update_cache=yes cache_valid_time=3600</span><br><span class="line">  become: True</span><br><span class="line">  with_items:</span><br><span class="line">    - git</span><br><span class="line">    - supervisor</span><br><span class="line"></span><br><span class="line">- include: django.yml</span><br><span class="line">- include: nginx.yml</span><br></pre></td></tr></table></figure></p>
<p><strong>Note</strong>: there’s one important difference between tasks defined in a role and tasks defined in a regular playbook, and that’s when using the <code>copy</code> or <code>template</code> modules.</p>
<p>When invoking <code>copy</code> in a task defined in a role, Ansible will first check the <em>rolename/files/</em> directory for the location of the file to copy. Similarly, when invoking <code>template</code> in a task defined in a role, Ansible will first check the <em>rolename/templates</em> directory for the location of the template to use.</p>
<p>This means that a task that used to look like this in a playbook:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: set the nginx config file</span><br><span class="line">  template: src=templates/nginx.conf.j2 \</span><br><span class="line">  dest=/etc/nginx/sites-available/mezzanine.conf</span><br></pre></td></tr></table></figure></p>
<p>now looks like this when invoked from inside the role (note the change of the src parameter):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: set the nginx config file</span><br><span class="line">  template: src=nginx.conf.j2 dest=/etc/nginx/sites-available/mezzanine.conf</span><br><span class="line">  notify: restart nginx</span><br></pre></td></tr></table></figure></p>
<h4 id="Creating-Role-Files-and-Directories-with-ansible-galaxy"><a href="#Creating-Role-Files-and-Directories-with-ansible-galaxy" class="headerlink" title="Creating Role Files and Directories with ansible-galaxy"></a>Creating Role Files and Directories with ansible-galaxy</h4><p>Ansible ships with another command-line tool we haven’t talked about yet, <code>ansible-galaxy</code>. Its primary purpose is to download roles that have been shared by the Ansible community. But it can also be used to generate <em>scaffolding</em>, an initial set of files and directories involved in a role:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-galaxy init &lt;path&gt;/roles/web</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">└── roles</span><br><span class="line">    └── web</span><br><span class="line">        ├── README.md</span><br><span class="line">        ├── defaults</span><br><span class="line">        │   └── main.yml</span><br><span class="line">        ├── files</span><br><span class="line">        ├── handlers</span><br><span class="line">        │   └── main.yml</span><br><span class="line">        ├── meta</span><br><span class="line">        │   └── main.yml</span><br><span class="line">        ├── tasks</span><br><span class="line">        │   └── main.yml</span><br><span class="line">        ├── templates</span><br><span class="line">        ├── tests</span><br><span class="line">        │   ├── inventory</span><br><span class="line">        │   └── test.yml</span><br><span class="line">        └── vars</span><br><span class="line">            └── main.yml</span><br></pre></td></tr></table></figure>
<h4 id="Dependent-Roles"><a href="#Dependent-Roles" class="headerlink" title="Dependent Roles"></a>Dependent Roles</h4><p>Ansible supports a feature called <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_roles.html#role-dependencies" target="_blank" rel="noopener">dependent roles</a> to deal with this scenario. When you define a role, you can specify that it depends on one or more other roles. Ansible will ensure that roles that are specified as dependencies are executed first.</p>
<p>Let’s say that we create an<code>ntp</code> role that configures a host to synchronize its time with an NTP server. Ansible allows us to pass parameters to dependent roles, so let’s also assume that we can pass the NTP server as a parameter to that role.</p>
<p>We specify that the <code>web</code> role depends on the <code>ntp</code> role by creating a <em>roles/web/meta/main.yml</em> file and listing <code>ntp</code> as a role, with a parameter:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dependencies:</span><br><span class="line">    - &#123; role: ntp, ntp_server=ntp.ubuntu.com &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="Ansible-Galaxy"><a href="#Ansible-Galaxy" class="headerlink" title="Ansible Galaxy"></a>Ansible Galaxy</h4><p>Whether you want to reuse a role somebody has already written, or you just want to see how someone else solved the problem you’re working on, <a href="https://galaxy.ansible.com/" target="_blank" rel="noopener">Ansible Galaxy</a> can help you out. Ansible Galaxy is an open source repository of Ansible roles contributed by the Ansible community. The roles themselves are stored on GitHub.</p>
<h3 id="Chapter-8-Complex-Playbooks"><a href="#Chapter-8-Complex-Playbooks" class="headerlink" title="Chapter 8. Complex Playbooks"></a>Chapter 8. Complex Playbooks</h3><p>This chapter touches on those additional features, which makes it a bit of a grab bag.</p>
<h4 id="Dealing-with-Badly-Behaved-Commands"><a href="#Dealing-with-Badly-Behaved-Commands" class="headerlink" title="Dealing with Badly Behaved Commands"></a>Dealing with Badly Behaved Commands</h4><p>What if we didn’t have a module that could invoke equivalent commands (wasn’t idempotent)? The answer is to use <code>changed_when</code> and <code>failed_when</code> clauses to change how Ansible identifies that a task has changed state or failed.</p>
<p>First, we need to understand the output of this command the first time it’s run, and the output when it’s run the second time.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: initialize the database</span><br><span class="line">  django_manage:</span><br><span class="line">    command: createdb --noinput --nodata</span><br><span class="line">    app_path: &quot;&#123;&#123; proj_path &#125;&#125;&quot;</span><br><span class="line">    virtualenv: &quot;&#123;&#123; venv_path &#125;&#125;&quot;</span><br><span class="line">  failed_when: False</span><br><span class="line">  register: result</span><br><span class="line"></span><br><span class="line">- debug: var=result</span><br><span class="line"></span><br><span class="line">- fail:</span><br></pre></td></tr></table></figure></p>
<p><code>failed_when: False</code> is to close task fail, so ansible play will continue to execute. We can run several times of the playbook and see different register variable output.<br><code>fail</code> statement here is to stop the execution.</p>
<p>Some module may not report changed state even though it did make change in target machine, so we can check if state changed ourselves by using <code>changed_when</code> clause:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: initialize the database</span><br><span class="line">  django_manage:</span><br><span class="line">    command: createdb --noinput --nodata</span><br><span class="line">    app_path: &quot;&#123;&#123; proj_path &#125;&#125;&quot;</span><br><span class="line">    virtualenv: &quot;&#123;&#123; venv_path &#125;&#125;&quot;</span><br><span class="line">  register: result</span><br><span class="line">  changed_when: &apos;&quot;Creating tables&quot; in result.out|default(&quot;&quot;)&apos;</span><br></pre></td></tr></table></figure></p>
<p>We use filter here in <code>changed_when</code> since register variable sometimes doesn’t have <code>out</code> field. Alternatively, we could provide a default value for <code>result.out</code> if it doesn’t exist by using the Jinja2 default filter.</p>
<h4 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h4><p><em>Filters</em> are a feature of the Jinja2 templating engine. Since Ansible uses Jinja2 for evaluating variables, as well as for templates, you can use filters inside <code></code> in your playbooks, as well as inside your template files. Using filters resembles using Unix pipes, whereby a variable is piped through a filter. Jinja2 ships with a set of <a href="http://bit.ly/1FvOGzI" target="_blank" rel="noopener">built-in filters</a>. In addition, Ansible ships with its own filters to augment the <a href="http://bit.ly/1FvOIrj" target="_blank" rel="noopener">Jinja2 filters</a>.</p>
<h5 id="The-Default-Filter"><a href="#The-Default-Filter" class="headerlink" title="The Default Filter"></a>The Default Filter</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;HOST&quot;: &quot;&#123;&#123; database_host | default(&apos;localhost&apos;) &#125;&#125;&quot;</span><br></pre></td></tr></table></figure>
<p>If the variable <code>database_host</code> is defined, the braces will evaluate to the value of that variable. If the variable <code>database_host</code> is not defined, the braces will evaluate to the string localhost.</p>
<h5 id="Filters-for-Registered-Variables"><a href="#Filters-for-Registered-Variables" class="headerlink" title="Filters for Registered Variables"></a>Filters for Registered Variables</h5><p>Let’s say we want to run a task and print out its output, even if the task fails. However, if the task does fail, we want Ansible to fail for that host after printing the output.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Run myprog</span><br><span class="line">  command: /opt/myprog</span><br><span class="line">  register: result</span><br><span class="line">  ignore_errors: True</span><br><span class="line"></span><br><span class="line">- debug: var=result</span><br><span class="line"></span><br><span class="line">- debug: msg=&quot;Stop running the playbook if myprog failed&quot;</span><br><span class="line">  failed_when: result|failed</span><br></pre></td></tr></table></figure></p>
<p> a list of filters you can use on registered variables to check the status:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Name    	| Description                                           	|</span><br><span class="line">|---------	|-------------------------------------------------------	|</span><br><span class="line">| failed  	| True if a registered value is a task that failed      	|</span><br><span class="line">| changed 	| True if a registered value is a task that changed     	|</span><br><span class="line">| success 	| True if a registered value is a task that succeeded   	|</span><br><span class="line">| skipped 	| True if a registered value is a task that was skipped 	|</span><br></pre></td></tr></table></figure></p>
<p>The basename filter will let us extract the index.html part of the filename from the full path, allowing us to write the playbook without repeating the filename:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vars:</span><br><span class="line">    homepage: /usr/share/nginx/html/index.html</span><br><span class="line">  tasks:</span><br><span class="line">  - name: copy home page</span><br><span class="line">    copy: src=files/&#123;&#123; homepage | basename &#125;&#125; dest=&#123;&#123; homepage &#125;&#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="Lookups"><a href="#Lookups" class="headerlink" title="Lookups"></a>Lookups</h4><p>Sometimes a piece of configuration data you need lives somewhere else. Maybe it’s in a text file or a <em>.csv</em> file, and you don’t want to just copy the data into an Ansible variable file because now you have to maintain two copies of the same data. </p>
<p>Ansible has a feature called <code>lookups</code> that allows you to read in configuration data from various sources and then use that data in your playbooks and template.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Name     	| Description                        	|</span><br><span class="line">|----------	|------------------------------------	|</span><br><span class="line">| file     	| Contents of a file                 	|</span><br><span class="line">| password 	| Randomly generate a password       	|</span><br><span class="line">| pipe     	| Output of locally executed command 	|</span><br><span class="line">| env      	| Environment variable               	|</span><br><span class="line">| template 	| Jinja2 template after evaluation   	|</span><br><span class="line">| csvfile  	| Entry in a .csv file               	|</span><br><span class="line">| dnstxt   	| DNS TXT record                     	|</span><br><span class="line">| redis_kv 	| Redis key lookup                   	|</span><br><span class="line">| etcd     	| etcd key lookup                    	|</span><br></pre></td></tr></table></figure></p>
<p>You can invoke lookups in your playbooks between <code></code>, or you can put them in templates. </p>
<p><strong>Note</strong> all Ansible lookup plugins execute on the control machine, not the remote host.</p>
<h5 id="file"><a href="#file" class="headerlink" title="file"></a>file</h5><p>Let’s say you have a text file on your control machine that contains a public SSH key that you want to copy to a remote server.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Add my public key as an EC2 key</span><br><span class="line">  ec2_key: name=mykey key_material=&quot;&#123;&#123; lookup(&apos;file&apos;,  &apos;/Users/lorin/.ssh/id_rsa.pub&apos;) &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<h5 id="pipe"><a href="#pipe" class="headerlink" title="pipe"></a>pipe</h5><p>The <code>pipe</code> lookup invokes an external program on the control machine and evaluates to the program’s output on standard out.</p>
<p>For example, if our playbooks are version controlled using <code>git</code>, and we want to get the <code>SHA-1</code> value of the most recent <code>git commit</code>, we could use the <code>pipe</code> lookup<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: get SHA of most recent commit</span><br><span class="line">  debug: msg=&quot;&#123;&#123; lookup(&apos;pipe&apos;, &apos;git rev-parse HEAD&apos;) &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK: [get the sha of the current commit] *************************************</span><br><span class="line">ok: [myserver] =&gt; &#123;</span><br><span class="line">    &quot;msg&quot;: &quot;e7748af0f040d58d61de1917980a210df419eae9&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="env"><a href="#env" class="headerlink" title="env"></a>env</h5><p>The <code>env</code> lookup retrieves the value of an environment variable set on the control machine.For example, we could use the lookup like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: get the current shell</span><br><span class="line">  debug: msg=&quot;&#123;&#123; lookup(&apos;env&apos;, &apos;SHELL&apos;) &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK: [get the current shell] *************************************************</span><br><span class="line">ok: [myserver] =&gt; &#123;</span><br><span class="line">    &quot;msg&quot;: &quot;/bin/zsh&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="password"><a href="#password" class="headerlink" title="password"></a>password</h5><p>The <code>password</code> lookup evaluates to a random password, and it will also write the password to a file specified in the argument. For example, if we want to create a Postgres user named <code>deploy</code> with a random password and write that password to <em>deploy-password.txt</em>on the control machine, we can do this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: create deploy postgres user</span><br><span class="line">  postgresql_user:</span><br><span class="line">    name: deploy</span><br><span class="line">    password: &quot;&#123;&#123; lookup(&apos;password&apos;, &apos;deploy-password.txt&apos;) &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<h5 id="template"><a href="#template" class="headerlink" title="template"></a>template</h5><p>The <code>template</code> lookup lets you specify a Jinja2 template file, and then returns the result of evaluating the template.</p>
<h5 id="csvfile"><a href="#csvfile" class="headerlink" title="csvfile"></a>csvfile</h5><p>The <code>csvfile</code> lookup reads an entry from a <em>.csv</em> file.<br>For example, we have a <code>users.csv</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">username,email</span><br><span class="line">lorin,lorin@ansiblebook.com</span><br><span class="line">john,john@example.com</span><br><span class="line">sue,sue@example.org</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lookup(&apos;csvfile&apos;, &apos;sue file=users.csv delimiter=, col=1&apos;)</span><br></pre></td></tr></table></figure>
<p>In the case of <code>csvfile</code>, the first argument is an entry that must appear exactly once in column 0 (the first column, 0-indexed) of the table.</p>
<p>In our example, we want to look in the file named <code>users.csv</code> and locate where the fields are delimited by commas, look up the row where the value in the first column is <code>sue</code>, and return the value in the second column (column 1, indexed by 0). This evaluates to <a href="mailto:sue@example.org" target="_blank" rel="noopener">sue@example.org</a>.</p>
<h5 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h5><p>Etcd is a distributed key-value store, commonly used for keeping configuration data and for implementing service discovery. You can use the <code>etcd</code> lookup to retrieve the value of a key.</p>
<p>For example, let’s say that we have an etcd server running on our control machine, and we set the key weather to the value cloudy by doing something like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -L http://127.0.0.1:4001/v2/keys/weather -XPUT -d value=cloudy</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: look up value in etcd</span><br><span class="line">  debug: msg=&quot;&#123;&#123; lookup(&apos;etcd&apos;, &apos;weather&apos;) &#125;&#125;&quot;</span><br><span class="line"></span><br><span class="line">TASK: [look up value in etcd] *************************************************</span><br><span class="line">ok: [localhost] =&gt; &#123;</span><br><span class="line">    &quot;msg&quot;: &quot;cloudy&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>By default, the etcd lookup looks for the etcd server at <a href="http://127.0.0.1:4001" target="_blank" rel="noopener">http://127.0.0.1:4001</a>, but you can change this by setting the <code>ANSIBLE_ETCD_URL</code> environment variable before invoking ansible-playbook.</p>
<h4 id="More-Complicated-Loops"><a href="#More-Complicated-Loops" class="headerlink" title="More Complicated Loops"></a>More Complicated Loops</h4><p>Up until this point, whenever we’ve written a task that iterates over a list of items, we’ve used the <code>with_items</code> clause to specify a list of items. Although this is the most common way to do loops, Ansible supports other mechanisms for iteration.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Name                     	| Input                	| Looping strategy                  	|</span><br><span class="line">|--------------------------	|----------------------	|-----------------------------------	|</span><br><span class="line">| with_items               	| List                 	| Loop over list elements           	|</span><br><span class="line">| with_lines               	| Command to execute   	| Loop over lines in command output 	|</span><br><span class="line">| with_fileglob            	| Glob                 	| Loop over filenames               	|</span><br><span class="line">| with_first_found         	| List of paths        	| First file in input that exists   	|</span><br><span class="line">| with_dict                	| Dictionary           	| Loop over dictionary elements     	|</span><br><span class="line">| with_flattened           	| List of lists        	| Loop over flattened list          	|</span><br><span class="line">| with_indexed_items       	| List                 	| Single iteration                  	|</span><br><span class="line">| with_nested              	| List                 	| Nested loop                       	|</span><br><span class="line">| with_random_choice       	| List                 	| Single iteration                  	|</span><br><span class="line">| with_sequence            	| Sequence of integers 	| Loop over sequence                	|</span><br><span class="line">| with_subelements         	| List of dictionaries 	| Nested loop                       	|</span><br><span class="line">| with_together            	| List of lists        	| Loop over zipped list             	|</span><br><span class="line">| with_inventory_hostnames 	| Host pattern         	| Loop over matching hosts          	|</span><br></pre></td></tr></table></figure></p>
<p>The <a href="http://bit.ly/1F6kfCP" target="_blank" rel="noopener">official documentation</a> covers these quite thoroughly, so I’ll show examples from just a few of them to give you a sense of how they work.</p>
<h5 id="with-lines"><a href="#with-lines" class="headerlink" title="with_lines"></a>with_lines</h5><p>The with_lines looping construct lets you run an arbitrary command on your control machine and iterate over the output, one line at a time. For example, read a file and iterate over its contents line by line.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Send out a slack message</span><br><span class="line">  slack:</span><br><span class="line">    domain: example.slack.com</span><br><span class="line">    token: &quot;&#123;&#123; slack_token &#125;&#125;&quot;</span><br><span class="line">    msg: &quot;&#123;&#123; item &#125;&#125; was in the list&quot;</span><br><span class="line">  with_lines:</span><br><span class="line">    - cat files/turing.txt</span><br></pre></td></tr></table></figure></p>
<h5 id="with-fileglob"><a href="#with-fileglob" class="headerlink" title="with_fileglob"></a>with_fileglob</h5><p>The with_fileglob construct is useful for iterating over a set of files on the control machine.</p>
<p>For example, iterate over files that end in <code>.pub</code> in the /var/keys directory, as well as a keys directory next to your playbook. It then uses the <code>file</code> lookup plugin to extract the contents of the file, which are passed to the authorized_key module.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: add public keys to account</span><br><span class="line">  authorized_key: user=deploy key=&quot;&#123;&#123; lookup(&apos;file&apos;, item) &#125;&#125;&quot;</span><br><span class="line">  with_fileglob:</span><br><span class="line">    - /var/keys/*.pub</span><br><span class="line">    - keys/*.pub</span><br></pre></td></tr></table></figure></p>
<h5 id="with-dict"><a href="#with-dict" class="headerlink" title="with_dict"></a>with_dict</h5><p>The <code>with_dict</code> construct lets you iterate over a dictionary instead of a list. When you use this looping construct, the <code>item</code> loop variable is a dictionary with two fields:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: iterate over ansible_eth0</span><br><span class="line">   debug: msg=&#123;&#123; item.key &#125;&#125;=&#123;&#123; item.value &#125;&#125;</span><br><span class="line">   with_dict: &quot;&#123;&#123; ansible_eth0.ipv4 &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<h5 id="Looping-Constructs-as-Lookup-Plugins"><a href="#Looping-Constructs-as-Lookup-Plugins" class="headerlink" title="Looping Constructs as Lookup Plugins"></a>Looping Constructs as Lookup Plugins</h5><p>Ansible implements looping constructs as lookup plugins. That means you can alter the form of lookup to perform as a loop:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: Add my public key as an EC2 key</span><br><span class="line">  ec2_key: name=mykey key_material=&quot;&#123;&#123; item &#125;&#125;&quot;</span><br><span class="line">  with_file: /Users/lorin/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure></p>
<p>Here we prefix <code>with_</code> with <code>file</code> lookup plugin. Typically, you use a lookup plugin as a looping construct only if it returns a list,</p>
<h4 id="Loop-Controls"><a href="#Loop-Controls" class="headerlink" title="Loop Controls"></a>Loop Controls</h4><p>With version 2.1, Ansible provides users with more control over loop handling.</p>
<h5 id="Setting-the-Variable-Name"><a href="#Setting-the-Variable-Name" class="headerlink" title="Setting the Variable Name"></a>Setting the Variable Name</h5><p>The <code>loop_var</code> control allows us to give the iteration variable a different name than the default name, <code>item</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- user:</span><br><span class="line">    name: &quot;&#123;&#123; user.name &#125;&#125;&quot;</span><br><span class="line">  with_items:</span><br><span class="line">  ## list of dict</span><br><span class="line">    - &#123; name: gil &#125;</span><br><span class="line">    - &#123; name: sarina &#125;</span><br><span class="line">    - &#123; name: leanne &#125;</span><br><span class="line">  loop_control:</span><br><span class="line">    loop_var: user</span><br></pre></td></tr></table></figure></p>
<p>Next one is a advanced usage, use <code>include</code> with <code>with_items</code>, we loop over multiple task at once, in current task we include a task called <code>vhosts.yml</code> which will be executed 3 times with different parameters passed in:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: run a set of tasks in one loop</span><br><span class="line">  include: vhosts.yml</span><br><span class="line">  with_items:</span><br><span class="line">    - &#123; domain: www1.example.com &#125;</span><br><span class="line">    - &#123; domain: www2.example.com &#125;</span><br><span class="line">    - &#123; domain: www3.example.com &#125;</span><br><span class="line">  loop_control:</span><br><span class="line">    loop_var: vhost</span><br></pre></td></tr></table></figure></p>
<p>The <code>vhosts.yml</code> file that is going to be included may also contain <code>with_items</code> in some tasks. This would produce a conflict, as the default loop_var <code>item</code> is used for both loops at the same time.</p>
<p>To prevent a naming collision, we specify a different name for loop_var in the outer loop.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: create nginx directories</span><br><span class="line">  file:</span><br><span class="line">    path: /var/www/html/&#123;&#123; vhost.domain &#125;&#125;/&#123;&#123; item &#125;&#125;</span><br><span class="line">  state: directory</span><br><span class="line">  with_items:</span><br><span class="line">    - logs</span><br><span class="line">    - public_http</span><br><span class="line">    - public_https</span><br><span class="line">    - includes</span><br><span class="line"></span><br><span class="line">- name: create nginx vhost config</span><br><span class="line">  template:</span><br><span class="line">    src: &quot;&#123;&#123; vhost.domain &#125;&#125;.j2&quot;</span><br><span class="line">    dest: /etc/nginx/conf.d/&#123;&#123; vhost.domain &#125;&#125;.conf</span><br></pre></td></tr></table></figure></p>
<h5 id="Labeling-the-Output"><a href="#Labeling-the-Output" class="headerlink" title="Labeling the Output"></a>Labeling the Output</h5><p>The <code>label</code> control was added in Ansible 2.2 and provides some control over how the loop output will be shown to the user during execution.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: create nginx vhost configs</span><br><span class="line">  template:</span><br><span class="line">    src: &quot;&#123;&#123; item.domain &#125;&#125;.conf.j2&quot;</span><br><span class="line">    dest: &quot;/etc/nginx/conf.d/&#123;&#123; item.domain &#125;&#125;.conf&quot;</span><br><span class="line">  with_items:</span><br><span class="line">    - &#123; domain: www1.example.com, ssl_enabled: yes &#125;</span><br><span class="line">    - &#123; domain: www2.example.com &#125;</span><br><span class="line">    - &#123; domain: www3.example.com,</span><br><span class="line">      aliases: [ edge2.www.example.com, eu.www.example.com ] &#125;</span><br><span class="line">  loop_control:</span><br><span class="line">    label: &quot;for domain &#123;&#123; item.domain &#125;&#125;&quot;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK [create nginx vhost configs] **********************************************</span><br><span class="line">ok: [localhost] =&gt; (item=for domain www1.example.com)</span><br><span class="line">ok: [localhost] =&gt; (item=for domain www2.example.com)</span><br><span class="line">ok: [localhost] =&gt; (item=for domain www3.example.com)</span><br></pre></td></tr></table></figure>
<h4 id="Includes"><a href="#Includes" class="headerlink" title="Includes"></a>Includes</h4><p>The <code>include</code> feature allows you to include tasks or even whole playbooks, depending on where you define an include. It is often used in roles to separate or even group tasks and task arguments to each task in the included file.</p>
<p>For example, you can extract different part of tasks, put them into a separate yml file and include it into another task along with common arguments:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># nginx_include.yml file</span><br><span class="line">- name: install nginx</span><br><span class="line">  package:</span><br><span class="line">    name: nginx</span><br><span class="line"></span><br><span class="line">- name: ensure nginx is running</span><br><span class="line">  service:</span><br><span class="line">    name: nginx</span><br><span class="line">    state: started</span><br><span class="line">    enabled: yes</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- include: nginx_include.yml</span><br><span class="line">  tags: nginx</span><br><span class="line">  become: yes</span><br><span class="line">  when: ansible_os_family == &apos;RedHat&apos;</span><br></pre></td></tr></table></figure>
<p>Ansible <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_tags.html" target="_blank" rel="noopener">Tags</a>: If you have a large playbook, it may become useful to be able to run only a specific part of it rather than running everything in the playbook. Ansible supports a <code>tags:</code> attribute for this reason.</p>
<h5 id="Dynamic-includes"><a href="#Dynamic-includes" class="headerlink" title="Dynamic includes"></a>Dynamic includes</h5><p>A common pattern in roles is to define tasks specific to a particular operating system into separate task files.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- include: Redhat.yml</span><br><span class="line">  when: ansible_os_family == &apos;Redhat&apos;</span><br><span class="line"></span><br><span class="line">- include: Debian.yml</span><br><span class="line">  when: ansible_os_family == &apos;Debian&apos;</span><br></pre></td></tr></table></figure></p>
<p>Since version 2.0, Ansible allows us to dynamically include a file by using variable substitution:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- include: &quot;&#123;&#123; ansible_os_family &#125;&#125;.yml&quot;</span><br><span class="line">  static: no</span><br></pre></td></tr></table></figure></p>
<p>However, there is a drawback to using dynamic includes: <code>ansible-playbook --list-tasks</code> might not list the tasks from a dynamic include if Ansible does not have enough information to populate the variables that determine which file will be included.</p>
<p>You can use <code>ansible-playbook &lt;playbook&gt; --list-tasks</code> to list all the tasks in it.</p>
<h5 id="Role-includes"><a href="#Role-includes" class="headerlink" title="Role includes"></a>Role includes</h5><p>A special include is the <code>include_role</code> clause. In contrast with the <code>role</code> clause, which will use all parts of the role, the <code>include_role</code> not only allows us to selectively choose what parts of a role will be included and used, but also where in the play.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: install php</span><br><span class="line">  include_role:</span><br><span class="line">    name: php</span><br></pre></td></tr></table></figure></p>
<p>This will include and run main.yml from the php role, remember a role can have multiple tasks yml files: main.yml and others.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: install php</span><br><span class="line">  include_role:</span><br><span class="line">    name: php</span><br><span class="line">    tasks_from: install</span><br></pre></td></tr></table></figure></p>
<p>This will include and run install.yml from php role.</p>
<h4 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h4><p>Much like the <code>include</code> clause, the <code>block</code> clause provides a mechanism for grouping tasks. The <code>block</code> clause allows you to set conditions or arguments for all tasks within a block at once:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- block:</span><br><span class="line">  - name: install nginx</span><br><span class="line">    package:</span><br><span class="line">      name: nginx</span><br><span class="line">  - name: ensure nginx is running</span><br><span class="line">    service:</span><br><span class="line">      name: nginx</span><br><span class="line">      state: started</span><br><span class="line">      enabled: yes</span><br><span class="line">  become: yes</span><br><span class="line">  when: &quot;ansible_os_family == &apos;RedHat&apos;&quot;</span><br></pre></td></tr></table></figure></p>
<p>The <code>become</code> and <code>when</code> apply for both tasks.</p>
<h5 id="Error-Handling-with-Blocks"><a href="#Error-Handling-with-Blocks" class="headerlink" title="Error Handling with Blocks"></a>Error Handling with Blocks</h5><p>Dealing with error scenarios has always been a challenge. Historically, Ansible has been error agnostic in the sense that errors and failures may occur on a host. Ansible’s default error-handling behavior is to take a host out of the play if a task fails and continue as long as there are hosts remaining that haven’t encountered errors.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- block:</span><br><span class="line">  - debug: msg=&quot;You will see a failed tasks right after this&quot;</span><br><span class="line">  - command: /bin/false</span><br><span class="line">  - debug: &quot;You won&apos;t see this message&quot;</span><br><span class="line">  rescue: # Tasks to be executed in case of a failure in block clause</span><br><span class="line">  - debug: &quot;You only see this message in case of an failure in the block&quot;</span><br><span class="line">  always: # Tasks to always be executed</span><br><span class="line">  - debug: &quot;This will be always executed&quot;</span><br></pre></td></tr></table></figure></p>
<p>If you have some programming experience, the way error handling is implemented may remind you of the <code>try-catch-finally</code> paradigm, and it works much the same way.</p>
<h4 id="Encrypting-Sensitive-Data-with-Vault"><a href="#Encrypting-Sensitive-Data-with-Vault" class="headerlink" title="Encrypting Sensitive Data with Vault"></a>Encrypting Sensitive Data with Vault</h4><p>Ansible provides an alternative solution: instead of keeping the <code>secrets.yml</code> file out of version control, we can commit an encrypted version. That way, even if our version-control repository were compromised, the attacker would not have access to the contents of the <code>secrets.yml</code> file unless he also had the password used for the encryption.</p>
<p>The <code>ansible-vault</code> command-line tool allows you to create and edit an encrypted file that <code>ansible-playbook</code> will recognize and decrypt automatically, given the password.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-vault create secrets.yml</span><br><span class="line">ansible-vault encrypt secrets.yml</span><br></pre></td></tr></table></figure></p>
<p>You will be prompted for a password, and then <code>ansible-vault</code> will launch a text editor so that you can populate the file. It launches the editor specified in the <code>$EDITOR</code> environment variable. If that variable is not defined, it defaults to <code>vim</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook &lt;playbook&gt; --ask-vault-pass</span><br><span class="line">ansible-playbook &lt;playbook&gt; --vault-password-file ~/password.txt</span><br></pre></td></tr></table></figure></p>
<p>If the argument to <code>--vault-password-file</code> has the executable bit set, Ansible will execute it and use the contents of standard out as the vault password. This allows you to use a script to provide the password to Ansible.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Command                        	| Description                                       	|</span><br><span class="line">|--------------------------------	|---------------------------------------------------	|</span><br><span class="line">| ansible-vault encrypt file.yml 	| Encrypt the plain-text file.yml file              	|</span><br><span class="line">| ansible-vault decrypt file.yml 	| Decrypt the encrypted file.yml file               	|</span><br><span class="line">| ansible-vault view file.yml    	| Print the contents of the encrypted file.yml file 	|</span><br><span class="line">| ansible-vault create file.yml  	| Create a new encrypted file.yml file              	|</span><br><span class="line">| ansible-vault edit file.yml    	| Edit an encrypted file.yml file                   	|</span><br><span class="line">| ansible-vault rekey file.yml   	| Change the password on an encrypted file.yml file 	|</span><br></pre></td></tr></table></figure></p>
<h3 id="Chapter-9-Customizing-Hosts-Runs-and-Handlers"><a href="#Chapter-9-Customizing-Hosts-Runs-and-Handlers" class="headerlink" title="Chapter 9. Customizing Hosts, Runs, and Handlers"></a>Chapter 9. Customizing Hosts, Runs, and Handlers</h3><p>In this chapter, we cover Ansible features that provide customization by controlling which hosts to run against, how tasks are run, and how handlers are run.</p>
<h4 id="Patterns-for-Specifying-Hosts"><a href="#Patterns-for-Specifying-Hosts" class="headerlink" title="Patterns for Specifying Hosts"></a>Patterns for Specifying Hosts</h4><p>Instead of specifying a single host or group for a play, you can specify a <em>pattern</em>. You’ve already seen the <code>all</code> pattern, which will run a play against all known hosts:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hosts: all</span><br></pre></td></tr></table></figure></p>
<p>You can specify a union of two groups with a colon. You specify all dev and staging machines as follows:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hosts: dev:staging</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Action                    	| Example Usage               	|</span><br><span class="line">|---------------------------	|-----------------------------	|</span><br><span class="line">| All hosts                 	| all                         	|</span><br><span class="line">| All hosts                 	| *                           	|</span><br><span class="line">| Union                     	| dev:staging                 	|</span><br><span class="line">| Intersection              	| dev:&amp;database               	|</span><br><span class="line">| Exclusion                 	| dev:!queue                  	|</span><br><span class="line">| Wildcard                  	| *.example.com               	|</span><br><span class="line">| Range of numbered servers 	| web[5:12]                   	|</span><br><span class="line">| Regular expression        	| ~web\d+\.example\.(com|org) 	|</span><br></pre></td></tr></table></figure>
<p>Ansible supports multiple combinations of patterns—for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hosts: dev:staging:&amp;database:!queue</span><br></pre></td></tr></table></figure></p>
<h4 id="Limiting-Which-Hosts-Run"><a href="#Limiting-Which-Hosts-Run" class="headerlink" title="Limiting Which Hosts Run"></a>Limiting Which Hosts Run</h4><p>Use the <code>-l hosts</code> or <code>--limit hosts</code> flag to tell Ansible to limit the hosts to run the playbook against the specified list of hosts<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook -l hosts playbook.yml</span><br><span class="line">ansible-playbook --limit hosts playbook.yml</span><br><span class="line">ansible-playbook -l &apos;staging:&amp;database&apos; playbook.yml</span><br></pre></td></tr></table></figure></p>
<h4 id="Running-a-Task-on-the-Control-Machine"><a href="#Running-a-Task-on-the-Control-Machine" class="headerlink" title="Running a Task on the Control Machine"></a>Running a Task on the Control Machine</h4><p>Sometimes you want to run a particular task on the control machine instead of on the remote host. Ansible provides the <code>local_action</code> clause for tasks to support this. For example, when we check the node ready status in k8s cluster.</p>
<p>Imagine that the server we want to install Mezzanine onto has just booted, so that if we run our playbook too soon, it will error out because the server hasn’t fully started up yet. We could start off our playbook by invoking the <code>wait_for</code> module to wait until the SSH server is ready to accept connections before we execute the rest of the playbook.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: wait for ssh server to be running</span><br><span class="line">  local_action: wait_for port=22 host=&quot;&#123;&#123; inventory_hostname &#125;&#125;&quot; search_regex=OpenSSH</span><br></pre></td></tr></table></figure></p>
<p>Note that <code>inventory_hostname</code> evaluates to the name of the remote host, not <code>localhost</code>. That’s because the scope of these variables is still the remote host, even though the task is executing locally.</p>
<p>If your play involves multiple hosts, and you use <code>local_action</code>, the task will be executed multiple times, one for each host. You can restrict this by using <code>run_once</code></p>
<h4 id="Running-a-Task-on-a-Machine-Other-Than-the-Host"><a href="#Running-a-Task-on-a-Machine-Other-Than-the-Host" class="headerlink" title="Running a Task on a Machine Other Than the Host"></a>Running a Task on a Machine Other Than the Host</h4><p>Sometimes you want to run a task that’s associated with a host, but you want to execute the task on a different server. You can use the <code>delegate_to</code> clause to run the task on a different host.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: enable alerts for web servers</span><br><span class="line">  hosts: web</span><br><span class="line">  tasks:</span><br><span class="line">    - name: enable alerts</span><br><span class="line">      nagios: action=enable_alerts service=web host=&#123;&#123; inventory_hostname &#125;&#125;</span><br><span class="line">      delegate_to: nagios.example.com</span><br></pre></td></tr></table></figure></p>
<p>In this example, Ansible would execute the <code>nagios task</code> on nagios.example.com, but the <code>inventory_hostname</code> variable referenced in the play would evaluate to the web host.</p>
<blockquote>
<p>Note: if you specify <code>delegate_to: localhost</code> to control machine, it’s the same as <code>local_action</code>, also the same as <code>connection: local</code></p>
</blockquote>
<h4 id="Running-on-One-Host-at-a-Time"><a href="#Running-on-One-Host-at-a-Time" class="headerlink" title="Running on One Host at a Time"></a>Running on One Host at a Time</h4><p>By default, Ansible runs each task in parallel across all hosts. Sometimes you want to run your task on one host at a time. The canonical example is when upgrading application servers that are behind a load balancer. Typically, you take the application server out of the load balancer, upgrade it, and put it back. But you don’t want to take all of your application servers out of the load balancer, or your service will become unavailable.</p>
<p>You can use the <code>serial</code> clause on a play to tell Ansible to restrict the number of hosts that a play runs on.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: upgrade packages on servers behind load balancer</span><br><span class="line">  hosts: myhosts</span><br><span class="line">  serial: 1</span><br><span class="line">  tasks:</span><br><span class="line">    - name: get the ec2 instance id and elastic load balancer id</span><br><span class="line">      ec2_facts:</span><br><span class="line"></span><br><span class="line">    - name: take the host out of the elastic load balancer</span><br><span class="line">      local_action: ec2_elb</span><br><span class="line">      args:</span><br><span class="line">        instance_id: &quot;&#123;&#123; ansible_ec2_instance_id &#125;&#125;&quot;</span><br><span class="line">        state: absent</span><br><span class="line"></span><br><span class="line">    - name: upgrade packages</span><br><span class="line">      apt: update_cache=yes upgrade=yes</span><br><span class="line"></span><br><span class="line">    - name: put the host back in the elastic load balancer</span><br><span class="line">      local_action: ec2_elb</span><br><span class="line">      args:</span><br><span class="line">        instance_id: &quot;&#123;&#123; ansible_ec2_instance_id &#125;&#125;&quot;</span><br><span class="line">        state: present</span><br><span class="line">        ec2_elbs: &quot;&#123;&#123; item &#125;&#125;&quot;</span><br><span class="line">      with_items: ec2_elbs</span><br></pre></td></tr></table></figure></p>
<p>In our example, we pass 1 as the argument to the serial clause, telling Ansible to run on only one host at a time. If we had passed 2, Ansible would have run two hosts at a time.</p>
<p>Normally, when a task fails, Ansible stops running tasks against the host that fails, <strong>but</strong> continues to run against other hosts. In the load-balancing scenario, you might want Ansible to fail the entire play before all hosts have failed a task. Otherwise, you might end up with the situation where you have taken each host out of the load balancer, and have it fail, leaving no hosts left inside your load balancer.</p>
<p>You can use a <code>max_fail_percentage</code> clause along with the <code>serial</code> clause to specify the maximum percentage of failed hosts before Ansible fails the entire play. For example, assume that we specify a maximum fail percentage of 25%, as shown here:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: upgrade packages on servers behind load balancer</span><br><span class="line">  hosts: myhosts</span><br><span class="line">  serial: 1</span><br><span class="line">  max_fail_percentage: 25</span><br><span class="line">  tasks:</span><br><span class="line">    # tasks go here</span><br></pre></td></tr></table></figure></p>
<p>If you want Ansible to fail if any of the hosts fail a task, set the <code>max_fail_percentage</code> to 0.</p>
<blockquote>
<p>Note: <code>any_errors_fatal: true</code> is just like set <code>max_fail_percentage</code> to 0, with the <code>any_errors_fatal</code> option, any failure on any host in a multi-host play will be treated as fatal and Ansible will exit immediately without waiting for the other hosts.</p>
</blockquote>
<p>We can get even more sophisticated. For example, you might want to run the play on one host first, to verify that the play works as expected, and then run the play on a larger number of hosts in subsequent runs.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: configure CDN servers</span><br><span class="line">  hosts: cdn</span><br><span class="line">  serial:</span><br><span class="line">    - 1</span><br><span class="line">    - 30%</span><br><span class="line">  tasks:</span><br><span class="line">    # tasks go here</span><br></pre></td></tr></table></figure></p>
<p>In the preceding play with 30 CDN hosts, on the first batch run Ansible would run against one host, and on each subsequent batch run it would run against at most 30% of the hosts (e.g., 1, 10, 10, 9).</p>
<h4 id="Running-Only-Once"><a href="#Running-Only-Once" class="headerlink" title="Running Only Once"></a>Running Only Once</h4><p>Using <code>run_once</code> can be particularly useful when using <code>local_action</code> if your playbook involves multiple hosts, and you want to run the local task only once:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: run the task locally, only once</span><br><span class="line">  local_action: command /opt/my-custom-command</span><br><span class="line">  run_once: true</span><br></pre></td></tr></table></figure></p>
<h4 id="Running-Strategies"><a href="#Running-Strategies" class="headerlink" title="Running Strategies"></a>Running Strategies</h4><p>The strategy clause on a play level gives you additional control over how Ansible behaves per task for all hosts.</p>
<p>The default behavior we are already familiar with is the <code>linear</code> strategy. This is the strategy in which Ansible executes one task on all hosts and waits until the task has completed (of failed) on all hosts before it executes the next task on all hosts. As a result, a task takes as much time as the slowest host takes to complete the task.</p>
<h5 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h5><p><strong>Note</strong>: I forget that host file can define variable, here <code>sleep_seconds</code> can be referred in task:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">one   sleep_seconds=1</span><br><span class="line">two   sleep_seconds=6</span><br><span class="line">three  sleep_seconds=10</span><br></pre></td></tr></table></figure></p>
<p><strong>Note</strong> that the orders show up is the complete order in target host, first done at top.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK [setup] *******************************************************************</span><br><span class="line">ok: [two]</span><br><span class="line">ok: [three]</span><br><span class="line">ok: [one]</span><br></pre></td></tr></table></figure></p>
<h5 id="Free"><a href="#Free" class="headerlink" title="Free"></a>Free</h5><p>Another strategy available in Ansible is the <code>free</code> strategy. In contrast to <code>linear</code>, Ansible will not wait for results of the task to execute on all hosts. Instead, if a host completes one task, Ansible will execute the next task on that host.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- hosts: all</span><br><span class="line">  strategy: free</span><br><span class="line">  tasks:</span><br><span class="line">     ...</span><br></pre></td></tr></table></figure></p>
<h4 id="Advanced-Handlers"><a href="#Advanced-Handlers" class="headerlink" title="Advanced Handlers"></a>Advanced Handlers</h4><p>When we covered handlers, you learned that they are usually executed after all tasks, once, and only when they get notified. But keep in mind there are not only <code>tasks</code>, but <code>pre_tasks</code>, <code>tasks</code>, and <code>post_tasks</code>.</p>
<p>Each tasks section in a playbook is handled separately; any handler notified in <code>pre_tasks</code>, <code>tasks</code>, or <code>post_tasks</code> is executed at the end of each section. As a result, it is possible to execute one handler several times in one play:</p>
<p><strong>Note</strong>: the rest of Chapter 9 is useless for me now, just skip it.</p>
<h3 id="Chapter-16-Debugging-Ansible-Playbooks"><a href="#Chapter-16-Debugging-Ansible-Playbooks" class="headerlink" title="Chapter 16. Debugging Ansible Playbooks"></a>Chapter 16. Debugging Ansible Playbooks</h3><h4 id="Humane-Error-Messages"><a href="#Humane-Error-Messages" class="headerlink" title="Humane Error Messages"></a>Humane Error Messages</h4><p>Enable the plugin by adding the following to the <code>defaults</code> section of <em>ansible.cfg</em>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[defaults]</span><br><span class="line">stdout_callback = debug</span><br></pre></td></tr></table></figure></p>
<p>the <code>debug</code> callback plugin makes this output much easier for a human to read, for example the format is like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK [check out the repository on the host] *************************************</span><br><span class="line">fatal: [web]: FAILED! =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;cmd&quot;: &quot;/usr/bin/git clone --origin origin &apos;&apos; /home/vagrant/mezzanine/mezzani</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">STDERR:</span><br><span class="line"></span><br><span class="line">Cloning into &apos;/home/vagrant/mezzanine/mezzanine_example&apos;...</span><br><span class="line">Permission denied (publickey).</span><br><span class="line">fatal: Could not read from remote repository.</span><br><span class="line">...</span><br><span class="line">MSG:</span><br><span class="line"></span><br><span class="line">Cloning into &apos;/home/vagrant/mezzanine/mezzanine_example&apos;...</span><br><span class="line">Permission denied (publickey).</span><br><span class="line">fatal: Could not read from remote repository.</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h4 id="Debugging-SSH-Issues"><a href="#Debugging-SSH-Issues" class="headerlink" title="Debugging SSH Issues"></a>Debugging SSH Issues</h4><p>Sometimes Ansible fails to make a successful SSH connection with the host. When this happens, it’s helpful to see exactly what arguments Ansible is passing to the underlying SSH client so you can reproduce the problem manually on the command line.</p>
<p>If you invoke <code>ansible-playbook</code> with the <code>-vvv</code> argument, you can see the exact SSH commands that Ansible invokes. This can be handy for debugging.</p>
<blockquote>
<p>Note that usually I use <code>-v</code> flag</p>
</blockquote>
<p>Sometimes you might need to use -vvvv when debugging a connection issue, in order to see an error message that the SSH client is throwing. </p>
<h4 id="The-Debug-Module"><a href="#The-Debug-Module" class="headerlink" title="The Debug Module"></a>The Debug Module</h4><p>We’ve used the <code>debug</code> module several times in this book. It’s Ansible’s version of a <code>print</code> statement.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- debug: var=myvariable</span><br><span class="line">- debug: msg=&quot;The value of myvariable is &#123;&#123; var &#125;&#125;&quot;</span><br><span class="line">- debug: var=hostvars[inventory_hostname]</span><br></pre></td></tr></table></figure></p>
<h4 id="Playbook-Debugger"><a href="#Playbook-Debugger" class="headerlink" title="Playbook Debugger"></a>Playbook Debugger</h4><p>Ansible 2.1 added support for an <strong>interactive debugger</strong>. To enable debugging, add <code>strategy: debug</code> to your play; for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: an example play</span><br><span class="line">  strategy: debug</span><br><span class="line">  tasks:</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure></p>
<p>If debugging is enabled, Ansible drops into the debugger when a task fails, for example, I write a task like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: install xxx package</span><br><span class="line">  yum:</span><br><span class="line">    name: xxx</span><br><span class="line">    state: latest</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK [install.components : interactive debug] ************************************************************************</span><br><span class="line">fatal: [myk8s2.fyre.ibm.com]: FAILED! =&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: false,</span><br><span class="line">    &quot;rc&quot;: 126,</span><br><span class="line">    &quot;results&quot;: [</span><br><span class="line">        &quot;No package matching &apos;xxx&apos; found available, installed or updated&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">MSG:</span><br><span class="line"></span><br><span class="line">No package matching &apos;xxx&apos; found available, installed or updated</span><br><span class="line"></span><br><span class="line">Debugger invoked</span><br><span class="line">(debug) p task</span><br></pre></td></tr></table></figure>
<p>Let’s see the command list<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Command              | Description                                 |</span><br><span class="line">|----------------------|---------------------------------------------|</span><br><span class="line">| p var                | Print out the value of a supported variable |</span><br><span class="line">| task.args[key]=value | Modify an argument for the failed task      |</span><br><span class="line">| vars[key]=value      | Modify the value of a variable              |</span><br><span class="line">| r                    | rerun the failed task                       |</span><br><span class="line">| c                    | continue execute next                       |</span><br><span class="line">| q                    | abort the play                              |</span><br><span class="line">| help                 | show help message                           |</span><br></pre></td></tr></table></figure></p>
<p>variables supported by the debugger<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| Command     | Description                            |</span><br><span class="line">|-------------|----------------------------------------|</span><br><span class="line">| p task      | the name of the failed task            |</span><br><span class="line">| p task.args | The module arguments                   |</span><br><span class="line">| p result    | The result returned by the failed task |</span><br><span class="line">| p vars      | Value of all known variables           |</span><br><span class="line">| p vars[key] | Value of one variable                  |</span><br></pre></td></tr></table></figure></p>
<h4 id="The-Assert-Module"><a href="#The-Assert-Module" class="headerlink" title="The Assert Module"></a>The Assert Module</h4><p>The <code>assert</code> module will fail with an error if a specified condition is not met. For example, to fail the playbook if there’s no <code>eth1</code> interface:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- name: assert that eth1 interface exists</span><br><span class="line">  assert:</span><br><span class="line">    that: ansible_eth1 is defined</span><br></pre></td></tr></table></figure></p>
<p>When debugging a playbook, it can be helpful to insert assertions so that a failure happens as soon as any assumption you’ve made has been violated.</p>
<p>Keep in mind that the code in an <code>assert</code> statement is Jinja2, not Python.</p>
<h4 id="Checking-Your-Playbook-Before-Execution"><a href="#Checking-Your-Playbook-Before-Execution" class="headerlink" title="Checking Your Playbook Before Execution"></a>Checking Your Playbook Before Execution</h4><p>The <code>ansible-playbook</code> command supports several flags that allow you to sanity check your playbook before you execute it.</p>
<h5 id="Syntax-Check"><a href="#Syntax-Check" class="headerlink" title="Syntax Check"></a>Syntax Check</h5><p>The <code>--syntax-check</code> flag checks that your playbook’s syntax is valid, but it does not execute it.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook --syntax-check -i &lt;host file&gt; playbook.yml</span><br></pre></td></tr></table></figure></p>
<h5 id="List-Hosts"><a href="#List-Hosts" class="headerlink" title="List Hosts"></a>List Hosts</h5><p>The –list-hosts flag outputs the hosts that the playbook will run against, but it does not execute the playbook.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook --list-hosts -i &lt;host file&gt; playbook.yml</span><br></pre></td></tr></table></figure></p>
<h5 id="List-Tasks"><a href="#List-Tasks" class="headerlink" title="List Tasks"></a>List Tasks</h5><p>Outputs the tasks that the playbook will run against. It does not execute the playbook.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook --list-tasks -i &lt;host file&gt; playbook.yml</span><br></pre></td></tr></table></figure></p>
<h5 id="Check-Mode"><a href="#Check-Mode" class="headerlink" title="Check Mode"></a>Check Mode</h5><p>The <code>-C</code> and <code>--check</code> flags run Ansible in check mode (sometimes known as <em>dry-run</em>), which tells you whether each task in the playbook will modify the host, but does not make any changes to the server.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook --check -i &lt;host file&gt; playbook.yml</span><br></pre></td></tr></table></figure>
<p>One of the challenges with using check mode is that later parts of a playbook might succeed only if earlier parts of the playbook were executed.</p>
<h5 id="Diff-Show-File-Changes"><a href="#Diff-Show-File-Changes" class="headerlink" title="Diff (Show File Changes)"></a>Diff (Show File Changes)</h5><p>The <code>-D</code> and <code>-diff</code> flags output differences for any files that are changed on the remote machine. It’s a helpful option to use in conjunction with <code>--check</code> to show how Ansible would change the file if it were run normally:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook --diff --check -i &lt;host file&gt; playbook.yml</span><br></pre></td></tr></table></figure></p>
<p>If Ansible would modify any files (e.g., using modules such as <code>copy</code>, <code>template</code>, and <code>lineinfile</code>), it will show the changes in .diff format, like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TASK: [set the gunicorn config file] ******************************************</span><br><span class="line">--- before: /home/vagrant/mezzanine-example/project/gunicorn.conf.py</span><br><span class="line">+++ after: /Users/lorin/dev/ansiblebook/ch06/playbooks/templates/gunicor</span><br><span class="line">n.conf.py.j2</span><br><span class="line">@@ -1,7 +1,7 @@</span><br><span class="line"> from __future__ import unicode_literals</span><br><span class="line"> import multiprocessing</span><br><span class="line"></span><br><span class="line"> bind = &quot;127.0.0.1:8000&quot;</span><br><span class="line"> workers = multiprocessing.cpu_count() * 2 + 1</span><br><span class="line">-loglevel = &quot;error&quot;</span><br><span class="line">+loglevel = &quot;warning&quot;</span><br><span class="line"> proc_name = &quot;mezzanine-example&quot;</span><br></pre></td></tr></table></figure></p>
<h4 id="Limiting-Which-Tasks-Run"><a href="#Limiting-Which-Tasks-Run" class="headerlink" title="Limiting Which Tasks Run"></a>Limiting Which Tasks Run</h4><p>Sometimes you don’t want Ansible to run every single task in your playbook, particularly when you’re first writing and debugging the playbook. Ansible provides several command-line options that let you control which tasks run.</p>
<h5 id="Step"><a href="#Step" class="headerlink" title="Step"></a>Step</h5><p>The <code>--step</code> flag, shown in <a href="https://learning.oreilly.com/library/view/ansible-up-and/9781491979792/ch16.html#step-example" target="_blank" rel="noopener">Example 16-7</a>, has Ansible prompt you before running each task, like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Perform task: install packages (y/n/c):</span><br></pre></td></tr></table></figure></p>
<p>You can choose to execute the task (y), skip it (n), or tell Ansible to continue running the rest of the playbook without prompting you (c).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook -i &lt;host file&gt; --step playbook.yml</span><br></pre></td></tr></table></figure></p>
<h5 id="Start-at-Task"><a href="#Start-at-Task" class="headerlink" title="Start-at-Task"></a>Start-at-Task</h5><p>The <code>--start-at-task taskname</code> flag tells Ansible to start running the playbook at the specified task, instead of at the beginning. This can be handy if one of your tasks failed because there was a bug in one of your tasks, and you want to rerun your playbook starting at the task you just fixed.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook -i &lt;host file&gt; --start-at-task=&quot;install packages&quot; playbook.yml</span><br></pre></td></tr></table></figure></p>
<h5 id="Tags"><a href="#Tags" class="headerlink" title="Tags"></a>Tags</h5><p>Ansible allows you to add one or more tags to a task or a play. For example, here’s a play that’s tagged with <code>foo</code> and a task that’s tagged with <code>bar</code> and <code>quux</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- hosts: myservers</span><br><span class="line">  tags:</span><br><span class="line">   - foo</span><br><span class="line">  tasks:</span><br><span class="line">   - name: install editors</span><br><span class="line">     apt: name=&#123;&#123; item &#125;&#125;</span><br><span class="line">     with_items:</span><br><span class="line">       - vim</span><br><span class="line">       - emacs</span><br><span class="line">       - nano</span><br><span class="line"></span><br><span class="line">   - name: run arbitrary command</span><br><span class="line">     command: /opt/myprog</span><br><span class="line">     tags:</span><br><span class="line">       - bar</span><br><span class="line">       - quux</span><br></pre></td></tr></table></figure></p>
<p>Use the <code>-t tagnames</code> or <code>--tags tagnames</code> flag to tell Ansible to run only plays and tasks that have certain tags. Use the <code>--skip-tags tagnames</code> flag to tell Ansible to skip plays and tasks that have certain tags.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible-playbook -t foo,bar playbook.yml</span><br><span class="line">ansible-playbook --tags=foo,bar playbook.yml</span><br><span class="line">ansible-playbook --skip-tags=baz,quux playbook.yml</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>book</tag>
      </tags>
  </entry>
  <entry>
    <title>How Linux Works, 2nd Edition</title>
    <url>/2019/04/19/book-how-linux-works/</url>
    <content><![CDATA[<p>Great book for all Linux developers and administrators! Just note for future quick revisit!</p>
<h2 id="Chapter1-The-Big-picture"><a href="#Chapter1-The-Big-picture" class="headerlink" title="Chapter1. The Big picture"></a>Chapter1. The Big picture</h2><p>The most effective way to understand how an operating system works is through abstraction—a fancy way of saying that you can ignore most of the details.</p>
<p>The <code>kernel</code> is software residing in memory that tells the CPU what to do. The kernel manages the hardware and acts primarily as an interface between the hardware and any running program.</p>
<p>Processes—the running programs that the kernel manages—collectively make up the system’s upper level, called <code>user space</code>.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line">|                                                                         |</span><br><span class="line">|  User process                                                           |</span><br><span class="line">|                                                                         |</span><br><span class="line">|   +-------------------+   +-----------------+    +---------------+      |</span><br><span class="line">|   |  GUI              |   |  Servers        |    |  Shell        |      |</span><br><span class="line">|   |                   |   |                 |    |               |      |</span><br><span class="line">|   +-------------------+   +-----------------+    +---------------+      |</span><br><span class="line">|                                                                         |</span><br><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line">|                                                                         |</span><br><span class="line">|  Linux kernel                                                           |</span><br><span class="line">|  +--------------+     +--------------------------+                      |</span><br><span class="line">|  |  system calls|     |   process management     |                      |</span><br><span class="line">|  +--------------+     +--------------------------+                      |</span><br><span class="line">|                                                                         |</span><br><span class="line">|  +---------------------+        +-------------------------------+       |</span><br><span class="line">|  |  device driver      |        |   memory management           |       |</span><br><span class="line">|  +---------------------+        +-------------------------------+       |</span><br><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line"></span><br><span class="line">+-------------------------------------------------------------------------+</span><br><span class="line">|                                                                         |</span><br><span class="line">|  Hardware                                                               |</span><br><span class="line">|                                                                         |</span><br><span class="line">|  +-------------------+   +-------------------+   +---------------+      |</span><br><span class="line">|  |   CPU             |   |    RAM            |   |  Disk         |      |</span><br><span class="line">|  +-------------------+   +-------------------+   +---------------+      |</span><br><span class="line">|  +---------------------+                                                |</span><br><span class="line">|  |   Network           |                                                |</span><br><span class="line">|  +---------------------+                                                |</span><br><span class="line">+-------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<p>There is a critical difference between the ways that the kernel and user processes run: The kernel runs in kernel mode, and the user processes run in user mode. Code running in kernel mode has unrestricted access to the processor and main memory. This is a powerful but dangerous privilege that allows a kernel process to easily crash the entire system. The area that only the kernel can access is called kernel space.</p>
<p>User mode, in comparison, restricts access to a (usually quite small) subset of memory and safe CPU operations. User space refers to the parts of main memory that the user processes can access. If a process makes a mistake and crashes, the consequences are limited and can be cleaned up by the kernel. This means that if your web browser crashes, it probably won’t take down the scientific computation that you’ve been running in the background for days.</p>
<h3 id="Hardware"><a href="#Hardware" class="headerlink" title="Hardware"></a>Hardware</h3><p>A CPU is just an operator on memory; it reads its instructions and data from the memory and writes data back out to the memory.</p>
<p>You’ll often hear the term <code>state</code> in reference to memory, processes, the kernel, and other parts of a computer system. Strictly speaking, a state is a particular arrangement of bits. For example, if you have four bits in your memory, 0110, 0001, and 1011 represent three different states.</p>
<p>The term <code>image</code> refers to a particular physical arrangement of bits.</p>
<h3 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h3><p>Nearly everything that the kernel does revolves around main memory. One of the kernel’s tasks is to split memory into many subdivisions, and it must maintain certain state information about those subdivisions at all times. Each process gets its own share of memory, and the kernel must ensure that each process keeps to its share.</p>
<p>The kernel is in charge of managing tasks in four general system areas:<br><strong>Processes</strong>. The kernel is responsible for determining which processes are allowed to use the CPU.</p>
<p><strong>Memory</strong>. The kernel needs to keep track of all memory—what is currently allocated to a particular process, what might be shared between processes, and what is free.</p>
<p><strong>Device drivers</strong>. The kernel acts as an interface between hardware (such as a disk) and processes. It’s usually the kernel’s job to operate the hardware.</p>
<p><strong>System calls and support</strong>. Processes normally use system calls to communicate with the kernel.</p>
<p>The act of one process giving up control of the CPU to another process is called a <strong>context switch</strong>.</p>
<p>The kernel is responsible for context switching. To understand how this works, let’s think about a situation in which a process is running in user mode but its time slice is up. Here’s what happens:</p>
<ol>
<li>The CPU (the actual hardware) interrupts the current process based on an internal timer, switches into kernel mode, and hands control back to the kernel.</li>
<li>The kernel records the current state of the CPU and memory, which will be essential to resuming the process that was just interrupted.</li>
<li>The kernel performs any tasks that might have come up during the preceding time slice (such as collecting data from input and output, or I/O, operations).</li>
<li>The kernel is now ready to let another process run. The kernel analyzes the list of processes that are ready to run and chooses one.</li>
<li>The kernel prepares the memory for this new process, and then prepares the CPU.</li>
<li>The kernel tells the CPU how long the time slice for the new process will last.</li>
<li>The kernel switches the CPU into user mode and hands control of the CPU to the process.</li>
</ol>
<p>The context switch answers the important question of <strong>when</strong> the kernel runs. The answer is that it runs <strong>between</strong> process time slices during a context switch.</p>
<p>Modern CPUs include a <code>memory management unit (MMU)</code> that enables a memory access scheme called <code>virtual memory</code>. When using virtual memory, a process does not directly access the memory by its physical location in the hardware. Instead, the kernel sets up each process to act as if it had an entire machine to itself. When the process accesses some of its memory, the MMU intercepts the access and uses a memory address map to translate the memory location from the process into an actual physical memory location on the machine. The kernel must still initialize and continuously maintain and alter this memory address map. For example, during a context switch, the kernel has to change the map from the outgoing process to the incoming process.</p>
<blockquote>
<p>The implementation of a memory address map is called a page table.</p>
</blockquote>
<p>The kernel’s role with devices is pretty simple. A device is typically accessible only in kernel mode because improper access (such as a user process asking to turn off the power) could crash the machine. Another problem is that different devices rarely have the same programming interface, even if the devices do the same thing, such as two different network cards. Therefore, device drivers have traditionally been part of the kernel.</p>
<p>There are several other kinds of kernel features available to user processes. For example, <code>system calls</code> (or syscalls) perform specific tasks that a user process alone cannot do well or at all. For example, the acts of opening, reading, and writing files all involve system calls.</p>
<p>Other than <code>init</code>, <strong>all</strong> user processes on a Linux system start as a result of <code>fork()</code>, and most of the time, you also run <code>exec()</code> to start a new program instead of running a copy of an existing process.</p>
<h3 id="User-Space"><a href="#User-Space" class="headerlink" title="User Space"></a>User Space</h3><p>As mentioned earlier, the main memory that the kernel allocates for user processes is called <code>user space</code>. Because a process is simply a state (or image) in memory, user space also refers to the memory for the entire collection of running processes. </p>
<h3 id="Users"><a href="#Users" class="headerlink" title="Users"></a>Users</h3><p>A <code>user</code> is an entity that can run processes and own files. A user is associated with a username. For example, a system could have a user named billyjoe. However, the kernel does not manage the usernames; instead, it identifies users by simple numeric identifiers called userids.</p>
<p>Users exist primarily to support permissions and boundaries.</p>
<p>In addition, as powerful as the <strong>root</strong> user is, it still runs in the operating system’s user mode, not kernel mode.</p>
<p><code>Groups</code> are sets of users. The primary purpose of groups is to allow a user to share file access to other users in a group.</p>
<h2 id="Chapter-2-Basic-Commands-and-Directory-Hierarchy"><a href="#Chapter-2-Basic-Commands-and-Directory-Hierarchy" class="headerlink" title="Chapter 2. Basic Commands and Directory Hierarchy"></a>Chapter 2. Basic Commands and Directory Hierarchy</h2><p>Some resources:<br><code>&lt;&lt;UNIX for the Impatient&gt;&gt;</code><br><code>&lt;&lt;Learning the UNIX Operating System&gt;&gt;</code></p>
<p>The <code>shell</code> is one of the most important parts of a Unix system. A shell is a program that runs commands. The shell also serves as a small programming environment.</p>
<p>Many important parts of the system are actually <code>shell scripts</code>—text files that contain a sequence of shell commands. </p>
<p>There are many different Unix shells, but all derive several of their features from the <code>Bourne shell</code> (/bin/sh), a standard shell developed at Bell Labs for early versions of Unix. Every Unix system needs the Bourne shell in order to function correctly, as you will see throughout this book.</p>
<p>Linux uses an enhanced version of the Bourne shell called <code>bash</code> or the “Bourne-again” shell. The bash shell is the default shell on most Linux distributions, and /bin/sh is normally a link to bash on a Linux system. </p>
<blockquote>
<p><code>cat</code> command: The command is called cat because it performs concatenation when it prints the contents of more than one file.</p>
</blockquote>
<p>Pressing <code>CTRL-D</code> on an empty line stops the current standard input entry from the terminal (and often terminates a program). Don’t confuse this with <code>CTRL-C</code>, which terminates a program regardless of its input or output.</p>
<blockquote>
<p>Unix filenames do not need extensions and often do not carry them.</p>
</blockquote>
<p><code>shell globs</code> don’t match dot files unless you explicitly use a pattern such as <code>.*</code>. This is why <code>rm -rf ./*</code> doesn’t remove hidden objects.</p>
<blockquote>
<p>You can run into problems with globs because <code>.*</code> matches <code>.</code> and <code>..</code> (the current and parent directories)</p>
</blockquote>
<p>The shell can store temporary variables, called <code>shell variables</code>, containing the values of text strings. Shell variables are very useful for keeping track of values in scripts, and some shell variables control the way the shell behaves.</p>
<p>An <code>environment variable</code> is like a shell variable, but it’s not specific to the shell. All processes on Unix systems have environment variable storage. The main difference between environment and shell variables is that the operating system passes all of your shell’s <code>environment variables</code> to programs that the shell runs (for example, the sub-script), whereas shell variables cannot be accessed in the commands that you run.</p>
<p>Assign an environment variable with the shell’s <code>export</code> command. For example, if you’d like to make the <code>$STUFF</code> shell variable into an environment variable, use the following:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">STUFF=123</span><br><span class="line">export STUFF</span><br></pre></td></tr></table></figure></p>
<p><code>PATH</code> is a special environment variable that contains the <code>command path</code> (or path for short). A command path is a list of system directories that the shell searches when trying to locate a command.</p>
<p>resource:<br><code>&lt;&lt;Learning the vi and Vim Editor&gt;&gt;</code></p>
<p>Some <code>kill process</code> ways.There are many types of signals. The default is <code>TERM</code>, or terminate.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kill -STOP pid</span><br><span class="line">kill -CONT pid</span><br><span class="line">kill -KILL pid  # the same as kill -9 pid</span><br></pre></td></tr></table></figure></p>
<p>To see if you’ve accidentally suspended any processes on your current terminal, run the <code>jobs</code> command.</p>
<p>You can detach a process from the shell and put it in the “background” with the ampersand <code>&amp;</code>. The best way to make sure that a background process doesn’t bother you is to redirect its output (and possibly input).</p>
<p>Some executable files have an <code>s</code> in the <code>owner permissions</code> listing instead of an x. This indicates that the executable is <code>setuid</code>, meaning that when you execute the program, it runs as though the file owner is the user instead of you. Many programs use this <code>setuid</code> bit to run as root in order to get the privileges they need to change system files. One example is the <code>passwd</code> program, which needs to change the <code>/etc/passwd</code> file.</p>
<p>Directories also have permissions. You can list the contents of a directory if it’s readable, but you can only access a file in a directory if the directory is <code>executable</code>. (One common mistake people make when setting the permissions of directories is to accidentally remove the execute permission when using absolute modes.)</p>
<p>You can specify a set of default permissions with the <code>umask (user file-creation mode mask)</code>shell command, which applies a predefined set of permissions to any new file you create. In general, use <code>umask 022</code> if you want everyone to be able to see all of the files and directories that you create, and use <code>umask 077</code> if you don’t. (You’ll need to put the umask command with the desired mode in one of your startup files to make your new default permissions apply to later sessions).</p>
<blockquote>
<p>How to calculate the <code>umask</code>?</p>
<p>For directories, the base permissions are (rwxrwxrwx) <code>0777</code> and for files they are <code>0666</code> (rw-rw-rw).</p>
<p>You can simply subtract the umask from the base permissions to determine the final permission for file as follows:<br>666 – 022 = 644<br>subtract to get permissions of new file (666-022) : 644 (rw-r–r–)</p>
<p>You can simply subtract the umask from the base permissions to determine the final permission for directory as follows:<br>777 – 022 = 755<br>Subtract to get permissions of new directory (777-022) : 755 (rwxr-xr-x)</p>
</blockquote>
<p>Another compression program in Unix is <code>bzip2</code>, whose compressed files end with <code>.bz2</code>. While marginally slower than gzip, bzip2 often compacts text files a little more, and it is therefore increasingly popular in the distribution of source code. </p>
<p>The <code>bzip2</code> compression/decompression option for tar is <code>j</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar jcvf xx.bz2 file...</span><br><span class="line">tar jxvf xx.bz2</span><br></pre></td></tr></table></figure></p>
<h3 id="Linux-Directory-Hierarchy-Essentials"><a href="#Linux-Directory-Hierarchy-Essentials" class="headerlink" title="Linux Directory Hierarchy Essentials"></a>Linux Directory Hierarchy Essentials</h3><p>Simplified overview of the hierarchy<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">                                                  +---------+</span><br><span class="line">                                                  |   /     |</span><br><span class="line">                                                  +-----+---+</span><br><span class="line">                                                        |</span><br><span class="line">    +-------------+-------------+-----------+----------------------+-----------+-----------+----------+</span><br><span class="line">    |             |             |           |           |          |           |           |          |</span><br><span class="line">    |             |             |           |           |          |           |           |          |</span><br><span class="line">    |             |             |           |           |          |           |           |          |</span><br><span class="line">    v             v             v           v           v          v           v           v          v</span><br><span class="line">+---+----+    +---+----+   +----+---+  +----+---+  +----+---+  +---+---+  +----+---+  +----+----+ +---------+</span><br><span class="line">|  /bin  |    |  /dev  |   |  /etc  |  |   /usr |  | /home  |  | /lib  |  |  /sbin |  |   /tmp  | |  /var   |</span><br><span class="line">+--------+    +--------+   +--------+  +----+---+  +--------+  +-------+  +--------+  +---------+ +----+----+</span><br><span class="line">                                            |                                                          |</span><br><span class="line">                                            |                                                     +----+-----+</span><br><span class="line">                                            |                                                     |          |</span><br><span class="line">              +---------+----------+--------------------+----------+                              |          |</span><br><span class="line">              |         |          |        |           |          |                              |          |</span><br><span class="line">              v         v          v        v           v          v                              v          v</span><br><span class="line">         +----+--+  +---+--+  +----+---+  +-+----+  +---+---+  +---+---+                     +----+---+  +---+----+</span><br><span class="line">         | bin/  |  | man/ |  |  lib/  |  |local/|  | sbin/ |  | share/|                     | log/   |  |  /tmp  |</span><br><span class="line">         +-------+  +------+  +--------+  +------+  +-------+  +-------+                     +--------+  +--------+</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p><code>/bin</code> Contains ready-to-run programs (also known as an executables), including most of the basic Unix commands such as ls and cp. Most of the programs in /bin are in binary format, having been created by a C compiler, but some are shell scripts in modern systems.</p>
</li>
<li><p><code>/dev</code> Contains device files.</p>
</li>
<li><p><code>/etc</code> This core system configuration directory contains the user password, boot, device, networking, and other setup files. Many items in /etc are specific to the machine’s hardware. </p>
</li>
<li><p><code>/home</code> Holds personal directories for regular users. </p>
</li>
<li><p><code>/lib</code> An abbreviation for library, this directory holds library files containing code that executables can use.</p>
</li>
<li><p><code>/proc</code> Provides system statistics through a browsable directory-and-file interface. The <code>/proc</code> directory contains information about currently running processes as well as some kernel parameters.</p>
</li>
<li><p><code>/sys</code> This directory is similar to /proc in that it provides a device and system interface.</p>
</li>
<li><p><code>/sbin</code> The place for system executables. Programs in /sbin directories relate to system management.</p>
</li>
<li><p><code>/tmp</code> A storage area for smaller, temporary files that you don’t care much about. If something is extremely important, don’t put it in /tmp because most distributions clear /tmp when the machine boots and some even remove its old files periodically. Also, don’t let /tmp fill up with garbage because its space is usually shared with something critical  </p>
</li>
<li><p><code>/usr</code> Although pronounced “user,” this subdirectory has no user files. Instead, it contains a large directory hierarchy, including the bulk of the Linux system. Many of the directory names in /usr are the same as those in the root directory (like /usr/bin and /usr/lib), and they hold the same type of files. (The reason that the root directory does not contain the complete system is primarily historic—in the past, it was to keep space requirements low for the root.)</p>
</li>
<li><p><code>/var</code> The variable subdirectory, where programs record runtime information. System logging, user tracking, caches, and other files that system programs create and manage are here.</p>
</li>
<li><p><code>/boot</code> Contains kernel boot loader files. These files pertain only to the very first stage of the Linux startup procedure.</p>
</li>
<li><p><code>/media</code> A base attachment point for removable media such as flash drives that is found in many distributions.</p>
</li>
<li><p><code>/opt</code> This may contain additional third-party software. </p>
</li>
</ul>
<h3 id="Kernel-Location"><a href="#Kernel-Location" class="headerlink" title="Kernel Location"></a>Kernel Location</h3><p>On Linux systems, the kernel is normally in <code>/vmlinuz</code> or <code>/boot/vmlinuz</code>. A boot loader loads this file into memory and sets it in motion when the system boots.</p>
<p>Once the boot loader runs and sets the kernel in motion, the main kernel file is no longer used by the running system. However, you’ll find many modules that the kernel can load and unload on demand during the course of normal system operation. Called loadable kernel modules, they are located under <code>/lib/modules</code>.</p>
<h2 id="Chapter-3-Devices"><a href="#Chapter-3-Devices" class="headerlink" title="Chapter 3. Devices"></a>Chapter 3. Devices</h2><p>It’s important to understand how the kernel interacts with user space when presented with new devices. The <code>udev</code> system enables user-space programs to automatically configure and use new devices. </p>
<blockquote>
<p><code>udev</code> (userspace /dev) is a device manager for the Linux kernel. As the successor of devfsd and hotplug, udev primarily manages device nodes in the /dev directory.</p>
</blockquote>
<h3 id="Device-Files"><a href="#Device-Files" class="headerlink" title="Device Files"></a>Device Files</h3><p>It is easy to manipulate most devices on a Unix system because the kernel presents many of the device I/O interfaces to user processes as <strong>files</strong>. These device files are sometimes called <code>device nodes</code>. Not only can a programmer use regular file operations to work with a device, but some devices are also accessible to standard programs like <code>cat</code>. However, not all devices or device capabilities are accessible with standard file I/O.</p>
<p>Device files are in the <code>/dev</code> directory, and running <code>ls /dev</code> reveals more than a few files in <code>/dev</code>.</p>
<p>if run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -l</span><br><span class="line">brw-rw----     1 root disk 8, 1 Sep  6 08:37 sda1</span><br><span class="line">crw-rw-rw-     1 root root 1, 3 Sep  6 08:37 null</span><br><span class="line">prw-r--r--     1 root root    0 Mar  3 19:17 fdata</span><br><span class="line">srw-rw-rw-     1 root root    0 Dec 18 07:43 log</span><br></pre></td></tr></table></figure></p>
<p>if the first char in file mode is <code>b</code>, <code>c</code>, <code>p</code>, or <code>s</code>, the file is a device. These letters stand for block, character, pipe, and socket, respectively.</p>
<p>The numbers before the dates in the first two lines are the <code>major</code> and <code>minor</code> device numbers that help the kernel identify the device. Similar devices usually have the same major number.</p>
<h4 id="Block-device"><a href="#Block-device" class="headerlink" title="Block device"></a>Block device</h4><p>Programs access data from a block device in fixed chunks. The sda1 in the preceding example is a disk device, a type of block device.</p>
<h4 id="Character-device"><a href="#Character-device" class="headerlink" title="Character device"></a>Character device</h4><p>Character devices work with data streams. Printers directly attached to your computer are represented by character devices. It’s important to note that during character device interaction, the kernel cannot back up and reexamine the data stream after it has passed data to a device or process.</p>
<h4 id="Pipe-device"><a href="#Pipe-device" class="headerlink" title="Pipe device"></a>Pipe device</h4><p>Named pipes are like character devices, with another process at the other end of the I/O stream instead of a kernel driver.</p>
<h3 id="Socket-device"><a href="#Socket-device" class="headerlink" title="Socket device"></a>Socket device</h3><p>Sockets are special-purpose interfaces that are frequently used for <code>interprocess communication</code>. </p>
<blockquote>
<p>Not all devices have device files because the block and character device I/O interfaces are not appropriate in all cases. For example, <code>network interfaces</code> don’t have device files. It is theoretically possible to interact with a network interface using a single character device, but because it would be exceptionally difficult, the kernel uses other I/O interfaces.</p>
</blockquote>
<h3 id="The-sysfs-Device-Path"><a href="#The-sysfs-Device-Path" class="headerlink" title="The sysfs Device Path"></a>The sysfs Device Path</h3><p>To provide a uniform view for attached devices based on their actual hardware attributes, the Linux kernel offers the <code>sysfs</code> interface through a system of files and directories. The base path for devices is <code>/sys/devices</code> (this is a real directory!).<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -ltr /sys/devices/</span><br><span class="line"></span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x 21 root root 0 Apr 25 23:18 virtual</span><br><span class="line">drwxr-xr-x  3 root root 0 Apr 25 23:18 tracepoint</span><br><span class="line">drwxr-xr-x 10 root root 0 Apr 25 23:18 system</span><br><span class="line">drwxr-xr-x  3 root root 0 Apr 25 23:18 software</span><br><span class="line">drwxr-xr-x  8 root root 0 Apr 25 23:18 pnp0</span><br><span class="line">drwxr-xr-x  9 root root 0 Apr 25 23:18 platform</span><br><span class="line">drwxr-xr-x 15 root root 0 Apr 25 23:18 pci0000:00</span><br><span class="line">drwxr-xr-x  5 root root 0 Apr 25 23:18 msr</span><br><span class="line">drwxr-xr-x  6 root root 0 Apr 25 23:18 LNXSYSTM:00</span><br><span class="line">drwxr-xr-x  3 root root 0 Apr 25 23:18 breakpoint</span><br></pre></td></tr></table></figure></p>
<p>The <code>/dev</code> file is there so that user processes can use the device, whereas the <code>/sys/devices</code> path is used to view information and manage the device. In <code>/dev</code> you can run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">udevadm info --query=all --name=/dev/null</span><br><span class="line"></span><br><span class="line">P: /devices/virtual/mem/null</span><br><span class="line">N: null</span><br><span class="line">E: DEVMODE=0666</span><br><span class="line">E: DEVNAME=/dev/null</span><br><span class="line">E: DEVPATH=/devices/virtual/mem/null</span><br><span class="line">E: MAJOR=1</span><br><span class="line">E: MINOR=3</span><br><span class="line">E: SUBSYSTEM=mem</span><br></pre></td></tr></table></figure></p>
<p>this command will show the sysfs location <code>/devices/virtual/mem/null</code></p>
<h3 id="dd-and-Devices"><a href="#dd-and-Devices" class="headerlink" title="dd and Devices"></a>dd and Devices</h3><p>The program <code>dd</code> is extremely useful when working with block and character devices. This program’s sole function is to read from an input file or stream and write to an output file or stream, possibly doing some encoding conversion on the way.</p>
<p>I am not using it.</p>
<h3 id="Device-Name-Summary"><a href="#Device-Name-Summary" class="headerlink" title="Device Name Summary"></a>Device Name Summary</h3><p>Not necessarily as described below, may be some variations:</p>
<ul>
<li>Hard Disks: /dev/sd*</li>
</ul>
<p>Most hard disks attached to current Linux systems correspond to device names with an <code>sd</code> prefix, such as <code>/dev/sda</code>, <code>/dev/sdb</code>, and so on. These devices represent entire disks; the kernel makes separate device files, such as <code>/dev/sda1</code> and <code>/dev/sda2</code>, for the partitions on a disk.</p>
<blockquote>
<p>The <code>sd</code> portion of the name stands for SCSI disk.</p>
</blockquote>
<p>Linux assigns devices to device files in the <strong>order</strong> in which its drivers encounter devices. This may cause problem when you remove one disk and insert another, because the device name changed for old disk. Most modern Linux systems use the Universally Unique Identifier (<code>UUID</code>) for persistent disk device access.</p>
<ul>
<li>CD and DVD Drives: /dev/sr*</li>
</ul>
<p>Linux recognizes most optical storage drives as the SCSI devices /dev/sr0, /dev/sr1, and so on. </p>
<ul>
<li><p>PATA Hard Disks: /dev/hd*</p>
</li>
<li><p>Terminals: /dev/tty<em>, /dev/pts/</em>, and /dev/tty</p>
</li>
</ul>
<p>Terminals are devices for moving characters between a user process and an I/O device, usually for text output to a terminal screen. </p>
<p><code>Pseudoterminal</code> devices are emulated terminals that understand the I/O features of real terminals. </p>
<p>Two common terminal devices are <code>/dev/tty1</code> (the first virtual console) and <code>/dev/pts/0</code> (the first pseudoterminal device). The <code>/dev/tty</code> device is the controlling terminal of the current process.</p>
<blockquote>
<p>teletypewriter, <code>tty</code> in shorthand</p>
</blockquote>
<p>I am always confused, at least you need to know <strong>shell</strong> is the command line interpreter!<br><a href="https://askubuntu.com/questions/506510/what-is-the-difference-between-terminal-console-shell-and-command-line" target="_blank" rel="noopener">What is the difference between Terminal, Console, Shell, and Command Line?</a></p>
<p>Linux has two primary display modes: <code>text mode</code> and an <code>X Window System server</code> (graphics mode, usually via a display manager). Although Linux systems traditionally booted in text mode, most distributions now use kernel parameters and interim graphical display mechanisms to completely hide text mode as the system is booting. In such cases, the system switches over to full graphics mode near the end of the boot process.</p>
<p>OK, skip rest of the content in Chapter 3.</p>
<h2 id="Chapter-4-Disks-and-Filesystems"><a href="#Chapter-4-Disks-and-Filesystems" class="headerlink" title="Chapter 4. Disks and Filesystems"></a>Chapter 4. Disks and Filesystems</h2><p>Schematic of a typical Linux disk:</p>
<p><img src="https://drive.google.com/uc?id=1e0ziORmoEx6zPk6J6qEid26aWl-zw21G" alt=""></p>
<p><code>Partitions</code> are subdivisions of the whole disk. On Linux, they’re denoted with a number after the whole block device, and therefore have device names such as <code>/dev/sda1</code> and <code>/dev/sdb3</code>.</p>
<p>Partitions are defined on a small area of the disk called a <code>partition table</code>.</p>
<p>The next layer after the partition is the <code>filesystem</code>, the database of files and directories that you’re accustomed to interacting with in user space.</p>
<p>To access data on a disk, the Linux kernel uses the system of layers like this:</p>
<p><img src="https://drive.google.com/uc?id=1Hy8vWUIBuo33oH976PNEkVzvAOzCuyKJ" alt=""></p>
<blockquote>
<p>Notice that you can work with the disk through the filesystem as well as directly through the disk devices.</p>
</blockquote>
<h3 id="Partitioning-Disk-Devices"><a href="#Partitioning-Disk-Devices" class="headerlink" title="Partitioning Disk Devices"></a>Partitioning Disk Devices</h3><blockquote>
<p>You can view RedHat <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/storage_administration_guide/ch-partitions" target="_blank" rel="noopener">Doc</a> for more information about partition</p>
</blockquote>
<p>Let’s view the partition table:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">parted -l</span><br><span class="line"></span><br><span class="line">Model: ATA WDC WD3200AAJS-2 (scsi)</span><br><span class="line">Disk /dev/sda: 320GB</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: msdos</span><br><span class="line"></span><br><span class="line">Number   Start   End    Size   Type      File system    Flags</span><br><span class="line"> 1       1049kB  316GB  316GB  primary   ext4           boot</span><br><span class="line"> 2       316GB   320GB  4235MB extended</span><br><span class="line"> 5       316GB   320GB  4235MB logical   linux-swap(v1)</span><br><span class="line"></span><br><span class="line">Model: FLASH Drive UT_USB20 (scsi)</span><br><span class="line">Disk /dev/sdf: 4041MB</span><br><span class="line">Sector size (logical/physical): 512B/512B</span><br><span class="line">Partition Table: gpt</span><br><span class="line"></span><br><span class="line">Number  Start   End     Size     File system  Name        Flags</span><br><span class="line"> 1      17.4kB  1000MB  1000MB                myfirst</span><br><span class="line"> 2      1000MB  4040MB  3040MB                mysecond</span><br></pre></td></tr></table></figure></p>
<p>There are 2 different partition tables: MBR (msdos) and GPT (gpt). The MBR table in this example contains primary, extended, and logical partitions. </p>
<h3 id="Changing-Partition-Tables"><a href="#Changing-Partition-Tables" class="headerlink" title="Changing Partition Tables"></a>Changing Partition Tables</h3><p>You can use <code>parted</code> command to change partition. Check <code>/proc/partitions</code> can get full partition information.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat /proc/partitions</span><br><span class="line"></span><br><span class="line">major minor  #blocks  name</span><br><span class="line"> 252        0  262144000 vda</span><br><span class="line"> 252        1    1048576 vda1</span><br><span class="line"> 252        2  260976640 vda2</span><br><span class="line"> 253        0  252706816 dm-0</span><br><span class="line"> 253        1    8257536 dm-1</span><br></pre></td></tr></table></figure></p>
<h3 id="Filesystems"><a href="#Filesystems" class="headerlink" title="Filesystems"></a>Filesystems</h3><p>The last link between the kernel and user space for disks is typically the file-system; this is what you’re accustomed to interacting with when you run commands such as <code>ls</code> and <code>cd</code>. As previously mentioned, the <strong>filesystem is a form of database</strong>; it supplies the structure to transform a simple block device into the sophisticated hierarchy of files and subdirectories that users can understand.</p>
<h4 id="Filesystem-Types"><a href="#Filesystem-Types" class="headerlink" title="Filesystem Types"></a>Filesystem Types</h4><ul>
<li>The <code>Fourth Extended filesystem (ext4)</code> is the current iteration of a line of filesystems native to Linux. The <code>Second Extended filesystem (ext2)</code> was a longtime default for Linux systems inspired by traditional Unix filesystems such as the Unix File System (UFS) and the Fast File System (FFS). The <code>Third Extended filesystem (ext3)</code> added a journal feature (a small cache outside the normal filesystem data structure) to enhance data integrity and hasten booting. The ext4 filesystem is an incremental improvement with support for larger files than ext2 or ext3 support and a greater number of subdirectories.</li>
</ul>
<h4 id="Create-a-Filesystems"><a href="#Create-a-Filesystems" class="headerlink" title="Create a Filesystems"></a>Create a Filesystems</h4><p>Once you’re done with the partitioning process, you’re ready to create filesystems. As with partitioning, you’ll do this in user space because a user-space process can directly access and manipulate a block device. </p>
<p>For example, you can create an ext4 partition on /dev/sdf2<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkfs -t ext4 /dev/sdf2</span><br></pre></td></tr></table></figure></p>
<p>Filesystem creation is a task that you should only need to perform after adding a new disk or repartitioning an old one. You should create a filesystem just once for each new partition that has no preexisting data (or that has data that you want to remove). Creating a new filesystem on top of an existing filesystem will effectively destroy the old data.</p>
<p>It turns out that mkfs is only a frontend for a series of filesystem creation programs:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -l /sbin/mkfs.*</span><br><span class="line"></span><br><span class="line">-rwxr-xr-x. 1 root root 375240 Mar  7  2017 /sbin/mkfs.btrfs</span><br><span class="line">-rwxr-xr-x  1 root root  37080 Jul 12  2018 /sbin/mkfs.cramfs</span><br><span class="line">-rwxr-xr-x  4 root root  96384 Apr 10  2018 /sbin/mkfs.ext2</span><br><span class="line">-rwxr-xr-x  4 root root  96384 Apr 10  2018 /sbin/mkfs.ext3</span><br><span class="line">-rwxr-xr-x  4 root root  96384 Apr 10  2018 /sbin/mkfs.ext4</span><br><span class="line">-rwxr-xr-x  1 root root  37184 Jul 12  2018 /sbin/mkfs.minix</span><br><span class="line">-rwxr-xr-x. 1 root root 368504 Feb 27  2018 /sbin/mkfs.xfs</span><br></pre></td></tr></table></figure></p>
<h4 id="Mounting-a-Filesystem"><a href="#Mounting-a-Filesystem" class="headerlink" title="Mounting a Filesystem"></a>Mounting a Filesystem</h4><p>On Unix, the process of attaching a filesystem is called <code>mounting</code>. When the system boots, the kernel reads some configuration data and mounts root (/) based on the configuration data.</p>
<p>When mounting a filesystem, the common terminology is <em>mount a device on a mount point.</em></p>
<p>To see current system mount status:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount </span><br><span class="line">...</span><br><span class="line">cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)</span><br><span class="line">/dev/mapper/rhel-root on / type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">mqueue on /dev/mqueue type mqueue (rw,relatime)</span><br><span class="line">hugetlbfs on /dev/hugepages type hugetlbfs (rw,relatime)</span><br><span class="line">/dev/vda1 on /boot type xfs (rw,relatime,attr2,inode64,noquota)</span><br><span class="line">tmpfs on /run/user/0 type tmpfs (rw,nosuid,nodev,relatime,size=800956k,mode=700)</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>There are 3 key fields:</p>
<ul>
<li>The filesystem’s device, such as a disk partition; where the actual file-system data resides</li>
<li>The filesystem type</li>
<li>The mount point—that is, the place in the current system’s directory hierarchy where the filesystem will be attached. </li>
</ul>
<p>For example, to mount the Fourth Extended filesystem /dev/sdf2 on /home/extra, use this command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount -t ext4 /dev/sdf2 /home/extra</span><br></pre></td></tr></table></figure></p>
<p>To unmount (detach) a filesystem, use the umount command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">umount mountpoint</span><br></pre></td></tr></table></figure></p>
<h4 id="Filesystem-UUID"><a href="#Filesystem-UUID" class="headerlink" title="Filesystem UUID"></a>Filesystem UUID</h4><p>You can identify and mount filesystems by their <code>Universally Unique Identifier (UUID)</code>, a software standard. The UUID is a type of serial number, and each one should be different.</p>
<p>For example, if you know the UUID of /dev/sdf2 is a9011c2b-1c03-4288-b3fe-8ba961ab0898, so you can mount it as:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount UUID=a9011c2b-1c03-4288-b3fe-8ba961ab0898 /home/extra</span><br></pre></td></tr></table></figure></p>
<p>Here no <code>-t  ext4</code> option, because mount know that.</p>
<p>To view a list of devices and the corresponding filesystems and UUIDs on your system, use the blkid (block ID) program:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">blkid</span><br><span class="line"></span><br><span class="line">/dev/sdf2: UUID=&quot;a9011c2b-1c03-4288-b3fe-8ba961ab0898&quot; TYPE=&quot;ext4&quot;</span><br><span class="line">/dev/sda1: UUID=&quot;70ccd6e7-6ae6-44f6-812c-51aab8036d29&quot; TYPE=&quot;ext4&quot;</span><br><span class="line">/dev/sda5: UUID=&quot;592dcfd1-58da-4769-9ea8-5f412a896980&quot; TYPE=&quot;swap&quot;</span><br><span class="line">/dev/sde1: SEC_TYPE=&quot;msdos&quot; UUID=&quot;3762-6138&quot; TYPE=&quot;vfat&quot;</span><br></pre></td></tr></table></figure></p>
<p>For one thing, they’re the preferred way to automatically mount filesystems in <code>/etc/fstab</code> at boot time.</p>
<h4 id="Disk-Buffering-Caching-and-Filesystems"><a href="#Disk-Buffering-Caching-and-Filesystems" class="headerlink" title="Disk Buffering, Caching, and Filesystems"></a>Disk Buffering, Caching, and Filesystems</h4><p>Linux, like other versions of Unix, buffers writes to the disk. This means that the kernel usually doesn’t immediately write changes to filesystems when processes request changes. <strong>Instead it stores the changes in RAM until the kernel can conveniently make the actual change to the disk</strong>. This buffering system is transparent to the user and improves performance.</p>
<blockquote>
<p>This is the reason why before we remove the USB, we need to unmount it in case of data lose.</p>
</blockquote>
<p>When you unmount a filesystem with umount, the kernel automatically synchronizes with the disk. At any other time, you can force the kernel to write the changes in its buffer to the disk by running the <code>sync</code> command.</p>
<h4 id="The-etc-fstab-Filesystem-Table"><a href="#The-etc-fstab-Filesystem-Table" class="headerlink" title="The /etc/fstab Filesystem Table"></a>The /etc/fstab Filesystem Table</h4><p>I encounter this when write <code>/etc/fstab</code> file with NFS when developing k8s.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/dev/mapper/rhel-root   /                       xfs     defaults        0 0</span><br><span class="line">UUID=a44461e9-e1d7-45fd-a387-255fafd14746 /boot                   xfs     defaults        0 0</span><br><span class="line">/dev/mapper/rhel-swap   swap                    swap    defaults        0 0</span><br><span class="line">halos1.fyre.ibm.com:/data /mnt nfs defaults,timeo=10,retrans=3,rsize=1048576,wsize=1048576 0 0</span><br></pre></td></tr></table></figure></p>
<p>To mount filesystems at boot time and take the drudgery out of the mount command, Linux systems keep a permanent list of filesystems and options in <code>/etc/fstab</code>.</p>
<ul>
<li><p><code>The device or UUID</code>. Most current Linux systems no longer use the device in /etc/fstab, preferring the UUID. </p>
</li>
<li><p><code>The mount point</code>. Indicates where to attach the filesystem.</p>
</li>
<li><p><code>The filesystem type</code>.</p>
</li>
<li><p><code>Options</code>. Use long mount options separated by commas.</p>
</li>
<li><p><code>Backup information for use by the dump command</code>. You should always use a 0 in this field.</p>
</li>
<li><p><code>The filesystem integrity test order.</code> To ensure that fsck always runs on the root first, always set this to 1 for the root filesystem and 2 for any other filesystems on a hard disk. Use <code>0</code> to disable the bootup check for everything else, including CD-ROM drives, swap, and the /proc file-system</p>
</li>
</ul>
<p>You can also try to mount all entries at once in /etc/fstab that do not contain the noauto option with this command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mount -a</span><br></pre></td></tr></table></figure></p>
<p>Let’s see some commonly use options:</p>
<ul>
<li><p><code>defaults</code>. This uses the mount defaults: read-write mode, enable device files, executables, the setuid bit, and so on. Use this when you don’t want to give the filesystem any special options but you do want to fill all fields in /etc/fstab.</p>
</li>
<li><p><code>noauto</code>. This option tells a mount -a command to ignore the entry. </p>
</li>
</ul>
<h4 id="Filesystem-Capacity"><a href="#Filesystem-Capacity" class="headerlink" title="Filesystem Capacity"></a>Filesystem Capacity</h4><p>To view the size and utilization of your currently mounted filesystems, use the <code>df</code> command.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">df -BM</span><br><span class="line"></span><br><span class="line">Filesystem                1M-blocks   Used Available Use% Mounted on</span><br><span class="line">/dev/mapper/rhel-root       245640M 75636M   170005M  31% /</span><br><span class="line">devtmpfs                      7931M     0M     7931M   0% /dev</span><br><span class="line">tmpfs                         7943M     0M     7943M   0% /dev/shm</span><br><span class="line">tmpfs                         7943M   835M     7109M  11% /run</span><br><span class="line">tmpfs                         7943M     0M     7943M   0% /sys/fs/cgroup</span><br><span class="line">/dev/vda1                     1014M   183M      832M  19% /boot</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h4 id="Checking-and-Repairing-Filesystems"><a href="#Checking-and-Repairing-Filesystems" class="headerlink" title="Checking and Repairing Filesystems"></a>Checking and Repairing Filesystems</h4><p>Filesystem errors are usually due to a user shutting down the system in a rude way (for example, by pulling out the power cord). In such cases, the filesystem cache in memory may not match the data on the disk, and the system also may be in the process of altering the filesystem when you happen to give the computer a kick. Although a new generation of filesystems supports journals to make filesystem corruption far less common, you should always shut the system down properly. And regardless of the filesystem in use, filesystem checks are still necessary every now and to maintain sanity.</p>
<p>The tool to check a filesystem is <code>fsck</code>.</p>
<p>In the worst cases, you can try:</p>
<ul>
<li><p>You can try to extract the entire filesystem image from the disk with <code>dd</code> and transfer it to a partition on another disk of the same size.</p>
</li>
<li><p>You can try to patch the filesystem as much as possible, mount it in read-only mode, and salvage what you can.</p>
</li>
<li><p>You can try <code>debugfs</code>.</p>
</li>
</ul>
<h4 id="Special-Purpose-Filesystems"><a href="#Special-Purpose-Filesystems" class="headerlink" title="Special-Purpose Filesystems"></a>Special-Purpose Filesystems</h4><p>Not all filesystems represent storage on physical media. Specifically, most versions of Unix have filesystems that serve as system interfaces. That is, rather than serving only as a means to store data on a device, a filesystem can represent system information such as process IDs and kernel diagnostics.</p>
<p>The special filesystem types in common use on Linux include the following:</p>
<ul>
<li><p><code>proc</code>. Mounted on /proc. The name proc is actually an abbreviation for process. Each numbered directory inside /proc is actually the process ID of a current process on the system; the files in those directories represent various aspects of the processes. The file /proc/self represents the current process. </p>
</li>
<li><p><code>sysfs</code>. Mounted on /sys.</p>
</li>
<li><p><code>tmpfs</code>. Mounted on /run and other locations. With tmpfs, you can use your physical memory and swap space as temporary storage, stored in volatile memory instead of a persistent storage device.</p>
</li>
</ul>
<h3 id="Swap-Space"><a href="#Swap-Space" class="headerlink" title="Swap Space"></a>Swap Space</h3><p>Not every partition on a disk contains a filesystem. It’s also possible to augment the RAM on a machine with disk space. The disk area used to store memory pages is called <code>swap space</code> (or just swap for short).</p>
<p>you can use <code>free</code> command to see the swap usage:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">free -m</span><br><span class="line"></span><br><span class="line">              total        used        free      shared  buff/cache   available</span><br><span class="line">Mem:          32010       10894        3992        1605       17123       18811</span><br><span class="line">Swap:          8063          64        7999</span><br></pre></td></tr></table></figure></p>
<p>you can use a disk partition and a regular file as swap space, for disk:</p>
<ol>
<li>Ensure partition is empty</li>
<li>Run <code>mkswap dev</code>, dev is the partition device</li>
<li>Execute <code>swapon dev</code> to register the space with the kernel.</li>
<li>Register in <code>/etc/fstab</code> file</li>
</ol>
<p>Use these commands to create an empty file, initialize it as swap, and add it to the swap pool:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dd if=/dev/zero of=swap_file bs=1024k count=num_mb</span><br><span class="line">mkswap swap_file</span><br><span class="line">swapon swap_file</span><br></pre></td></tr></table></figure></p>
<p>Here, <code>swap_file</code> is the name of the new swap file, and <code>num_mb</code> is the desired size, in megabytes.</p>
<p>To remove a swap partition or file from the kernel’s active pool, use the <code>swapoff</code> command.</p>
<p><strong>Note</strong> some administrators configure certain systems with <strong>no</strong> swap space at all. For example, high-performance network servers should never dip into swap space and should avoid disk access if at all possible.</p>
<p>It’s dangerous to do this on a general-purpose machine. If a machine completely runs out of both real memory and swap space, the Linux kernel invokes the <code>out-of-memory (OOM)</code> killer to kill a process in order to free up some memory. You obviously don’t want this to happen to your desktop applications. On the other hand, high-performance servers include sophisticated monitoring and load-balancing systems to ensure that they never reach the danger zone.</p>
<h3 id="Looking-Forward-Disks-and-User-Space"><a href="#Looking-Forward-Disks-and-User-Space" class="headerlink" title="Looking Forward: Disks and User Space"></a>Looking Forward: Disks and User Space</h3><p>In disk-related components on a Unix system, the boundaries between user space and the kernel can be difficult to characterize. As you’ve seen, the kernel handles raw block I/O from the devices, and user-space tools can use the block I/O through device files. However, user space typically uses the block I/O only for initializing operations such as partitioning, file-system creation, and swap space creation.</p>
<p>In normal use, user space uses only the filesystem support that the kernel provides on top of the block I/O.</p>
<h2 id="Chapter-5-How-the-Linux-Kernel-Boots"><a href="#Chapter-5-How-the-Linux-Kernel-Boots" class="headerlink" title="Chapter 5. How the Linux Kernel Boots"></a>Chapter 5. How the Linux Kernel Boots</h2><p>You’ll learn how the kernel moves into memory up to the point where the first user process starts.</p>
<p><strong>A simplified view of the boot process looks like this:</strong></p>
<ol>
<li>The machine’s BIOS or boot firmware loads and runs a boot loader.</li>
<li>The boot loader finds the kernel image on disk, loads it into memory, and starts it.</li>
<li>The kernel initializes the devices and its drivers.</li>
<li>The kernel mounts the root filesystem.</li>
<li>The kernel starts a program called init with a process ID of 1. This point is the user space start.</li>
<li>init sets the rest of the system processes in motion.</li>
<li>At some point, init starts a process allowing you to log in, usually at the end or near the end of the boot.</li>
</ol>
<h3 id="Startup-Messages"><a href="#Startup-Messages" class="headerlink" title="Startup Messages"></a>Startup Messages</h3><p>There are two ways to view the kernel’s boot and runtime diagnostic messages:</p>
<ul>
<li><p>Look at the kernel system log file. You’ll often find this in <code>/var/log/ kern.log</code>, but depending on how your system is configured, it might also be lumped together with a lot of other system logs in <code>/var/log/messages</code> or elsewhere.</p>
</li>
<li><p>Use the <code>dmesg</code> command, but be sure to pipe the output to less because there will be much more than a screen’s worth. The <code>dmesg</code> command uses the kernel ring buffer, which is of limited size, but most newer kernels have a large enough buffer to hold boot messages for a long time.</p>
</li>
</ul>
<h3 id="Kernel-Initialization-and-Boot-Options"><a href="#Kernel-Initialization-and-Boot-Options" class="headerlink" title="Kernel Initialization and Boot Options"></a>Kernel Initialization and Boot Options</h3><p>Upon startup, the Linux kernel initializes in this general order:</p>
<ol>
<li>CPU inspection</li>
<li>Memory inspection</li>
<li>Device bus discovery</li>
<li>Device discovery</li>
<li>Auxiliary kernel subsystem setup (networking, and so on)</li>
<li>Root filesystem mount</li>
<li>User space start</li>
</ol>
<p>The following memory management messages are a good indication that the user-space handoff is about to happen because this is where the kernel protects its own memory from user-space processes:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[    0.972934] Freeing unused kernel memory: 1844k freed</span><br><span class="line">[    0.973411] Write protecting the kernel read-only data: 12288k</span><br><span class="line">[    0.975623] Freeing unused kernel memory: 832k freed</span><br><span class="line">[    0.977405] Freeing unused kernel memory: 676k freed</span><br></pre></td></tr></table></figure></p>
<h3 id="Kernel-Parameters"><a href="#Kernel-Parameters" class="headerlink" title="Kernel Parameters"></a>Kernel Parameters</h3><p>I just encountered an issue about kernel parameters for Db2… Let’s see.</p>
<p>When running the Linux kernel, the boot loader passes in a set of text-based <strong>kernel parameters</strong> that tell the kernel how it should start. The parameters specify many different types of behavior, such as the amount of diagnostic output the kernel should produce and device driver–specific options.</p>
<p>You can view the kernel parameters from your system’s boot by looking at the <code>/proc/cmdline</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BOOT_IMAGE=/vmlinuz-3.10.0-862.14.4.el7.x86_64 root=/dev/mapper/rhel-root ro crashkernel=auto rd.lvm.lv=rhel/root rd.lvm.lv=rhel/swap rhgb quiet elevator=noop LANG=en_US.UTF-8</span><br></pre></td></tr></table></figure></p>
<p>The <code>root=/dev/mapper/rhel-root</code> is where root filesystem resides.</p>
<h3 id="Boot-Loader"><a href="#Boot-Loader" class="headerlink" title="Boot Loader"></a>Boot Loader</h3><p><a href="https://searchdatacenter.techtarget.com/definition/boot-loader-boot-manager" target="_blank" rel="noopener">Other boot loader intro</a></p>
<p>At the start of the boot process, before the kernel and init start, a boot loader starts the kernel. The task of a boot loader sounds simple: It loads the kernel into memory, and then starts the kernel with a set of kernel parameters.</p>
<p>Kernel and its parameters are usually somewhere on the root filesystem.</p>
<p>On PCs, boot loaders use the <code>Basic Input/Output System (BIOS)</code> or <code>Unified Extensible Firmware Interface (UEFI)</code> to access disks. Nearly all disk hardware has firmware that allows the BIOS to access attached storage hardware with <code>Linear Block Addressing (LBA)</code>. Although it exhibits poor performance, this mode of access does allow universal access to disks. Boot loaders are often the only programs to use the BIOS for disk access; the kernel uses its own high-performance drivers.</p>
<p>Most modern boot loaders can read partition tables and have built-in support for read-only access to filesystems. </p>
<h4 id="Boot-loader-tasks"><a href="#Boot-loader-tasks" class="headerlink" title="Boot loader tasks"></a>Boot loader tasks</h4><ol>
<li>Select among multiple kernels.</li>
<li>Switch between sets of kernel parameters.</li>
<li>Allow the user to manually override and edit kernel image names and parameters </li>
<li>Provide support for booting other operating systems.</li>
</ol>
<h4 id="Boot-loader-typres"><a href="#Boot-loader-typres" class="headerlink" title="Boot loader typres"></a>Boot loader typres</h4><ul>
<li>GRUB. A near-universal standard on Linux systems (mainly talks about this)</li>
<li>LILO. One of the first Linux boot loaders.</li>
<li>LOADLIN. Boots a kernel from MS-DOS</li>
</ul>
<h3 id="GRUB-Introduction"><a href="#GRUB-Introduction" class="headerlink" title="GRUB Introduction"></a>GRUB Introduction</h3><p>GRUB stands for Grand Unified Boot Loader. We’ll cover GRUB 2.</p>
<p>This section talks about GRUB menu and look into some boot options, actually, if you check <code>/boot</code> directory, you will see kernel image file and initial RAM filesystem:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">-rwxr-xr-x. 1 root root  6381872 Mar 21  2018 vmlinuz-3.10.0-862.el7.x86_64</span><br><span class="line">-rw-r--r--. 1 root root   304926 Mar 21  2018 symvers-3.10.0-862.el7.x86_64.gz</span><br><span class="line">drwx------. 5 root root       97 Oct  1  2018 grub2</span><br><span class="line">-rw-------  1 root root 21096334 Oct  1  2018 initramfs-3.10.0-862.9.1.el7.x86_64.img</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>Not interested in the rest of the content in this chapter.</p>
<h2 id="Chapter-6-How-User-Space-Starts"><a href="#Chapter-6-How-User-Space-Starts" class="headerlink" title="Chapter 6. How User Space Starts"></a>Chapter 6. How User Space Starts</h2><p>The point where the kernel starts its first user-space process, init, is significant—not just because that’s where the memory and CPU are finally ready for normal system operation, but because that’s where you can see how the rest of the system builds up as a whole. </p>
<p>User space is far more modular. It’s much easier to see what goes into the user space startup and operation.</p>
<p>User space starts in roughly this order:</p>
<ol>
<li>init</li>
<li>Essential low-level services such as udevd and syslogd</li>
<li>Network configuration</li>
<li>Mid- and high-level services (cron, printing, and so on)</li>
<li>Login prompts, GUIs, and other high-level applications</li>
</ol>
<h3 id="Introduction-to-init"><a href="#Introduction-to-init" class="headerlink" title="Introduction to init"></a>Introduction to init</h3><p><a href="https://en.wikipedia.org/wiki/Init" target="_blank" rel="noopener">wiki init</a></p>
<p>The init program is a <strong>user-space program</strong> like any other program on the Linux system, and you’ll find it in <code>/sbin</code> along with many of the other system binaries. Its main purpose is to start and stop the essential service processes on the system, but newer versions have more responsibilities.</p>
<p>In my vm <code>/sbin</code> directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lrwxrwxrwx  1 root root          22 Oct  1  2018 init -&gt; ../lib/systemd/systemd</span><br></pre></td></tr></table></figure></p>
<p>There are three major implementations of init in Linux distributions:</p>
<ul>
<li><code>System V</code> init. A traditional sequenced init (Sys V, usually <em>pronounced “sys-five”</em>). Red Hat Enterprise Linux and several other distributions use this version.</li>
<li><code>systemd</code>. The emerging standard for init. Many distributions have moved to systemd, and most that have not yet done so are planning to move to it.</li>
<li><code>Upstart</code>. The init on Ubuntu installations. However, as of this writing, Ubuntu has also planned to migrate to systemd.</li>
</ul>
<p>There are many different implementations of init because <code>System V</code> init and other older versions relied on a sequence that performed only one startup task at a time. <code>systemd</code> and <code>Upstart</code> attempt to remedy the performance issue by allowing many services to start in parallel thereby speeding up the boot process. </p>
<h3 id="System-V-Runlevels"><a href="#System-V-Runlevels" class="headerlink" title="System V Runlevels"></a>System V Runlevels</h3><p><a href="https://en.wikipedia.org/wiki/Runlevel" target="_blank" rel="noopener">wiki Runlevel</a></p>
<p>At any given time on a Linux system, a certain base set of processes is running. In System V init, this state of the machine is called its <code>runlevel</code>, which is denoted by a number from 0 through 6. A system spends most of its time in a single runlevel, but when you shut the machine down, init switches to a different runlevel in order to terminate the system services in an orderly fashion and to tell the kernel to stop.</p>
<p>You can check your system’s runlevel with the <code>who -r</code> command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">who -r</span><br><span class="line"></span><br><span class="line">run-level 3  2019-04-17 13:49</span><br></pre></td></tr></table></figure></p>
<p>Runlevels serve various purposes, but the most common one is to distinguish between system startup, shutdown, single-user mode, and console mode states.</p>
<p>But runlevels are becoming a thing of the past. Even though all three init versions in this book support them, systemd and Upstart consider runlevels obsolete as end states for the system. </p>
<h3 id="Identifying-Your-init"><a href="#Identifying-Your-init" class="headerlink" title="Identifying Your init"></a>Identifying Your init</h3><ul>
<li><p>If your system has /usr/lib/systemd and /etc/systemd directories, you have systemd.</p>
</li>
<li><p>If you have an /etc/init directory that contains several .conf files, you’re probably running Upstart </p>
</li>
<li><p>If neither of the above is true, but you have an /etc/inittab file, you’re probably running System V init.</p>
</li>
</ul>
<p><strong>Here I focus on systemd</strong></p>
<h3 id="systemd"><a href="#systemd" class="headerlink" title="systemd"></a>systemd</h3><p>The systemd init is one of the newest init implementations on Linux. In addition to handling the regular boot process, systemd aims to incorporate a number of standard Unix services such as cron and inetd. One of its most significant features is its ability to defer the start of services and operating system features until they are necessary.</p>
<p>Let’s outline what happens when systemd runs at boot time:</p>
<ol>
<li>systemd loads its configuration.</li>
<li>systemd determines its boot goal, which is usually named default.target.</li>
<li>systemd determines all of the dependencies of the default boot goal, dependencies of these dependencies, and so on.</li>
<li>systemd activates the dependencies and the boot goal.</li>
<li>After boot, systemd can react to system events (such as uevents) and activate additional components.</li>
</ol>
<h4 id="Units-and-Unit-Types"><a href="#Units-and-Unit-Types" class="headerlink" title="Units and Unit Types"></a>Units and Unit Types</h4><p>One of the most interesting things about <code>systemd</code> is that it does not just operate processes and services; it can also mount filesystems, monitor network sockets, run timers, and more. Each type of capability is called a <code>unit type</code>, and each specific capability is called a <code>unit</code>. When you turn on a unit, you activate it.</p>
<p>The default boot goal is usually a <code>target unit</code> that groups together a number of <code>service</code> and <code>mount</code> units as dependencies. </p>
<p><a href="https://www.digitalocean.com/community/tutorials/understanding-systemd-units-and-unit-files" target="_blank" rel="noopener">understand systemd unit and unit files</a></p>
<h4 id="systemd-Dependencies"><a href="#systemd-Dependencies" class="headerlink" title="systemd Dependencies"></a>systemd Dependencies</h4><p>To accommodate the need for flexibility and fault tolerance, systemd offers a myriad of dependency types and styles:</p>
<ul>
<li><p><code>Requires</code> Strict dependencies. When activating a unit with a Requires dependency unit, systemd attempts to activate the dependency unit. If the dependency unit fails, systemd deactivates the dependent unit.</p>
</li>
<li><p><code>Wants</code>. Dependencies for activation only. Upon activating a unit, systemd activates the unit’s Wants dependencies, but it doesn’t care if those dependencies fail.</p>
</li>
<li><p><code>Requisite</code>. Units that must already be active.</p>
</li>
<li><p><code>Conflicts</code>. Negative dependencies. When activating a unit with a Conflict dependency, systemd automatically deactivates the dependency if it is active.</p>
</li>
</ul>
<p>There are many other dependency syntax, like ordering, conditional, etc…</p>
<h4 id="systemd-Configuration"><a href="#systemd-Configuration" class="headerlink" title="systemd Configuration"></a>systemd Configuration</h4><p>The systemd configuration files are spread among many directories across the system, so you typically won’t find the files for all of the units on a system in one place.</p>
<p>That said, there are two main directories for systemd configuration: the system unit directory (globally configured, usually <code>/usr/lib/systemd/system</code>) and a system configuration directory (local definitions, usually <code>/etc/systemd/system</code>).</p>
<blockquote>
<p>Note: Avoid making changes to the system unit directory because your distribution will maintain it for you. Make your local changes to the system configuration directory.</p>
</blockquote>
<p>To see the system unit and configuration directories on your system, use the following commands:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pkg-config systemd --variable=systemdsystemunitdir</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pkg-config systemd --variable=systemdsystemconfdir</span><br></pre></td></tr></table></figure>
<p>Let’s see Unit files in <code>/usr/lib/systemd/system</code>, there is a sshd.service file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=OpenSSH server daemon</span><br><span class="line">Documentation=man:sshd(8) man:sshd_config(5)</span><br><span class="line">After=network.target sshd-keygen.service</span><br><span class="line">Wants=sshd-keygen.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">EnvironmentFile=/etc/sysconfig/sshd</span><br><span class="line">ExecStart=/usr/sbin/sshd -D $OPTIONS</span><br><span class="line">ExecReload=/bin/kill -HUP $MAINPID</span><br><span class="line">KillMode=process</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=42s</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure></p>
<p>The [Unit] section gives some details about the unit and contains description and dependency information. </p>
<p>You’ll find the details about the service in the [Service] section, including how to prepare, start, and reload the service. </p>
<p>During normal operation, systemd ignores the [Install] section. However, consider the case when sshd.service is disabled on your system and you would like to turn it on. When you enable a unit, systemd reads the [Install] section.</p>
<p>The [Install] section is usually responsible for the the .wants and .requires directories in the system configuration directory (<code>/etc/systemd/system</code>), see:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">basic.target.wants                                       getty.target.wants           remote-fs.target.wants</span><br><span class="line">default.target                                           local-fs.target.wants        sockets.target.wants</span><br><span class="line">default.target.wants                                     multi-user.target.wants      sysinit.target.wants</span><br><span class="line">dev-virtio\x2dports-org.qemu.guest_agent.0.device.wants  network-online.target.wants  system-update.target.wants</span><br></pre></td></tr></table></figure></p>
<p>the  $OPTIONS in unit file is the variable, also specifier is another variable-like feature often found in unit files, like %n and %H.</p>
<h3 id="systemd-Operation"><a href="#systemd-Operation" class="headerlink" title="systemd Operation"></a>systemd Operation</h3><p>You’ll interact with systemd primarily through the <code>systemctl</code> command, which allows you to activate and deactivate services, list status, reload the configuration, and much more.</p>
<p>List of active units:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl</span><br><span class="line"></span><br><span class="line">  UNIT                                           LOAD   ACTIVE SUB       DESCRIPTION</span><br><span class="line">...</span><br><span class="line">  sys-kernel-debug.mount                         loaded active mounted   Debug File System</span><br><span class="line">  var-lib-nfs-rpc_pipefs.mount                   loaded active mounted   RPC Pipe File System</span><br><span class="line">  brandbot.path                                  loaded active waiting   Flexible branding</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>List all units, includes inactives:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl --all</span><br></pre></td></tr></table></figure></p>
<p>Get status of a unit:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl status sshd.service</span><br></pre></td></tr></table></figure></p>
<p>To activate, deactivate, and restart units, use the systemd <code>start</code>, <code>stop</code>, and <code>restart</code> commands. However, if you’ve changed a unit configuration file, you can tell systemd to reload the file in one of two ways:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl reload unit #Reloads just the configuration for unit.</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload #Reloads all unit configurations.</span><br></pre></td></tr></table></figure>
<h4 id="systemd-Process-Tracking-and-Synchronization"><a href="#systemd-Process-Tracking-and-Synchronization" class="headerlink" title="systemd Process Tracking and Synchronization"></a>systemd Process Tracking and Synchronization</h4><p>systemd wants a reasonable amount of information and control over every process that it starts. The main problem that it faces is that a service can start in different ways; it may fork new instances of itself or even daemonize and detach itself from the original process.</p>
<p>To minimize the work that a package developer or administrator needs to do in order to create a working unit file, systemd uses <code>control groups (cgroups)</code>, an optional Linux kernel feature that allows for finer tracking of a process hierarchy.</p>
<h4 id="systemd-On-Demand-and-Resource-Parallelized-Startup"><a href="#systemd-On-Demand-and-Resource-Parallelized-Startup" class="headerlink" title="systemd On-Demand and Resource-Parallelized Startup"></a>systemd On-Demand and Resource-Parallelized Startup</h4><p>One of systemd’s most significant features is its ability to delay a unit startup until it is absolutely needed. </p>
<h4 id="systemd-Auxiliary-Programs"><a href="#systemd-Auxiliary-Programs" class="headerlink" title="systemd Auxiliary Programs"></a>systemd Auxiliary Programs</h4><p>When starting out with systemd, you may notice the exceptionally large number of programs in <code>/lib/systemd</code>. These are primarily support programs for units. For example, <code>udevd</code> is part of systemd, and you’ll find it there as <code>systemd-udevd</code>. Another, the <code>systemd-fsck</code> program, works as a middleman between systemd and fsck.</p>
<h3 id="Shutting-Down-Your-System"><a href="#Shutting-Down-Your-System" class="headerlink" title="Shutting Down Your System"></a>Shutting Down Your System</h3><p>init controls how the system shuts down and reboots. The commands to shut down the system are the same regardless of which version of init you run. The proper way to shut down a Linux machine is to use the <code>shutdown</code> command.</p>
<p>to shutdown machine immediately:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">shutdown -h now</span><br></pre></td></tr></table></figure></p>
<p>to reboot the machine now:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">shutdown -r now</span><br></pre></td></tr></table></figure></p>
<p>When system shutdown time finally arrives, shutdown tells init to begin the shutdown process. On systemd, it means activating the shutdown units; and on System V init, it means changing the runlevel to 0 or 6.</p>
<h3 id="The-Initial-RAM-Filesystem"><a href="#The-Initial-RAM-Filesystem" class="headerlink" title="The Initial RAM Filesystem"></a>The Initial RAM Filesystem</h3><p>The <code>initramfs</code> is in <code>/boot</code> directory.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ls -ltr | grep init</span><br><span class="line"></span><br><span class="line">-rw-------. 1 root root 55376391 Apr 13  2018 initramfs-0-rescue-e57cfe9136e9430587366e04f14195e1.img</span><br><span class="line">-rw-------. 1 root root 13131435 Apr 13  2018 initramfs-3.10.0-862.el7.x86_64kdump.img</span><br><span class="line">-rw-------  1 root root 21098233 Jul 23  2018 initramfs-3.10.0-862.el7.x86_64.img</span><br><span class="line">-rw-------  1 root root 21134858 Oct  1  2018 initramfs-3.10.0-862.14.4.el7.x86_64.img</span><br><span class="line">-rw-------  1 root root 21096334 Oct  1  2018 initramfs-3.10.0-862.9.1.el7.x86_64.img</span><br></pre></td></tr></table></figure></p>
<p>The problem stems from the availability of many different kinds of storage hardware. Remember, the Linux kernel does not talk to the PC BIOS or EFI interfaces to get data from disks, so in order to mount its root file-system, it needs driver support for the underlying storage mechanism.</p>
<p>The workaround is to gather a small collection of kernel driver modules along with a few other utilities into an archive. The boot loader loads this archive into memory before running the kernel.</p>
<h2 id="Chapter-7-System-Configuration"><a href="#Chapter-7-System-Configuration" class="headerlink" title="Chapter 7. System Configuration"></a>Chapter 7. System Configuration</h2><p>When you first look in the <code>/etc</code> directory, you might feel a bit overwhelmed. Although most of the files that you see affect a system’s operations to some extent, a few are fundamental.</p>
<h3 id="The-Structure-of-etc"><a href="#The-Structure-of-etc" class="headerlink" title="The Structure of /etc"></a>The Structure of /etc</h3><p>Most system configuration files on a Linux system are found in <code>/etc</code>. Historically, each program had one or more configuration files there, and because there are so many packages on a Unix system, /etc would accumulate files quickly.</p>
<p>The trend for many years now has been to place system configuration files into subdirectories under <code>/etc</code>. There are still a few individual configuration files in /etc, but for the most part, if you run <code>ls -F /etc</code>, you’ll see that most of the items there are now subdirectories.</p>
<p>What kind of configuration files are found in <code>/etc</code>? The basic guideline is that customizable configurations for a single machine. And you’ll often find that noncustomizable system configuration files may be found elsewhere, as with the prepackaged systemd unit files in <code>/usr/lib/systemd</code>.</p>
<h3 id="System-Logging"><a href="#System-Logging" class="headerlink" title="System Logging"></a>System Logging</h3><p>Most system programs write their diagnostic output to the <code>syslog</code> service. The traditional syslogd daemon waits for messages and, depending on the type of message received, funnels the output to a file, the screen, users, or some combination of these, or just ignores it.</p>
<h4 id="The-System-Logger"><a href="#The-System-Logger" class="headerlink" title="The System Logger"></a>The System Logger</h4><p>Most Linux distributions run a new version of syslogd called <code>rsyslogd</code> that does much more than simply write log messages to files. For example, in my vm:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl status rsyslog</span><br><span class="line"></span><br><span class="line">   rsyslog.service - System Logging Service</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/rsyslog.service; enabled; vendor preset: enabled)</span><br><span class="line">   Active: active (running) since Wed 2019-04-17 13:49:14 PDT; 2 weeks 6 days ago</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>Many of the files in <code>/var/log</code> aren’t maintained by the system logger. The only way to know for sure which ones belong to rsyslogd is to look at its configuration file.</p>
<h4 id="Configuration-Files"><a href="#Configuration-Files" class="headerlink" title="Configuration Files"></a>Configuration Files</h4><p>The base rsyslogd configuration file is <code>/etc/rsyslog.conf</code>, but you’ll find certain configurations in other directories, such as <code>/etc/rsyslog.d</code>.</p>
<p>It talks about the syntax in the configuration file:<br>The configuration format is a blend of traditional rules and <code>rsyslog-specific</code> extensions. One rule of thumb is that anything beginning with a dollar sign ($) is an extension.</p>
<h3 id="User-Management-Files"><a href="#User-Management-Files" class="headerlink" title="User Management Files"></a>User Management Files</h3><p>Unix systems allow for multiple independent users. At the kernel level, users are simply numbers (user IDs).</p>
<h4 id="The-etc-passwd-File"><a href="#The-etc-passwd-File" class="headerlink" title="The /etc/passwd File"></a>The /etc/passwd File</h4><p>The plaintext file /etc/passwd maps usernames to user IDs.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root:x:0:0:Superuser:/root:/bin/sh</span><br><span class="line">######</span><br><span class="line">daemon:*:1:1:daemon:/usr/sbin:/bin/sh</span><br><span class="line">#or</span><br><span class="line">daemon:x:2:2:daemon:/sbin:/sbin/nologin</span><br><span class="line">######</span><br><span class="line">bin:*:2:2:bin:/bin:/bin/sh</span><br><span class="line">sys:*:3:3:sys:/dev:/bin/sh</span><br><span class="line">nobody:*:65534:65534:nobody:/home:/bin/false</span><br><span class="line">juser:x:3119:1000:J. Random User:/home/juser:/bin/bash</span><br><span class="line">beazley:x:143:1000:David Beazley:/home/beazley:/bin/bash</span><br></pre></td></tr></table></figure></p>
<p>The fields are as follows:</p>
<ul>
<li><p>The username.</p>
</li>
<li><p>The user’s encrypted password. On most Linux systems, the password is not actually stored in the <code>passwd</code> file, but rather, in the <code>shadow</code> file . Normal users do not have read permission for shadow. The second field in <code>passwd</code> or <code>shadow</code> is the encrypted password, Unix passwords are never stored as clear text.</p>
</li>
<li><p>An <code>x</code> in the second passwd file field indicates that the encrypted password is stored in the <code>shadow</code> file. A <code>*</code> indicates that the user cannot log in, and if the field is blank (that is, you see two colons in a row, like ::), no password is required to log in. (Beware of blank passwords. You should never have a user without a password.)</p>
</li>
<li><p>The user ID (UID), which is the user’s representation in the kernel.</p>
</li>
<li><p>The group ID (GID). This should be one of the numbered entries in the <code>/etc/group</code> file. Groups determine file permissions and little else. This group is also called the user’s <code>primary</code> group.</p>
</li>
<li><p>The user’s real name. You’ll sometimes find commas in this field, denoting room and telephone numbers.</p>
</li>
<li><p>The user’s home directory.</p>
</li>
<li><p>The user’s shell (the program that runs when the user runs a terminal session).</p>
</li>
</ul>
<h4 id="Special-Users"><a href="#Special-Users" class="headerlink" title="Special Users"></a>Special Users</h4><p>The superuser (root) always has UID 0 and GID 0. Some users, such as daemon, have no login privileges. The nobody user is an underprivileged user. Some processes run as nobody because the nobody user cannot write to anything on the system.</p>
<p>The users that cannot log in are called <code>pseudo-users</code>. Although they can’t log in, the system can start processes with their user IDs. Pseudo-users such as nobody are usually created for security reasons.</p>
<h4 id="The-etc-shadow-File"><a href="#The-etc-shadow-File" class="headerlink" title="The /etc/shadow File"></a>The /etc/shadow File</h4><p>The shadow password file <code>/etc/shadow</code> on a Linux system normally contains user authentication information, including the encrypted passwords and password expiration information that correspond to the users in <code>/etc/passwd</code>.</p>
<p>Regular users interact with <code>/etc/passwd</code> using the <code>passwd</code> command. By default, <code>passwd</code> changes the user’s password. The <code>passwd</code> command is an <code>suid-root</code> program, because only the superuser can change the <code>/etc/passwd</code> file.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rwsr-xr-x. 1 root root 27832 Jan 29  2014 /usr/bin/passwd</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>in <code>/etc/shells</code> file have multiple shell types:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; /bin/sh</span><br><span class="line">&gt; /bin/bash</span><br><span class="line">&gt; /sbin/nologin</span><br><span class="line">&gt; /usr/bin/sh</span><br><span class="line">&gt; /usr/bin/bash</span><br><span class="line">&gt; /usr/sbin/nologin</span><br><span class="line">&gt; /bin/ksh</span><br><span class="line">&gt; /bin/rksh</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p>Because /etc/passwd is plaintext, the superuser may use any text editor to make changes. To add a user, simply add an appropriate line and create a home directory for the user; to delete, do the opposite. However, to edit the file, you’ll most likely want to use the <code>vipw</code> program</p>
<p>Use <code>adduser</code> and <code>userde</code>l to add and remove users. Run <code>passwd user</code> as the superuser.</p>
<h4 id="Working-with-Groups"><a href="#Working-with-Groups" class="headerlink" title="Working with Groups"></a>Working with Groups</h4><p>Groups in Unix offer a way to <strong>share</strong> files with certain users but deny access to all others. The idea is that you can set read or write permission bits for a particular group, excluding everyone else.</p>
<p>The <code>/etc/group</code> file defines the group IDs:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root:*:0:juser</span><br><span class="line">daemon:*:1:</span><br><span class="line">bin:*:2:</span><br><span class="line">disk:*:6:juser,beazley</span><br><span class="line">nogroup:*:65534:</span><br><span class="line">user:*:1000:</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>The group name.</p>
</li>
<li><p>The group password. This is hardly ever used, nor should you use it. Use * or any other default value.</p>
</li>
<li><p>The group ID (a number). The GID must be unique within the group file. This number goes into a user’s group field in that user’s <code>/etc/passwd</code> entry.</p>
</li>
<li><p>An optional list of users that belong to the group. In addition to the users listed here, users with the corresponding group ID in their passwd file entries also belong to the group.</p>
</li>
</ul>
<blockquote>
<p>Linux distributions often create a new group for each new user added, with the same name as the user.</p>
</blockquote>
<h3 id="Setting-the-Time"><a href="#Setting-the-Time" class="headerlink" title="Setting the Time"></a>Setting the Time</h3><p>Unix machines depend on accurate timekeeping. The kernel maintains the system clock, which is the clock that is consulted when you run commands like date.</p>
<p>PC hardware has a battery-backed <code>real-time clock (RTC)</code>. The RTC isn’t the best clock in the world, but it’s better than nothing. The kernel usually sets its time based on the RTC at boot time, and you can reset the system clock to the current hardware time with <code>hwclock</code>.</p>
<p>You should not try to fix the time drift with <code>hwclock</code> because time-based system events can get lost or mangled. Usually it’s best to keep your system time correct with a network time daemon.</p>
<h4 id="Network-Time"><a href="#Network-Time" class="headerlink" title="Network Time"></a>Network Time</h4><p>If your machine is permanently connected to the Internet, you can run a <code>Network Time Protocol (NTP)</code> daemon to maintain the time using a remote server. Many distributions have built-in support for an NTP daemon, but it may not be enabled by default. You might need to install an ntpd package to get it to work.</p>
<h3 id="Scheduling-Recurring-Tasks-with-cron"><a href="#Scheduling-Recurring-Tasks-with-cron" class="headerlink" title="Scheduling Recurring Tasks with cron"></a>Scheduling Recurring Tasks with cron</h3><p>The Unix cron service runs programs repeatedly on a fixed schedule. Most experienced administrators consider cron to be <strong>vital</strong> to the system because it can perform automatic system maintenance. For example, cron runs log file rotation utilities to ensure that your hard drive doesn’t fill up with old log files. You should know how to use cron because it’s just plain useful.</p>
<blockquote>
<p>Also see <code>cronjob</code> in k8s <a href="https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/" target="_blank" rel="noopener">doc</a>.</p>
</blockquote>
<p>You can run any program with <code>cron</code> at whatever times suit you. The program running through cron is called a <code>cron job</code>. To install a cron job, you’ll create an entry line in your <code>crontab</code> file, usually by running the <code>crontab</code> command.</p>
<p>for example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">15 09 * * * /home/juser/bin/spmake</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>Minute (0 through 59). The cron job above is set for minute 15.</p>
</li>
<li><p>Hour (0 through 23). The job above is set for the ninth hour.</p>
</li>
<li><p>Day of month (1 through 31).</p>
</li>
<li><p>Month (1 through 12).</p>
</li>
<li><p>Day of week (0 through 7). The numbers 0 and 7 are Sunday.</p>
</li>
</ul>
<p>A <code>*</code> in any field means to match every value. The preceding example runs spmake daily because the day of month, month, and day of week fields are all filled with stars, which cron reads as “run this job every day, of every month, of every week.”</p>
<p>also can be 5th and the 14th day of each month:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">15 09 5,14 * * /home/juser/bin/spmake</span><br></pre></td></tr></table></figure></p>
<h4 id="Installing-Crontab-Files"><a href="#Installing-Crontab-Files" class="headerlink" title="Installing Crontab Files"></a>Installing Crontab Files</h4><p>Each user can have his or her own crontab file, which means that every system may have multiple crontabs, usually found in <code>/var/spool/cron/</code> folder. the <code>crontab</code> command installs, lists, edits, and removes a user’s crontab.</p>
<p>The easiest way to install a crontab is to put your crontab entries into a file and then use <code>crontab file</code> to install file as your current crontab.</p>
<p>Actually, there is a default place for every user crontab file includes root. Once you create a crontab file for the user, the corresponding folder is put under /var/spool/cron/`.</p>
<p>For example, run as root, I want to set a recurring task for user <code>dsadm</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -u dsadm -e</span><br></pre></td></tr></table></figure></p>
<p>Then edit like this:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">00 21 * * * /home/dsadm/test.sh &gt; /tmp/cron-log 2&gt;&amp;1</span><br></pre></td></tr></table></figure></p>
<p>after run the job, go to <code>/tmp</code> folder you will see the log file.</p>
<p>to list the <code>dsadm</code> cron job:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -l -u dsadm</span><br></pre></td></tr></table></figure></p>
<p>to remove cron job for <code>dsadm</code><br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">crontab -r -u dsadm</span><br></pre></td></tr></table></figure></p>
<h4 id="System-Crontab-Files"><a href="#System-Crontab-Files" class="headerlink" title="System Crontab Files"></a>System Crontab Files</h4><p>Linux distributions normally have an <code>/etc/crontab</code> file. You can also edit here, but the format is a little bit difference:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Example of job definition:</span><br><span class="line"># .---------------- minute (0 - 59)</span><br><span class="line"># |  .------------- hour (0 - 23)</span><br><span class="line"># |  |  .---------- day of month (1 - 31)</span><br><span class="line"># |  |  |  .------- month (1 - 12) OR jan,feb,mar,apr ...</span><br><span class="line"># |  |  |  |  .---- day of week (0 - 6) (Sunday=0 or 7) OR sun,mon,tue,wed,thu,fri,sat</span><br><span class="line"># |  |  |  |  |</span><br><span class="line"># *  *  *  *  * user-name  command to be executed</span><br></pre></td></tr></table></figure></p>
<h3 id="Understanding-User-IDs-and-User-Switching"><a href="#Understanding-User-IDs-and-User-Switching" class="headerlink" title="Understanding User IDs and User Switching"></a>Understanding User IDs and User Switching</h3><p>We’ve discussed how <code>setuid</code> programs such as <code>sudo</code> and <code>su</code> allow you to change users:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---s--x--x 1 root root 143248 May 28  2018 /usr/bin/sudo</span><br><span class="line">-rwsr-xr-x 1 root root 32184 Jul 12  2018 /usr/bin/su</span><br></pre></td></tr></table></figure></p>
<p>In reality, every process has more than one user ID. When you run a setuid program, Linux sets the effective user ID to the program’s owner during execution, but it keeps your original user ID in the real user ID.</p>
<p>Think of the effective user ID as the actor and the real user ID as the owner. The real user ID defines the user that can interact with the running process—most significantly, which user can kill and send signals to a process. For example, if user A starts a new process that runs as user B (based on setuid permissions), user A still owns the process and can kill it.</p>
<p>On normal Linux systems, most processes have the <strong>same</strong> <code>effective user ID</code> and <code>real user ID</code>. I verify this by a test.sh script run as<code>dsadm</code>, the euser and ruser are the same:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-rwsr-xr-x 1 root  root        56 May 11 22:17 test.sh</span><br></pre></td></tr></table></figure></p>
<p>By default, <code>ps</code> and other system diagnostic programs show the <code>effective user ID</code>.</p>
<p>In conductor container, I run many su commands, you can see this, the euser and ruser are different:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps -eo pid,euser,ruser,comm</span><br><span class="line"></span><br><span class="line">1574 root     dsadm    su</span><br><span class="line">2735 root     dsadm    su</span><br><span class="line">4535 root     dsadm    su</span><br></pre></td></tr></table></figure></p>
<h3 id="PAM"><a href="#PAM" class="headerlink" title="PAM"></a>PAM</h3><p>In 1995 Sun Microsystems proposed a new standard called <code>Pluggable Authentication Modules (PAM)</code>, a system of shared libraries for authentication. To authenticate a user, an application hands the user to PAM to determine whether the user can successfully identify itself. </p>
<p>Because there are many kinds of authentication scenarios, PAM employs a number of dynamically <code>loadable authentication modules</code>. Each module performs a specific task; for example, the <code>pam_unix.so</code> module can check a user’s password.</p>
<h4 id="PAM-Configuration"><a href="#PAM-Configuration" class="headerlink" title="PAM Configuration"></a>PAM Configuration</h4><p>You’ll normally find PAM’s application configuration files in the <code>/etc/pam.d</code> directory (older systems may use a single <code>/etc/pam.conf</code> file). </p>
<p>Let’s see an example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auth       requisite     pam_shells.so</span><br></pre></td></tr></table></figure></p>
<p>Each configuration line has three fields: <code>function type</code>, <code>control argument</code>, and <code>module</code>:</p>
<ul>
<li><p>Function type. The function that a user application asks PAM to perform. Here, it’s <code>auth</code>, the task of authenticating the user.</p>
</li>
<li><p>Control argument. This setting controls what PAM does after success or failure of its action for the current line (<code>requisite</code> in this example).</p>
</li>
<li><p>Module. The authentication module that runs for this line, determining what the line actually does. Here, the <code>pam_shells.so</code> module checks to see whether the user’s current shell is listed in <code>/etc/shells</code>.</p>
</li>
</ul>
<p>PAM configuration is detailed on the pam.conf(5) manual page:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">man 5 pam.conf</span><br></pre></td></tr></table></figure></p>
<h2 id="Chapter-8-A-Closer-Look-at-Processes-and-Resource-Utilization"><a href="#Chapter-8-A-Closer-Look-at-Processes-and-Resource-Utilization" class="headerlink" title="Chapter 8. A Closer Look at Processes and Resource Utilization"></a>Chapter 8. A Closer Look at Processes and Resource Utilization</h2><p>This chapter takes you deeper into the relationships between processes, the kernel, and system resources.</p>
<p>Many of the tools that you see in this chapter are often thought of as performance-monitoring tools. They’re particularly helpful if your system is slowing to a crawl and you’re trying to figure out why.</p>
<h3 id="Tracking-Processes"><a href="#Tracking-Processes" class="headerlink" title="Tracking Processes"></a>Tracking Processes</h3><p>The <code>top</code> program is often more useful than <code>ps</code> because it displays the current system status as well as many of the fields in a <code>ps</code> listing, and it updates the display every second.</p>
<p>You can send commands to <code>top</code> with keystrokes. When you enter <code>top</code> command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Tasks: 382 total,   2 running, 380 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s):  1.2 us,  0.5 sy,  0.0 ni, 96.4 id,  0.4 wa,  0.0 hi,  0.2 si,  1.3 st</span><br><span class="line">KiB Mem :  8009536 total,   441360 free,   930236 used,  6637940 buff/cache</span><br><span class="line">KiB Swap:        0 total,        0 free,        0 used.  6284448 avail Mem</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line">10438 root      20   0  519148 282140  19392 S   4.6  3.5 586:19.28 kube-apiserver</span><br><span class="line">10449 root      20   0  275308  80184  14584 S   4.3  1.0 516:46.86 kube-controller</span><br><span class="line"> 9691 root      20   0 1648968 159104  30708 S   2.6  2.0 492:06.83 kubelet</span><br><span class="line">10206 root      20   0   10.1g  56568   7760 S   2.0  0.7 262:08.45 etcd</span><br><span class="line">19459 root      20   0   82100  53780   9392 S   1.7  0.7 209:35.52 calico-node</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note: if you want to see memory in MB, GB… Typing <code>shift + e</code> cycle through.</p>
</blockquote>
<p>then type followings:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Spacebar: Updates the display immediately.</span><br><span class="line">M: Sorts by current resident memory usage.</span><br><span class="line">T: Sorts by total (cumulative) CPU usage.</span><br><span class="line">P: Sorts by current CPU usage (the default).</span><br><span class="line">u: Displays only one user’s processes.</span><br><span class="line">f: Selects different statistics to display. (use arrow to move and space to select)</span><br><span class="line">?: Displays a usage summary for all top commands.</span><br></pre></td></tr></table></figure></p>
<h3 id="Finding-Open-Files-by-lsof"><a href="#Finding-Open-Files-by-lsof" class="headerlink" title="Finding Open Files by lsof"></a>Finding Open Files by lsof</h3><p>One use for this command is when a disk cannot be unmounted because (unspecified) files are in use. The listing of open files can be consulted (suitably filtered if necessary) to identify the process that is using the files.</p>
<p>The <code>lsof</code> command lists open files and the processes using them. <code>lsof</code> doesn’t stop at regular files—it can list network resources, dynamic libraries, pipes, and more.</p>
<p>For example:<br>Display entries for open files in <code>/usr</code> directory and successors.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lsof /usr/*</span><br></pre></td></tr></table></figure></p>
<p>List open files for a particular PID:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lsof -p 1623</span><br></pre></td></tr></table></figure></p>
<h3 id="Tracing-Program-Execution-and-System-Calls"><a href="#Tracing-Program-Execution-and-System-Calls" class="headerlink" title="Tracing Program Execution and System Calls"></a>Tracing Program Execution and System Calls</h3><p>The most common use is to start a program using <code>strace</code>, which prints a list of <code>system calls</code> made by the program. This is useful if the program continually crashes, or does not behave as expected; for example using strace may reveal that the program is attempting to access a file which does not exist or cannot be read.</p>
<p>The <code>strace</code> (system call trace) and <code>ltrace</code> (library trace) commands can help you discover what a program attempts to do. These tools produce extraordinarily large amounts of output, but once you know what to look for, you’ll have more tools at your disposal for tracking down problems.</p>
<p>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">strace cat not_a_file</span><br></pre></td></tr></table></figure></p>
<p>you get errors in <code>open(&quot;not_a_file&quot;, O_RDONLY)</code> line:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">execve(&quot;/usr/bin/cat&quot;, [&quot;cat&quot;, &quot;not_a_file&quot;], [/* 23 vars */]) = 0</span><br><span class="line">brk(NULL)                               = 0x81f000</span><br><span class="line">mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fc85159d000</span><br><span class="line">access(&quot;/etc/ld.so.preload&quot;, R_OK)      = -1 ENOENT (No such file or directory)</span><br><span class="line">...</span><br><span class="line">...</span><br><span class="line">close(3)                                = 0</span><br><span class="line">fstat(1, &#123;st_mode=S_IFCHR|0620, st_rdev=makedev(136, 0), ...&#125;) = 0</span><br><span class="line">open(&quot;not_a_file&quot;, O_RDONLY)            = -1 ENOENT (No such file or directory)</span><br><span class="line">write(2, &quot;cat: &quot;, 5cat: )                    = 5</span><br><span class="line">write(2, &quot;not_a_file&quot;, 10not_a_file) </span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h3 id="Threads"><a href="#Threads" class="headerlink" title="Threads"></a>Threads</h3><p>In Linux, some processes are divided into pieces called threads.</p>
<p>To display the thread information in <code>ps</code>, add the m option.<br>For example:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps axm -o pid,tid,command</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PID   TID   COMMAND</span><br><span class="line">1891     - db2ckpwd 0</span><br><span class="line">    -  1891 -</span><br><span class="line">1892     - db2ckpwd 0</span><br><span class="line">    -  1892 -</span><br><span class="line">3501     - db2fmp ( ,1,0,0,0,0,0,00000000,0,0,0,0000000000000000,0000000000000000,00000000,00000000,00000000,0000000</span><br><span class="line">    -  3501 -</span><br><span class="line">    -  3502 -</span><br><span class="line">    -  3503 -</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>The main thread ID is the as the process ID</p>
<h3 id="Introduction-to-Resource-Monitoring"><a href="#Introduction-to-Resource-Monitoring" class="headerlink" title="Introduction to Resource Monitoring"></a>Introduction to Resource Monitoring</h3><p>To monitor one or more specific processes over time, use the <code>-p</code> option to <code>top</code>, with this syntax:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">top -p &lt;pid&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="Adjusting-Process-Priorities"><a href="#Adjusting-Process-Priorities" class="headerlink" title="Adjusting Process Priorities"></a>Adjusting Process Priorities</h4><p>You can change the way the kernel <strong>schedules</strong> a process in order to give the process more or less CPU time than other processes. </p>
<p>The kernel runs each process according to its scheduling priority, which is a number between <code>–20</code> and <code>20</code>, with <code>–20</code> being the <strong>foremost</strong> priority.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ps axl</span><br><span class="line"></span><br><span class="line">F   UID   PID  PPID PRI  NI    VSZ   RSS WCHAN  STAT TTY        TIME COMMAND</span><br><span class="line">4  1000     1     0  20   0  15120  1596 do_wai Ss   ?          0:00 /bin/bash /opt/IBM/InformationServer/initScripts</span><br><span class="line">4     0  1882     1  20   0 1225076 48936 futex_ Sl  ?          0:00 db2wdog 0 [db2inst1]</span><br><span class="line">4  1000  1884  1882  20   0 10302284 1699292 futex_ Sl ?       58:25 db2sysc 0</span><br><span class="line">5     0  1890  1882  20   0 1227236 18292 do_msg S   ?          0:13 db2ckpwd 0</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">top</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND</span><br><span class="line"> 1884 db2inst1  20   0    9.8g   1.6g   1.6g S   1.3 10.4  58:25.82 db2sysc</span><br><span class="line">    1 db2inst1  20   0   15120   1596   1360 S   0.0  0.0   0:00.01 startcontainer.</span><br><span class="line"> 1882 root      20   0 1225076  48936  33072 S   0.0  0.3   0:00.13 db2syscr</span><br></pre></td></tr></table></figure>
<p><code>PR</code> is the priority value. <code>NI</code> (nice value), high nice value means nicer, more likely to give up CPU time.</p>
<p>Alter the nice value:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">renice &lt;value&gt; &lt;pid&gt;</span><br></pre></td></tr></table></figure></p>
<h4 id="Load-Averages"><a href="#Load-Averages" class="headerlink" title="Load Averages"></a>Load Averages</h4><p>The <code>load average</code> is the average number of processes currently ready to run. Keep in mind that most processes on your system are usually waiting for input (from the keyboard, mouse, or network, for example), meaning that most processes are not ready to run and should contribute nothing to the load average. Only processes that are actually doing something affect the load average.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># uptime</span><br><span class="line"></span><br><span class="line">... up 91 days, ... load average: 0.08, 0.03, 0.01</span><br></pre></td></tr></table></figure>
<p>The three numbers are the load averages for the past 1 minute, 5 minutes, and 15 minutes, respectively. An average of only 0.01 processes have been running across all processors for the past 15 minutes. </p>
<p>If a load average goes up to around 1, a single process is probably using the CPU nearly all of the time. To identify that process, use the top command; the process will usually rise to the the top of the display.</p>
<p>If you have two cores, a load average of 1 means that only one of the cores is likely active at any given time, and a load average of 2 means that both cores have just enough to do all of the time.</p>
<p>A high load average does not necessarily mean that your system is having trouble. A system with enough memory and I/O resources can easily handle many running processes. If your load average is high and your system still responds well, don’t panic</p>
<p>However, if you sense that the system is slow and the load average is high, you might be running into memory performance problems. </p>
<h3 id="Memory"><a href="#Memory" class="headerlink" title="Memory"></a>Memory</h3><p>CPU has a <code>memory management unit (MMU)</code> that translates the virtual memory addresses used by processes into real ones. The kernel assists the MMU by breaking the memory used by processes into smaller chunks called <code>pages</code>.</p>
<p>The kernel maintains a data structure, called a <code>page table</code>, that contains a mapping of a processes’ virtual page addresses to real page addresses in memory. As a process accesses memory, the MMU translates the virtual addresses used by the process into real addresses based on the kernel’s page table.</p>
<p>A user process does not actually need all of its pages to be immediately available in order to run. The kernel generally loads and allocates pages as a process needs them; this system is known as <code>on-demand paging</code> or just <code>demand paging</code>.</p>
<h4 id="Page-Faults"><a href="#Page-Faults" class="headerlink" title="Page Faults"></a>Page Faults</h4><p>If a memory page is not ready when a process wants to use it, the process triggers a <code>page fault</code>.</p>
<ul>
<li><p>MINOR PAGE FAULTS<br>A minor page fault occurs when the desired page is actually in main memory but the MMU doesn’t know where it is. This can happen when the process requests more memory or when the MMU doesn’t have enough space to store all of the page locations for a process. In this case, the kernel tells the MMU about the page and permits the process to continue. Minor page faults aren’t such a big deal, and many occur as a process runs. Unless you need maximum performance from some memory-intensive program, you probably shouldn’t worry about them.</p>
</li>
<li><p>MAJOR PAGE FAULTS<br>A major page fault occurs when the desired memory page isn’t in main memory at all, which means that the <strong>kernel must load it from the disk or some other slow storage mechanism</strong>. Some major page faults are unavoidable, such as those that occur when you load the code from disk when running a program for the first time. </p>
</li>
</ul>
<p>Let’s see the page faults:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># /usr/bin/time netstat &gt; /dev/null</span><br><span class="line"></span><br><span class="line">0.05user 0.02system 0:01.74elapsed 4%CPU (0avgtext+0avgdata 2556maxresident)k</span><br><span class="line">1752inputs+0outputs (3major+781minor)pagefaults 0swaps</span><br></pre></td></tr></table></figure></p>
<p>There are 3 major page faults and 781 minor page faults when running <code>netstat</code> program. The major page faults occurred when the kernel needed to load the program from the disk for the first time. If you ran the command again, you probably wouldn’t get any major page faults because the kernel would have cached the pages from the disk:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># /usr/bin/time netstat &gt; /dev/null</span><br><span class="line"></span><br><span class="line">0.04user 0.02system 0:01.61elapsed 3%CPU (0avgtext+0avgdata 2552maxresident)k</span><br><span class="line">0inputs+0outputs (0major+783minor)pagefaults 0swaps</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Note that <code>time</code> here is not the shell built-in <code>time</code> command! If you run<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; type -a time</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>you will see<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; time is a shell keyword</span><br><span class="line">&gt; time is /usr/bin/time</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></p>
</blockquote>
<blockquote>
<p>see this <a href="https://www.cyberciti.biz/faq/linux-command-to-see-major-minor-pagefaults/" target="_blank" rel="noopener">doc</a></p>
</blockquote>
<p>If you’d rather see the <strong>number</strong> of page faults of processes as they’re running, use <code>top</code> or <code>ps</code>. When running <code>top</code>, use <code>f</code> to add the displayed fields and space to display the <code>nMaj</code> and <code>nMin</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># top</span><br><span class="line"></span><br><span class="line">  PID USER      %CPU  PR  NI    VIRT    RES    SHR S %MEM     TIME+ COMMAND                                nMaj nMin</span><br><span class="line"> 1303 dsadm      1.7  20   0 4753196  82704  13412 S  0.5 158:31.05 java                                      0  25k</span><br><span class="line"> 1929 dsadm      0.3  20   0  203344   2556   2116 S  0.0   2:16.80 ResTrackApp                               0 1028</span><br></pre></td></tr></table></figure></p>
<p>When using <code>ps</code>, you can use a custom output format to view the page faults for a particular process:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ps -o pid,min_flt,maj_flt 1</span><br><span class="line"></span><br><span class="line">  PID  MINFL  MAJFL</span><br><span class="line">    1   2059      6</span><br></pre></td></tr></table></figure></p>
<h3 id="Monitoring-CPU-and-Memory-Performance"><a href="#Monitoring-CPU-and-Memory-Performance" class="headerlink" title="Monitoring CPU and Memory Performance"></a>Monitoring CPU and Memory Performance</h3><p>Among the many tools available to monitor system performance, the <code>vmstat</code> command is one of the oldest, with minimal overhead. You’ll find it handy for getting a high-level view of how often the kernel is swapping pages in and out, how busy the CPU is, and IO utilization.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vmstat 2</span><br><span class="line"></span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line"> 2  0      0 174452   1064 6874152    0    0    17    55    4    0  2  2 95  0  1</span><br><span class="line"> 2  0      0 173900   1064 6874168    0    0     0    16 10362 12869  5  3 90  0  2</span><br><span class="line"> 3  0      0 173932   1064 6874180    0    0     0   291 9110 10761  2  1 95  1  1</span><br><span class="line"> 0  0      0 174056   1064 6874180    0    0     0    59 9126 12447  3  3 92  0  1</span><br><span class="line"> 0  0      0 174228   1064 6874184    0    0     0   167 7100 9601  1  1 97  0  1</span><br></pre></td></tr></table></figure>
<p>Not easy to understand, can dig deeper into it by reading vmstat(8) manual page. </p>
<h3 id="I-O-Monitoring"><a href="#I-O-Monitoring" class="headerlink" title="I/O Monitoring"></a>I/O Monitoring</h3><p>Like <code>vmstat</code> and <code>netstat</code> (talk later), we have <code>iostat</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iostat 2 -d -p ALL</span><br><span class="line"></span><br><span class="line">Linux 3.10.0-862.14.4.el7.x86_64 (dstest1.fyre.ibm.com)         05/21/2019      _x86_64_        (8 CPU)</span><br><span class="line"></span><br><span class="line">Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn</span><br><span class="line">vda              18.12        87.72       201.61  270042131  620650624</span><br><span class="line">vda1              0.00         0.00         0.00      11165       2270</span><br><span class="line">vda2             13.59        87.71       201.61  270022634  620648353</span><br><span class="line">dm-0             17.99        86.13       201.61  265157850  620648353</span><br><span class="line">dm-1              0.06         1.58         0.00    4860836          0</span><br></pre></td></tr></table></figure></p>
<p>This means update every 2 seconds, show device only and show all partitions.</p>
<p>If you need to dig even deeper to see I/O resources used by individual processes, the <code>iotop</code> tool can help. Using <code>iotop</code> is similar to using top.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iotop</span><br><span class="line"></span><br><span class="line">Total DISK READ:         4.76 K/s | Total DISK WRITE:     333.31 K/s</span><br><span class="line">  TID  PRIO  USER       DISK READ DISK  WRITE  SWAPIN     IO&gt; COMMAND</span><br><span class="line">  260 be/3 root          0.00 B/s  38.09 K/s  0.00 %  6.98 % [jbd2/sda1-8]</span><br><span class="line"> 2611 be/4 juser         4.76 K/s  10.32 K/s  0.00 %  0.21 % zeitgeist-daemon</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure></p>
<p>It shows TID (thread ID) instead of PID, PRIO (priority) indicates the IO priority, <code>be/3</code> is more important than <code>be/4</code>. The kernel uses the <code>scheduling class</code> to add more control for I/O scheduling. You’ll see three scheduling classes from <code>iotop</code>:</p>
<ul>
<li><p><strong>be</strong> Best-effort. The kernel does its best to fairly schedule I/O for this class. Most processes run under this I/O scheduling class.</p>
</li>
<li><p><strong>rt</strong> Real-time. The kernel schedules any real-time I/O before any other class of I/O, no matter what.</p>
</li>
<li><p><strong>idle</strong> Idle. The kernel performs I/O for this class only when there is no other I/O to be done. There is no priority level for the idle scheduling class.</p>
</li>
</ul>
<h3 id="Per-Process-Monitoring"><a href="#Per-Process-Monitoring" class="headerlink" title="Per-Process Monitoring"></a>Per-Process Monitoring</h3><p>The <code>pidstat</code> utility allows you to see the resource consumption of a process over time in the style of <code>vmstat</code>.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># pidstat -p 27946 1</span><br><span class="line"></span><br><span class="line">Linux 3.10.0-862.14.4.el7.x86_64 (myk8s1.fyre.ibm.com)  05/21/2019      _x86_64_        (4 CPU)</span><br><span class="line"></span><br><span class="line">08:16:27 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">08:16:28 PM  1002     27946    0.00    0.00    0.00    0.00     3  tail</span><br><span class="line">08:16:29 PM  1002     27946    0.00    0.00    0.00    0.00     3  tail</span><br><span class="line">08:16:30 PM  1002     27946    0.00    0.00    0.00    0.00     3  tail</span><br></pre></td></tr></table></figure></p>
<p>The <code>CPU</code> column tells you about this process is running on which CPU.</p>
<h2 id="Chapter-9-Network-and-Configuration"><a href="#Chapter-9-Network-and-Configuration" class="headerlink" title="Chapter 9. Network and Configuration"></a>Chapter 9. Network and Configuration</h2><blockquote>
<p>Note that the <code>ifconfig</code> command, as well some of the others you’ll see later in this chapter (such as <code>route</code> and <code>arp</code>), has been technically supplanted with the newer <code>ip</code> command. The ip command can do more than the old commands, and it is preferable when writing scripts. However, most people still use the old commands when manually working with the network, and these commands can also be used on other versions of Unix. For this reason, we’ll use the old-style commands.</p>
</blockquote>
<h3 id="Routes-and-the-Kernel-Routing-Table"><a href="#Routes-and-the-Kernel-Routing-Table" class="headerlink" title="Routes and the Kernel Routing Table"></a>Routes and the Kernel Routing Table</h3><p>Let’s see the routing table by <code>route</code> command, <code>-n</code> means show numerical address instead of hostname:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># route -n</span><br><span class="line"></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         9.30.94.1       0.0.0.0         UG    0      0        0 eth1</span><br><span class="line">9.30.94.0       0.0.0.0         255.255.254.0   U     0      0        0 eth1</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0 eth0</span><br><span class="line">169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0 eth1</span><br><span class="line">172.16.0.0      0.0.0.0         255.255.0.0     U     0      0        0 eth0</span><br><span class="line">172.17.0.0      0.0.0.0         255.255.0.0     U     0      0        0 docker0</span><br><span class="line">192.168.0.0     0.0.0.0         255.255.255.0   U     0      0        0 *</span><br><span class="line">192.168.0.2     0.0.0.0         255.255.255.255 UH    0      0        0 calib4daf4f1db0</span><br><span class="line">192.168.0.3     0.0.0.0         255.255.255.255 UH    0      0        0 cali987b4d0c33f</span><br><span class="line">192.168.1.0     172.16.182.156  255.255.255.0   UG    0      0        0 eth0</span><br><span class="line">192.168.2.0     172.16.182.187  255.255.255.0   UG    0      0        0 eth0</span><br></pre></td></tr></table></figure></p>
<p>The <code>Destination</code> column tells you a network prefix (outside network), and the <code>Genmask</code> column is the netmask corresponding to that network. Each network has a <code>U</code> under its <code>Flags</code> column, indicating that the route is active (“up”).</p>
<p>There is a <code>G</code> in the <code>Flags</code> column, meaning that communication for this network must be sent through the gateway in the Gateway column, for example, for networl <code>0.0.0.0/0</code> send through it’s gateway <code>9.30.94.1</code>. If no <code>G</code> in <code>Flags</code>, indicating that the network is directly connected in some way.</p>
<p>An entry for <code>0.0.0.0/0</code> in the routing table has special significance because it matches any address on the Internet. This is the default route, and the address configured under the Gateway column (in the <code>route -n</code> output) in the default route is the <code>default gateway</code>.</p>
<h3 id="Basic-ICMP-and-DNS-Tools"><a href="#Basic-ICMP-and-DNS-Tools" class="headerlink" title="Basic ICMP and DNS Tools"></a>Basic ICMP and DNS Tools</h3><h4 id="ping"><a href="#ping" class="headerlink" title="ping"></a>ping</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># ping baidu.com</span><br><span class="line"></span><br><span class="line">PING baidu.com (123.125.114.144) 56(84) bytes of data.</span><br><span class="line">64 bytes from 123.125.114.144 (123.125.114.144): icmp_seq=1 ttl=40 time=212 ms</span><br><span class="line">64 bytes from 123.125.114.144 (123.125.114.144): icmp_seq=2 ttl=40 time=212 ms</span><br><span class="line">64 bytes from 123.125.114.144 (123.125.114.144): icmp_seq=3 ttl=40 time=212 ms</span><br><span class="line">^C</span><br><span class="line">--- baidu.com ping statistics ---</span><br><span class="line">3 packets transmitted, 3 received, 0% packet loss, time 2002ms</span><br><span class="line">rtt min/avg/max/mdev = 212.335/212.495/212.578/0.393 ms</span><br></pre></td></tr></table></figure>
<p><code>56(84) bytes of data</code> means send a 56 bytes packet (84 bytes when include header).<br><code>icmp_seq</code> is sequence number, sometimes you will have gap, usually means there’s some kind of connectivity problem.<br><code>time</code> is round-trip time.</p>
<h4 id="traceroute"><a href="#traceroute" class="headerlink" title="traceroute"></a>traceroute</h4><p>One of the best things about <code>traceroute</code> is that it reports return trip times at each step in the route:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## -n will not do hostname lookup for IP in output</span><br><span class="line"># traceroute -n google.com</span><br><span class="line"></span><br><span class="line">traceroute to google.com (172.217.1.206), 30 hops max, 60 byte packets</span><br><span class="line"> 1  9.30.94.3  0.626 ms  0.742 ms  0.845 ms</span><br><span class="line"> 2  9.30.156.13  0.529 ms  0.801 ms  0.918 ms</span><br><span class="line"> 3  9.55.129.109  0.668 ms  0.852 ms 9.55.129.105  0.515 ms</span><br><span class="line"> 4  9.55.187.13  0.476 ms  0.255 ms  0.425 ms</span><br><span class="line"> 5  9.55.128.6  0.326 ms  0.433 ms  0.294 ms</span><br><span class="line"> 6  9.64.38.194  0.941 ms  0.898 ms  0.843 ms</span><br><span class="line"> 7  9.64.3.86  18.220 ms  18.230 ms  18.229 ms</span><br><span class="line"> 8  9.64.3.85  31.521 ms  31.527 ms  31.563 ms</span><br><span class="line"> 9  9.17.3.35  31.803 ms  31.613 ms  31.875 ms</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure></p>
<h4 id="DNS-and-host"><a href="#DNS-and-host" class="headerlink" title="DNS and host"></a>DNS and host</h4><p>To find the IP address behind a domain name, use the <code>host</code> command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># host www.google.com</span><br><span class="line"></span><br><span class="line">www.google.com has address 172.217.11.228</span><br><span class="line">www.google.com has IPv6 address 2607:f8b0:400f:801::2004</span><br></pre></td></tr></table></figure></p>
<p>You can also use <code>host</code> in reverse: Enter an IP address instead of a hostname to try to discover the hostname behind the IP address. But don’t expect this to work reliably. Many hostnames can represent a single IP address, and DNS doesn’t know how to determine which hostname should correspond to an IP address. </p>
<h3 id="Kernel-Network-Interfaces"><a href="#Kernel-Network-Interfaces" class="headerlink" title="Kernel Network Interfaces"></a>Kernel Network Interfaces</h3><p>Network interfaces have names that usually indicate the kind of hardware underneath, such as <code>eth0</code> (the first Ethernet card in the computer) and <code>wlan0</code> (a wireless interface).</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">eth1: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 9.30.94.85  netmask 255.255.254.0  broadcast 9.30.95.255</span><br><span class="line">        ether 00:20:09:1e:5e:55  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 17164860  bytes 9046289828 (8.4 GiB)</span><br><span class="line">        RX errors 0  dropped 6  overruns 0  frame 0</span><br><span class="line">        TX packets 11669220  bytes 9566003426 (8.9 GiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure>
<p><code>UP,RUNNING</code> means this interface is active.</p>
<h3 id="Resolving-Hostnames"><a href="#Resolving-Hostnames" class="headerlink" title="Resolving Hostnames"></a>Resolving Hostnames</h3><p>On most systems, you can <strong>override</strong> hostname lookups with the <code>/etc/hosts</code> file.<br>Usually resolution will first check this file before resort to DNS server.</p>
<p>The traditional configuration file for DNS servers is <code>/etc/resolv.conf</code>:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">## this is the search pattern:</span><br><span class="line">search fyre.ibm.com. svl.ibm.com.</span><br><span class="line">nameserver 172.16.200.52</span><br><span class="line">nameserver 172.16.200.50</span><br></pre></td></tr></table></figure></p>
<p><code>172.16.200.52</code> and <code>172.16.200.50</code> are the DNS server IP.</p>
<h3 id="netstat-command"><a href="#netstat-command" class="headerlink" title="netstat command"></a>netstat command</h3><p>This <code>netstat</code> command is extremely important and common in use. Ususally I use <code>netstat -tunlp</code>, let’s dig deeper into it:</p>
<ul>
<li><code>-t</code>: show TCP connection.</li>
<li><code>-u</code>: show UDP connection.</li>
<li><code>-n</code>: show numerical addresses.</li>
<li><code>-l</code>: show only listening sockets.</li>
<li><code>-p</code>: show PID belongs to.</li>
</ul>
<p>Instead of <code>ifconfig</code> to see the interface, you can use:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># netstat -i</span><br><span class="line"></span><br><span class="line">Kernel Interface table</span><br><span class="line">Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg</span><br><span class="line">cali9550  1440 60880456      0      6 0      37444050      0      0      0 BMRU</span><br><span class="line">cali986f  1440        0      0      0 0             0      0      0      0 BMRU</span><br><span class="line">docker0   1500        0      0      0 0             0      0      0      0 BMU</span><br><span class="line">eth0      1500 5606028968      0      0 0      33647018      0      0      0 BMRU</span><br><span class="line">eth1      1500 60880456      0      6 0      37444050      0      0      0 BMRU</span><br><span class="line">lo       65536 431426103      0      0 0      431426103      0      0      0 LRU</span><br></pre></td></tr></table></figure></p>
<p>Instead of <code>route -n</code> to see route table, you can use:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># netstat -rn</span><br></pre></td></tr></table></figure></p>
<p>Show TCP connections (not include listening sockets):<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># netstat -tn</span><br></pre></td></tr></table></figure></p>
<p>To see well-known ports translate into names. check <code>/etc/services</code> file:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">http            80/tcp          www www-http    # WorldWideWeb HTTP</span><br><span class="line">http            80/udp          www www-http    # HyperText Transfer Protocol</span><br><span class="line">http            80/sctp                         # HyperText Transfer Protoco</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p>On Linux, only processes running as the superuser can use ports 1 through 1023. All user processes may listen on and create connections from ports 1024 and up.</p>
<p><strong>I skip the rest of this chapter, majority is concept</strong></p>
<h2 id="Chapter-10-Network-Applications-and-Services"><a href="#Chapter-10-Network-Applications-and-Services" class="headerlink" title="Chapter 10. Network Applications and Services"></a>Chapter 10. Network Applications and Services</h2><p>Let’s mainly focus on some important commands here:</p>
<h3 id="curl-command"><a href="#curl-command" class="headerlink" title="curl command"></a>curl command</h3><p><code>curl</code> is a command line tool to transfer data to or from a server, using any of the supported protocols (HTTP, FTP, IMAP, POP3, SCP, SFTP, SMTP, TFTP, TELNET, LDAP or FILE). <code>curl</code> is powered by <code>Libcurl</code>. This tool is preferred for automation, since it is designed to work without user interaction. curl can transfer multiple file at once.</p>
<p>you can refer this <a href="https://www.geeksforgeeks.org/curl-command-in-linux-with-examples/" target="_blank" rel="noopener">article</a>.</p>
<h3 id="Diagnostic-Tools"><a href="#Diagnostic-Tools" class="headerlink" title="Diagnostic Tools"></a>Diagnostic Tools</h3><p><code>lsof</code> can track open files, but it can also list the programs currently using or listening to ports. Please read more when you need this tool.</p>
<p><code>tcpdump</code>, a command tool version of wireshark.</p>
<p><code>netcat</code>(or <code>nc</code>) I used it before for developing PXEngine, we use TCP to replace ssh connection between conductor and compute containers. <code>netcat</code> can connect to remote TCP/UDP ports, specify a local port, listen on ports, scan ports, redirect standard I/O to and from network connections, and more.</p>
<p>I remember I use <code>nc</code> to listen on a port and on other side connect to that port and transfer data.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nc -l -p 1234</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nc localhost 1234</span><br></pre></td></tr></table></figure>
<p><code>nmap</code> scans all ports on a machine or network of machines looking for open ports, and it lists the ports it finds.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># nmap myk8s1.fyre.ibm.com</span><br><span class="line"></span><br><span class="line">Starting Nmap 6.40 ( http://nmap.org ) at 2019-05-22 23:33 PDT</span><br><span class="line">Nmap scan report for myk8s1.fyre.ibm.com (9.30.94.85)</span><br><span class="line">Host is up (0.00024s latency).</span><br><span class="line">Not shown: 995 closed ports</span><br><span class="line">PORT     STATE SERVICE</span><br><span class="line">22/tcp   open  ssh</span><br><span class="line">111/tcp  open  rpcbind</span><br><span class="line">179/tcp  open  bgp</span><br><span class="line">2049/tcp open  nfs</span><br><span class="line">5000/tcp open  upnp</span><br><span class="line"></span><br><span class="line">Nmap done: 1 IP address (1 host up) scanned in 0.20 seconds</span><br></pre></td></tr></table></figure></p>
<h2 id="Chapter-11-Introduction-to-Shell-Scripts"><a href="#Chapter-11-Introduction-to-Shell-Scripts" class="headerlink" title="Chapter 11. Introduction to Shell Scripts"></a>Chapter 11. Introduction to Shell Scripts</h2><p>A shell script is a series of commands written in a file.<br>The <code>#!</code> part is called a <code>shebang</code>.</p>
<p>When writing scripts and working on the command line, just remember what happens whenever the shell runs a command:</p>
<ol>
<li>Before running the command, the shell looks for variables, globs, and other substitutions and performs the substitutions if they appear.</li>
<li>The shell passes the results of the substitutions to the command.</li>
</ol>
<p>if you use single quote:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep &apos;r.*t&apos; /etc/passwd</span><br></pre></td></tr></table></figure></p>
<p>This will prevent sheel from expanding the <code>*</code> in current directory.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep &apos;r.*t /etc/passwd&apos;</span><br></pre></td></tr></table></figure></p>
<p>This will fail, because things wrapped by single/double quote treat as one parameter.</p>
<p>Double quotes (“) work just like single quotes, except that the shell expands <strong>variables</strong> that appear within double quotes. It will not expand globs like <code>*</code> in double quotes!</p>
<p>Just like I saw, use <code>shift</code> to forward arguments passed in:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">echo $1</span><br><span class="line">shift</span><br><span class="line">echo $1</span><br></pre></td></tr></table></figure></p>
<p><code>$#</code> is the number of arguments passed in, used in loop to pick up parameters.<br><code>$@</code> represents all of the script arguments.<br><code>$$</code> holds the PID of current shell.</p>
<p>bad message should go to standard error, just like redriect standard error to standard output:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo $0: bad option ... 1&gt;&amp;2</span><br></pre></td></tr></table></figure></p>
<p><code>$?</code> exit code: If you intend to use the exit code of a command, you <strong>must</strong> use or store the code immediately after running the command. </p>
<h3 id="if-condition"><a href="#if-condition" class="headerlink" title="if condition"></a>if condition</h3><p>Let’s see an example, these 2 are good:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if [ &quot;$1&quot; = hi ]; then</span><br><span class="line">if [ x&quot;$1&quot; = x&quot;hi&quot; ]; then</span><br></pre></td></tr></table></figure></p>
<p>Here, <code>&quot;&quot;</code> is vital, since user may not input <code>$1</code>, if no double quotes, it could be:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">if [ = hi ]; then</span><br></pre></td></tr></table></figure></p>
<p>the test (<code>[</code>) command aborts immediately.</p>
<blockquote>
<p>Note that the stuff follows <code>if</code> is a command! so we have <code>;</code> before <code>then</code>.</p>
</blockquote>
<p>So you can use other commands instead of <code>[</code> command, cool!<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">if grep -q daemon /etc/passwd; then</span><br><span class="line">    echo The daemon user is in the passwd file.</span><br><span class="line">else</span><br><span class="line">    echo There is a big problem. daemon is not in the passwd file.</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></p>
<p>Let’s see <code>&amp;&amp;</code> and <code>||</code> and test condition:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">if [ &quot;$1&quot; = hi ] || [ &quot;$1&quot; = bye ]; then</span><br><span class="line">    echo &apos;The first argument was &quot;&apos;$1&apos;&quot;&apos;</span><br><span class="line">fi</span><br></pre></td></tr></table></figure></p>
<p>The <code>-a</code> and <code>-o</code> flags are the logical <code>and</code> and <code>or</code> operators in test:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ &quot;$1&quot; = hi -o &quot;$1&quot; = ho ]</span><br></pre></td></tr></table></figure></p>
<h3 id="test-command"><a href="#test-command" class="headerlink" title="test command"></a>test command</h3><p>There are dozens of test operations, all of which fall into three general categories: file tests, string tests, and arithmetic tests.</p>
<h4 id="file-filter"><a href="#file-filter" class="headerlink" title="file filter"></a>file filter</h4><p><code>-f</code>: regular file return 0<br><code>-e</code>: file exist return 0<br><code>-s</code>: not empty file return 0<br><code>-d</code>: directory return 0<br><code>-h</code>: softlink return 0</p>
<p>File permission:<br><code>-r</code>: readable<br><code>-w</code>: writable<br><code>-x</code>: executable<br><code>-u</code>: setuid<br><code>-g</code>: setgid<br><code>-k</code>: sticky</p>
<blockquote>
<p>The test command follows symbolic links (except for the <code>-h</code> test). That is, if link is a symbolic link to a regular file, [ <code>-f</code> link ] returns an exit code of true (0).</p>
</blockquote>
<p>Finally, three binary operators (tests that need two files as arguments) are used in file tests, but they’re not terribly common.<br><code>[ file1 -nt file2 ]</code>: if file1 has a newer modification date than file2 return 0<br><code>[ file1 -ot file2 ]</code>: if file1 has a older modification date than file2 return 0<br><code>[ file1 -ef file2 ]</code>: compares two files and returns true if they share inode numbers and devices.</p>
<h4 id="string-test"><a href="#string-test" class="headerlink" title="string test"></a>string test</h4><p><code>=</code>: equal<br><code>!=</code>: not equal<br><code>-z</code>: empty string return 0<br><code>-n</code>: not empty return 0</p>
<h4 id="arithmetic-test"><a href="#arithmetic-test" class="headerlink" title="arithmetic test"></a>arithmetic test</h4><p><code>-eq</code>: equal to<br><code>-ne</code>: not equal to<br><code>-lt</code>: less than<br><code>-gt</code>: greater than<br><code>-le</code>: less than or equal to<br><code>-ge</code>: greater than or equal to</p>
<h3 id="case-condition"><a href="#case-condition" class="headerlink" title="case condition"></a>case condition</h3><p>The case keyword forms another conditional construct that is exceptionally useful for matching strings, it can do pattern matching:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">case $1 in</span><br><span class="line">    bye)</span><br><span class="line">        echo Fine, bye.</span><br><span class="line">        ;;</span><br><span class="line">    hi|hello)</span><br><span class="line">        echo Nice to see you.</span><br><span class="line">        ;;</span><br><span class="line">    what*)</span><br><span class="line">        echo Whatever.</span><br><span class="line">        ;;</span><br><span class="line">    *)</span><br><span class="line">        echo &apos;Huh?&apos;</span><br><span class="line">        ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>Each case must end with a double semicolon (;;) or you risk a syntax error.</p>
</blockquote>
<h3 id="loop"><a href="#loop" class="headerlink" title="loop"></a>loop</h3><p>for loop:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">for str in one two three four; do</span><br><span class="line">    echo $str</span><br><span class="line">done</span><br></pre></td></tr></table></figure></p>
<p>while loop:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">FILE=/tmp/whiletest.$$;</span><br><span class="line">echo firstline &gt; $FILE</span><br><span class="line">while tail -10 $FILE | grep -q firstline; do</span><br><span class="line">    # add lines to $FILE until tail -10 $FILE no longer prints &quot;firstline&quot;</span><br><span class="line">    echo -n Number of lines in $FILE:&apos; &apos;</span><br><span class="line">    wc -l $FILE | awk &apos;&#123;print $1&#125;&apos;</span><br><span class="line">    echo newline &gt;&gt; $FILE</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">rm -f $FILE</span><br></pre></td></tr></table></figure></p>
<p>In fact, if you find that you need to use while, you should probably be using a language like awk or Python instead.</p>
<h3 id="Command-Substitution"><a href="#Command-Substitution" class="headerlink" title="Command Substitution"></a>Command Substitution</h3><p>You can use a command’s output as an argument to another command, or you can store the command output in a shell variable by enclosing a command in <code>$()</code>.</p>
<h3 id="Temporary-File-Management"><a href="#Temporary-File-Management" class="headerlink" title="Temporary File Management"></a>Temporary File Management</h3><p>Note the <code>mktemp</code> command:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">TMPFILE1=$(mktemp /tmp/im1.XXXXXX)</span><br><span class="line">TMPFILE2=$(mktemp /tmp/im2.XXXXXX)</span><br><span class="line"></span><br><span class="line">cat /proc/interrupts &gt; $TMPFILE1</span><br><span class="line">sleep 2</span><br><span class="line">cat /proc/interrupts &gt; $TMPFILE2</span><br><span class="line">diff $TMPFILE1 $TMPFILE2</span><br><span class="line">rm -f $TMPFILE1 $TMPFILE2</span><br></pre></td></tr></table></figure></p>
<p>If the script is aborted, the temporary files could be left behind. In the preceding example, pressing <code>CTRL-C</code> before the second cat command leaves a temporary file in <code>/tmp</code>. Avoid this if possible. Instead, use the <code>trap</code> command to create a signal handler to catch the signal that <code>CTRL-C</code> generates and remove the temporary files, as in this handler:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/bin/sh</span><br><span class="line">TMPFILE1=$(mktemp /tmp/im1.XXXXXX)</span><br><span class="line">TMPFILE2=$(mktemp /tmp/im2.XXXXXX)</span><br><span class="line">trap &quot;rm -f $TMPFILE1 $TMPFILE2; exit 1&quot; INT</span><br></pre></td></tr></table></figure></p>
<p>You must use exit in the handler to explicitly end script execution, or the shell will continue running as usual after running the signal handler.</p>
<blockquote>
<p>Note that in <code>startcontainer.sh</code> we also have trap and we use shell function there, now I understand!</p>
</blockquote>
<h3 id="Important-Shell-Script-Utilities"><a href="#Important-Shell-Script-Utilities" class="headerlink" title="Important Shell Script Utilities"></a>Important Shell Script Utilities</h3><h4 id="basename"><a href="#basename" class="headerlink" title="basename"></a>basename</h4><p>This one strip the extension of file name:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># basename example.html .html</span><br><span class="line"></span><br><span class="line">example</span><br></pre></td></tr></table></figure></p>
<p>This one git rid of directory in full path:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># basename /usr/local/bin/example</span><br><span class="line"></span><br><span class="line">example</span><br></pre></td></tr></table></figure></p>
<h4 id="awk"><a href="#awk" class="headerlink" title="awk"></a>awk</h4><p>The <code>awk</code> command is not a simple single-purpose command; it’s actually a powerful programming language. Unfortunately, awk usage is now something of a lost art, having been replaced by larger languages such as Python.</p>
<h4 id="sed"><a href="#sed" class="headerlink" title="sed"></a>sed</h4><p>The sed program (sed stands for stream editor) is an automatic <strong>text editor</strong> that takes an input stream (a file or the standard input), alters it according to some expression, and prints the results to standard output.</p>
<h4 id="xargs"><a href="#xargs" class="headerlink" title="xargs"></a>xargs</h4><p>When you have to run one command on a huge number of files, the command or shell may respond that it can’t fit all of the arguments in its buffer.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># find . -name &apos;*.gif&apos; -print0 | xargs -0 file</span><br></pre></td></tr></table></figure></p>
<p>xargs starts a lot of processes, so don’t expect great performance if you have a large list of files.</p>
<p>There’s an alternative to <code>xargs</code> when using <code>find</code>: the <code>-exec</code> option. However, the syntax is somewhat tricky because you need to supply a <code>{}</code> to substitute the filename and a literal <code>;</code> to indicate the end of the command.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . -name &apos;*.gif&apos; -exec file &#123;&#125; \;</span><br></pre></td></tr></table></figure></p>
<h4 id="expr"><a href="#expr" class="headerlink" title="expr"></a>expr</h4><p>The <code>expr</code> command is a clumsy, slow way of doing math. If you find yourself using it frequently, you should probably be using a language like Python instead of a shell script.</p>
<h3 id="Subshells"><a href="#Subshells" class="headerlink" title="Subshells"></a>Subshells</h3><p>An entirely <strong>new</strong> shell process that you can create just to run a command or two. The new shell has a <strong>copy</strong> of the original shell’s environment, and when the new shell exits, any changes you made to its shell environment disappear, leaving the initial shell to run as normal.</p>
<p>Using a subshell to make a single-use alteration to an environment variable is such a common task:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># (PATH=/usr/confusing:$PATH; ./runprogram.sh)</span><br></pre></td></tr></table></figure></p>
<h2 id="Chapter-12-Moving-Files-Across-the-Network"><a href="#Chapter-12-Moving-Files-Across-the-Network" class="headerlink" title="Chapter 12. Moving Files Across the Network"></a>Chapter 12. Moving Files Across the Network</h2><h3 id="Quick-copy-browser"><a href="#Quick-copy-browser" class="headerlink" title="Quick copy browser"></a>Quick copy browser</h3><p>Go to target directory run:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python -m SimpleHTTPServer</span><br></pre></td></tr></table></figure></p>
<p>This usually open 8000 port on your machine, then go to another machine open:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># use ifconfig to check the source machine IP</span><br><span class="line">192.168.1.29:8000</span><br></pre></td></tr></table></figure></p>
<p>you can see the content there.</p>
<h3 id="rsync"><a href="#rsync" class="headerlink" title="rsync"></a>rsync</h3><p>Actually you can first enable Mac ssh access then use <code>rsync</code> to backup files:<br>System Preference -&gt; Sharing -&gt; check remote login</p>
<p>To get <code>rsync</code> working between two hosts, the rsync program must be installed on both the source and destination, and you’ll need a way to access one machine from the other.</p>
<p>Copy files to remote home:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync files remote:</span><br><span class="line">rsync files user@remote:</span><br></pre></td></tr></table></figure></p>
<p>If <code>rsync</code> isn’t in the remote path but is on the system, use <code>--rsync-path=path</code> to manually specify its location.</p>
<p>Unless you supply extra options, <code>rsync</code> copies only files. You will see:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">skipping directory xxx</span><br></pre></td></tr></table></figure></p>
<p>To transfer entire directory hierarchies, complete with symbolic links, permissions, modes, and devices—use the <code>-a</code> option.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -nv files -a dir user@remote:</span><br></pre></td></tr></table></figure></p>
<p><code>-n</code>: dry-run, this is vital when you are not sure.<br><code>-vv</code>: verbose mode</p>
<p>To make an exact replica of the source directory, you must delete files in the destination directory that do not exist in the source directory:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -v --delete -a dir user@remote:</span><br></pre></td></tr></table></figure></p>
<p>Please use <code>-n</code> dry-run to see what will be deleted before performing command.</p>
<p>Be particular careful with tailing slash after dir:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -a dir/ user@remote:dest</span><br></pre></td></tr></table></figure></p>
<p>This will copy all files under dir to dest folder in remote instead of copy dir into dest.</p>
<p>You can also <code>--exclude=</code>, <code>--exclude-from=</code> and <code>--include=</code> in command.</p>
<p>To speed operation, <code>rsync</code> uses a quick check to determine whether any files on the transfer source are already on the destination. The quick check uses a combination of the file size and its last-modified date. </p>
<p>When the files on the source side are not identical to the files on the destination side, <code>rsync</code> transfers the source files and overwrites any files that exist on the remote side. The default behavior may be inadequate, though, because you may need additional reassurance that files are indeed the same before skipping over them in transfers, or you may want to put in some extra safeguards.</p>
<ul>
<li><p><code>--checksum</code>(abbreviation: <code>-c</code>) Compute checksums (mostly unique signatures) of the files to see if they’re the same. This consumes additional I/O and CPU resources during transfers, but if you’re dealing with sensitive data or files that often have uniform sizes, this option is a must. (This will focus on file content, not date stamp)</p>
</li>
<li><p><code>--ignore-existing</code> Doesn’t clobber files already on the target side.</p>
</li>
<li><p><code>--backup</code> (abbreviation: <code>-b</code>) Doesn’t clobber files already on the target but rather renames these existing files by adding a <code>~</code> suffix to their names before transferring the new files.</p>
</li>
<li><p><code>--suffix=s</code> Changes the suffix used with –backup from <code>~</code> to <code>s</code>.</p>
</li>
<li><p><code>--update</code> (abbreviation: <code>-u</code>) Doesn’t clobber any file on the target that has a later date than the corresponding file on the source.</p>
</li>
</ul>
<p>You can also compress the dir when transfer:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -az dir user@remote:</span><br></pre></td></tr></table></figure></p>
<p>You can also reverse the process:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rsync -a user@remote:dir dest</span><br></pre></td></tr></table></figure></p>
<p>The rest of this chapter talks <code>samba</code> for file sharing, I skip it.</p>
<h2 id="Chapter-13-User-Environments"><a href="#Chapter-13-User-Environments" class="headerlink" title="Chapter 13. User Environments"></a>Chapter 13. User Environments</h2><p>Startup files play an important role at this point, because they set defaults for the shell and other interactive programs. They determine how the system behaves when a user logs in.</p>
<p>I see vi theme config in <code>~/.bashrc</code> file.</p>
<h3 id="The-Command-Path"><a href="#The-Command-Path" class="headerlink" title="The Command Path"></a>The Command Path</h3><p>The most important part of any shell startup file is the command path. The path should cover the directories that contain every application of interest to a regular user. At the very least, the path should contain these components, in order:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/usr/local/bin</span><br><span class="line">/usr/bin</span><br><span class="line">/bin</span><br></pre></td></tr></table></figure></p>
<p>If the application is on another directory, use symbolic link to <code>/usr/local/bin</code> or you defined <code>bin</code> folder.</p>
<h3 id="The-prompt"><a href="#The-prompt" class="headerlink" title="The prompt"></a>The prompt</h3><p>I never use this so far, usually prompt shows hostname, username, current directory and sign (<code>$</code> or <code>#</code>). you can change the color and more.</p>
<h3 id="Alias"><a href="#Alias" class="headerlink" title="Alias"></a>Alias</h3><p>This is common use, sometimes I use shell functions too.</p>
<h3 id="Permission-mask"><a href="#Permission-mask" class="headerlink" title="Permission mask"></a>Permission mask</h3><p>It depends on your needs:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">umask 022/077</span><br></pre></td></tr></table></figure></p>
<h3 id="Startup-file-order"><a href="#Startup-file-order" class="headerlink" title="Startup file order"></a>Startup file order</h3><p>These startup files are used to create <strong>environment</strong>. Each script has a specific use and affects the login environment differently. Every subsequent script executed can override the values assigned by previous scripts.</p>
<p>The two main shell <code>instance types</code> are <code>interactive</code> and <code>noninteractive</code>, but of those, only interactive shells are of interest because noninteractive shells (such as those that run shell scripts) usually don’t read any startup files. </p>
<p>Interactive shells are the ones that you use to <strong>run commands from a terminal</strong>, they can be classified as <code>login</code> or <code>non-login</code>.</p>
<p>I know there are lots of startup files under each user’s home directory or in other system folder, how do they take effect? In what order:<br><strong>Reference Doc</strong><br><a href="http://howtolamp.com/articles/difference-between-login-and-non-login-shell/" target="_blank" rel="noopener">Difference between Login shell and Non login shell</a></p>
<p>Logging in remotely with <code>SSH</code> also gives you a login shell. </p>
<p>You can tell if a shell is a login shell by running <code>echo $0</code>; if the first character is a <code>-</code>, the shell’s a login shell.</p>
<p>When Bash is invoked as a <code>Login</code> shell:</p>
<ol>
<li>Login process calls <code>/etc/profile</code></li>
<li><code>/etc/profile</code> calls the scripts in <code>/etc/profile.d/</code></li>
<li>Login process calls <code>~/.bash_profile</code>, <code>~/.bash_login</code> and <code>~/.profile</code>. running only the first one that it sees.</li>
</ol>
<p>Login Shells created by explicitly telling to login.<br>examples: <code># su - | # su -l | # su --login | # su USERNAME - | # su -l USERNAME | # su --login USERNAME | # sudo -i</code></p>
<p>When bash is invoked as a <code>Non-login</code> shell;</p>
<ol>
<li>Non-login process(shell) calls <code>/etc/bashrc</code></li>
<li>then calls <code>~/.bashrc</code></li>
</ol>
<p><code>Non-Login</code> shells created using the below command syntax:<br>examples: <code># su | # su USERNAME</code></p>
<p>Note that I can run <code>bash</code> or <code>sh</code> or <code>csh</code> in terminal, it will give me a new simple prompt without user profile or setting…</p>
<p>It seems if you use non-login like <code>su dsadm</code>, the export env vars are still there in <code>env</code> scope, I think the reason is it’s not login! still use current environment. But if you run <code>su - dsadm</code>, it is gone.</p>
]]></content>
      <categories>
        <category>Book</category>
      </categories>
      <tags>
        <tag>book</tag>
        <tag>linux</tag>
      </tags>
  </entry>
</search>
